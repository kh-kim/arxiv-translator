<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2105.09680] KLUE: Korean Language Understanding Evaluation</title><meta property="og:description" content="We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE is a collection of 8 Korean natural language understanding (NLU) tasks, including Topic Classification, Semantic Textual Similarity, Natural …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="KLUE: Korean Language Understanding Evaluation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="KLUE: Korean Language Understanding Evaluation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2105.09680">

<!--Generated on Fri Mar  8 00:24:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="ACROFAN (Acrofan News), AIRBNB (Airbnb Reviews), CC-100-Kor, DP (Dependency Parsing), DST (Dialogue State Tracking), KLUE , KLUE-BERT, KLUE-DP, KLUE-MRC, KLUE-NER, KLUE-NLI, KLUE-RE, KLUE-RoBERTa, KLUE-STS, MODU (Modu Corpus), MRC (Machine Reading Comprehension), NAMUWIKI, NER (Named Entity Recognition), NEWSCRAWL, NLI (Natural Language Inference), NSMC (NAVER Sentiment Movie Corpus), PARAKQC, PETITION, POLICY (Policy News), RE (Relation Extraction), STS (Semantic Textual Similarity), TC (Topic Classification), The Korea Economy Daily, WIKINEWS, WIKIPEDIA, WIKITREE, WoS (Wizard of Seoul, KLUE-DST), YNA (Yonhap News Agency), YNAT (YNA Topic Classification, KLUE-TC)">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">[columns=2, intoc]</p>
</div>
<h1 class="ltx_title ltx_title_document">KLUE: Korean Language Understanding Evaluation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Sungjoon Park<sup id="id5.4.id1" class="ltx_sup">*</sup>
<br class="ltx_break"><span id="id3.3.3" class="ltx_text" style="font-size:90%;">Upstage, KAIST
<br class="ltx_break"><span id="id3.3.3.4" class="ltx_text ltx_font_typewriter" style="font-size:78%;">sungjoon.park@kaist.ac.kr<span id="id3.3.3.4.1" class="ltx_text ltx_font_serif">&amp;Jihyung Moon<sup id="id3.3.3.4.1.1" class="ltx_sup">*</sup>
<br class="ltx_break"></span></span>Upstage
<br class="ltx_break"><span id="id3.3.3.5" class="ltx_text ltx_font_typewriter" style="font-size:78%;">jihyung.moon@upstage.ai<span id="id3.3.3.5.1" class="ltx_text ltx_font_serif">&amp;Sungdong Kim<sup id="id3.3.3.5.1.1" class="ltx_sup">*</sup>
<br class="ltx_break"></span></span>NAVER AI Lab
<br class="ltx_break"><span id="id1.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:78%;">sungdong.kim@navercorp.com<span id="id1.1.1.1.2" class="ltx_text ltx_font_serif"> &amp;Won Ik Cho<sup id="id1.1.1.1.2.1" class="ltx_sup">*</sup>
<br class="ltx_break"><span id="id1.1.1.1.2.2" class="ltx_text" style="font-size:114%;">Seoul National University
<br class="ltx_break"></span></span>tsatsuki@snu.ac.kr<span id="id1.1.1.1.1" class="ltx_text ltx_font_serif"> &amp;Jiyoon Han<sup id="id1.1.1.1.1.1" class="ltx_sup"><math id="id1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="id1.1.1.1.1.1.m1.1a"><mo id="id1.1.1.1.1.1.m1.1.1" xref="id1.1.1.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id1.1.1.1.1.1.m1.1b"><ci id="id1.1.1.1.1.1.m1.1.1.cmml" xref="id1.1.1.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.1.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
<br class="ltx_break"></span></span>Yonsei University
<br class="ltx_break"><span id="id3.3.3.6" class="ltx_text ltx_font_typewriter" style="font-size:78%;">clinamen35@yonsei.ac.kr<span id="id3.3.3.6.1" class="ltx_text ltx_font_serif"> &amp;Jangwon Park
<br class="ltx_break"></span>jangwon.pk@gmail.com<span id="id3.3.3.6.2" class="ltx_text ltx_font_serif"> &amp;Chisung Song
<br class="ltx_break"></span>daydrilling@gmail.com<span id="id3.3.3.6.3" class="ltx_text ltx_font_serif"> &amp;Junseong Kim
<br class="ltx_break"></span></span>Scatter Lab
<br class="ltx_break"><span id="id3.3.3.7" class="ltx_text ltx_font_typewriter" style="font-size:56%;">junseong.kim@scatterlab.co.kr<span id="id3.3.3.7.1" class="ltx_text ltx_font_serif"> &amp;Youngsook Song
<br class="ltx_break"></span></span>KyungHee University 
<br class="ltx_break"><span id="id2.2.2.2" class="ltx_text ltx_font_typewriter" style="font-size:78%;">youngsoksong@khu.ac.kr<span id="id2.2.2.2.1" class="ltx_text ltx_font_serif"> &amp;Taehwan Oh<sup id="id2.2.2.2.1.1" class="ltx_sup"><math id="id2.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="id2.2.2.2.1.1.m1.1a"><mo id="id2.2.2.2.1.1.m1.1.1" xref="id2.2.2.2.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id2.2.2.2.1.1.m1.1b"><ci id="id2.2.2.2.1.1.m1.1.1.cmml" xref="id2.2.2.2.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id2.2.2.2.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
<br class="ltx_break"></span></span>Yonsei University 
<br class="ltx_break"><span id="id3.3.3.8" class="ltx_text ltx_font_typewriter" style="font-size:78%;">ghksl0604@yonsei.ac.kr<span id="id3.3.3.8.1" class="ltx_text ltx_font_serif"> &amp;Joohong Lee
<br class="ltx_break"></span></span>Scatter Lab
<br class="ltx_break"><span id="id3.3.3.3" class="ltx_text ltx_font_typewriter" style="font-size:78%;">joohong@scatterlab.co.kr<span id="id3.3.3.3.1" class="ltx_text ltx_font_serif"> &amp;Juhyun Oh<sup id="id3.3.3.3.1.1" class="ltx_sup"><math id="id3.3.3.3.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="id3.3.3.3.1.1.m1.1a"><mo id="id3.3.3.3.1.1.m1.1.1" xref="id3.3.3.3.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id3.3.3.3.1.1.m1.1b"><ci id="id3.3.3.3.1.1.m1.1.1.cmml" xref="id3.3.3.3.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id3.3.3.3.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
<br class="ltx_break"><span id="id3.3.3.3.1.2" class="ltx_text" style="font-size:114%;">Seoul National University 
<br class="ltx_break"></span></span>411juhyun@snu.ac.kr<span id="id3.3.3.3.2" class="ltx_text ltx_font_serif"> &amp;Sungwon Lyu
<br class="ltx_break"></span></span>Kakao Enterprise 
<br class="ltx_break"><span id="id3.3.3.9" class="ltx_text ltx_font_typewriter" style="font-size:56%;">james.ryu@kakaoenterprise.com<span id="id3.3.3.9.1" class="ltx_text ltx_font_serif"> &amp;Younghoon Jeong
<br class="ltx_break"></span></span>Sogang University 
<br class="ltx_break"><span id="id3.3.3.10" class="ltx_text ltx_font_typewriter" style="font-size:78%;">boychaboy@sogang.ac.kr<span id="id3.3.3.10.1" class="ltx_text ltx_font_serif"> &amp;Inkwon Lee
<br class="ltx_break"></span></span>Sogang University 
<br class="ltx_break"><span id="id3.3.3.11" class="ltx_text ltx_font_typewriter" style="font-size:78%;">md98765@naver.com<span id="id3.3.3.11.1" class="ltx_text ltx_font_serif"> &amp;Sangwoo Seo
<br class="ltx_break"></span></span>Scatter Lab 
<br class="ltx_break"><span id="id3.3.3.12" class="ltx_text ltx_font_typewriter" style="font-size:56%;">sangwoo@scatterlab.co.kr<span id="id3.3.3.12.1" class="ltx_text ltx_font_serif"> &amp;Dongjun Lee
<br class="ltx_break"></span>humanbrain.djlee@gmail.com<span id="id3.3.3.12.2" class="ltx_text ltx_font_serif"> &amp;Hyunwoo Kim
<br class="ltx_break"><span id="id3.3.3.12.2.1" class="ltx_text" style="font-size:160%;">Seoul National University 
<br class="ltx_break"></span></span><span id="id3.3.3.12.3" class="ltx_text" style="font-size:140%;">hyunw.kim@vl.snu.ac.kr<span id="id3.3.3.12.3.1" class="ltx_text ltx_font_serif"> &amp;Myeonghwa Lee
<br class="ltx_break"></span></span></span>KAIST 
<br class="ltx_break"><span id="id3.3.3.13" class="ltx_text ltx_font_typewriter" style="font-size:78%;">myeon9h@kaist.ac.kr<span id="id3.3.3.13.1" class="ltx_text ltx_font_serif"> &amp;Seongbo Jang
<br class="ltx_break"></span></span>Scatter Lab 
<br class="ltx_break"><span id="id3.3.3.14" class="ltx_text ltx_font_typewriter" style="font-size:56%;">seongbo@scatterlab.co.kr<span id="id3.3.3.14.1" class="ltx_text ltx_font_serif"> &amp;Seungwon Do
<br class="ltx_break"></span><span id="id3.3.3.14.2" class="ltx_text" style="font-size:140%;">seungwon.do1@gmail.com<span id="id3.3.3.14.2.1" class="ltx_text ltx_font_serif"> &amp;Sunkyoung Kim
<br class="ltx_break">KAIST 
<br class="ltx_break"></span>sunkyoung@kaist.ac.kr<span id="id3.3.3.14.2.2" class="ltx_text ltx_font_serif"> &amp;Kyungtae Lim
<br class="ltx_break"><span id="id3.3.3.14.2.2.1" class="ltx_text" style="font-size:114%;">Hanbat National University 
<br class="ltx_break"></span></span>ktlim@hanbat.ac.kr<span id="id3.3.3.14.2.3" class="ltx_text ltx_font_serif"> &amp;Jongwon Lee
<br class="ltx_break"></span>mybizzer@gmail.com<span id="id3.3.3.14.2.4" class="ltx_text ltx_font_serif"> &amp;Kyumin Park
<br class="ltx_break"></span></span></span>KAIST 
<br class="ltx_break"><span id="id3.3.3.15" class="ltx_text ltx_font_typewriter" style="font-size:78%;">pkm9403@kaist.ac.kr<span id="id3.3.3.15.1" class="ltx_text ltx_font_serif"> &amp;Jamin Shin
<br class="ltx_break"></span></span>Riiid AI Research 
<br class="ltx_break"><span id="id3.3.3.16" class="ltx_text ltx_font_typewriter" style="font-size:78%;">jshin49@gmail.com<span id="id3.3.3.16.1" class="ltx_text ltx_font_serif"> &amp;Seonghyun Kim 
<br class="ltx_break"></span>bananaband657@gmail.com<span id="id3.3.3.16.2" class="ltx_text ltx_font_serif"> &amp;Lucy Park
<br class="ltx_break"></span></span>Upstage 
<br class="ltx_break"><span id="id3.3.3.17" class="ltx_text ltx_font_typewriter" style="font-size:78%;">lucy@upstage.ai<span id="id3.3.3.17.1" class="ltx_text ltx_font_serif"> &amp;Alice Oh<sup id="id3.3.3.17.1.1" class="ltx_sup">**</sup>
<br class="ltx_break"></span></span>KAIST 
<br class="ltx_break"><span id="id3.3.3.18" class="ltx_text ltx_font_typewriter" style="font-size:78%;">alice.oh@kaist.edu<span id="id3.3.3.18.1" class="ltx_text ltx_font_serif"> &amp;Jung-Woo Ha<sup id="id3.3.3.18.1.1" class="ltx_sup">**</sup>
<br class="ltx_break"></span></span>NAVER AI Lab 
<br class="ltx_break"><span id="id3.3.3.19" class="ltx_text ltx_font_typewriter" style="font-size:78%;">jungwoo.ha@navercorp.com<span id="id3.3.3.19.1" class="ltx_text ltx_font_serif"> &amp;Kyunghyun Cho<sup id="id3.3.3.19.1.1" class="ltx_sup">**</sup>
<br class="ltx_break"></span></span>New York University 
<br class="ltx_break"><span id="id3.3.3.20" class="ltx_text ltx_font_typewriter" style="font-size:78%;">kyunghyun.cho@nyu.edu<span id="id3.3.3.20.1" class="ltx_text ltx_font_serif">
</span></span></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.1" class="ltx_p">We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE is a collection of 8 Korean natural language understanding (NLU) tasks, including Topic Classification, Semantic Textual Similarity, Natural Language Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing, Machine Reading Comprehension, and Dialogue State Tracking. We build all of the tasks from scratch from diverse source corpora while respecting copyrights, to ensure accessibility for anyone without any restrictions. With ethical considerations in mind, we carefully design annotation protocols. Along with the benchmark tasks and data, we provide suitable evaluation metrics and fine-tuning recipes for pretrained language models for each task. We furthermore release the pretrained language models (PLM), KLUE-BERT and KLUE-RoBERTa, to help reproducing baseline models on KLUE and thereby facilitate future research.
We make a few interesting observations from the preliminary experiments using the proposed KLUE benchmark suite, already demonstrating the usefulness of this new benchmark suite. First, we find <math id="id4.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" display="inline"><semantics id="id4.1.m1.1a"><msub id="id4.1.m1.1.1" xref="id4.1.m1.1.1.cmml"><mtext id="id4.1.m1.1.1.2" xref="id4.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="id4.1.m1.1.1.3" xref="id4.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="id4.1.m1.1b"><apply id="id4.1.m1.1.1.cmml" xref="id4.1.m1.1.1"><csymbol cd="ambiguous" id="id4.1.m1.1.1.1.cmml" xref="id4.1.m1.1.1">subscript</csymbol><ci id="id4.1.m1.1.1.2a.cmml" xref="id4.1.m1.1.1.2"><mtext id="id4.1.m1.1.1.2.cmml" xref="id4.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="id4.1.m1.1.1.3a.cmml" xref="id4.1.m1.1.1.3"><mtext mathsize="70%" id="id4.1.m1.1.1.3.cmml" xref="id4.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math> outperforms other baselines, including multilingual PLMs and existing open-source Korean PLMs. Second, we see minimal degradation in performance even when we replace personally identifiable information from the pretraining corpus, suggesting that privacy and NLU capability are not at odds with each other. Lastly, we find that using BPE tokenization in combination with morpheme-level pre-tokenization is effective in tasks involving morpheme-level tagging, detection and generation. In addition to accelerating Korean NLP research, our comprehensive documentation on creating KLUE will facilitate creating similar resources for other languages in the future. KLUE is available at <a target="_blank" href="https://klue-benchmark.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://klue-benchmark.com/</a>.</p>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span>Equal Contribution. A description of each author’s contribution is available at the end of paper.</span></span></span><span id="footnotex2" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span>Corresponding Authors.</span></span></span><span id="footnotex3" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span>Work done at Upstage.</span></span></span>
<div class="ltx_pagination ltx_role_newpage"></div>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents</h6>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S1" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S1.SS1" title="In 1 Introduction ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Summary</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S2" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Source Corpora</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS1" title="In 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Corpora Selection Criteria</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S2.SS2" title="In 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Selected Corpora</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S2.SS2.SSS1" title="In 2.2 Selected Corpora ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>Potential Concerns</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS3" title="In 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS4" title="In 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Task Assignment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S3" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>KLUE Benchmark</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS1" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Topic Classification (TC)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS1.SSS1" title="In 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS1.SSS2" title="In 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Evaluation Metric</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS1.SSS3" title="In 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS1.SSS4" title="In 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS2" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Semantic Textual Similarity (STS)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS2.SSS1" title="In 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS2.SSS2" title="In 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS2.SSS3" title="In 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS2.SSS4" title="In 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS3" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Natural Language Inference (NLI)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS3.SSS1" title="In 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS3.SSS2" title="In 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Evaluation Metric</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS3.SSS3" title="In 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS3.SSS4" title="In 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS4" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Named Entity Recognition (NER)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS4.SSS1" title="In 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS4.SSS2" title="In 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS4.SSS3" title="In 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS4.SSS4" title="In 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS5" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Relation Extraction (RE)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS5.SSS1" title="In 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.1 </span>Data Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS5.SSS2" title="In 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS5.SSS3" title="In 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS5.SSS4" title="In 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS6" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6 </span>Dependency Parsing (DP)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS6.SSS1" title="In 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS6.SSS2" title="In 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS6.SSS3" title="In 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS6.SSS4" title="In 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS7" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7 </span>Machine Reading Comprehension (MRC)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS1" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS2" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS3" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.3 </span>Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS4" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.4 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS5" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.5 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS8" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8 </span>Dialogue State Tracking (DST)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS1" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS2" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS3" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.3 </span>Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS4" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.4 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS5" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.5 </span>Conclusion</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S4" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Pretrained Language Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S4.SS1" title="In 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Language Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S4.SS2" title="In 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Existing Language Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S5" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Fine-tuning Language Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S5.SS1" title="In 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Task-Specific Architectures</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS1" title="In 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Single Sentence Classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS2" title="In 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Sentence Pair Classification / Regression</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS3" title="In 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.3 </span>Multiple-Sentence Slot-Value Prediction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS4" title="In 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.4 </span>Sequence Tagging</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S5.SS2" title="In 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Fine-Tuning Configurations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S5.SS3" title="In 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Evaluation Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S5.SS4" title="In 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Analysis of Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S6" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Ethical Considerations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S6.SS1" title="In 6 Ethical Considerations ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Copyright and Accessibility</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S6.SS2" title="In 6 Ethical Considerations ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Toxic Content</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S6.SS3" title="In 6 Ethical Considerations ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Personally Identifiable Information</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S7" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S8" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S9" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a href="#A1" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">A</span> </span><span class="ltx_text" style="font-size:90%;">Dev Set Results</span></span></a></li>
</ol></nav>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">A major factor behind recent success of pretrained language models, such as BERT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and its variants&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> as well as GPT-3&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite> and its variants&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>, <a href="#bib.bib76" title="" class="ltx_ref">76</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, has been the availability of well-designed benchmark suites for evaluating their effectiveness in natural language understanding (NLU). GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> and SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> are representative examples of such suites and were designed to evaluate diverse aspects of NLU, including syntax, semantics and pragmatics. The research community has embraced GLUE and SuperGLUE, and has made rapid progress in developing better model architectures as well as learning algorithms for NLU.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The success of GLUE and SuperGLUE has sparked interest in building such a standardized benchmark suite for other languages, in order to better measure the progress in NLU in languages beyond English. Such efforts have been pursued along two directions. First, various groups in the world have independently created language-specific benchmark suites; a Chinese version of GLUE (CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>), a French version of GLUE (FLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>), an Indonesian variant <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>]</cite>, an Indic version <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> and a Russian variant of SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>. On the other hand, some have relied on both machine and human translation of existing benchmark suites for building multilingual version of the benchmark suites which were often created initially in English. These include for instance XGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> and XTREME <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. Although the latter approach scales much better than the former does, the latter often fails to capture societal aspects of NLU and also introduces various artifacts arising from translation.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To this end, we build a new benchmark suite for evaluating NLU in Korean which is the 13-th most used language in the world according to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> but lacks a unified benchmark suite for NLU. Instead of starting from existing benchmark tasks or corpora, we build this benchmark suite from ground up by determining and collecting base corpora, identifying a set of benchmark tasks, designing appropriate annotation protocols and finally validating collected annotation. This allows us to preemptively address and avoid properties that may have undesirable consequences, such as copyright infringement, annotation artifacts, social biases and privacy violations.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In the rest of this section, we summarize a series of decisions and principles that went behind creating KLUE.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Summary</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">In designing the Korean Language Understanding Evaluation (KLUE), we aim to make KLUE; 1) cover diverse tasks and corpora, 2) accessible to everyone without any restriction, 3) include accurate and unambiguous annotations, 4) mitigate AI ethical issues. KLUE is safe to use for both building and evaluating systems, because KLUE has proactively addressed potential <span id="S1.SS1.p1.1.1" class="ltx_text ltx_font_italic">ethical</span> issues. Here, we describe more in detail how these principles have guided creating KLUE from task selection, corpus selection, annotation protocols, determining evaluation metrics to baseline construction.</p>
</div>
<section id="S1.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Design Principles</h5>

<div id="S1.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS1.SSS0.Px1.p1.1" class="ltx_p">First, let us describe each design principle in detail:</p>
</div>
<div id="S1.SS1.SSS0.Px1.p2" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Covering diverse tasks and corpora</span>:
To cover diverse aspects of language understanding,
we choose eight tasks that cover diverse domain, including news, encyclopedia, user review, smart home queries and task-oriented dialogue, and diverse style, both formal and colloquial.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Accessible to everyone without any restriction</span>:
It is critical for a benchmark suite to be accessible by everyone for it to serve as a true guideline in evaluating and improving NLU systems. We thus use only corpora and resources that can be freely copied, redistributed, remixed and transformed for the purpose of benchmarking NLU systems.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Obtaining accurate and unambiguous annotations</span>:
Ambiguity in benchmark tasks leads to ambiguity in evaluation, which often leads to the discrepancy between the quality of an NLU system measured by the benchmark and its true quality. In order to minimize such discrepancy,
we carefully design annotation guidelines of all tasks and improve them over multiple iterations, to avoid accurate annotations.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p"><span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">Mitigating AI ethical issues</span>:
It has been repeatedly observed that large-scale language models can and often do amplify social biases embedded in text used to train them <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. In order to disincentivize such behaviors, we proactively remove examples, from both unlabeled and labeled corpora, that reflect social biases, contain toxic content and have personally identifiable information (PII), both manually and automatically. Social biases are defined as overgeneralized judgment on certain individuals or group based on social attributes (e.g., gender, ethnicity, religion). Toxic contents include insults, sexual harassment and offensive expressions.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Diverse Task Selection</h5>

<div id="S1.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S1.SS1.SSS0.Px2.p1.1" class="ltx_p">We carefully choose the following eight NLU tasks with two goals; 1) to cover as diverse aspects of NLU in Korean, and 2) to minimize redundancy among the tasks. See Table&nbsp;<a href="#S1.T1" title="Table 1 ‣ Source Corpora Collection ‣ 1.1 Summary ‣ 1 Introduction ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for their formats, evaluation granularity and other properties:</p>
</div>
<div id="S1.SS1.SSS0.Px2.p2" class="ltx_para">
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">Topic Classification (TC): classify a single sentence into a single class.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">Semantic Textual Similarity (STS): judge the semantic similarity between two sentences.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">Natural Language Inference (NLI): classify whether the first sentence entails the second one.</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i4.p1" class="ltx_para">
<p id="S1.I2.i4.p1.1" class="ltx_p">Named Entity Recognition (NER): extract entities from a sentence.</p>
</div>
</li>
<li id="S1.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i5.p1" class="ltx_para">
<p id="S1.I2.i5.p1.1" class="ltx_p">Relation Extraction (RE): predict the relationship between two entities within a sentence.</p>
</div>
</li>
<li id="S1.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i6.p1" class="ltx_para">
<p id="S1.I2.i6.p1.1" class="ltx_p">Dependency Parsing (DP): predict the syntactic structure of a sentence.</p>
</div>
</li>
<li id="S1.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i7.p1" class="ltx_para">
<p id="S1.I2.i7.p1.1" class="ltx_p">Machine Reading Comprehension (MRC): identify an answer span within a paragraph given a question.</p>
</div>
</li>
<li id="S1.I2.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i8.p1" class="ltx_para">
<p id="S1.I2.i8.p1.1" class="ltx_p">Dialogue State Tracking (DST): track the state of a goal-oriented dialogue.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora Collection</h5>

<div id="S1.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S1.SS1.SSS0.Px3.p1.1" class="ltx_p">We have actively sought corpora that are accessible, cover diverse domains and topics and are written in modern Korean. This active search has ended up with the following ten source corpora from which we derive task-specific corpora. These ten sources are released under CC BY(-SA) license or not considered as copyrighted work, permitting 1) derivative work, 2) redistribution, and 3) commercial use:</p>
</div>
<div id="S1.SS1.SSS0.Px3.p2" class="ltx_para">
<ul id="S1.I3" class="ltx_itemize">
<li id="S1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i1.p1" class="ltx_para">
<p id="S1.I3.i1.p1.1" class="ltx_p">News Headlines from Yonhap News Agency</p>
</div>
</li>
<li id="S1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i2.p1" class="ltx_para">
<p id="S1.I3.i2.p1.1" class="ltx_p">Wikipedia</p>
</div>
</li>
<li id="S1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i3.p1" class="ltx_para">
<p id="S1.I3.i3.p1.1" class="ltx_p">Wikinews</p>
</div>
</li>
<li id="S1.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i4.p1" class="ltx_para">
<p id="S1.I3.i4.p1.1" class="ltx_p">Wikitree</p>
</div>
</li>
<li id="S1.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i5.p1" class="ltx_para">
<p id="S1.I3.i5.p1.1" class="ltx_p">Policy News</p>
</div>
</li>
<li id="S1.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i6.p1" class="ltx_para">
<p id="S1.I3.i6.p1.1" class="ltx_p">ParaKQC</p>
</div>
</li>
<li id="S1.I3.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i7.p1" class="ltx_para">
<p id="S1.I3.i7.p1.1" class="ltx_p">Airbnb Reviews</p>
</div>
</li>
<li id="S1.I3.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i8.p1" class="ltx_para">
<p id="S1.I3.i8.p1.1" class="ltx_p">NAVER Sentiment Movie Corpus</p>
</div>
</li>
<li id="S1.I3.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i9.p1" class="ltx_para">
<p id="S1.I3.i9.p1.1" class="ltx_p">The Korea Economics Daily News</p>
</div>
</li>
<li id="S1.I3.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i10.p1" class="ltx_para">
<p id="S1.I3.i10.p1.1" class="ltx_p">Acrofan News</p>
</div>
</li>
</ul>
</div>
<div id="S1.SS1.SSS0.Px3.p3" class="ltx_para">
<p id="S1.SS1.SSS0.Px3.p3.1" class="ltx_p">Before sending a subset for annotation, we filter them to remove noisy, toxic or socially biased content, as well as PII. This is done automatically using predefined rules and machine learning models.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Task Overview</figcaption>
<div id="S1.T1.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:638.9pt;height:535.6pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S1.T1.2.2" class="ltx_p"><span id="S1.T1.2.2.2" class="ltx_text">
<span id="S1.T1.2.2.2.2" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.3.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.1.1" class="ltx_text ltx_font_bold">Name</span></span>
<span id="S1.T1.2.2.2.2.3.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.2.1" class="ltx_text ltx_font_bold">Type</span></span>
<span id="S1.T1.2.2.2.2.3.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.3.1" class="ltx_text ltx_font_bold">Format</span></span>
<span id="S1.T1.2.2.2.2.3.4" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S1.T1.2.2.2.2.3.4.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.3.4.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.4.1.1.1.1" class="ltx_text ltx_font_bold">Eval.</span></span></span>
<span id="S1.T1.2.2.2.2.3.4.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.4.1.2.1.1" class="ltx_text ltx_font_bold">Metric</span></span></span>
</span></span>
<span id="S1.T1.2.2.2.2.3.5" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S1.T1.2.2.2.2.3.5.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.3.5.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.3.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.5.1.1.1.1" class="ltx_text ltx_font_bold">#</span></span></span>
<span id="S1.T1.2.2.2.2.3.5.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.3.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.5.1.2.1.1" class="ltx_text ltx_font_bold">Class</span></span></span>
</span></span>
<span id="S1.T1.2.2.2.2.3.6" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S1.T1.2.2.2.2.3.6.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.3.6.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.3.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.6.1.1.1.1" class="ltx_text ltx_font_bold">{|Train|,</span></span></span>
<span id="S1.T1.2.2.2.2.3.6.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.3.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.6.1.2.1.1" class="ltx_text ltx_font_bold">|Dev|,</span></span></span>
<span id="S1.T1.2.2.2.2.3.6.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.3.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.6.1.3.1.1" class="ltx_text ltx_font_bold">|Test|}</span></span></span>
</span></span>
<span id="S1.T1.2.2.2.2.3.7" class="ltx_td ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.7.1" class="ltx_text ltx_font_bold">Source</span></span>
<span id="S1.T1.2.2.2.2.3.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.8.1" class="ltx_text ltx_font_bold">Style</span></span></span>
<span id="S1.T1.2.2.2.2.4" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.1" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S1.T1.2.2.2.2.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.4.1.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">KLUE-TC</span></span>
<span id="S1.T1.2.2.2.2.4.1.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(YNAT)</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.4.2" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S1.T1.2.2.2.2.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.4.2.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Topic</span></span>
<span id="S1.T1.2.2.2.2.4.2.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Classification</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.4.3" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S1.T1.2.2.2.2.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.4.3.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Single Sentence</span></span>
<span id="S1.T1.2.2.2.2.4.3.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Classification</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.4.4" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S1.T1.2.2.2.2.4.4.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.4.4.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Macro F1</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.4.5" class="ltx_td ltx_align_center ltx_border_tt">7</span>
<span id="S1.T1.2.2.2.2.4.6" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S1.T1.2.2.2.2.4.6.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.4.6.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">45k,</span></span>
<span id="S1.T1.2.2.2.2.4.6.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9k,</span></span>
<span id="S1.T1.2.2.2.2.4.6.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9k</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.4.7" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S1.T1.2.2.2.2.4.7.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.4.7.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News</span></span>
<span id="S1.T1.2.2.2.2.4.7.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.4.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(Headline)</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.4.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt">Formal</span></span>
<span id="S1.T1.2.2.2.2.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.3" class="ltx_td ltx_align_left ltx_border_t">KLUE-STS</span>
<span id="S1.T1.2.2.2.2.2.4" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.2.4.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.2.4.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Semantic</span></span>
<span id="S1.T1.2.2.2.2.2.4.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Textual</span></span>
<span id="S1.T1.2.2.2.2.2.4.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Similarity</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.5" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.2.5.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.2.5.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Sentence</span></span>
<span id="S1.T1.2.2.2.2.2.5.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Pair</span></span>
<span id="S1.T1.2.2.2.2.2.5.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Regression</span></span>
</span></span>
<span id="S1.T1.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S1.T1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Pearson’s <math id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.1.1.1.1.1.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1c">r</annotation></semantics></math>,</span></span>
<span id="S1.T1.1.1.1.1.1.1.1.2" class="ltx_tr">
<span id="S1.T1.1.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">F1</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.2.2.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2" class="ltx_Math" alttext="[0,5]" display="inline"><semantics id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2a"><mrow id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2.1" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml">[</mo><mn id="S1.T1.2.2.2.2.2.2.1.1.1.m1.1.1" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.1.1.cmml">0</mn><mo id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2.2" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml">,</mo><mn id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.2" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.2.cmml">5</mn><mo stretchy="false" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2.3" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2b"><interval closure="closed" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2"><cn type="integer" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.1.1.cmml" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.1.1">0</cn><cn type="integer" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.2.cmml" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.2">5</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2c">[0,5]</annotation></semantics></math></span></span>
<span id="S1.T1.2.2.2.2.2.2.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">2</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.6" class="ltx_td ltx_align_center ltx_border_t">
<span id="S1.T1.2.2.2.2.2.6.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.2.6.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">11k,</span></span>
<span id="S1.T1.2.2.2.2.2.6.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">0.5k,</span></span>
<span id="S1.T1.2.2.2.2.2.6.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1k</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.7" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.2.7.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.2.7.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News,</span></span>
<span id="S1.T1.2.2.2.2.2.7.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Review,</span></span>
<span id="S1.T1.2.2.2.2.2.7.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Query</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.2.8.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.2.8.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Colloquial,</span></span>
<span id="S1.T1.2.2.2.2.2.8.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.5" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-NLI</span>
<span id="S1.T1.2.2.2.2.5.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.5.2.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Natural</span></span>
<span id="S1.T1.2.2.2.2.5.2.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Language</span></span>
<span id="S1.T1.2.2.2.2.5.2.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Inference</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.5.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.5.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.5.3.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Sentence</span></span>
<span id="S1.T1.2.2.2.2.5.3.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Pair</span></span>
<span id="S1.T1.2.2.2.2.5.3.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Classification</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.5.4" class="ltx_td ltx_align_left ltx_border_t">Accuracy</span>
<span id="S1.T1.2.2.2.2.5.5" class="ltx_td ltx_align_center ltx_border_t">3</span>
<span id="S1.T1.2.2.2.2.5.6" class="ltx_td ltx_align_center ltx_border_t">
<span id="S1.T1.2.2.2.2.5.6.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.5.6.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">25k,</span></span>
<span id="S1.T1.2.2.2.2.5.6.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3k,</span></span>
<span id="S1.T1.2.2.2.2.5.6.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3k</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.5.7" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.5.7.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.5.7.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News,</span></span>
<span id="S1.T1.2.2.2.2.5.7.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Wikipedia,</span></span>
<span id="S1.T1.2.2.2.2.5.7.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Review</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.5.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.5.8.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.5.8.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Colloquial,</span></span>
<span id="S1.T1.2.2.2.2.5.8.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.5.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.6" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-NER</span>
<span id="S1.T1.2.2.2.2.6.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.6.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.6.2.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Named</span></span>
<span id="S1.T1.2.2.2.2.6.2.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Entity</span></span>
<span id="S1.T1.2.2.2.2.6.2.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Recognition</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.6.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.6.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.6.3.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Sequence</span></span>
<span id="S1.T1.2.2.2.2.6.3.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Tagging</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.6.4" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.6.4.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.6.4.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Entity-level Macro F1</span></span>
<span id="S1.T1.2.2.2.2.6.4.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Character-level Macro F1</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.6.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S1.T1.2.2.2.2.6.5.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.6.5.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">6,</span></span>
<span id="S1.T1.2.2.2.2.6.5.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">12</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.6.6" class="ltx_td ltx_align_center ltx_border_t">
<span id="S1.T1.2.2.2.2.6.6.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.6.6.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">21k,</span></span>
<span id="S1.T1.2.2.2.2.6.6.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5k,</span></span>
<span id="S1.T1.2.2.2.2.6.6.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5k</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.6.7" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.6.7.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.6.7.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News,</span></span>
<span id="S1.T1.2.2.2.2.6.7.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Review</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.6.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.6.8.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.6.8.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Colloquial,</span></span>
<span id="S1.T1.2.2.2.2.6.8.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.6.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.7" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-RE</span>
<span id="S1.T1.2.2.2.2.7.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.7.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.7.2.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Relation</span></span>
<span id="S1.T1.2.2.2.2.7.2.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Extraction</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.7.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.7.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.7.3.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Single Sentence</span></span>
<span id="S1.T1.2.2.2.2.7.3.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Classification</span></span>
<span id="S1.T1.2.2.2.2.7.3.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.7.3.1.3.1.1" class="ltx_text" style="font-size:50%;">(+2 Entity Spans)</span></span></span>
</span></span>
<span id="S1.T1.2.2.2.2.7.4" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.7.4.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.7.4.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Micro F1 <span id="S1.T1.2.2.2.2.7.4.1.1.1.1" class="ltx_text" style="font-size:80%;">(without <span id="S1.T1.2.2.2.2.7.4.1.1.1.1.1" class="ltx_text ltx_font_italic">no_relation</span>),</span></span></span>
<span id="S1.T1.2.2.2.2.7.4.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">AUPRC</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.7.5" class="ltx_td ltx_align_center ltx_border_t">30</span>
<span id="S1.T1.2.2.2.2.7.6" class="ltx_td ltx_align_center ltx_border_t">
<span id="S1.T1.2.2.2.2.7.6.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.7.6.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">32k,</span></span>
<span id="S1.T1.2.2.2.2.7.6.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8k,</span></span>
<span id="S1.T1.2.2.2.2.7.6.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8k</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.7.7" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.7.7.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.7.7.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Wikipedia,</span></span>
<span id="S1.T1.2.2.2.2.7.7.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">News</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.7.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.7.8.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.7.8.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.7.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.8" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-DP</span>
<span id="S1.T1.2.2.2.2.8.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.8.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.8.2.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Dependency</span></span>
<span id="S1.T1.2.2.2.2.8.2.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Parsing</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.8.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.8.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.8.3.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Sequence</span></span>
<span id="S1.T1.2.2.2.2.8.3.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Tagging</span></span>
<span id="S1.T1.2.2.2.2.8.3.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.8.3.1.3.1.1" class="ltx_text" style="font-size:50%;">(+ POS Tags)</span></span></span>
</span></span>
<span id="S1.T1.2.2.2.2.8.4" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.8.4.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.8.4.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Unlabeled Attachment Score,</span></span>
<span id="S1.T1.2.2.2.2.8.4.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Labeled Attachment Score</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.8.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S1.T1.2.2.2.2.8.5.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.8.5.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"># Words,</span></span>
<span id="S1.T1.2.2.2.2.8.5.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">38</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.8.6" class="ltx_td ltx_align_center ltx_border_t">
<span id="S1.T1.2.2.2.2.8.6.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.8.6.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">10k,</span></span>
<span id="S1.T1.2.2.2.2.8.6.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2k,</span></span>
<span id="S1.T1.2.2.2.2.8.6.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">2.5k</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.8.7" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.8.7.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.8.7.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News,</span></span>
<span id="S1.T1.2.2.2.2.8.7.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Review</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.8.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.8.8.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.8.8.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Colloquial,</span></span>
<span id="S1.T1.2.2.2.2.8.8.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.8.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.9" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-MRC</span>
<span id="S1.T1.2.2.2.2.9.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.9.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.9.2.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Machine</span></span>
<span id="S1.T1.2.2.2.2.9.2.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Reading</span></span>
<span id="S1.T1.2.2.2.2.9.2.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Comprehension</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.9.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.9.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.9.3.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Span Prediction</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.9.4" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.9.4.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.9.4.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Exact Match,</span></span>
<span id="S1.T1.2.2.2.2.9.4.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">ROUGE-W (LCCS-based F1)</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.9.5" class="ltx_td ltx_align_center ltx_border_t">2</span>
<span id="S1.T1.2.2.2.2.9.6" class="ltx_td ltx_align_center ltx_border_t">
<span id="S1.T1.2.2.2.2.9.6.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.9.6.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">12k,</span></span>
<span id="S1.T1.2.2.2.2.9.6.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8k,</span></span>
<span id="S1.T1.2.2.2.2.9.6.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9k</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.9.7" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.2.2.2.2.9.7.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.9.7.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Wikipedia,</span></span>
<span id="S1.T1.2.2.2.2.9.7.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.9.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">News</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.9.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Formal</span></span>
<span id="S1.T1.2.2.2.2.10" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.10.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.10.1.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">KLUE-DST</span></span>
<span id="S1.T1.2.2.2.2.10.1.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(WoS)</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.10.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.10.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.10.2.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Dialogue</span></span>
<span id="S1.T1.2.2.2.2.10.2.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">State</span></span>
<span id="S1.T1.2.2.2.2.10.2.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Tracking</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.10.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.10.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.10.3.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Slot-Value</span></span>
<span id="S1.T1.2.2.2.2.10.3.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Prediction</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.10.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.10.4.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.10.4.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Joint Goal Accuracy</span></span>
<span id="S1.T1.2.2.2.2.10.4.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Slot Micro F1</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.10.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">(45)</span>
<span id="S1.T1.2.2.2.2.10.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.10.6.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.10.6.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8k,</span></span>
<span id="S1.T1.2.2.2.2.10.6.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1k,</span></span>
<span id="S1.T1.2.2.2.2.10.6.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1k</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.10.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.10.7.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.2.10.7.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Task</span></span>
<span id="S1.T1.2.2.2.2.10.7.1.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Oriented</span></span>
<span id="S1.T1.2.2.2.2.10.7.1.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.10.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Dialogue</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.10.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t">Colloquial</span></span>
</span></span></p>
</span></div>
</figure>
</section>
<section id="S1.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Considerations in Annotation</h5>

<div id="S1.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S1.SS1.SSS0.Px4.p1.1" class="ltx_p">For each task, we annotate a subset from the source corpora. In doing so, we take into account three major considerations below:</p>
</div>
<div id="S1.SS1.SSS0.Px4.p2" class="ltx_para">
<ul id="S1.I4" class="ltx_itemize">
<li id="S1.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I4.i1.p1" class="ltx_para">
<p id="S1.I4.i1.p1.1" class="ltx_p"><span id="S1.I4.i1.p1.1.1" class="ltx_text ltx_font_italic">Better reflection of linguistic characteristics of Korean</span>: Many existing Korean datasets were constructed as a part of multilingually aligned benchmarks, and they do not fully reflect linguistic characteristics of Korean such as agglutinative nature in named entity recognition (NER) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>, or tagset in part-of-speech (POS) tagging and dependency parsing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. We write and revise annotation guidelines more appropriately to the linguistic property of Korean.</p>
</div>
</li>
<li id="S1.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I4.i2.p1" class="ltx_para">
<p id="S1.I4.i2.p1.1" class="ltx_p"><span id="S1.I4.i2.p1.1.1" class="ltx_text ltx_font_italic">Obtaining accurate annotations</span>:
We provide crowdworkers or select participants with carefully designed annotation guidelines and improve them over multiple iterations, in order to reduce the ambiguity of annotation process as well as to mitigate known artifact issues. In particular, we often filter out examples for which annotators cannot easily agree with each other.</p>
</div>
</li>
<li id="S1.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I4.i3.p1" class="ltx_para">
<p id="S1.I4.i3.p1.1" class="ltx_p"><span id="S1.I4.i3.p1.1.1" class="ltx_text ltx_font_italic">Mitigating harmful social bias and removing PII</span>:
To disincentivize socially biased NLU systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, we explicitly instruct annotators as well as inspectors to manually mark and/or exclude examples that are unacceptable according to our principle of ethics. Our definitions of <span id="S1.I4.i3.p1.1.2" class="ltx_text ltx_font_italic">bias</span> and <span id="S1.I4.i3.p1.1.3" class="ltx_text ltx_font_italic">hate speech</span> follow <cite class="ltx_cite ltx_citemacro_citet">Moon et&nbsp;al. [<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>. We denote <span id="S1.I4.i3.p1.1.4" class="ltx_text ltx_font_italic">bias</span> as an overgeneralized prejudice on certain groups or individuals based on the following traits: gender, race, background, nationality, ethnic group, political stance, skin color, religion, disability, age, appearance, (socio-)economic status, and occupations. In the case of <span id="S1.I4.i3.p1.1.5" class="ltx_text ltx_font_italic">hate speech</span>, we include offensive, aggressive, insulting, or sarcastic contents. We identify a list of personally identifiable information (PII) following KISA (Korea Internet and Security Agency) guideline,<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.kisa.or.kr/public/laws/laws2_View.jsp?cPage=1&amp;mode=view&amp;p_No=282&amp;b_No=282&amp;d_No=3" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kisa.or.kr/public/laws/laws2_View.jsp?cPage=1&amp;mode=view&amp;p_No=282&amp;b_No=282&amp;d_No=3</a></span></span></span> whose information is related to a living individual based on personal information protection act of Korea.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://www.law.go.kr/LSW//lsInfoP.do?lsiSeq=213857&amp;chrClsCd=010203&amp;urlMode=engLsInfoR&amp;viewCls=engLsInfoR#0000</span></span></span> We do not consider public figure’s name as personal information.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>
See the precedent set by the Supreme Court in Korea: 대법원 2011. 9. 2. 선고 2008다42430 전원합의체 판결 available at <a target="_blank" href="https://glaw.scourt.go.kr/wsjo/panre/sjo100.do?contId=2060159&amp;q=2008%EB%8B%A442430" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://glaw.scourt.go.kr/wsjo/panre/sjo100.do?contId=2060159&amp;q=2008%EB%8B%A442430</a>.
</span></span></span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS1.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation Metrics</h5>

<div id="S1.SS1.SSS0.Px5.p1" class="ltx_para">
<p id="S1.SS1.SSS0.Px5.p1.1" class="ltx_p">The diversity of tasks in KLUE implies that we must choose a proper set of evaluation metrics for each task carefully and separately. Here, we list the tasks and describe how we choose the evaluation metrics for each of these tasks.</p>
</div>
<div id="S1.SS1.SSS0.Px5.p2" class="ltx_para">
<ul id="S1.I5" class="ltx_itemize">
<li id="S1.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i1.p1" class="ltx_para">
<p id="S1.I5.i1.p1.1" class="ltx_p"><span id="S1.I5.i1.p1.1.1" class="ltx_text ltx_font_italic">KLUE-TC</span> (Yonhap News Agency Topic Classification (YNAT)):
We formulate KLUE-TC as a multi-class classification problem with seven classes. Because the headline alone is often not enough to precisely identify the proper class to which it belongs, we manually annotate and keep 70,000 headlines, for each of which there was a majority consensus on the class by the annotators. We then use the consensus classes as ground-truth classes and use macro F1 score as an evaluation metric.</p>
</div>
</li>
<li id="S1.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i2.p1" class="ltx_para">
<p id="S1.I5.i2.p1.1" class="ltx_p"><span id="S1.I5.i2.p1.1.1" class="ltx_text ltx_font_italic">KLUE-STS</span>:
In KLUE-STS the similarity between each pair of sentences is annotated with the average (real-valued) similarity rating (between 0 and 5). We measure the quality of an NLU model in two different ways. First, we use the Pearson correlation coefficient between the real-valued target and prediction. Second, we compute the F1 score after binarizing the real-valued similarity rating as in paraphrase detection.</p>
</div>
</li>
<li id="S1.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i3.p1" class="ltx_para">
<p id="S1.I5.i3.p1.1" class="ltx_p"><span id="S1.I5.i3.p1.1.1" class="ltx_text ltx_font_italic">KLUE-NLI</span>:
Similar to existing NLI datasets, such as SNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>, we use classification accuracy, and this is appropriate, as we create KLUE-NLI dev/test set to have a balanced class distribution.</p>
</div>
</li>
<li id="S1.I5.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i4.p1" class="ltx_para">
<p id="S1.I5.i4.p1.1" class="ltx_p"><span id="S1.I5.i4.p1.1.1" class="ltx_text ltx_font_italic">KLUE-NER</span>:
In KLUE-NER, a named entity recognizer is expected to output BIO tags and also categorize each detected entity into one of six types; person, location, organization, date, time and quantity. To account for rich morphology in Korean, we use entity-level and character-level F1 score to evaluate the quality of the detection to evaluate the recognizer’s ability in determining the type of each entity.</p>
</div>
</li>
<li id="S1.I5.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i5.p1" class="ltx_para">
<p id="S1.I5.i5.p1.1" class="ltx_p"><span id="S1.I5.i5.p1.1.1" class="ltx_text ltx_font_italic">KLUE-RE</span>:
KLUE-RE is designed as a sentence classification task in which the input is a single sentence with two marked entities and the output is their relationship out of 30 types. We use two evaluation metrics. The first one is micro F1 score, considering only meaningful types (excluding no relationship), which allows us to evaluate the NLU system’s ability to identify a fine-grained relationship between a pair of entities. The second one is the area under the precision-recall curve (AUPRC), which gives us a holistic view into the quality of the relation extraction model in question.</p>
</div>
</li>
<li id="S1.I5.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i6.p1" class="ltx_para">
<p id="S1.I5.i6.p1.1" class="ltx_p"><span id="S1.I5.i6.p1.1.1" class="ltx_text ltx_font_italic">KLUE-DP</span>:
Following standard practice in dependency parsing, we use both unlabeled attachment score (UAS) and labeled attachment score (LAS) to evaluate a dependency parser. We annotate and use both formal and informal text (subsets from the news corpora and colloquial review corpora, respectively), which allows us to perform fine-grained analysis across multiple domains.</p>
</div>
</li>
<li id="S1.I5.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i7.p1" class="ltx_para">
<p id="S1.I5.i7.p1.1" class="ltx_p"><span id="S1.I5.i7.p1.1.1" class="ltx_text ltx_font_italic">KLUE-MRC</span>:
Similarly to KLUE-NER, KLUE-MRC is framed as a span prediction problem. We keep character-level exact match (EM) for comparison against existing datasets, while we propose to use ROUGE-W which measures the F1 score based on the longest common consecutive subsequence (LCCS) between the ground-truth and predicted answer spans. The latter handles rich morphology of Korean as well as the former does while being more interpretable.</p>
</div>
</li>
<li id="S1.I5.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i8.p1" class="ltx_para">
<p id="S1.I5.i8.p1.1" class="ltx_p"><span id="S1.I5.i8.p1.1.1" class="ltx_text ltx_font_italic">KLUE-DST</span> (Wizard of Seoul, WoS):
We formulate KLUE-DST as a multiple-sentence slot-value prediction task, and evaluate an NLU system using two metrics. The first metric is the joint goal accuracy which measures whether all the slots were correctly predicted, while the other metric is average F1 score. Because the former treats all examples for which not all slots were correctly filled in, it often fails to distinguish similarly performing NLU systems. We address this shortcoming by reporting both the joint goal accuracy and slot F1 score. We furthermore build it using multiple domains in order to facilitate finer-grain analysis.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS1.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Baselines</h5>

<div id="S1.SS1.SSS0.Px6.p1" class="ltx_para">
<p id="S1.SS1.SSS0.Px6.p1.2" class="ltx_p">In addition to creating a benchmark suite, we also build and publicly release a set of strong baselines based on large-scale pretrained language models. In due course, we pretrain and release large-scale language models for Korean ourselves, which will reduce the burden of retraining these large-scale models from individual researchers. We also use several existing multilingual pretrained language models and open-source Korean-specific models in addition to our own models, to gain further insights into the proposed KLUE benchmark. We present all the results in Table&nbsp;<a href="#S5.T32" title="Table 32 ‣ 5.3 Evaluation Results ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">32</span></a> and summarize a few interesting observations here. First, Korean-specific language models generally outperform multilingual models. Second, different models perform best on different tasks when controlled for their sizes; KLUE-BERT performs best for YNAT and WoS, KLUE-RoBERTa for KLUE-RE and KLUE-MRC, and <math id="S1.SS1.SSS0.Px6.p1.1.m1.1" class="ltx_Math" alttext="\text{KoELECTRA}_{\text{BASE}}" display="inline"><semantics id="S1.SS1.SSS0.Px6.p1.1.m1.1a"><msub id="S1.SS1.SSS0.Px6.p1.1.m1.1.1" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.cmml"><mtext id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2a.cmml">KoELECTRA</mtext><mtext id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.SS1.SSS0.Px6.p1.1.m1.1b"><apply id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.1.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1">subscript</csymbol><ci id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2a.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2"><mtext id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2">KoELECTRA</mtext></ci><ci id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3a.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS1.SSS0.Px6.p1.1.m1.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math> for KLUE-STS and KLUE-NLI. Third, as we increase the model size, <math id="S1.SS1.SSS0.Px6.p1.2.m2.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" display="inline"><semantics id="S1.SS1.SSS0.Px6.p1.2.m2.1a"><msub id="S1.SS1.SSS0.Px6.p1.2.m2.1.1" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.cmml"><mtext id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.SS1.SSS0.Px6.p1.2.m2.1b"><apply id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.1.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1">subscript</csymbol><ci id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2a.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2"><mtext id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3a.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS1.SSS0.Px6.p1.2.m2.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math> ends up outperforming all the other models in all the tasks other than KLUE-NER. Lastly, we observe that removing PII has minimal effect on the downstream task performances, and our tokenization scheme, morpheme-based subword tokenization, is effective in tasks involving tagging, detection and even generation at the morpheme level.</p>
</div>
</section>
<section id="S1.SS1.SSS0.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task Overview</h5>

<div id="S1.SS1.SSS0.Px7.p1" class="ltx_para">
<p id="S1.SS1.SSS0.Px7.p1.1" class="ltx_p">In Table&nbsp;<a href="#S1.T1" title="Table 1 ‣ Source Corpora Collection ‣ 1.1 Summary ‣ 1 Introduction ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we summarize the resulting eight KLUE tasks, listing important properties, such as type, format, evaluation metrics and annotated data sizes. In the rest of the paper, we will walk through the process by which each and every one of these tasks was constructed much more in detail.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Source Corpora</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We build KLUE from scratch, instead of putting together existing datasets, which has been a common practice in setting up benchmarks. We investigate available textual resources, and document the process in order to provide better understanding on how and why we select some corpora but not others. We adopt the recently proposed documentation frameworks; <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">datasheets</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> and <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">data statements</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Based on these frameworks, we document and provide more information to carefully describe our protocol.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Corpora Selection Criteria</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We consider two criteria when sourcing a set of corpora to build a source corpus from which task-specific corpora are derived and annotated. The first criterion is accessibility. As the main purpose of KLUE is to facilitate future NLP research and development, we ensure KLUE comes with data that can be used and shared as freely as possible to all. The second criterion is the quality and diversity. We ensure each example with these corpora is of certain quality by removing low-quality text and also the balance is met between formal and colloquial text within these corpora.</p>
</div>
<section id="S2.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Accessibility</h5>

<div id="S2.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS1.SSS0.Px1.p1.1" class="ltx_p">Unlike <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. [<a href="#bib.bib132" title="" class="ltx_ref">132</a>], Hu et&nbsp;al. [<a href="#bib.bib54" title="" class="ltx_ref">54</a>], Kakwani et&nbsp;al. [<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, we design KLUE to reach as broad and diverse researchers as possible by avoiding any restriction on affiliations of users as well as the purpose of its use. Furthermore, we acknowledge the rapid pace of advances in the field and allow users to reproduce and redistribute KLUE to prolong its usability as a standard benchmark of NLU. To do so, we build and release the source corpus with CC BY-SA.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>
<a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/licenses/by-sa/4.0/</a>
</span></span></span></p>
</div>
<div id="S2.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS1.SSS0.Px1.p2.1" class="ltx_p">The source corpus, or a set of source corpora, satisfies the following conditions:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">No restriction on the use:</span>
We allow both non-commercial and commercial use of KLUE, in order to accommodate the recent trend of fundamental research from industry labs.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Derivatives:</span>
We allow users to freely refurbish any part of KLUE to first address any shortcomings, such as unanticipated artifacts, ethical issues and annotation mistakes, and second derive more challenging benchmarks for the future. This is similar to what has been done with SQuAD 2.0&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> which was created to include SQuAD 1.1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Redistributable:</span>
We allow KLUE benchmark datasets to be distributed by anyone via any channel as long as the proper attribution is given to the original creators of KLUE.
We deliberately make this decision to avoid situations where only a limited and select group of researchers have a monopoly on resources, ultimately hindering the progress overall. This is in reaction to some of the existing Korean corpora which come together with restrictive policies, often preventing derivatives as well as redistribution, and are only accessible by researchers in Korea after acquiring permissions from the corpus publishers who are often public institutions in Korea. KLUE avoids such preventive policies in order to maximally facilitate the progress in Korean NLP.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS1.SSS0.Px1.p3" class="ltx_para">
<p id="S2.SS1.SSS0.Px1.p3.1" class="ltx_p">Because most of the existing datasets do not meet these conditions, we curate the source corpus from scratch by considering only those resources that either come with one of the following licenses: CC0,<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://creativecommons.org/publicdomain/zero/1.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/publicdomain/zero/1.0/</a></span></span></span> CC BY,<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/licenses/by/4.0/</a></span></span></span> CC BY-SA,<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/licenses/by-sa/4.0/</a></span></span></span> and other similar licenses such as KOGL Type 1,<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://www.kogl.or.kr/info/license.do#05-tab" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kogl.or.kr/info/license.do#05-tab</a></span></span></span>
are not protected by the copyright act according to the latest copyright act in Korea,<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>
See <a target="_blank" href="https://www.law.go.kr/%EB%B2%95%EB%A0%B9/%EC%A0%80%EC%9E%91%EA%B6%8C%EB%B2%95" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.law.go.kr/%EB%B2%95%EB%A0%B9/%EC%A0%80%EC%9E%91%EA%B6%8C%EB%B2%95</a> for the copyright act which went effective as of Dec 8 2020.
</span></span></span>
or have been explicitly provided to us by copyright holders under contracts.
We end up 20 candidate corpora in total, of which subset is selected to form a source corpus set of KLUE. They are listed in Table&nbsp;<a href="#S2.T2" title="Table 2 ‣ The Final Source Corpora ‣ 2.1 Corpora Selection Criteria ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Quality and Diversity</h5>

<div id="S2.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS1.SSS0.Px2.p1.1" class="ltx_p">Among these 20 source corpora, we select a subset of ten corpora to form the source corpus and to build the KLUE benchmark. In doing so, we consider the following criteria; 1) the corpus should not be specific to narrow domains (diversity), 2) the corpus must be written in contemporary Korean (quality), 3) the corpus should not be dominated by contents that have privacy or toxicity concerns (quality) and 4) the corpus must be amenable to annotation for at least one of the eight benchmark tasks. Furthermore, we select the subset of corpora to cover both formal and colloquial uses.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">The Final Source Corpora</h5>

<div id="S2.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS1.SSS0.Px3.p1.1" class="ltx_p">Based on these criteria and decisions, we choose News Headlines, Wikipedia, Wikinews, Policy News, The Korea Economics Daily News, and Acrofan News for (relatively) formal text.<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>
Although Wikitree was found to include some contents that could be considered unethical, socially biased and/or of low quality in general, we include it, as Wikitree is the largest source of license-free news articles. We address these problematic contents via annotation.
</span></span></span>
For more colloquial text, we use ParaKQC, Airbnb Reviews, and NAVER Sentiment Movie Corpus. These are marked bold in Table&nbsp;<a href="#S2.T2" title="Table 2 ‣ The Final Source Corpora ‣ 2.1 Corpora Selection Criteria ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Collected source corpora. The corpora in the first section are not protected by copyright act. Specifically, <span id="S2.T2.9.1" class="ltx_text ltx_font_italic">News Headlines</span> are not classified as a work due to their lack of creativity and <span id="S2.T2.10.2" class="ltx_text ltx_font_italic">Judgements</span> are not protected works under Article 7, Act 3. <span id="S2.T2.11.3" class="ltx_text ltx_font_italic">National Assembly Minutes</span> and <span id="S2.T2.12.4" class="ltx_text ltx_font_italic">Patents</span>, made in National Assembly, shall not apply the copyright act by Article 24, Act 2. The second section is a collection of corpora under the permissive licenses. The last section corpora, KED and Acrofan, are originally prohibited from creating derivative works, however, we release such condition by exclusive contract. For the column, <span id="S2.T2.13.5" class="ltx_text ltx_font_italic">Volume</span>, we denote <span id="S2.T2.14.6" class="ltx_text ltx_font_italic">Small</span> as corpus size under 1k, <span id="S2.T2.15.7" class="ltx_text ltx_font_italic">Medium</span> as in between 1k and 50k, and <span id="S2.T2.16.8" class="ltx_text ltx_font_italic">Large</span> as over 50k. Bold represents our final source corpora to build KLUE benchmark.</figcaption>
<div id="S2.T2.17" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:583.6pt;height:613pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S2.T2.17.1" class="ltx_p"><span id="S2.T2.17.1.1" class="ltx_text">
<span id="S2.T2.17.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T2.17.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
<span id="S2.T2.17.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.17.1.1.1.1.2.1" class="ltx_text ltx_font_bold">License</span></span>
<span id="S2.T2.17.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.17.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Domain</span></span>
<span id="S2.T2.17.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.17.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Style</span></span>
<span id="S2.T2.17.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S2.T2.17.1.1.1.1.5.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.1.5.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.1.5.1.1.1.1" class="ltx_text ltx_font_bold">Ethical</span></span></span>
<span id="S2.T2.17.1.1.1.1.5.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.1.5.1.2.1.1" class="ltx_text ltx_font_bold">Risks</span></span></span>
</span></span>
<span id="S2.T2.17.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.17.1.1.1.1.6.1" class="ltx_text ltx_font_bold">Volume</span></span>
<span id="S2.T2.17.1.1.1.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt">
<span id="S2.T2.17.1.1.1.1.7.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.1.7.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.1.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.1.7.1.1.1.1" class="ltx_text ltx_font_bold">Contemporary</span></span></span>
<span id="S2.T2.17.1.1.1.1.7.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.1.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.1.7.1.2.1.1" class="ltx_text ltx_font_bold">Korean</span></span></span>
</span></span></span>
<span id="S2.T2.17.1.1.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.17.1.1.1.2.1.1" class="ltx_text ltx_font_bold">News Headlines</span></span>
<span id="S2.T2.17.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.2.1" class="ltx_text ltx_font_bold">N/A</span></span>
<span id="S2.T2.17.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S2.T2.17.1.1.1.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.2.3.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.2.3.1.1.1.1" class="ltx_text ltx_font_bold">News (Headline)</span></span></span>
</span></span>
<span id="S2.T2.17.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.4.1" class="ltx_text ltx_font_bold">Formal</span></span>
<span id="S2.T2.17.1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.5.1" class="ltx_text ltx_font_bold">Low</span></span>
<span id="S2.T2.17.1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.6.1" class="ltx_text ltx_font_bold">Large</span></span>
<span id="S2.T2.17.1.1.1.2.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
<span id="S2.T2.17.1.1.1.3" class="ltx_tr">
<span id="S2.T2.17.1.1.1.3.1" class="ltx_td ltx_align_left">Judgments</span>
<span id="S2.T2.17.1.1.1.3.2" class="ltx_td ltx_align_center">Public Domain</span>
<span id="S2.T2.17.1.1.1.3.3" class="ltx_td ltx_align_center">Law</span>
<span id="S2.T2.17.1.1.1.3.4" class="ltx_td ltx_align_center">Formal</span>
<span id="S2.T2.17.1.1.1.3.5" class="ltx_td ltx_align_center">Low</span>
<span id="S2.T2.17.1.1.1.3.6" class="ltx_td ltx_align_center">Large</span>
<span id="S2.T2.17.1.1.1.3.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span>
<span id="S2.T2.17.1.1.1.4" class="ltx_tr">
<span id="S2.T2.17.1.1.1.4.1" class="ltx_td ltx_align_left">
<span id="S2.T2.17.1.1.1.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.4.1.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">National Assembly</span></span>
<span id="S2.T2.17.1.1.1.4.1.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Minutes</span></span>
</span></span>
<span id="S2.T2.17.1.1.1.4.2" class="ltx_td ltx_align_center">Public Domain</span>
<span id="S2.T2.17.1.1.1.4.3" class="ltx_td ltx_align_center">Politics</span>
<span id="S2.T2.17.1.1.1.4.4" class="ltx_td ltx_align_center">Colloquial</span>
<span id="S2.T2.17.1.1.1.4.5" class="ltx_td ltx_align_center">Medium</span>
<span id="S2.T2.17.1.1.1.4.6" class="ltx_td ltx_align_center">Large</span>
<span id="S2.T2.17.1.1.1.4.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span>
<span id="S2.T2.17.1.1.1.5" class="ltx_tr">
<span id="S2.T2.17.1.1.1.5.1" class="ltx_td ltx_align_left">Patents</span>
<span id="S2.T2.17.1.1.1.5.2" class="ltx_td ltx_align_center">Public Domain</span>
<span id="S2.T2.17.1.1.1.5.3" class="ltx_td ltx_align_center">Patent</span>
<span id="S2.T2.17.1.1.1.5.4" class="ltx_td ltx_align_center">Formal</span>
<span id="S2.T2.17.1.1.1.5.5" class="ltx_td ltx_align_center">Low</span>
<span id="S2.T2.17.1.1.1.5.6" class="ltx_td ltx_align_center">Large</span>
<span id="S2.T2.17.1.1.1.5.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span>
<span id="S2.T2.17.1.1.1.6" class="ltx_tr">
<span id="S2.T2.17.1.1.1.6.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.17.1.1.1.6.1.1" class="ltx_text ltx_font_bold">Wikipedia</span></span>
<span id="S2.T2.17.1.1.1.6.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.2.1" class="ltx_text ltx_font_bold">CC BY-SA 3.0</span></span>
<span id="S2.T2.17.1.1.1.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.3.1" class="ltx_text ltx_font_bold">Wikipedia</span></span>
<span id="S2.T2.17.1.1.1.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.4.1" class="ltx_text ltx_font_bold">Formal</span></span>
<span id="S2.T2.17.1.1.1.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.5.1" class="ltx_text ltx_font_bold">Low</span></span>
<span id="S2.T2.17.1.1.1.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.6.1" class="ltx_text ltx_font_bold">Large</span></span>
<span id="S2.T2.17.1.1.1.6.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
<span id="S2.T2.17.1.1.1.7" class="ltx_tr">
<span id="S2.T2.17.1.1.1.7.1" class="ltx_td ltx_align_left">Wikibooks</span>
<span id="S2.T2.17.1.1.1.7.2" class="ltx_td ltx_align_center">CC BY-SA 3.0</span>
<span id="S2.T2.17.1.1.1.7.3" class="ltx_td ltx_align_center">Book</span>
<span id="S2.T2.17.1.1.1.7.4" class="ltx_td ltx_align_center">Formal</span>
<span id="S2.T2.17.1.1.1.7.5" class="ltx_td ltx_align_center">Low</span>
<span id="S2.T2.17.1.1.1.7.6" class="ltx_td ltx_align_center">Medium</span>
<span id="S2.T2.17.1.1.1.7.7" class="ltx_td ltx_nopad_r ltx_align_center">x</span></span>
<span id="S2.T2.17.1.1.1.8" class="ltx_tr">
<span id="S2.T2.17.1.1.1.8.1" class="ltx_td ltx_align_left ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.1.1" class="ltx_text">Wikisource</span></span>
<span id="S2.T2.17.1.1.1.8.2" class="ltx_td ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.2.1" class="ltx_text">CC BY-SA 3.0</span></span>
<span id="S2.T2.17.1.1.1.8.3" class="ltx_td ltx_align_center">Law</span>
<span id="S2.T2.17.1.1.1.8.4" class="ltx_td ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.4.1" class="ltx_text">Formal</span></span>
<span id="S2.T2.17.1.1.1.8.5" class="ltx_td ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.5.1" class="ltx_text">Low</span></span>
<span id="S2.T2.17.1.1.1.8.6" class="ltx_td ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.6.1" class="ltx_text">Medium</span></span>
<span id="S2.T2.17.1.1.1.8.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.7.1" class="ltx_text">x</span></span></span>
<span id="S2.T2.17.1.1.1.9" class="ltx_tr">
<span id="S2.T2.17.1.1.1.9.1" class="ltx_td ltx_align_center">Book</span></span>
<span id="S2.T2.17.1.1.1.10" class="ltx_tr">
<span id="S2.T2.17.1.1.1.10.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.10.1.1" class="ltx_text ltx_font_bold">Wikinews</span></span>
<span id="S2.T2.17.1.1.1.10.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.2.1" class="ltx_text ltx_font_bold">CC BY 2.5</span></span>
<span id="S2.T2.17.1.1.1.10.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.3.1" class="ltx_text ltx_font_bold">News</span></span>
<span id="S2.T2.17.1.1.1.10.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.4.1" class="ltx_text ltx_font_bold">Formal</span></span>
<span id="S2.T2.17.1.1.1.10.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.5.1" class="ltx_text ltx_font_bold">Low</span></span>
<span id="S2.T2.17.1.1.1.10.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.6.1" class="ltx_text ltx_font_bold">Small</span></span>
<span id="S2.T2.17.1.1.1.10.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.10.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
<span id="S2.T2.17.1.1.1.11" class="ltx_tr">
<span id="S2.T2.17.1.1.1.11.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.11.1.1" class="ltx_text ltx_font_bold">Wikitree</span></span>
<span id="S2.T2.17.1.1.1.11.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.2.1" class="ltx_text ltx_font_bold">CC BY-SA 2.0</span></span>
<span id="S2.T2.17.1.1.1.11.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.3.1" class="ltx_text ltx_font_bold">News</span></span>
<span id="S2.T2.17.1.1.1.11.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.4.1" class="ltx_text ltx_font_bold">Formal</span></span>
<span id="S2.T2.17.1.1.1.11.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.5.1" class="ltx_text ltx_font_bold">Medium</span></span>
<span id="S2.T2.17.1.1.1.11.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.6.1" class="ltx_text ltx_font_bold">Large</span></span>
<span id="S2.T2.17.1.1.1.11.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.11.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
<span id="S2.T2.17.1.1.1.12" class="ltx_tr">
<span id="S2.T2.17.1.1.1.12.1" class="ltx_td ltx_align_left">Librewiki</span>
<span id="S2.T2.17.1.1.1.12.2" class="ltx_td ltx_align_center">CC BY-SA 3.0</span>
<span id="S2.T2.17.1.1.1.12.3" class="ltx_td ltx_align_center">Wiki</span>
<span id="S2.T2.17.1.1.1.12.4" class="ltx_td ltx_align_center">Formal</span>
<span id="S2.T2.17.1.1.1.12.5" class="ltx_td ltx_align_center">Medium</span>
<span id="S2.T2.17.1.1.1.12.6" class="ltx_td ltx_align_center">Large</span>
<span id="S2.T2.17.1.1.1.12.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span>
<span id="S2.T2.17.1.1.1.13" class="ltx_tr">
<span id="S2.T2.17.1.1.1.13.1" class="ltx_td ltx_align_left">Zetawiki</span>
<span id="S2.T2.17.1.1.1.13.2" class="ltx_td ltx_align_center">CC BY-SA 3.0</span>
<span id="S2.T2.17.1.1.1.13.3" class="ltx_td ltx_align_center">Wiki</span>
<span id="S2.T2.17.1.1.1.13.4" class="ltx_td ltx_align_center">Formal</span>
<span id="S2.T2.17.1.1.1.13.5" class="ltx_td ltx_align_center">Medium</span>
<span id="S2.T2.17.1.1.1.13.6" class="ltx_td ltx_align_center">Large</span>
<span id="S2.T2.17.1.1.1.13.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span>
<span id="S2.T2.17.1.1.1.14" class="ltx_tr">
<span id="S2.T2.17.1.1.1.14.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.14.1.1" class="ltx_text ltx_font_bold">Policy News</span></span>
<span id="S2.T2.17.1.1.1.14.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.2.1" class="ltx_text ltx_font_bold">KOGL Type 1</span></span>
<span id="S2.T2.17.1.1.1.14.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.3.1" class="ltx_text ltx_font_bold">News</span></span>
<span id="S2.T2.17.1.1.1.14.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.4.1" class="ltx_text ltx_font_bold">Formal</span></span>
<span id="S2.T2.17.1.1.1.14.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.5.1" class="ltx_text ltx_font_bold">Low</span></span>
<span id="S2.T2.17.1.1.1.14.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.6.1" class="ltx_text ltx_font_bold">Medium</span></span>
<span id="S2.T2.17.1.1.1.14.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.14.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
<span id="S2.T2.17.1.1.1.15" class="ltx_tr">
<span id="S2.T2.17.1.1.1.15.1" class="ltx_td ltx_align_left">
<span id="S2.T2.17.1.1.1.15.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.15.1.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.15.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">NIKL Standard</span></span>
<span id="S2.T2.17.1.1.1.15.1.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.15.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Korean Dictionary</span></span>
</span></span>
<span id="S2.T2.17.1.1.1.15.2" class="ltx_td ltx_align_center">CC BY-SA 2.0</span>
<span id="S2.T2.17.1.1.1.15.3" class="ltx_td ltx_align_center">Dictionary</span>
<span id="S2.T2.17.1.1.1.15.4" class="ltx_td ltx_align_center">Formal</span>
<span id="S2.T2.17.1.1.1.15.5" class="ltx_td ltx_align_center">Low</span>
<span id="S2.T2.17.1.1.1.15.6" class="ltx_td ltx_align_center">Large</span>
<span id="S2.T2.17.1.1.1.15.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span>
<span id="S2.T2.17.1.1.1.16" class="ltx_tr">
<span id="S2.T2.17.1.1.1.16.1" class="ltx_td ltx_align_left">
<span id="S2.T2.17.1.1.1.16.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.16.1.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.16.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Open</span></span>
<span id="S2.T2.17.1.1.1.16.1.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.16.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Korean Dictionary</span></span>
</span></span>
<span id="S2.T2.17.1.1.1.16.2" class="ltx_td ltx_align_center">CC BY-SA 2.0</span>
<span id="S2.T2.17.1.1.1.16.3" class="ltx_td ltx_align_center">Dictionary</span>
<span id="S2.T2.17.1.1.1.16.4" class="ltx_td ltx_align_center">Formal</span>
<span id="S2.T2.17.1.1.1.16.5" class="ltx_td ltx_align_center">Low</span>
<span id="S2.T2.17.1.1.1.16.6" class="ltx_td ltx_align_center">Large</span>
<span id="S2.T2.17.1.1.1.16.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span>
<span id="S2.T2.17.1.1.1.17" class="ltx_tr">
<span id="S2.T2.17.1.1.1.17.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.17.1.1" class="ltx_text ltx_font_bold">ParaKQC</span></span>
<span id="S2.T2.17.1.1.1.17.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.17.2.1" class="ltx_text ltx_font_bold">CC BY-SA 4.0</span></span>
<span id="S2.T2.17.1.1.1.17.3" class="ltx_td ltx_align_center">
<span id="S2.T2.17.1.1.1.17.3.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.17.3.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.17.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.17.3.1.1.1.1" class="ltx_text ltx_font_bold">Smart Home</span></span></span>
<span id="S2.T2.17.1.1.1.17.3.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.17.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.17.3.1.2.1.1" class="ltx_text ltx_font_bold">Utterances</span></span></span>
</span></span>
<span id="S2.T2.17.1.1.1.17.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.17.4.1" class="ltx_text ltx_font_bold">Colloquial</span></span>
<span id="S2.T2.17.1.1.1.17.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.17.5.1" class="ltx_text ltx_font_bold">Low</span></span>
<span id="S2.T2.17.1.1.1.17.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.17.6.1" class="ltx_text ltx_font_bold">Medium</span></span>
<span id="S2.T2.17.1.1.1.17.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.17.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
<span id="S2.T2.17.1.1.1.18" class="ltx_tr">
<span id="S2.T2.17.1.1.1.18.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.18.1.1" class="ltx_text ltx_font_bold">Airbnb Reviews</span></span>
<span id="S2.T2.17.1.1.1.18.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.2.1" class="ltx_text ltx_font_bold">CC0 1.0</span></span>
<span id="S2.T2.17.1.1.1.18.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.3.1" class="ltx_text ltx_font_bold">Review</span></span>
<span id="S2.T2.17.1.1.1.18.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.4.1" class="ltx_text ltx_font_bold">Colloquial</span></span>
<span id="S2.T2.17.1.1.1.18.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.5.1" class="ltx_text ltx_font_bold">Medium</span></span>
<span id="S2.T2.17.1.1.1.18.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.6.1" class="ltx_text ltx_font_bold">Large</span></span>
<span id="S2.T2.17.1.1.1.18.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.18.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
<span id="S2.T2.17.1.1.1.19" class="ltx_tr">
<span id="S2.T2.17.1.1.1.19.1" class="ltx_td ltx_align_left">
<span id="S2.T2.17.1.1.1.19.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.19.1.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.19.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.17.1.1.1.19.1.1.1.1.1" class="ltx_text ltx_font_bold">NAVER Sentiment</span></span></span>
<span id="S2.T2.17.1.1.1.19.1.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.19.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.17.1.1.1.19.1.1.2.1.1" class="ltx_text ltx_font_bold">Movie Corpus (NSMC)</span></span></span>
</span></span>
<span id="S2.T2.17.1.1.1.19.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.2.1" class="ltx_text ltx_font_bold">CC0 1.0</span></span>
<span id="S2.T2.17.1.1.1.19.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.3.1" class="ltx_text ltx_font_bold">Review</span></span>
<span id="S2.T2.17.1.1.1.19.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.4.1" class="ltx_text ltx_font_bold">Colloquial</span></span>
<span id="S2.T2.17.1.1.1.19.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.5.1" class="ltx_text ltx_font_bold">Medium</span></span>
<span id="S2.T2.17.1.1.1.19.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.6.1" class="ltx_text ltx_font_bold">Large</span></span>
<span id="S2.T2.17.1.1.1.19.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.19.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
<span id="S2.T2.17.1.1.1.20" class="ltx_tr">
<span id="S2.T2.17.1.1.1.20.1" class="ltx_td ltx_align_left">
<span id="S2.T2.17.1.1.1.20.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.20.1.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.20.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">NAVER Entertainment</span></span>
<span id="S2.T2.17.1.1.1.20.1.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.20.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">News Reviews</span></span>
</span></span>
<span id="S2.T2.17.1.1.1.20.2" class="ltx_td ltx_align_center">CC BY-SA 4.0</span>
<span id="S2.T2.17.1.1.1.20.3" class="ltx_td ltx_align_center">Review</span>
<span id="S2.T2.17.1.1.1.20.4" class="ltx_td ltx_align_center">Colloquial</span>
<span id="S2.T2.17.1.1.1.20.5" class="ltx_td ltx_align_center">High</span>
<span id="S2.T2.17.1.1.1.20.6" class="ltx_td ltx_align_center">Large</span>
<span id="S2.T2.17.1.1.1.20.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span>
<span id="S2.T2.17.1.1.1.21" class="ltx_tr">
<span id="S2.T2.17.1.1.1.21.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.17.1.1.1.21.1.1" class="ltx_text ltx_font_bold">Acrofan News</span></span>
<span id="S2.T2.17.1.1.1.21.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S2.T2.17.1.1.1.21.2.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.21.2.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.21.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.21.2.1.1.1.1" class="ltx_text ltx_font_bold">CC BY-SA 4.0</span></span></span>
<span id="S2.T2.17.1.1.1.21.2.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.21.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.21.2.1.2.1.1" class="ltx_text ltx_font_bold">for KLUE-MRC by Contract</span></span></span>
</span></span>
<span id="S2.T2.17.1.1.1.21.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.3.1" class="ltx_text ltx_font_bold">News</span></span>
<span id="S2.T2.17.1.1.1.21.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.4.1" class="ltx_text ltx_font_bold">Formal</span></span>
<span id="S2.T2.17.1.1.1.21.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.5.1" class="ltx_text ltx_font_bold">Low</span></span>
<span id="S2.T2.17.1.1.1.21.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.6.1" class="ltx_text ltx_font_bold">Large</span></span>
<span id="S2.T2.17.1.1.1.21.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
<span id="S2.T2.17.1.1.1.22" class="ltx_tr">
<span id="S2.T2.17.1.1.1.22.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S2.T2.17.1.1.1.22.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.22.1.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.22.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.17.1.1.1.22.1.1.1.1.1" class="ltx_text ltx_font_bold">The Korea Economics</span></span></span>
<span id="S2.T2.17.1.1.1.22.1.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.22.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.17.1.1.1.22.1.1.2.1.1" class="ltx_text ltx_font_bold">Daily News</span></span></span>
</span></span>
<span id="S2.T2.17.1.1.1.22.2" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S2.T2.17.1.1.1.22.2.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.17.1.1.1.22.2.1.1" class="ltx_tr">
<span id="S2.T2.17.1.1.1.22.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.22.2.1.1.1.1" class="ltx_text ltx_font_bold">CC BY-SA 4.0</span></span></span>
<span id="S2.T2.17.1.1.1.22.2.1.2" class="ltx_tr">
<span id="S2.T2.17.1.1.1.22.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.22.2.1.2.1.1" class="ltx_text ltx_font_bold">for KLUE-MRC by Contract</span></span></span>
</span></span>
<span id="S2.T2.17.1.1.1.22.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.3.1" class="ltx_text ltx_font_bold">News</span></span>
<span id="S2.T2.17.1.1.1.22.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.4.1" class="ltx_text ltx_font_bold">Formal</span></span>
<span id="S2.T2.17.1.1.1.22.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.5.1" class="ltx_text ltx_font_bold">Low</span></span>
<span id="S2.T2.17.1.1.1.22.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.6.1" class="ltx_text ltx_font_bold">Large</span></span>
<span id="S2.T2.17.1.1.1.22.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.7.1" class="ltx_text ltx_font_bold">o</span></span></span>
</span></span></p>
</span></div>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Selected Corpora</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Here, we describe in more detail general characteristics and potential concerns of each source corpus. We document the collection mechanisms, timeframe, domain, style, license, and background of each corpus as well.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">News Headlines</h5>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p1.1" class="ltx_p">from Yonhap News Agency (YNA).</p>
</div>
<div id="S2.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p2.1" class="ltx_p">YNA is a dataset of news headlines from Yonhap News Agency, one of the representative news agencies in South Korea. Using news headlines does not infringe on copyrights, unlike the actual contents of news articles. We include YNA from 2016 to 2020 with a main purpose of using it for a single sentence classification task.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Wikipedia (WIKIPEDIA)</h5>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p1.1" class="ltx_p">WIKIPEDIA is an open encyclopedia written in a formal style and has been widely used for language modeling and dataset construction across many languages, because of its high-quality and well-curated text. The Wikipedia articles in Korean are released under CC BY-SA. We use the dump of Korean Wikipedia released on December 1st, 2020.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Wikinews (WIKINEWS)</h5>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p1.1" class="ltx_p">WIKINEWS implements collective journalism and provides news articles for free under CC BY, both of which are rare for news articles. Due to these properties, we include it in the source corpora despite its limited number of articles (approximately 500 of them).</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Wikitree (WIKITREE)</h5>

<div id="S2.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px4.p1.1" class="ltx_p">WIKITREE is a dataset of news articles derived from Wikitree, the first Korean social media-based news platform that started in 2010.
Although there are concerns that the articles on Wikitree are in many cases advertisement-in-disguise or click-bait headlines and express undesirable biases,
we include WIKITREE, as it is the only large-scale source of news articles that are freely distributed under CC BY-SA, to the best of our knowledge. It also covers a broad spectrum of topics, including politics, economics, culture and life. We use the articles published between 2016 and 2020. We conduct more thorough manual inspection of WIKITREE is more thoroughly conducted. See Section&nbsp;<a href="#S2.SS2.SSS1" title="2.2.1 Potential Concerns ‣ 2.2 Selected Corpora ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.1</span></a> for more details.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Policy News (POLICY)</h5>

<div id="S2.SS2.SSS0.Px5.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px5.p1.1" class="ltx_p">POLICY is a dataset of various articles distributed by ministries, national offices, and national commissions of South Korea. It covers statements, notices, or media notes reported by the government agencies. POLICY is protected under the Korea Open Government License (KOGL) Type 1, which permits users to share and remix even for commercial purposes, if attribution is properly done. We include articles released up to the end of 2020.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ParaKQC (PARAKQC)</h5>

<div id="S2.SS2.SSS0.Px6.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px6.p1.1" class="ltx_p">PARAKQC is a dataset of 10,000 utterances aimed at smart home devices, consisting of 1,000 intents of 10 similar queries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. It covers various topics which are probable when interacting with smart home speakers, such as scheduling an appointment and asking about the weather. PARAKQC is available under CC BY-SA.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Airbnb Reviews (AIRBNB)</h5>

<div id="S2.SS2.SSS0.Px7.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px7.p1.1" class="ltx_p">AIRBNB is a review dataset sourced from the publicly accessible portion of the Airbnb website. More specifically, we start from the existing multilingual Airbnb reviews collected and preprocessed by Inside Airbnb.<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>
<a target="_blank" href="http://insideairbnb.com/get-the-data.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://insideairbnb.com/get-the-data.html</a>
</span></span></span>
We identify a subset of reviews written in Korean from this multilingual Airbnb corpus, using regular expressions. Reviews are from hosts and guests who have completed their stays. AIRBNB is available under CC0.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px8" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">NAVER Sentiment Movie Corpus (NSMC)</h5>

<div id="S2.SS2.SSS0.Px8.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px8.p1.1" class="ltx_p">NSMC is a movie review dataset scraped from NAVER Movies.<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>
<a target="_blank" href="https://movie.naver.com/movie/point/af/list.nhn" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://movie.naver.com/movie/point/af/list.nhn</a>
</span></span></span>
The reviews are written by online users. Each review comes with both the textual content and the binary sentiment label. There are 200,000 reviews in total.
The numbers of positive and negative reviewers are balanced. NSMC is available under CC0.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px9" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Acrofan News (ACROFAN)</h5>

<div id="S2.SS2.SSS0.Px9.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px9.p1.1" class="ltx_p">ACROFAN is a corpus consisting of news articles released by ACROFAN. Most articles are press release-like in that they often introduce new products or events of companies. The formats and styles are quite templated, although the articles cover a broad set of categories including automobiles, IT, startups, big companies, energy, beauty and fashion.
We obtain the permission and use of the articles from ACROFAN for KLUE. We include news articles published between Dec 2020 and Jan 2021.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px10" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">The Korea Economics Daily News (The Korea Economy Daily)</h5>

<div id="S2.SS2.SSS0.Px10.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px10.p1.1" class="ltx_p">The Korea Economy Daily is a news corpus consisting of articles from the Korea Economics Daily owned by Hankyung corporation. Korea Economics Daily is a newspaper that mainly covers economic issues, but also publishes various topics such as politics, culture and IT topics. The owner of the Korea Economics Daily and we have entered a contract to use news articles published between Jan 2013 and Dec 2015, provided by the Hankyung corporation, as a part of KLUE. This allows us to ensure high-quality, well-curated news articles are included in KLUE. We release The Korea Economy Daily under CC BY-SA, with the condition that these articles are used for the purpose of machine learning research.</p>
</div>
</section>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Potential Concerns</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.1" class="ltx_p">Based on the ten selected corpora above, we list up and discuss some of the concerns here. Some concerns are focused on the quality of data, while the others are more societal and ethical.</p>
</div>
<section id="S2.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Toxic Content</h5>

<div id="S2.SS2.SSS1.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.Px1.p1.1" class="ltx_p">Although news articles, such as those from YNA, WIKINEWS, WIKITREE, POLICY, ACROFAN, and The Korea Economy Daily are better written and curated than user-generated contents, such as online reviews, these articles nevertheless may reflect some of the biases possessed by journalists and editors. In particular, our manual inspection has revealed that WIKITREE contains more of potentially problematic patterns than the other news sources, due to the incentive structure that incentivizes articles that are more widely shared and clicked more on social media. This is especially true with headlines of these articles, and we thus refrain from using the headlines from WIKITREE when constructing TC. We also do not use the article contents from WIKITREE for MRC, as articles in whole often exaggerate and emphasize sensational aspects of stories. We however use sentences sampled from WIKITREE when building other task-specific corpora, as they are often complete and well-formed. We discard any problematic sentences via annotation.</p>
</div>
<div id="S2.SS2.SSS1.Px1.p2" class="ltx_para">
<p id="S2.SS2.SSS1.Px1.p2.1" class="ltx_p">Unlike news articles, online reviews have higher potential to contain toxic content, although such tendency varies from one corpus to another. Due to its peer-reviewing system, AIRBNB rarely contains reviews that are deemed toxic. NSMC on the other hand contains comments that could be considered offensive toward movies, their casts, and their directors. As there is a Korean hate speech dataset on review domains&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>, we first filter out toxic content with a detector trained on the dataset. Then we discard problematic sentences via the annotation procedure.</p>
</div>
<div id="S2.SS2.SSS1.Px1.p3" class="ltx_para">
<p id="S2.SS2.SSS1.Px1.p3.1" class="ltx_p">All utterances of PARAKQC are carefully created based on a pre-defined annotation guideline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. This largely prevents toxic content from entering the corpus.</p>
</div>
</section>
<section id="S2.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Personally Identifiable Information (PII)</h5>

<div id="S2.SS2.SSS1.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS1.Px2.p1.1" class="ltx_p">Private information is any information that can be used to identify an individual who is not considered a public figure.<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>
See the precedent set by the Supreme Court in Korea: 대법원 2011. 9. 2. 선고 2008다42430 전원합의체 판결 available at <a target="_blank" href="https://glaw.scourt.go.kr/wsjo/panre/sjo100.do?contId=2060159&amp;q=2008%EB%8B%A442430" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://glaw.scourt.go.kr/wsjo/panre/sjo100.do?contId=2060159&amp;q=2008%EB%8B%A442430</a>.
</span></span></span>
It includes for instance names, social security numbers, telephone numbers and bank account numbers.</p>
</div>
<div id="S2.SS2.SSS1.Px2.p2" class="ltx_para">
<p id="S2.SS2.SSS1.Px2.p2.1" class="ltx_p">In the case of news articles, due to their nature of describing social events, they often contain PII such as names and addresses. This is less so with online reviews, as they are often about public figures, such as actors, actresses and directors, as we observe in NSMC. We however notice that the reviews in AIRBNB contain the names of hosts and/or guests as well as their addresses, which must be carefully handled.</p>
</div>
<div id="S2.SS2.SSS1.Px2.p3" class="ltx_para">
<p id="S2.SS2.SSS1.Px2.p3.1" class="ltx_p">Some of the artificially generated utterances in PARAKQC do contain names. It is however our understanding that these are mostly fictional, meaning that they are unlikely to be truly private information.</p>
</div>
</section>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Preprocessing</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Because these source corpora come from various sources with varying levels of quality and curation, we carefully preprocess them even before deriving a subset for each downstream task. In this section, we describe our preprocessing routines which are applied after splitting each document within these corpora into sentences using the Korean Sentence Splitter (KSS) v2.2.0.2.<span id="footnote14" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>
<a target="_blank" href="https://github.com/hyunwoongko/kss" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/hyunwoongko/kss</a>
</span></span></span>
The proprocessing routines below are <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_italic">in addition to</span> manual inspection and filtering during the annotation stage of each KLUE task.</p>
</div>
<section id="S2.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Noise Filtering</h5>

<div id="S2.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS3.SSS0.Px1.p1.1" class="ltx_p">We remove noisy and/or non-Korean text from the selected source corpora.
We first remove hashtags (e.g., #JMT), HTML tags (e.g., &lt;br&gt;), bad characters (e.g., U+200B (zero-width space), U+FEFF (byte order mark)), empty parenthesis (e.g., ()), and consecutive blanks. We then filter out sentences with more than 10 Chinese or Japanese characters. For the corpora derived from news articles, we remove information about reporters and press, images, source tags as well as copyright tags (e.g., copyright by ©).</p>
</div>
</section>
<section id="S2.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Toxic Content Removal</h5>

<div id="S2.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS3.SSS0.Px2.p1.2" class="ltx_p">In order to avoid introducing undesire contents and biases into KLUE, we use a number of automatic tools to remove various undesirable sentences from the source corpora. Using the Korean hate speech dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>, we train a gender bias<span id="footnote15" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>
<a target="_blank" href="https://huggingface.co/monologg/koelectra-base-v3-gender-bias" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/monologg/koelectra-base-v3-gender-bias</a>
</span></span></span>
and a hate speech detector.<span id="footnote16" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span>
<a target="_blank" href="https://huggingface.co/monologg/koelectra-base-v3-hate-speech" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/monologg/koelectra-base-v3-hate-speech</a>
</span></span></span>
We discard a sentence which was predicted to exhibit gender bias with the predictive score of at least <math id="S2.SS3.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S2.SS3.SSS0.Px2.p1.1.m1.1a"><mn id="S2.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS3.SSS0.Px2.p1.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px2.p1.1.m1.1b"><cn type="float" id="S2.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS3.SSS0.Px2.p1.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px2.p1.1.m1.1c">0.5</annotation></semantics></math>. We also discard a sentence if it was deemed to be hate speech, with the predictive score of <math id="S2.SS3.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="0.9" display="inline"><semantics id="S2.SS3.SSS0.Px2.p1.2.m2.1a"><mn id="S2.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS3.SSS0.Px2.p1.2.m2.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px2.p1.2.m2.1b"><cn type="float" id="S2.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS3.SSS0.Px2.p1.2.m2.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px2.p1.2.m2.1c">0.9</annotation></semantics></math> or above. The thresholds are manually determined for each corpus. This approach work well for online text, such as reviews, because the Korean hate speech dataset was constructed using online reviews. It however does not work well for more formal text, such as found in news articles, based on which we decide against using this strategy on The Korea Economy Daily, ACROFAN, and YNA.</p>
</div>
</section>
<section id="S2.SS3.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">PII Removal</h5>

<div id="S2.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS3.SSS0.Px3.p1.1" class="ltx_p">To mitigate potential privacy issues, we get rid of sentences that contain private information. We detect such sentences using regular expressions that match email addresses, URL and user-mentioning keywords, such as ‘@gildong’.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Task Assignment</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">We use these source corpora to build the datasets for the seven KLUE tasks, except for the DST. DST is built from simulated dialogues by crowdworkers and does not require access to offline text. For each downstream task, we use a subset of the source corpora, as described below:</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p">Topic Classification (TC): We use YNA, which has been widely studied for a single sentence topic classification task.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">Semantic Textual Similarity (STS): We use AIRBNB, POLICY, and PARAKQC to include diverse semantic contexts. Intent queries and topic information of PARAKQC are useful when generating semantically related sentence pairs.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p">Natural Language Inference (NLI): Following MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>, we use multiple sources to construct NLI. We use WIKITREE, POLICY, WIKINEWS, WIKIPEDIA, NSMC and AIRBNB.</p>
</div>
</li>
<li id="S2.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i4.p1" class="ltx_para">
<p id="S2.I2.i4.p1.1" class="ltx_p">Named Entity Recognition (NER): Due to the nature of NER, we must build a corpus in which (named) entities frequently appear. We thus use WIKITREE and NSMC, which enables us to include both formal and informal writing styles.</p>
</div>
</li>
<li id="S2.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i5.p1" class="ltx_para">
<p id="S2.I2.i5.p1.1" class="ltx_p">Relation Extraction (RE):
We use WIKIPEDIA, WIKITREE and POLICY. These corpora tend to have long complete sentences with the names of public figures and their relationships to various organizations.</p>
</div>
</li>
<li id="S2.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i6.p1" class="ltx_para">
<p id="S2.I2.i6.p1.1" class="ltx_p">Dependency Parsing (DP): We balance formal and colloquial writing styles, while ensuring most of sentences from selected corpora are complete.
We end up using WIKITREE and AIRBNB. We choose AIRBNB over NSMC, because the former has better-formed sentences.</p>
</div>
</li>
<li id="S2.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i7.p1" class="ltx_para">
<p id="S2.I2.i7.p1.1" class="ltx_p">Machine Reading Comprehension (MRC): To provide informative passages, we use WIKIPEDIA, The Korea Economy Daily, and ACROFAN.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>KLUE Benchmark</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The goal of KLUE is to provide high quality evaluation datasets and suitable automatic metrics to test a system’s ability to understand Korean language. We provide comprehensive details on how we construct our 8 benchmark datasets. We document 1) background of source corpus selection, 2) annotation protocol, 3) annotation process, 4) dataset split strategy, and 5) design process of the metrics. In the annotation process, we guide workers to identify texts containing potential ethical issues. See Section&nbsp;<a href="#footnote3" title="footnote 3 ‣ 3rd item ‣ Considerations in Annotation ‣ 1.1 Summary ‣ 1 Introduction ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for our definitions on bias, hate, and PII.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Topic Classification (TC)</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In topic classification (TC), the goal is to train a classifier to predict the topic of a given text snippet. Topic classification datasets typically consist of news or Wikipedia articles and their predefined categories, because the categories often represent topics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">We include TC in our KLUE benchmark, as inferring the topic of a text is a key capability that should be possessed by a language understanding system. As a typical single sentence classification task, other NLU benchmarks such as CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite> and IndicGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> also contain TNEWS and News Category Classification. For Korean, no dataset has been proposed for the task, which motivates us to construct the first Korean topic classification benchmark.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In this task, given a news headline, a text classifier must predict a topic which is one of {politics, economy, society, culture, world, IT/science, sports}. We formulate TC as single sentence classification task following previous works and use macro-F1 score as an evaluation metric.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Dataset Construction</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">Our TC benchmark is constructed in three stages. First, we collect headlines and their corresponding categories, then we annotate the topics without looking at the categories and we finalize the dataset by defining its split into training, development and test splits considering the publication date and term appearances.</p>
</div>
<section id="S3.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS1.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px1.p1.1" class="ltx_p">We collect news headlines from online articles distributed by Yonhap News Agency (YNA), the largest news agency in Korea. Specifically, we collect the headlines of the published articles from January 2016 to December 2020 from Naver News.<span id="footnote17" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span><a target="_blank" href="https://news.naver.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://news.naver.com/</a></span></span></span> These articles belong to one of the following seven sections: politics, economy, society, culture, world, IT/science, and sports. To balance the data across the different sections, we randomly sample 10,000 articles from each section, except for the sports and IT/science section. We collect 9,000 sports articles and 11,000 IT/science articles.</p>
</div>
<div id="S3.SS1.SSS1.Px1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.Px1.p2.1" class="ltx_p">Unlike other benchmarks such as TNEWS in CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite> or AG News <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite>, we exclude contents of the articles to avoid infringement of copyright. Since the contents are protected as copyrighted work, we cannot freely use them without permission. Headlines, on the other hand, are not considered copyrighted work based on a legal precedent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS1.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px2.p1.1" class="ltx_p">The headline of each article may not reflect all of the main content, such that the <span id="S3.SS1.SSS1.Px2.p1.1.1" class="ltx_text ltx_font_italic">topic</span> of the headline may be different from the original news section of the article. To address this gap between the headline and the corresponding article, we manually annotate the topics of the headlines.</p>
</div>
<div id="S3.SS1.SSS1.Px2.p2" class="ltx_para">
<p id="S3.SS1.SSS1.Px2.p2.1" class="ltx_p">We use SelectStar,<span id="footnote18" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span><a target="_blank" href="https://selectstar.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://selectstar.ai/</a></span></span></span> a crowdsourcing platform in Korea, to annotate topics of the headlines. For each headline, three annotators label topics independently from each other. Each annotator picks at most three topics in the order of relevance among the seven categories. For precise annotation, we also present <span id="S3.SS1.SSS1.Px2.p2.1.1" class="ltx_text ltx_font_italic">key terms</span> of each topic to annotators. The terms are subsections of corresponding topics in NAVER news platform as shown in Table&nbsp;<a href="#S3.T3" title="Table 3 ‣ Final Dataset ‣ 3.1.1 Dataset Construction ‣ 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S3.SS1.SSS1.Px2.p3" class="ltx_para">
<p id="S3.SS1.SSS1.Px2.p3.1" class="ltx_p">An annotator may choose <span id="S3.SS1.SSS1.Px2.p3.1.1" class="ltx_text ltx_font_italic">unable-to-decide</span> if the headline does not contain sufficient information to identify the appropriate categories. Such an example is “Youngsoo Kim awards an appreciation plaque”. There is no clue about who “Youngsoo Kim” is nor why he is awarding the appreciation plaque, in this headline.</p>
</div>
<div id="S3.SS1.SSS1.Px2.p4" class="ltx_para">
<p id="S3.SS1.SSS1.Px2.p4.1" class="ltx_p">We request the workers to report any headline that includes personally identifiable information (PII), expresses social bias, or is hate speech. We discard the reported headline after manually reviewing them.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS1.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p1.1" class="ltx_p">We run a pilot study to select workers, before commencing the main annotation process. We exclude workers who have continuously failed to assign a topic or have failed to agree with the other workers during the pilot stage. As a result, 13 workers have passed this stage of pilot study.</p>
</div>
<div id="S3.SS1.SSS1.Px3.p2" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p2.1" class="ltx_p">In the main annotation, the 13 selected workers labeled topics for all 70,000 headlines. During the annotation, they reported 650 headlines are including potential PIIs (0.93%), 194 toxic contents (0.28%), and 2,515 <span id="S3.SS1.SSS1.Px3.p2.1.1" class="ltx_text ltx_font_italic">unable-to-decide</span>s (3.59%). We first exclude such invalid 2,953 headlines. The sum of the three type of problematic headlines are larger than the total value because of the intersection among them. After filtering them, 67,047 headlines remain.</p>
</div>
<div id="S3.SS1.SSS1.Px3.p3" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p3.1" class="ltx_p">We look at agreements between three annotators in valid headlines. We consider each of the first relevant topics chosen by three annotators. In 40,359 (60.5%) headlines, all three annotators agree to a single topic. 23,353 (34.8%) had two majority votes, and the other 3,155 (4.7%) did not reached to agreement. To make the headlines classified to a single topic, we remove the others, leaving 63,892 headlines.</p>
</div>
<div id="S3.SS1.SSS1.Px3.p4" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p4.1" class="ltx_p">We examine the second and third relevant topics within an annotator. For 48,885 (69.8%) of headlines, three annotators did not choose any second and third most relevant topic. Only 5,088 (7.3%) of headlines have the second topic in three annotators. We thus assume that headlines are sufficiently represented by the first relevant topics within an annotator.</p>
</div>
<div id="S3.SS1.SSS1.Px3.p5" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p5.1" class="ltx_p">We thus keep only a single topic for each headline, selected by at least two annotators out of three. The annotator agreement on the resulting 63,892 headlines is fairly high (Krippendorff’s <math id="S3.SS1.SSS1.Px3.p5.1.m1.1" class="ltx_Math" alttext="\alpha=0.713" display="inline"><semantics id="S3.SS1.SSS1.Px3.p5.1.m1.1a"><mrow id="S3.SS1.SSS1.Px3.p5.1.m1.1.1" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.2" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.2.cmml">α</mi><mo id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.1" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.3" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.3.cmml">0.713</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p5.1.m1.1b"><apply id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1"><eq id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.1"></eq><ci id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.2">𝛼</ci><cn type="float" id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.3">0.713</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p5.1.m1.1c">\alpha=0.713</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS1.SSS1.Px4.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px4.p1.1" class="ltx_p">We partition the final dataset, named YNAT (Yonhap News Agency dataset for Topic classification), into train, development, and test sets.
We split the dataset based on the publication date. We include headlines published after 2020 in the development and test sets, while those published before 2020 in the training set. To prevent TC models attending specific keyword to classify the headlines, we also include headlines containing terms that have not appeared in the train set in the development and test set. As shown in the Table&nbsp;<a href="#S3.T3" title="Table 3 ‣ Final Dataset ‣ 3.1.1 Dataset Construction ‣ 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, train, development, and test sets consist of 45,678, 9,107, and 9,107 examples, respectively.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The final statistics of YNAT (KLUE-TC), provided with the key terms of each category.</figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T3.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.1.1" class="ltx_text ltx_font_bold">Topic</span></td>
<td id="S3.T3.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.2.1" class="ltx_text ltx_font_bold">Key Terms</span></td>
<td id="S3.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.3.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.4.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T3.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.5.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T3.1.1.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.6.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T3.1.2" class="ltx_tr">
<td id="S3.T3.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Politics</td>
<td id="S3.T3.1.2.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T3.1.2.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.2.2.1.1" class="ltx_tr">
<td id="S3.T3.1.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.2.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Blue House, Ministry, Parliament, North Korea</span></td>
</tr>
<tr id="S3.T3.1.2.2.1.2" class="ltx_tr">
<td id="S3.T3.1.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.2.2.1.2.1.1" class="ltx_text" style="font-size:90%;">Political parties, Defense, Diplomacy</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.2.3" class="ltx_td ltx_align_center ltx_border_t">7,379</td>
<td id="S3.T3.1.2.4" class="ltx_td ltx_align_center ltx_border_t">750</td>
<td id="S3.T3.1.2.5" class="ltx_td ltx_align_center ltx_border_t">722</td>
<td id="S3.T3.1.2.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">8,851</td>
</tr>
<tr id="S3.T3.1.3" class="ltx_tr">
<td id="S3.T3.1.3.1" class="ltx_td ltx_align_left">Economy</td>
<td id="S3.T3.1.3.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.3.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.3.2.1.1" class="ltx_tr">
<td id="S3.T3.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.3.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Stock, Finance, Industry Enterprise, Real estate</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.3.3" class="ltx_td ltx_align_center">6,118</td>
<td id="S3.T3.1.3.4" class="ltx_td ltx_align_center">1,268</td>
<td id="S3.T3.1.3.5" class="ltx_td ltx_align_center">1,348</td>
<td id="S3.T3.1.3.6" class="ltx_td ltx_nopad_r ltx_align_center">8,734</td>
</tr>
<tr id="S3.T3.1.4" class="ltx_tr">
<td id="S3.T3.1.4.1" class="ltx_td ltx_align_left">Society</td>
<td id="S3.T3.1.4.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.4.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.4.2.1.1" class="ltx_tr">
<td id="S3.T3.1.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.4.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Education, Labor, Journalism</span></td>
</tr>
<tr id="S3.T3.1.4.2.1.2" class="ltx_tr">
<td id="S3.T3.1.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.4.2.1.2.1.1" class="ltx_text" style="font-size:90%;">Environment, Human rights, Food and drugs</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.4.3" class="ltx_td ltx_align_center">5,133</td>
<td id="S3.T3.1.4.4" class="ltx_td ltx_align_center">3,740</td>
<td id="S3.T3.1.4.5" class="ltx_td ltx_align_center">3,701</td>
<td id="S3.T3.1.4.6" class="ltx_td ltx_nopad_r ltx_align_center">12,574</td>
</tr>
<tr id="S3.T3.1.5" class="ltx_tr">
<td id="S3.T3.1.5.1" class="ltx_td ltx_align_left">Culture</td>
<td id="S3.T3.1.5.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.5.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.5.2.1.1" class="ltx_tr">
<td id="S3.T3.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T3.1.5.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Health, Transportation, Leisure, Hot places, Fashion</span>,</td>
</tr>
<tr id="S3.T3.1.5.2.1.2" class="ltx_tr">
<td id="S3.T3.1.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.5.2.1.2.1.1" class="ltx_text" style="font-size:90%;">Beauty, Performance, Exhibition, Books, Weather</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.5.3" class="ltx_td ltx_align_center">5,751</td>
<td id="S3.T3.1.5.4" class="ltx_td ltx_align_center">1,387</td>
<td id="S3.T3.1.5.5" class="ltx_td ltx_align_center">1,369</td>
<td id="S3.T3.1.5.6" class="ltx_td ltx_nopad_r ltx_align_center">8,507</td>
</tr>
<tr id="S3.T3.1.6" class="ltx_tr">
<td id="S3.T3.1.6.1" class="ltx_td ltx_align_left">World</td>
<td id="S3.T3.1.6.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.6.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.6.2.1.1" class="ltx_tr">
<td id="S3.T3.1.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.6.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Asia/Australia, America, Europe, Middle East/Africa</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.6.3" class="ltx_td ltx_align_center">8,320</td>
<td id="S3.T3.1.6.4" class="ltx_td ltx_align_center">776</td>
<td id="S3.T3.1.6.5" class="ltx_td ltx_align_center">835</td>
<td id="S3.T3.1.6.6" class="ltx_td ltx_nopad_r ltx_align_center">9,931</td>
</tr>
<tr id="S3.T3.1.7" class="ltx_tr">
<td id="S3.T3.1.7.1" class="ltx_td ltx_align_left">IT/Science</td>
<td id="S3.T3.1.7.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.7.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.7.2.1.1" class="ltx_tr">
<td id="S3.T3.1.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.7.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Mobile, IT, Internet Social media, Communication</span></td>
</tr>
<tr id="S3.T3.1.7.2.1.2" class="ltx_tr">
<td id="S3.T3.1.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.7.2.1.2.1.1" class="ltx_text" style="font-size:90%;">Computer, Game, Scientific journalism</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.7.3" class="ltx_td ltx_align_center">5,235</td>
<td id="S3.T3.1.7.4" class="ltx_td ltx_align_center">587</td>
<td id="S3.T3.1.7.5" class="ltx_td ltx_align_center">554</td>
<td id="S3.T3.1.7.6" class="ltx_td ltx_nopad_r ltx_align_center">6,376</td>
</tr>
<tr id="S3.T3.1.8" class="ltx_tr">
<td id="S3.T3.1.8.1" class="ltx_td ltx_align_left">Sports</td>
<td id="S3.T3.1.8.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.8.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.8.2.1.1" class="ltx_tr">
<td id="S3.T3.1.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.8.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Baseball, Basketball, Volleyball, E-sports</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.8.3" class="ltx_td ltx_align_center">7,742</td>
<td id="S3.T3.1.8.4" class="ltx_td ltx_align_center">599</td>
<td id="S3.T3.1.8.5" class="ltx_td ltx_align_center">578</td>
<td id="S3.T3.1.8.6" class="ltx_td ltx_nopad_r ltx_align_center">8,919</td>
</tr>
<tr id="S3.T3.1.9" class="ltx_tr">
<td id="S3.T3.1.9.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T3.1.9.2" class="ltx_td ltx_border_bb ltx_border_t"></td>
<td id="S3.T3.1.9.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.3.1" class="ltx_text ltx_font_bold">45,678</span></td>
<td id="S3.T3.1.9.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.4.1" class="ltx_text ltx_font_bold">9,107</span></td>
<td id="S3.T3.1.9.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.5.1" class="ltx_text ltx_font_bold">9,107</span></td>
<td id="S3.T3.1.9.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.6.1" class="ltx_text ltx_font_bold">63,892</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Evaluation Metric</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">The evaluation metric for YNAT is macro F1 score. Macro F1 score is defined as the mean of topic-wise F1 scores, giving the same importance to each topic. Topic-wise F1 score weights recall and precision equally.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Related Work</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">Although many topic classification datasets have been proposed in various languages, we are not aware of any public TC benchmark in Korea. AG News <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite>, a widely used benchmark for topic classification in English, consists of more than a million of news articles collected from the news search engine ComeToMyHead,<span id="footnote19" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note">19</span>
More information available in <a target="_blank" href="http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html</a></span></span></span>
and categorizes articles into four sections: world, sports, business, and science/technology. More recently, a number of TC benchmark datasets in languages other than English were proposed.
IndicGLUE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> includes News Genre Classification in Indian languages, in which the goal is to classify a news article or news headline into seven categories; entertainment, sports, business, lifestyle, technology, politics, and crime.
TNEWS from CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite> is a news topic classification task in Mandarin and consists of 73K titles with 15 news categories, published in Toutiao.</p>
</div>
<div id="S3.SS1.SSS3.p2" class="ltx_para">
<p id="S3.SS1.SSS3.p2.1" class="ltx_p">Since a large language model fine-tuned on TC benchmark can closely reach 100% accuracy as in IndicGLUE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, some researchers focus on making challenging TC benchmark to leave a room for improvement. CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite> filters easy examples in TNEWS by using 4-fold cross-validation, and then randomly shuffle and split the dataset. Instead of designing our benchmark artificially more difficult, we reflect how topic classification is done in practice even a baseline model reaches to good performance with relatively easy examples in our benchmark.</p>
</div>
</section>
<section id="S3.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.4 </span>Conclusion</h4>

<div id="S3.SS1.SSS4.p1" class="ltx_para">
<p id="S3.SS1.SSS4.p1.1" class="ltx_p">We introduce YNAT, the first Korean topic classification benchmark. The benchmark includes 63,892 news headlines classified to a single hand-labeled topic among 7 categories. We assume each headline has only a single topic, but it could be formulated as multi-label classification. We thus open the second and third relevant topic annotations. Also, URLs for each headlines are accompanied for future work if metadata is needed. If some of them requires permission to use, one should contact to the agency. We expect YNAT to serve as a simple and basic NLU task compared to others in KLUE.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Semantic Textual Similarity (STS)</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Semantic textual similarity (STS) is to measure the degree of semantic equivalence between two sentences. We include STS in our benchmark because it is essential to other NLP tasks such as machine translation, summarization, and question answering. Like STS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> in GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>, many NLU benchmarks include comparing semantic similarity of text snippets such as semantic similarity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>, paraphrase detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, or word sense disambiguation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We formulate STS as a sentence pair regression task which predicts the semantic similarity of two input sentences as a real value from 0 (no meaning overlap) to 5 (meaning equivalence). A model performance is measured by Pearson’s correlation coefficient following the evaluation scheme of STS-b <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. We additionally binarize the real numbers into two classes with a threshold score 3.0 (paraphrased or not), and use F1 score to evaluate the model.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Dataset Construction</h4>

<section id="S3.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS2.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.Px1.p1.1" class="ltx_p">To diversify domain and style of source corpora, we collect sentences from AIRBNB (colloquial review), POLICY (formal news), and PARAKQC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> (smart home utterances). We carefully match them to sentence pairs.</p>
</div>
<div id="S3.SS2.SSS1.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.Px1.p2.1" class="ltx_p">For each corpus, we design a sampling strategy of sentence pairs to uniformly cover all range of the similarity scores. Without a sophisticated strategy, simple random sampling and matching sentence to pairs would result in a majority of the score zero. To alleviate this skewness, <span id="S3.SS2.SSS1.Px1.p2.1.1" class="ltx_text ltx_font_italic">potentially</span> similar and less similar sentences are separately paired by using various methods. For instance, if two descriptions are depicting the same image or headlines referring to the same event, they are likely to be similar because of the additional information. Otherwise, they would not be similar <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Inspired from these, we use available additional information to pair sentences as similar or not. If not available, we use round-trip translation (RTT) to obtain the similar pairs and <span id="S3.SS2.SSS1.Px1.p2.1.2" class="ltx_text ltx_font_italic">greedy sentence matching</span> for the less similar pairs.</p>
</div>
<div id="S3.SS2.SSS1.Px1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.Px1.p3.1" class="ltx_p">We specify the strategy for PARAKQC where the intent of each sentence is available. All sentences are queries for a smart home domain and their intent are shared among some queries. For example, “<span id="S3.SS2.SSS1.Px1.p3.1.1" class="ltx_text ltx_font_italic">How’s the weather today in Seoul?</span>” and “<span id="S3.SS2.SSS1.Px1.p3.1.2" class="ltx_text ltx_font_italic">You know what the weather is like in Seoul today?</span>” share the same intent which is asking “The weather of Seoul today”. We pair two sentences with the same intent as similar pairs and different intent as the less similar. Note that even the less similar pairs share topic to avoid making too many mutually dissimilar pairs.</p>
</div>
<div id="S3.SS2.SSS1.Px1.p4" class="ltx_para">
<p id="S3.SS2.SSS1.Px1.p4.1" class="ltx_p">For AIRBNB and POLICY, we cannot find meaningful metadata to estimate similarity between sentences. So we adopt RTT technique using NAVER Papago<span id="footnote20" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span><a target="_blank" href="https://papago.naver.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://papago.naver.com/</a></span></span></span> to generate the similar sentence pairs, since RTT is known to yield sentences with slightly different lexical representation while preserving the core meaning of the original sentence. We set English as an intermediate language. We choose a honorific option when translating back to Korean because the option tends to preserve the meaning of the sentences empirically. For less similar pairs, we first compute ROUGE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> of all possible sentence pairs, by assuming the higher score correlates with higher semantic similarity.<span id="footnote21" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">21</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">21</sup><span class="ltx_tag ltx_tag_note">21</span>This might be replaced to any other similarity measures.</span></span></span> Then we draw a pair with the largest score from all possible pairs and the draw is repeated over remaining pairs until all of sentences are matched. As it progresses, the score declines as the number of remaining pairs becomes smaller, producing less similar pairs. We summarize this process as <span id="S3.SS2.SSS1.Px1.p4.1.1" class="ltx_text ltx_font_italic">greedy sentence matching</span> (GSM), as presented in Algorithm&nbsp;<a href="#algorithm1" title="In Source Corpora ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="algorithm1" class="ltx_float ltx_algorithm">
<div id="algorithm1.2" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="algorithm1.2.3" class="ltx_listingline">
<span id="algorithm1.2.3.1" class="ltx_text"><span id="algorithm1.2.3.1.1" class="ltx_text ltx_font_bold">Result:</span> </span>Set of sentence pairs SET in a corpus C
</div>
<div id="algorithm1.2.4" class="ltx_listingline">
Prepare corpus C, Let SET = [];
</div>
<div id="algorithm1.1.1" class="ltx_listingline">
<span id="algorithm1.1.1.2" class="ltx_text ltx_font_bold">while</span>&nbsp;<em id="algorithm1.1.1.1" class="ltx_emph ltx_font_italic">size of C <math id="algorithm1.1.1.1.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="algorithm1.1.1.1.m1.1a"><mo id="algorithm1.1.1.1.m1.1.1" xref="algorithm1.1.1.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.1.m1.1b"><geq id="algorithm1.1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.1.m1.1c">\geq</annotation></semantics></math> 2</em>&nbsp;<span id="algorithm1.1.1.3" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="algorithm1.2.5" class="ltx_listingline">&nbsp;&nbsp;<span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;">&nbsp;</span>&nbsp;&nbsp;&nbsp;
1. Choose a random sentence S from C;
</div>
<div id="algorithm1.2.2" class="ltx_listingline">&nbsp;&nbsp;<span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;">&nbsp;</span>&nbsp;&nbsp;&nbsp;
2. Find a sentence T where ROUGE(S, T) is maximized and T <math id="algorithm1.2.2.m1.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="algorithm1.2.2.m1.1a"><mo id="algorithm1.2.2.m1.1.1" xref="algorithm1.2.2.m1.1.1.cmml">∈</mo><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.m1.1b"><in id="algorithm1.2.2.m1.1.1.cmml" xref="algorithm1.2.2.m1.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.m1.1c">\in</annotation></semantics></math> C\{S};
</div>
<div id="algorithm1.2.6" class="ltx_listingline">&nbsp;&nbsp;<span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;">&nbsp;</span>&nbsp;&nbsp;&nbsp;
3. Remove {S, T} from C;
</div>
<div id="algorithm1.2.7" class="ltx_listingline">&nbsp;&nbsp;<span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;">&nbsp;</span>&nbsp;&nbsp;&nbsp;
4. Add matched pair {(S, T)} to SET

</div>
<div id="algorithm1.2.8" class="ltx_listingline"> end while
</div>
<div id="algorithm1.2.9" class="ltx_listingline">

</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="algorithm1.4.1.1" class="ltx_text ltx_font_bold">Algorithm&nbsp;1</span> </span>Pseudocode of our greedy sentence matching (GSM) in AIRBNB and POLICY.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS2.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS1.Px2.p1.1" class="ltx_p">We modify the original annotation guide used in SemEval-2015 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. It suggests chunking both sentences and compares similarity in chunk-level (e.g., NP, verb chain, PP, etc.). Then an annotator should sum up their judgement to sentence-level similarity. However, we could not directly apply the guide because chunking is highly challenging in Korean. In chunking, tokenization and morpheme-level decomposition of words are required, but they are difficult and even not deterministic in some cases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>.
We thus guide an annotator to evaluate the similarity without chunking and stick to sentence-level comparison.</p>
</div>
<div id="S3.SS2.SSS1.Px2.p2" class="ltx_para">
<p id="S3.SS2.SSS1.Px2.p2.1" class="ltx_p">We give crowdworkers additional cues what is <span id="S3.SS2.SSS1.Px2.p2.1.1" class="ltx_text ltx_font_italic">important</span> or <span id="S3.SS2.SSS1.Px2.p2.1.2" class="ltx_text ltx_font_italic">unimportant</span> for sentence-level similarity evaluation. <span id="S3.SS2.SSS1.Px2.p2.1.3" class="ltx_text ltx_font_italic">Important</span> content indicates the main idea in a sentence. If it is a declarative sentence, its providing facts, explanation, or information is the main idea. For an interrogative and imperative sentence, conveying a request or command is important. In exclamatory sentence, feelings or opinion is the main content <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Other components than these <span id="S3.SS2.SSS1.Px2.p2.1.4" class="ltx_text ltx_font_italic">important</span> contents are regarded as <span id="S3.SS2.SSS1.Px2.p2.1.5" class="ltx_text ltx_font_italic">unimportant</span>. For example, they are auxiliary verbs or function words which affect its nuance or politeness. An annotator should score the similarity as follows:</p>
</div>
<div id="S3.SS2.SSS1.Px2.p3" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">5: Two sentences are equivalent in terms of <span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">important</span> and <span id="S3.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">unimportant</span> content.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">4: Two sentences are closely equivalent. Some <span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">unimportant</span> content differ.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">3: Two sentences are roughly equivalent. <span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Important</span> content are similar to each other, but difference between <span id="S3.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">unimportant</span> content is not ignorable.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">2: Two sentences are not equivalent. <span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">Important</span> content are not similar to each other, only sharing some <span id="S3.I1.i4.p1.1.2" class="ltx_text ltx_font_italic">unimportant</span> contents.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p">1: Two sentences are not equivalent. <span id="S3.I1.i5.p1.1.1" class="ltx_text ltx_font_italic">Important</span> and <span id="S3.I1.i5.p1.1.2" class="ltx_text ltx_font_italic">unimportant</span> content are not similar to each other. Two sentences only share their topics.</p>
</div>
</li>
<li id="S3.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i6.p1" class="ltx_para">
<p id="S3.I1.i6.p1.1" class="ltx_p">0: Two sentences are not equivalent. They are not sharing any <span id="S3.I1.i6.p1.1.1" class="ltx_text ltx_font_italic">important</span> and <span id="S3.I1.i6.p1.1.2" class="ltx_text ltx_font_italic">unimportant</span> contents and even topics.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS1.Px2.p4" class="ltx_para">
<p id="S3.SS2.SSS1.Px2.p4.1" class="ltx_p">We also guide crowdworkers to consider the context of sentences. If it significantly affects distinguishing the meaning of two sentences, the score should be low. For example, let two sentences contain important information ‘check-in’ such as “Check-in was done by someone other than the host.” and “Check-in was done by someone.” In the latter sentence, ‘someone’ might be the host. Since we lose information by dropping ‘other than the host’ from the former, difference of meaning between the two sentence is not ignorable. We score this pair to 3. Furthermore, if the former sentence is compared to ‘Check-out was done by someone other than the host.’, <span id="S3.SS2.SSS1.Px2.p4.1.1" class="ltx_text ltx_font_italic">important</span> information differ so we give score 2.</p>
</div>
</section>
<section id="S3.SS2.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS2.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS1.Px3.p1.1" class="ltx_p">We recruit workers from SelectStar,<span id="footnote22" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">22</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">22</sup><span class="ltx_tag ltx_tag_note">22</span><a target="_blank" href="https://selectstar.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://selectstar.ai/</a></span></span></span> a crowdsourcing platform in Korea and familiarize them to our annotation protocol. We run pilot annotation to select qualified workers. If a crowdworker’s judgement is frequently disagreed against that of other workers, the person is excluded from the main annotation process. As a result, 19 out of the initial 20 workers participate in the main annotation. After removing the sentence pairs used in the pilot, we use 14,869 pairs for the main annotation, consisting of 7,375 for AIRBNB, 2,956 for POLICY, and 4,538 for PARAKQC. 7 different workers labeled all sentence pairs independently.</p>
</div>
<div id="S3.SS2.SSS1.Px3.p2" class="ltx_para">
<p id="S3.SS2.SSS1.Px3.p2.1" class="ltx_p">We average 7 labels for each sentence pair and remove outliers following <cite class="ltx_cite ltx_citemacro_citet">Agirre et&nbsp;al. [<a href="#bib.bib3" title="" class="ltx_ref">3</a>], Cer et&nbsp;al. [<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. First, we filter out annotators showing Pearson’s correlation &lt; 0.80 or Krippendorff’s alpha &lt; 0.20 (nominal) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> with others’ annotations. We exclude two annotators with this criteria so all sentence pairs have annotations from at least five people. Lastly, similarity score is rounded up to the first decimal place.</p>
</div>
<div id="S3.SS2.SSS1.Px3.p3" class="ltx_para">
<p id="S3.SS2.SSS1.Px3.p3.1" class="ltx_p">A few more filtering schemes are applied. First, we drop 14 pairs whose annotations are showing larger than 2 standard deviation. Those pairs might contain ambiguous expressions interpreted in various ways, or misannotations. Second, we ask workers to report the sentences including translation error or misinformation caused by RTT. We inspect the reported sentences and remove 418 sentence pairs. Third, we drop sentences involving ethical issues. Workers report the pairs if they are including any kind of hate speech, social bias, and potential personally identifiable information (PII). 1,213 sentence pairs were additionally removed after inspection. As a result, we have 13,224 sentence pairs in total. We report inter-annotator agreement (IAA) by using Krippendorff’s alpha instead of Pearson’s correlation because 7 annotators (or less) differ by pairs. The annotator agreed to each other’s annotations. (Krippendorff’s alpha (interval) = 0.85).</p>
</div>
<div id="S3.SS2.SSS1.Px3.p4" class="ltx_para">
<p id="S3.SS2.SSS1.Px3.p4.1" class="ltx_p">We observe the distribution of similarity score annotations differ between the <span id="S3.SS2.SSS1.Px3.p4.1.1" class="ltx_text ltx_font_italic">potentially</span> similar sentence pairs and the less similar pairs. Figure <a href="#S3.F1" title="Figure 1 ‣ Annotation Process ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates label distributions generated by RTT (top) and GSM (bottom) in AIRBNB. As expected, RTT pairs tend to show high similarity (from 3 to 5) while GSM pairs are considered less similar (from 0 to 3). Note that the number of GSM pairs scored 0 is high even we employ similarity-based matching. Similar tendencies are observed in POLICY and PARAKQC. By combining two distributions, we manage to obtain various sentence pairs in terms of similarity scores.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2105.09680/assets/figs/sts-fig2.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="208" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Label distributions generated by RTT (top) and GSM (bottom) in AIRBNB.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS2.SSS1.Px4.p1" class="ltx_para">
<p id="S3.SS2.SSS1.Px4.p1.2" class="ltx_p">We collect 13,224 sentence pairs and corresponding similarity scores. We split them to training, development, and test sets, considering the distribution of the scores. Even if we carefully sampled the pairs, the overall score distribution is not uniform across 0<math id="S3.SS2.SSS1.Px4.p1.1.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S3.SS2.SSS1.Px4.p1.1.m1.1a"><mo id="S3.SS2.SSS1.Px4.p1.1.m1.1.1" xref="S3.SS2.SSS1.Px4.p1.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.Px4.p1.1.m1.1b"><minus id="S3.SS2.SSS1.Px4.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.Px4.p1.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.Px4.p1.1.m1.1c">-</annotation></semantics></math>5 as shown in Figure <a href="#S3.F1" title="Figure 1 ‣ Annotation Process ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. However, we prefer uniform distribution at least in evaluation (development and test) set, in order to prevent evaluation bias toward a specific score. We therefore construct the evaluation set having approximately uniform distribution as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ Final Dataset ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. To this end, we divide the score range 0<math id="S3.SS2.SSS1.Px4.p1.2.m2.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S3.SS2.SSS1.Px4.p1.2.m2.1a"><mo id="S3.SS2.SSS1.Px4.p1.2.m2.1.1" xref="S3.SS2.SSS1.Px4.p1.2.m2.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.Px4.p1.2.m2.1b"><minus id="S3.SS2.SSS1.Px4.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS1.Px4.p1.2.m2.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.Px4.p1.2.m2.1c">-</annotation></semantics></math>5 to 51 bins, rounding up to the first decimal place of every scores. We try to balance the number of pairs across bins. Since some of them have small number of pairs, we try to fit all number of the pairs close to that number.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2105.09680/assets/figs/sts-fig1.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="204" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Similarity score distribution of the train (top) and dev (bottom) set. The scores of dev set is close to uniform distribution across range 0<math id="S3.F2.2.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S3.F2.2.m1.1b"><mo id="S3.F2.2.m1.1.1" xref="S3.F2.2.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S3.F2.2.m1.1c"><minus id="S3.F2.2.m1.1.1.cmml" xref="S3.F2.2.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.m1.1d">-</annotation></semantics></math>5. The scores are rounded to the first decimal place.</figcaption>
</figure>
<div id="S3.SS2.SSS1.Px4.p2" class="ltx_para">
<p id="S3.SS2.SSS1.Px4.p2.1" class="ltx_p">We also consider word overlap between sentences in each pair for evaluation set. Since larger word overlap might indicate higher semantic similarity, we try to reduce pairs satisfying such tendency to prevent the model from predicting similarity simply using word overlap. The overlap is measured by morpheme-level Jaccard distance by using MeCab <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>. We choose the pairs with the least word overlap from score 3<math id="S3.SS2.SSS1.Px4.p2.1.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S3.SS2.SSS1.Px4.p2.1.m1.1a"><mo id="S3.SS2.SSS1.Px4.p2.1.m1.1.1" xref="S3.SS2.SSS1.Px4.p2.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.Px4.p2.1.m1.1b"><minus id="S3.SS2.SSS1.Px4.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS1.Px4.p2.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.Px4.p2.1.m1.1c">-</annotation></semantics></math>5, and the pairs with most word overlap from the rest. Such pairs are prioritized to be included to every bins in the dev and the test sets.</p>
</div>
<div id="S3.SS2.SSS1.Px4.p3" class="ltx_para">
<p id="S3.SS2.SSS1.Px4.p3.1" class="ltx_p">We split the evaluation set with 1:2 ratio to construct the dev and the test sets, resulting in 519 and 1,037 pairs, respectively. The rest 11,668 pairs comprise the train set. Detailed numbers for each corpus are presented in Table <a href="#S3.T4" title="Table 4 ‣ Final Dataset ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. For all the sets, we balance the ratio between source corpora with that of the original pairs. Additionally, the scores are binarized with a threshold 3.0 same as paraphrase detection task.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Statistics for KLUE-STS. The first three columns provide the number of examples in train, dev, and test sets of each source corpus and the final data.</figcaption>
<table id="S3.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T4.1.1" class="ltx_tr">
<td id="S3.T4.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T4.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T4.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T4.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T4.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T4.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T4.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T4.1.2" class="ltx_tr">
<td id="S3.T4.1.2.1" class="ltx_td ltx_align_left ltx_border_t">AIRBNB</td>
<td id="S3.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">5,371</td>
<td id="S3.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_t">255</td>
<td id="S3.T4.1.2.4" class="ltx_td ltx_align_center ltx_border_t">510</td>
<td id="S3.T4.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">6,136</td>
</tr>
<tr id="S3.T4.1.3" class="ltx_tr">
<td id="S3.T4.1.3.1" class="ltx_td ltx_align_left">POLICY</td>
<td id="S3.T4.1.3.2" class="ltx_td ltx_align_center">2,344</td>
<td id="S3.T4.1.3.3" class="ltx_td ltx_align_center">132</td>
<td id="S3.T4.1.3.4" class="ltx_td ltx_align_center">264</td>
<td id="S3.T4.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">2,740</td>
</tr>
<tr id="S3.T4.1.4" class="ltx_tr">
<td id="S3.T4.1.4.1" class="ltx_td ltx_align_left">PARAKQC</td>
<td id="S3.T4.1.4.2" class="ltx_td ltx_align_center">3,953</td>
<td id="S3.T4.1.4.3" class="ltx_td ltx_align_center">132</td>
<td id="S3.T4.1.4.4" class="ltx_td ltx_align_center">263</td>
<td id="S3.T4.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center">4,348</td>
</tr>
<tr id="S3.T4.1.5" class="ltx_tr">
<td id="S3.T4.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.1.1" class="ltx_text ltx_font_bold">Overall</span></td>
<td id="S3.T4.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.2.1" class="ltx_text ltx_font_bold">11,668</span></td>
<td id="S3.T4.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.3.1" class="ltx_text ltx_font_bold">519</span></td>
<td id="S3.T4.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.4.1" class="ltx_text ltx_font_bold">1,037</span></td>
<td id="S3.T4.1.5.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.5.1" class="ltx_text ltx_font_bold">13,224</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Evaluation Metrics</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.2" class="ltx_p">The evaluation metrics for KLUE-STS is 1) Pearson’s correlation coefficient (Pearson’ <math id="S3.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mi id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><ci id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">r</annotation></semantics></math>), and 2) F1 score. Pearson’s <math id="S3.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><mi id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><ci id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">r</annotation></semantics></math> is a measure of linear correlation between human-labeled sentence-similarity scores and model predicted scores, adopted in STS-b <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Since our dev and test set have a balanced score distribution, the coefficient correctly gives the magnitude of the relationship. F1 score is adopted to measure binarized results (<span id="S3.SS2.SSS2.p1.2.1" class="ltx_text ltx_font_italic">paraphrased</span> / <span id="S3.SS2.SSS2.p1.2.2" class="ltx_text ltx_font_italic">not paraphrased</span>). Specifically, our F1 reports results for the <span id="S3.SS2.SSS2.p1.2.3" class="ltx_text ltx_font_italic">paraphrased</span> class.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Related Work</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">Measuring similarity between sentences is a fundamental natural language understanding problem so that closely related to various NLP applications. Because of its importance, STS is included in various NLU benchmarks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>, <a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>. To facilitate research in this area, many shared tasks have been held and annotated corpora are released <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Typically, they cover multiple text domains such as question pairs, image descriptions, news headlines, annotated with a real value from 0 (no meaning overlap) to 5 (meaning equivalence).</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p id="S3.SS2.SSS3.p2.1" class="ltx_p">Recently, <cite class="ltx_cite ltx_citemacro_citet">Ham et&nbsp;al. [<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> introduces a machine-translated Korean STS benchmark. This is a translation of <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> in GLUE, which contains around 8,600 sentence pairs in total. All examples are solely relying on machine translation, and sentence pairs in evaluation (dev and test) set are further post-edited by human. However, corresponding labels were not adjusted to translated meanings. Lack of re-labeling process would be problematic because Korean speakers would judge the similarity between them differently.</p>
</div>
<div id="S3.SS2.SSS3.p3" class="ltx_para">
<p id="S3.SS2.SSS3.p3.1" class="ltx_p">If similarity labels are binarized by a certain threshold, STS also could be seen as paraphrase detection task such as Microsoft Research Paraphrase Corpus (MRPC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, Quora Question Pairs (QQP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>, or PAWS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite> and PAWS-X <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite>. Thus we additionally binarize our ground truths and predictions, reporting binary classification performance to see how well a model performs in paraphrase detection.</p>
</div>
<div id="S3.SS2.SSS3.p4" class="ltx_para">
<p id="S3.SS2.SSS3.p4.1" class="ltx_p">In paraphrase detection, <cite class="ltx_cite ltx_citemacro_citet">Cho et&nbsp;al. [<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> presents a benchmark that includes the human-generated queries for smart home, where ten paraphrase sentences are grouped together to make up a total of 1,000 groups. The granularity of scale is from 0 to 5, but the semantic similarity is judged only with attributes such as topic (smart home, weather, etc.) and speech act (question, prohibition, etc.), which does not consider other details such as nuance and syntactic structure because it lacks direct human judgement of similarity. PAWS-X <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite> provides a translated version of PAWS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite> of Korean. Like KorSTS, the train split is machine-translated and its dev and test splits are human-translated, and corresponding labels are preserved without human inspection. There are also paraphrase corpora provided by government-funded institutions such as National Institute of Korean Language (NIKL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>, but it simply provides human-generated and machine-paraphrased sentences with limited accessibility.</p>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>Conclusion</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p">We create the first human-annotated Korean STS benchmark, KLUE-STS, that covers multiple domains and styles with free accessibility to everyone. The similarity score annotation process is specially designed to capture the characteristics of the Korean language. Covering the expressions from various domains, our benchmark is expected to be a useful resource for further research, beyond serving as a benchmark. Our benchmark helps to develop numerous models established on STS resources, such as SentenceBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Natural Language Inference (NLI)</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The goal of natural language inference (NLI) is to train a model to infer the relationship between the <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">hypothesis</span> sentence and the <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_italic">premise</span> sentence. Given a <span id="S3.SS3.p1.1.3" class="ltx_text ltx_font_italic">premise</span>, an NLI model determines if <span id="S3.SS3.p1.1.4" class="ltx_text ltx_font_italic">hypothesis</span> is true (entailment), false (contradiction), or undetermined (neutral). The task is also known as recognizing textual entailment (RTE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Understanding entailment and contradiction between sentences is fundamental to NLU. NLI datasets are also included in various NLU benchmarks such as GLUE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> and superGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite>, and they are valuable as training data for other NLU tasks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib107" title="" class="ltx_ref">107</a>, <a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">We formulate NLI as a classification task where an NLI model reads each pair of <span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_italic">premise</span> and <span id="S3.SS3.p3.1.2" class="ltx_text ltx_font_italic">hypothesis</span> sentences and predicts whether the relationship is entailment, contradiction, or neutral. We use the classification accuracy to measure the model performance.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Dataset Construction</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">We construct KLUE-NLI by using a collection method similar to that of SNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>. First, we collect premise sentences from existing corpora. Then for each premise sentence, we ask one annotator to generate three new hypothesis sentences, one for each of the three relationship classes. Then for each pair of premise and hypothesis sentences, we ask four additional annotators to label the relationship for validation. We follow the criteria proposed by <cite class="ltx_cite ltx_citemacro_citet">Williams et&nbsp;al. [<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite> to describe the three labels to the annotators. For both hypothesis generation and pair validation, we recruit workers from SelectStar,<span id="footnote23" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">23</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">23</sup><span class="ltx_tag ltx_tag_note">23</span><a target="_blank" href="https://selectstar.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://selectstar.ai/</a></span></span></span> a Korean crowdsourcing platform.</p>
</div>
<section id="S3.SS3.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora for Premise Sentences</h5>

<div id="S3.SS3.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.Px1.p1.1" class="ltx_p">We use six corpora for the set of premise sentences: WIKITREE, POLICY, WIKINEWS, WIKIPEDIA, NSMC and AIRBNB. They cover diverse topics and writing styles of contemporary Korean. WIKITREE, POLICY and WIKINEWS are news articles and WIKIPEDIA is a crowd-sourced encyclopedia, all of which are written in formal Korean. NSMC and AIRBNB consist of colloquial reviews in the domains of movies and travel, respectively.</p>
</div>
<div id="S3.SS3.SSS1.Px1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.Px1.p2.1" class="ltx_p">From the six corpora, we extract 10,000 premises with which we elicit hypotheses. A valid premise should satisfy three conditions. First, premise is a proposition, a declarative sentence to which we can assign a truth value, excluding mathematical formulae and lists. Second, a premise must include at least one predicate, and the predicate can be of diverse types such as states (e.g., be, believe, know), activities (e.g., play, smile, walk), achievements (e.g. realize, reach, break), and accomplishments (e.g. eat, build, paint). Third, the length of a premise should be from 20 to 90 characters including whitespace.</p>
</div>
</section>
<section id="S3.SS3.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol for Hypothesis Generation</h5>

<div id="S3.SS3.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS1.Px2.p1.1" class="ltx_p">We show annotators a premise and ask them to write three hypotheses that correspond to each label. This allows us to collect nearly equal number of the (premise, hypothesis) pairs for each labels. We maintain the outline of the criteria as follows:</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">ENTAILMENT: The hypothesis is necessarily true given the premise is true</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">CONTRADICTION: The hypothesis is necessarily false given the premise is true</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p">NEUTRAL: The hypothesis may or may not be true given the premise is true</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS1.Px2.p2" class="ltx_para">
<p id="S3.SS3.SSS1.Px2.p2.1" class="ltx_p">We are aware of the annotation artifacts coming from human writing-based hypothesis generation. Sentence length and explicit lexical patterns are highly associated with certain classes. Neutral sentences tend to be the longest among all classes, since workers can produce neutral hypothesis simply by introducing additional phrase or clause not stated in the premise. Negations such as “no”, “never” and “nothing” are often accompanied with the class CONTRADICTION <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>.</p>
</div>
<div id="S3.SS3.SSS1.Px2.p3" class="ltx_para">
<p id="S3.SS3.SSS1.Px2.p3.1" class="ltx_p">Despite the concerns of such artifacts, we stick to such a writing-based annotation procedure.
Compared to automatic pipelines to collect hypotheses, human writing yields higher quality data and is still an effective protocol <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite>. We focus on ways to encourage annotators to avoid injecting trivial patterns. We prepare guidelines with specific <span id="S3.SS3.SSS1.Px2.p3.1.1" class="ltx_text ltx_font_italic">Do</span>s and <span id="S3.SS3.SSS1.Px2.p3.1.2" class="ltx_text ltx_font_italic">Don’t</span>s, and rigorously train the workers in advance.
To minimize annotation artifacts, we instruct the annotators to write sentences with similar lengths across the classes, refrain from inserting certain lexical items repeatedly, and use as diverse strategies as possible when making inferences.</p>
</div>
<div id="S3.SS3.SSS1.Px2.p4" class="ltx_para">
<p id="S3.SS3.SSS1.Px2.p4.1" class="ltx_p">Specifically, we provide detailed guidelines for hypothesis generation together with examples. We encourage annotators to create hypotheses that exhibit diverse linguistic phenomena, in terms of 1) lexical choice, 2) syntactic structures and 3) world knowledge. In the case of lexical choice, our guideline suggests annotators use synonyms/antonyms, hypernyms/hyponyms, and auxiliary particles. To introduce various syntactic structures, we provide several syntactic transformation strategies such as word scrambling, voice alteration, and causative alternation. Methods like subject/object swapping or passivization is motivated by existing NLI data augmentation strategies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. We also encourage using expressions that reflect world knowledge such as time, quantity and geography in order to create a dataset grounded to the real world.</p>
</div>
<div id="S3.SS3.SSS1.Px2.p5" class="ltx_para">
<p id="S3.SS3.SSS1.Px2.p5.1" class="ltx_p">There are a few more details in the guideline. We instruct annotators to maintain the writing style of the premise to create a balanced dataset in terms of the style as well. We also instruct them to skip sentences that are difficult to understand either due to the ungrammaticality or the complexity of the content. They are also instructed to skip and report sentences that contain ethical issues such as hate speech, social bias, or personally identifiable information. We examine all reported sentences and make final decisions whether to include the sentences in the dataset.</p>
</div>
</section>
<section id="S3.SS3.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol for Label Validation</h5>

<div id="S3.SS3.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS3.SSS1.Px3.p1.1" class="ltx_p">Crowdworkers annotate the relations of the resulting premise-hypothesis pairs for validation. For each of the pairs created, we ask four crowdworkers to supply a single label among (ENTAILMENT, CONTRADICTION, NEUTRAL). This yields a total of five labels per pair, including the initial label intended by the annotator who wrote the hypothesis sentence. For each validated sentence pair, we assign a gold label representing the majority of three or more votes out of five.</p>
</div>
</section>
<section id="S3.SS3.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS3.SSS1.Px4.p1" class="ltx_para">
<p id="S3.SS3.SSS1.Px4.p1.1" class="ltx_p">For hypothesis generation, we go through a pilot phase where we iteratively update the guidelines and train the workers. During the pilot, we find writing a semantically unacceptable sentence or introducing a demonstrative pronoun not used in the premise could be potential problems. Since they might alter the intended label, we ask workers to avoid writing such sentences. The number of workers for this part of the annotation process is 11.</p>
</div>
<div id="S3.SS3.SSS1.Px4.p2" class="ltx_para">
<p id="S3.SS3.SSS1.Px4.p2.1" class="ltx_p">We then validate the relation labels for every pair. We go through a pilot phase, starting with 2,604 applicants in the pilot, then select 684 who passed the test to participate in the validation step. With 138 workers dropping out, the final number of workers is 546.</p>
</div>
<div id="S3.SS3.SSS1.Px4.p3" class="ltx_para">
<p id="S3.SS3.SSS1.Px4.p3.1" class="ltx_p">Validation results are summarized in Table <a href="#S3.T5" title="Table 5 ‣ Annotation Process ‣ 3.3.1 Dataset Construction ‣ 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. They suggest that our writing protocol is effective in producing a high quality corpus. The rate of unanimous gold labeled examples in KLUE-NLI is 18% higher than SNLI and MNLI. The higher the rate of such examples, the clearer the relationship between the generated hypothesis sentences and the original premise sentences. Individual annotator’s agreement with the gold label and the author’s label are also higher than SNLI and MNLI, and almost all pairs receive the gold label. Only a few sentence pairs (0.53%) lack the gold label, and we remove those before finalizing our dataset.</p>
</div>
<figure id="S3.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Summary of validation statistics for KLUE-NLI compared to SNLI and MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>. We call the label intended by the original annotator in writing the hypothesis "author’s label." Consensus among three out of five annotators is "gold label."</figcaption>
<table id="S3.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T5.1.2" class="ltx_tr">
<td id="S3.T5.1.2.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T5.1.2.1.1" class="ltx_text ltx_font_bold">Statistics</span></td>
<td id="S3.T5.1.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T5.1.2.2.1" class="ltx_text ltx_font_bold">SNLI</span></td>
<td id="S3.T5.1.2.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T5.1.2.3.1" class="ltx_text ltx_font_bold">MNLI</span></td>
<td id="S3.T5.1.2.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T5.1.2.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></td>
</tr>
<tr id="S3.T5.1.3" class="ltx_tr">
<td id="S3.T5.1.3.1" class="ltx_td ltx_align_left ltx_border_t">Unanimous Gold Label</td>
<td id="S3.T5.1.3.2" class="ltx_td ltx_align_center ltx_border_t">58.30%</td>
<td id="S3.T5.1.3.3" class="ltx_td ltx_align_center ltx_border_t">58.20%</td>
<td id="S3.T5.1.3.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T5.1.3.4.1" class="ltx_text ltx_font_bold">76.29%</span></td>
</tr>
<tr id="S3.T5.1.4" class="ltx_tr">
<td id="S3.T5.1.4.1" class="ltx_td ltx_align_left ltx_border_t">Individual Label = Gold Label</td>
<td id="S3.T5.1.4.2" class="ltx_td ltx_align_center ltx_border_t">89.00%</td>
<td id="S3.T5.1.4.3" class="ltx_td ltx_align_center ltx_border_t">88.70%</td>
<td id="S3.T5.1.4.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T5.1.4.4.1" class="ltx_text ltx_font_bold">92.63%</span></td>
</tr>
<tr id="S3.T5.1.5" class="ltx_tr">
<td id="S3.T5.1.5.1" class="ltx_td ltx_align_left">Individual Label = Author’s Label</td>
<td id="S3.T5.1.5.2" class="ltx_td ltx_align_center">85.80%</td>
<td id="S3.T5.1.5.3" class="ltx_td ltx_align_center">85.20%</td>
<td id="S3.T5.1.5.4" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T5.1.5.4.1" class="ltx_text ltx_font_bold">90.92%</span></td>
</tr>
<tr id="S3.T5.1.6" class="ltx_tr">
<td id="S3.T5.1.6.1" class="ltx_td ltx_align_left ltx_border_t">Gold Label = Author’s Label</td>
<td id="S3.T5.1.6.2" class="ltx_td ltx_align_center ltx_border_t">91.20%</td>
<td id="S3.T5.1.6.3" class="ltx_td ltx_align_center ltx_border_t">92.60%</td>
<td id="S3.T5.1.6.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T5.1.6.4.1" class="ltx_text ltx_font_bold">96.76%</span></td>
</tr>
<tr id="S3.T5.1.1" class="ltx_tr">
<td id="S3.T5.1.1.1" class="ltx_td ltx_align_left">Gold Label <math id="S3.T5.1.1.1.m1.1" class="ltx_Math" alttext="\neq" display="inline"><semantics id="S3.T5.1.1.1.m1.1a"><mo id="S3.T5.1.1.1.m1.1.1" xref="S3.T5.1.1.1.m1.1.1.cmml">≠</mo><annotation-xml encoding="MathML-Content" id="S3.T5.1.1.1.m1.1b"><neq id="S3.T5.1.1.1.m1.1.1.cmml" xref="S3.T5.1.1.1.m1.1.1"></neq></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.1.1.1.m1.1c">\neq</annotation></semantics></math> Author’s Label</td>
<td id="S3.T5.1.1.2" class="ltx_td ltx_align_center">6.80%</td>
<td id="S3.T5.1.1.3" class="ltx_td ltx_align_center">5.60%</td>
<td id="S3.T5.1.1.4" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T5.1.1.4.1" class="ltx_text ltx_font_bold">2.71%</span></td>
</tr>
<tr id="S3.T5.1.7" class="ltx_tr">
<td id="S3.T5.1.7.1" class="ltx_td ltx_align_left ltx_border_bb">No Gold Label (No 3 Labels Match)</td>
<td id="S3.T5.1.7.2" class="ltx_td ltx_align_center ltx_border_bb">2.00%</td>
<td id="S3.T5.1.7.3" class="ltx_td ltx_align_center ltx_border_bb">1.80%</td>
<td id="S3.T5.1.7.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S3.T5.1.7.4.1" class="ltx_text ltx_font_bold">0.53%</span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS3.SSS1.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS3.SSS1.Px5.p1" class="ltx_para">
<p id="S3.SS3.SSS1.Px5.p1.1" class="ltx_p">The final dataset consists of 30,998 sentence pairs that are divided into train/development/test sets. Table&nbsp;<a href="#S3.T6" title="Table 6 ‣ Final Dataset ‣ 3.3.1 Dataset Construction ‣ 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the basic statistics of the dataset. As observed in SNLI and MNLI, our premise sentences also tend to be longer than the corresponding hypothesis sentences. This is because workers generally use partial information of a premise to write a hypothesis.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p2" class="ltx_para">
<p id="S3.SS3.SSS1.Px5.p2.1" class="ltx_p">Note that we deliberately form the development and test sets in a way to 1) contain balanced source styles and 2) disincentivize models exploiting annotation artifacts. The development and the test set each contains 3,000 sentence pairs.</p>
</div>
<figure id="S3.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Statistics for KLUE-NLI. The first three columns provide the number of sentence pairs in train, dev, and test sets. <span id="S3.T6.3.1" class="ltx_text ltx_font_italic">Avg Len Prem</span> and <span id="S3.T6.4.2" class="ltx_text ltx_font_italic">Avg Len Hyp</span> are the mean character counts of premise and hypothesis sentences, respectively.</figcaption>
<table id="S3.T6.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T6.5.1" class="ltx_tr">
<td id="S3.T6.5.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T6.5.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T6.5.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T6.5.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T6.5.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T6.5.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T6.5.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.6.1" class="ltx_text ltx_font_bold">Avg Len Prem</span></td>
<td id="S3.T6.5.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.7.1" class="ltx_text ltx_font_bold">Avg Len Hyp</span></td>
</tr>
<tr id="S3.T6.5.2" class="ltx_tr">
<td id="S3.T6.5.2.1" class="ltx_td ltx_align_left ltx_border_t">WIKITREE</td>
<td id="S3.T6.5.2.2" class="ltx_td ltx_align_center ltx_border_t">3,838</td>
<td id="S3.T6.5.2.3" class="ltx_td ltx_align_center ltx_border_t">450</td>
<td id="S3.T6.5.2.4" class="ltx_td ltx_align_center ltx_border_t">450</td>
<td id="S3.T6.5.2.5" class="ltx_td ltx_align_center ltx_border_t">4,738</td>
<td id="S3.T6.5.2.6" class="ltx_td ltx_align_center ltx_border_t">52.81</td>
<td id="S3.T6.5.2.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">26.86</td>
</tr>
<tr id="S3.T6.5.3" class="ltx_tr">
<td id="S3.T6.5.3.1" class="ltx_td ltx_align_left">POLICY</td>
<td id="S3.T6.5.3.2" class="ltx_td ltx_align_center">3,833</td>
<td id="S3.T6.5.3.3" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.3.4" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.3.5" class="ltx_td ltx_align_center">4,733</td>
<td id="S3.T6.5.3.6" class="ltx_td ltx_align_center">56.73</td>
<td id="S3.T6.5.3.7" class="ltx_td ltx_nopad_r ltx_align_center">32.93</td>
</tr>
<tr id="S3.T6.5.4" class="ltx_tr">
<td id="S3.T6.5.4.1" class="ltx_td ltx_align_left">WIKINEWS</td>
<td id="S3.T6.5.4.2" class="ltx_td ltx_align_center">3,824</td>
<td id="S3.T6.5.4.3" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.4.4" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.4.5" class="ltx_td ltx_align_center">4,724</td>
<td id="S3.T6.5.4.6" class="ltx_td ltx_align_center">64.17</td>
<td id="S3.T6.5.4.7" class="ltx_td ltx_nopad_r ltx_align_center">29.11</td>
</tr>
<tr id="S3.T6.5.5" class="ltx_tr">
<td id="S3.T6.5.5.1" class="ltx_td ltx_align_left">WIKIPEDIA</td>
<td id="S3.T6.5.5.2" class="ltx_td ltx_align_center">3,780</td>
<td id="S3.T6.5.5.3" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.5.4" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.5.5" class="ltx_td ltx_align_center">4,680</td>
<td id="S3.T6.5.5.6" class="ltx_td ltx_align_center">57.45</td>
<td id="S3.T6.5.5.7" class="ltx_td ltx_nopad_r ltx_align_center">23.70</td>
</tr>
<tr id="S3.T6.5.6" class="ltx_tr">
<td id="S3.T6.5.6.1" class="ltx_td ltx_align_left ltx_border_t">NSMC</td>
<td id="S3.T6.5.6.2" class="ltx_td ltx_align_center ltx_border_t">4,899</td>
<td id="S3.T6.5.6.3" class="ltx_td ltx_align_center ltx_border_t">600</td>
<td id="S3.T6.5.6.4" class="ltx_td ltx_align_center ltx_border_t">600</td>
<td id="S3.T6.5.6.5" class="ltx_td ltx_align_center ltx_border_t">6,099</td>
<td id="S3.T6.5.6.6" class="ltx_td ltx_align_center ltx_border_t">27.48</td>
<td id="S3.T6.5.6.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">21.49</td>
</tr>
<tr id="S3.T6.5.7" class="ltx_tr">
<td id="S3.T6.5.7.1" class="ltx_td ltx_align_left">AIRBNB</td>
<td id="S3.T6.5.7.2" class="ltx_td ltx_align_center">4,824</td>
<td id="S3.T6.5.7.3" class="ltx_td ltx_align_center">600</td>
<td id="S3.T6.5.7.4" class="ltx_td ltx_align_center">600</td>
<td id="S3.T6.5.7.5" class="ltx_td ltx_align_center">6,024</td>
<td id="S3.T6.5.7.6" class="ltx_td ltx_align_center">24.28</td>
<td id="S3.T6.5.7.7" class="ltx_td ltx_nopad_r ltx_align_center">18.65</td>
</tr>
<tr id="S3.T6.5.8" class="ltx_tr">
<td id="S3.T6.5.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.1.1" class="ltx_text ltx_font_bold">Overall</span></td>
<td id="S3.T6.5.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.2.1" class="ltx_text ltx_font_bold">24,998</span></td>
<td id="S3.T6.5.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.3.1" class="ltx_text ltx_font_bold">3,000</span></td>
<td id="S3.T6.5.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.4.1" class="ltx_text ltx_font_bold">3,000</span></td>
<td id="S3.T6.5.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.5.1" class="ltx_text ltx_font_bold">30,998</span></td>
<td id="S3.T6.5.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.6.1" class="ltx_text ltx_font_bold">47.15</span></td>
<td id="S3.T6.5.8.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.7.1" class="ltx_text ltx_font_bold">25.46</span></td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS3.SSS1.Px5.p3" class="ltx_para">
<p id="S3.SS3.SSS1.Px5.p3.1" class="ltx_p">To maintain consistency of style in development and test sets, we include in each set 60% formal and 40% colloquial sentences. We sample 450 sentences each from formal text WIKITREE, POLICY, WIKINEWS, WIKIPEDIA, and 600 sentences each from colloquial text NSMC, AIRBNB.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p4" class="ltx_para">
<p id="S3.SS3.SSS1.Px5.p4.1" class="ltx_p">To prevent our NLI benchmark from incentivizing a model that predicts a label using a spurious cue in the hypothesis, we first fine-tune the KLUE-RoBERTa-base model using only the hypothesis sentences with their corresponding labels. If the model finds no clue between the hypothesis and the label, the predicted probability scores for each label should be uniform (i.e., one-third (<math id="S3.SS3.SSS1.Px5.p4.1.m1.1" class="ltx_Math" alttext="\frac{1}{3}" display="inline"><semantics id="S3.SS3.SSS1.Px5.p4.1.m1.1a"><mfrac id="S3.SS3.SSS1.Px5.p4.1.m1.1.1" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.cmml"><mn id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.2" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.2.cmml">1</mn><mn id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.3" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px5.p4.1.m1.1b"><apply id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1"><divide id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1"></divide><cn type="integer" id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.2">1</cn><cn type="integer" id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px5.p4.1.m1.1c">\frac{1}{3}</annotation></semantics></math>) when classified 3-way). Assuming that such score distribution is ideal, we prefer the pairs for development/test sets whose hypothesis-only model’s predictions are closest to the ideal. We compute the distance between the prediction and the ideal using cross entropy. To preserve the intact sets of a premise and its three hypotheses, we calculate the mean distance of each set. We extract the sets whose mean distance is among the lowest 20%, and randomly split them into dev and test sets.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p5" class="ltx_para">
<p id="S3.SS3.SSS1.Px5.p5.2" class="ltx_p">Our idea can be viewed as an extension of pointwise mutual information (PMI). PMI between each hypothesis word (<math id="S3.SS3.SSS1.Px5.p5.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.SS3.SSS1.Px5.p5.1.m1.1a"><mi id="S3.SS3.SSS1.Px5.p5.1.m1.1.1" xref="S3.SS3.SSS1.Px5.p5.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px5.p5.1.m1.1b"><ci id="S3.SS3.SSS1.Px5.p5.1.m1.1.1.cmml" xref="S3.SS3.SSS1.Px5.p5.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px5.p5.1.m1.1c">w</annotation></semantics></math>) and class label (<math id="S3.SS3.SSS1.Px5.p5.2.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS3.SSS1.Px5.p5.2.m2.1a"><mi id="S3.SS3.SSS1.Px5.p5.2.m2.1.1" xref="S3.SS3.SSS1.Px5.p5.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px5.p5.2.m2.1b"><ci id="S3.SS3.SSS1.Px5.p5.2.m2.1.1.cmml" xref="S3.SS3.SSS1.Px5.p5.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px5.p5.2.m2.1c">c</annotation></semantics></math>) has been used to discover the association of the word with each class <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite>. If PMI is expanded to the sentence-level association, the metric provides a similar measure to the hypothesis-only model prediction probability as below.</p>
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.13" class="ltx_Math" alttext="\text{PMI}(w,c)=\log{\frac{P(w,c)}{P(w)P(c)}}=\log{\frac{P(c|w)P(w)}{P(w)P(c)}}=\log{\frac{P(c|w)}{P(c)}}\propto P(c|w)" display="block"><semantics id="S3.Ex1.m1.13a"><mrow id="S3.Ex1.m1.13.13" xref="S3.Ex1.m1.13.13.cmml"><mrow id="S3.Ex1.m1.13.13.3" xref="S3.Ex1.m1.13.13.3.cmml"><mtext id="S3.Ex1.m1.13.13.3.2" xref="S3.Ex1.m1.13.13.3.2a.cmml">PMI</mtext><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.13.13.3.1" xref="S3.Ex1.m1.13.13.3.1.cmml">​</mo><mrow id="S3.Ex1.m1.13.13.3.3.2" xref="S3.Ex1.m1.13.13.3.3.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.13.13.3.3.2.1" xref="S3.Ex1.m1.13.13.3.3.1.cmml">(</mo><mi id="S3.Ex1.m1.11.11" xref="S3.Ex1.m1.11.11.cmml">w</mi><mo id="S3.Ex1.m1.13.13.3.3.2.2" xref="S3.Ex1.m1.13.13.3.3.1.cmml">,</mo><mi id="S3.Ex1.m1.12.12" xref="S3.Ex1.m1.12.12.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.13.13.3.3.2.3" xref="S3.Ex1.m1.13.13.3.3.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.13.13.4" xref="S3.Ex1.m1.13.13.4.cmml">=</mo><mrow id="S3.Ex1.m1.13.13.5" xref="S3.Ex1.m1.13.13.5.cmml"><mi id="S3.Ex1.m1.13.13.5.1" xref="S3.Ex1.m1.13.13.5.1.cmml">log</mi><mo lspace="0.167em" id="S3.Ex1.m1.13.13.5a" xref="S3.Ex1.m1.13.13.5.cmml">⁡</mo><mfrac id="S3.Ex1.m1.4.4" xref="S3.Ex1.m1.4.4.cmml"><mrow id="S3.Ex1.m1.2.2.2" xref="S3.Ex1.m1.2.2.2.cmml"><mi id="S3.Ex1.m1.2.2.2.4" xref="S3.Ex1.m1.2.2.2.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.2.3" xref="S3.Ex1.m1.2.2.2.3.cmml">​</mo><mrow id="S3.Ex1.m1.2.2.2.5.2" xref="S3.Ex1.m1.2.2.2.5.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.2.5.2.1" xref="S3.Ex1.m1.2.2.2.5.1.cmml">(</mo><mi id="S3.Ex1.m1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.cmml">w</mi><mo id="S3.Ex1.m1.2.2.2.5.2.2" xref="S3.Ex1.m1.2.2.2.5.1.cmml">,</mo><mi id="S3.Ex1.m1.2.2.2.2" xref="S3.Ex1.m1.2.2.2.2.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.2.2.2.5.2.3" xref="S3.Ex1.m1.2.2.2.5.1.cmml">)</mo></mrow></mrow><mrow id="S3.Ex1.m1.4.4.4" xref="S3.Ex1.m1.4.4.4.cmml"><mi id="S3.Ex1.m1.4.4.4.4" xref="S3.Ex1.m1.4.4.4.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.4.4.4.3" xref="S3.Ex1.m1.4.4.4.3.cmml">​</mo><mrow id="S3.Ex1.m1.4.4.4.5.2" xref="S3.Ex1.m1.4.4.4.cmml"><mo stretchy="false" id="S3.Ex1.m1.4.4.4.5.2.1" xref="S3.Ex1.m1.4.4.4.cmml">(</mo><mi id="S3.Ex1.m1.3.3.3.1" xref="S3.Ex1.m1.3.3.3.1.cmml">w</mi><mo stretchy="false" id="S3.Ex1.m1.4.4.4.5.2.2" xref="S3.Ex1.m1.4.4.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.4.4.4.3a" xref="S3.Ex1.m1.4.4.4.3.cmml">​</mo><mi id="S3.Ex1.m1.4.4.4.6" xref="S3.Ex1.m1.4.4.4.6.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.4.4.4.3b" xref="S3.Ex1.m1.4.4.4.3.cmml">​</mo><mrow id="S3.Ex1.m1.4.4.4.7.2" xref="S3.Ex1.m1.4.4.4.cmml"><mo stretchy="false" id="S3.Ex1.m1.4.4.4.7.2.1" xref="S3.Ex1.m1.4.4.4.cmml">(</mo><mi id="S3.Ex1.m1.4.4.4.2" xref="S3.Ex1.m1.4.4.4.2.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.4.4.4.7.2.2" xref="S3.Ex1.m1.4.4.4.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S3.Ex1.m1.13.13.6" xref="S3.Ex1.m1.13.13.6.cmml">=</mo><mrow id="S3.Ex1.m1.13.13.7" xref="S3.Ex1.m1.13.13.7.cmml"><mi id="S3.Ex1.m1.13.13.7.1" xref="S3.Ex1.m1.13.13.7.1.cmml">log</mi><mo lspace="0.167em" id="S3.Ex1.m1.13.13.7a" xref="S3.Ex1.m1.13.13.7.cmml">⁡</mo><mfrac id="S3.Ex1.m1.8.8" xref="S3.Ex1.m1.8.8.cmml"><mrow id="S3.Ex1.m1.6.6.2" xref="S3.Ex1.m1.6.6.2.cmml"><mi id="S3.Ex1.m1.6.6.2.4" xref="S3.Ex1.m1.6.6.2.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.6.6.2.3" xref="S3.Ex1.m1.6.6.2.3.cmml">​</mo><mrow id="S3.Ex1.m1.6.6.2.2.1" xref="S3.Ex1.m1.6.6.2.2.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.6.6.2.2.1.2" xref="S3.Ex1.m1.6.6.2.2.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.6.6.2.2.1.1" xref="S3.Ex1.m1.6.6.2.2.1.1.cmml"><mi id="S3.Ex1.m1.6.6.2.2.1.1.2" xref="S3.Ex1.m1.6.6.2.2.1.1.2.cmml">c</mi><mo fence="false" id="S3.Ex1.m1.6.6.2.2.1.1.1" xref="S3.Ex1.m1.6.6.2.2.1.1.1.cmml">|</mo><mi id="S3.Ex1.m1.6.6.2.2.1.1.3" xref="S3.Ex1.m1.6.6.2.2.1.1.3.cmml">w</mi></mrow><mo stretchy="false" id="S3.Ex1.m1.6.6.2.2.1.3" xref="S3.Ex1.m1.6.6.2.2.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.6.6.2.3a" xref="S3.Ex1.m1.6.6.2.3.cmml">​</mo><mi id="S3.Ex1.m1.6.6.2.5" xref="S3.Ex1.m1.6.6.2.5.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.6.6.2.3b" xref="S3.Ex1.m1.6.6.2.3.cmml">​</mo><mrow id="S3.Ex1.m1.6.6.2.6.2" xref="S3.Ex1.m1.6.6.2.cmml"><mo stretchy="false" id="S3.Ex1.m1.6.6.2.6.2.1" xref="S3.Ex1.m1.6.6.2.cmml">(</mo><mi id="S3.Ex1.m1.5.5.1.1" xref="S3.Ex1.m1.5.5.1.1.cmml">w</mi><mo stretchy="false" id="S3.Ex1.m1.6.6.2.6.2.2" xref="S3.Ex1.m1.6.6.2.cmml">)</mo></mrow></mrow><mrow id="S3.Ex1.m1.8.8.4" xref="S3.Ex1.m1.8.8.4.cmml"><mi id="S3.Ex1.m1.8.8.4.4" xref="S3.Ex1.m1.8.8.4.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.8.8.4.3" xref="S3.Ex1.m1.8.8.4.3.cmml">​</mo><mrow id="S3.Ex1.m1.8.8.4.5.2" xref="S3.Ex1.m1.8.8.4.cmml"><mo stretchy="false" id="S3.Ex1.m1.8.8.4.5.2.1" xref="S3.Ex1.m1.8.8.4.cmml">(</mo><mi id="S3.Ex1.m1.7.7.3.1" xref="S3.Ex1.m1.7.7.3.1.cmml">w</mi><mo stretchy="false" id="S3.Ex1.m1.8.8.4.5.2.2" xref="S3.Ex1.m1.8.8.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.8.8.4.3a" xref="S3.Ex1.m1.8.8.4.3.cmml">​</mo><mi id="S3.Ex1.m1.8.8.4.6" xref="S3.Ex1.m1.8.8.4.6.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.8.8.4.3b" xref="S3.Ex1.m1.8.8.4.3.cmml">​</mo><mrow id="S3.Ex1.m1.8.8.4.7.2" xref="S3.Ex1.m1.8.8.4.cmml"><mo stretchy="false" id="S3.Ex1.m1.8.8.4.7.2.1" xref="S3.Ex1.m1.8.8.4.cmml">(</mo><mi id="S3.Ex1.m1.8.8.4.2" xref="S3.Ex1.m1.8.8.4.2.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.8.8.4.7.2.2" xref="S3.Ex1.m1.8.8.4.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S3.Ex1.m1.13.13.8" xref="S3.Ex1.m1.13.13.8.cmml">=</mo><mrow id="S3.Ex1.m1.13.13.9" xref="S3.Ex1.m1.13.13.9.cmml"><mi id="S3.Ex1.m1.13.13.9.1" xref="S3.Ex1.m1.13.13.9.1.cmml">log</mi><mo lspace="0.167em" id="S3.Ex1.m1.13.13.9a" xref="S3.Ex1.m1.13.13.9.cmml">⁡</mo><mfrac id="S3.Ex1.m1.10.10" xref="S3.Ex1.m1.10.10.cmml"><mrow id="S3.Ex1.m1.9.9.1" xref="S3.Ex1.m1.9.9.1.cmml"><mi id="S3.Ex1.m1.9.9.1.3" xref="S3.Ex1.m1.9.9.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.9.9.1.2" xref="S3.Ex1.m1.9.9.1.2.cmml">​</mo><mrow id="S3.Ex1.m1.9.9.1.1.1" xref="S3.Ex1.m1.9.9.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.9.9.1.1.1.2" xref="S3.Ex1.m1.9.9.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.9.9.1.1.1.1" xref="S3.Ex1.m1.9.9.1.1.1.1.cmml"><mi id="S3.Ex1.m1.9.9.1.1.1.1.2" xref="S3.Ex1.m1.9.9.1.1.1.1.2.cmml">c</mi><mo fence="false" id="S3.Ex1.m1.9.9.1.1.1.1.1" xref="S3.Ex1.m1.9.9.1.1.1.1.1.cmml">|</mo><mi id="S3.Ex1.m1.9.9.1.1.1.1.3" xref="S3.Ex1.m1.9.9.1.1.1.1.3.cmml">w</mi></mrow><mo stretchy="false" id="S3.Ex1.m1.9.9.1.1.1.3" xref="S3.Ex1.m1.9.9.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.Ex1.m1.10.10.2" xref="S3.Ex1.m1.10.10.2.cmml"><mi id="S3.Ex1.m1.10.10.2.3" xref="S3.Ex1.m1.10.10.2.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.10.10.2.2" xref="S3.Ex1.m1.10.10.2.2.cmml">​</mo><mrow id="S3.Ex1.m1.10.10.2.4.2" xref="S3.Ex1.m1.10.10.2.cmml"><mo stretchy="false" id="S3.Ex1.m1.10.10.2.4.2.1" xref="S3.Ex1.m1.10.10.2.cmml">(</mo><mi id="S3.Ex1.m1.10.10.2.1" xref="S3.Ex1.m1.10.10.2.1.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.10.10.2.4.2.2" xref="S3.Ex1.m1.10.10.2.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S3.Ex1.m1.13.13.10" xref="S3.Ex1.m1.13.13.10.cmml">∝</mo><mrow id="S3.Ex1.m1.13.13.1" xref="S3.Ex1.m1.13.13.1.cmml"><mi id="S3.Ex1.m1.13.13.1.3" xref="S3.Ex1.m1.13.13.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.13.13.1.2" xref="S3.Ex1.m1.13.13.1.2.cmml">​</mo><mrow id="S3.Ex1.m1.13.13.1.1.1" xref="S3.Ex1.m1.13.13.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.13.13.1.1.1.2" xref="S3.Ex1.m1.13.13.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.13.13.1.1.1.1" xref="S3.Ex1.m1.13.13.1.1.1.1.cmml"><mi id="S3.Ex1.m1.13.13.1.1.1.1.2" xref="S3.Ex1.m1.13.13.1.1.1.1.2.cmml">c</mi><mo fence="false" id="S3.Ex1.m1.13.13.1.1.1.1.1" xref="S3.Ex1.m1.13.13.1.1.1.1.1.cmml">|</mo><mi id="S3.Ex1.m1.13.13.1.1.1.1.3" xref="S3.Ex1.m1.13.13.1.1.1.1.3.cmml">w</mi></mrow><mo stretchy="false" id="S3.Ex1.m1.13.13.1.1.1.3" xref="S3.Ex1.m1.13.13.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.13b"><apply id="S3.Ex1.m1.13.13.cmml" xref="S3.Ex1.m1.13.13"><and id="S3.Ex1.m1.13.13a.cmml" xref="S3.Ex1.m1.13.13"></and><apply id="S3.Ex1.m1.13.13b.cmml" xref="S3.Ex1.m1.13.13"><eq id="S3.Ex1.m1.13.13.4.cmml" xref="S3.Ex1.m1.13.13.4"></eq><apply id="S3.Ex1.m1.13.13.3.cmml" xref="S3.Ex1.m1.13.13.3"><times id="S3.Ex1.m1.13.13.3.1.cmml" xref="S3.Ex1.m1.13.13.3.1"></times><ci id="S3.Ex1.m1.13.13.3.2a.cmml" xref="S3.Ex1.m1.13.13.3.2"><mtext id="S3.Ex1.m1.13.13.3.2.cmml" xref="S3.Ex1.m1.13.13.3.2">PMI</mtext></ci><interval closure="open" id="S3.Ex1.m1.13.13.3.3.1.cmml" xref="S3.Ex1.m1.13.13.3.3.2"><ci id="S3.Ex1.m1.11.11.cmml" xref="S3.Ex1.m1.11.11">𝑤</ci><ci id="S3.Ex1.m1.12.12.cmml" xref="S3.Ex1.m1.12.12">𝑐</ci></interval></apply><apply id="S3.Ex1.m1.13.13.5.cmml" xref="S3.Ex1.m1.13.13.5"><log id="S3.Ex1.m1.13.13.5.1.cmml" xref="S3.Ex1.m1.13.13.5.1"></log><apply id="S3.Ex1.m1.4.4.cmml" xref="S3.Ex1.m1.4.4"><divide id="S3.Ex1.m1.4.4.5.cmml" xref="S3.Ex1.m1.4.4"></divide><apply id="S3.Ex1.m1.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2"><times id="S3.Ex1.m1.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.2.3"></times><ci id="S3.Ex1.m1.2.2.2.4.cmml" xref="S3.Ex1.m1.2.2.2.4">𝑃</ci><interval closure="open" id="S3.Ex1.m1.2.2.2.5.1.cmml" xref="S3.Ex1.m1.2.2.2.5.2"><ci id="S3.Ex1.m1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1">𝑤</ci><ci id="S3.Ex1.m1.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2">𝑐</ci></interval></apply><apply id="S3.Ex1.m1.4.4.4.cmml" xref="S3.Ex1.m1.4.4.4"><times id="S3.Ex1.m1.4.4.4.3.cmml" xref="S3.Ex1.m1.4.4.4.3"></times><ci id="S3.Ex1.m1.4.4.4.4.cmml" xref="S3.Ex1.m1.4.4.4.4">𝑃</ci><ci id="S3.Ex1.m1.3.3.3.1.cmml" xref="S3.Ex1.m1.3.3.3.1">𝑤</ci><ci id="S3.Ex1.m1.4.4.4.6.cmml" xref="S3.Ex1.m1.4.4.4.6">𝑃</ci><ci id="S3.Ex1.m1.4.4.4.2.cmml" xref="S3.Ex1.m1.4.4.4.2">𝑐</ci></apply></apply></apply></apply><apply id="S3.Ex1.m1.13.13c.cmml" xref="S3.Ex1.m1.13.13"><eq id="S3.Ex1.m1.13.13.6.cmml" xref="S3.Ex1.m1.13.13.6"></eq><share href="#S3.Ex1.m1.13.13.5.cmml" id="S3.Ex1.m1.13.13d.cmml" xref="S3.Ex1.m1.13.13"></share><apply id="S3.Ex1.m1.13.13.7.cmml" xref="S3.Ex1.m1.13.13.7"><log id="S3.Ex1.m1.13.13.7.1.cmml" xref="S3.Ex1.m1.13.13.7.1"></log><apply id="S3.Ex1.m1.8.8.cmml" xref="S3.Ex1.m1.8.8"><divide id="S3.Ex1.m1.8.8.5.cmml" xref="S3.Ex1.m1.8.8"></divide><apply id="S3.Ex1.m1.6.6.2.cmml" xref="S3.Ex1.m1.6.6.2"><times id="S3.Ex1.m1.6.6.2.3.cmml" xref="S3.Ex1.m1.6.6.2.3"></times><ci id="S3.Ex1.m1.6.6.2.4.cmml" xref="S3.Ex1.m1.6.6.2.4">𝑃</ci><apply id="S3.Ex1.m1.6.6.2.2.1.1.cmml" xref="S3.Ex1.m1.6.6.2.2.1"><csymbol cd="latexml" id="S3.Ex1.m1.6.6.2.2.1.1.1.cmml" xref="S3.Ex1.m1.6.6.2.2.1.1.1">conditional</csymbol><ci id="S3.Ex1.m1.6.6.2.2.1.1.2.cmml" xref="S3.Ex1.m1.6.6.2.2.1.1.2">𝑐</ci><ci id="S3.Ex1.m1.6.6.2.2.1.1.3.cmml" xref="S3.Ex1.m1.6.6.2.2.1.1.3">𝑤</ci></apply><ci id="S3.Ex1.m1.6.6.2.5.cmml" xref="S3.Ex1.m1.6.6.2.5">𝑃</ci><ci id="S3.Ex1.m1.5.5.1.1.cmml" xref="S3.Ex1.m1.5.5.1.1">𝑤</ci></apply><apply id="S3.Ex1.m1.8.8.4.cmml" xref="S3.Ex1.m1.8.8.4"><times id="S3.Ex1.m1.8.8.4.3.cmml" xref="S3.Ex1.m1.8.8.4.3"></times><ci id="S3.Ex1.m1.8.8.4.4.cmml" xref="S3.Ex1.m1.8.8.4.4">𝑃</ci><ci id="S3.Ex1.m1.7.7.3.1.cmml" xref="S3.Ex1.m1.7.7.3.1">𝑤</ci><ci id="S3.Ex1.m1.8.8.4.6.cmml" xref="S3.Ex1.m1.8.8.4.6">𝑃</ci><ci id="S3.Ex1.m1.8.8.4.2.cmml" xref="S3.Ex1.m1.8.8.4.2">𝑐</ci></apply></apply></apply></apply><apply id="S3.Ex1.m1.13.13e.cmml" xref="S3.Ex1.m1.13.13"><eq id="S3.Ex1.m1.13.13.8.cmml" xref="S3.Ex1.m1.13.13.8"></eq><share href="#S3.Ex1.m1.13.13.7.cmml" id="S3.Ex1.m1.13.13f.cmml" xref="S3.Ex1.m1.13.13"></share><apply id="S3.Ex1.m1.13.13.9.cmml" xref="S3.Ex1.m1.13.13.9"><log id="S3.Ex1.m1.13.13.9.1.cmml" xref="S3.Ex1.m1.13.13.9.1"></log><apply id="S3.Ex1.m1.10.10.cmml" xref="S3.Ex1.m1.10.10"><divide id="S3.Ex1.m1.10.10.3.cmml" xref="S3.Ex1.m1.10.10"></divide><apply id="S3.Ex1.m1.9.9.1.cmml" xref="S3.Ex1.m1.9.9.1"><times id="S3.Ex1.m1.9.9.1.2.cmml" xref="S3.Ex1.m1.9.9.1.2"></times><ci id="S3.Ex1.m1.9.9.1.3.cmml" xref="S3.Ex1.m1.9.9.1.3">𝑃</ci><apply id="S3.Ex1.m1.9.9.1.1.1.1.cmml" xref="S3.Ex1.m1.9.9.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.9.9.1.1.1.1.1.cmml" xref="S3.Ex1.m1.9.9.1.1.1.1.1">conditional</csymbol><ci id="S3.Ex1.m1.9.9.1.1.1.1.2.cmml" xref="S3.Ex1.m1.9.9.1.1.1.1.2">𝑐</ci><ci id="S3.Ex1.m1.9.9.1.1.1.1.3.cmml" xref="S3.Ex1.m1.9.9.1.1.1.1.3">𝑤</ci></apply></apply><apply id="S3.Ex1.m1.10.10.2.cmml" xref="S3.Ex1.m1.10.10.2"><times id="S3.Ex1.m1.10.10.2.2.cmml" xref="S3.Ex1.m1.10.10.2.2"></times><ci id="S3.Ex1.m1.10.10.2.3.cmml" xref="S3.Ex1.m1.10.10.2.3">𝑃</ci><ci id="S3.Ex1.m1.10.10.2.1.cmml" xref="S3.Ex1.m1.10.10.2.1">𝑐</ci></apply></apply></apply></apply><apply id="S3.Ex1.m1.13.13g.cmml" xref="S3.Ex1.m1.13.13"><csymbol cd="latexml" id="S3.Ex1.m1.13.13.10.cmml" xref="S3.Ex1.m1.13.13.10">proportional-to</csymbol><share href="#S3.Ex1.m1.13.13.9.cmml" id="S3.Ex1.m1.13.13h.cmml" xref="S3.Ex1.m1.13.13"></share><apply id="S3.Ex1.m1.13.13.1.cmml" xref="S3.Ex1.m1.13.13.1"><times id="S3.Ex1.m1.13.13.1.2.cmml" xref="S3.Ex1.m1.13.13.1.2"></times><ci id="S3.Ex1.m1.13.13.1.3.cmml" xref="S3.Ex1.m1.13.13.1.3">𝑃</ci><apply id="S3.Ex1.m1.13.13.1.1.1.1.cmml" xref="S3.Ex1.m1.13.13.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.13.13.1.1.1.1.1.cmml" xref="S3.Ex1.m1.13.13.1.1.1.1.1">conditional</csymbol><ci id="S3.Ex1.m1.13.13.1.1.1.1.2.cmml" xref="S3.Ex1.m1.13.13.1.1.1.1.2">𝑐</ci><ci id="S3.Ex1.m1.13.13.1.1.1.1.3.cmml" xref="S3.Ex1.m1.13.13.1.1.1.1.3">𝑤</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.13c">\text{PMI}(w,c)=\log{\frac{P(w,c)}{P(w)P(c)}}=\log{\frac{P(c|w)P(w)}{P(w)P(c)}}=\log{\frac{P(c|w)}{P(c)}}\propto P(c|w)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.SSS1.Px5.p6" class="ltx_para">
<p id="S3.SS3.SSS1.Px5.p6.1" class="ltx_p">To measure human performance and examine whether KLUE-NLI test set improves upon KorNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> test set, a machine-translation of the XNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> test set, we conduct a round of human evaluation. We employ four native Korean undergraduates who major in Korean linguistics and did not participate in the KLUE-NLI construction process. We randomly sample 100 sentence pairs from KLUE-NLI test set and ask the workers to annotate them. We check the agreement of their annotations with the given gold label. We do the same on the subset of the KorNLI test set, to examine whether the human-elicited dataset improves the quality of the dataset. The results are shown in Table&nbsp;<a href="#S3.T7" title="Table 7 ‣ Final Dataset ‣ 3.3.1 Dataset Construction ‣ 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p7" class="ltx_para">
<p id="S3.SS3.SSS1.Px5.p7.1" class="ltx_p">For KorNLI, 38% of the sentence pairs have responses from all four annotators that match with the gold labels. There are 18%, 18%, and 16% of sentences, respectively, when three, and two, and one response match with the gold label. 10 pairs do not match with the gold label. On the other hand, KLUE-NLI shows much higher agreement with the given gold label. All annotators agree with the gold label in 71% of the pairs, and 95% obtain at least three agreements. Furthermore, only 258 out of 400 (64.50%) individual annotations are the same as the gold label in KorNLI. Again, KLUE-NLI shows better agreement with the gold labels. 360 (91.00%) annotations are the same as the gold label.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p8" class="ltx_para">
<p id="S3.SS3.SSS1.Px5.p8.1" class="ltx_p">These numbers in annotation quality of KLUE-NLI are better than KorNLI as well as SNLI and MLNI. In KorNLI, annotators often report that they do not quite understand at least one of the two sentences or choose NEUTRAL because it is difficult to distinguish the semantic relationships of the sentences. Although the distribution of the gold label is uniform (respectively 33, 33, and 34% of entailment, contradiction, and neutral sentences), the label chosen most frequently by the annotators is NEUTRAL (56.75% on average). There are 26% of cases where the gold labels are different from the majority vote by the annotator. These results suggest that the annotators struggle to grasp the logical semantic relationship of KorNLI sentences.</p>
</div>
<figure id="S3.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Statistics for human evaluation results of KorNLI and KLUE-NLI. We compare the labels of four annotators with gold labels of korNLI and KLUE-NLI test data.</figcaption>
<table id="S3.T7.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T7.1.2" class="ltx_tr">
<td id="S3.T7.1.2.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T7.1.2.1.1" class="ltx_text ltx_font_bold">Statistics</span></td>
<td id="S3.T7.1.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T7.1.2.2.1" class="ltx_text ltx_font_bold">KorNLI</span></td>
<td id="S3.T7.1.2.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T7.1.2.3.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></td>
</tr>
<tr id="S3.T7.1.3" class="ltx_tr">
<td id="S3.T7.1.3.1" class="ltx_td ltx_align_left ltx_border_t">Unanimous Gold Label (4 Agree)</td>
<td id="S3.T7.1.3.2" class="ltx_td ltx_align_center ltx_border_t">38.00%</td>
<td id="S3.T7.1.3.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T7.1.3.3.1" class="ltx_text ltx_font_bold">71.00%</span></td>
</tr>
<tr id="S3.T7.1.4" class="ltx_tr">
<td id="S3.T7.1.4.1" class="ltx_td ltx_align_left">3 Agree with Gold Label</td>
<td id="S3.T7.1.4.2" class="ltx_td ltx_align_center">18.00%</td>
<td id="S3.T7.1.4.3" class="ltx_td ltx_nopad_r ltx_align_center">24.00%</td>
</tr>
<tr id="S3.T7.1.5" class="ltx_tr">
<td id="S3.T7.1.5.1" class="ltx_td ltx_align_left">2 Agree with Gold Label</td>
<td id="S3.T7.1.5.2" class="ltx_td ltx_align_center">18.00%</td>
<td id="S3.T7.1.5.3" class="ltx_td ltx_nopad_r ltx_align_center">3.00%</td>
</tr>
<tr id="S3.T7.1.6" class="ltx_tr">
<td id="S3.T7.1.6.1" class="ltx_td ltx_align_left">1 Agrees with Gold Label</td>
<td id="S3.T7.1.6.2" class="ltx_td ltx_align_center">16.00%</td>
<td id="S3.T7.1.6.3" class="ltx_td ltx_nopad_r ltx_align_center">2.00%</td>
</tr>
<tr id="S3.T7.1.7" class="ltx_tr">
<td id="S3.T7.1.7.1" class="ltx_td ltx_align_left">0 Agrees with Gold Label</td>
<td id="S3.T7.1.7.2" class="ltx_td ltx_align_center">10.00%</td>
<td id="S3.T7.1.7.3" class="ltx_td ltx_nopad_r ltx_align_center">0.00%</td>
</tr>
<tr id="S3.T7.1.8" class="ltx_tr">
<td id="S3.T7.1.8.1" class="ltx_td ltx_align_left ltx_border_t">Individual Label = Gold Label</td>
<td id="S3.T7.1.8.2" class="ltx_td ltx_align_center ltx_border_t">64.50%</td>
<td id="S3.T7.1.8.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T7.1.8.3.1" class="ltx_text ltx_font_bold">91.00%</span></td>
</tr>
<tr id="S3.T7.1.9" class="ltx_tr">
<td id="S3.T7.1.9.1" class="ltx_td ltx_align_left ltx_border_t">No Gold Label (No 3 Labels Match)</td>
<td id="S3.T7.1.9.2" class="ltx_td ltx_align_center ltx_border_t">4.00%</td>
<td id="S3.T7.1.9.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T7.1.9.3.1" class="ltx_text ltx_font_bold">0.00%</span></td>
</tr>
<tr id="S3.T7.1.1" class="ltx_tr">
<td id="S3.T7.1.1.1" class="ltx_td ltx_align_left ltx_border_bb">Majority Vote <math id="S3.T7.1.1.1.m1.1" class="ltx_Math" alttext="\neq" display="inline"><semantics id="S3.T7.1.1.1.m1.1a"><mo id="S3.T7.1.1.1.m1.1.1" xref="S3.T7.1.1.1.m1.1.1.cmml">≠</mo><annotation-xml encoding="MathML-Content" id="S3.T7.1.1.1.m1.1b"><neq id="S3.T7.1.1.1.m1.1.1.cmml" xref="S3.T7.1.1.1.m1.1.1"></neq></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.1.1.1.m1.1c">\neq</annotation></semantics></math> Gold Label</td>
<td id="S3.T7.1.1.2" class="ltx_td ltx_align_center ltx_border_bb">26.00%</td>
<td id="S3.T7.1.1.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S3.T7.1.1.3.1" class="ltx_text ltx_font_bold">0.00%</span></td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS3.SSS1.Px5.p9" class="ltx_para">
<p id="S3.SS3.SSS1.Px5.p9.1" class="ltx_p">On the other hand, for KLUE-NLI, there is no case where none of the four responses matches the gold label. Considering the cases where more than two of the responses match the gold label, there is a 98% chance of the gold label to be re-selected as the majority tag. Compared to KorNLI, we can see that KLUE-NLI is a much more reliable dataset. This result also confirms that the headroom of our current best model (accuracy: 89.77%) is still there, given that the human accuracy, represented by the majority tag, is 98%.</p>
</div>
</section>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Evaluation Metric</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">The evaluation metric for KLUE-NLI is accuracy, following SNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>. Accuracy measures how well a classifier correctly identifies the results. The class labels are almost equally distributed, thus higher accuracy will correctly represent performances of a model.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>Related Work</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">Recognizing Textual Entailment (RTE)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> is a task similar to NLI and was introduced in a series of textual entailment challenges. In the RTE task, two sentences are given, and the model decides whether the meaning of one sentence can be entailed from the other sentence. In earlier RTE 1–3, the task is binary, ‘ENTAILMENT’ and ‘NO ENTAILMENT’. In RTE 4-5, a new class ‘UNKNOWN’ is introduced, and the task is formulated as a three-way classification.</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.1" class="ltx_p">Two major datasets for NLI in English are Stanford Natural Language Inference (SNLI)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and Multi-Genre Natural Language Inference (MNLI)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>. Hypothesis sentences in SNLI and MNLI are labeled ENTAILMENT, CONTRADICTION, or NEUTRAL. SNLI is two orders of magnitude larger than the RTE corpora, made from 570,152 image captions in Flickr30k &nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite>. MNLI premise sentences are derived from 10 different sources, covering a wider range of styles, degrees of formality, and topics.</p>
</div>
<div id="S3.SS3.SSS3.p3" class="ltx_para">
<p id="S3.SS3.SSS3.p3.1" class="ltx_p">Most of the existing NLI datasets are in English, including SNLI and MNLI, and one common approach for constructing NLI datasets in other languages is to translate the existing English corpora to the language of interest. <cite class="ltx_cite ltx_citemacro_citet">Conneau et&nbsp;al. [<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> provides XNLI (Cross-lingual natural language inference) by employing professional translators to translate the development and test sets of MNLI into 15 languages. One main concern of the translation-based approach is whether the relation of the original sentence pair is maintained in the process. <cite class="ltx_cite ltx_citemacro_citet">Conneau et&nbsp;al. [<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> find some translated pairs lose the initial semantic relationship, validated by human annotators who re-annotate a sample of the dataset. The result demonstrates that human translations cause 2% misannotations given the 85% correct examples in the MNLI and 83% in XNLI.</p>
</div>
<div id="S3.SS3.SSS3.p4" class="ltx_para">
<p id="S3.SS3.SSS3.p4.1" class="ltx_p">Motivated by the fact that Korean is not included in XNLI, KorNLI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> is introduced. KorNLI&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> is a translation of existing English corpora whose train set is created through machine translation of training sets of SNLI and MNLI, and the development and test sets through machine translation of development and tests sets of XNLI and post-editing by professional translators. Although <cite class="ltx_cite ltx_citemacro_citet">Ham et&nbsp;al. [<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> also investigate the data manually and acknowledge some incorrect examples after the translation, no human validation process is performed to quantify the observation and leave analyzing such errors to future work. Moreover, even with post-editing, there are some sentences that are either unnatural in terms of syntactic structure or word choice.</p>
</div>
<div id="S3.SS3.SSS3.p5" class="ltx_para">
<p id="S3.SS3.SSS3.p5.1" class="ltx_p">Many studies have been proposed based on SNLI and MNLI; however, SNLI and MNLI are known to have annotation artifacts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>. Annotation artifacts are the product of certain types of annotation strategies and heuristics naturally arising from the crowdsourcing process. Such artifacts are problematic as they may lead models to adopt heuristics rather than to actually learn the relationship.</p>
</div>
<div id="S3.SS3.SSS3.p6" class="ltx_para">
<p id="S3.SS3.SSS3.p6.1" class="ltx_p">There have been some efforts to reduce annotation artifacts in NLI. <cite class="ltx_cite ltx_citemacro_citet">Vania et&nbsp;al. [<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite> experiment with two fully automated protocols for creating premise-hypothesis pairs, but find that the methods yield poor-quality data and mixed results on annotation artifacts. OCNLI&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> enhance writing-base protocol with some interventions to control the bias: encouraging writers to use diverse ways of making inference, and putting constraints on overused words. Despite partial effects on reducing negators, the explicit constraint gives rise to other words of correlation, and the final OCNLI dataset exhibit similar level of hypothesis-only test scores to most benchmark NLI datasets.</p>
</div>
</section>
<section id="S3.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.4 </span>Conclusion</h4>

<div id="S3.SS3.SSS4.p1" class="ltx_para">
<p id="S3.SS3.SSS4.p1.1" class="ltx_p">Our new dataset, KLUE-NLI, is the first resource constructed upon naturally occurring Korean sentences. KLUE-NLI represents diverse linguistic phenomena, writing style, degree of formality and contents that are most natural and suitable for Korean. The premise sentences of our dataset come from six Korean corpora, and the hypothesis sentences are written by well-trained workers.</p>
</div>
<div id="S3.SS3.SSS4.p2" class="ltx_para">
<p id="S3.SS3.SSS4.p2.1" class="ltx_p">By keeping the writing-based protocol and thoroughly training workers based on detailed guidelines, we improve upon the existing NLI datasets in the reliability of the labels. KLUE-NLI shows much higher inter-annotator agreement rate than both the MNLI and the translation-based Korean dataset, KorNLI. The gap between the human performance scores of KLUE-NLI and KorNLI also provides evidence that KLUE-NLI is currently the optimal Korean NLI dataset.</p>
</div>
<div id="S3.SS3.SSS4.p3" class="ltx_para">
<p id="S3.SS3.SSS4.p3.1" class="ltx_p">Beyond its main purpose as an NLI benchmark dataset, we hope KLUE-NLI will be a useful resource for future NLU research, as English dataset such as MNLI and SNLI are extended&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib107" title="" class="ltx_ref">107</a>, <a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Named Entity Recognition (NER)</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The goal of named entity recognition (NER) is to detect the boundaries of named entities in unstructured text and classify the types. An entity can be series of words that refers to the person, location, organization, time expressions, quantities, monetary values.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">Since NER is an important for application fields like syntax analysis, goal-oriented dialog system, question and answering chatbot and information extraction, various NLU benchmarks contains NER datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. Despite the rise of necessity of NER datasets in various domains and styles, there are few existing Korean NER datasets to cover such need. Therefore, we annotate corpora including web texts that can be applied to real-word applications.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">In KLUE-NER, a model should detect the spans and classify the types of entities included in an input sentence. The six entity types used in KLUE-NER are person, location, organization, date, time, and quantity. They are tagged via character-level BIO (Begin-Inside-Outside) tagging scheme, and thus we evaluate a model’s performance using entity-level and character-level F1 score.</p>
</div>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>Dataset Construction</h4>

<section id="S3.SS4.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS4.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.Px1.p1.1" class="ltx_p">To incorporate both formal and informal writing styles, we use two corpora, WIKITREE and NSMC for annotation. WIKITREE is a news article corpus and thus contains formal sentences with many entity types, which suits well as a source corpus for NER. NSMC includes colloquial reviews of movies or TV shows. Since the texts in NSMC are user-generated comments, they contain errata and non-normalized expressions, along with emojis and slang. Such a noisy dataset will help broaden the application field of NER models.</p>
</div>
<div id="S3.SS4.SSS1.Px1.p2" class="ltx_para">
<p id="S3.SS4.SSS1.Px1.p2.1" class="ltx_p">The preprocessing of the two corpora is performed differently considering the characteristics of each corpus. For WIKITREE, since the news articles are mainly composed of well-written sentences, we simply split the articles into sentences. In contrast, the web texts from NSMC are written in the style of spoken language with blurry sentence boundaries. As each review is generally quite short and the sentences consisting it are on the same topic, we use each review as a single unit of input. In addition, the sentences that contain hate speech or socially biased terms are removed manually. For both corpora, we remove sentences longer than 400 characters.</p>
</div>
<div id="S3.SS4.SSS1.Px1.p3" class="ltx_para">
<p id="S3.SS4.SSS1.Px1.p3.1" class="ltx_p">For efficient annotation, we perform pseudo-labeling with a pretrained model. The model is trained with BERT-CRF using a publicly available dataset KMOU-NER corpus,<span id="footnote24" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">24</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">24</sup><span class="ltx_tag ltx_tag_note">24</span><a target="_blank" href="https://github.com/kmounlp/NER" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kmounlp/NER</a></span></span></span> to support fast and accurate entity tagging for annotators. We also filter out the sentences with no pseudo-labeled entity assuming they do not include any of the entities. Remaining sentences account for about 80% in WIKITREE and 41% in NSMC, leaving a total of 36,515 sentences.</p>
</div>
</section>
<section id="S3.SS4.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS4.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS4.SSS1.Px2.p1.1" class="ltx_p">We use six entity types for KLUE-NER annotation: PS (Person), LC (Location), OG (Organization), DT (Date), TI (Time), and QT (Quantity). The description of each entity type is as follows.</p>
</div>
<div id="S3.SS4.SSS1.Px2.p2" class="ltx_para">
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p">PS (Person): Name of an individual or a group</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p">LC (Location): Name of a district/province or a geographical location</p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p">OG (Organization): Name of an organization or an enterprise</p>
</div>
</li>
<li id="S3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i4.p1" class="ltx_para">
<p id="S3.I3.i4.p1.1" class="ltx_p">DT (Date): Expressions related to date/period/era/age</p>
</div>
</li>
<li id="S3.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i5.p1" class="ltx_para">
<p id="S3.I3.i5.p1.1" class="ltx_p">TI (Time): Expressions related to time</p>
</div>
</li>
<li id="S3.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i6.p1" class="ltx_para">
<p id="S3.I3.i6.p1.1" class="ltx_p">QT (Quantity): Expressions related to quantity or number including units</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS1.Px2.p3" class="ltx_para">
<p id="S3.SS4.SSS1.Px2.p3.1" class="ltx_p">We employ the above sets following the convention of two existing tag sets: Korean Telecommunications Technology Association (TTA) NER guidelines<span id="footnote25" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">25</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">25</sup><span class="ltx_tag ltx_tag_note">25</span>
<a target="_blank" href="https://committee.tta.or.kr/data/standard_view.jsp?nowPage=2&amp;pk_num=TTAK.KO-10.0852&amp;commit_code=PG606" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://committee.tta.or.kr/data/standard_view.jsp?nowPage=2&amp;pk_num=TTAK.KO-10.0852&amp;commit_code=PG606</a>
</span></span></span> and MUC-7 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. TTA guideline is a standardized NER tagging scheme for Korean language and we follow the names and the definitions of its entity types. Among the 15 entity types of TTA, we select our six types that correspond with tagsets used in MUC-7 (DATE, LOCATION, MONEY, ORGANIZATION, PERCENT, PERSON and TIME). As MONEY and PERCENT types are included in QT (QUANTITY) type from TTA set, we instead adopt an entity type QT.</p>
</div>
<div id="S3.SS4.SSS1.Px2.p4" class="ltx_para">
<p id="S3.SS4.SSS1.Px2.p4.1" class="ltx_p">In the case of entities with multiple possible entity types, instead of assigning a unique tag for all use cases, we determine their tags based on the context. One example is <span id="S3.SS4.SSS1.Px2.p4.1.1" class="ltx_text ltx_font_italic">Cine21</span>, which, in Korean, can either refer to the name of a magazine or the publisher of the magazine. In a sentence like “’I bought a Cine21 from a bookstore and read it page by page,” ‘Buy something from a bookstore’ and ‘read page by page’ are properties regarding media (magazine), rather than an organization; thus we do not assign an OG tag.</p>
</div>
<div id="S3.SS4.SSS1.Px2.p5" class="ltx_para">
<p id="S3.SS4.SSS1.Px2.p5.1" class="ltx_p">We guide crowdworkers to report if the text for annotation does not meet certain conditions. For example, texts consisting of multiple sentences, texts that are not in a sentence form, a fragment, and a simple sequence of nouns are discarded. Workers are also required to report sentences that include hate speech and various biases in tagging process.
</p>
</div>
<div id="S3.SS4.SSS1.Px2.p6" class="ltx_para">
<p id="S3.SS4.SSS1.Px2.p6.1" class="ltx_p">In terms of personally identifiable information, we cannot simply drop or pseudonymize the information because the very task of NER often requires the specific information of proper nouns such as person names (PS). In order to minimize the loss of sentences, we inspect through the sentences after the annotation process. We investigate the sentences that include PS tags, and keep the ones that contain the name of public figures that appear in Korean search engines.<span id="footnote26" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">26</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">26</sup><span class="ltx_tag ltx_tag_note">26</span>Daum: <a target="_blank" href="http://search.daum.net/search?nil_suggest=btn&amp;nil_ch=&amp;rtupcoll=&amp;w=tot&amp;m=&amp;f=&amp;lpp=&amp;q=%C0%CE%B9%B0%B0%CB%BB%F6" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://search.daum.net/search?nil_suggest=btn&amp;nil_ch=&amp;rtupcoll=&amp;w=tot&amp;m=&amp;f=&amp;lpp=&amp;q=%C0%CE%B9%B0%B0%CB%BB%F6</a> / Naver: <a target="_blank" href="https://people.search.naver.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://people.search.naver.com/</a></span></span></span> Other sentences are removed if it has potential privacy issues.</p>
</div>
</section>
<section id="S3.SS4.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS4.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS4.SSS1.Px3.p1.1" class="ltx_p">51 qualified crowdworkers recruited by a Korean crowdsourcing platform, DeepNatural<span id="footnote27" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">27</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">27</sup><span class="ltx_tag ltx_tag_note">27</span><a target="_blank" href="https://deepnatural.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://deepnatural.ai/</a></span></span></span> participate in the annotation process. The qualification is given when passing a pilot entity tagging test. Then two linguists check whether the crowdworkers’ annotations are correct or not. We find some erroneous annotations remaining even after validation. Therefore, six NLP researchers manually correct the annotation errors.</p>
</div>
<div id="S3.SS4.SSS1.Px3.p2" class="ltx_para">
<p id="S3.SS4.SSS1.Px3.p2.1" class="ltx_p">During the annotation process, 5,354 sentences are dropped by workers due to their inadequacy. 118 sentences are dropped due to the privacy issue, and 35 sentences are removed after the inspection by the researchers because all annotations are false positives. A total of 5,507 sentences are dropped in the inspection process, resulting in 31,008 sentences.</p>
</div>
<figure id="S3.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Statistics for KLUE-NER.</figcaption>
<table id="S3.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T8.1.1" class="ltx_tr">
<td id="S3.T8.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T8.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T8.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T8.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T8.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T8.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T8.1.2" class="ltx_tr">
<td id="S3.T8.1.2.1" class="ltx_td ltx_align_left ltx_border_t">WIKITREE</td>
<td id="S3.T8.1.2.2" class="ltx_td ltx_align_center ltx_border_t">11,435</td>
<td id="S3.T8.1.2.3" class="ltx_td ltx_align_center ltx_border_t">2,534</td>
<td id="S3.T8.1.2.4" class="ltx_td ltx_align_center ltx_border_t">2,685</td>
<td id="S3.T8.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">16,664</td>
</tr>
<tr id="S3.T8.1.3" class="ltx_tr">
<td id="S3.T8.1.3.1" class="ltx_td ltx_align_left">NSMC</td>
<td id="S3.T8.1.3.2" class="ltx_td ltx_align_center">9,573</td>
<td id="S3.T8.1.3.3" class="ltx_td ltx_align_center">2,466</td>
<td id="S3.T8.1.3.4" class="ltx_td ltx_align_center">2,315</td>
<td id="S3.T8.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">14,354</td>
</tr>
<tr id="S3.T8.1.4" class="ltx_tr">
<td id="S3.T8.1.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T8.1.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.2.1" class="ltx_text ltx_font_bold">21,008</span></td>
<td id="S3.T8.1.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.3.1" class="ltx_text ltx_font_bold">5,000</span></td>
<td id="S3.T8.1.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.4.1" class="ltx_text ltx_font_bold">5,000</span></td>
<td id="S3.T8.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.5.1" class="ltx_text ltx_font_bold">31,008</span></td>
</tr>
</tbody></table>
</figure>
<figure id="S3.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Entity-wise statistics for KLUE-NER. Note that the numbers in parentheses denote the number of types. The total number does not match Table&nbsp;<a href="#S3.T8" title="Table 8 ‣ Annotation Process ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> since this table does not remove duplication.</figcaption>
<table id="S3.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T9.1.1" class="ltx_tr">
<td id="S3.T9.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T9.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T9.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T9.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T9.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T9.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T9.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T9.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T9.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T9.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T9.1.2" class="ltx_tr">
<td id="S3.T9.1.2.1" class="ltx_td ltx_align_left ltx_border_t">PS</td>
<td id="S3.T9.1.2.2" class="ltx_td ltx_align_center ltx_border_t">14,453 (5,428)</td>
<td id="S3.T9.1.2.3" class="ltx_td ltx_align_center ltx_border_t">4,418 (2,706)</td>
<td id="S3.T9.1.2.4" class="ltx_td ltx_align_center ltx_border_t">4,830 (3,063)</td>
<td id="S3.T9.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">23,289 (7,124)</td>
</tr>
<tr id="S3.T9.1.3" class="ltx_tr">
<td id="S3.T9.1.3.1" class="ltx_td ltx_align_left">LC</td>
<td id="S3.T9.1.3.2" class="ltx_td ltx_align_center">6,663 (2,068)</td>
<td id="S3.T9.1.3.3" class="ltx_td ltx_align_center">1,649 (896)</td>
<td id="S3.T9.1.3.4" class="ltx_td ltx_align_center">2,064 (1,130)</td>
<td id="S3.T9.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">9,961 (2,650)</td>
</tr>
<tr id="S3.T9.1.4" class="ltx_tr">
<td id="S3.T9.1.4.1" class="ltx_td ltx_align_left">OG</td>
<td id="S3.T9.1.4.2" class="ltx_td ltx_align_center">8,491 (3,008)</td>
<td id="S3.T9.1.4.3" class="ltx_td ltx_align_center">2,182 (1,291)</td>
<td id="S3.T9.1.4.4" class="ltx_td ltx_align_center">2,514 (1,579)</td>
<td id="S3.T9.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center">12,855 (3,796)</td>
</tr>
<tr id="S3.T9.1.5" class="ltx_tr">
<td id="S3.T9.1.5.1" class="ltx_td ltx_align_left">DT</td>
<td id="S3.T9.1.5.2" class="ltx_td ltx_align_center">8,029 (1,608)</td>
<td id="S3.T9.1.5.3" class="ltx_td ltx_align_center">2,312 (835)</td>
<td id="S3.T9.1.5.4" class="ltx_td ltx_align_center">2,498 (933)</td>
<td id="S3.T9.1.5.5" class="ltx_td ltx_nopad_r ltx_align_center">12,653 (2,060)</td>
</tr>
<tr id="S3.T9.1.6" class="ltx_tr">
<td id="S3.T9.1.6.1" class="ltx_td ltx_align_left">TI</td>
<td id="S3.T9.1.6.2" class="ltx_td ltx_align_center">2,020 (573)</td>
<td id="S3.T9.1.6.3" class="ltx_td ltx_align_center">5,45 (268)</td>
<td id="S3.T9.1.6.4" class="ltx_td ltx_align_center">579 (316)</td>
<td id="S3.T9.1.6.5" class="ltx_td ltx_nopad_r ltx_align_center">3,110 (730)</td>
</tr>
<tr id="S3.T9.1.7" class="ltx_tr">
<td id="S3.T9.1.7.1" class="ltx_td ltx_align_left">QT</td>
<td id="S3.T9.1.7.2" class="ltx_td ltx_align_center">11,717 (3,628)</td>
<td id="S3.T9.1.7.3" class="ltx_td ltx_align_center">3,151 (1,763)</td>
<td id="S3.T9.1.7.4" class="ltx_td ltx_align_center">3,827 (2,369)</td>
<td id="S3.T9.1.7.5" class="ltx_td ltx_nopad_r ltx_align_center">18,019 (4,776)</td>
</tr>
<tr id="S3.T9.1.8" class="ltx_tr">
<td id="S3.T9.1.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T9.1.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.2.1" class="ltx_text ltx_font_bold">51,373 (16,313)</span></td>
<td id="S3.T9.1.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.3.1" class="ltx_text ltx_font_bold">14,257 (7,759)</span></td>
<td id="S3.T9.1.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.4.1" class="ltx_text ltx_font_bold">16,312 (9,390)</span></td>
<td id="S3.T9.1.8.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.5.1" class="ltx_text ltx_font_bold">79,887 (21,136)</span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS4.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS4.SSS1.Px4.p1" class="ltx_para">
<p id="S3.SS4.SSS1.Px4.p1.1" class="ltx_p">The resulting corpus is split into train/dev/test sets, each consisting of 21,008, 5,000, and 5,000 sentences (Table&nbsp;<a href="#S3.T8" title="Table 8 ‣ Annotation Process ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>). The entity-wise statistics is provided in Table&nbsp;<a href="#S3.T9" title="Table 9 ‣ Annotation Process ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. We design the test set to include unseen entities to check the robustness of the models in terms of domain transitions and generalization.</p>
</div>
<div id="S3.SS4.SSS1.Px4.p2" class="ltx_para">
<p id="S3.SS4.SSS1.Px4.p2.1" class="ltx_p">The finalized entity types are tagged in the character level BIO tagging scheme (Figure&nbsp;<a href="#S3.F3" title="Figure 3 ‣ Final Dataset ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). In most English and Korean NER datasets, the entities are tagged with the word-level BIO scheme, following CoNLL 2003 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite>. In Korean, however, it is difficult to adhere to the word level tagging scheme based on whitespace for two reasons. First, whitespace-split units (eojeols) are often not a single word and are a composite of content words and functional words (e.g., ‘담주가 (the next week is)’ = ‘담주 (the next week)’ + ‘가 (is)’) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. Second, many compound words in Korean contain whitespaces. Therefore, we choose to tag in character level.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2105.09680/assets/figs/ner-bio.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="57" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An example of BIO scheme for NER tagging. The sentence is translated as: “&lt;CNBlue:PS&gt; is the best♥!!!! So sad &lt;the next week:DT&gt; is their last weekT.T Nooooo!!” where 씨엔블루 (<span id="S3.F3.4.1" class="ltx_text ltx_font_italic">CNBlue</span>) is a rock band of Korea. 담주 (<span id="S3.F3.5.2" class="ltx_text ltx_font_italic">the next week</span>) is tagged as DT here, while it is agglutinated with a functional word 가 (<span id="S3.F3.6.3" class="ltx_text ltx_font_italic">is</span>) in this sentence and is separately annotated with the character-level BIO scheme.</figcaption>
</figure>
</section>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>Evaluation Metrics</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p">The evaluation metrics for KLUE-NER are 1) entity-level macro F1 (Entity F1) and 2) character-level macro F1 (Char F1) scores. Entity F1 score measures how many predicted entities and types are exactly matched with the ground truths in entity-level. Suppose a ground truth is [B-PS, I-PS, O, O, B-OG, I-OG] and a prediction is [B-PS, I-PS, I-PS, O, B-OG, I-OG]. For entity type PS, F1 score is 0 since a model fails to predict the exact span, while in case of OG, a model gets a score. To get a high score, a model should be careful at tokenization. Char F1 score is newly provided to measure a partial overlap between a model prediction and a ground truth. We additionally report this measure to see how well a model decomposes stems and affixes in Korean, which significantly affects the model performance of NER. Char F1 is an average of class-wise F1-scores. In KLUE-NER, the classes are B-PS, I-PS, B-LC, I-LC, B-OG, I-OG, B-DT, I-DT, B-TI, I-TI, B-QT, and I-QT. We exclude the majority negative entity class (O), to focus on positive entities.</p>
</div>
</section>
<section id="S3.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.3 </span>Related Work</h4>

<div id="S3.SS4.SSS3.p1" class="ltx_para">
<p id="S3.SS4.SSS3.p1.1" class="ltx_p">CoNLL2003&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite> is the most widely used NER benchmark which covers texts from Reuters newswire articles. It handles English and German and is annotated with four named entity types (persons, locations, organizations, and miscellaneous entities). Another dataset on news articles from the Wall Street Journal, MUC (Message Understanding Conference)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, presents an extended tag set, including temporal and numerical entities. The resulting materials, e.g., MUC-6&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and MUC-7&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, which include six and seven classes of entities, respectively, are adopted as a training source for developing the Stanford NER parser&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.</p>
</div>
<div id="S3.SS4.SSS3.p2" class="ltx_para">
<p id="S3.SS4.SSS3.p2.1" class="ltx_p">To handle more informal and less sentence-like documents, WNUT16 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite> is proposed. It deals with English Twitter texts which are first suggested in TwitterNER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>. A total of 15 types of entities are labeled, more subdivided than CoNLL03 and MUC.</p>
</div>
<div id="S3.SS4.SSS3.p3" class="ltx_para">
<p id="S3.SS4.SSS3.p3.1" class="ltx_p">For Korean, there are four existing NER datasets which are published by Korea Maritime &amp; Ocean University (KMOU), Changwon University, National Institute of Korean Language (NIKL) and Electronics and Telecommunications Research Institute (ETRI). All of them follow the tagging schema of Telecommunications Technology Association (TTA).<span id="footnote28" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">28</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">28</sup><span class="ltx_tag ltx_tag_note">28</span>KMOU utilizes a modified guideline KMOU-NLP-2018-001 based on the TTA scheme, which is available in <a target="_blank" href="https://github.com/kmounlp/NER/blob/master/NER%20Guideline%20(ver%201.0).pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kmounlp/NER/blob/master/NER%20Guideline%20(ver%201.0).pdf</a></span></span></span> TTA provides a standardized named entity tagging scheme that serves as an integrated guideline for NER research in Korean. It incorporates 15 named entity tags with 146 subcategories, and provides the definition and the examples regarding each tag with the instructions on the tagging procedure.</p>
</div>
<div id="S3.SS4.SSS3.p4" class="ltx_para">
<p id="S3.SS4.SSS3.p4.1" class="ltx_p">No existing Korean NER dataset is both freely accessible and covers diverse text domains. According to <cite class="ltx_cite ltx_citemacro_citet">Cho et&nbsp;al. [<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, the NER dataset provided by Korea Maritime &amp; Ocean University (KMOU) and the dataset constructed by Changwon University are publicly accessible. The datasets provided by ETRI and NIKL are not fully public, and the usage is also restricted to domestic researchers. We overcome this issue by making KLUE NER freely available to anyone. None of the aforementioned datasets cover sentences from noisy user generated web texts, which helps model trained on those to be more robust and generalizable. Moreover, except for the KMOU dataset, all the above datasets are tagged in word level, which often conflicts with the morphological characteristics of Korean. In comparison, KLUE-NER uses web texts as source corpora and the entities are annotated in character level, thus being more practical and useful.</p>
</div>
</section>
<section id="S3.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.4 </span>Conclusion</h4>

<div id="S3.SS4.SSS4.p1" class="ltx_para">
<p id="S3.SS4.SSS4.p1.1" class="ltx_p">We construct a new Korean NER benchmark that covers broad domains and styles, which is freely accessible to anyone. The entity types are annotated so that a model has to use both morphological and contextual cues. The character-level entity tagging and evaluation method reflects the characteristics of Korean morphology. Since KLUE-NER dataset covers both formal news articles and informal user-generated web texts, we hope that our benchmark helps develop NER models that can be used in a wide a range of domains, and serve as a resource for developing advanced models for Information Extraction.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Relation Extraction (RE)</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.2" class="ltx_p">Relation extraction (RE) identifies semantic relations between entity pairs in a text. The relation is defined between an entity pair consisting of <span id="S3.SS5.p1.2.1" class="ltx_text ltx_font_italic">subject entity</span> (<math id="S3.SS5.p1.1.m1.1" class="ltx_Math" alttext="e_{\text{subj}}" display="inline"><semantics id="S3.SS5.p1.1.m1.1a"><msub id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml"><mi id="S3.SS5.p1.1.m1.1.1.2" xref="S3.SS5.p1.1.m1.1.1.2.cmml">e</mi><mtext id="S3.SS5.p1.1.m1.1.1.3" xref="S3.SS5.p1.1.m1.1.1.3a.cmml">subj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><apply id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.1.m1.1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.p1.1.m1.1.1.2.cmml" xref="S3.SS5.p1.1.m1.1.1.2">𝑒</ci><ci id="S3.SS5.p1.1.m1.1.1.3a.cmml" xref="S3.SS5.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS5.p1.1.m1.1.1.3.cmml" xref="S3.SS5.p1.1.m1.1.1.3">subj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">e_{\text{subj}}</annotation></semantics></math>) and <span id="S3.SS5.p1.2.2" class="ltx_text ltx_font_italic">object entity</span> (<math id="S3.SS5.p1.2.m2.1" class="ltx_Math" alttext="e_{\text{obj}}" display="inline"><semantics id="S3.SS5.p1.2.m2.1a"><msub id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml"><mi id="S3.SS5.p1.2.m2.1.1.2" xref="S3.SS5.p1.2.m2.1.1.2.cmml">e</mi><mtext id="S3.SS5.p1.2.m2.1.1.3" xref="S3.SS5.p1.2.m2.1.1.3a.cmml">obj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b"><apply id="S3.SS5.p1.2.m2.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.2.m2.1.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS5.p1.2.m2.1.1.2.cmml" xref="S3.SS5.p1.2.m2.1.1.2">𝑒</ci><ci id="S3.SS5.p1.2.m2.1.1.3a.cmml" xref="S3.SS5.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S3.SS5.p1.2.m2.1.1.3.cmml" xref="S3.SS5.p1.2.m2.1.1.3">obj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.1c">e_{\text{obj}}</annotation></semantics></math>). For example, in a sentence ‘Kierkegaard was born to an affluent family in Copenhagen’, the subject entity is ‘Kierkegaard’ and the object entity is ‘Copenhagen’. The goal is then to pick an appropriate relationship between these two entities; ‘<span id="S3.SS5.p1.2.3" class="ltx_text ltx_font_italic">place_of_birth</span>’.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p">RE is a task suitable for evaluating whether a model correctly understands the relationships between entities.
In order to ensure KLUE-RE captures this aspect of language understanding, we include a large-scale RE benchmark.
Because there is no large-scale RE benchmark publicly available in Korean, we collect and annotate our own dataset.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p id="S3.SS5.p3.7" class="ltx_p">We formulate RE as a single sentence classification task. A model picks one of predefined relation classes describing the relation between two entities within a given sentence. In other words, the RE model predicts an appropriate relation <math id="S3.SS5.p3.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS5.p3.1.m1.1a"><mi id="S3.SS5.p3.1.m1.1.1" xref="S3.SS5.p3.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.1.m1.1b"><ci id="S3.SS5.p3.1.m1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.1.m1.1c">r</annotation></semantics></math> of entity pair <math id="S3.SS5.p3.2.m2.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.SS5.p3.2.m2.2a"><mrow id="S3.SS5.p3.2.m2.2.2.2" xref="S3.SS5.p3.2.m2.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.p3.2.m2.2.2.2.3" xref="S3.SS5.p3.2.m2.2.2.3.cmml">(</mo><msub id="S3.SS5.p3.2.m2.1.1.1.1" xref="S3.SS5.p3.2.m2.1.1.1.1.cmml"><mi id="S3.SS5.p3.2.m2.1.1.1.1.2" xref="S3.SS5.p3.2.m2.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.p3.2.m2.1.1.1.1.3" xref="S3.SS5.p3.2.m2.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.p3.2.m2.2.2.2.4" xref="S3.SS5.p3.2.m2.2.2.3.cmml">,</mo><msub id="S3.SS5.p3.2.m2.2.2.2.2" xref="S3.SS5.p3.2.m2.2.2.2.2.cmml"><mi id="S3.SS5.p3.2.m2.2.2.2.2.2" xref="S3.SS5.p3.2.m2.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.p3.2.m2.2.2.2.2.3" xref="S3.SS5.p3.2.m2.2.2.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.p3.2.m2.2.2.2.5" xref="S3.SS5.p3.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.2.m2.2b"><interval closure="open" id="S3.SS5.p3.2.m2.2.2.3.cmml" xref="S3.SS5.p3.2.m2.2.2.2"><apply id="S3.SS5.p3.2.m2.1.1.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS5.p3.2.m2.1.1.1.1.2.cmml" xref="S3.SS5.p3.2.m2.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.p3.2.m2.1.1.1.1.3a.cmml" xref="S3.SS5.p3.2.m2.1.1.1.1.3"><mtext mathsize="70%" id="S3.SS5.p3.2.m2.1.1.1.1.3.cmml" xref="S3.SS5.p3.2.m2.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.p3.2.m2.2.2.2.2.cmml" xref="S3.SS5.p3.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.p3.2.m2.2.2.2.2.1.cmml" xref="S3.SS5.p3.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS5.p3.2.m2.2.2.2.2.2.cmml" xref="S3.SS5.p3.2.m2.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.p3.2.m2.2.2.2.2.3a.cmml" xref="S3.SS5.p3.2.m2.2.2.2.2.3"><mtext mathsize="70%" id="S3.SS5.p3.2.m2.2.2.2.2.3.cmml" xref="S3.SS5.p3.2.m2.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.2.m2.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math> in a sentence <math id="S3.SS5.p3.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS5.p3.3.m3.1a"><mi id="S3.SS5.p3.3.m3.1.1" xref="S3.SS5.p3.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.3.m3.1b"><ci id="S3.SS5.p3.3.m3.1.1.cmml" xref="S3.SS5.p3.3.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.3.m3.1c">s</annotation></semantics></math>, where <math id="S3.SS5.p3.4.m4.1" class="ltx_Math" alttext="e_{\text{subj}}" display="inline"><semantics id="S3.SS5.p3.4.m4.1a"><msub id="S3.SS5.p3.4.m4.1.1" xref="S3.SS5.p3.4.m4.1.1.cmml"><mi id="S3.SS5.p3.4.m4.1.1.2" xref="S3.SS5.p3.4.m4.1.1.2.cmml">e</mi><mtext id="S3.SS5.p3.4.m4.1.1.3" xref="S3.SS5.p3.4.m4.1.1.3a.cmml">subj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.4.m4.1b"><apply id="S3.SS5.p3.4.m4.1.1.cmml" xref="S3.SS5.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.4.m4.1.1.1.cmml" xref="S3.SS5.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS5.p3.4.m4.1.1.2.cmml" xref="S3.SS5.p3.4.m4.1.1.2">𝑒</ci><ci id="S3.SS5.p3.4.m4.1.1.3a.cmml" xref="S3.SS5.p3.4.m4.1.1.3"><mtext mathsize="70%" id="S3.SS5.p3.4.m4.1.1.3.cmml" xref="S3.SS5.p3.4.m4.1.1.3">subj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.4.m4.1c">e_{\text{subj}}</annotation></semantics></math> is the subject entity and <math id="S3.SS5.p3.5.m5.1" class="ltx_Math" alttext="e_{\text{obj}}" display="inline"><semantics id="S3.SS5.p3.5.m5.1a"><msub id="S3.SS5.p3.5.m5.1.1" xref="S3.SS5.p3.5.m5.1.1.cmml"><mi id="S3.SS5.p3.5.m5.1.1.2" xref="S3.SS5.p3.5.m5.1.1.2.cmml">e</mi><mtext id="S3.SS5.p3.5.m5.1.1.3" xref="S3.SS5.p3.5.m5.1.1.3a.cmml">obj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.5.m5.1b"><apply id="S3.SS5.p3.5.m5.1.1.cmml" xref="S3.SS5.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.5.m5.1.1.1.cmml" xref="S3.SS5.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS5.p3.5.m5.1.1.2.cmml" xref="S3.SS5.p3.5.m5.1.1.2">𝑒</ci><ci id="S3.SS5.p3.5.m5.1.1.3a.cmml" xref="S3.SS5.p3.5.m5.1.1.3"><mtext mathsize="70%" id="S3.SS5.p3.5.m5.1.1.3.cmml" xref="S3.SS5.p3.5.m5.1.1.3">obj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.5.m5.1c">e_{\text{obj}}</annotation></semantics></math> is the object entity. We refer to <math id="S3.SS5.p3.6.m6.3" class="ltx_Math" alttext="(e_{\text{subj}},r,e_{\text{obj}})" display="inline"><semantics id="S3.SS5.p3.6.m6.3a"><mrow id="S3.SS5.p3.6.m6.3.3.2" xref="S3.SS5.p3.6.m6.3.3.3.cmml"><mo stretchy="false" id="S3.SS5.p3.6.m6.3.3.2.3" xref="S3.SS5.p3.6.m6.3.3.3.cmml">(</mo><msub id="S3.SS5.p3.6.m6.2.2.1.1" xref="S3.SS5.p3.6.m6.2.2.1.1.cmml"><mi id="S3.SS5.p3.6.m6.2.2.1.1.2" xref="S3.SS5.p3.6.m6.2.2.1.1.2.cmml">e</mi><mtext id="S3.SS5.p3.6.m6.2.2.1.1.3" xref="S3.SS5.p3.6.m6.2.2.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.p3.6.m6.3.3.2.4" xref="S3.SS5.p3.6.m6.3.3.3.cmml">,</mo><mi id="S3.SS5.p3.6.m6.1.1" xref="S3.SS5.p3.6.m6.1.1.cmml">r</mi><mo id="S3.SS5.p3.6.m6.3.3.2.5" xref="S3.SS5.p3.6.m6.3.3.3.cmml">,</mo><msub id="S3.SS5.p3.6.m6.3.3.2.2" xref="S3.SS5.p3.6.m6.3.3.2.2.cmml"><mi id="S3.SS5.p3.6.m6.3.3.2.2.2" xref="S3.SS5.p3.6.m6.3.3.2.2.2.cmml">e</mi><mtext id="S3.SS5.p3.6.m6.3.3.2.2.3" xref="S3.SS5.p3.6.m6.3.3.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.p3.6.m6.3.3.2.6" xref="S3.SS5.p3.6.m6.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.6.m6.3b"><vector id="S3.SS5.p3.6.m6.3.3.3.cmml" xref="S3.SS5.p3.6.m6.3.3.2"><apply id="S3.SS5.p3.6.m6.2.2.1.1.cmml" xref="S3.SS5.p3.6.m6.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.6.m6.2.2.1.1.1.cmml" xref="S3.SS5.p3.6.m6.2.2.1.1">subscript</csymbol><ci id="S3.SS5.p3.6.m6.2.2.1.1.2.cmml" xref="S3.SS5.p3.6.m6.2.2.1.1.2">𝑒</ci><ci id="S3.SS5.p3.6.m6.2.2.1.1.3a.cmml" xref="S3.SS5.p3.6.m6.2.2.1.1.3"><mtext mathsize="70%" id="S3.SS5.p3.6.m6.2.2.1.1.3.cmml" xref="S3.SS5.p3.6.m6.2.2.1.1.3">subj</mtext></ci></apply><ci id="S3.SS5.p3.6.m6.1.1.cmml" xref="S3.SS5.p3.6.m6.1.1">𝑟</ci><apply id="S3.SS5.p3.6.m6.3.3.2.2.cmml" xref="S3.SS5.p3.6.m6.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.p3.6.m6.3.3.2.2.1.cmml" xref="S3.SS5.p3.6.m6.3.3.2.2">subscript</csymbol><ci id="S3.SS5.p3.6.m6.3.3.2.2.2.cmml" xref="S3.SS5.p3.6.m6.3.3.2.2.2">𝑒</ci><ci id="S3.SS5.p3.6.m6.3.3.2.2.3a.cmml" xref="S3.SS5.p3.6.m6.3.3.2.2.3"><mtext mathsize="70%" id="S3.SS5.p3.6.m6.3.3.2.2.3.cmml" xref="S3.SS5.p3.6.m6.3.3.2.2.3">obj</mtext></ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.6.m6.3c">(e_{\text{subj}},r,e_{\text{obj}})</annotation></semantics></math> as a relation triplet. The entities are marked as corresponding spans in each sentence <math id="S3.SS5.p3.7.m7.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS5.p3.7.m7.1a"><mi id="S3.SS5.p3.7.m7.1.1" xref="S3.SS5.p3.7.m7.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.7.m7.1b"><ci id="S3.SS5.p3.7.m7.1.1.cmml" xref="S3.SS5.p3.7.m7.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.7.m7.1c">s</annotation></semantics></math>. There are 30 relation classes that consist of 18 person-related relations, 11 organization-related relations, and <span id="S3.SS5.p3.7.1" class="ltx_text ltx_font_italic">no_relation</span>. Detailed explanation of these classes are presented in Table&nbsp;<a href="#S3.T10" title="Table 10 ‣ 3.5.1 Data Construction ‣ 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. We evaluate a model using micro F1 score, computed after excluding <span id="S3.SS5.p3.7.2" class="ltx_text ltx_font_italic">no_relation</span>, and area under the precision-recall curve including all 30 classes.</p>
</div>
<section id="S3.SS5.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.1 </span>Data Construction</h4>

<div id="S3.SS5.SSS1.p1" class="ltx_para">
<p id="S3.SS5.SSS1.p1.4" class="ltx_p">Distant supervision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> is a popular way to build a large-scale RE benchmark. It leverages relation triplets <math id="S3.SS5.SSS1.p1.1.m1.3" class="ltx_Math" alttext="(e_{\text{subj}},r,e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.p1.1.m1.3a"><mrow id="S3.SS5.SSS1.p1.1.m1.3.3.2" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.p1.1.m1.3.3.2.3" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml">(</mo><msub id="S3.SS5.SSS1.p1.1.m1.2.2.1.1" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.cmml"><mi id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.2" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.p1.1.m1.3.3.2.4" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml">,</mo><mi id="S3.SS5.SSS1.p1.1.m1.1.1" xref="S3.SS5.SSS1.p1.1.m1.1.1.cmml">r</mi><mo id="S3.SS5.SSS1.p1.1.m1.3.3.2.5" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS5.SSS1.p1.1.m1.3.3.2.2" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.cmml"><mi id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.2" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.p1.1.m1.3.3.2.6" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p1.1.m1.3b"><vector id="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2"><apply id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.cmml" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3a.cmml" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3.cmml" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3">subj</mtext></ci></apply><ci id="S3.SS5.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS1.p1.1.m1.1.1">𝑟</ci><apply id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.1.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3a.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3">obj</mtext></ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p1.1.m1.3c">(e_{\text{subj}},r,e_{\text{obj}})</annotation></semantics></math> in existing large-scale knowledge base (KB) such as Freebase. If a sentence <math id="S3.SS5.SSS1.p1.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS5.SSS1.p1.2.m2.1a"><mi id="S3.SS5.SSS1.p1.2.m2.1.1" xref="S3.SS5.SSS1.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p1.2.m2.1b"><ci id="S3.SS5.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.p1.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p1.2.m2.1c">s</annotation></semantics></math> in a large corpora includes <math id="S3.SS5.SSS1.p1.3.m3.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.p1.3.m3.2a"><mrow id="S3.SS5.SSS1.p1.3.m3.2.2.2" xref="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.p1.3.m3.2.2.2.3" xref="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.p1.3.m3.1.1.1.1" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.2" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.p1.3.m3.2.2.2.4" xref="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.p1.3.m3.2.2.2.2" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.2" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.p1.3.m3.2.2.2.5" xref="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p1.3.m3.2b"><interval closure="open" id="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2"><apply id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.cmml" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p1.3.m3.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math> detected by an NER model simultaneously, it is added to the dataset with relation label <math id="S3.SS5.SSS1.p1.4.m4.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS5.SSS1.p1.4.m4.1a"><mi id="S3.SS5.SSS1.p1.4.m4.1.1" xref="S3.SS5.SSS1.p1.4.m4.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p1.4.m4.1b"><ci id="S3.SS5.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS5.SSS1.p1.4.m4.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p1.4.m4.1c">r</annotation></semantics></math> by assuming any sentence which contains the pair will express that relation. This approach does not require expensive human annotation, thus allowing us to build a large-scale RE benchmark in a cost-effective way.</p>
</div>
<div id="S3.SS5.SSS1.p2" class="ltx_para">
<p id="S3.SS5.SSS1.p2.1" class="ltx_p">Despite this advantage, distant supervision often ends up with incorrect relation labels when the assumption is not satisfied. In particular, it only considers pairs of entities which are related to each other, which results in an RE model trained on such corpus to over-predict the existence of some relationship between any given pair of entities.
In other words, the predicted relation class distribution from such predictors is not realistic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>. <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Nam et&nbsp;al. [<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite> thus propose to employ crowdworkers to alleviate erroneous relations extracted by distant supervision. <cite class="ltx_cite ltx_citemacro_citet">Riedel et&nbsp;al. [<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite> furthermore intentionally collect irrelevant entity pairs to prevent RE models from overly predicting false positives relations.</p>
</div>
<figure id="S3.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 10: </span>30 relation classes defined in the relation schema of KLUE-RE. Relation class <math id="S3.T10.2.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.T10.2.m1.1b"><mi id="S3.T10.2.m1.1.1" xref="S3.T10.2.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.T10.2.m1.1c"><ci id="S3.T10.2.m1.1.1.cmml" xref="S3.T10.2.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T10.2.m1.1d">r</annotation></semantics></math> should be one of the followings which consist of 18 person-related relations, 11 organization-related relations, and <span id="S3.T10.9.1" class="ltx_text ltx_font_italic">no_relation</span>.</figcaption>
<table id="S3.T10.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T10.3.2" class="ltx_tr">
<td id="S3.T10.3.2.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T10.3.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Relation Class</span></td>
<td id="S3.T10.3.2.2" class="ltx_td ltx_align_justify ltx_border_tt">
<span id="S3.T10.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.2.2.1.1" class="ltx_p"><span id="S3.T10.3.2.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Description</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.1" class="ltx_tr">
<td id="S3.T10.3.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T10.3.1.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">no_relation</span></td>
<td id="S3.T10.3.1.1" class="ltx_td ltx_align_justify ltx_border_t">
<span id="S3.T10.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.1.1.1.1" class="ltx_p"><span id="S3.T10.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">No relation in between </span><math id="S3.T10.3.1.1.1.1.m1.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.T10.3.1.1.1.1.m1.2a"><mrow id="S3.T10.3.1.1.1.1.m1.2.2.2" xref="S3.T10.3.1.1.1.1.m1.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.3" xref="S3.T10.3.1.1.1.1.m1.2.2.3.cmml">(</mo><msub id="S3.T10.3.1.1.1.1.m1.1.1.1.1" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.T10.3.1.1.1.1.m1.1.1.1.1.2" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.2.cmml">e</mi><mtext mathsize="90%" id="S3.T10.3.1.1.1.1.m1.1.1.1.1.3" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.3a.cmml">subj</mtext></msub><mo mathsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.4" xref="S3.T10.3.1.1.1.1.m1.2.2.3.cmml">,</mo><msub id="S3.T10.3.1.1.1.1.m1.2.2.2.2" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.cmml"><mi mathsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.2.2" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.2.cmml">e</mi><mtext mathsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.2.3" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.3a.cmml">obj</mtext></msub><mo maxsize="90%" minsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.5" xref="S3.T10.3.1.1.1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T10.3.1.1.1.1.m1.2b"><interval closure="open" id="S3.T10.3.1.1.1.1.m1.2.2.3.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2"><apply id="S3.T10.3.1.1.1.1.m1.1.1.1.1.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.T10.3.1.1.1.1.m1.1.1.1.1.1.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.T10.3.1.1.1.1.m1.1.1.1.1.2.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.2">𝑒</ci><ci id="S3.T10.3.1.1.1.1.m1.1.1.1.1.3a.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.3"><mtext mathsize="63%" id="S3.T10.3.1.1.1.1.m1.1.1.1.1.3.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.T10.3.1.1.1.1.m1.2.2.2.2.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.T10.3.1.1.1.1.m1.2.2.2.2.1.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.T10.3.1.1.1.1.m1.2.2.2.2.2.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.2">𝑒</ci><ci id="S3.T10.3.1.1.1.1.m1.2.2.2.2.3a.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.3"><mtext mathsize="63%" id="S3.T10.3.1.1.1.1.m1.2.2.2.2.3.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.T10.3.1.1.1.1.m1.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.3" class="ltx_tr">
<td id="S3.T10.3.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T10.3.3.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:dissolved</span></td>
<td id="S3.T10.3.3.2" class="ltx_td ltx_align_justify ltx_border_t">
<span id="S3.T10.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.3.2.1.1" class="ltx_p"><span id="S3.T10.3.3.2.1.1.1" class="ltx_text" style="font-size:90%;">The date when the specified organization was dissolved</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.4" class="ltx_tr">
<td id="S3.T10.3.4.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.4.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:founded</span></td>
<td id="S3.T10.3.4.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.4.2.1.1" class="ltx_p"><span id="S3.T10.3.4.2.1.1.1" class="ltx_text" style="font-size:90%;">The date when the specified organization was founded</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.5" class="ltx_tr">
<td id="S3.T10.3.5.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.5.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:place_of_headquarters</span></td>
<td id="S3.T10.3.5.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.5.2.1.1" class="ltx_p"><span id="S3.T10.3.5.2.1.1.1" class="ltx_text" style="font-size:90%;">The place which the headquarters of the specified organization are located in</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.6" class="ltx_tr">
<td id="S3.T10.3.6.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.6.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:alternate_names</span></td>
<td id="S3.T10.3.6.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.6.2.1.1" class="ltx_p"><span id="S3.T10.3.6.2.1.1.1" class="ltx_text" style="font-size:90%;">Alternative names called instead of the official name to refer to the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.7" class="ltx_tr">
<td id="S3.T10.3.7.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.7.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:member_of</span></td>
<td id="S3.T10.3.7.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.7.2.1.1" class="ltx_p"><span id="S3.T10.3.7.2.1.1.1" class="ltx_text" style="font-size:90%;">Organizations to which the specified organization belongs</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.8" class="ltx_tr">
<td id="S3.T10.3.8.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.8.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:members</span></td>
<td id="S3.T10.3.8.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.8.2.1.1" class="ltx_p"><span id="S3.T10.3.8.2.1.1.1" class="ltx_text" style="font-size:90%;">Organizations which belong to the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.9" class="ltx_tr">
<td id="S3.T10.3.9.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.9.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:political/religious_affiliation</span></td>
<td id="S3.T10.3.9.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.9.2.1.1" class="ltx_p"><span id="S3.T10.3.9.2.1.1.1" class="ltx_text" style="font-size:90%;">Political/religious groups which the specified organization is affiliated in</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.10" class="ltx_tr">
<td id="S3.T10.3.10.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.10.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:product</span></td>
<td id="S3.T10.3.10.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.10.2.1.1" class="ltx_p"><span id="S3.T10.3.10.2.1.1.1" class="ltx_text" style="font-size:90%;">Products or merchandise produced by the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.11" class="ltx_tr">
<td id="S3.T10.3.11.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.11.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:founded_by</span></td>
<td id="S3.T10.3.11.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.11.2.1.1" class="ltx_p"><span id="S3.T10.3.11.2.1.1.1" class="ltx_text" style="font-size:90%;">The person or organization that founded the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.12" class="ltx_tr">
<td id="S3.T10.3.12.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.12.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:top_members/employees</span></td>
<td id="S3.T10.3.12.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.12.2.1.1" class="ltx_p"><span id="S3.T10.3.12.2.1.1.1" class="ltx_text" style="font-size:90%;">The representative(s) or members of the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.13" class="ltx_tr">
<td id="S3.T10.3.13.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.13.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:number_of_employees/members</span></td>
<td id="S3.T10.3.13.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.13.2.1.1" class="ltx_p"><span id="S3.T10.3.13.2.1.1.1" class="ltx_text" style="font-size:90%;">The total number of members that are affiliated in the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.14" class="ltx_tr">
<td id="S3.T10.3.14.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T10.3.14.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:date_of_birth</span></td>
<td id="S3.T10.3.14.2" class="ltx_td ltx_align_justify ltx_border_t">
<span id="S3.T10.3.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.14.2.1.1" class="ltx_p"><span id="S3.T10.3.14.2.1.1.1" class="ltx_text" style="font-size:90%;">The date when the specified person was born</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.15" class="ltx_tr">
<td id="S3.T10.3.15.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.15.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:date_of_death</span></td>
<td id="S3.T10.3.15.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.15.2.1.1" class="ltx_p"><span id="S3.T10.3.15.2.1.1.1" class="ltx_text" style="font-size:90%;">The date when the specified person died</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.16" class="ltx_tr">
<td id="S3.T10.3.16.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.16.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:place_of_birth</span></td>
<td id="S3.T10.3.16.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.16.2.1.1" class="ltx_p"><span id="S3.T10.3.16.2.1.1.1" class="ltx_text" style="font-size:90%;">The place where the specified person was born</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.17" class="ltx_tr">
<td id="S3.T10.3.17.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.17.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:place_of_death</span></td>
<td id="S3.T10.3.17.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.17.2.1.1" class="ltx_p"><span id="S3.T10.3.17.2.1.1.1" class="ltx_text" style="font-size:90%;">The place where the specified person died</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.18" class="ltx_tr">
<td id="S3.T10.3.18.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.18.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:place_of_residence</span></td>
<td id="S3.T10.3.18.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.18.2.1.1" class="ltx_p"><span id="S3.T10.3.18.2.1.1.1" class="ltx_text" style="font-size:90%;">The place where the specified person lives</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.19" class="ltx_tr">
<td id="S3.T10.3.19.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.19.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:origin</span></td>
<td id="S3.T10.3.19.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.19.2.1.1" class="ltx_p"><span id="S3.T10.3.19.2.1.1.1" class="ltx_text" style="font-size:90%;">The origins or the nationality of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.20" class="ltx_tr">
<td id="S3.T10.3.20.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.20.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:employee_of</span></td>
<td id="S3.T10.3.20.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.20.2.1.1" class="ltx_p"><span id="S3.T10.3.20.2.1.1.1" class="ltx_text" style="font-size:90%;">The organization where the specified person works</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.21" class="ltx_tr">
<td id="S3.T10.3.21.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.21.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:schools_attended</span></td>
<td id="S3.T10.3.21.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.21.2.1.1" class="ltx_p"><span id="S3.T10.3.21.2.1.1.1" class="ltx_text" style="font-size:90%;">A school where the specified person attended</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.22" class="ltx_tr">
<td id="S3.T10.3.22.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.22.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:alternate_names</span></td>
<td id="S3.T10.3.22.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.22.2.1.1" class="ltx_p"><span id="S3.T10.3.22.2.1.1.1" class="ltx_text" style="font-size:90%;">Alternative names called instead of the official name to refer to the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.23" class="ltx_tr">
<td id="S3.T10.3.23.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.23.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:parents</span></td>
<td id="S3.T10.3.23.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.23.2.1.1" class="ltx_p"><span id="S3.T10.3.23.2.1.1.1" class="ltx_text" style="font-size:90%;">The parents of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.24" class="ltx_tr">
<td id="S3.T10.3.24.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.24.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:children</span></td>
<td id="S3.T10.3.24.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.24.2.1.1" class="ltx_p"><span id="S3.T10.3.24.2.1.1.1" class="ltx_text" style="font-size:90%;">The children of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.25" class="ltx_tr">
<td id="S3.T10.3.25.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.25.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:siblings</span></td>
<td id="S3.T10.3.25.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.25.2.1.1" class="ltx_p"><span id="S3.T10.3.25.2.1.1.1" class="ltx_text" style="font-size:90%;">The brothers and sisters of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.26" class="ltx_tr">
<td id="S3.T10.3.26.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.26.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:spouse</span></td>
<td id="S3.T10.3.26.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.26.2.1.1" class="ltx_p"><span id="S3.T10.3.26.2.1.1.1" class="ltx_text" style="font-size:90%;">The spouse(s) of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.27" class="ltx_tr">
<td id="S3.T10.3.27.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.27.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:other_family</span></td>
<td id="S3.T10.3.27.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.27.2.1.1" class="ltx_p"><span id="S3.T10.3.27.2.1.1.1" class="ltx_text" style="font-size:90%;">Family members of the specified person other than parents, children, siblings, and spouse(s)</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.28" class="ltx_tr">
<td id="S3.T10.3.28.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.28.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:colleagues</span></td>
<td id="S3.T10.3.28.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.28.2.1.1" class="ltx_p"><span id="S3.T10.3.28.2.1.1.1" class="ltx_text" style="font-size:90%;">People who work together with the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.29" class="ltx_tr">
<td id="S3.T10.3.29.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.29.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:product</span></td>
<td id="S3.T10.3.29.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.29.2.1.1" class="ltx_p"><span id="S3.T10.3.29.2.1.1.1" class="ltx_text" style="font-size:90%;">Products or artworks produced by the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.30" class="ltx_tr">
<td id="S3.T10.3.30.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.30.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:religion</span></td>
<td id="S3.T10.3.30.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.30.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.30.2.1.1" class="ltx_p"><span id="S3.T10.3.30.2.1.1.1" class="ltx_text" style="font-size:90%;">The religion in which the specified person believes</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.31" class="ltx_tr">
<td id="S3.T10.3.31.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T10.3.31.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:title</span></td>
<td id="S3.T10.3.31.2" class="ltx_td ltx_align_justify ltx_border_bb">
<span id="S3.T10.3.31.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.31.2.1.1" class="ltx_p"><span id="S3.T10.3.31.2.1.1.1" class="ltx_text" style="font-size:90%;">Official or unofficial names that represent the occupational position of the specified person</span></span>
</span>
</td>
</tr>
</tbody></table>
</figure>
<section id="S3.SS5.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Overview</h5>

<div id="S3.SS5.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS5.SSS1.Px1.p1.2" class="ltx_p">We modify the original strategy of distant supervision above, to address this weakness and to better fit our situation. First, we collect triplets <math id="S3.SS5.SSS1.Px1.p1.1.m1.3" class="ltx_Math" alttext="(e_{\text{subj}},r,e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.Px1.p1.1.m1.3a"><mrow id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.3" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.cmml"><mi id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.2" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.4" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml">,</mo><mi id="S3.SS5.SSS1.Px1.p1.1.m1.1.1" xref="S3.SS5.SSS1.Px1.p1.1.m1.1.1.cmml">r</mi><mo id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.5" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.cmml"><mi id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.2" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.6" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px1.p1.1.m1.3b"><vector id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2"><apply id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3a.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3">subj</mtext></ci></apply><ci id="S3.SS5.SSS1.Px1.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.1.1">𝑟</ci><apply id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.1.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3a.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3">obj</mtext></ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px1.p1.1.m1.3c">(e_{\text{subj}},r,e_{\text{obj}})</annotation></semantics></math> from a small Korean KB<span id="footnote29" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">29</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">29</sup><span class="ltx_tag ltx_tag_note">29</span>
<a target="_blank" href="https://aihub.or.kr/aidata/84" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aihub.or.kr/aidata/84</a>
</span></span></span>
and build additional ones by parsing the infoboxes in WIKIPEDIA and NAMUWIKI<span id="footnote30" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">30</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">30</sup><span class="ltx_tag ltx_tag_note">30</span>
<a target="_blank" href="https://namu.wiki" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://namu.wiki</a>
</span></span></span>
to enlarge the pool of the candidate triplets. We then ask crowdworkers to select the correct relation class of each candidate triplet within a sentence, compared to distant supervision which directly uses automatically generated relation labels.
In addition, we randomly sample entity pairs in <math id="S3.SS5.SSS1.Px1.p1.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS5.SSS1.Px1.p1.2.m2.1a"><mi id="S3.SS5.SSS1.Px1.p1.2.m2.1.1" xref="S3.SS5.SSS1.Px1.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px1.p1.2.m2.1b"><ci id="S3.SS5.SSS1.Px1.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px1.p1.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px1.p1.2.m2.1c">s</annotation></semantics></math> to obtain more realistic relation class distribution in our benchmark. Those examples would include unseen entities in existing KB as well as have higher chance to be irrelevant (<span id="S3.SS5.SSS1.Px1.p1.2.1" class="ltx_text ltx_font_italic">no_relation</span>).</p>
</div>
<div id="S3.SS5.SSS1.Px1.p2" class="ltx_para">
<p id="S3.SS5.SSS1.Px1.p2.1" class="ltx_p">This procedure can be divided into five steps; (1) candidate sentence collection, (2) relation schema definition, (3) entity detection, (4) entity pair selection and (5) relation annotation. We elaborate each step in the rest of this section.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">1. Collect Candidate Sentences</h5>

<div id="S3.SS5.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS5.SSS1.Px2.p1.1" class="ltx_p">We sample candidate sentences from WIKIPEDIA, WIKITREE and POLICY corpora to cover a diverse set of named entities and relational facts. Since our task deals with single sentences, we exploit individual sentences split by Korean Sentence Splitter <span id="footnote31" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">31</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">31</sup><span class="ltx_tag ltx_tag_note">31</span>
<a target="_blank" href="https://github.com/hyunwoongko/kss" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/hyunwoongko/kss</a>
</span></span></span> at the preprocessing step.
We filter out sentences that contain undesirable social bias and are considered hate speech, using a classifier trained on the Korean hate speech dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2. Define Relation Schema</h5>

<div id="S3.SS5.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS5.SSS1.Px3.p1.2" class="ltx_p">We design a relation schema based on the schema from Text Analysis Conference Knowledge Base Population (TAC-KBP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. Our schema defines entity types and relation classes. Similar to TAC-KBP, we constrain <math id="S3.SS5.SSS1.Px3.p1.1.m1.1" class="ltx_Math" alttext="e_{\text{subj}}" display="inline"><semantics id="S3.SS5.SSS1.Px3.p1.1.m1.1a"><msub id="S3.SS5.SSS1.Px3.p1.1.m1.1.1" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.cmml"><mi id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.2" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3a.cmml">subj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px3.p1.1.m1.1b"><apply id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3.cmml" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3">subj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px3.p1.1.m1.1c">e_{\text{subj}}</annotation></semantics></math> to be of either PER (Person) or ORG (Organization) type. <math id="S3.SS5.SSS1.Px3.p1.2.m2.1" class="ltx_Math" alttext="e_{\text{obj}}" display="inline"><semantics id="S3.SS5.SSS1.Px3.p1.2.m2.1a"><msub id="S3.SS5.SSS1.Px3.p1.2.m2.1.1" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.cmml"><mi id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.2" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3a.cmml">obj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px3.p1.2.m2.1b"><apply id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.1.cmml" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.2.cmml" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3a.cmml" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3.cmml" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3">obj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px3.p1.2.m2.1c">e_{\text{obj}}</annotation></semantics></math> can have one of the following types: PER, ORG, LOC (Location), DAT (Date and time), POH (Other proper nouns), and NOH (Other numerals). For the relation classes, we adapt the original classes in TAC-KBP to our corpus, following <cite class="ltx_cite ltx_citemacro_citet">Yu et&nbsp;al. [<a href="#bib.bib149" title="" class="ltx_ref">149</a>]</cite>.</p>
</div>
<div id="S3.SS5.SSS1.Px3.p2" class="ltx_para">
<p id="S3.SS5.SSS1.Px3.p2.1" class="ltx_p">We remove rarely appearing relation classes in our corpus such as <span id="S3.SS5.SSS1.Px3.p2.1.1" class="ltx_text ltx_font_italic">org:website</span>, <span id="S3.SS5.SSS1.Px3.p2.1.2" class="ltx_text ltx_font_italic">per:shareholders</span>, <span id="S3.SS5.SSS1.Px3.p2.1.3" class="ltx_text ltx_font_italic">per:cause_of_death</span>, <span id="S3.SS5.SSS1.Px3.p2.1.4" class="ltx_text ltx_font_italic">per:charges</span>, and <span id="S3.SS5.SSS1.Px3.p2.1.5" class="ltx_text ltx_font_italic">per:age</span>. For the same reason, we incorporate <span id="S3.SS5.SSS1.Px3.p2.1.6" class="ltx_text ltx_font_italic">org:parents</span> into <span id="S3.SS5.SSS1.Px3.p2.1.7" class="ltx_text ltx_font_italic">org:member_of</span> and <span id="S3.SS5.SSS1.Px3.p2.1.8" class="ltx_text ltx_font_italic">org:subsidiaries</span> into <span id="S3.SS5.SSS1.Px3.p2.1.9" class="ltx_text ltx_font_italic">org:members</span>.
Since the taxonomy of TAC-KBP does not precisely reflect the regional hierarchy of Korea, we integrate the prefixes <span id="S3.SS5.SSS1.Px3.p2.1.10" class="ltx_text ltx_font_italic">country_of</span>, <span id="S3.SS5.SSS1.Px3.p2.1.11" class="ltx_text ltx_font_italic">city_of</span>, and <span id="S3.SS5.SSS1.Px3.p2.1.12" class="ltx_text ltx_font_italic">stateorprovince_of</span> into <span id="S3.SS5.SSS1.Px3.p2.1.13" class="ltx_text ltx_font_italic">place_of</span>.
We introduce additional classes frequently appearing in our corpus such as <span id="S3.SS5.SSS1.Px3.p2.1.14" class="ltx_text ltx_font_italic">org:product</span>, <span id="S3.SS5.SSS1.Px3.p2.1.15" class="ltx_text ltx_font_italic">per:product</span> and <span id="S3.SS5.SSS1.Px3.p2.1.16" class="ltx_text ltx_font_italic">per:colleague</span>:</p>
</div>
<div id="S3.SS5.SSS1.Px3.p3" class="ltx_para">
<ul id="S3.I4" class="ltx_itemize">
<li id="S3.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i1.p1" class="ltx_para">
<p id="S3.I4.i1.p1.1" class="ltx_p"><span id="S3.I4.i1.p1.1.1" class="ltx_text ltx_font_italic">org:product</span>: A product or merchandise produced by an organization. This includes intangible goods such as an event hosted and a business launched by the organization.</p>
</div>
</li>
<li id="S3.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i2.p1" class="ltx_para">
<p id="S3.I4.i2.p1.1" class="ltx_p"><span id="S3.I4.i2.p1.1.1" class="ltx_text ltx_font_italic">per:product</span>: A product produced by a person. Artworks (e.g. book, music, movie) or contribution to producing them.</p>
</div>
</li>
<li id="S3.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i3.p1" class="ltx_para">
<p id="S3.I4.i3.p1.1" class="ltx_p"><span id="S3.I4.i3.p1.1.1" class="ltx_text ltx_font_italic">per:colleague</span>: A person could be a colleague of someone if they work together. Two people in the same group such as political party or alliance are colleagues as well.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS5.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">3. Detect Entities</h5>

<div id="S3.SS5.SSS1.Px4.p1" class="ltx_para">
<p id="S3.SS5.SSS1.Px4.p1.1" class="ltx_p">We automatically detect named entities in all candidate sentences. We fine-tune a pre-trained ELECTRA for Korean<span id="footnote32" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">32</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">32</sup><span class="ltx_tag ltx_tag_note">32</span>
<a target="_blank" href="https://github.com/monologg/KoELECTRA" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/monologg/KoELECTRA</a>
</span></span></span>
to build two named entity recognition (NER) models on two existing Korean NER resources respectively. One is provided by National Institute of Korean Language <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>, and the other is built by Korea Maritime &amp; Ocean University.<span id="footnote33" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">33</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">33</sup><span class="ltx_tag ltx_tag_note">33</span>
<a target="_blank" href="https://github.com/kmounlp/NER" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kmounlp/NER</a>
</span></span></span>
We modify the named entity types defined in these resources to be compatible with our own entity types previously defined in the schema. We take the union of both models’ predictions to extract as many entities as possible. We use crowdsourcing to correct incorrect boundaries of the detected entities, as described later.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">4. Select Entity Pairs</h5>

<div id="S3.SS5.SSS1.Px5.p1" class="ltx_para">
<p id="S3.SS5.SSS1.Px5.p1.3" class="ltx_p">We select two entities from the entity set <math id="S3.SS5.SSS1.Px5.p1.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS5.SSS1.Px5.p1.1.m1.1a"><mi id="S3.SS5.SSS1.Px5.p1.1.m1.1.1" xref="S3.SS5.SSS1.Px5.p1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p1.1.m1.1b"><ci id="S3.SS5.SSS1.Px5.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p1.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p1.1.m1.1c">E</annotation></semantics></math> of a given sentence <math id="S3.SS5.SSS1.Px5.p1.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS5.SSS1.Px5.p1.2.m2.1a"><mi id="S3.SS5.SSS1.Px5.p1.2.m2.1.1" xref="S3.SS5.SSS1.Px5.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p1.2.m2.1b"><ci id="S3.SS5.SSS1.Px5.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px5.p1.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p1.2.m2.1c">s</annotation></semantics></math> to make an entity pair <math id="S3.SS5.SSS1.Px5.p1.3.m3.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.Px5.p1.3.m3.2a"><mrow id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.3" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.2" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.4" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.2" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.5" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p1.3.m3.2b"><interval closure="open" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2"><apply id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p1.3.m3.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math>. In doing so, we take two distinct approaches; (1) KB-based sampling and (2) uniform sampling.</p>
</div>
<div id="S3.SS5.SSS1.Px5.p2" class="ltx_para">
<p id="S3.SS5.SSS1.Px5.p2.5" class="ltx_p">For the first approach, we only consider the subset of entities such that each entity pair <math id="S3.SS5.SSS1.Px5.p2.1.m1.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.Px5.p2.1.m1.2a"><mrow id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.3" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.2" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.4" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.2" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.5" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.1.m1.2b"><interval closure="open" id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2"><apply id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.1.m1.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math> appears in the pool of triplets <math id="S3.SS5.SSS1.Px5.p2.2.m2.3" class="ltx_Math" alttext="(e_{\text{subj}},r,e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.Px5.p2.2.m2.3a"><mrow id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.3" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.2" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.4" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml">,</mo><mi id="S3.SS5.SSS1.Px5.p2.2.m2.1.1" xref="S3.SS5.SSS1.Px5.p2.2.m2.1.1.cmml">r</mi><mo id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.5" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.2" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.6" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.2.m2.3b"><vector id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2"><apply id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3">subj</mtext></ci></apply><ci id="S3.SS5.SSS1.Px5.p2.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.1.1">𝑟</ci><apply id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3">obj</mtext></ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.2.m2.3c">(e_{\text{subj}},r,e_{\text{obj}})</annotation></semantics></math>. We collect these triplets from two sources. First, we create the initial pool of triplets, using a Korean KB.<span id="footnote34" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">34</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">34</sup><span class="ltx_tag ltx_tag_note">34</span>
Released by NIA, a government-funded institution. Available at <a target="_blank" href="https://aihub.or.kr/aidata/84" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aihub.or.kr/aidata/84</a>.
</span></span></span>
Because the number of triplets (<math id="S3.SS5.SSS1.Px5.p2.3.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.SS5.SSS1.Px5.p2.3.m3.1a"><mo id="S3.SS5.SSS1.Px5.p2.3.m3.1.1" xref="S3.SS5.SSS1.Px5.p2.3.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.3.m3.1b"><csymbol cd="latexml" id="S3.SS5.SSS1.Px5.p2.3.m3.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.3.m3.1c">\sim</annotation></semantics></math>800k) from the Korean KB is small compared to, for instance, that of Freebase (<math id="S3.SS5.SSS1.Px5.p2.4.m4.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.SS5.SSS1.Px5.p2.4.m4.1a"><mo id="S3.SS5.SSS1.Px5.p2.4.m4.1.1" xref="S3.SS5.SSS1.Px5.p2.4.m4.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.4.m4.1b"><csymbol cd="latexml" id="S3.SS5.SSS1.Px5.p2.4.m4.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.4.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.4.m4.1c">\sim</annotation></semantics></math>2b), we enlarge this pool of triplets by gathering and then parsing infoboxes in WIKIPEDIA and Namuwiki.
In order to avoid over-inclusion of frequent entities, such as the President of Korea,
we set an upper bound to the number of co-occurrence between <math id="S3.SS5.SSS1.Px5.p2.5.m5.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.Px5.p2.5.m5.2a"><mrow id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.3" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.2" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.4" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.2" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.5" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.5.m5.2b"><interval closure="open" id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2"><apply id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.5.m5.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math> during sampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite>.</p>
</div>
<div id="S3.SS5.SSS1.Px5.p3" class="ltx_para">
<p id="S3.SS5.SSS1.Px5.p3.3" class="ltx_p">In the second approach, <math id="S3.SS5.SSS1.Px5.p3.1.m1.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.Px5.p3.1.m1.2a"><mrow id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.3" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.2" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.4" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.2" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.5" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p3.1.m1.2b"><interval closure="open" id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2"><apply id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p3.1.m1.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math> is uniformly sampled from the entire entity set <math id="S3.SS5.SSS1.Px5.p3.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS5.SSS1.Px5.p3.2.m2.1a"><mi id="S3.SS5.SSS1.Px5.p3.2.m2.1.1" xref="S3.SS5.SSS1.Px5.p3.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p3.2.m2.1b"><ci id="S3.SS5.SSS1.Px5.p3.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px5.p3.2.m2.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p3.2.m2.1c">E</annotation></semantics></math> of a given sentence <math id="S3.SS5.SSS1.Px5.p3.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS5.SSS1.Px5.p3.3.m3.1a"><mi id="S3.SS5.SSS1.Px5.p3.3.m3.1.1" xref="S3.SS5.SSS1.Px5.p3.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p3.3.m3.1b"><ci id="S3.SS5.SSS1.Px5.p3.3.m3.1.1.cmml" xref="S3.SS5.SSS1.Px5.p3.3.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p3.3.m3.1c">s</annotation></semantics></math>, at random. Because there is no cue whether a sampled pair has any relation between them, the pair is highly likely to be irrelevant (<span id="S3.SS5.SSS1.Px5.p3.3.1" class="ltx_text ltx_font_italic">no_relation</span>). Irrelevant pairs will account for a large portion of realistic relation distribution between two arbitrary entities. Therefore, this approach helps to set up real-world scenario.
Such a pair is also likely to contain entities that are not selected in the first approach. This leads to capturing entity pairs and their relations independent of KBs.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">5. Annotate Relations</h5>

<figure id="S3.F4" class="ltx_figure"><img src="/html/2105.09680/assets/figs/re_tool.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="330" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Annotation tool for crowdsourcing. Main features are translated in English with red color.</figcaption>
</figure>
<div id="S3.SS5.SSS1.Px6.p1" class="ltx_para">
<p id="S3.SS5.SSS1.Px6.p1.2" class="ltx_p">We ask workers recruited by DeepNatural,<span id="footnote35" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">35</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">35</sup><span class="ltx_tag ltx_tag_note">35</span><a target="_blank" href="https://deepnatural.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://deepnatural.ai/</a></span></span></span> a Korean crowdsourcing platform, to annotate each entity pair <math id="S3.SS5.SSS1.Px6.p1.1.m1.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.Px6.p1.1.m1.2a"><mrow id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.3" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.2" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.4" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.2" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.5" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px6.p1.1.m1.2b"><interval closure="open" id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2"><apply id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px6.p1.1.m1.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math> with a relation label <math id="S3.SS5.SSS1.Px6.p1.2.m2.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS5.SSS1.Px6.p1.2.m2.1a"><mi id="S3.SS5.SSS1.Px6.p1.2.m2.1.1" xref="S3.SS5.SSS1.Px6.p1.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px6.p1.2.m2.1b"><ci id="S3.SS5.SSS1.Px6.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px6.p1.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px6.p1.2.m2.1c">r</annotation></semantics></math>. We instruct workers to focus on the current relationship, not ones from the past. For instance, if a person described in a sentence is a former member of a certain organization, workers are asked not to choose the relation <span id="S3.SS5.SSS1.Px6.p1.2.1" class="ltx_text ltx_font_italic">per:employee_of</span>. We also ask them to avoid relying on external knowledge, or common sense, to infer the relation from the context solely within a given sentence. Workers report examples that contain hate speech, biased expressions, or personally identifiable information. In addition, they are asked to report sentences with incorrect entity boundaries.</p>
</div>
<div id="S3.SS5.SSS1.Px6.p2" class="ltx_para">
<p id="S3.SS5.SSS1.Px6.p2.1" class="ltx_p">We employ 163 qualified workers, each of which correctly labelled at least 4 out of 5 questions during the pilot annotation phase. After the pilot phase, 3 workers are assigned to each example independently to label the relation. Figure&nbsp;<a href="#S3.F4" title="Figure 4 ‣ 5. Annotate Relations ‣ 3.5.1 Data Construction ‣ 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the annotation tool for crowdsourcing. To reduce cognitive burden of annotators, we provide a small number of candidate relations at first. The candidates consist of relations that can be defined between types of entity pair predicted by the NER models. If one cannot find appropriate <math id="S3.SS5.SSS1.Px6.p2.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS5.SSS1.Px6.p2.1.m1.1a"><mi id="S3.SS5.SSS1.Px6.p2.1.m1.1.1" xref="S3.SS5.SSS1.Px6.p2.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px6.p2.1.m1.1b"><ci id="S3.SS5.SSS1.Px6.p2.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px6.p2.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px6.p2.1.m1.1c">r</annotation></semantics></math> in the candidates, they are expanded to all relation classes.</p>
</div>
<figure id="S3.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Relation distribution of KLUE-RE.</figcaption>
<table id="S3.T11.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T11.1.1" class="ltx_tr">
<td id="S3.T11.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T11.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T11.1.1.2.1" class="ltx_text ltx_font_bold">Train</span></td>
<td id="S3.T11.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T11.1.1.3.1" class="ltx_text ltx_font_bold">Dev</span></td>
<td id="S3.T11.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T11.1.1.4.1" class="ltx_text ltx_font_bold">Test</span></td>
</tr>
<tr id="S3.T11.1.2" class="ltx_tr">
<td id="S3.T11.1.2.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.2.1.1" class="ltx_text ltx_font_bold">Relation Class</span></td>
<td id="S3.T11.1.2.2" class="ltx_td ltx_align_center ltx_border_t">Count</td>
<td id="S3.T11.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Ratio</td>
<td id="S3.T11.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Count</td>
<td id="S3.T11.1.2.5" class="ltx_td ltx_align_center ltx_border_t">Ratio</td>
<td id="S3.T11.1.2.6" class="ltx_td ltx_align_center ltx_border_t">Count</td>
<td id="S3.T11.1.2.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">Ratio</td>
</tr>
<tr id="S3.T11.1.3" class="ltx_tr">
<td id="S3.T11.1.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T11.1.3.1.1" class="ltx_text ltx_font_italic">no_relation</span></td>
<td id="S3.T11.1.3.2" class="ltx_td ltx_align_center ltx_border_t">9,534</td>
<td id="S3.T11.1.3.3" class="ltx_td ltx_align_center ltx_border_t">29.36%</td>
<td id="S3.T11.1.3.4" class="ltx_td ltx_align_center ltx_border_t">4,631</td>
<td id="S3.T11.1.3.5" class="ltx_td ltx_align_center ltx_border_t">59.64%</td>
<td id="S3.T11.1.3.6" class="ltx_td ltx_align_center ltx_border_t">4,632</td>
<td id="S3.T11.1.3.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">59.64%</td>
</tr>
<tr id="S3.T11.1.4" class="ltx_tr">
<td id="S3.T11.1.4.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T11.1.4.1.1" class="ltx_text ltx_font_italic">org:dissolved</span></td>
<td id="S3.T11.1.4.2" class="ltx_td ltx_align_center ltx_border_t">66</td>
<td id="S3.T11.1.4.3" class="ltx_td ltx_align_center ltx_border_t">0.20%</td>
<td id="S3.T11.1.4.4" class="ltx_td ltx_align_center ltx_border_t">11</td>
<td id="S3.T11.1.4.5" class="ltx_td ltx_align_center ltx_border_t">0.14%</td>
<td id="S3.T11.1.4.6" class="ltx_td ltx_align_center ltx_border_t">10</td>
<td id="S3.T11.1.4.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.13%</td>
</tr>
<tr id="S3.T11.1.5" class="ltx_tr">
<td id="S3.T11.1.5.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.5.1.1" class="ltx_text ltx_font_italic">org:founded</span></td>
<td id="S3.T11.1.5.2" class="ltx_td ltx_align_center">450</td>
<td id="S3.T11.1.5.3" class="ltx_td ltx_align_center">1.39%</td>
<td id="S3.T11.1.5.4" class="ltx_td ltx_align_center">20</td>
<td id="S3.T11.1.5.5" class="ltx_td ltx_align_center">0.26%</td>
<td id="S3.T11.1.5.6" class="ltx_td ltx_align_center">20</td>
<td id="S3.T11.1.5.7" class="ltx_td ltx_nopad_r ltx_align_center">0.26%</td>
</tr>
<tr id="S3.T11.1.6" class="ltx_tr">
<td id="S3.T11.1.6.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.6.1.1" class="ltx_text ltx_font_italic">org:place_of_headquarters</span></td>
<td id="S3.T11.1.6.2" class="ltx_td ltx_align_center">1,195</td>
<td id="S3.T11.1.6.3" class="ltx_td ltx_align_center">3.68%</td>
<td id="S3.T11.1.6.4" class="ltx_td ltx_align_center">194</td>
<td id="S3.T11.1.6.5" class="ltx_td ltx_align_center">2.50%</td>
<td id="S3.T11.1.6.6" class="ltx_td ltx_align_center">193</td>
<td id="S3.T11.1.6.7" class="ltx_td ltx_nopad_r ltx_align_center">2.49%</td>
</tr>
<tr id="S3.T11.1.7" class="ltx_tr">
<td id="S3.T11.1.7.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.7.1.1" class="ltx_text ltx_font_italic">org:alternate_names</span></td>
<td id="S3.T11.1.7.2" class="ltx_td ltx_align_center">1,320</td>
<td id="S3.T11.1.7.3" class="ltx_td ltx_align_center">4.07%</td>
<td id="S3.T11.1.7.4" class="ltx_td ltx_align_center">78</td>
<td id="S3.T11.1.7.5" class="ltx_td ltx_align_center">1.00%</td>
<td id="S3.T11.1.7.6" class="ltx_td ltx_align_center">77</td>
<td id="S3.T11.1.7.7" class="ltx_td ltx_nopad_r ltx_align_center">0.99%</td>
</tr>
<tr id="S3.T11.1.8" class="ltx_tr">
<td id="S3.T11.1.8.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.8.1.1" class="ltx_text ltx_font_italic">org:member_of</span></td>
<td id="S3.T11.1.8.2" class="ltx_td ltx_align_center">1,866</td>
<td id="S3.T11.1.8.3" class="ltx_td ltx_align_center">5.75%</td>
<td id="S3.T11.1.8.4" class="ltx_td ltx_align_center">104</td>
<td id="S3.T11.1.8.5" class="ltx_td ltx_align_center">1.34%</td>
<td id="S3.T11.1.8.6" class="ltx_td ltx_align_center">105</td>
<td id="S3.T11.1.8.7" class="ltx_td ltx_nopad_r ltx_align_center">1.35%</td>
</tr>
<tr id="S3.T11.1.9" class="ltx_tr">
<td id="S3.T11.1.9.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.9.1.1" class="ltx_text ltx_font_italic">org:members</span></td>
<td id="S3.T11.1.9.2" class="ltx_td ltx_align_center">420</td>
<td id="S3.T11.1.9.3" class="ltx_td ltx_align_center">1.29%</td>
<td id="S3.T11.1.9.4" class="ltx_td ltx_align_center">122</td>
<td id="S3.T11.1.9.5" class="ltx_td ltx_align_center">1.57%</td>
<td id="S3.T11.1.9.6" class="ltx_td ltx_align_center">122</td>
<td id="S3.T11.1.9.7" class="ltx_td ltx_nopad_r ltx_align_center">1.57%</td>
</tr>
<tr id="S3.T11.1.10" class="ltx_tr">
<td id="S3.T11.1.10.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.10.1.1" class="ltx_text ltx_font_italic">org:political/religious_affiliation</span></td>
<td id="S3.T11.1.10.2" class="ltx_td ltx_align_center">98</td>
<td id="S3.T11.1.10.3" class="ltx_td ltx_align_center">0.30%</td>
<td id="S3.T11.1.10.4" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.10.5" class="ltx_td ltx_align_center">0.17%</td>
<td id="S3.T11.1.10.6" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.10.7" class="ltx_td ltx_nopad_r ltx_align_center">0.17%</td>
</tr>
<tr id="S3.T11.1.11" class="ltx_tr">
<td id="S3.T11.1.11.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.11.1.1" class="ltx_text ltx_font_italic">org:product</span></td>
<td id="S3.T11.1.11.2" class="ltx_td ltx_align_center">380</td>
<td id="S3.T11.1.11.3" class="ltx_td ltx_align_center">1.17%</td>
<td id="S3.T11.1.11.4" class="ltx_td ltx_align_center">235</td>
<td id="S3.T11.1.11.5" class="ltx_td ltx_align_center">3.03%</td>
<td id="S3.T11.1.11.6" class="ltx_td ltx_align_center">235</td>
<td id="S3.T11.1.11.7" class="ltx_td ltx_nopad_r ltx_align_center">3.03%</td>
</tr>
<tr id="S3.T11.1.12" class="ltx_tr">
<td id="S3.T11.1.12.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.12.1.1" class="ltx_text ltx_font_italic">org:founded_by</span></td>
<td id="S3.T11.1.12.2" class="ltx_td ltx_align_center">155</td>
<td id="S3.T11.1.12.3" class="ltx_td ltx_align_center">0.48%</td>
<td id="S3.T11.1.12.4" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.12.5" class="ltx_td ltx_align_center">0.14%</td>
<td id="S3.T11.1.12.6" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.12.7" class="ltx_td ltx_nopad_r ltx_align_center">0.14%</td>
</tr>
<tr id="S3.T11.1.13" class="ltx_tr">
<td id="S3.T11.1.13.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.13.1.1" class="ltx_text ltx_font_italic">org:top_members/employees</span></td>
<td id="S3.T11.1.13.2" class="ltx_td ltx_align_center">4,284</td>
<td id="S3.T11.1.13.3" class="ltx_td ltx_align_center">13.19%</td>
<td id="S3.T11.1.13.4" class="ltx_td ltx_align_center">513</td>
<td id="S3.T11.1.13.5" class="ltx_td ltx_align_center">6.61%</td>
<td id="S3.T11.1.13.6" class="ltx_td ltx_align_center">514</td>
<td id="S3.T11.1.13.7" class="ltx_td ltx_nopad_r ltx_align_center">6.62%</td>
</tr>
<tr id="S3.T11.1.14" class="ltx_tr">
<td id="S3.T11.1.14.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.14.1.1" class="ltx_text ltx_font_italic">org:number_of_employees/members</span></td>
<td id="S3.T11.1.14.2" class="ltx_td ltx_align_center">48</td>
<td id="S3.T11.1.14.3" class="ltx_td ltx_align_center">0.15%</td>
<td id="S3.T11.1.14.4" class="ltx_td ltx_align_center">17</td>
<td id="S3.T11.1.14.5" class="ltx_td ltx_align_center">0.22%</td>
<td id="S3.T11.1.14.6" class="ltx_td ltx_align_center">18</td>
<td id="S3.T11.1.14.7" class="ltx_td ltx_nopad_r ltx_align_center">0.23%</td>
</tr>
<tr id="S3.T11.1.15" class="ltx_tr">
<td id="S3.T11.1.15.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T11.1.15.1.1" class="ltx_text ltx_font_italic">per:date_of_birth</span></td>
<td id="S3.T11.1.15.2" class="ltx_td ltx_align_center ltx_border_t">1,130</td>
<td id="S3.T11.1.15.3" class="ltx_td ltx_align_center ltx_border_t">3.48%</td>
<td id="S3.T11.1.15.4" class="ltx_td ltx_align_center ltx_border_t">12</td>
<td id="S3.T11.1.15.5" class="ltx_td ltx_align_center ltx_border_t">0.15%</td>
<td id="S3.T11.1.15.6" class="ltx_td ltx_align_center ltx_border_t">12</td>
<td id="S3.T11.1.15.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.15%</td>
</tr>
<tr id="S3.T11.1.16" class="ltx_tr">
<td id="S3.T11.1.16.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.16.1.1" class="ltx_text ltx_font_italic">per:date_of_death</span></td>
<td id="S3.T11.1.16.2" class="ltx_td ltx_align_center">418</td>
<td id="S3.T11.1.16.3" class="ltx_td ltx_align_center">1.29%</td>
<td id="S3.T11.1.16.4" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.16.5" class="ltx_td ltx_align_center">0.17%</td>
<td id="S3.T11.1.16.6" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.16.7" class="ltx_td ltx_nopad_r ltx_align_center">0.17%</td>
</tr>
<tr id="S3.T11.1.17" class="ltx_tr">
<td id="S3.T11.1.17.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.17.1.1" class="ltx_text ltx_font_italic">per:place_of_birth</span></td>
<td id="S3.T11.1.17.2" class="ltx_td ltx_align_center">166</td>
<td id="S3.T11.1.17.3" class="ltx_td ltx_align_center">0.51%</td>
<td id="S3.T11.1.17.4" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.17.5" class="ltx_td ltx_align_center">0.14%</td>
<td id="S3.T11.1.17.6" class="ltx_td ltx_align_center">10</td>
<td id="S3.T11.1.17.7" class="ltx_td ltx_nopad_r ltx_align_center">0.13%</td>
</tr>
<tr id="S3.T11.1.18" class="ltx_tr">
<td id="S3.T11.1.18.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.18.1.1" class="ltx_text ltx_font_italic">per:place_of_death</span></td>
<td id="S3.T11.1.18.2" class="ltx_td ltx_align_center">40</td>
<td id="S3.T11.1.18.3" class="ltx_td ltx_align_center">0.12%</td>
<td id="S3.T11.1.18.4" class="ltx_td ltx_align_center">10</td>
<td id="S3.T11.1.18.5" class="ltx_td ltx_align_center">0.13%</td>
<td id="S3.T11.1.18.6" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.18.7" class="ltx_td ltx_nopad_r ltx_align_center">0.14%</td>
</tr>
<tr id="S3.T11.1.19" class="ltx_tr">
<td id="S3.T11.1.19.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.19.1.1" class="ltx_text ltx_font_italic">per:place_of_residence</span></td>
<td id="S3.T11.1.19.2" class="ltx_td ltx_align_center">193</td>
<td id="S3.T11.1.19.3" class="ltx_td ltx_align_center">0.59%</td>
<td id="S3.T11.1.19.4" class="ltx_td ltx_align_center">124</td>
<td id="S3.T11.1.19.5" class="ltx_td ltx_align_center">1.60%</td>
<td id="S3.T11.1.19.6" class="ltx_td ltx_align_center">125</td>
<td id="S3.T11.1.19.7" class="ltx_td ltx_nopad_r ltx_align_center">1.61%</td>
</tr>
<tr id="S3.T11.1.20" class="ltx_tr">
<td id="S3.T11.1.20.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.20.1.1" class="ltx_text ltx_font_italic">per:origin</span></td>
<td id="S3.T11.1.20.2" class="ltx_td ltx_align_center">1,234</td>
<td id="S3.T11.1.20.3" class="ltx_td ltx_align_center">3.80%</td>
<td id="S3.T11.1.20.4" class="ltx_td ltx_align_center">118</td>
<td id="S3.T11.1.20.5" class="ltx_td ltx_align_center">1.52%</td>
<td id="S3.T11.1.20.6" class="ltx_td ltx_align_center">118</td>
<td id="S3.T11.1.20.7" class="ltx_td ltx_nopad_r ltx_align_center">1.52%</td>
</tr>
<tr id="S3.T11.1.21" class="ltx_tr">
<td id="S3.T11.1.21.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.21.1.1" class="ltx_text ltx_font_italic">per:employee_of</span></td>
<td id="S3.T11.1.21.2" class="ltx_td ltx_align_center">3,573</td>
<td id="S3.T11.1.21.3" class="ltx_td ltx_align_center">11.00%</td>
<td id="S3.T11.1.21.4" class="ltx_td ltx_align_center">242</td>
<td id="S3.T11.1.21.5" class="ltx_td ltx_align_center">3.12%</td>
<td id="S3.T11.1.21.6" class="ltx_td ltx_align_center">241</td>
<td id="S3.T11.1.21.7" class="ltx_td ltx_nopad_r ltx_align_center">3.10%</td>
</tr>
<tr id="S3.T11.1.22" class="ltx_tr">
<td id="S3.T11.1.22.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.22.1.1" class="ltx_text ltx_font_italic">per:schools_attended</span></td>
<td id="S3.T11.1.22.2" class="ltx_td ltx_align_center">82</td>
<td id="S3.T11.1.22.3" class="ltx_td ltx_align_center">0.25%</td>
<td id="S3.T11.1.22.4" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.22.5" class="ltx_td ltx_align_center">0.14%</td>
<td id="S3.T11.1.22.6" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.22.7" class="ltx_td ltx_nopad_r ltx_align_center">0.14%</td>
</tr>
<tr id="S3.T11.1.23" class="ltx_tr">
<td id="S3.T11.1.23.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.23.1.1" class="ltx_text ltx_font_italic">per:alternate_names</span></td>
<td id="S3.T11.1.23.2" class="ltx_td ltx_align_center">1,001</td>
<td id="S3.T11.1.23.3" class="ltx_td ltx_align_center">3.08%</td>
<td id="S3.T11.1.23.4" class="ltx_td ltx_align_center">104</td>
<td id="S3.T11.1.23.5" class="ltx_td ltx_align_center">1.34%</td>
<td id="S3.T11.1.23.6" class="ltx_td ltx_align_center">103</td>
<td id="S3.T11.1.23.7" class="ltx_td ltx_nopad_r ltx_align_center">1.33%</td>
</tr>
<tr id="S3.T11.1.24" class="ltx_tr">
<td id="S3.T11.1.24.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.24.1.1" class="ltx_text ltx_font_italic">per:parents</span></td>
<td id="S3.T11.1.24.2" class="ltx_td ltx_align_center">520</td>
<td id="S3.T11.1.24.3" class="ltx_td ltx_align_center">1.60%</td>
<td id="S3.T11.1.24.4" class="ltx_td ltx_align_center">27</td>
<td id="S3.T11.1.24.5" class="ltx_td ltx_align_center">0.35%</td>
<td id="S3.T11.1.24.6" class="ltx_td ltx_align_center">27</td>
<td id="S3.T11.1.24.7" class="ltx_td ltx_nopad_r ltx_align_center">0.35%</td>
</tr>
<tr id="S3.T11.1.25" class="ltx_tr">
<td id="S3.T11.1.25.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.25.1.1" class="ltx_text ltx_font_italic">per:children</span></td>
<td id="S3.T11.1.25.2" class="ltx_td ltx_align_center">304</td>
<td id="S3.T11.1.25.3" class="ltx_td ltx_align_center">0.94%</td>
<td id="S3.T11.1.25.4" class="ltx_td ltx_align_center">27</td>
<td id="S3.T11.1.25.5" class="ltx_td ltx_align_center">0.35%</td>
<td id="S3.T11.1.25.6" class="ltx_td ltx_align_center">27</td>
<td id="S3.T11.1.25.7" class="ltx_td ltx_nopad_r ltx_align_center">0.35%</td>
</tr>
<tr id="S3.T11.1.26" class="ltx_tr">
<td id="S3.T11.1.26.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.26.1.1" class="ltx_text ltx_font_italic">per:siblings</span></td>
<td id="S3.T11.1.26.2" class="ltx_td ltx_align_center">136</td>
<td id="S3.T11.1.26.3" class="ltx_td ltx_align_center">0.42%</td>
<td id="S3.T11.1.26.4" class="ltx_td ltx_align_center">24</td>
<td id="S3.T11.1.26.5" class="ltx_td ltx_align_center">0.31%</td>
<td id="S3.T11.1.26.6" class="ltx_td ltx_align_center">24</td>
<td id="S3.T11.1.26.7" class="ltx_td ltx_nopad_r ltx_align_center">0.31%</td>
</tr>
<tr id="S3.T11.1.27" class="ltx_tr">
<td id="S3.T11.1.27.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.27.1.1" class="ltx_text ltx_font_italic">per:spouse</span></td>
<td id="S3.T11.1.27.2" class="ltx_td ltx_align_center">795</td>
<td id="S3.T11.1.27.3" class="ltx_td ltx_align_center">2.45%</td>
<td id="S3.T11.1.27.4" class="ltx_td ltx_align_center">41</td>
<td id="S3.T11.1.27.5" class="ltx_td ltx_align_center">0.53%</td>
<td id="S3.T11.1.27.6" class="ltx_td ltx_align_center">40</td>
<td id="S3.T11.1.27.7" class="ltx_td ltx_nopad_r ltx_align_center">0.52%</td>
</tr>
<tr id="S3.T11.1.28" class="ltx_tr">
<td id="S3.T11.1.28.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.28.1.1" class="ltx_text ltx_font_italic">per:other_family</span></td>
<td id="S3.T11.1.28.2" class="ltx_td ltx_align_center">190</td>
<td id="S3.T11.1.28.3" class="ltx_td ltx_align_center">0.59%</td>
<td id="S3.T11.1.28.4" class="ltx_td ltx_align_center">34</td>
<td id="S3.T11.1.28.5" class="ltx_td ltx_align_center">0.44%</td>
<td id="S3.T11.1.28.6" class="ltx_td ltx_align_center">35</td>
<td id="S3.T11.1.28.7" class="ltx_td ltx_nopad_r ltx_align_center">0.45%</td>
</tr>
<tr id="S3.T11.1.29" class="ltx_tr">
<td id="S3.T11.1.29.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.29.1.1" class="ltx_text ltx_font_italic">per:colleagues</span></td>
<td id="S3.T11.1.29.2" class="ltx_td ltx_align_center">534</td>
<td id="S3.T11.1.29.3" class="ltx_td ltx_align_center">1.64%</td>
<td id="S3.T11.1.29.4" class="ltx_td ltx_align_center">220</td>
<td id="S3.T11.1.29.5" class="ltx_td ltx_align_center">2.83%</td>
<td id="S3.T11.1.29.6" class="ltx_td ltx_align_center">220</td>
<td id="S3.T11.1.29.7" class="ltx_td ltx_nopad_r ltx_align_center">2.83%</td>
</tr>
<tr id="S3.T11.1.30" class="ltx_tr">
<td id="S3.T11.1.30.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.30.1.1" class="ltx_text ltx_font_italic">per:product</span></td>
<td id="S3.T11.1.30.2" class="ltx_td ltx_align_center">139</td>
<td id="S3.T11.1.30.3" class="ltx_td ltx_align_center">0.43%</td>
<td id="S3.T11.1.30.4" class="ltx_td ltx_align_center">67</td>
<td id="S3.T11.1.30.5" class="ltx_td ltx_align_center">0.86%</td>
<td id="S3.T11.1.30.6" class="ltx_td ltx_align_center">69</td>
<td id="S3.T11.1.30.7" class="ltx_td ltx_nopad_r ltx_align_center">0.89%</td>
</tr>
<tr id="S3.T11.1.31" class="ltx_tr">
<td id="S3.T11.1.31.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.31.1.1" class="ltx_text ltx_font_italic">per:religion</span></td>
<td id="S3.T11.1.31.2" class="ltx_td ltx_align_center">96</td>
<td id="S3.T11.1.31.3" class="ltx_td ltx_align_center">0.30%</td>
<td id="S3.T11.1.31.4" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.31.5" class="ltx_td ltx_align_center">0.17%</td>
<td id="S3.T11.1.31.6" class="ltx_td ltx_align_center">12</td>
<td id="S3.T11.1.31.7" class="ltx_td ltx_nopad_r ltx_align_center">0.15%</td>
</tr>
<tr id="S3.T11.1.32" class="ltx_tr">
<td id="S3.T11.1.32.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.32.1.1" class="ltx_text ltx_font_italic">per:title</span></td>
<td id="S3.T11.1.32.2" class="ltx_td ltx_align_center">2,103</td>
<td id="S3.T11.1.32.3" class="ltx_td ltx_align_center">6.48%</td>
<td id="S3.T11.1.32.4" class="ltx_td ltx_align_center">718</td>
<td id="S3.T11.1.32.5" class="ltx_td ltx_align_center">9.25%</td>
<td id="S3.T11.1.32.6" class="ltx_td ltx_align_center">718</td>
<td id="S3.T11.1.32.7" class="ltx_td ltx_nopad_r ltx_align_center">9.25%</td>
</tr>
<tr id="S3.T11.1.33" class="ltx_tr">
<td id="S3.T11.1.33.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T11.1.33.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T11.1.33.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T11.1.33.2.1" class="ltx_text ltx_font_bold">32,470</span></td>
<td id="S3.T11.1.33.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">100.00%</td>
<td id="S3.T11.1.33.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T11.1.33.4.1" class="ltx_text ltx_font_bold">7,765</span></td>
<td id="S3.T11.1.33.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">100.00%</td>
<td id="S3.T11.1.33.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T11.1.33.6.1" class="ltx_text ltx_font_bold">7,766</span></td>
<td id="S3.T11.1.33.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t">100.00%</td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS5.SSS1.Px6.p3" class="ltx_para">
<p id="S3.SS5.SSS1.Px6.p3.1" class="ltx_p">We take majority-voted labels as gold labels. For each example without a majority label, the top 30 annotators select the final label from the annotated labels. We do not include examples reported as hate speech, biased, or to have privacy issues. The inter-annotator agreement (Krippendorff’s <math id="S3.SS5.SSS1.Px6.p3.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS5.SSS1.Px6.p3.1.m1.1a"><mi id="S3.SS5.SSS1.Px6.p3.1.m1.1.1" xref="S3.SS5.SSS1.Px6.p3.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px6.p3.1.m1.1b"><ci id="S3.SS5.SSS1.Px6.p3.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px6.p3.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px6.p3.1.m1.1c">\alpha</annotation></semantics></math>) on the annotated dataset is 0.701 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS5.SSS1.Px7.p1" class="ltx_para">
<p id="S3.SS5.SSS1.Px7.p1.1" class="ltx_p">KLUE-RE consists of 32,470 training, 7,765 development and 7,766 test examples.
For real-world scenario, we only use examples created from uniform sampling when building the development and test sets. In the test set, we only include sentences with entities that do not appear in the training set.</p>
</div>
<div id="S3.SS5.SSS1.Px7.p2" class="ltx_para">
<p id="S3.SS5.SSS1.Px7.p2.1" class="ltx_p">The average length of a sentence in KLUE-RE is 95.9 characters including whitespaces. The proportions of the entity types are: PER (38.1%), ORG (36.3%), LOC (6.2%), DAT (6.2%), POH (11.9%), and NOH (1.3%). The distribution of the relation classes is shown in Table&nbsp;<a href="#S3.T11" title="Table 11 ‣ 5. Annotate Relations ‣ 3.5.1 Data Construction ‣ 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
</section>
</section>
<section id="S3.SS5.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.2 </span>Evaluation Metrics</h4>

<div id="S3.SS5.SSS2.p1" class="ltx_para">
<p id="S3.SS5.SSS2.p1.1" class="ltx_p">The evaluation metrics for KLUE-RE are 1) micro F1 score on relation existing cases, and 2) area under the precision-recall curve (AUPRC) on all classes. Micro F1 score is a harmonic mean of micro-precision and micro-recall. It measures the F1 score of the aggregated contributions of all classes. It gives each sample the same importance, thus naturally weighting more on the majority class. We remove the dominant class (<math id="S3.SS5.SSS2.p1.1.m1.1" class="ltx_Math" alttext="no\_relation" display="inline"><semantics id="S3.SS5.SSS2.p1.1.m1.1a"><mrow id="S3.SS5.SSS2.p1.1.m1.1.1" xref="S3.SS5.SSS2.p1.1.m1.1.1.cmml"><mi id="S3.SS5.SSS2.p1.1.m1.1.1.2" xref="S3.SS5.SSS2.p1.1.m1.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.3" xref="S3.SS5.SSS2.p1.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1a" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS5.SSS2.p1.1.m1.1.1.4" xref="S3.SS5.SSS2.p1.1.m1.1.1.4.cmml">_</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1b" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.5" xref="S3.SS5.SSS2.p1.1.m1.1.1.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1c" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.6" xref="S3.SS5.SSS2.p1.1.m1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1d" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.7" xref="S3.SS5.SSS2.p1.1.m1.1.1.7.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1e" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.8" xref="S3.SS5.SSS2.p1.1.m1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1f" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.9" xref="S3.SS5.SSS2.p1.1.m1.1.1.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1g" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.10" xref="S3.SS5.SSS2.p1.1.m1.1.1.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1h" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.11" xref="S3.SS5.SSS2.p1.1.m1.1.1.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS2.p1.1.m1.1.1.1i" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.12" xref="S3.SS5.SSS2.p1.1.m1.1.1.12.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS2.p1.1.m1.1b"><apply id="S3.SS5.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1"><times id="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.1"></times><ci id="S3.SS5.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.2">𝑛</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.3">𝑜</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.4.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.4">_</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.5.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.5">𝑟</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.6.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.6">𝑒</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.7.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.7">𝑙</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.8.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.8">𝑎</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.9.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.9">𝑡</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.10.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.10">𝑖</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.11.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.11">𝑜</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.12.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.12">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS2.p1.1.m1.1c">no\_relation</annotation></semantics></math>) for this metric to not incentivize the model that focus more on predicting negative class. AUPRC is an averaged area under the precision-recall curves whose x-axis is recall and y-axis is the precision of all relation classes. It is a useful metric for this imbalanced data setting where important positive examples are rarely occurred.</p>
</div>
</section>
<section id="S3.SS5.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.3 </span>Related Work</h4>

<div id="S3.SS5.SSS3.p1" class="ltx_para">
<p id="S3.SS5.SSS3.p1.1" class="ltx_p">Many researchers attempt to build KBs from unstructured text through automatically identifying relational facts between entity pairs in plain text by applying machine learning techniques. <cite class="ltx_cite ltx_citemacro_citet">Doddington et&nbsp;al. [<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Hendrickx et&nbsp;al. [<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> construct English datasets to train such models, including a relatively small number of relation classes for general domain text. <cite class="ltx_cite ltx_citemacro_citet">Mintz et&nbsp;al. [<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> further propose distant supervision to automatically annotate plain text by aligning it to the schema of KBs. This allows researchers to scale up the size of RE datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>, <a href="#bib.bib153" title="" class="ltx_ref">153</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib147" title="" class="ltx_ref">147</a>, <a href="#bib.bib149" title="" class="ltx_ref">149</a>]</cite>. Among these recent studies, TACRED <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite> is the most widely used dataset, built based on the popular relation schema TAC-KBP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite> which mainly focuses on person and organization entities. Specifically, TACRED contains 106,264 examples annotated with the 42 relation classes. <cite class="ltx_cite ltx_citemacro_citet">Yu et&nbsp;al. [<a href="#bib.bib149" title="" class="ltx_ref">149</a>]</cite> also proposes a dialogue-based RE task by refining TAC-KBP to obtain 36 relation classes adapted for the dialogue domain. We also follow TAC-KBP to build the relation schema and modify them suitable for our situation.</p>
</div>
<div id="S3.SS5.SSS3.p2" class="ltx_para">
<p id="S3.SS5.SSS3.p2.1" class="ltx_p">In the cases of languages other than English, there are only a few existing benchmarks, including one in Chinese <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite>, one in German <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite>, and one in French <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. <cite class="ltx_cite ltx_citemacro_citet">Nam et&nbsp;al. [<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite> propose an RE dataset in Korean using distant supervision to automatically generate and annotate examples. It however has a relatively small test set (<math id="S3.SS5.SSS3.p2.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.SS5.SSS3.p2.1.m1.1a"><mo id="S3.SS5.SSS3.p2.1.m1.1.1" xref="S3.SS5.SSS3.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS3.p2.1.m1.1b"><csymbol cd="latexml" id="S3.SS5.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS5.SSS3.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS3.p2.1.m1.1c">\sim</annotation></semantics></math>3k), making it difficult to evaluate performance for the total 49 relation classes properly. Moreover, since there is no negative class (<span id="S3.SS5.SSS3.p2.1.1" class="ltx_text ltx_font_italic">no_relation</span> in ours), it is likely to encourage models to overly predict false positives <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite>. We thus consider KLUE-RE as a standard large-scale RE benchmark to properly evaluate Korean language models.</p>
</div>
</section>
<section id="S3.SS5.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.4 </span>Conclusion</h4>

<div id="S3.SS5.SSS4.p1" class="ltx_para">
<p id="S3.SS5.SSS4.p1.1" class="ltx_p">We propose KLUE-RE, a large-scale human-annotated RE benchmark for Korean. To overcome the lack of large-scale and up-to-date Korean KBs, we design an efficient candidate collection method, coupled with an effective annotation scheme. KLUE-RE can not only be used for online information extraction but also contribute to building a large-scale knowledge graph from unstructured texts.
We therefore expect KLUE-RE to be a starting point for building a large-scale, ever-growing public KB in Korean, as well as a valuable Korean NLU benchmark.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Dependency Parsing (DP)</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.1" class="ltx_p">Dependency parsing (DP) is an NLP task that aims at finding relational information among words. It has been an important component in many NLP systems, because of its ability to capture the syntactic feature of a sentence. We include DP in KLUE to evaluate the representational power of language models in terms of syntactic features.</p>
</div>
<div id="S3.SS6.p2" class="ltx_para">
<p id="S3.SS6.p2.1" class="ltx_p">Formally, a dependency parser predicts a graph structure of an input sentence based on the dependency grammar <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. In general, a parsed tree consists of dependency arcs, connecting dependents to their heads, and the dependency labels attached to the arcs that represent the relations between dependents and their heads.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2105.09680/assets/figs/dp-fig1.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="167" height="100" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>An example of dependency parsing, that translates to "Chul-Soo ate an apple."</figcaption>
</figure>
<div id="S3.SS6.p3" class="ltx_para">
<p id="S3.SS6.p3.1" class="ltx_p">For example, Figure&nbsp;<a href="#S3.F5" title="Figure 5 ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows a parsed result of the example sentence: “철수가 사과를 먹었다 (Chul-Soo ate an apple.)”. In the tree, arrows depart from <span id="S3.SS6.p3.1.1" class="ltx_text ltx_font_italic">head</span> and point to their <span id="S3.SS6.p3.1.2" class="ltx_text ltx_font_italic">dependents</span>. Thus ‘철수가 (Chul-Soo)’ and ‘사과를 (an apple)’ are <span id="S3.SS6.p3.1.3" class="ltx_text ltx_font_italic">dependents</span> of ‘먹었다(ate)’ and ‘먹었다(ate)’ is the <span id="S3.SS6.p3.1.4" class="ltx_text ltx_font_italic">head</span> of ‘철수가 (Chul-Soo)’ and ‘사과를 (an apple)’. Also, ‘철수가 (Chul-Soo)’ is dependent on ‘먹었다 (ate)’ with a “Subject” relation. This dependency relation label is called DEPREL. For DEPREL, we follow the TTA Dependency annotation
scheme<span id="footnote36" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">36</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">36</sup><span class="ltx_tag ltx_tag_note">36</span>
<a target="_blank" href="https://aiopen.etri.re.kr/data/003.%EC%9D%98%EC%A1%B4%EA%B5%AC%EB%AC%B8%EB%B6%84%EC%84%9D_%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aiopen.etri.re.kr/data/003.%EC%9D%98%EC%A1%B4%EA%B5%AC%EB%AC%B8%EB%B6%84%EC%84%9D_%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8.pdf</a></span></span></span> consisting of a combination of 9 syntax tags and 6 function tags.</p>
</div>
<div id="S3.SS6.p4" class="ltx_para">
<p id="S3.SS6.p4.1" class="ltx_p">Since each word in a sentence has a pair of dependency information (HEAD, DEPREL), DP is conventionally formulated as a word-level sequence tagging task. We evaluate a model’s performance using unlabeled attachment score (UAS) and labeled attachment score (LAS). During the evaluation, labels with a cumulative frequency of 1% from the bottom are grouped into the OTHERS label to compensate for the negative impact of lower frequency labels on LAS.</p>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2105.09680/assets/figs/dp-fig2.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="259" height="57" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>A demonstration of the KLUE-DP output format using a sentence that translates to “Chul-Soo ate an apple.”</figcaption>
</figure>
<div id="S3.SS6.p5" class="ltx_para">
<p id="S3.SS6.p5.1" class="ltx_p">We represent the output in a CoNLL-like format, as shown in Figure&nbsp;<a href="#S3.F6" title="Figure 6 ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. This format consists of 6 columns, each column contains a word index (ID), word form (FORM), lemma of word form (LEMMA), part-of-speech tag (POS), head of the current word (HEAD), and dependency relation (DEPREL).</p>
</div>
<section id="S3.SS6.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.1 </span>Dataset Construction</h4>

<section id="S3.SS6.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS6.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS6.SSS1.Px1.p1.1" class="ltx_p">To build our corpus as a suitable dataset for a general-usage DP model, we take into account both formal and informal texts. We use WIKITREE and AIRBNB as source corpora. WIKITREE consists of news articles and represents grammatically sound formal texts. On the other hand, AIRBNB mostly consists of user-generated reviews containing web texts, thus showing frequent omission of components and free word order. We collect the same rate of data from both WIKITREE and AIRBNB so that our dataset represents both refined written sentences and noisy colloquial texts.</p>
</div>
</section>
<section id="S3.SS6.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS6.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS6.SSS1.Px2.p1.1" class="ltx_p">Since the part-of-speech indicates how the word functions grammatically in a sentence, it is highly related to the dependency relations. To utilize POS information as an additional syntactic feature, we first annotate POS on the corpus prior to dependency relation annotation. To this end, we follow TTA POS tagging guideline.<span id="footnote37" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">37</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">37</sup><span class="ltx_tag ltx_tag_note">37</span><a target="_blank" href="https://aiopen.etri.re.kr/data/001.%ED%98%95%ED%83%9C%EC%86%8C%EB%B6%84%EC%84%9D_%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aiopen.etri.re.kr/data/001.%ED%98%95%ED%83%9C%EC%86%8C%EB%B6%84%EC%84%9D_%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8.pdf</a></span></span></span> We use annotated POS information when constructing the DP corpus.</p>
</div>
<div id="S3.SS6.SSS1.Px2.p2" class="ltx_para">
<p id="S3.SS6.SSS1.Px2.p2.1" class="ltx_p">Next, we modify the original TTA DP guideline for dependency relation annotation. We add guides for spoken and web data, since the original guideline only contains instruction for annotating written data.</p>
</div>
<figure id="S3.T12" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Syntax and function tagset (label types) of TTA DP guideline.</figcaption>
<table id="S3.T12.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T12.1.1" class="ltx_tr">
<td id="S3.T12.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T12.1.1.1.1" class="ltx_text ltx_font_bold">Label Type</span></td>
<td id="S3.T12.1.1.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S3.T12.1.1.2.1" class="ltx_text ltx_font_bold">Description</span></td>
</tr>
<tr id="S3.T12.1.2" class="ltx_tr">
<td id="S3.T12.1.2.1" class="ltx_td ltx_align_left ltx_border_t" colspan="2">Syntax</td>
</tr>
<tr id="S3.T12.1.3" class="ltx_tr">
<td id="S3.T12.1.3.1" class="ltx_td ltx_align_left ltx_border_t">NP</td>
<td id="S3.T12.1.3.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Noun Phrase</td>
</tr>
<tr id="S3.T12.1.4" class="ltx_tr">
<td id="S3.T12.1.4.1" class="ltx_td ltx_align_left">VP</td>
<td id="S3.T12.1.4.2" class="ltx_td ltx_nopad_r ltx_align_left">Verb Phrase</td>
</tr>
<tr id="S3.T12.1.5" class="ltx_tr">
<td id="S3.T12.1.5.1" class="ltx_td ltx_align_left">AP</td>
<td id="S3.T12.1.5.2" class="ltx_td ltx_nopad_r ltx_align_left">Adverb Phrase</td>
</tr>
<tr id="S3.T12.1.6" class="ltx_tr">
<td id="S3.T12.1.6.1" class="ltx_td ltx_align_left">VNP</td>
<td id="S3.T12.1.6.2" class="ltx_td ltx_nopad_r ltx_align_left">Copula Phrase</td>
</tr>
<tr id="S3.T12.1.7" class="ltx_tr">
<td id="S3.T12.1.7.1" class="ltx_td ltx_align_left">DP</td>
<td id="S3.T12.1.7.2" class="ltx_td ltx_nopad_r ltx_align_left">Adnoun Phrase</td>
</tr>
<tr id="S3.T12.1.8" class="ltx_tr">
<td id="S3.T12.1.8.1" class="ltx_td ltx_align_left">IP</td>
<td id="S3.T12.1.8.2" class="ltx_td ltx_nopad_r ltx_align_left">Interjection Phrase</td>
</tr>
<tr id="S3.T12.1.9" class="ltx_tr">
<td id="S3.T12.1.9.1" class="ltx_td ltx_align_left">X</td>
<td id="S3.T12.1.9.2" class="ltx_td ltx_nopad_r ltx_align_left">Pseudo Phrase</td>
</tr>
<tr id="S3.T12.1.10" class="ltx_tr">
<td id="S3.T12.1.10.1" class="ltx_td ltx_align_left">L</td>
<td id="S3.T12.1.10.2" class="ltx_td ltx_nopad_r ltx_align_left">Left Parenthesis and Quotation Mark</td>
</tr>
<tr id="S3.T12.1.11" class="ltx_tr">
<td id="S3.T12.1.11.1" class="ltx_td ltx_align_left">R</td>
<td id="S3.T12.1.11.2" class="ltx_td ltx_nopad_r ltx_align_left">Right Parenthesis and Quotation Mark</td>
</tr>
<tr id="S3.T12.1.12" class="ltx_tr">
<td id="S3.T12.1.12.1" class="ltx_td ltx_align_left ltx_border_t" colspan="2">Function</td>
</tr>
<tr id="S3.T12.1.13" class="ltx_tr">
<td id="S3.T12.1.13.1" class="ltx_td ltx_align_left ltx_border_t">SBJ</td>
<td id="S3.T12.1.13.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Subject</td>
</tr>
<tr id="S3.T12.1.14" class="ltx_tr">
<td id="S3.T12.1.14.1" class="ltx_td ltx_align_left">OBJ</td>
<td id="S3.T12.1.14.2" class="ltx_td ltx_nopad_r ltx_align_left">Object</td>
</tr>
<tr id="S3.T12.1.15" class="ltx_tr">
<td id="S3.T12.1.15.1" class="ltx_td ltx_align_left">MOD</td>
<td id="S3.T12.1.15.2" class="ltx_td ltx_nopad_r ltx_align_left">Noun Modifier</td>
</tr>
<tr id="S3.T12.1.16" class="ltx_tr">
<td id="S3.T12.1.16.1" class="ltx_td ltx_align_left">AJT</td>
<td id="S3.T12.1.16.2" class="ltx_td ltx_nopad_r ltx_align_left">Predicate Modifier</td>
</tr>
<tr id="S3.T12.1.17" class="ltx_tr">
<td id="S3.T12.1.17.1" class="ltx_td ltx_align_left">CMP</td>
<td id="S3.T12.1.17.2" class="ltx_td ltx_nopad_r ltx_align_left">Complement</td>
</tr>
<tr id="S3.T12.1.18" class="ltx_tr">
<td id="S3.T12.1.18.1" class="ltx_td ltx_align_left ltx_border_bb">CNJ</td>
<td id="S3.T12.1.18.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">Conjunction</td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS6.SSS1.Px2.p3" class="ltx_para">
<p id="S3.SS6.SSS1.Px2.p3.1" class="ltx_p">We follow TTA DP tagset, which is a standard in Korean. As shown in Table <a href="#S3.T12" title="Table 12 ‣ Annotation Protocol ‣ 3.6.1 Dataset Construction ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, it is made up of a combination of 9 syntax tags and 6 function tags. The syntax tag indicates the POS for token, and there are NP (noun phrase), VP (verb phrase), AP (adverb phrase), VNP (copula phrase), DP (adnoun phrase), IP (interjection phrase), X (pseudo phrase), L (left parenthesis and quotation mark) and R (right parenthesis and quotation mark). The function tag indicates what function the token performs in relation to the head, and there are SBJ (subject), OBJ (object), MOD (noun modifier), AJT (predicate modifier), CMP (complement), and CNJ (conjunction). The TTA DP combines a syntax tag and a function tag into a single tag, such as NP_SBJ (noun phrase subject) and VP_AJT (verb phrase adverb).</p>
</div>
</section>
<section id="S3.SS6.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS6.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS6.SSS1.Px3.p1.1" class="ltx_p">To build highly reliable corpora for both POS and DP annotation, we use an annotation tool provided by DeepNatural,<span id="footnote38" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">38</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">38</sup><span class="ltx_tag ltx_tag_note">38</span><a target="_blank" href="https://deepnatural.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://deepnatural.ai/</a></span></span></span> a Korean crowdsourcing platform, which asks the annotators to annotate cross-reference. After POS annotation is completed, dependency relation annotation proceeds on the same sentences by using POS information. Both POS and DP are annotated by ten PhD students in Korean linguistics, who previously contributed to constructing MODU<span id="footnote39" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">39</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">39</sup><span class="ltx_tag ltx_tag_note">39</span><a target="_blank" href="https://corpus.korean.go.kr/main.do" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://corpus.korean.go.kr/main.do</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> opened by the National Institute of the Korean Language. Prior to annotation, we instruct them with our guideline. During annotation, we respond to questions from annotators in real-time, and accordingly, the guidelines are iteratively updated. Annotators report sentences containing hate speech or bias during the annotation. In addition, sentences containing personal information (e.g., name, address, phone number, etc.) are reported. The reported sentences are removed from the dataset after our inspection.</p>
</div>
<div id="S3.SS6.SSS1.Px3.p2" class="ltx_para">
<p id="S3.SS6.SSS1.Px3.p2.1" class="ltx_p">Annotations are validated in two steps. First, each annotator reviews and corrects POS and DP labels annotated by other annotators. Then we finally review all data and revise remaining mislabeled sentences.</p>
</div>
</section>
<section id="S3.SS6.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS6.SSS1.Px4.p1" class="ltx_para">
<p id="S3.SS6.SSS1.Px4.p1.1" class="ltx_p">KLUE-DP consists of a total of 14,500 sentences, including 7,250 sentences for WIKINEWS and 7,250 sentences for AIRBNB. POS annotation is given in the 4th column of CoNLL-like format, along with HEAD and DEPREL information in next columns. We set the train/dev/test split as 10,000, 2,000, 2,500 sentences. Tables&nbsp;<a href="#S3.T13" title="Table 13 ‣ Final Dataset ‣ 3.6.1 Dataset Construction ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> and <a href="#S3.T14" title="Table 14 ‣ Final Dataset ‣ 3.6.1 Dataset Construction ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a> show detailed statistics of KLUE-DP.</p>
</div>
<figure id="S3.T13" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>Statistics for KLUE-DP.</figcaption>
<table id="S3.T13.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T13.1.1" class="ltx_tr">
<td id="S3.T13.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T13.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T13.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T13.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T13.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T13.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T13.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T13.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T13.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T13.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T13.1.2" class="ltx_tr">
<td id="S3.T13.1.2.1" class="ltx_td ltx_align_left ltx_border_t">WIKITREE</td>
<td id="S3.T13.1.2.2" class="ltx_td ltx_align_center ltx_border_t">5,000</td>
<td id="S3.T13.1.2.3" class="ltx_td ltx_align_center ltx_border_t">1,000</td>
<td id="S3.T13.1.2.4" class="ltx_td ltx_align_center ltx_border_t">1,250</td>
<td id="S3.T13.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">7,250</td>
</tr>
<tr id="S3.T13.1.3" class="ltx_tr">
<td id="S3.T13.1.3.1" class="ltx_td ltx_align_left">AIRBNB</td>
<td id="S3.T13.1.3.2" class="ltx_td ltx_align_center">5,000</td>
<td id="S3.T13.1.3.3" class="ltx_td ltx_align_center">1,000</td>
<td id="S3.T13.1.3.4" class="ltx_td ltx_align_center">1,250</td>
<td id="S3.T13.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">7,250</td>
</tr>
<tr id="S3.T13.1.4" class="ltx_tr">
<td id="S3.T13.1.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T13.1.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.2.1" class="ltx_text ltx_font_bold">10,000</span></td>
<td id="S3.T13.1.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.3.1" class="ltx_text ltx_font_bold">2,000</span></td>
<td id="S3.T13.1.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.4.1" class="ltx_text ltx_font_bold">2,500</span></td>
<td id="S3.T13.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.5.1" class="ltx_text ltx_font_bold">14,500</span></td>
</tr>
</tbody></table>
</figure>
<figure id="S3.T14" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 14: </span>Label statistics for KLUE-DP. Predictions on the labels from VP_CMP to NP_SVJ is be merged into OTHERS when calculating LAS.</figcaption>
<table id="S3.T14.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T14.1.1" class="ltx_tr">
<td id="S3.T14.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T14.1.1.1.1" class="ltx_text ltx_font_bold">Label</span></td>
<td id="S3.T14.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T14.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T14.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T14.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T14.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T14.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T14.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T14.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T14.1.2" class="ltx_tr">
<td id="S3.T14.1.2.1" class="ltx_td ltx_align_left ltx_border_t">NP</td>
<td id="S3.T14.1.2.2" class="ltx_td ltx_align_center ltx_border_t">23,902 (20.88%)</td>
<td id="S3.T14.1.2.3" class="ltx_td ltx_align_center ltx_border_t">4,559 (20.27%)</td>
<td id="S3.T14.1.2.4" class="ltx_td ltx_align_center ltx_border_t">4,884 (19.51%)</td>
<td id="S3.T14.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">33,345 (20.58%)</td>
</tr>
<tr id="S3.T14.1.3" class="ltx_tr">
<td id="S3.T14.1.3.1" class="ltx_td ltx_align_left">NP_AJT</td>
<td id="S3.T14.1.3.2" class="ltx_td ltx_align_center">17,552 (15.33%)</td>
<td id="S3.T14.1.3.3" class="ltx_td ltx_align_center">3,415 (15.18%)</td>
<td id="S3.T14.1.3.4" class="ltx_td ltx_align_center">3,526 (14.09%)</td>
<td id="S3.T14.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">24,493 (15.12%)</td>
</tr>
<tr id="S3.T14.1.4" class="ltx_tr">
<td id="S3.T14.1.4.1" class="ltx_td ltx_align_left">VP</td>
<td id="S3.T14.1.4.2" class="ltx_td ltx_align_center">16,786 (14.66%)</td>
<td id="S3.T14.1.4.3" class="ltx_td ltx_align_center">3,322 (14.77%)</td>
<td id="S3.T14.1.4.4" class="ltx_td ltx_align_center">3,917 (15.65%)</td>
<td id="S3.T14.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center">24,025 (14.83%)</td>
</tr>
<tr id="S3.T14.1.5" class="ltx_tr">
<td id="S3.T14.1.5.1" class="ltx_td ltx_align_left">NP_SBJ</td>
<td id="S3.T14.1.5.2" class="ltx_td ltx_align_center">13,412 (11.71%)</td>
<td id="S3.T14.1.5.3" class="ltx_td ltx_align_center">2,737 (12.17%)</td>
<td id="S3.T14.1.5.4" class="ltx_td ltx_align_center">3,112 (12.43%)</td>
<td id="S3.T14.1.5.5" class="ltx_td ltx_nopad_r ltx_align_center">19,261 (11.89%)</td>
</tr>
<tr id="S3.T14.1.6" class="ltx_tr">
<td id="S3.T14.1.6.1" class="ltx_td ltx_align_left">VP_MOD</td>
<td id="S3.T14.1.6.2" class="ltx_td ltx_align_center">12,210 (10.66%)</td>
<td id="S3.T14.1.6.3" class="ltx_td ltx_align_center">2,457 (10.92%)</td>
<td id="S3.T14.1.6.4" class="ltx_td ltx_align_center">2,682 (10.71%)</td>
<td id="S3.T14.1.6.5" class="ltx_td ltx_nopad_r ltx_align_center">17,349 (10.71%)</td>
</tr>
<tr id="S3.T14.1.7" class="ltx_tr">
<td id="S3.T14.1.7.1" class="ltx_td ltx_align_left">NP_OBJ</td>
<td id="S3.T14.1.7.2" class="ltx_td ltx_align_center">8,531 (7.45%)</td>
<td id="S3.T14.1.7.3" class="ltx_td ltx_align_center">1,691 (7.52%)</td>
<td id="S3.T14.1.7.4" class="ltx_td ltx_align_center">1,951 (7.79%)</td>
<td id="S3.T14.1.7.5" class="ltx_td ltx_nopad_r ltx_align_center">12,173 (7.51%)</td>
</tr>
<tr id="S3.T14.1.8" class="ltx_tr">
<td id="S3.T14.1.8.1" class="ltx_td ltx_align_left">AP</td>
<td id="S3.T14.1.8.2" class="ltx_td ltx_align_center">6,638 (5.80%)</td>
<td id="S3.T14.1.8.3" class="ltx_td ltx_align_center">1,274 (5.66%)</td>
<td id="S3.T14.1.8.4" class="ltx_td ltx_align_center">1,716 (6.85%)</td>
<td id="S3.T14.1.8.5" class="ltx_td ltx_nopad_r ltx_align_center">9,628 (5.94%)</td>
</tr>
<tr id="S3.T14.1.9" class="ltx_tr">
<td id="S3.T14.1.9.1" class="ltx_td ltx_align_left">NP_CNJ</td>
<td id="S3.T14.1.9.2" class="ltx_td ltx_align_center">3,945 (3.45%)</td>
<td id="S3.T14.1.9.3" class="ltx_td ltx_align_center">795 (3.53%)</td>
<td id="S3.T14.1.9.4" class="ltx_td ltx_align_center">764 (3.05%)</td>
<td id="S3.T14.1.9.5" class="ltx_td ltx_nopad_r ltx_align_center">5,504 (3.40%)</td>
</tr>
<tr id="S3.T14.1.10" class="ltx_tr">
<td id="S3.T14.1.10.1" class="ltx_td ltx_align_left">NP_MOD</td>
<td id="S3.T14.1.10.2" class="ltx_td ltx_align_center">3,450 (3.01%)</td>
<td id="S3.T14.1.10.3" class="ltx_td ltx_align_center">659 (2.93%)</td>
<td id="S3.T14.1.10.4" class="ltx_td ltx_align_center">727 (2.90%)</td>
<td id="S3.T14.1.10.5" class="ltx_td ltx_nopad_r ltx_align_center">4,836 (2.98%)</td>
</tr>
<tr id="S3.T14.1.11" class="ltx_tr">
<td id="S3.T14.1.11.1" class="ltx_td ltx_align_left">VNP</td>
<td id="S3.T14.1.11.2" class="ltx_td ltx_align_center">2,550 (2.23%)</td>
<td id="S3.T14.1.11.3" class="ltx_td ltx_align_center">495 (2.20%)</td>
<td id="S3.T14.1.11.4" class="ltx_td ltx_align_center">558 (2.23%)</td>
<td id="S3.T14.1.11.5" class="ltx_td ltx_nopad_r ltx_align_center">3,603 (2.22%)</td>
</tr>
<tr id="S3.T14.1.12" class="ltx_tr">
<td id="S3.T14.1.12.1" class="ltx_td ltx_align_left">DP</td>
<td id="S3.T14.1.12.2" class="ltx_td ltx_align_center">1,994 (1.74%)</td>
<td id="S3.T14.1.12.3" class="ltx_td ltx_align_center">376 (1.67%)</td>
<td id="S3.T14.1.12.4" class="ltx_td ltx_align_center">419 (1.67%)</td>
<td id="S3.T14.1.12.5" class="ltx_td ltx_nopad_r ltx_align_center">2,789 (1.72%)</td>
</tr>
<tr id="S3.T14.1.13" class="ltx_tr">
<td id="S3.T14.1.13.1" class="ltx_td ltx_align_left">VP_AJT</td>
<td id="S3.T14.1.13.2" class="ltx_td ltx_align_center">882 (0.77%)</td>
<td id="S3.T14.1.13.3" class="ltx_td ltx_align_center">196 (0.87%)</td>
<td id="S3.T14.1.13.4" class="ltx_td ltx_align_center">182 (0.73%)</td>
<td id="S3.T14.1.13.5" class="ltx_td ltx_nopad_r ltx_align_center">1,260 (0.78%)</td>
</tr>
<tr id="S3.T14.1.14" class="ltx_tr">
<td id="S3.T14.1.14.1" class="ltx_td ltx_align_left">VNP_MOD</td>
<td id="S3.T14.1.14.2" class="ltx_td ltx_align_center">854 (0.75%)</td>
<td id="S3.T14.1.14.3" class="ltx_td ltx_align_center">180 (0.80%)</td>
<td id="S3.T14.1.14.4" class="ltx_td ltx_align_center">164 (0.66%)</td>
<td id="S3.T14.1.14.5" class="ltx_td ltx_nopad_r ltx_align_center">1,198 (0.74%)</td>
</tr>
<tr id="S3.T14.1.15" class="ltx_tr">
<td id="S3.T14.1.15.1" class="ltx_td ltx_align_left">NP_CMP</td>
<td id="S3.T14.1.15.2" class="ltx_td ltx_align_center">408 (0.36%)</td>
<td id="S3.T14.1.15.3" class="ltx_td ltx_align_center">83 (0.37%)</td>
<td id="S3.T14.1.15.4" class="ltx_td ltx_align_center">97 (0.39%)</td>
<td id="S3.T14.1.15.5" class="ltx_td ltx_nopad_r ltx_align_center">588 (0.36%)</td>
</tr>
<tr id="S3.T14.1.16" class="ltx_tr">
<td id="S3.T14.1.16.1" class="ltx_td ltx_align_left">VP_SBJ</td>
<td id="S3.T14.1.16.2" class="ltx_td ltx_align_center">338 (0.30%)</td>
<td id="S3.T14.1.16.3" class="ltx_td ltx_align_center">59 (0.26%)</td>
<td id="S3.T14.1.16.4" class="ltx_td ltx_align_center">94 (0.38%)</td>
<td id="S3.T14.1.16.5" class="ltx_td ltx_nopad_r ltx_align_center">491 (0.30%)</td>
</tr>
<tr id="S3.T14.1.17" class="ltx_tr">
<td id="S3.T14.1.17.1" class="ltx_td ltx_align_left ltx_border_t">VP_CMP</td>
<td id="S3.T14.1.17.2" class="ltx_td ltx_align_center ltx_border_t">330 (0.29%)</td>
<td id="S3.T14.1.17.3" class="ltx_td ltx_align_center ltx_border_t">59 (0.26%)</td>
<td id="S3.T14.1.17.4" class="ltx_td ltx_align_center ltx_border_t">91 (0.36%)</td>
<td id="S3.T14.1.17.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">483 (0.30%)</td>
</tr>
<tr id="S3.T14.1.18" class="ltx_tr">
<td id="S3.T14.1.18.1" class="ltx_td ltx_align_left">VP_OBJ</td>
<td id="S3.T14.1.18.2" class="ltx_td ltx_align_center">279 (0.24%)</td>
<td id="S3.T14.1.18.3" class="ltx_td ltx_align_center">39 (0.17%)</td>
<td id="S3.T14.1.18.4" class="ltx_td ltx_align_center">68 (0.27%)</td>
<td id="S3.T14.1.18.5" class="ltx_td ltx_nopad_r ltx_align_center">386 (0.24%)</td>
</tr>
<tr id="S3.T14.1.19" class="ltx_tr">
<td id="S3.T14.1.19.1" class="ltx_td ltx_align_left">VNP_CMP</td>
<td id="S3.T14.1.19.2" class="ltx_td ltx_align_center">131 (0.11%)</td>
<td id="S3.T14.1.19.3" class="ltx_td ltx_align_center">27 (0.12%)</td>
<td id="S3.T14.1.19.4" class="ltx_td ltx_align_center">26 (0.10%)</td>
<td id="S3.T14.1.19.5" class="ltx_td ltx_nopad_r ltx_align_center">184 (0.11%)</td>
</tr>
<tr id="S3.T14.1.20" class="ltx_tr">
<td id="S3.T14.1.20.1" class="ltx_td ltx_align_left">AP_MOD</td>
<td id="S3.T14.1.20.2" class="ltx_td ltx_align_center">59 (0.05%)</td>
<td id="S3.T14.1.20.3" class="ltx_td ltx_align_center">15 (0.07%)</td>
<td id="S3.T14.1.20.4" class="ltx_td ltx_align_center">11 (0.04%)</td>
<td id="S3.T14.1.20.5" class="ltx_td ltx_nopad_r ltx_align_center">84 (0.05%)</td>
</tr>
<tr id="S3.T14.1.21" class="ltx_tr">
<td id="S3.T14.1.21.1" class="ltx_td ltx_align_left">X_AJT</td>
<td id="S3.T14.1.21.2" class="ltx_td ltx_align_center">41 (0.04%)</td>
<td id="S3.T14.1.21.3" class="ltx_td ltx_align_center">14 (0.06%)</td>
<td id="S3.T14.1.21.4" class="ltx_td ltx_align_center">10 (0.04%)</td>
<td id="S3.T14.1.21.5" class="ltx_td ltx_nopad_r ltx_align_center">63 (0.04%)</td>
</tr>
<tr id="S3.T14.1.22" class="ltx_tr">
<td id="S3.T14.1.22.1" class="ltx_td ltx_align_left">VNP_AJT</td>
<td id="S3.T14.1.22.2" class="ltx_td ltx_align_center">37 (0.03%)</td>
<td id="S3.T14.1.22.3" class="ltx_td ltx_align_center">13 (0.06%)</td>
<td id="S3.T14.1.22.4" class="ltx_td ltx_align_center">9 (0.04%)</td>
<td id="S3.T14.1.22.5" class="ltx_td ltx_nopad_r ltx_align_center">59 (0.04%)</td>
</tr>
<tr id="S3.T14.1.23" class="ltx_tr">
<td id="S3.T14.1.23.1" class="ltx_td ltx_align_left">VP_CNJ</td>
<td id="S3.T14.1.23.2" class="ltx_td ltx_align_center">37 (0.03%)</td>
<td id="S3.T14.1.23.3" class="ltx_td ltx_align_center">7 (0.03%)</td>
<td id="S3.T14.1.23.4" class="ltx_td ltx_align_center">7 (0.03%)</td>
<td id="S3.T14.1.23.5" class="ltx_td ltx_nopad_r ltx_align_center">46 (0.03%)</td>
</tr>
<tr id="S3.T14.1.24" class="ltx_tr">
<td id="S3.T14.1.24.1" class="ltx_td ltx_align_left">IP</td>
<td id="S3.T14.1.24.2" class="ltx_td ltx_align_center">27 (0.02%)</td>
<td id="S3.T14.1.24.3" class="ltx_td ltx_align_center">4 (0.02%)</td>
<td id="S3.T14.1.24.4" class="ltx_td ltx_align_center">6 (0.02%)</td>
<td id="S3.T14.1.24.5" class="ltx_td ltx_nopad_r ltx_align_center">41 (0.03%)</td>
</tr>
<tr id="S3.T14.1.25" class="ltx_tr">
<td id="S3.T14.1.25.1" class="ltx_td ltx_align_left">X</td>
<td id="S3.T14.1.25.2" class="ltx_td ltx_align_center">26 (0.02%)</td>
<td id="S3.T14.1.25.3" class="ltx_td ltx_align_center">4 (0.02%)</td>
<td id="S3.T14.1.25.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.25.5" class="ltx_td ltx_nopad_r ltx_align_center">31 (0.02%)</td>
</tr>
<tr id="S3.T14.1.26" class="ltx_tr">
<td id="S3.T14.1.26.1" class="ltx_td ltx_align_left">VNP_OBJ</td>
<td id="S3.T14.1.26.2" class="ltx_td ltx_align_center">18 (0.02%)</td>
<td id="S3.T14.1.26.3" class="ltx_td ltx_align_center">3 (0.01%)</td>
<td id="S3.T14.1.26.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.26.5" class="ltx_td ltx_nopad_r ltx_align_center">26 (0.02%)</td>
</tr>
<tr id="S3.T14.1.27" class="ltx_tr">
<td id="S3.T14.1.27.1" class="ltx_td ltx_align_left">X_SBJ</td>
<td id="S3.T14.1.27.2" class="ltx_td ltx_align_center">17 (0.01%)</td>
<td id="S3.T14.1.27.3" class="ltx_td ltx_align_center">3 (0.01%)</td>
<td id="S3.T14.1.27.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.27.5" class="ltx_td ltx_nopad_r ltx_align_center">21 (0.01%)</td>
</tr>
<tr id="S3.T14.1.28" class="ltx_tr">
<td id="S3.T14.1.28.1" class="ltx_td ltx_align_left">X_OBJ</td>
<td id="S3.T14.1.28.2" class="ltx_td ltx_align_center">12 (0.01%)</td>
<td id="S3.T14.1.28.3" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.28.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.28.5" class="ltx_td ltx_nopad_r ltx_align_center">17 (0.01%)</td>
</tr>
<tr id="S3.T14.1.29" class="ltx_tr">
<td id="S3.T14.1.29.1" class="ltx_td ltx_align_left">VNP_SBJ</td>
<td id="S3.T14.1.29.2" class="ltx_td ltx_align_center">11 (0.01%)</td>
<td id="S3.T14.1.29.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.29.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.29.5" class="ltx_td ltx_nopad_r ltx_align_center">14 (0.01%)</td>
</tr>
<tr id="S3.T14.1.30" class="ltx_tr">
<td id="S3.T14.1.30.1" class="ltx_td ltx_align_left">L</td>
<td id="S3.T14.1.30.2" class="ltx_td ltx_align_center">3 (0.00%)</td>
<td id="S3.T14.1.30.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.30.4" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.30.5" class="ltx_td ltx_nopad_r ltx_align_center">4 (0.00%)</td>
</tr>
<tr id="S3.T14.1.31" class="ltx_tr">
<td id="S3.T14.1.31.1" class="ltx_td ltx_align_left">AP_AJT</td>
<td id="S3.T14.1.31.2" class="ltx_td ltx_align_center">2 (0.00%)</td>
<td id="S3.T14.1.31.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.31.4" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.31.5" class="ltx_td ltx_nopad_r ltx_align_center">4 (0.00%)</td>
</tr>
<tr id="S3.T14.1.32" class="ltx_tr">
<td id="S3.T14.1.32.1" class="ltx_td ltx_align_left">X_CMP</td>
<td id="S3.T14.1.32.2" class="ltx_td ltx_align_center">2 (0.00%)</td>
<td id="S3.T14.1.32.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.32.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.32.5" class="ltx_td ltx_nopad_r ltx_align_center">4 (0.00%)</td>
</tr>
<tr id="S3.T14.1.33" class="ltx_tr">
<td id="S3.T14.1.33.1" class="ltx_td ltx_align_left">X_CNJ</td>
<td id="S3.T14.1.33.2" class="ltx_td ltx_align_center">2 (0.00%)</td>
<td id="S3.T14.1.33.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.33.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.33.5" class="ltx_td ltx_nopad_r ltx_align_center">3 (0.00%)</td>
</tr>
<tr id="S3.T14.1.34" class="ltx_tr">
<td id="S3.T14.1.34.1" class="ltx_td ltx_align_left">X_MOD</td>
<td id="S3.T14.1.34.2" class="ltx_td ltx_align_center">2 (0.00%)</td>
<td id="S3.T14.1.34.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.34.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.34.5" class="ltx_td ltx_nopad_r ltx_align_center">2 (0.00%)</td>
</tr>
<tr id="S3.T14.1.35" class="ltx_tr">
<td id="S3.T14.1.35.1" class="ltx_td ltx_align_left">AP_CMP</td>
<td id="S3.T14.1.35.2" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.35.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.35.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.35.5" class="ltx_td ltx_nopad_r ltx_align_center">2 (0.00%)</td>
</tr>
<tr id="S3.T14.1.36" class="ltx_tr">
<td id="S3.T14.1.36.1" class="ltx_td ltx_align_left">R</td>
<td id="S3.T14.1.36.2" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.36.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.36.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.36.5" class="ltx_td ltx_nopad_r ltx_align_center">1 (0.00%)</td>
</tr>
<tr id="S3.T14.1.37" class="ltx_tr">
<td id="S3.T14.1.37.1" class="ltx_td ltx_align_left">VNP_CNJ</td>
<td id="S3.T14.1.37.2" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.37.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.37.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.37.5" class="ltx_td ltx_nopad_r ltx_align_center">1 (0.00%)</td>
</tr>
<tr id="S3.T14.1.38" class="ltx_tr">
<td id="S3.T14.1.38.1" class="ltx_td ltx_align_left">AP_SBJ</td>
<td id="S3.T14.1.38.2" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.38.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.38.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.38.5" class="ltx_td ltx_nopad_r ltx_align_center">1 (0.00%)</td>
</tr>
<tr id="S3.T14.1.39" class="ltx_tr">
<td id="S3.T14.1.39.1" class="ltx_td ltx_align_left">NP_SVJ</td>
<td id="S3.T14.1.39.2" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.39.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.39.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.39.5" class="ltx_td ltx_nopad_r ltx_align_center">0 (0.00%)</td>
</tr>
<tr id="S3.T14.1.40" class="ltx_tr">
<td id="S3.T14.1.40.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T14.1.40.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.2.1" class="ltx_text ltx_font_bold">114,491</span></td>
<td id="S3.T14.1.40.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.3.1" class="ltx_text ltx_font_bold">22,496</span></td>
<td id="S3.T14.1.40.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.4.1" class="ltx_text ltx_font_bold">25,033</span></td>
<td id="S3.T14.1.40.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.5.1" class="ltx_text ltx_font_bold">162,020</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS6.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.2 </span>Evaluation Metrics</h4>

<div id="S3.SS6.SSS2.p1" class="ltx_para">
<p id="S3.SS6.SSS2.p1.1" class="ltx_p">The evaluation metrics for KLUE-DP are 1) unlabeled attachment score (UAS) and 2) labeled attachment score (LAS), which are popular metrics for DP. Given the goal of DP is to predict head indices (HEAD) and dependency relation classes (DEPREL), UAS only counts HEAD prediction while LAS counts both HEAD and DEPREL. Specifically, UAS calculates macro F1 score on HEAD prediction, while LAS calculates macro F1 score on DEPREL whose HEAD prediction is correct. Both scores give the same importance to all classes. For LAS, since DEPREL distribution is highly skewed, we combine the predictions on the labels with a cumulative frequency of 1% from the bottom into a single label (OTHERS) and then calculate F1 score. The less-appeared labels are referred in Table&nbsp;<a href="#S3.T14" title="Table 14 ‣ Final Dataset ‣ 3.6.1 Dataset Construction ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>.</p>
</div>
</section>
<section id="S3.SS6.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.3 </span>Related Work</h4>

<div id="S3.SS6.SSS3.p1" class="ltx_para">
<p id="S3.SS6.SSS3.p1.1" class="ltx_p">The Penn Treebank <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite> is a constituency parsed dataset created from 1989 to 1996. It has a size of about 3 million words, including IBM computer manuals, nursing notes, Wall Street Journal articles, phone conversations. A total of 48 POS tags and 18 syntax tags are used by combining meta tags such as symbols. The Penn Treebank was the best-known parsing data set before dependency parsing became prevalent. Later studies convert the Penn Treebank to dependency parsing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.</p>
</div>
<div id="S3.SS6.SSS3.p2" class="ltx_para">
<p id="S3.SS6.SSS3.p2.1" class="ltx_p">A representative DP corpus is the Universal Dependencies(UD) dataset.<span id="footnote40" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">40</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">40</sup><span class="ltx_tag ltx_tag_note">40</span><a target="_blank" href="https://universaldependencies.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://universaldependencies.org</a></span></span></span> UD is de facto standard of DP data, aiming for a unified treebank annotation in various languages. Google Universal POS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite> composed of 12 tags, was developed and a corpus was built that applied it to 25 different languages. Also <cite class="ltx_cite ltx_citemacro_citet">de&nbsp;Marneffe and Manning [<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> studied guidelines for dependency parsing markers used in Stanford parsers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. The Universal Dependency Treebank Project in 2013 attempted to combine the two studies above to have a consistent annotation system for multiple languages. UD started by modifying and supplementing this. UD first started in 2015 and <cite class="ltx_cite ltx_citemacro_citet">Nivre et&nbsp;al. [<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> and 10 corpora in a total of 10 languages were released through the website. As of 2021, UD (UD 2.7v) offers 104 languages and 183 corpora.</p>
</div>
<div id="S3.SS6.SSS3.p3" class="ltx_para">
<p id="S3.SS6.SSS3.p3.1" class="ltx_p">The corpus constructed with UD scheme is made according to a certain structure called CoNLL-U format. Since UD aims to study general linguistic universality by using the same tag and annotation system in different languages, a unified format for integrating and managing each corpus is needed. The CoNLL-U format is a modified version of this CoNLL format so that it can well represent Universal dependency parsing. CoNLL-U format consists of 10 columns, each column display a word index (ID), word form (FORM), lemma of word form (LEMMA), universal part-of-speech tag (UPOS), language-specific part- It represents of-speech tag (XPOS), list of morphological features (FEATS), head of the current word (HEAD), dependency relation (DEPREL), enhanced dependency graph (DEPS), any other annotation (MISC). In this format, each word stands on a line along with different associated features (word form, lemma, POS tag, etc.) and we adopt this format in our final dataset.</p>
</div>
<div id="S3.SS6.SSS3.p4" class="ltx_para">
<p id="S3.SS6.SSS3.p4.1" class="ltx_p">In Korean, DP corpus is divided into those that follow the UD scheme and those that do not. Among the former are The Google Korean Universal Dependency Treebank (GKT), The KAIST Korean Universal Dependency Treebank (KTB), and The Penn Korean Universal Dependency Treebank (PKT). These three datasets are converted from The Google Korean Treebank <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>, The Kaist Treebank <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite>, and The Penn Korean treebank <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> according to the UD scheme, respectively&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. These were first automatically converted according to the head-finding rule and then heuristically modified. These are composed of 6k, 27k, and 5k sentences, respectively, and include the genres of blog, newswire, literature, academic, and manuscript. Among them, PKT was revised by changing the analysis unit and several rules to further reveal the characteristics of Korean <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>.</p>
</div>
<div id="S3.SS6.SSS3.p5" class="ltx_para">
<p id="S3.SS6.SSS3.p5.1" class="ltx_p">Corpora that do not follow the UD scheme include the TTA DP Corpus built by Electronics and Telecommunications Research Institute (ETRI) and the Modu Corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> built by the National Institute of the Korean Language (NIKL). Both corpora follow the CoNLL format, and use their own tagset, which was developed from the 21st century Sejong Plan corpus. The syntactic analysis corpus of the 21st century Sejong Plan is constructed according to the constituency grammar, following a scheme similar to the Penn Treebank. Unlike the dependency grammar, which grasps only the dominant relationship between two words, the constituency grammar identifies the relationship between words hierarchically. However, since Korean has relatively free word order, dependency parsing is more suitable than phrase-structure parsing. Studies on converting the 21st century Sejong Plan corpus into DP format have been conducted, and since then, corpora that use the 21st century Sejong Plan’s tagset but follow dependency parsing have been constructed. The size of TTA DP corpus is about 27k, and the Modu corpus about 2000k. Unlike UD, which emphasizes general linguistic characteristics, better represents the characteristics of Korean as an individual language, and serves as a national standard for Korean DP tagging. Also, there are already corpus annotated according to the TTA scheme, so we consider compatibility between them and our benchmark. For this reason, we constructed the KLUE-DP using the TTA tagset.</p>
</div>
</section>
<section id="S3.SS6.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.4 </span>Conclusion</h4>

<div id="S3.SS6.SSS4.p1" class="ltx_para">
<p id="S3.SS6.SSS4.p1.1" class="ltx_p">We build a Korean DP benchmark KLUE-DP consisting of formal news and informal user-generated web data. KLUE-DP is helpful for developing a DP model that can be used in multiple domains. POS tagging is performed together to improve DP performance, and the tagset and guideline for DP and POS tagging are applied by revising the existing TTA dataset. This guideline is customized to reflect the characteristics of Korean (agglutinative, free word order, etc.), and it also tackles omission of predicates in web data or errors in spacing. We hope that our benchmarks will help in the development of Korean DP models and other natural language processing.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.7 </span>Machine Reading Comprehension (MRC)</h3>

<div id="S3.SS7.p1" class="ltx_para">
<p id="S3.SS7.p1.1" class="ltx_p">Machine reading comprehension (MRC) is a task designed to evaluate models’ abilities to read a given text passage and then answer a question about the passage, that is, its ability of comprehension.</p>
</div>
<div id="S3.SS7.p2" class="ltx_para">
<p id="S3.SS7.p2.1" class="ltx_p">Most of existing, widely-used MRC benchmarks are largely in English <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib112" title="" class="ltx_ref">112</a>, <a href="#bib.bib113" title="" class="ltx_ref">113</a>, <a href="#bib.bib145" title="" class="ltx_ref">145</a>, <a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite>. Those resources are widely used in evaluating pre-trained language models since it is one of the most intuitive methods for measuring text comprehension. SQuAD 1.1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite> and SQuAD 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> are popular evaluation tasks along with GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib82" title="" class="ltx_ref">82</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. BoolQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, ReCoRD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite>, and MultiRC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> are selected as a member of SuperGLUE for rigorous evaluation of language models. Recently, open-domain QA task which can be viewed as an MRC task without a given text passage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib145" title="" class="ltx_ref">145</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, is included in a knowledge-intensive NLP task benchmark <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>.</p>
</div>
<div id="S3.SS7.p3" class="ltx_para">
<p id="S3.SS7.p3.1" class="ltx_p">Motivated by those datasets, MRC has become an essential task in NLU benchmarks for various languages such as Indonesian <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>]</cite>, Chinese <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>, and Russian <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>. In Korean, however, an appropriate MRC benchmark is not available because existing Korean MRC datasets are either less challenging, limited in access, or simply machine-translated from an English dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>. We therefore include MRC in KLUE and create a new challenging Korean MRC benchmark (KLUE-MRC) with the following contributions:</p>
</div>
<div id="S3.SS7.p4" class="ltx_para">
<ul id="S3.I5" class="ltx_itemize">
<li id="S3.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i1.p1" class="ltx_para">
<p id="S3.I5.i1.p1.1" class="ltx_p"><span id="S3.I5.i1.p1.1.1" class="ltx_text ltx_font_bold">Providing multiple question types</span>: In order to evaluate different aspects of MRC capability of models, we provide three question types: paraphrase, multi-sentence reasoning, and unanswerable. We collect questions by following strict guidelines with specific sets of rules for each type.</p>
</div>
</li>
<li id="S3.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i2.p1" class="ltx_para">
<p id="S3.I5.i2.p1.1" class="ltx_p"><span id="S3.I5.i2.p1.1.1" class="ltx_text ltx_font_bold">Preventing reasoning shortcuts</span>: We prevent MRC models from exploiting reasoning shortcuts with simple word-matching by enforcing lexical and syntactic variations when workers generate questions. Also, we aim to generate questions which can be answered by considering the full query sentence.</p>
</div>
</li>
<li id="S3.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i3.p1" class="ltx_para">
<p id="S3.I5.i3.p1.1" class="ltx_p"><span id="S3.I5.i3.p1.1.1" class="ltx_text ltx_font_bold">Multiple passage domains accessible to everyone</span> : We include news domain passages as well as Wikipedia. To guarantee CC BY-SA license of KLUE-MRC, we made signed contracts with corresponding news providers.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS7.p5" class="ltx_para">
<p id="S3.SS7.p5.1" class="ltx_p">We formulate MRC as a task of predicting the answer span of the question from the given text passage. The input is a concatenated sequence of the question and the passage separated with a delimiter. The output is the start and end positions of the predicted answer span within the passage.
</p>
</div>
<div id="S3.SS7.p6" class="ltx_para">
<p id="S3.SS7.p6.1" class="ltx_p">We evaluate models with two metrics: 1) exact match (EM) and 2) character-level ROUGE-W. Note that character-level ROUGE-W is different from the character-level F1 score used in the previous Korean MRC datasets. If the question is unanswerable within the given passage, the model should predict the empty answer string. The motivation of our metrics are described in Section&nbsp;<a href="#S3.SS7.SSS2" title="3.7.2 Evaluation Metrics ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.7.2</span></a>.</p>
</div>
<section id="S3.SS7.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.1 </span>Dataset Construction</h4>

<section id="S3.SS7.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS7.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS7.SSS1.Px1.p1.1" class="ltx_p">First, we collect passages from Korean WIKIPEDIA and news articles provided by The Korea Economy Daily and ACROFAN. WIKIPEDIA articles are one of the most commonly used resources for creating MRC datasets.
We additionally include news articles reporting contemporary social issues to enhance diversity of passages. They are provided by The Korea Economy Daily and ACROFAN. As news articles are generally copyrighted work, we sign a contract with the news providers to use and redistribute the articles under CC BY-SA license only for building a dataset for machine learning purposes. We believe multi-domain corpus can help MRC models enhance their generalizability.</p>
</div>
<div id="S3.SS7.SSS1.Px1.p2" class="ltx_para">
<p id="S3.SS7.SSS1.Px1.p2.1" class="ltx_p">We preprocess the corpus to collect passages. For WIKIPEDIA articles, we remove duplicates in other existing Korean MRC benchmarks (e.g., KorQuAD) for precise evaluation of models. Then, we split each article by its sections to obtain passages. For the news articles, we filter out political articles and articles belonging to categories which have less than 100 articles. We finally gather all preprocessed passages whose length is longer than 512 and shorter than 2048 in characters.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS7.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS7.SSS1.Px2.p1.1" class="ltx_p">We annotate questions and answers by giving passages to crowdworkers. We provide a detailed tutorial session to introduce our guidelines. 60 out of 80 workers are selected after a pilot test of creating 15 question-answer pairs with a given passage. The selected workers generate questions and label corresponding answers spans (for Types 1 and 2) or fake answers spans (for Type 3). We use Tagtog annotation toolkit <span id="footnote41" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">41</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">41</sup><span class="ltx_tag ltx_tag_note">41</span>https://www.tagtog.net/</span></span></span> for the annotation.
We assign three inspectors for each question type to validate the generated questions and answers following common and type-specific guidelines.
If the generated question-answer pair fails to pass the inspection, the worker refines it based on the feedback given by the inspector.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">1. Common Guidelines</h5>

<div id="S3.SS7.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS7.SSS1.Px3.p1.1" class="ltx_p">We first build common annotation guidelines for crowdworkers. The workers are required to follow the instructions during corresponding question generation and answer span annotation for all three question types as below.</p>
</div>
<div id="S3.SS7.SSS1.Px3.p2" class="ltx_para">
<p id="S3.SS7.SSS1.Px3.p2.1" class="ltx_p"><span id="S3.SS7.SSS1.Px3.p2.1.1" class="ltx_text ltx_font_bold">A question should:</span></p>
</div>
<div id="S3.SS7.SSS1.Px3.p3" class="ltx_para">
<ul id="S3.I6" class="ltx_itemize">
<li id="S3.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i1.p1" class="ltx_para">
<p id="S3.I6.i1.p1.1" class="ltx_p"><span id="S3.I6.i1.p1.1.1" class="ltx_text ltx_font_bold">Be natural as a web search query</span>: Trying to generate challenging questions can lead to the use of unnatural expressions. We guide workers to make natural questions as if they are for web search queries. We care about the generalizability of questions to extend the task to open-domain QA tasks in future work.</p>
</div>
</li>
<li id="S3.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i2.p1" class="ltx_para">
<p id="S3.I6.i2.p1.1" class="ltx_p"><span id="S3.I6.i2.p1.1.1" class="ltx_text ltx_font_bold">Avoid omission</span>: Pronoun-dropping is prevalent in Korean, hence it tends to omit the subject or object. The omission can result in ambiguity for finding answers. We explicitly guide workers to keep all grammatical components in generated questions.</p>
</div>
</li>
<li id="S3.I6.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i3.p1" class="ltx_para">
<p id="S3.I6.i3.p1.1" class="ltx_p"><span id="S3.I6.i3.p1.1.1" class="ltx_text ltx_font_bold">Not copy a phrase in the passage</span>: Questions might have similar meaning to some phrases in the passage but should not contain exactly the same phrase. This mitigates high word-overlap between questions and the passage as reported in previous work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>.</p>
</div>
</li>
<li id="S3.I6.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i4.p1" class="ltx_para">
<p id="S3.I6.i4.p1.1" class="ltx_p"><span id="S3.I6.i4.p1.1.1" class="ltx_text ltx_font_bold">Not refer to external knowledge</span>: Questions need to be fully understood without any external knowledge. We do not allow workers using their background knowledge or any world knowledge to generate a question. Questions should be derived solely based on the given passage.</p>
</div>
</li>
<li id="S3.I6.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i5.p1" class="ltx_para">
<p id="S3.I6.i5.p1.1" class="ltx_p"><span id="S3.I6.i5.p1.1.1" class="ltx_text ltx_font_bold">Be meaningful in every part for finding the answer</span>: Answers should not be found with only a small fraction of the question. We encourage workers to generate questions that require understanding of the whole question text to find an answer. We do not allow the use of expressions that appear only once in the passage because models can easily infer answers without understanding the whole question.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS7.SSS1.Px3.p4" class="ltx_para">
<p id="S3.SS7.SSS1.Px3.p4.1" class="ltx_p"><span id="S3.SS7.SSS1.Px3.p4.1.1" class="ltx_text ltx_font_bold">An answer should:</span></p>
</div>
<div id="S3.SS7.SSS1.Px3.p5" class="ltx_para">
<ul id="S3.I7" class="ltx_itemize">
<li id="S3.I7.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I7.i1.p1" class="ltx_para">
<p id="S3.I7.i1.p1.1" class="ltx_p"><span id="S3.I7.i1.p1.1.1" class="ltx_text ltx_font_bold">Be a unique entity within a passage</span>: To clarify what to ask, only a single answer should be inferred from the question. When answers can be represented in various lexical forms, workers should mark all answer spans (e.g. Television, TV).</p>
</div>
</li>
<li id="S3.I7.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I7.i2.p1" class="ltx_para">
<p id="S3.I7.i2.p1.1" class="ltx_p"><span id="S3.I7.i2.p1.1.1" class="ltx_text ltx_font_bold">Not be the main topic or title</span>: We aim to prevent a known artifact which the most frequently appeared words within a given passage are likely to be the answer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS7.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2. Type-Specific Guidelines</h5>

<div id="S3.SS7.SSS1.Px4.p1" class="ltx_para">
<p id="S3.SS7.SSS1.Px4.p1.1" class="ltx_p">Here we elaborate question type-specific guidelines. These guidelines are additionally presented to workers along with the common guideline above.</p>
</div>
<div id="S3.SS7.SSS1.Px4.p2" class="ltx_para">
<p id="S3.SS7.SSS1.Px4.p2.1" class="ltx_p"><span id="S3.SS7.SSS1.Px4.p2.1.1" class="ltx_text ltx_font_bold">2.1. Question Paraphrasing (Type 1)</span>
Type 1 examples focus on paraphrasing the passage sentences when generating questions to reduce word overlap between them. The paraphrasing enables us to validate whether the model can correctly understand the semantics of the paraphrased question and infer the answer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>.</p>
</div>
<figure id="S3.T15" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 15: </span>Paraphrase question type example for Korean and its English translation</figcaption>
<div id="S3.T15.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:429.6pt;height:181.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S3.T15.1.1" class="ltx_p"><span id="S3.T15.1.1.1" class="ltx_text">
<span id="S3.T15.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T15.1.1.1.1.1" class="ltx_tr">
<span id="S3.T15.1.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T15.1.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.1.1.1.1" class="ltx_p" style="width:43.4pt;"><span id="S3.T15.1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Type</span></span>
</span></span>
<span id="S3.T15.1.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T15.1.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.1.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T15.1.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Korean</span></span>
</span></span>
<span id="S3.T15.1.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T15.1.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.1.3.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T15.1.1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">English (Translated)</span></span>
</span></span></span>
<span id="S3.T15.1.1.1.1.2" class="ltx_tr">
<span id="S3.T15.1.1.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T15.1.1.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.2.1.1.1" class="ltx_p" style="width:43.4pt;">Passage</span>
</span></span>
<span id="S3.T15.1.1.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T15.1.1.1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.2.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T15.1.1.1.1.2.2.1.1.1" class="ltx_text" style="font-size:90%;">브르타뉴 공국은 939년 트랑라포레 전투에서 기원을 했으며, 브르타뉴와 노르망디 간에 경계인 쿠에농강에 세워졌다.</span></span>
</span></span>
<span id="S3.T15.1.1.1.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T15.1.1.1.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.2.3.1.1" class="ltx_p" style="width:173.4pt;">Duchy of Brittany originates in the Battle of Trans-la-Forêt of year 939, and was established on and around the Couesnon River, the boundary of Britanny and Normandy.</span>
</span></span></span>
<span id="S3.T15.1.1.1.1.3" class="ltx_tr">
<span id="S3.T15.1.1.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T15.1.1.1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.3.1.1.1" class="ltx_p" style="width:43.4pt;">
<span id="S3.T15.1.1.1.1.3.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T15.1.1.1.1.3.1.1.1.1.1" class="ltx_tr">
<span id="S3.T15.1.1.1.1.3.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Good</span></span>
<span id="S3.T15.1.1.1.1.3.1.1.1.1.2" class="ltx_tr">
<span id="S3.T15.1.1.1.1.3.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Question</span></span>
</span></span>
</span></span>
<span id="S3.T15.1.1.1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T15.1.1.1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.3.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T15.1.1.1.1.3.2.1.1.1" class="ltx_text" style="font-size:90%;">브르타뉴와 노르망디를 구분짓는 것은?</span></span>
</span></span>
<span id="S3.T15.1.1.1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T15.1.1.1.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.3.3.1.1" class="ltx_p" style="width:173.4pt;">What distinguishes Britanny and Normandy?</span>
</span></span></span>
<span id="S3.T15.1.1.1.1.4" class="ltx_tr">
<span id="S3.T15.1.1.1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T15.1.1.1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.4.1.1.1" class="ltx_p" style="width:43.4pt;">
<span id="S3.T15.1.1.1.1.4.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T15.1.1.1.1.4.1.1.1.1.1" class="ltx_tr">
<span id="S3.T15.1.1.1.1.4.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Bad</span></span>
<span id="S3.T15.1.1.1.1.4.1.1.1.1.2" class="ltx_tr">
<span id="S3.T15.1.1.1.1.4.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Question</span></span>
</span></span>
</span></span>
<span id="S3.T15.1.1.1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T15.1.1.1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.4.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T15.1.1.1.1.4.2.1.1.1" class="ltx_text" style="font-size:90%;">브르타뉴와 노르망디 간의 경계는?</span></span>
</span></span>
<span id="S3.T15.1.1.1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T15.1.1.1.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.4.3.1.1" class="ltx_p" style="width:173.4pt;">What is the boundary of Britanny and Normandy?</span>
</span></span></span>
<span id="S3.T15.1.1.1.1.5" class="ltx_tr">
<span id="S3.T15.1.1.1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T15.1.1.1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.5.1.1.1" class="ltx_p" style="width:43.4pt;">Answer</span>
</span></span>
<span id="S3.T15.1.1.1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T15.1.1.1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.5.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T15.1.1.1.1.5.2.1.1.1" class="ltx_text" style="font-size:90%;">쿠에농 강</span></span>
</span></span>
<span id="S3.T15.1.1.1.1.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T15.1.1.1.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T15.1.1.1.1.5.3.1.1" class="ltx_p" style="width:173.4pt;">Cuesnon River</span>
</span></span></span>
</span></span></p>
</span></div>
</figure>
<div id="S3.SS7.SSS1.Px4.p3" class="ltx_para">
<p id="S3.SS7.SSS1.Px4.p3.1" class="ltx_p">In our annotation guide for paraphrased questions, we further prevent workers from generating them by simply shifting the order of subsequent phrases or changing the functional particles. Specifically, workers create questions by following principles:</p>
</div>
<div id="S3.SS7.SSS1.Px4.p4" class="ltx_para">
<ul id="S3.I8" class="ltx_itemize">
<li id="S3.I8.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I8.i1.p1" class="ltx_para">
<p id="S3.I8.i1.p1.1" class="ltx_p">Either syntactic or lexical variation should be applied to text snippets in the passage.</p>
<ul id="S3.I8.i1.I1" class="ltx_itemize">
<li id="S3.I8.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I8.i1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I8.i1.I1.i1.p1" class="ltx_para">
<p id="S3.I8.i1.I1.i1.p1.1" class="ltx_p">For syntactic variation, reconstructing the structure of the original sentence is preferred. Minimal changes such as swapping order between the nearby phrases is not allowed.</p>
</div>
</li>
<li id="S3.I8.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I8.i1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I8.i1.I1.i2.p1" class="ltx_para">
<p id="S3.I8.i1.I1.i2.p1.1" class="ltx_p">For lexical variation, changing verbs or modifiers is required, and variation of noun phrases is recommended.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="S3.I8.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I8.i2.p1" class="ltx_para">
<p id="S3.I8.i2.p1.1" class="ltx_p">More than half of the words in the question should not overlap with the corresponding part (sentence) of the passage.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS7.SSS1.Px4.p5" class="ltx_para">
<p id="S3.SS7.SSS1.Px4.p5.1" class="ltx_p">Then we comprehensively check whether the question has low word overlap with the passage. As shown in Table <a href="#S3.T15" title="Table 15 ‣ 2. Type-Specific Guidelines ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a>, where Cuesnon River is the answer, the question paraphrases the given evidence sentence (“the boundary of Britanny and Normandy”) by providing a new sentence structure. The structure is changed from a wh-question with copula to a question with an intransitive verb. Also, a new term “distinguishes” is introduced which replaces the phrase “is the boundary of”.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2.2. Multiple-Sentence Reasoning (Type 2)</h5>

<div id="S3.SS7.SSS1.Px5.p1" class="ltx_para">
<p id="S3.SS7.SSS1.Px5.p1.1" class="ltx_p">Type 2 examples focus on making questions requiring multiple-sentence reasoning. Multiple-sentence reasoning requires models to derive answers from the questions by reasoning over at least two sentences in the passage. We focus on evaluating whether an MRC model can infer the answer span by comprehensively aggregating the information spread across the passage. We carefully design annotation guidelines for multiple-sentence reasoning examples. Since <cite class="ltx_cite ltx_citemacro_citet">Min et&nbsp;al. [<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite> report multiple-sentence reasoning questions can easily fall back to single-sentence reasoning, we aim to avoid such cases by guiding workers to follow the steps below:</p>
<ul id="S3.I9" class="ltx_itemize">
<li id="S3.I9.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i1.p1" class="ltx_para">
<p id="S3.I9.i1.p1.1" class="ltx_p"><span id="S3.I9.i1.p1.1.1" class="ltx_text ltx_font_bold">(Step 1.)</span> Find at least two statements in the given passage that share some properties.</p>
</div>
</li>
<li id="S3.I9.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i2.p1" class="ltx_para">
<p id="S3.I9.i2.p1.1" class="ltx_p"><span id="S3.I9.i2.p1.1.1" class="ltx_text ltx_font_bold">(Step 2.)</span> Select one as the answer among the entities regarding the shared properties.</p>
</div>
</li>
<li id="S3.I9.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i3.p1" class="ltx_para">
<p id="S3.I9.i3.p1.1" class="ltx_p"><span id="S3.I9.i3.p1.1.1" class="ltx_text ltx_font_bold">(Step 3.)</span> Generate a question with the selected entity.</p>
</div>
</li>
</ul>
</div>
<figure id="S3.T16" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 16: </span>Multiple sentence reasoning question type example for Korean and its English translation</figcaption>
<div id="S3.T16.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.9pt;height:343.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S3.T16.1.1" class="ltx_p"><span id="S3.T16.1.1.1" class="ltx_text">
<span id="S3.T16.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T16.1.1.1.1.1" class="ltx_tr">
<span id="S3.T16.1.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T16.1.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.1.1.1.1" class="ltx_p" style="width:47.7pt;"><span id="S3.T16.1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Type</span></span>
</span></span>
<span id="S3.T16.1.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T16.1.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.1.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T16.1.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Korean</span></span>
</span></span>
<span id="S3.T16.1.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T16.1.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.1.3.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T16.1.1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">English (Translated)</span></span>
</span></span></span>
<span id="S3.T16.1.1.1.1.2" class="ltx_tr">
<span id="S3.T16.1.1.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.2.1.1.1" class="ltx_p" style="width:47.7pt;">Passage</span>
</span></span>
<span id="S3.T16.1.1.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.2.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T16.1.1.1.1.2.2.1.1.1" class="ltx_text" style="font-size:90%;">트라야누스 황제 시대(98년-117년)에 로마 제국은 북으로는 스코틀랜드에서 남으로는 아프리카 수단까지, 서로는 포르투갈의 대서양 연안에서 동으로는 카프카스 지방까지 최대 판도를 이룩했다. 오늘날 면적으로 환산하면 현재 미국 면적의 2/3에 달하고 인구도 현 미국의 절반에 약간 안되는 정도로 추산된다. 서기 5세기 경 서로마 제국은 멸망 후 게르만족의 여러 독립 국가로 갈라져 프랑크 왕국, 신성 로마 제국 등 로마의 후계자를 자처하는 여타 서유럽의 정치 세력들이 나타난다.</span></span>
</span></span>
<span id="S3.T16.1.1.1.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.2.3.1.1" class="ltx_p" style="width:173.4pt;">Under Trajan(AD 98-AD 117), Roman Empire reached its territorial peak. In terms of the area today, it is estimated to represent two-thirds of the current U.S. area and its population is only slightly less than half that of the current U.S. Plagued by internal instability and attacked by various migrating peoples, the western part of the empire broke up into independent barbarian kingdoms in the 5th century.</span>
</span></span></span>
<span id="S3.T16.1.1.1.1.3" class="ltx_tr">
<span id="S3.T16.1.1.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.3.1.1.1" class="ltx_p" style="width:47.7pt;">Statement A</span>
</span></span>
<span id="S3.T16.1.1.1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.3.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T16.1.1.1.1.3.2.1.1.1" class="ltx_text" style="font-size:90%;">오늘날 면적으로 환산하면 현재 미국 면적의 2/3에 달하고 인구도 현 미국의 절반에 약간 안되는 정도로 추산된다.</span></span>
</span></span>
<span id="S3.T16.1.1.1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.3.3.1.1" class="ltx_p" style="width:173.4pt;">In terms of the area today, it is estimated to represent two-thirds of the current U.S. area</span>
</span></span></span>
<span id="S3.T16.1.1.1.1.4" class="ltx_tr">
<span id="S3.T16.1.1.1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.4.1.1.1" class="ltx_p" style="width:47.7pt;">Statement B</span>
</span></span>
<span id="S3.T16.1.1.1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.4.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T16.1.1.1.1.4.2.1.1.1" class="ltx_text" style="font-size:90%;">트라야누스 황제 시대(98년-117년)에 로마 제국은 북으로는 스코틀랜드에서 남으로는 아프리카 수단까지, 서로는 포르투갈의 대서양 연안에서 동으로는 카프카스 지방까지 최대 판도를 이룩했다.</span></span>
</span></span>
<span id="S3.T16.1.1.1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.4.3.1.1" class="ltx_p" style="width:173.4pt;">Under Trajan(AD 98-AD 117), Roman Empire reached its territorial peak.</span>
</span></span></span>
<span id="S3.T16.1.1.1.1.5" class="ltx_tr">
<span id="S3.T16.1.1.1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.5.1.1.1" class="ltx_p" style="width:47.7pt;">
<span id="S3.T16.1.1.1.1.5.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T16.1.1.1.1.5.1.1.1.1.1" class="ltx_tr">
<span id="S3.T16.1.1.1.1.5.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Shared</span></span>
<span id="S3.T16.1.1.1.1.5.1.1.1.1.2" class="ltx_tr">
<span id="S3.T16.1.1.1.1.5.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Properties</span></span>
</span></span>
</span></span>
<span id="S3.T16.1.1.1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.5.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T16.1.1.1.1.5.2.1.1.1" class="ltx_text" style="font-size:90%;">로마제국, 트라야누스 황제시대(98년-117년)</span></span>
</span></span>
<span id="S3.T16.1.1.1.1.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.5.3.1.1" class="ltx_p" style="width:173.4pt;">Roman Empire, Trajan(AD 98-AD 117)</span>
</span></span></span>
<span id="S3.T16.1.1.1.1.6" class="ltx_tr">
<span id="S3.T16.1.1.1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.6.1.1.1" class="ltx_p" style="width:47.7pt;">Question</span>
</span></span>
<span id="S3.T16.1.1.1.1.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.6.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T16.1.1.1.1.6.2.1.1.1" class="ltx_text" style="font-size:90%;">로마 제국의 면적이 현재 미국 면적의 2/3에 다다르던 시기는 언제인가?</span></span>
</span></span>
<span id="S3.T16.1.1.1.1.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T16.1.1.1.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.6.3.1.1" class="ltx_p" style="width:173.4pt;">When was the area of the Roman Empire two-thirds of that of the current U.S.?</span>
</span></span></span>
<span id="S3.T16.1.1.1.1.7" class="ltx_tr">
<span id="S3.T16.1.1.1.1.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T16.1.1.1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.7.1.1.1" class="ltx_p" style="width:47.7pt;">Answer</span>
</span></span>
<span id="S3.T16.1.1.1.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T16.1.1.1.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.7.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T16.1.1.1.1.7.2.1.1.1" class="ltx_text" style="font-size:90%;">트라야누스 황제 시대(98년-117년) / 트라야누스 황제 시대 / 98년-117년</span></span>
</span></span>
<span id="S3.T16.1.1.1.1.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T16.1.1.1.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T16.1.1.1.1.7.3.1.1" class="ltx_p" style="width:173.4pt;">Trajan(AD 98-AD 117) / Trajan / AD 98-AD 117</span>
</span></span></span>
</span></span></p>
</span></div>
</figure>
<div id="S3.SS7.SSS1.Px5.p2" class="ltx_para">
<p id="S3.SS7.SSS1.Px5.p2.1" class="ltx_p">The example in Table <a href="#S3.T16" title="Table 16 ‣ 2.2. Multiple-Sentence Reasoning (Type 2) ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a> follows the steps described above. Shared properties between the two statements (A: “In terms of the area today, it is estimated to represent two-thirds of the current U.S. area”, B: “Under Trajan(AD 98-AD 117), Roman Empire reached its territorial peak.”) are “Roman Empire” and “(Under) Trajan(AD 98 -AD 117)”. Assume we pick “Trajan(AD 98-AD 117)” as the answer and generate a question “When was the area of the Roman Empire two-thirds of that of the current U.S.?”. Neither of the two statements is enough to single out the answer alone. When given the question and statement A alone, it is not possible to resolve an answer between “Trajan(AD 98-AD 117)” and “the 5th century” which both represent time period in the passage. Since statement B does not include specific information on the territory size, it is also not sufficient to narrow down the answer by itself. Therefore, statement A and B both needs to be aggregated to correctly answer the question.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2.3. Unanswerable Questions (Type 3)</h5>

<div id="S3.SS7.SSS1.Px6.p1" class="ltx_para">
<p id="S3.SS7.SSS1.Px6.p1.1" class="ltx_p">Type 3 examples are questions unable to be answered within the given passage. We name these as ‘unanswerable’ questions. In the real world, a question is often unanswerable if a passage is not available. If a model is built upon the premise that an answer always exists within the passage, it would not effectively handle such cases as SQuAD 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> pointed out. We therefore add unanswerable questions in our benchmark to incentivize models to identify whether a question is answerable or not.</p>
</div>
<div id="S3.SS7.SSS1.Px6.p2" class="ltx_para">
<p id="S3.SS7.SSS1.Px6.p2.1" class="ltx_p">In the annotation guideline, we present the following principles to generate desirable unanswerable questions. The unanswerable questions should:</p>
</div>
<div id="S3.SS7.SSS1.Px6.p3" class="ltx_para">
<ul id="S3.I10" class="ltx_itemize">
<li id="S3.I10.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I10.i1.p1" class="ltx_para">
<p id="S3.I10.i1.p1.1" class="ltx_p"><span id="S3.I10.i1.p1.1.1" class="ltx_text ltx_font_bold">Be relevant to the passage:</span> An entity appearing in the given passage should be included in the question. The entity makes the question relevant to the passage. Otherwise the question would be too easy to be determined as unanswerable.</p>
</div>
</li>
<li id="S3.I10.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I10.i2.p1" class="ltx_para">
<p id="S3.I10.i2.p1.1" class="ltx_p"><span id="S3.I10.i2.p1.1.1" class="ltx_text ltx_font_bold">Have fake answers within the passage:</span> A fake answer is plausible but incorrect regarding the corresponding question. The fake answer should exist in the passage as a distractor.</p>
</div>
</li>
<li id="S3.I10.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I10.i3.p1" class="ltx_para">
<p id="S3.I10.i3.p1.1" class="ltx_p"><span id="S3.I10.i3.p1.1.1" class="ltx_text ltx_font_bold">Not have correct answers within the passage:</span> Despite the existence of fake answers, the correct answer for the generated question must not exist in the passage.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS7.SSS1.Px6.p4" class="ltx_para">
<p id="S3.SS7.SSS1.Px6.p4.1" class="ltx_p">In our setting, a model is likely to fail to identify the question’s unanswerability based on the word overlap between the question and the passage.
Our question includes entities from the passage which increases the overlap. In that case, an MRC model would choose plausible fake answers that exist in the passage.</p>
</div>
<div id="S3.SS7.SSS1.Px6.p5" class="ltx_para">
<p id="S3.SS7.SSS1.Px6.p5.1" class="ltx_p">Table <a href="#S3.T17" title="Table 17 ‣ 2.3. Unanswerable Questions (Type 3) ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a> shows an example of the Type 3 problem. The question includes “bandwidth” which also exists in the given passage.
The question is asking for the bandwidth, so “1 to 5 Gigabit Ethernet” would be a plausible but incorrect answer.
There is no cue about the correct answer to “bandwidth-hungry server” from the question in the passage. The model should predict the empty string using the out of the context span range, such as using the [CLS] token from BERT.</p>
</div>
<figure id="S3.T17" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 17: </span>Unanswerable question type example for Korean and its English translation</figcaption>
<div id="S3.T17.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:429.6pt;height:112.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S3.T17.1.1" class="ltx_p"><span id="S3.T17.1.1.1" class="ltx_text">
<span id="S3.T17.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T17.1.1.1.1.1" class="ltx_tr">
<span id="S3.T17.1.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T17.1.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.1.1.1.1" class="ltx_p" style="width:43.4pt;"><span id="S3.T17.1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Type</span></span>
</span></span>
<span id="S3.T17.1.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T17.1.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.1.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Korean</span></span>
</span></span>
<span id="S3.T17.1.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T17.1.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.1.3.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">English (Translated)</span></span>
</span></span></span>
<span id="S3.T17.1.1.1.1.2" class="ltx_tr">
<span id="S3.T17.1.1.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T17.1.1.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.2.1.1.1" class="ltx_p" style="width:43.4pt;">Passage</span>
</span></span>
<span id="S3.T17.1.1.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T17.1.1.1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.2.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.2.2.1.1.1" class="ltx_text" style="font-size:90%;">아직도 대역폭이 많이 필요하지 않은 서버는 1-5기가비트 이더넷을 사용한다.</span></span>
</span></span>
<span id="S3.T17.1.1.1.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T17.1.1.1.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.2.3.1.1" class="ltx_p" style="width:173.4pt;">Servers that still do not require much bandwidth use 1 to 5 Gigabit Ethernet.</span>
</span></span></span>
<span id="S3.T17.1.1.1.1.3" class="ltx_tr">
<span id="S3.T17.1.1.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T17.1.1.1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.3.1.1.1" class="ltx_p" style="width:43.4pt;">Question</span>
</span></span>
<span id="S3.T17.1.1.1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T17.1.1.1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.3.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.3.2.1.1.1" class="ltx_text" style="font-size:90%;">대역폭이 많이 필요한 서버는 어느 대역을 사용하는가?</span></span>
</span></span>
<span id="S3.T17.1.1.1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T17.1.1.1.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.3.3.1.1" class="ltx_p" style="width:173.4pt;">Which bandwidth does the bandwidth-hungry server use?</span>
</span></span></span>
<span id="S3.T17.1.1.1.1.4" class="ltx_tr">
<span id="S3.T17.1.1.1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T17.1.1.1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.4.1.1.1" class="ltx_p" style="width:43.4pt;">
<span id="S3.T17.1.1.1.1.4.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T17.1.1.1.1.4.1.1.1.1.1" class="ltx_tr">
<span id="S3.T17.1.1.1.1.4.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Fake</span></span>
<span id="S3.T17.1.1.1.1.4.1.1.1.1.2" class="ltx_tr">
<span id="S3.T17.1.1.1.1.4.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Answers</span></span>
</span></span>
</span></span>
<span id="S3.T17.1.1.1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T17.1.1.1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.4.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.4.2.1.1.1" class="ltx_text" style="font-size:90%;">1-5기가비트 이더넷</span></span>
</span></span>
<span id="S3.T17.1.1.1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T17.1.1.1.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T17.1.1.1.1.4.3.1.1" class="ltx_p" style="width:173.4pt;">1 to 5 Gigabit Ethernet</span>
</span></span></span>
</span></span></p>
</span></div>
</figure>
</section>
<section id="S3.SS7.SSS1.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS7.SSS1.Px7.p1" class="ltx_para">
<p id="S3.SS7.SSS1.Px7.p1.1" class="ltx_p">We employ workers recruited by SelectStar,<span id="footnote42" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">42</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">42</sup><span class="ltx_tag ltx_tag_note">42</span><a target="_blank" href="https://selectstar.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://selectstar.ai/</a></span></span></span> a Korean crowdsourcing platform, to make each type of question and answers for a given passage. For type 1, 28 workers annotate examples and other 3 workers inspect all of them. For types 2 and 3, 19 and 13 workers annotate examples and other 3 and 2 workers validate them, respectively. If the generated question is rejected by the inspectors, it is regenerated based on the feedback.</p>
</div>
<div id="S3.SS7.SSS1.Px7.p2" class="ltx_para">
<p id="S3.SS7.SSS1.Px7.p2.1" class="ltx_p">To meet the ethical standards, examples which contain sexual, violent, hate, bias or any other ethically inappropriate contents are eliminated. We manually re-check all examples at the end of the annotation process. Through the filtering process, we remove 173 examples in total.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px8" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS7.SSS1.Px8.p1" class="ltx_para">
<p id="S3.SS7.SSS1.Px8.p1.1" class="ltx_p">KLUE-MRC consists of 12,207 paraphrasing-based questions, 7,895 multi-sentence reasoning questions, and 9,211 unanswerable questions. In total, 29,313 examples are made with 22,343 documents and 23,717 passages. As we prioritize creating a challenging dataset for evaluating MRC models, we give more examples to dev and test splits. We set the train/dev/test split ratios as 6:2:2 for robust evaluation, resulting in 17,554 training, 5,841 development and 5,918 test examples. For each split, we randomly sample the examples from each question type independently to balance the number of question types. Tables <a href="#S3.T18" title="Table 18 ‣ Final Dataset ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">18</span></a> and <a href="#S3.T19" title="Table 19 ‣ Final Dataset ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></a> show the detailed statistics of KLUE-MRC.</p>
</div>
<figure id="S3.T18" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 18: </span>Number of examples per each dataset split and question types.</figcaption>
<table id="S3.T18.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T18.1.1" class="ltx_tr">
<td id="S3.T18.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T18.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T18.1.1.2.1" class="ltx_text ltx_font_bold">Paraphrase</span></td>
<td id="S3.T18.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T18.1.1.3.1" class="ltx_text ltx_font_bold">Multi-sentence</span></td>
<td id="S3.T18.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T18.1.1.4.1" class="ltx_text ltx_font_bold">Unanswerable</span></td>
<td id="S3.T18.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T18.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T18.1.2" class="ltx_tr">
<td id="S3.T18.1.2.1" class="ltx_td"></td>
<td id="S3.T18.1.2.2" class="ltx_td ltx_align_center">(41.65%)</td>
<td id="S3.T18.1.2.3" class="ltx_td ltx_align_center">(26.93%)</td>
<td id="S3.T18.1.2.4" class="ltx_td ltx_align_center">(31.42%)</td>
<td id="S3.T18.1.2.5" class="ltx_td ltx_align_center">(100.0%)</td>
</tr>
<tr id="S3.T18.1.3" class="ltx_tr">
<td id="S3.T18.1.3.1" class="ltx_td ltx_align_left ltx_border_t">Train (60%)</td>
<td id="S3.T18.1.3.2" class="ltx_td ltx_align_center ltx_border_t">7,308</td>
<td id="S3.T18.1.3.3" class="ltx_td ltx_align_center ltx_border_t">4,729</td>
<td id="S3.T18.1.3.4" class="ltx_td ltx_align_center ltx_border_t">5,517</td>
<td id="S3.T18.1.3.5" class="ltx_td ltx_align_center ltx_border_t">17,554</td>
</tr>
<tr id="S3.T18.1.4" class="ltx_tr">
<td id="S3.T18.1.4.1" class="ltx_td ltx_align_left">Dev (20%)</td>
<td id="S3.T18.1.4.2" class="ltx_td ltx_align_center">2,437</td>
<td id="S3.T18.1.4.3" class="ltx_td ltx_align_center">1,571</td>
<td id="S3.T18.1.4.4" class="ltx_td ltx_align_center">1,833</td>
<td id="S3.T18.1.4.5" class="ltx_td ltx_align_center">5,841</td>
</tr>
<tr id="S3.T18.1.5" class="ltx_tr">
<td id="S3.T18.1.5.1" class="ltx_td ltx_align_left">Test (20%)</td>
<td id="S3.T18.1.5.2" class="ltx_td ltx_align_center">2,462</td>
<td id="S3.T18.1.5.3" class="ltx_td ltx_align_center">1,595</td>
<td id="S3.T18.1.5.4" class="ltx_td ltx_align_center">1,861</td>
<td id="S3.T18.1.5.5" class="ltx_td ltx_align_center">5,918</td>
</tr>
<tr id="S3.T18.1.6" class="ltx_tr">
<td id="S3.T18.1.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Total (100%)</td>
<td id="S3.T18.1.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">12,207</td>
<td id="S3.T18.1.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">7,895</td>
<td id="S3.T18.1.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">9,211</td>
<td id="S3.T18.1.6.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">29,313</td>
</tr>
</tbody></table>
</figure>
<figure id="S3.T19" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 19: </span>Statistics of KLUE-MRC.</figcaption>
<table id="S3.T19.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T19.1.1" class="ltx_tr">
<td id="S3.T19.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T19.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T19.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T19.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T19.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T19.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T19.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T19.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T19.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T19.1.2" class="ltx_tr">
<td id="S3.T19.1.2.1" class="ltx_td ltx_align_left ltx_border_t"># Documents</td>
<td id="S3.T19.1.2.2" class="ltx_td ltx_align_center ltx_border_t">12,174</td>
<td id="S3.T19.1.2.3" class="ltx_td ltx_align_center ltx_border_t">5,075</td>
<td id="S3.T19.1.2.4" class="ltx_td ltx_align_center ltx_border_t">5,094</td>
<td id="S3.T19.1.2.5" class="ltx_td ltx_align_center ltx_border_t">22,343</td>
</tr>
<tr id="S3.T19.1.3" class="ltx_tr">
<td id="S3.T19.1.3.1" class="ltx_td ltx_align_left"># Passages</td>
<td id="S3.T19.1.3.2" class="ltx_td ltx_align_center">13,072</td>
<td id="S3.T19.1.3.3" class="ltx_td ltx_align_center">5,310</td>
<td id="S3.T19.1.3.4" class="ltx_td ltx_align_center">5,335</td>
<td id="S3.T19.1.3.5" class="ltx_td ltx_align_center">23,717</td>
</tr>
<tr id="S3.T19.1.4" class="ltx_tr">
<td id="S3.T19.1.4.1" class="ltx_td ltx_align_left"># Questions</td>
<td id="S3.T19.1.4.2" class="ltx_td ltx_align_center">17,554</td>
<td id="S3.T19.1.4.3" class="ltx_td ltx_align_center">5,841</td>
<td id="S3.T19.1.4.4" class="ltx_td ltx_align_center">5,918</td>
<td id="S3.T19.1.4.5" class="ltx_td ltx_align_center">29,313</td>
</tr>
<tr id="S3.T19.1.5" class="ltx_tr">
<td id="S3.T19.1.5.1" class="ltx_td ltx_align_left ltx_border_t">Avg Length of Passage</td>
<td id="S3.T19.1.5.2" class="ltx_td ltx_align_center ltx_border_t">1,004.62</td>
<td id="S3.T19.1.5.3" class="ltx_td ltx_align_center ltx_border_t">1,014.64</td>
<td id="S3.T19.1.5.4" class="ltx_td ltx_align_center ltx_border_t">1,010.13</td>
<td id="S3.T19.1.5.5" class="ltx_td ltx_align_center ltx_border_t">1,008.10</td>
</tr>
<tr id="S3.T19.1.6" class="ltx_tr">
<td id="S3.T19.1.6.1" class="ltx_td ltx_align_left">Avg Length of Question</td>
<td id="S3.T19.1.6.2" class="ltx_td ltx_align_center">29.00</td>
<td id="S3.T19.1.6.3" class="ltx_td ltx_align_center">29.05</td>
<td id="S3.T19.1.6.4" class="ltx_td ltx_align_center">29.01</td>
<td id="S3.T19.1.6.5" class="ltx_td ltx_align_center">29.01</td>
</tr>
<tr id="S3.T19.1.7" class="ltx_tr">
<td id="S3.T19.1.7.1" class="ltx_td ltx_align_left ltx_border_bb">Avg Length of Answer</td>
<td id="S3.T19.1.7.2" class="ltx_td ltx_align_center ltx_border_bb">6.03</td>
<td id="S3.T19.1.7.3" class="ltx_td ltx_align_center ltx_border_bb">6.03</td>
<td id="S3.T19.1.7.4" class="ltx_td ltx_align_center ltx_border_bb">5.82</td>
<td id="S3.T19.1.7.5" class="ltx_td ltx_align_center ltx_border_bb">5.99</td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS7.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.2 </span>Evaluation Metrics</h4>

<div id="S3.SS7.SSS2.p1" class="ltx_para">
<p id="S3.SS7.SSS2.p1.1" class="ltx_p">The evaluation metrics for KLUE-MRC are 1) exact match (EM) and 2) character-level ROUGE-W (ROUGE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>, which can be viewed as longest common consecutive subsequence (LCCS)-based F1 score. EM is the most commonly used metric for MRC tasks, which measures the equality of ground truth and predicted answer string. If there are multiple gold labels, a model can earn score when at least one prediction is matched. In contrast, ROUGE gives a partial score although a model fails to predict exactly matched answer. Due to the characteristics of Korean, an answer span can be located inside a single word, hence subword-level span should be considered. ROUGE calculates F1 score of the length ratio of LCCS to a prediction and the length ratio of LCCS to the ground truth string. In the case when multiple ground truth answer spans have the same meaning but different lexical variations (e.g. TV, Television), we use the maximum ROUGE score among the combinations of answers and the prediction. We do not adopt character-level F1 score (char F1), which is used in all the previous Korean MRC datasets, since it measures character overlap regardless of the order. When a model predicts “한국의 위인들 (great people in Korea)” and an answer is “국한된 범위 (limited scope)”, a metric should give a low score. ROUGE scores 15.38, whereas char F1 gives 54.55 due to the overlap of “한”, “국”, and “위”.</p>
</div>
</section>
<section id="S3.SS7.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.3 </span>Analysis</h4>

<div id="S3.SS7.SSS3.p1" class="ltx_para">
<p id="S3.SS7.SSS3.p1.1" class="ltx_p">We investigate KLUE-MRC by comparing with other Korean MRC datasets. KorQuAD 1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> and 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> are commonly used in Korean MRC research, released with training and evaluation sets separately. However, KorQuAD 2.0 shows a quite different composition in contents compared to ours and KorQUAD 1.0, in specific, HTML tags and tables. Therefore, we conduct comparison only with KorQuAD 1.0 dataset. KorQuAD 1.0 dev set was leveraged because its test set is not available.</p>
</div>
<section id="S3.SS7.SSS3.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Question Difficulty of KLUE-MRC Evaluation Set</h5>

<div id="S3.SS7.SSS3.Px1.p1" class="ltx_para">
<p id="S3.SS7.SSS3.Px1.p1.1" class="ltx_p">As we aim to make KLUE-MRC challenging, it is necessary to check the difficulty of test sets. We compare the performance on the evaluation set of ours and KorQuAD 1.0 with the model trained with both datasets in Table <a href="#S3.T20" title="Table 20 ‣ Question Difficulty of KLUE-MRC Evaluation Set ‣ 3.7.3 Analysis ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">20</span></a>. We fine-tune the model<span id="footnote43" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">43</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">43</sup><span class="ltx_tag ltx_tag_note">43</span>We fine-tune pretrained RoBERTa-base model with following hyperparameters: epochs 5, batch size 16, learning rate 3e-5, lr warmup ratio 0.0.</span></span></span> with a collection of the train set from both datasets and test the model on each evaluation set.</p>
</div>
<div id="S3.SS7.SSS3.Px1.p2" class="ltx_para">
<p id="S3.SS7.SSS3.Px1.p2.1" class="ltx_p">KorQuAD 1.0 train examples (60,407) are almost four times larger than KLUE-MRC (17,554), and it may have resulted in the higher performance for KorQuAD 1.0 dev set. We additionally conduct fine-tuning with a collection of the same amount of both train datasets for fair comparison. We adjust KorQuAD 1.0 train set to fit the size of KLUE-MRC train set by random sampling. Table <a href="#S3.T20" title="Table 20 ‣ Question Difficulty of KLUE-MRC Evaluation Set ‣ 3.7.3 Analysis ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">20</span></a> shows consistently lower scores of KLUE-MRC compared to KorQuAD 1.0. Thus, our dataset is more challenging regardless of the size of train set.</p>
</div>
<figure id="S3.T20" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 20: </span>Difficulty comparison between KLUE-MRC test and KorQuAD 1.0 dev set.</figcaption>
<table id="S3.T20.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T20.1.1" class="ltx_tr">
<td id="S3.T20.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T20.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T20.1.1.2.1" class="ltx_text ltx_font_bold">KLUE + KorQuAD (Full:Full)</span></td>
<td id="S3.T20.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T20.1.1.3.1" class="ltx_text ltx_font_bold">KLUE + KorQuAD (1:1)</span></td>
</tr>
<tr id="S3.T20.1.2" class="ltx_tr">
<td id="S3.T20.1.2.1" class="ltx_td ltx_align_left"><span id="S3.T20.1.2.1.1" class="ltx_text ltx_font_bold">Evaluation Dataset</span></td>
<td id="S3.T20.1.2.2" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T20.1.2.3" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
<td id="S3.T20.1.2.4" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T20.1.2.5" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
</tr>
<tr id="S3.T20.1.3" class="ltx_tr">
<td id="S3.T20.1.3.1" class="ltx_td ltx_align_left ltx_border_t">KorQuAD 1.0 (Dev)</td>
<td id="S3.T20.1.3.2" class="ltx_td ltx_align_center ltx_border_t">86.59</td>
<td id="S3.T20.1.3.3" class="ltx_td ltx_align_center ltx_border_t">94.19</td>
<td id="S3.T20.1.3.4" class="ltx_td ltx_align_center ltx_border_t">85.00</td>
<td id="S3.T20.1.3.5" class="ltx_td ltx_align_center ltx_border_t">93.07</td>
</tr>
<tr id="S3.T20.1.4" class="ltx_tr">
<td id="S3.T20.1.4.1" class="ltx_td ltx_align_left ltx_border_bb">KLUE-MRC (Test)</td>
<td id="S3.T20.1.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T20.1.4.2.1" class="ltx_text ltx_font_bold">70.42</span></td>
<td id="S3.T20.1.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T20.1.4.3.1" class="ltx_text ltx_font_bold">75.42</span></td>
<td id="S3.T20.1.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T20.1.4.4.1" class="ltx_text ltx_font_bold">69.75</span></td>
<td id="S3.T20.1.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T20.1.4.5.1" class="ltx_text ltx_font_bold">75.20</span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS7.SSS3.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Lexical Overlap</h5>

<div id="S3.SS7.SSS3.Px2.p1" class="ltx_para">
<p id="S3.SS7.SSS3.Px2.p1.1" class="ltx_p">As high lexical overlap between question and passage can cause shortcut reasoning, reducing lexical overlap is important to build a challenging dataset. To investigate the effects of the proposed strict guidelines and challenging question types, we calculate the lexical overlap of ours and KorQuAD 1.0. The lexical overlap ratio is calculated by dividing the number of common components between question and passage into the number of components in the question. We exclude functional particles such as postposition(조사, josa) and ending components (어미, eomi) when computing the overlap ratio via an open-sourced Korean POS tagger.<span id="footnote44" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">44</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">44</sup><span class="ltx_tag ltx_tag_note">44</span>Twitter tagger of KoNLPy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>.</span></span></span> We observe our lexical overlap ratio is almost 10%p lower than that of KorQuAD dataset (70%). For each questions types, Types 1 and 3 show similar ratio in range from 55% to 59%. Type 2 exhibits 68% overlap ratio.</p>
</div>
</section>
<section id="S3.SS7.SSS3.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Human Evaluation</h5>

<div id="S3.SS7.SSS3.Px3.p1" class="ltx_para">
<p id="S3.SS7.SSS3.Px3.p1.1" class="ltx_p">We evaluate human performance on our KLUE-MRC to measure its difficulty concerning human reading comprehension capabilities. We randomly sample 1,000 examples from our test set and hire three workers to solve them. We select the score of the top scoring worker as human performance. Table <a href="#S3.T21" title="Table 21 ‣ Human Evaluation ‣ 3.7.3 Analysis ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">21</span></a> reports the comparison between human performance and base model.</p>
</div>
<figure id="S3.T21" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 21: </span>Comparison of evaluation scores between model prediction and human answer</figcaption>
<table id="S3.T21.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T21.1.2" class="ltx_tr">
<td id="S3.T21.1.2.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T21.1.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T21.1.2.2.1" class="ltx_text ltx_font_bold">Paraphrase</span></td>
<td id="S3.T21.1.2.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T21.1.2.3.1" class="ltx_text ltx_font_bold">Multi-sentence</span></td>
<td id="S3.T21.1.2.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T21.1.2.4.1" class="ltx_text ltx_font_bold">Unanswerable</span></td>
<td id="S3.T21.1.2.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T21.1.2.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T21.1.3" class="ltx_tr">
<td id="S3.T21.1.3.1" class="ltx_td"></td>
<td id="S3.T21.1.3.2" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T21.1.3.3" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
<td id="S3.T21.1.3.4" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T21.1.3.5" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
<td id="S3.T21.1.3.6" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T21.1.3.7" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
<td id="S3.T21.1.3.8" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T21.1.3.9" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
</tr>
<tr id="S3.T21.1.1" class="ltx_tr">
<td id="S3.T21.1.1.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S3.T21.1.1.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="S3.T21.1.1.1.m1.1a"><msub id="S3.T21.1.1.1.m1.1.1" xref="S3.T21.1.1.1.m1.1.1.cmml"><mtext id="S3.T21.1.1.1.m1.1.1.2" xref="S3.T21.1.1.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S3.T21.1.1.1.m1.1.1.3" xref="S3.T21.1.1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T21.1.1.1.m1.1b"><apply id="S3.T21.1.1.1.m1.1.1.cmml" xref="S3.T21.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T21.1.1.1.m1.1.1.1.cmml" xref="S3.T21.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T21.1.1.1.m1.1.1.2a.cmml" xref="S3.T21.1.1.1.m1.1.1.2"><mtext id="S3.T21.1.1.1.m1.1.1.2.cmml" xref="S3.T21.1.1.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S3.T21.1.1.1.m1.1.1.3a.cmml" xref="S3.T21.1.1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.T21.1.1.1.m1.1.1.3.cmml" xref="S3.T21.1.1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T21.1.1.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math></td>
<td id="S3.T21.1.1.2" class="ltx_td ltx_align_center ltx_border_t">67.74</td>
<td id="S3.T21.1.1.3" class="ltx_td ltx_align_center ltx_border_t">75.73</td>
<td id="S3.T21.1.1.4" class="ltx_td ltx_align_center ltx_border_t">65.07</td>
<td id="S3.T21.1.1.5" class="ltx_td ltx_align_center ltx_border_t">73.13</td>
<td id="S3.T21.1.1.6" class="ltx_td ltx_align_center ltx_border_t">72.48</td>
<td id="S3.T21.1.1.7" class="ltx_td ltx_align_center ltx_border_t">72.48</td>
<td id="S3.T21.1.1.8" class="ltx_td ltx_align_center ltx_border_t">68.51</td>
<td id="S3.T21.1.1.9" class="ltx_td ltx_align_center ltx_border_t">74.01</td>
</tr>
<tr id="S3.T21.1.4" class="ltx_tr">
<td id="S3.T21.1.4.1" class="ltx_td ltx_align_left ltx_border_bb">Human</td>
<td id="S3.T21.1.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.2.1" class="ltx_text ltx_font_bold">84.18</span></td>
<td id="S3.T21.1.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.3.1" class="ltx_text ltx_font_bold">88.33</span></td>
<td id="S3.T21.1.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.4.1" class="ltx_text ltx_font_bold">87.72</span></td>
<td id="S3.T21.1.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.5.1" class="ltx_text ltx_font_bold">90.91</span></td>
<td id="S3.T21.1.4.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.6.1" class="ltx_text ltx_font_bold">86.53</span></td>
<td id="S3.T21.1.4.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.7.1" class="ltx_text ltx_font_bold">86.53</span></td>
<td id="S3.T21.1.4.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.8.1" class="ltx_text ltx_font_bold">85.90</span></td>
<td id="S3.T21.1.4.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.9.1" class="ltx_text ltx_font_bold">88.48</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS7.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.4 </span>Related Work</h4>

<div id="S3.SS7.SSS4.p1" class="ltx_para">
<p id="S3.SS7.SSS4.p1.1" class="ltx_p">In recent years, significant progress has been achieved in English MRC research with challenging datasets of various question types, including but not limited to: paraphrase, multi-sentence, and unanswerable.</p>
</div>
<div id="S3.SS7.SSS4.p2" class="ltx_para">
<p id="S3.SS7.SSS4.p2.1" class="ltx_p">Paraphrased questions have low word overlap between the question and reading passage, which prevents MRC models from exploiting simple word-matching. <cite class="ltx_cite ltx_citemacro_citet">Trischler et&nbsp;al. [<a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite> create a NewsQA dataset by generating questions from news headlines and summarizing them via crowdsourcing. They reduce the word overlap by annotating answers on the main articles which are not given during question generation. <cite class="ltx_cite ltx_citemacro_citet">Saha et&nbsp;al. [<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite> leverage pairs of plot summaries for the same movies from Wikipedia and IMDb.<span id="footnote45" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">45</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">45</sup><span class="ltx_tag ltx_tag_note">45</span><a target="_blank" href="https://www.imdb.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.imdb.com/</a></span></span></span> They generate questions from the shorter plots and annotate answers on the longer ones to obtain naturally paraphrased questions. <cite class="ltx_cite ltx_citemacro_citet">Sen and Saffari [<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> report that datasets with low question-passage overlap will enhance the generalizability of MRC models.</p>
</div>
<div id="S3.SS7.SSS4.p3" class="ltx_para">
<p id="S3.SS7.SSS4.p3.1" class="ltx_p">Multi-sentence questions require reasoning over multiple sentences. As a result, they are more difficult compared to single-sentence questions. <cite class="ltx_cite ltx_citemacro_citet">Joshi et&nbsp;al. [<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> introduce TriviaQA, a dataset of questions from trivia websites. Since they gather evidence passages from various sources (e.g., Wikipedia and the Web), multiple sentences are naturally required for answering the given question. <cite class="ltx_cite ltx_citemacro_citet">Khashabi et&nbsp;al. [<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> explicitly generate multi-sentence questions on various texts through crowdsourcing and release the MultiRC dataset. The SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> benchmark adopts the MultiRC dataset as one of its tasks.</p>
</div>
<div id="S3.SS7.SSS4.p4" class="ltx_para">
<p id="S3.SS7.SSS4.p4.1" class="ltx_p">Several MRC datasets have incorporated unanswerable questions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib96" title="" class="ltx_ref">96</a>, <a href="#bib.bib113" title="" class="ltx_ref">113</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>. <cite class="ltx_cite ltx_citemacro_citet">Rajpurkar et&nbsp;al. [<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> report performance drop in MRC models when unanswerable questions are included in the dataset.</p>
</div>
<div id="S3.SS7.SSS4.p5" class="ltx_para">
<p id="S3.SS7.SSS4.p5.1" class="ltx_p">Compared to MRC research on English, Korean MRC research stands on a small number of existing datasets. The primary benchmark for Korean MRC has been KorQuAD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, which adopts the same data collection process as SQuAD 1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>. However, the model performance on KorQuAD has already exceeded human performance in a short period, leaving little headroom for further research. Moreover, unlike SQuAD, KorQuAD is under CC BY-ND license and does not allow derivative works (e.g., adding unanswerable questions).
AI Hub MRC dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> is based on newspapers and includes unanswerable questions. However, its access is strictly limited to native Korean researchers, prohibiting collaboration even with international researchers residing in Korea.
K-QuAD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> leverage Google Translate<span id="footnote46" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">46</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">46</sup><span class="ltx_tag ltx_tag_note">46</span><a target="_blank" href="https://translate.google.co.kr/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://translate.google.co.kr/</a></span></span></span> to translate SQuAD 1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite> into Korean. Since the K-QuAD dataset does not get updated over time, its quality depends on the machine translator’s performance at the time of release.
Our KLUE-MRC is different from the existing Korean MRC benchmarks in terms of accessibility-enhance license and more challenging difficulty.</p>
</div>
</section>
<section id="S3.SS7.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.5 </span>Conclusion</h4>

<div id="S3.SS7.SSS5.p1" class="ltx_para">
<p id="S3.SS7.SSS5.p1.1" class="ltx_p">We create a new challenging Korean MRC benchmark named (KLUE-MRC). In order to evaluate different aspects of MRC capabilities, KLUE-MRC includes multi-domain passages and three types of questions: paraphrase, multi-sentence reasoning, and unanswerable. KLUE-MRC shows improvements in question type diversity, difficulty, and lexical overlap compared to existing Korean MRC datasets.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.8 </span>Dialogue State Tracking (DST)</h3>

<div id="S3.SS8.p1" class="ltx_para">
<p id="S3.SS8.p1.1" class="ltx_p">Building a human-computer conversation system has been increasingly attracting attention, and a task-oriented dialogue system is one type of the dialogue systems&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. A core module of task-oriented dialogue systems, namely, Dialogue State Tracking (DST) is about predicting the <span id="S3.SS8.p1.1.1" class="ltx_text ltx_font_italic">dialogue states</span> from a given dialogue context. As illustrated in Table&nbsp;<a href="#S3.T22" title="Table 22 ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">22</span></a>, dialogue states are sets of slot and value pairs that are relevant categories (e.g. hotel type) and their possible values (e.g. guest house, hotel, motel), respectively.</p>
</div>
<div id="S3.SS8.p2" class="ltx_para">
<p id="S3.SS8.p2.1" class="ltx_p">Several recent works have considered task-oriented dialogue (TOD) as an important problem of natural language understanding. For instance, DecaNLP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite> includes a DST, which is a key component of TOD, into one of their benchmark tasks, while DialoGLUE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> releases the first task-oriented dialogue benchmark containing various sub-tasks including DST. In light of such, we include DST as a part of the KLUE benchmark.</p>
</div>
<div id="S3.SS8.p3" class="ltx_para">
<p id="S3.SS8.p3.1" class="ltx_p">The task of dialogue state tracking is to predict slot and value pairs after each user utterance, and the potential pairs are predefined by a task schema and knowledge base (KB), tied to the choice of a scenario. For evaluation, we use joint goal accuracy (JGA) and slot micro F1 score. The JGA checks if all of the predicted slot-value pairs are exactly matched with the ground-truths for every turn, while the slot micro F1 computes f1 score for each slot-value pair independently.<span id="footnote47" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">47</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">47</sup><span class="ltx_tag ltx_tag_note">47</span>We adopt the evaluation script of <a target="_blank" href="https://github.com/jasonwu0731/trade-dst" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jasonwu0731/trade-dst</a></span></span></span></p>
</div>
<figure id="S3.T22" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 22: </span>An example of dialogue state tracking in our WoS. Note that all dialogue states are cumulative in the actual dataset and that we only track states in the user turns.</figcaption>
<div id="S3.T22.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:267pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-63.6pt,46.0pt) scale(0.743394455940881,0.743394455940881) ;">
<table id="S3.T22.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.1" class="ltx_tr">
<td id="S3.T22.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T22.1.1.1.1.1" class="ltx_text ltx_font_bold">Utterances (English Translations)</span></td>
<td id="S3.T22.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T22.1.1.1.2.1" class="ltx_text ltx_font_bold">Dialogue States</span></td>
</tr>
<tr id="S3.T22.1.1.2" class="ltx_tr">
<td id="S3.T22.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T22.1.1.2.1.1" class="ltx_text ltx_font_bold">User</span>: <span id="S3.T22.1.1.2.1.2" class="ltx_text" style="font-size:90%;">안녕하세요. (Hello.)</span>
</td>
<td id="S3.T22.1.1.2.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">-</td>
</tr>
<tr id="S3.T22.1.1.3" class="ltx_tr">
<td id="S3.T22.1.1.3.1" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T22.1.1.3.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.3.1.1.1" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Sys</span>: <span id="S3.T22.1.1.3.1.1.1.1.2" class="ltx_text" style="font-size:90%;">네. 안녕하세요. 무엇을 도와드릴까요? (Hello. How can I help?)</span>
</td>
</tr>
<tr id="S3.T22.1.1.3.1.1.2" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.3.1.1.2.1.1" class="ltx_text ltx_font_bold">User</span>: <span id="S3.T22.1.1.3.1.1.2.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">서울 중앙<span id="S3.T22.1.1.3.1.1.2.1.2.1" class="ltx_text ltx_font_medium">에 위치한 </span>호텔<span id="S3.T22.1.1.3.1.1.2.1.2.2" class="ltx_text ltx_font_medium">을 찾고 있습니다. 외국인 친구도 함께</span></span>
</td>
</tr>
<tr id="S3.T22.1.1.3.1.1.3" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.3.1.1.3.1.1" class="ltx_text" style="font-size:90%;">갈 예정이라서 원활하게 <span id="S3.T22.1.1.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold">인터넷을 사용할 수 있는 곳</span>이었으면 좋겠어요.</span></td>
</tr>
<tr id="S3.T22.1.1.3.1.1.4" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">(I’m looking for a <span id="S3.T22.1.1.3.1.1.4.1.1" class="ltx_text ltx_font_bold">hotel</span> at the city <span id="S3.T22.1.1.3.1.1.4.1.2" class="ltx_text ltx_font_bold">center</span>. I’m going with a foreign friend,</td>
</tr>
<tr id="S3.T22.1.1.3.1.1.5" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">so easy access to the <span id="S3.T22.1.1.3.1.1.5.1.1" class="ltx_text ltx_font_bold">Internet should be available</span>.)</td>
</tr>
</tbody></table>
</td>
<td id="S3.T22.1.1.3.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<table id="S3.T22.1.1.3.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.3.2.1.1" class="ltx_tr">
<td id="S3.T22.1.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-area<span id="S3.T22.1.1.3.2.1.1.1.1.1" class="ltx_text ltx_font_medium">: center</span></span></td>
</tr>
<tr id="S3.T22.1.1.3.2.1.2" class="ltx_tr">
<td id="S3.T22.1.1.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.3.2.1.2.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-type<span id="S3.T22.1.1.3.2.1.2.1.1.1" class="ltx_text ltx_font_medium">: hotel</span></span></td>
</tr>
<tr id="S3.T22.1.1.3.2.1.3" class="ltx_tr">
<td id="S3.T22.1.1.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.3.2.1.3.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-internet<span id="S3.T22.1.1.3.2.1.3.1.1.1" class="ltx_text ltx_font_medium">: yes</span></span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr id="S3.T22.1.1.4" class="ltx_tr">
<td id="S3.T22.1.1.4.1" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T22.1.1.4.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.4.1.1.1" class="ltx_tr">
<td id="S3.T22.1.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Sys</span>: <span id="S3.T22.1.1.4.1.1.1.1.2" class="ltx_text" style="font-size:90%;">네 확인해보겠습니다. 혹시 추가로 필요하신 사항이 있으실까요?</span>
</td>
</tr>
<tr id="S3.T22.1.1.4.1.1.2" class="ltx_tr">
<td id="S3.T22.1.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(Sure, let me check. Do you need anything else?)</td>
</tr>
<tr id="S3.T22.1.1.4.1.1.3" class="ltx_tr">
<td id="S3.T22.1.1.4.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.1.1.3.1.1" class="ltx_text ltx_font_bold">User</span>: <span id="S3.T22.1.1.4.1.1.3.1.2" class="ltx_text" style="font-size:90%;">음… 예약 인원은 총 <span id="S3.T22.1.1.4.1.1.3.1.2.1" class="ltx_text ltx_font_bold">8명</span>이고요. 아, <span id="S3.T22.1.1.4.1.1.3.1.2.2" class="ltx_text ltx_font_bold">가격대는 크게 상관 없습니다</span>.</span>
</td>
</tr>
<tr id="S3.T22.1.1.4.1.1.4" class="ltx_tr">
<td id="S3.T22.1.1.4.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">(Hmm.. I want to reserve for <span id="S3.T22.1.1.4.1.1.4.1.1" class="ltx_text ltx_font_bold">8 people</span>. Ah, the <span id="S3.T22.1.1.4.1.1.4.1.2" class="ltx_text ltx_font_bold">price range doesn’t matter</span>.)</td>
</tr>
</tbody></table>
</td>
<td id="S3.T22.1.1.4.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<table id="S3.T22.1.1.4.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.4.2.1.1" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.2.1.1.1.1" class="ltx_text ltx_font_bold">Hotel-area</span>: center</td>
</tr>
<tr id="S3.T22.1.1.4.2.1.2" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.2.1.2.1.1" class="ltx_text ltx_font_bold">Hotel-type</span>: hotel</td>
</tr>
<tr id="S3.T22.1.1.4.2.1.3" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.2.1.3.1.1" class="ltx_text ltx_font_bold">Hotel-internet</span>: yes</td>
</tr>
<tr id="S3.T22.1.1.4.2.1.4" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.4.2.1.4.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-book people<span id="S3.T22.1.1.4.2.1.4.1.1.1" class="ltx_text ltx_font_medium">: 8</span></span></td>
</tr>
<tr id="S3.T22.1.1.4.2.1.5" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.4.2.1.5.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-price range<span id="S3.T22.1.1.4.2.1.5.1.1.1" class="ltx_text ltx_font_medium">: dontcare</span></span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr id="S3.T22.1.1.5" class="ltx_tr">
<td id="S3.T22.1.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<table id="S3.T22.1.1.5.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.5.1.1.1" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Sys</span>: <span id="S3.T22.1.1.5.1.1.1.1.2" class="ltx_text" style="font-size:90%;">네, 확인 감사합니다. 숙박을 원하시는 요일과 기간 같이 확인 부탁드립니다.</span>
</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.2" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(Great, thanks for confirming. Please let us know when and how long</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.3" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">you want to stay.)</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.4" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.1.1.4.1.1" class="ltx_text ltx_font_bold">User</span>: <span id="S3.T22.1.1.5.1.1.4.1.2" class="ltx_text" style="font-size:90%;">아, 중요한 걸 깜빡했네요. <span id="S3.T22.1.1.5.1.1.4.1.2.1" class="ltx_text ltx_font_bold">일요일</span>에 <span id="S3.T22.1.1.5.1.1.4.1.2.2" class="ltx_text ltx_font_bold">2일</span>간 예약하고 싶습니다.</span>
</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.5" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">(Right, I forgot an important thing. I would like to book for <span id="S3.T22.1.1.5.1.1.5.1.1" class="ltx_text ltx_font_bold">two days</span>
</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.6" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">from <span id="S3.T22.1.1.5.1.1.6.1.1" class="ltx_text ltx_font_bold">Sunday</span>.)</td>
</tr>
</tbody></table>
</td>
<td id="S3.T22.1.1.5.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t">
<table id="S3.T22.1.1.5.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.5.2.1.1" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.1.1.1" class="ltx_text ltx_font_bold">Hotel-area</span>: center</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.2" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.2.1.1" class="ltx_text ltx_font_bold">Hotel-type</span>: hotel</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.3" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.3.1.1" class="ltx_text ltx_font_bold">Hotel-internet</span>: yes</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.4" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.4.1.1" class="ltx_text ltx_font_bold">Hotel-book people</span>: 8</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.5" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.5.1.1" class="ltx_text ltx_font_bold">Hotel-price range</span>: dontcare</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.6" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.5.2.1.6.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-book day<span id="S3.T22.1.1.5.2.1.6.1.1.1" class="ltx_text ltx_font_medium">: Sunday</span></span></td>
</tr>
<tr id="S3.T22.1.1.5.2.1.7" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.5.2.1.7.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-book stay<span id="S3.T22.1.1.5.2.1.7.1.1.1" class="ltx_text ltx_font_medium">: 2</span></span></td>
</tr>
</tbody></table>
</td>
</tr>
</tbody></table>
</span></div>
</figure>
<section id="S3.SS8.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.1 </span>Dataset Construction</h4>

<div id="S3.SS8.SSS1.p1" class="ltx_para">
<p id="S3.SS8.SSS1.p1.1" class="ltx_p">Our dataset construction protocol is a modified version of the Wizard-of-Oz framework (WOZ) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, which is a widely used paradigm for building dialogue datasets. The WOZ setting is a particular type of human-to-human dialogue collection, which employs two people that either takes a user and a system role. However, it is arguably time-consuming, complex, and expensive&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. To overcome the limitations, we adopt ‘Self-dialog’ scheme which requests a single worker to play both user and system roles&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. In addition, we introduce a new design choice to obtain a more precise dialogue dataset.</p>
</div>
<section id="S3.SS8.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Overview</h5>

<div id="S3.SS8.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS8.SSS1.Px1.p1.1" class="ltx_p">We construct WoS by following five steps: 1) define a task schema, 2) create knowledge base (KB), 3) design an annotation system, 4) collect and annotate a dataset, and 5) finalize the dataset. Different from the other datasets in our benchmarks, WoS is not following an ordinary protocol: collecting raw corpus followed by annotating labels. Rather, we collect dialogues (raw corpus) and their corresponding dialogue states (labels) at the same time.</p>
</div>
<figure id="S3.T23" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 23: </span>Task schema for all five domains in Wizard of Seoul (WoS) which shows names of the domain and their slots. Star<sup id="S3.T23.54.1" class="ltx_sup">⋆</sup>, asterisk<sup id="S3.T23.55.2" class="ltx_sup">∗</sup>, cross<sup id="S3.T23.56.3" class="ltx_sup">†</sup>, doubly-crosses<sup id="S3.T23.57.4" class="ltx_sup">‡</sup> denote required, boolean type, booking-related, and requestable after booking slot, respectively.</figcaption>
<table id="S3.T23.49" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T23.49.42" class="ltx_tr">
<td id="S3.T23.49.42.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T23.49.42.1.1" class="ltx_text ltx_font_bold">Domains</span></td>
<td id="S3.T23.49.42.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T23.49.42.2.1" class="ltx_text ltx_font_bold">Informable Slots</span></td>
<td id="S3.T23.49.42.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T23.49.42.3.1" class="ltx_text ltx_font_bold">Requestable Slots</span></td>
</tr>
<tr id="S3.T23.23.15" class="ltx_tr">
<td id="S3.T23.23.15.16" class="ltx_td ltx_align_left ltx_border_t">Hotel</td>
<td id="S3.T23.22.14.14" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.22.14.14.15" class="ltx_text"></span><span id="S3.T23.22.14.14.14" class="ltx_text">
<span id="S3.T23.22.14.14.14.14" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.11.3.3.3.3.3" class="ltx_tr">
<span id="S3.T23.11.3.3.3.3.3.3" class="ltx_td ltx_nopad_r ltx_align_left">name, type<sup id="S3.T23.11.3.3.3.3.3.3.1" class="ltx_sup">⋆</sup>, area<sup id="S3.T23.11.3.3.3.3.3.3.2" class="ltx_sup">⋆</sup>, price range<sup id="S3.T23.11.3.3.3.3.3.3.3" class="ltx_sup">⋆</sup>,</span></span>
<span id="S3.T23.14.6.6.6.6.6" class="ltx_tr">
<span id="S3.T23.14.6.6.6.6.6.3" class="ltx_td ltx_nopad_r ltx_align_left">book day<sup id="S3.T23.14.6.6.6.6.6.3.1" class="ltx_sup">†</sup>, book stay<sup id="S3.T23.14.6.6.6.6.6.3.2" class="ltx_sup">†</sup>, book people<sup id="S3.T23.14.6.6.6.6.6.3.3" class="ltx_sup">†</sup>,</span></span>
<span id="S3.T23.17.9.9.9.9.9" class="ltx_tr">
<span id="S3.T23.17.9.9.9.9.9.3" class="ltx_td ltx_nopad_r ltx_align_left">walkability<sup id="S3.T23.17.9.9.9.9.9.3.1" class="ltx_sup">∗</sup>, parking<sup id="S3.T23.17.9.9.9.9.9.3.2" class="ltx_sup">∗</sup>, internet<sup id="S3.T23.17.9.9.9.9.9.3.3" class="ltx_sup">∗</sup>,</span></span>
<span id="S3.T23.20.12.12.12.12.12" class="ltx_tr">
<span id="S3.T23.20.12.12.12.12.12.3" class="ltx_td ltx_nopad_r ltx_align_left">breakfast<sup id="S3.T23.20.12.12.12.12.12.3.1" class="ltx_sup">∗</sup>, smoking<sup id="S3.T23.20.12.12.12.12.12.3.2" class="ltx_sup">∗</sup>, fitness<sup id="S3.T23.20.12.12.12.12.12.3.3" class="ltx_sup">∗</sup>,</span></span>
<span id="S3.T23.22.14.14.14.14.14" class="ltx_tr">
<span id="S3.T23.22.14.14.14.14.14.2" class="ltx_td ltx_nopad_r ltx_align_left">swimming pool<sup id="S3.T23.22.14.14.14.14.14.2.1" class="ltx_sup">∗</sup>, spa<sup id="S3.T23.22.14.14.14.14.14.2.2" class="ltx_sup">∗</sup></span></span>
</span></span><span id="S3.T23.22.14.14.16" class="ltx_text"></span></td>
<td id="S3.T23.23.15.15" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.23.15.15.2" class="ltx_text"></span><span id="S3.T23.23.15.15.1" class="ltx_text">
<span id="S3.T23.23.15.15.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.23.15.15.1.1.2" class="ltx_tr">
<span id="S3.T23.23.15.15.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">rating, nearby station,</span></span>
<span id="S3.T23.23.15.15.1.1.3" class="ltx_tr">
<span id="S3.T23.23.15.15.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">minutes walk from station,</span></span>
<span id="S3.T23.23.15.15.1.1.4" class="ltx_tr">
<span id="S3.T23.23.15.15.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">address, phone number,</span></span>
<span id="S3.T23.23.15.15.1.1.1" class="ltx_tr">
<span id="S3.T23.23.15.15.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">business hour, reference number<sup id="S3.T23.23.15.15.1.1.1.1.1" class="ltx_sup">‡</sup></span></span>
</span></span><span id="S3.T23.23.15.15.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T23.36.28" class="ltx_tr">
<td id="S3.T23.36.28.14" class="ltx_td ltx_align_left ltx_border_t">Restaurant</td>
<td id="S3.T23.35.27.12" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.35.27.12.13" class="ltx_text"></span><span id="S3.T23.35.27.12.12" class="ltx_text">
<span id="S3.T23.35.27.12.12.12" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.26.18.3.3.3.3" class="ltx_tr">
<span id="S3.T23.26.18.3.3.3.3.3" class="ltx_td ltx_nopad_r ltx_align_left">name, type<sup id="S3.T23.26.18.3.3.3.3.3.1" class="ltx_sup">⋆</sup>, area<sup id="S3.T23.26.18.3.3.3.3.3.2" class="ltx_sup">⋆</sup>, price range<sup id="S3.T23.26.18.3.3.3.3.3.3" class="ltx_sup">⋆</sup>,</span></span>
<span id="S3.T23.29.21.6.6.6.6" class="ltx_tr">
<span id="S3.T23.29.21.6.6.6.6.3" class="ltx_td ltx_nopad_r ltx_align_left">book day<sup id="S3.T23.29.21.6.6.6.6.3.1" class="ltx_sup">†</sup>, book time<sup id="S3.T23.29.21.6.6.6.6.3.2" class="ltx_sup">†</sup>, book people<sup id="S3.T23.29.21.6.6.6.6.3.3" class="ltx_sup">†</sup>,</span></span>
<span id="S3.T23.32.24.9.9.9.9" class="ltx_tr">
<span id="S3.T23.32.24.9.9.9.9.3" class="ltx_td ltx_nopad_r ltx_align_left">alcohol<sup id="S3.T23.32.24.9.9.9.9.3.1" class="ltx_sup">∗</sup>, walkability<sup id="S3.T23.32.24.9.9.9.9.3.2" class="ltx_sup">∗</sup>, parking<sup id="S3.T23.32.24.9.9.9.9.3.3" class="ltx_sup">∗</sup>,</span></span>
<span id="S3.T23.35.27.12.12.12.12" class="ltx_tr">
<span id="S3.T23.35.27.12.12.12.12.3" class="ltx_td ltx_nopad_r ltx_align_left">internet<sup id="S3.T23.35.27.12.12.12.12.3.1" class="ltx_sup">∗</sup>, smoking<sup id="S3.T23.35.27.12.12.12.12.3.2" class="ltx_sup">∗</sup>, outdoor table<sup id="S3.T23.35.27.12.12.12.12.3.3" class="ltx_sup">∗</sup></span></span>
</span></span><span id="S3.T23.35.27.12.14" class="ltx_text"></span></td>
<td id="S3.T23.36.28.13" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.36.28.13.2" class="ltx_text"></span><span id="S3.T23.36.28.13.1" class="ltx_text">
<span id="S3.T23.36.28.13.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.36.28.13.1.1.2" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">rating, nearby station,</span></span>
<span id="S3.T23.36.28.13.1.1.3" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">minutes walk from station,</span></span>
<span id="S3.T23.36.28.13.1.1.4" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">address, phone number,</span></span>
<span id="S3.T23.36.28.13.1.1.5" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">business hour, last order time,</span></span>
<span id="S3.T23.36.28.13.1.1.1" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">representative menu, reference number<sup id="S3.T23.36.28.13.1.1.1.1.1" class="ltx_sup">‡</sup></span></span>
</span></span><span id="S3.T23.36.28.13.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T23.44.36" class="ltx_tr">
<td id="S3.T23.44.36.9" class="ltx_td ltx_align_left ltx_border_t">Attraction</td>
<td id="S3.T23.44.36.8" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.44.36.8.9" class="ltx_text"></span><span id="S3.T23.44.36.8.8" class="ltx_text">
<span id="S3.T23.44.36.8.8.8" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.38.30.2.2.2.2" class="ltx_tr">
<span id="S3.T23.38.30.2.2.2.2.2" class="ltx_td ltx_nopad_r ltx_align_left">name, type<sup id="S3.T23.38.30.2.2.2.2.2.1" class="ltx_sup">⋆</sup>, area<sup id="S3.T23.38.30.2.2.2.2.2.2" class="ltx_sup">⋆</sup>,</span></span>
<span id="S3.T23.41.33.5.5.5.5" class="ltx_tr">
<span id="S3.T23.41.33.5.5.5.5.3" class="ltx_td ltx_nopad_r ltx_align_left">walkability<sup id="S3.T23.41.33.5.5.5.5.3.1" class="ltx_sup">∗</sup>, parking<sup id="S3.T23.41.33.5.5.5.5.3.2" class="ltx_sup">∗</sup>, heritage<sup id="S3.T23.41.33.5.5.5.5.3.3" class="ltx_sup">∗</sup>,</span></span>
<span id="S3.T23.44.36.8.8.8.8" class="ltx_tr">
<span id="S3.T23.44.36.8.8.8.8.3" class="ltx_td ltx_nopad_r ltx_align_left">educational<sup id="S3.T23.44.36.8.8.8.8.3.1" class="ltx_sup">∗</sup>, scenic<sup id="S3.T23.44.36.8.8.8.8.3.2" class="ltx_sup">∗</sup>, cultural<sup id="S3.T23.44.36.8.8.8.8.3.3" class="ltx_sup">∗</sup></span></span>
</span></span><span id="S3.T23.44.36.8.10" class="ltx_text"></span></td>
<td id="S3.T23.44.36.10" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.44.36.10.1" class="ltx_text"></span><span id="S3.T23.44.36.10.2" class="ltx_text">
<span id="S3.T23.44.36.10.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.44.36.10.2.1.1" class="ltx_tr">
<span id="S3.T23.44.36.10.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">rating, nearby station,</span></span>
<span id="S3.T23.44.36.10.2.1.2" class="ltx_tr">
<span id="S3.T23.44.36.10.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">minutes walk from station,</span></span>
<span id="S3.T23.44.36.10.2.1.3" class="ltx_tr">
<span id="S3.T23.44.36.10.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">address, phone number,</span></span>
<span id="S3.T23.44.36.10.2.1.4" class="ltx_tr">
<span id="S3.T23.44.36.10.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">business hour, entrance fee</span></span>
</span></span><span id="S3.T23.44.36.10.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T23.47.39" class="ltx_tr">
<td id="S3.T23.47.39.4" class="ltx_td ltx_align_left ltx_border_t">Taxi</td>
<td id="S3.T23.47.39.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.47.39.3.4" class="ltx_text"></span><span id="S3.T23.47.39.3.3" class="ltx_text">
<span id="S3.T23.47.39.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.46.38.2.2.2.2" class="ltx_tr">
<span id="S3.T23.46.38.2.2.2.2.2" class="ltx_td ltx_nopad_r ltx_align_left">leave at<sup id="S3.T23.46.38.2.2.2.2.2.1" class="ltx_sup">⋆</sup>, departure<sup id="S3.T23.46.38.2.2.2.2.2.2" class="ltx_sup">⋆</sup>,</span></span>
<span id="S3.T23.47.39.3.3.3.3" class="ltx_tr">
<span id="S3.T23.47.39.3.3.3.3.1" class="ltx_td ltx_nopad_r ltx_align_left">arrive by, destination<sup id="S3.T23.47.39.3.3.3.3.1.1" class="ltx_sup">⋆</sup>, type</span></span>
</span></span><span id="S3.T23.47.39.3.5" class="ltx_text"></span></td>
<td id="S3.T23.47.39.5" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.47.39.5.1" class="ltx_text"></span><span id="S3.T23.47.39.5.2" class="ltx_text">
<span id="S3.T23.47.39.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.47.39.5.2.1.1" class="ltx_tr">
<span id="S3.T23.47.39.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">phone number, cost, duration</span></span>
</span></span><span id="S3.T23.47.39.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T23.49.41" class="ltx_tr">
<td id="S3.T23.49.41.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Metro</td>
<td id="S3.T23.49.41.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S3.T23.49.41.2.3" class="ltx_text"></span><span id="S3.T23.49.41.2.2" class="ltx_text">
<span id="S3.T23.49.41.2.2.2" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.49.41.2.2.2.2" class="ltx_tr">
<span id="S3.T23.49.41.2.2.2.2.2" class="ltx_td ltx_nopad_r ltx_align_left">leave at, departure<sup id="S3.T23.49.41.2.2.2.2.2.1" class="ltx_sup">⋆</sup>, destination<sup id="S3.T23.49.41.2.2.2.2.2.2" class="ltx_sup">⋆</sup></span></span>
</span></span><span id="S3.T23.49.41.2.4" class="ltx_text"></span></td>
<td id="S3.T23.49.41.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S3.T23.49.41.4.1" class="ltx_text"></span><span id="S3.T23.49.41.4.2" class="ltx_text">
<span id="S3.T23.49.41.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.49.41.4.2.1.1" class="ltx_tr">
<span id="S3.T23.49.41.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">departure line, destination line,</span></span>
<span id="S3.T23.49.41.4.2.1.2" class="ltx_tr">
<span id="S3.T23.49.41.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">arrive by, cost, duration,</span></span>
<span id="S3.T23.49.41.4.2.1.3" class="ltx_tr">
<span id="S3.T23.49.41.4.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">transfer, optimal path</span></span>
</span></span><span id="S3.T23.49.41.4.3" class="ltx_text"></span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS8.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">1. Defining Task Schema</h5>

<div id="S3.SS8.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS8.SSS1.Px2.p1.1" class="ltx_p">We first define a task schema which expresses the scenario of task-oriented dialogue. Our task schema consists of slots across five domains (hotel, restaurant, attraction, taxi, and metro) as shown in Table&nbsp;<a href="#S3.T23" title="Table 23 ‣ Overview ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">23</span></a>. Typically, slots are categorized into informable slots and requestable slots. The informable slots cover properties which can constrain a user goal<span id="footnote48" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">48</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">48</sup><span class="ltx_tag ltx_tag_note">48</span>A user goal is what the worker playing user should follow as shown in Table&nbsp;<a href="#S3.T24" title="Table 24 ‣ 1. Defining Task Schema ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">24</span></a>.</span></span></span> such as “price range”, “area”, and “booking day”. The requestable slots provide additional information that a user may ask, but not necessarily need to be specified as a user goal constraint. A typical example of a requestable slot is “phone number”, which a user may ask for, but would not work to narrow down the probable candidates of the goal <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>.</p>
</div>
<div id="S3.SS8.SSS1.Px2.p2" class="ltx_para">
<p id="S3.SS8.SSS1.Px2.p2.1" class="ltx_p">Based on this schema, we include additional attributes to the informable and requestable slots to provide an easy-to-operate annotation system and easy-to-follow guidelines. A slot could have one or more attributes among whether it is 1) boolean type, 2) required or not (<span id="S3.SS8.SSS1.Px2.p2.1.1" class="ltx_text ltx_font_italic">Required</span>), 3) related to booking (<span id="S3.SS8.SSS1.Px2.p2.1.2" class="ltx_text ltx_font_italic">Booking-related</span>), and 4) only available after booking is confirmed (<span id="S3.SS8.SSS1.Px2.p2.1.3" class="ltx_text ltx_font_italic">Requestable after booking</span>. e.g., reference number). The boolean type slots can have either <span id="S3.SS8.SSS1.Px2.p2.1.4" class="ltx_text ltx_font_italic">yes</span> or <span id="S3.SS8.SSS1.Px2.p2.1.5" class="ltx_text ltx_font_italic">no</span> as their values, such as “Parking (availability)” and “(has) swimming pool”. Such boolean type values do not appear in the dialogue context explicitly. In other words, they have abstractive properties. A model which understands abstractive properties is desirable, so we have much more boolean type slots than MultiWOZ&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>; WoS has 20 boolean slots across the domains while MultiWOZ includes only 2. Meanwhile, the required slots have to be specified with values in order to fill out a user intent. This helps us to simulate an actual service scenario in which an agent is not allowed to take the next steps without specifying required values <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>.</p>
</div>
<figure id="S3.T24" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 24: </span>An example of goal instruction. Unlike MultiWOZ, we present all instructions from the beginning to prevent ordering bias as in CoCo&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. The booking-related slots, “restaurant-book time (22:41)” and “restaurant-book day (Wednesday)” appear before a confirmation of KB entity.</figcaption>
<table id="S3.T24.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T24.1.1" class="ltx_tr">
<td id="S3.T24.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T24.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T24.1.1.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T24.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Korean</span></span>
</span>
</td>
<td id="S3.T24.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T24.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T24.1.1.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T24.1.1.2.1.1.1" class="ltx_text ltx_font_bold">English (Translated)</span></span>
</span>
</td>
</tr>
<tr id="S3.T24.1.2" class="ltx_tr">
<td id="S3.T24.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T24.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T24.1.2.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T24.1.2.1.1.1.1" class="ltx_text" style="font-size:90%;">당신은 오늘 <span id="S3.T24.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">22:41</span>에 <span id="S3.T24.1.2.1.1.1.1.2" class="ltx_text ltx_font_bold">서울 중앙</span>에서 식사할 계획을 가지고 있습니다.
아참 오늘은 <span id="S3.T24.1.2.1.1.1.1.3" class="ltx_text ltx_font_bold">수요일</span> 입니다.
그런 곳을 찾았다면 먼저 <span id="S3.T24.1.2.1.1.1.1.4" class="ltx_text ltx_font_bold">대표 메뉴</span>를 확인하세요.
그리고 나선 <span id="S3.T24.1.2.1.1.1.1.5" class="ltx_text ltx_font_bold">1</span>명으로 예약 거세요.
예약 이후엔 <span id="S3.T24.1.2.1.1.1.1.6" class="ltx_text ltx_font_bold">영업 시간</span>을 문의하시구요.
그리고 나선 <span id="S3.T24.1.2.1.1.1.1.7" class="ltx_text ltx_font_bold">식당 근처</span>에서 잘 곳을 찾아야 합니다.
그 곳은 반드시 <span id="S3.T24.1.2.1.1.1.1.8" class="ltx_text ltx_font_bold">흡연이 불가</span>해야 합니다.
찾았다면 <span id="S3.T24.1.2.1.1.1.1.9" class="ltx_text ltx_font_bold">같은 요일</span>에 예약하세요.
<span id="S3.T24.1.2.1.1.1.1.10" class="ltx_text ltx_font_bold">같은 인원</span>으로 <span id="S3.T24.1.2.1.1.1.1.11" class="ltx_text ltx_font_bold">4</span>일간 머물러야 합니다.
예약에 성공했다면 <span id="S3.T24.1.2.1.1.1.1.12" class="ltx_text ltx_font_bold">예약 번호</span>를 묻고, <span id="S3.T24.1.2.1.1.1.1.13" class="ltx_text ltx_font_bold">흡연 가능 유무</span>를 더블 체크하세요.
그런 다음 마지막으로 택시를 하나 부르세요.
<span id="S3.T24.1.2.1.1.1.1.14" class="ltx_text ltx_font_bold">식당</span>에서 <span id="S3.T24.1.2.1.1.1.1.15" class="ltx_text ltx_font_bold">숙소</span>로 향해야 합니다.
찾았다면 <span id="S3.T24.1.2.1.1.1.1.16" class="ltx_text ltx_font_bold">소요 시간</span>을 문의하세요.</span></span>
</span>
</td>
<td id="S3.T24.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T24.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T24.1.2.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T24.1.2.2.1.1.1" class="ltx_text" style="font-size:90%;">You have a plan to eat in the <span id="S3.T24.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">center of Seoul</span> at <span id="S3.T24.1.2.2.1.1.1.2" class="ltx_text ltx_font_bold">22:41</span> today.
Oh, today is <span id="S3.T24.1.2.2.1.1.1.3" class="ltx_text ltx_font_bold">Wednesday</span>.
If you find such a place, first check the <span id="S3.T24.1.2.2.1.1.1.4" class="ltx_text ltx_font_bold">representative menu</span>.
Then, make a booking for <span id="S3.T24.1.2.2.1.1.1.5" class="ltx_text ltx_font_bold">1</span> person.
After booking, inquire about the <span id="S3.T24.1.2.2.1.1.1.6" class="ltx_text ltx_font_bold">business hour</span>.
Then, you have to find a hotel to sleep in <span id="S3.T24.1.2.2.1.1.1.7" class="ltx_text ltx_font_bold">near the restaurant</span>.
The restaurant must be <span id="S3.T24.1.2.2.1.1.1.8" class="ltx_text ltx_font_bold">non-smoking</span>.
If you find it, book on the <span id="S3.T24.1.2.2.1.1.1.9" class="ltx_text ltx_font_bold">same day</span>.
You must stay for <span id="S3.T24.1.2.2.1.1.1.10" class="ltx_text ltx_font_bold">4</span> days as the <span id="S3.T24.1.2.2.1.1.1.11" class="ltx_text ltx_font_bold">same number of people</span>.
If the booking is done, ask for the <span id="S3.T24.1.2.2.1.1.1.12" class="ltx_text ltx_font_bold">reference number</span> and double-check the <span id="S3.T24.1.2.2.1.1.1.13" class="ltx_text ltx_font_bold">smoking allowed</span>.
Then, finally, call a taxi.
You have to go to the <span id="S3.T24.1.2.2.1.1.1.14" class="ltx_text ltx_font_bold">hotel</span> from the <span id="S3.T24.1.2.2.1.1.1.15" class="ltx_text ltx_font_bold">restaurant</span>.
If you call the taxi, inquire about the <span id="S3.T24.1.2.2.1.1.1.16" class="ltx_text ltx_font_bold">duration</span>.</span></span>
</span>
</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS8.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2. Creating Knowledge Base</h5>

<div id="S3.SS8.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS8.SSS1.Px3.p1.1" class="ltx_p">We construct a knowledge base (KB) based on the task schema of each domain to obtain a set of predefined realization candidates of a user’s goal. For the hotel and restaurant domains, we manually create virtual instances, whereas for the attraction and metro domains, we leverage real names (e.g. Gangnam Station or Namsan Tower) collected from the web. On the other hand, for the taxi domain, we do not define instances in advance, but dynamically generate the instances during the dialogue collection as in MultiWOZ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. With ethical considerations in mind, any personally identifiable information (PII, e.g., phone number, address) is replaced with randomly generated instances using <span id="S3.SS8.SSS1.Px3.p1.1.1" class="ltx_text ltx_font_typewriter">faker</span>.<span id="footnote49" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">49</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">49</sup><span class="ltx_tag ltx_tag_note">49</span><a target="_blank" href="https://faker.readthedocs.io" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://faker.readthedocs.io</a></span></span></span> Table&nbsp;<a href="#S3.T25" title="Table 25 ‣ 2. Creating Knowledge Base ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">25</span></a> shows the KB statistics for each domain.</p>
</div>
<figure id="S3.T25" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 25: </span>Statistics of Knowledge Base in WoS.</figcaption>
<table id="S3.T25.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T25.1.1" class="ltx_tr">
<td id="S3.T25.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T25.1.1.1.1" class="ltx_text ltx_font_bold">Domain</span></td>
<td id="S3.T25.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T25.1.1.2.1" class="ltx_text ltx_font_bold"># Instances</span></td>
<td id="S3.T25.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T25.1.1.3.1" class="ltx_text ltx_font_bold"># Slots</span></td>
</tr>
<tr id="S3.T25.1.2" class="ltx_tr">
<td id="S3.T25.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Hotel</td>
<td id="S3.T25.1.2.2" class="ltx_td ltx_align_center ltx_border_t">101</td>
<td id="S3.T25.1.2.3" class="ltx_td ltx_align_center ltx_border_t">19</td>
</tr>
<tr id="S3.T25.1.3" class="ltx_tr">
<td id="S3.T25.1.3.1" class="ltx_td ltx_align_left">Restaurant</td>
<td id="S3.T25.1.3.2" class="ltx_td ltx_align_center">56</td>
<td id="S3.T25.1.3.3" class="ltx_td ltx_align_center">20</td>
</tr>
<tr id="S3.T25.1.4" class="ltx_tr">
<td id="S3.T25.1.4.1" class="ltx_td ltx_align_left">Attraction</td>
<td id="S3.T25.1.4.2" class="ltx_td ltx_align_center">100</td>
<td id="S3.T25.1.4.3" class="ltx_td ltx_align_center">17</td>
</tr>
<tr id="S3.T25.1.5" class="ltx_tr">
<td id="S3.T25.1.5.1" class="ltx_td ltx_align_left">Taxi</td>
<td id="S3.T25.1.5.2" class="ltx_td ltx_align_center">-</td>
<td id="S3.T25.1.5.3" class="ltx_td ltx_align_center">8</td>
</tr>
<tr id="S3.T25.1.6" class="ltx_tr">
<td id="S3.T25.1.6.1" class="ltx_td ltx_align_left ltx_border_bb">Metro</td>
<td id="S3.T25.1.6.2" class="ltx_td ltx_align_center ltx_border_bb">3,306</td>
<td id="S3.T25.1.6.3" class="ltx_td ltx_align_center ltx_border_bb">10</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS8.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">3. Designing the Annotation System</h5>

<div id="S3.SS8.SSS1.Px4.p1" class="ltx_para">
<p id="S3.SS8.SSS1.Px4.p1.1" class="ltx_p">In this section, we describe the annotation platform we used for collecting data from both the User-side and System-side.</p>
</div>
</section>
<section id="S3.SS8.SSS1.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">3.1. User Side</h5>

<div id="S3.SS8.SSS1.Px5.p1" class="ltx_para">
<p id="S3.SS8.SSS1.Px5.p1.1" class="ltx_p">We provide a goal instruction for a user side role. The instruction includes descriptions of a user’s specific goal with corresponding slot values in natural language. It also contains the user’s context including persona for variety of dialogues. A user is asked to generate utterances following the instruction. An example is shown Table&nbsp;<a href="#S3.T24" title="Table 24 ‣ 1. Defining Task Schema ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">24</span></a>.</p>
</div>
<div id="S3.SS8.SSS1.Px5.p2" class="ltx_para">
<p id="S3.SS8.SSS1.Px5.p2.1" class="ltx_p">To devise a multi-domain dialogue scenario where slots are shared across multiple domains, we include <span id="S3.SS8.SSS1.Px5.p2.1.1" class="ltx_text ltx_font_italic">domain transition</span> in the instruction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>. For example, in case of a user aiming to book a hotel, the user might seek information about transportation (taxi, metro, etc.) to get there. In this dialogue, initial domain is changed to another (hotel to taxi/metro). It is more challenging compared with single domain in terms of dialogue state tracking. Because user could express their goal implicitly where values should be inferred by co-referencing other values of preceding domains.</p>
</div>
<div id="S3.SS8.SSS1.Px5.p3" class="ltx_para">
<p id="S3.SS8.SSS1.Px5.p3.1" class="ltx_p">The goal instructions are realized by the templates containing placeholders for goal constraining slots and their values. We design diverse templates for each domain, in order to cover various scenarios of the dialogues. Like MultiWOZ, the goal templates include a series of subgoals with corresponding slots. We carefully design the sentences to promote lexical entailment or co-referencing during conversation, which can be naturally observed in the user context or during the domain transition. When filling a template to complete instructions, we randomly assign the instances from KB built upon the domain-specific task schema to the given placeholders. The values of the instruction should be specifically mentioned by a user during a conversation. Each trackable slot either has valid values, <span id="S3.SS8.SSS1.Px5.p3.1.1" class="ltx_text ltx_font_italic">None</span> or <span id="S3.SS8.SSS1.Px5.p3.1.2" class="ltx_text ltx_font_italic">Dontcare</span>.<span id="footnote50" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">50</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">50</sup><span class="ltx_tag ltx_tag_note">50</span><span id="footnote50.1" class="ltx_text ltx_font_italic">Dontcare</span> means a user has no preference and <span id="footnote50.2" class="ltx_text ltx_font_italic">None</span> means a user is yet to specify a valid value for given slot <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>.</span></span></span></p>
</div>
<div id="S3.SS8.SSS1.Px5.p4" class="ltx_para">
<p id="S3.SS8.SSS1.Px5.p4.1" class="ltx_p">To properly evaluate a model’s generalization ability, we further add counterfactual goals and introduce unseen KB instances during the process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. To add new goal instruction based on the current slot distribution, we keep monitoring the slot value frequency and co-occurrence over slots during the construction. Specifically, we add new goal instructions which cover infrequent slot values or rarely co-occurring combination among slots. For example, when “(hotel-parking, no)” is infrequent pair in the as-is distribution, we promote it to appear in dialogues by designing goal instruction including it as constraint. Moreover, we differentiate KB instances between particular subset of dataset (train and dev/test set) to simulate realistic scenario regarding unseen slot values in the test time.</p>
</div>
<figure id="S3.F7" class="ltx_figure"><img src="/html/2105.09680/assets/figs/wos_gui.png" id="S3.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="347" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Graphical web interface for system side worker.</figcaption>
</figure>
</section>
<section id="S3.SS8.SSS1.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">3.2. System Side</h5>

<div id="S3.SS8.SSS1.Px6.p1" class="ltx_para">
<p id="S3.SS8.SSS1.Px6.p1.1" class="ltx_p">The role of a system side worker (wizard) is to 1) annotate dialogue states of user utterances while 2) generate responses by accessing to the KB if necessary, for every turn. First, the wizard is asked to fill in appropriate slot values inferred from the current dialogue context. If the word uttered by the user is not clear to directly map to a specific slot value, the wizard should clarify the meaning of the word first and then fill the slot when the word has the same meaning as the value. The annotation of a dialogue state is an explicit action of understanding a user request to fully focus on providing the required information. Then, the wizard generates response either to request or to convey information. If the values of required slots are absent, the system side worker is allowed to ask for the missing values to the user. Otherwise, the system provides the user with the adequate information. We enable the system to query the external knowledge base, if needed. When there are more than three search results, the system worker could request more details or recommend one among them.</p>
</div>
<div id="S3.SS8.SSS1.Px6.p2" class="ltx_para">
<p id="S3.SS8.SSS1.Px6.p2.1" class="ltx_p">To support the wizard to perform such complicate work effectively and efficiently, we provide a graphical web interface with a newly introduced feature: dropdown components (Figure&nbsp;<a href="#S3.F7" title="Figure 7 ‣ 3.1. User Side ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>). Dropdown interface enables the system side worker can choose a value from a list of pre-populated candidates. We present most probable value candidates based on the goal instruction and domain-specific knowledge base, since a dropdown might become worthless when too many options are presented to workers. This procedure naturally prevents several type of annotation errors, such as <span id="S3.SS8.SSS1.Px6.p2.1.1" class="ltx_text ltx_font_italic">multi-annotations</span>, <span id="S3.SS8.SSS1.Px6.p2.1.2" class="ltx_text ltx_font_italic">mis-annotations</span>, <span id="S3.SS8.SSS1.Px6.p2.1.3" class="ltx_text ltx_font_italic">typos</span>, and <span id="S3.SS8.SSS1.Px6.p2.1.4" class="ltx_text ltx_font_italic">value canonicalization</span> reported in MutiWOZ 2.1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS8.SSS1.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">4. Dataset Construction</h5>

<div id="S3.SS8.SSS1.Px7.p1" class="ltx_para">
<p id="S3.SS8.SSS1.Px7.p1.1" class="ltx_p">We adapt ‘Self-dialog’ scheme inspired by taskmaster-1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> to efficiently collect diverse dialogue dataset while reducing the cost and time. Self-dialog is effective to collect various dialogue data. By having both roles, a worker freely controls a flow of dialogue such as the order of slot occurrence in user utterances and recommendation of system responses. This also leads workers to speak their own styles naturally such that different personas are included. However, we found annotation errors in pilot phase such as <span id="S3.SS8.SSS1.Px7.p1.1.1" class="ltx_text ltx_font_italic">early-markup</span> (system pre-fills the values before receiving the values from the user) and <span id="S3.SS8.SSS1.Px7.p1.1.2" class="ltx_text ltx_font_italic">delayed-markup</span> (the system fills the values behindhand the proper turn) errors. We further improve the scheme by utilizing explicit turn-switching between user and system roles with providing error correction interface.</p>
</div>
<div id="S3.SS8.SSS1.Px7.p2" class="ltx_para">
<p id="S3.SS8.SSS1.Px7.p2.1" class="ltx_p">To elaborate, we train and select trustworthy workers to participate in the main collection process. Prior to the main phase, we conduct several pilot studies with crowdworkers to avoid aforementioned early-markups and delayed-markup errors, and to generate more realistic dialogues including some miscommunications. We also implement an explicit turn-switching between the two roles, in order to immerse themselves in a user/system role, which mitigates overly reduced miscommunications as well. Throughout the pilot, we finally employ 15 selected workers who can effectively handle such issues.</p>
</div>
</section>
<section id="S3.SS8.SSS1.Px8" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS8.SSS1.Px8.p1" class="ltx_para">
<p id="S3.SS8.SSS1.Px8.p1.1" class="ltx_p">Table&nbsp;<a href="#S3.T26" title="Table 26 ‣ Final Dataset ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">26</span></a> shows statistics of our dataset. WoS contains overall 10,000 dialogues with 146,692 turns across 5 domains. The evaluation (dev/test) set specifically includes dialogues with counterfactual goals and unseen KB instances against train set. The dev/test set contains 294 and 361 counterfactual goal-based dialogues, respectively. All the splits contain sufficient number of dialogues with domain transition.</p>
</div>
<figure id="S3.T26" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 26: </span>Statistics of Wizard-of-Seoul (WoS).</figcaption>
<table id="S3.T26.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T26.1.1" class="ltx_tr">
<td id="S3.T26.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T26.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T26.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T26.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T26.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T26.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T26.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T26.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T26.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T26.1.2" class="ltx_tr">
<td id="S3.T26.1.2.1" class="ltx_td ltx_align_left ltx_border_t"># Dialogues</td>
<td id="S3.T26.1.2.2" class="ltx_td ltx_align_center ltx_border_t">8,000</td>
<td id="S3.T26.1.2.3" class="ltx_td ltx_align_center ltx_border_t">1,000</td>
<td id="S3.T26.1.2.4" class="ltx_td ltx_align_center ltx_border_t">1,000</td>
<td id="S3.T26.1.2.5" class="ltx_td ltx_align_center ltx_border_t">10,000</td>
</tr>
<tr id="S3.T26.1.3" class="ltx_tr">
<td id="S3.T26.1.3.1" class="ltx_td ltx_align_left"># Single Domain Dialogues</td>
<td id="S3.T26.1.3.2" class="ltx_td ltx_align_center">1,806</td>
<td id="S3.T26.1.3.3" class="ltx_td ltx_align_center">263</td>
<td id="S3.T26.1.3.4" class="ltx_td ltx_align_center">226</td>
<td id="S3.T26.1.3.5" class="ltx_td ltx_align_center">2,295</td>
</tr>
<tr id="S3.T26.1.4" class="ltx_tr">
<td id="S3.T26.1.4.1" class="ltx_td ltx_align_left"># Multi Domain Dialogues</td>
<td id="S3.T26.1.4.2" class="ltx_td ltx_align_center">6,194</td>
<td id="S3.T26.1.4.3" class="ltx_td ltx_align_center">737</td>
<td id="S3.T26.1.4.4" class="ltx_td ltx_align_center">774</td>
<td id="S3.T26.1.4.5" class="ltx_td ltx_align_center">7,705</td>
</tr>
<tr id="S3.T26.1.5" class="ltx_tr">
<td id="S3.T26.1.5.1" class="ltx_td ltx_align_left"># Counterfactual Dialogues</td>
<td id="S3.T26.1.5.2" class="ltx_td ltx_align_center">0</td>
<td id="S3.T26.1.5.3" class="ltx_td ltx_align_center">294</td>
<td id="S3.T26.1.5.4" class="ltx_td ltx_align_center">361</td>
<td id="S3.T26.1.5.5" class="ltx_td ltx_align_center">655</td>
</tr>
<tr id="S3.T26.1.6" class="ltx_tr">
<td id="S3.T26.1.6.1" class="ltx_td ltx_align_left ltx_border_t"># Total Turns</td>
<td id="S3.T26.1.6.2" class="ltx_td ltx_align_center ltx_border_t">117,584</td>
<td id="S3.T26.1.6.3" class="ltx_td ltx_align_center ltx_border_t">14,448</td>
<td id="S3.T26.1.6.4" class="ltx_td ltx_align_center ltx_border_t">14,660</td>
<td id="S3.T26.1.6.5" class="ltx_td ltx_align_center ltx_border_t">146,692</td>
</tr>
<tr id="S3.T26.1.7" class="ltx_tr">
<td id="S3.T26.1.7.1" class="ltx_td ltx_align_left"># Total Tokens</td>
<td id="S3.T26.1.7.2" class="ltx_td ltx_align_center">899,450</td>
<td id="S3.T26.1.7.3" class="ltx_td ltx_align_center">114,169</td>
<td id="S3.T26.1.7.4" class="ltx_td ltx_align_center">114,914</td>
<td id="S3.T26.1.7.5" class="ltx_td ltx_align_center">1,128,533</td>
</tr>
<tr id="S3.T26.1.8" class="ltx_tr">
<td id="S3.T26.1.8.1" class="ltx_td ltx_align_left ltx_border_t">Avg Turns per Dialogue</td>
<td id="S3.T26.1.8.2" class="ltx_td ltx_align_center ltx_border_t">14.70</td>
<td id="S3.T26.1.8.3" class="ltx_td ltx_align_center ltx_border_t">14.45</td>
<td id="S3.T26.1.8.4" class="ltx_td ltx_align_center ltx_border_t">14.66</td>
<td id="S3.T26.1.8.5" class="ltx_td ltx_align_center ltx_border_t">14.67</td>
</tr>
<tr id="S3.T26.1.9" class="ltx_tr">
<td id="S3.T26.1.9.1" class="ltx_td ltx_align_left ltx_border_bb">Avg Tokens per Turn</td>
<td id="S3.T26.1.9.2" class="ltx_td ltx_align_center ltx_border_bb">7.65</td>
<td id="S3.T26.1.9.3" class="ltx_td ltx_align_center ltx_border_bb">7.90</td>
<td id="S3.T26.1.9.4" class="ltx_td ltx_align_center ltx_border_bb">7.84</td>
<td id="S3.T26.1.9.5" class="ltx_td ltx_align_center ltx_border_bb">7.69</td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS8.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.2 </span>Evaluation Metrics</h4>

<div id="S3.SS8.SSS2.p1" class="ltx_para">
<p id="S3.SS8.SSS2.p1.1" class="ltx_p">For evaluation metrics for WoS is 1) joint goal accuracy (JGA) and 2) slot micro F1 score. JGA measures the proportion of exactly matched dialogue state which consists of a set of slot-value pairs with the ground truth dialogue state among the total number of dialogue turns. Slot micro F1 score is an average of micro F1 scores in each turn. For each turn, micro F1 score is defined as the harmonic mean of precision and recall in terms of predicted slot-value pairs and ground-truth pairs. Note that the slot micro F1 score ignores when value of the ground truth is “<span id="S3.SS8.SSS2.p1.1.1" class="ltx_text ltx_font_typewriter">None</span>”.</p>
</div>
</section>
<section id="S3.SS8.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.3 </span>Analysis</h4>

<div id="S3.SS8.SSS3.p1" class="ltx_para">
<p id="S3.SS8.SSS3.p1.1" class="ltx_p">When splitting the train and dev/test set based on the counterfactual goals and unseen KB instances, like <cite class="ltx_cite ltx_citemacro_citet">Li et&nbsp;al. [<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>, we observe performance drop as shown in Table&nbsp;<a href="#S3.T27" title="Table 27 ‣ 3.8.3 Analysis ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">27</span></a>. This demonstrates that the counterfactual goal makes WoS more challenging.</p>
</div>
<figure id="S3.T27" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 27: </span>Comparison regarding data split strategy. Random is splitting train, dev and test set randomly. The CF-goal indicates they are included in dev and test set with unseen KB instances.</figcaption>
<table id="S3.T27.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T27.1.1" class="ltx_tr">
<td id="S3.T27.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T27.1.1.1.1" class="ltx_text ltx_font_bold">Domain Split</span></td>
<td id="S3.T27.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T27.1.1.2.1" class="ltx_text ltx_font_bold">Joint Goal Accuracy</span></td>
</tr>
<tr id="S3.T27.1.2" class="ltx_tr">
<td id="S3.T27.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Random</td>
<td id="S3.T27.1.2.2" class="ltx_td ltx_align_center ltx_border_t">57.53</td>
</tr>
<tr id="S3.T27.1.3" class="ltx_tr">
<td id="S3.T27.1.3.1" class="ltx_td ltx_align_left ltx_border_bb">CF-goal</td>
<td id="S3.T27.1.3.2" class="ltx_td ltx_align_center ltx_border_bb">47.38</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS8.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.4 </span>Related Work</h4>

<div id="S3.SS8.SSS4.p1" class="ltx_para">
<p id="S3.SS8.SSS4.p1.1" class="ltx_p">Wizard-of-Oz (WOZ) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> is a popular scheme in dialogue collection. In fact, conventional WOZ setting allows to collect various type of dialogues by employing role-playing of two humans. Each human should choose a role between the two: <span id="S3.SS8.SSS4.p1.1.1" class="ltx_text ltx_font_italic">user</span> and <span id="S3.SS8.SSS4.p1.1.2" class="ltx_text ltx_font_italic">system</span>. As taking a role, dialogues are collected by turn-taking generation of utterances with background information provided in advance. In the case of building a task-oriented dialogue, <span id="S3.SS8.SSS4.p1.1.3" class="ltx_text ltx_font_italic">goal</span> is given to a <span id="S3.SS8.SSS4.p1.1.4" class="ltx_text ltx_font_italic">user</span> while <span id="S3.SS8.SSS4.p1.1.5" class="ltx_text ltx_font_italic">knowledge base</span> is allowed to be accessed to <span id="S3.SS8.SSS4.p1.1.6" class="ltx_text ltx_font_italic">system</span>. The <span id="S3.SS8.SSS4.p1.1.7" class="ltx_text ltx_font_italic">system</span> can use its <span id="S3.SS8.SSS4.p1.1.8" class="ltx_text ltx_font_italic">knowledge base</span> when responding to <span id="S3.SS8.SSS4.p1.1.9" class="ltx_text ltx_font_italic">user</span>’s request.</p>
</div>
<div id="S3.SS8.SSS4.p2" class="ltx_para">
<p id="S3.SS8.SSS4.p2.1" class="ltx_p">Many dialogue datasets closely follow WOZ settings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, however, it costs a lot of time and money because two crowdworkers must be matched at the same time and successfully play each role, which prevents collecting dialogues at scale. We refer this limitation to ‘worker coexistence constraints’. To overcome the limitation, MultiWOZ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> slightly change this conventional WOZ to <span id="S3.SS8.SSS4.p2.1.1" class="ltx_text ltx_font_italic">asynchronously</span> collect dialogues turn-by-turn from crowdworkers, which allows different workers to play the same <span id="S3.SS8.SSS4.p2.1.2" class="ltx_text ltx_font_italic">user</span> or <span id="S3.SS8.SSS4.p2.1.3" class="ltx_text ltx_font_italic">system</span> in a single dialogue. This approach costs less but error-prone because every worker must adapt to dialogue already progressed so that their response might be incoherent to the previous context <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Recently, CrossWOZ and RiSAWOZ thus pair only selected trustworthy workers to collect dialogues in <span id="S3.SS8.SSS4.p2.1.4" class="ltx_text ltx_font_italic">synchronous</span> manner as suggested in the WOZ settings to keep the annotation quality despite the high construction cost <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>, <a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>.</p>
</div>
<div id="S3.SS8.SSS4.p3" class="ltx_para">
<p id="S3.SS8.SSS4.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Byrne et&nbsp;al. [<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> also argue that conventional WOZ settings are time consuming, complex and expensive, requiring considerable technical implementation as well as administrative procedures to train and manage both agents and crowdsourced workers, accordingly suggesting Self-dialog as an alternative. Self-dialog is a collection scheme in which workers write the entire dialogue playing both user and system roles. To demonstrate their idea, <cite class="ltx_cite ltx_citemacro_citet">Byrne et&nbsp;al. [<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> build a large-scale dialogue datase, Taskmaster-1, which is built upon the Self-dialog which stands on the WOZ schemes: 1) two people playing user and system roles (conventional WOZ setting) and 2) one person playing both roles (Self-dialog). As a result, Self-dialog can remedy the cost of ‘worker coexistence constraint’ effectively with avoiding incoherent dialogue generation caused by asynchronous dialogue collection. However, there is a tendency that little miscommunication occurs in the dialogue which compared to the real world conversations because the same person produces utterances in both roles, which might lead to a gap from reality.</p>
</div>
<div id="S3.SS8.SSS4.p4" class="ltx_para">
<p id="S3.SS8.SSS4.p4.1" class="ltx_p">Some researchers further tries to employ only machines to create such dialogues to maximize cost-efficiency. It builds the dialogues on top of a simulator which is able to create utterances by turn automatically from elaborately designed rules and given task schema. The simulator first generates psuedo-dialogue, then adopts crowdsourcing to paraphrase them to the natural utterances <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>. It requires much less human effort, however, heavily relies on the simulator.</p>
</div>
<div id="S3.SS8.SSS4.p5" class="ltx_para">
<p id="S3.SS8.SSS4.p5.1" class="ltx_p">Meanwhile, previous works exists addressing robust evaluation of DST models. According to CoCo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>, state-of-the-art DST models are not robust to realistic scenarios since they scarcely appear in the train data. As the name CoCo (controllable counterfactuals) suggests, it generates infrequent but realistic dialogues based on the predefined slot-value pairs. They show that even a state-of-the-art DST model’s performance drops significantly when they are evaluated on such dialogues including counterfactual goals. It means the current TOD benchmarks should be improved in terms of robustness to unseen but realistic scenarios.</p>
</div>
<div id="S3.SS8.SSS4.p6" class="ltx_para">
<p id="S3.SS8.SSS4.p6.1" class="ltx_p">As for Korean, there is a task-oriented dialog dataset is provided by National Information Society Agency (NIA). It covers about 10 domains related to the civil complaints and consists of more than 500k dialogues. The utterances are divided into four types: 1) a main question that a user asks, 2) a sub question that a system could ask for clarification, 3) a user answer, and 4) a system answer. Additionally, user intents are annotated and entities are extracted from each utterance. We find that this dataset does not follow any of the aforementioned settings; there is no dialogue state represented as slot-value pairs, only regarding single turn judgement. It also lacks information about task schema and redistribution is restricted which does not satisfy our accessibility principle, which motivates us to newly create a DST benchmark.</p>
</div>
</section>
<section id="S3.SS8.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.5 </span>Conclusion</h4>

<div id="S3.SS8.SSS5.p1" class="ltx_para">
<p id="S3.SS8.SSS5.p1.1" class="ltx_p">We introduce Wizard-of-Seoul (WoS), the first large-scale Korean multi-domain task-oriented dialogue dataset that simulates conversations between Seoul tourists and travel agents. We adapt ‘Self-dialog’ for efficiently scaling up of dialogue collection scheme. In addition, consideration on annotation interfaces (drop-down menu and turn-switching) mitigates erroneous cases and diverse goal instructions including counterfactual ones promote each conversation to be more natural and challenging. We hope that WoS sparks various future dialogue research in Korean and also offers valuable insights to pushing forward end-to-end dialogue modeling.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Pretrained Language Models</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In order to facilitate further research using KLUE, we provide strong baselines for all the benchmark tasks within it. As a part of this effort, we pretrain and release large-scale language models for Korean, which we hope would reduce the burden of retraining large-scale language models from individual researchers.
More specifically, We pretrain language models (PLM), including BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>, from scratch.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Language Models</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We pretrain multiple Korean language models while varying training configuration. This enables us to explore effective settings for pretraining Korean models and further establish simple yet effective baseline models for KLUE. We train KLUE-BERT and KLUE-RoBERTa. We vary the choice of a pretraining corpus, preprocessing procedure, tokenization strategy, and other training configurations.</p>
</div>
<figure id="S4.T28" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 28: </span>Statistics of the pretraining corpus.</figcaption>
<div id="S4.T28.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:481.8pt;height:82pt;vertical-align:-10.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T28.1.1" class="ltx_p"><span id="S4.T28.1.1.1" class="ltx_text">
<span id="S4.T28.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T28.1.1.1.1.1" class="ltx_tr">
<span id="S4.T28.1.1.1.1.1.1" class="ltx_td ltx_border_tt"></span>
<span id="S4.T28.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">MODU</span></span>
<span id="S4.T28.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">CC-100-Kor</span></span>
<span id="S4.T28.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">NAMUWIKI</span></span>
<span id="S4.T28.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.5.1" class="ltx_text ltx_font_bold">NEWSCRAWL</span></span>
<span id="S4.T28.1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.6.1" class="ltx_text ltx_font_bold">PETITION</span></span>
<span id="S4.T28.1.1.1.1.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.7.1" class="ltx_text ltx_font_bold">Total</span></span></span>
<span id="S4.T28.1.1.1.1.2" class="ltx_tr">
<span id="S4.T28.1.1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"># Sentences</span>
<span id="S4.T28.1.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">167M</span>
<span id="S4.T28.1.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">103M</span>
<span id="S4.T28.1.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">14M</span>
<span id="S4.T28.1.1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">183M</span>
<span id="S4.T28.1.1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">5.2M</span>
<span id="S4.T28.1.1.1.1.2.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T28.1.1.1.1.2.7.1" class="ltx_text ltx_font_bold">473M</span></span></span>
<span id="S4.T28.1.1.1.1.3" class="ltx_tr">
<span id="S4.T28.1.1.1.1.3.1" class="ltx_td ltx_align_left"># Words</span>
<span id="S4.T28.1.1.1.1.3.2" class="ltx_td ltx_align_center">1,892,814,395</span>
<span id="S4.T28.1.1.1.1.3.3" class="ltx_td ltx_align_center">1,593,887,022</span>
<span id="S4.T28.1.1.1.1.3.4" class="ltx_td ltx_align_center">265,203,602</span>
<span id="S4.T28.1.1.1.1.3.5" class="ltx_td ltx_align_center">2,716,968,038</span>
<span id="S4.T28.1.1.1.1.3.6" class="ltx_td ltx_align_center">50,631,183</span>
<span id="S4.T28.1.1.1.1.3.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T28.1.1.1.1.3.7.1" class="ltx_text ltx_font_bold">6,519,504,240</span></span></span>
<span id="S4.T28.1.1.1.1.4" class="ltx_tr">
<span id="S4.T28.1.1.1.1.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">size (GB)</span>
<span id="S4.T28.1.1.1.1.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">18.27</span>
<span id="S4.T28.1.1.1.1.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">15.46</span>
<span id="S4.T28.1.1.1.1.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">2.52</span>
<span id="S4.T28.1.1.1.1.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">25.87</span>
<span id="S4.T28.1.1.1.1.4.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.53</span>
<span id="S4.T28.1.1.1.1.4.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T28.1.1.1.1.4.7.1" class="ltx_text ltx_font_bold">62.65</span></span></span>
</span></span></p>
</span></div>
</figure>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretraining Corpora</h5>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">We gather the following five publicly available Korean corpora from diverse sources to cover a broad set of topics and many different styles. We combine these corpora to build the final pretraining corpus of size approximately 62GB. See Table&nbsp;<a href="#S4.T28" title="Table 28 ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">28</span></a> for overall statistics:</p>
</div>
<div id="S4.SS1.SSS0.Px1.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">MODU</span> : <span id="S4.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">Modu<span id="footnote51" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">51</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">51</sup><span class="ltx_tag ltx_tag_note"><span id="footnote51.1.1.1" class="ltx_text ltx_font_upright">51</span></span><span id="footnote51.5" class="ltx_text ltx_font_upright">
A transliteration of a Korean word ‘모두’ which means ‘Everyone’.
</span></span></span></span></span>
Corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> is a collection of Korean corpora distributed by National Institute of Korean Languages.<span id="footnote52" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">52</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">52</sup><span class="ltx_tag ltx_tag_note">52</span><a target="_blank" href="https://corpus.korean.go.kr/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://corpus.korean.go.kr/</a></span></span></span> It includes both formal articles (news and books) and colloquial text (dialogues).</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">CC-100-Kor</span> : CC-100<span id="footnote53" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">53</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">53</sup><span class="ltx_tag ltx_tag_note">53</span>
<a target="_blank" href="http://data.statmt.org/cc-100/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://data.statmt.org/cc-100/</a>
</span></span></span>
is the large-scale multilingual web crawled corpora by using CC-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite>. This is used for training XLM-R <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. We use the Korean portion from this corpora.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">NAMUWIKI</span> : NAMUWIKI is a Korean web-based encyclopedia, similar to Wikipedia, but known to be less formal. Specifically, we download the dump created on March 2nd, 2020.<span id="footnote54" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">54</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">54</sup><span class="ltx_tag ltx_tag_note">54</span>
<a target="_blank" href="http://dump.thewiki.kr" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dump.thewiki.kr</a>
</span></span></span></p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">NEWSCRAWL</span> : NEWSCRAWL consists of 12,800,000 news articles published from 2011 to 2020, collected from a news aggregation platform.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p"><span id="S4.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">PETITION</span> : Petition is a collection of public petitions posted to the Blue House asking for administrative actions on social issues. We use the articles in the Blue House National Petition<span id="footnote55" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">55</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">55</sup><span class="ltx_tag ltx_tag_note">55</span>
<a target="_blank" href="https://www1.president.go.kr/petitions" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www1.president.go.kr/petitions</a>
</span></span></span>
published from August 2017 to March 2019.<span id="footnote56" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">56</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">56</sup><span class="ltx_tag ltx_tag_note">56</span>
<a target="_blank" href="https://ko-nlp.github.io/Korpora/en-docs/corpuslist/korean_petitions.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ko-nlp.github.io/Korpora/en-docs/corpuslist/korean_petitions.html</a>
</span></span></span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Preprocessing</h5>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">We filter noisy text and non-Korean text using the same methods from Section&nbsp;<a href="#S2.SS3.SSS0.Px3" title="PII Removal ‣ 2.3 Preprocessing ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>. Each document in the corpus is split into sentences using C++ implementation (v1.3.1.) of rule-based Korean Sentence Splitter (KSS).<span id="footnote57" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">57</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">57</sup><span class="ltx_tag ltx_tag_note">57</span>
<a target="_blank" href="https://github.com/likejazz/korean-sentence-splitter" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/likejazz/korean-sentence-splitter</a>
</span></span></span>
For CC-100-Kor and NEWSCRAWL, we keep sentences of length greater than equal to 200 characters, as a heuristics to keep well-formed sentences. We then remove sentences included in our benchmark task datasets, using BM25 as a sentence similarity metric <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Ethical Considerations</h5>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">Because we collect and use as much publicly available data as possible for pretraining, these corpora often contain undesirable social biases. Furthermore, we noticed earlier quite a bit of PII in these corpora, although they were all publicly available. Both of these are problematic. Social biases in the corpus may result in a language model that learns such biases. PII in the corpus may be memorized by a language model and can subsequently be retrieved by adversarial attacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S4.SS1.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p2.1" class="ltx_p">We do not filter out socially biased contents nor hate speech for three reasons.
First, manual inspection is infeasible for this large-scale pretraining corpora. Second, it is a challenging problem on its own to automatically detect socially biased contents or hate space, as both of these highly depend on the context in which they appear <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. Lastly, being blind to such harmful contents prevents the future use of a language model for detecting and correcting these harmful contents, such as using it as an anti-expert&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. We expect future research on the pretrained language models we release to focus on how to detect and correct biases encoded in these models and on how to debias them, as has been recently demonstrated by <cite class="ltx_cite ltx_citemacro_citet">Cheng et&nbsp;al. [<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
<div id="S4.SS1.SSS0.Px3.p3" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p3.1" class="ltx_p">In contrast, we pseudonymize PII in our corpora as much as possible. We detect 16 personal data types using regular expressions based on the guideline from the Korea Internet and Security Agency (KISA).<span id="footnote58" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">58</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">58</sup><span class="ltx_tag ltx_tag_note">58</span>
<a target="_blank" href="https://www.kisa.or.kr/public/laws/laws2_View.jsp?cPage=1&amp;mode=view&amp;p_No=282&amp;b_No=282&amp;d_No=3" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kisa.or.kr/public/laws/laws2_View.jsp?cPage=1&amp;mode=view&amp;p_No=282&amp;b_No=282&amp;d_No=3</a>
</span></span></span> It is relatively easy to pseudonymize PII while keeping linguistic patterns, since the selected PII has standardized pattern.
We then replace the original information, using either the <a href="faker" title="" class="ltx_ref ltx_url ltx_font_typewriter">faker</a> library<span id="footnote59" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">59</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">59</sup><span class="ltx_tag ltx_tag_note">59</span>
<a target="_blank" href="https://github.com/joke2k/faker" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/joke2k/faker</a>
</span></span></span>
or random generation based on the pattern. As a result, we pseudonymize 1.2% of the pretraining corpora. Details are illustrated in Table&nbsp;<a href="#S4.T29" title="Table 29 ‣ Ethical Considerations ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">29</span></a>.</p>
</div>
<figure id="S4.T29" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 29: </span>Our pseudonymization methods and examples. The examples are from <a href="faker" title="" class="ltx_ref ltx_url ltx_font_typewriter">faker</a> library documentation or the public.</figcaption>
<div id="S4.T29.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:401.8pt;height:306pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T29.1.1" class="ltx_p"><span id="S4.T29.1.1.1" class="ltx_text">
<span id="S4.T29.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T29.1.1.1.1.1" class="ltx_tr">
<span id="S4.T29.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T29.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Private Information</span></span>
<span id="S4.T29.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T29.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Pseudonymization</span></span>
<span id="S4.T29.1.1.1.1.1.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S4.T29.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Pseudonymised Example</span></span></span>
<span id="S4.T29.1.1.1.1.2" class="ltx_tr">
<span id="S4.T29.1.1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T29.1.1.1.1.2.1.1" class="ltx_text ltx_font_bold">Telephone Number</span></span>
<span id="S4.T29.1.1.1.1.2.2" class="ltx_td ltx_align_left ltx_border_t">Faker</span>
<span id="S4.T29.1.1.1.1.2.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">055-604-8764</span></span>
<span id="S4.T29.1.1.1.1.3" class="ltx_tr">
<span id="S4.T29.1.1.1.1.3.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.3.1.1" class="ltx_text ltx_font_bold">Social Security Number</span></span>
<span id="S4.T29.1.1.1.1.3.2" class="ltx_td ltx_align_left">Faker</span>
<span id="S4.T29.1.1.1.1.3.3" class="ltx_td ltx_nopad_r ltx_align_left">600408-2764759</span></span>
<span id="S4.T29.1.1.1.1.4" class="ltx_tr">
<span id="S4.T29.1.1.1.1.4.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.4.1.1" class="ltx_text ltx_font_bold">Foreign Registration Number</span></span>
<span id="S4.T29.1.1.1.1.4.2" class="ltx_td ltx_align_left">Faker</span>
<span id="S4.T29.1.1.1.1.4.3" class="ltx_td ltx_nopad_r ltx_align_left">110527-1815659</span></span>
<span id="S4.T29.1.1.1.1.5" class="ltx_tr">
<span id="S4.T29.1.1.1.1.5.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.5.1.1" class="ltx_text ltx_font_bold">Email Address</span></span>
<span id="S4.T29.1.1.1.1.5.2" class="ltx_td ltx_align_left">Faker</span>
<span id="S4.T29.1.1.1.1.5.3" class="ltx_td ltx_nopad_r ltx_align_left">agweon@example.org</span></span>
<span id="S4.T29.1.1.1.1.6" class="ltx_tr">
<span id="S4.T29.1.1.1.1.6.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.6.1.1" class="ltx_text ltx_font_bold">IP Address</span></span>
<span id="S4.T29.1.1.1.1.6.2" class="ltx_td ltx_align_left">Faker</span>
<span id="S4.T29.1.1.1.1.6.3" class="ltx_td ltx_nopad_r ltx_align_left">166.186.169.69</span></span>
<span id="S4.T29.1.1.1.1.7" class="ltx_tr">
<span id="S4.T29.1.1.1.1.7.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.7.1.1" class="ltx_text ltx_font_bold">MAC Address</span></span>
<span id="S4.T29.1.1.1.1.7.2" class="ltx_td ltx_align_left">Faker</span>
<span id="S4.T29.1.1.1.1.7.3" class="ltx_td ltx_nopad_r ltx_align_left">c5:d7:14:84:f8:cf</span></span>
<span id="S4.T29.1.1.1.1.8" class="ltx_tr">
<span id="S4.T29.1.1.1.1.8.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.8.1.1" class="ltx_text ltx_font_bold">Mention(@)</span></span>
<span id="S4.T29.1.1.1.1.8.2" class="ltx_td ltx_align_left">Faker</span>
<span id="S4.T29.1.1.1.1.8.3" class="ltx_td ltx_nopad_r ltx_align_left">@gildong</span></span>
<span id="S4.T29.1.1.1.1.9" class="ltx_tr">
<span id="S4.T29.1.1.1.1.9.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.9.1.1" class="ltx_text ltx_font_bold">Address</span></span>
<span id="S4.T29.1.1.1.1.9.2" class="ltx_td ltx_align_left">Random Number Generation</span>
<span id="S4.T29.1.1.1.1.9.3" class="ltx_td ltx_nopad_r ltx_align_left">경상북도 성남시 서초대64가</span></span>
<span id="S4.T29.1.1.1.1.10" class="ltx_tr">
<span id="S4.T29.1.1.1.1.10.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.10.1.1" class="ltx_text ltx_font_bold">Bank Account Number</span></span>
<span id="S4.T29.1.1.1.1.10.2" class="ltx_td ltx_align_left">Random Number Generation</span>
<span id="S4.T29.1.1.1.1.10.3" class="ltx_td ltx_nopad_r ltx_align_left">110-245-124678</span></span>
<span id="S4.T29.1.1.1.1.11" class="ltx_tr">
<span id="S4.T29.1.1.1.1.11.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.11.1.1" class="ltx_text ltx_font_bold">Passport Number</span></span>
<span id="S4.T29.1.1.1.1.11.2" class="ltx_td ltx_align_left">Random Generation</span>
<span id="S4.T29.1.1.1.1.11.3" class="ltx_td ltx_nopad_r ltx_align_left">M123A4567</span></span>
<span id="S4.T29.1.1.1.1.12" class="ltx_tr">
<span id="S4.T29.1.1.1.1.12.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.12.1.1" class="ltx_text ltx_font_bold">Driver’s License</span></span>
<span id="S4.T29.1.1.1.1.12.2" class="ltx_td ltx_align_left">Random Number Generation</span>
<span id="S4.T29.1.1.1.1.12.3" class="ltx_td ltx_nopad_r ltx_align_left">11-17-174133-01</span></span>
<span id="S4.T29.1.1.1.1.13" class="ltx_tr">
<span id="S4.T29.1.1.1.1.13.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.13.1.1" class="ltx_text ltx_font_bold">Business Registration Number</span></span>
<span id="S4.T29.1.1.1.1.13.2" class="ltx_td ltx_align_left">Random Number Generation</span>
<span id="S4.T29.1.1.1.1.13.3" class="ltx_td ltx_nopad_r ltx_align_left">123-45-67890</span></span>
<span id="S4.T29.1.1.1.1.14" class="ltx_tr">
<span id="S4.T29.1.1.1.1.14.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.14.1.1" class="ltx_text ltx_font_bold">Health Insurance Information</span></span>
<span id="S4.T29.1.1.1.1.14.2" class="ltx_td ltx_align_left">Random Number Generation</span>
<span id="S4.T29.1.1.1.1.14.3" class="ltx_td ltx_nopad_r ltx_align_left">1-2345678901</span></span>
<span id="S4.T29.1.1.1.1.15" class="ltx_tr">
<span id="S4.T29.1.1.1.1.15.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.15.1.1" class="ltx_text ltx_font_bold">Credit or Debit Card Number</span></span>
<span id="S4.T29.1.1.1.1.15.2" class="ltx_td ltx_align_left">Random Number Generation</span>
<span id="S4.T29.1.1.1.1.15.3" class="ltx_td ltx_nopad_r ltx_align_left">1234-5678-9012-3456</span></span>
<span id="S4.T29.1.1.1.1.16" class="ltx_tr">
<span id="S4.T29.1.1.1.1.16.1" class="ltx_td ltx_align_left"><span id="S4.T29.1.1.1.1.16.1.1" class="ltx_text ltx_font_bold">Vehicle Registration Place</span></span>
<span id="S4.T29.1.1.1.1.16.2" class="ltx_td ltx_align_left">Random Generation</span>
<span id="S4.T29.1.1.1.1.16.3" class="ltx_td ltx_nopad_r ltx_align_left">55구 1601</span></span>
<span id="S4.T29.1.1.1.1.17" class="ltx_tr">
<span id="S4.T29.1.1.1.1.17.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T29.1.1.1.1.17.1.1" class="ltx_text ltx_font_bold">Homepage URL</span></span>
<span id="S4.T29.1.1.1.1.17.2" class="ltx_td ltx_align_left ltx_border_bb">Random Generation</span>
<span id="S4.T29.1.1.1.1.17.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">www.example.com</span></span>
</span></span></p>
</span></div>
</figure>
</section>
<section id="S4.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Tokenization</h5>

<div id="S4.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p1.1" class="ltx_p">We design and use a new tokenization method, <span id="S4.SS1.SSS0.Px4.p1.1.1" class="ltx_text ltx_font_italic">morpheme-based subword</span> tokenization. When building a vocabulary, we pre-tokenize a raw text into morphemes using a morphological analyzer, and then we apply byte pair encoding (BPE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite> to get the final vocabulary. For morpheme segmentation, we use <span id="S4.SS1.SSS0.Px4.p1.1.2" class="ltx_text ltx_font_typewriter">Mecab-ko</span>,<span id="footnote60" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">60</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">60</sup><span class="ltx_tag ltx_tag_note">60</span>
<a target="_blank" href="https://bitbucket.org/eunjeon/mecab-ko" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://bitbucket.org/eunjeon/mecab-ko</a>
</span></span></span>
MeCab <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> adapted for Korean, and for BPE segmentation, we use the wordpiece tokenizer from <span id="S4.SS1.SSS0.Px4.p1.1.3" class="ltx_text ltx_font_typewriter">Huggingface Tokenizers</span> library.<span id="footnote61" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">61</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">61</sup><span class="ltx_tag ltx_tag_note">61</span>
<a target="_blank" href="https://github.com/huggingface/tokenizers" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/tokenizers</a>
</span></span></span>
We specify the vocabulary size to 32k.
After building the vocabulary, we only use the BPE model during inference, which allows us to tokenize a word sequence by reflecting morphemes without a morphological analyzer. This improves both usability and speed. Examples are presented in Table&nbsp;<a href="#S4.T30" title="Table 30 ‣ Tokenization ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">30</span></a>.</p>
</div>
<div id="S4.SS1.SSS0.Px4.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p2.1" class="ltx_p">The motivation behind this method is that Korean is an agglutinative language, which is to say, a word is a constitution of morphemes - stems and affixes. The morphemes tend to remain unchange on different unions, and the boundary is generally clear. Although BPE has been widely used across many languages due to its effectiveness, it struggles to identify morphemes correctly as demonstrated in Table&nbsp;<a href="#S4.T30" title="Table 30 ‣ Tokenization ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">30</span></a>.</p>
</div>
<figure id="S4.T30" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 30: </span>An input text “조경현은 인공지능 분야의 저명한 연구자이다. (Kyunghyun Cho is a prominent AI researcher.)” is segmented with various tokenization strategies. We denote slash (/) as a token separator. The mBERT tokenizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> splits the input text into nearly in characters resulting in a longer sequence than monolingual tokenizers. BPE tokenizer generates tokens spanning multiple morphemes (##현은, ##명한). <span id="S4.T30.2.1" class="ltx_text ltx_font_italic">Morpheme-based subword</span> tokenizer, on the other hand, better splits text into morphemes (##은, ##의).</figcaption>
<div id="S4.T30.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:581.1pt;height:118.1pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T30.3.1" class="ltx_p"><span id="S4.T30.3.1.1" class="ltx_text">
<span id="S4.T30.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T30.3.1.1.1.1" class="ltx_tr">
<span id="S4.T30.3.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T30.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Tokenization</span></span>
<span id="S4.T30.3.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T30.3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Tokenized Sequence</span></span></span>
<span id="S4.T30.3.1.1.1.2" class="ltx_tr">
<span id="S4.T30.3.1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Raw Text</span>
<span id="S4.T30.3.1.1.1.2.2" class="ltx_td ltx_align_left ltx_border_t">조경현은 인공지능 분야의 저명한 연구자이다.</span></span>
<span id="S4.T30.3.1.1.1.3" class="ltx_tr">
<span id="S4.T30.3.1.1.1.3.1" class="ltx_td ltx_align_left ltx_border_t">BPE (Multilingual)</span>
<span id="S4.T30.3.1.1.1.3.2" class="ltx_td ltx_align_left ltx_border_t">조 / ##경 / ##현 / ##은 / 인 / ##공 / ##지 / ##능 / 분 / ##야 / ##의 / 저 / ##명한 / 연구 / ##자 / ##이다 / .</span></span>
<span id="S4.T30.3.1.1.1.4" class="ltx_tr">
<span id="S4.T30.3.1.1.1.4.1" class="ltx_td ltx_align_left ltx_border_t">BPE</span>
<span id="S4.T30.3.1.1.1.4.2" class="ltx_td ltx_align_left ltx_border_t">조경 / ##현은 / 인공지능 / 분야의 / 저 / ##명한 / 연구 / ##자이 / ##다 / .</span></span>
<span id="S4.T30.3.1.1.1.5" class="ltx_tr">
<span id="S4.T30.3.1.1.1.5.1" class="ltx_td ltx_align_left">Morpheme</span>
<span id="S4.T30.3.1.1.1.5.2" class="ltx_td ltx_align_left">조경현 / 은 / 인공지능 / 분야 / 의 / 저명 / 한 / 연구자 / 이 / 다 / .</span></span>
<span id="S4.T30.3.1.1.1.6" class="ltx_tr">
<span id="S4.T30.3.1.1.1.6.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T30.3.1.1.1.6.1.1" class="ltx_text ltx_font_bold">Morpheme-based Subword</span></span>
<span id="S4.T30.3.1.1.1.6.2" class="ltx_td ltx_align_left ltx_border_bb">조경 / ##현 / ##은 / 인공지능 / 분야 / ##의 / 저명 / ##한 / 연구자 / ##이다 / .</span></span>
</span></span></p>
</span></div>
</figure>
</section>
<section id="S4.SS1.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Training Configurations</h5>

<div id="S4.SS1.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px5.p1.1" class="ltx_p">We choose BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>
architectures for our language models. Table&nbsp;<a href="#S4.T31" title="Table 31 ‣ Training Configurations ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">31</span></a> describes the implementation details. All models take sequences of at most 512 tokens long each and are pretrained with a static or dynamic masking strategy following the original training procedure. When masking tokens, we use whole word masking (WWM) which masks all of the the tokens that form a single word. BERT also performs next sentence prediction (NSP). Other hyperparameters not specified in Table&nbsp;<a href="#S4.T31" title="Table 31 ‣ Training Configurations ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">31</span></a> nor in the pretraining procedure details are same as the original configurations from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. Due to the resource constraints, we could increase batch size only up to 2,048, unlike <cite class="ltx_cite ltx_citemacro_citet">Liu et&nbsp;al. [<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> who use the batch size of 8k. We decrease the learning rate accordingly. We fix the learning rate to <math id="S4.SS1.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.SS1.SSS0.Px5.p1.1.m1.1a"><msup id="S4.SS1.SSS0.Px5.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.cmml"><mn id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2.cmml">10</mn><mrow id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml"><mo id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3a" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml">−</mo><mn id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.2" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px5.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2">10</cn><apply id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3"><minus id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3"></minus><cn type="integer" id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px5.p1.1.m1.1c">10^{-4}</annotation></semantics></math> for both BERT and RoBERTa.</p>
</div>
<figure id="S4.T31" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 31: </span>Implementation details of KLUE-BERT and KLUE-RoBERTa. WWM refers to the whole word masking strategy.</figcaption>
<div id="S4.T31.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:552.2pt;height:91pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T31.11.11" class="ltx_p"><span id="S4.T31.11.11.11" class="ltx_text">
<span id="S4.T31.11.11.11.11" class="ltx_tabular ltx_align_middle">
<span id="S4.T31.11.11.11.11.12" class="ltx_tr">
<span id="S4.T31.11.11.11.11.12.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T31.11.11.11.11.12.1.1" class="ltx_text ltx_font_bold">Model</span></span>
<span id="S4.T31.11.11.11.11.12.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.2.1" class="ltx_text ltx_font_bold"># Parameter</span></span>
<span id="S4.T31.11.11.11.11.12.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.3.1" class="ltx_text ltx_font_bold">Masking</span></span>
<span id="S4.T31.11.11.11.11.12.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.4.1" class="ltx_text ltx_font_bold">Training Steps</span></span>
<span id="S4.T31.11.11.11.11.12.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.5.1" class="ltx_text ltx_font_bold">Batch Size</span></span>
<span id="S4.T31.11.11.11.11.12.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.6.1" class="ltx_text ltx_font_bold">Learning Rate</span></span>
<span id="S4.T31.11.11.11.11.12.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.7.1" class="ltx_text ltx_font_bold">Device</span></span></span>
<span id="S4.T31.2.2.2.2.2" class="ltx_tr">
<span id="S4.T31.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T31.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\text{KLUE-BERT}_{\text{BASE}}" display="inline"><semantics id="S4.T31.1.1.1.1.1.1.m1.1a"><msub id="S4.T31.1.1.1.1.1.1.m1.1.1" xref="S4.T31.1.1.1.1.1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T31.1.1.1.1.1.1.m1.1.1.2" xref="S4.T31.1.1.1.1.1.1.m1.1.1.2a.cmml">KLUE-BERT</mtext><mtext class="ltx_mathvariant_bold" id="S4.T31.1.1.1.1.1.1.m1.1.1.3" xref="S4.T31.1.1.1.1.1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T31.1.1.1.1.1.1.m1.1b"><apply id="S4.T31.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T31.1.1.1.1.1.1.m1.1.1.2a.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T31.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1.2">KLUE-BERT</mtext></ci><ci id="S4.T31.1.1.1.1.1.1.m1.1.1.3a.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.T31.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.1.1.1.1.1.1.m1.1c">\text{KLUE-BERT}_{\text{BASE}}</annotation></semantics></math></span>
<span id="S4.T31.2.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">110M</span>
<span id="S4.T31.2.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">Static, WWM</span>
<span id="S4.T31.2.2.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">1M</span>
<span id="S4.T31.2.2.2.2.2.6" class="ltx_td ltx_align_center ltx_border_t">256</span>
<span id="S4.T31.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T31.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.T31.2.2.2.2.2.2.m1.1a"><msup id="S4.T31.2.2.2.2.2.2.m1.1.1" xref="S4.T31.2.2.2.2.2.2.m1.1.1.cmml"><mn id="S4.T31.2.2.2.2.2.2.m1.1.1.2" xref="S4.T31.2.2.2.2.2.2.m1.1.1.2.cmml">10</mn><mrow id="S4.T31.2.2.2.2.2.2.m1.1.1.3" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3.cmml"><mo id="S4.T31.2.2.2.2.2.2.m1.1.1.3a" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3.cmml">−</mo><mn id="S4.T31.2.2.2.2.2.2.m1.1.1.3.2" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T31.2.2.2.2.2.2.m1.1b"><apply id="S4.T31.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.2.2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T31.2.2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1.2">10</cn><apply id="S4.T31.2.2.2.2.2.2.m1.1.1.3.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3"><minus id="S4.T31.2.2.2.2.2.2.m1.1.1.3.1.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3"></minus><cn type="integer" id="S4.T31.2.2.2.2.2.2.m1.1.1.3.2.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.2.2.2.2.2.2.m1.1c">10^{-4}</annotation></semantics></math></span>
<span id="S4.T31.2.2.2.2.2.7" class="ltx_td ltx_align_center ltx_border_t">TPU v3-8</span></span>
<span id="S4.T31.5.5.5.5.5" class="ltx_tr">
<span id="S4.T31.3.3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T31.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{SMALL}}" display="inline"><semantics id="S4.T31.3.3.3.3.3.1.m1.1a"><msub id="S4.T31.3.3.3.3.3.1.m1.1.1" xref="S4.T31.3.3.3.3.3.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T31.3.3.3.3.3.1.m1.1.1.2" xref="S4.T31.3.3.3.3.3.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S4.T31.3.3.3.3.3.1.m1.1.1.3" xref="S4.T31.3.3.3.3.3.1.m1.1.1.3a.cmml">SMALL</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T31.3.3.3.3.3.1.m1.1b"><apply id="S4.T31.3.3.3.3.3.1.m1.1.1.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.3.3.3.3.3.1.m1.1.1.1.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1">subscript</csymbol><ci id="S4.T31.3.3.3.3.3.1.m1.1.1.2a.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T31.3.3.3.3.3.1.m1.1.1.2.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S4.T31.3.3.3.3.3.1.m1.1.1.3a.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.T31.3.3.3.3.3.1.m1.1.1.3.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1.3">SMALL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.3.3.3.3.3.1.m1.1c">\text{KLUE-RoBERTa}_{\text{SMALL}}</annotation></semantics></math></span>
<span id="S4.T31.5.5.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t">68M</span>
<span id="S4.T31.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">Dynamic, WWM</span>
<span id="S4.T31.5.5.5.5.5.6" class="ltx_td ltx_align_center ltx_border_t">1M</span>
<span id="S4.T31.5.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">2048</span>
<span id="S4.T31.4.4.4.4.4.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T31.4.4.4.4.4.2.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.T31.4.4.4.4.4.2.m1.1a"><msup id="S4.T31.4.4.4.4.4.2.m1.1.1" xref="S4.T31.4.4.4.4.4.2.m1.1.1.cmml"><mn id="S4.T31.4.4.4.4.4.2.m1.1.1.2" xref="S4.T31.4.4.4.4.4.2.m1.1.1.2.cmml">10</mn><mrow id="S4.T31.4.4.4.4.4.2.m1.1.1.3" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3.cmml"><mo id="S4.T31.4.4.4.4.4.2.m1.1.1.3a" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3.cmml">−</mo><mn id="S4.T31.4.4.4.4.4.2.m1.1.1.3.2" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T31.4.4.4.4.4.2.m1.1b"><apply id="S4.T31.4.4.4.4.4.2.m1.1.1.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.4.4.4.4.4.2.m1.1.1.1.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T31.4.4.4.4.4.2.m1.1.1.2.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1.2">10</cn><apply id="S4.T31.4.4.4.4.4.2.m1.1.1.3.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3"><minus id="S4.T31.4.4.4.4.4.2.m1.1.1.3.1.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3"></minus><cn type="integer" id="S4.T31.4.4.4.4.4.2.m1.1.1.3.2.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.4.4.4.4.4.2.m1.1c">10^{-4}</annotation></semantics></math></span>
<span id="S4.T31.5.5.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t">8<math id="S4.T31.5.5.5.5.5.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T31.5.5.5.5.5.3.m1.1a"><mo id="S4.T31.5.5.5.5.5.3.m1.1.1" xref="S4.T31.5.5.5.5.5.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T31.5.5.5.5.5.3.m1.1b"><times id="S4.T31.5.5.5.5.5.3.m1.1.1.cmml" xref="S4.T31.5.5.5.5.5.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.5.5.5.5.5.3.m1.1c">\times</annotation></semantics></math> V100 GPUs</span></span>
<span id="S4.T31.8.8.8.8.8" class="ltx_tr">
<span id="S4.T31.6.6.6.6.6.1" class="ltx_td ltx_align_left"><math id="S4.T31.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="S4.T31.6.6.6.6.6.1.m1.1a"><msub id="S4.T31.6.6.6.6.6.1.m1.1.1" xref="S4.T31.6.6.6.6.6.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T31.6.6.6.6.6.1.m1.1.1.2" xref="S4.T31.6.6.6.6.6.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S4.T31.6.6.6.6.6.1.m1.1.1.3" xref="S4.T31.6.6.6.6.6.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T31.6.6.6.6.6.1.m1.1b"><apply id="S4.T31.6.6.6.6.6.1.m1.1.1.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.6.6.6.6.6.1.m1.1.1.1.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1">subscript</csymbol><ci id="S4.T31.6.6.6.6.6.1.m1.1.1.2a.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T31.6.6.6.6.6.1.m1.1.1.2.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S4.T31.6.6.6.6.6.1.m1.1.1.3a.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.T31.6.6.6.6.6.1.m1.1.1.3.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.6.6.6.6.6.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math></span>
<span id="S4.T31.8.8.8.8.8.4" class="ltx_td ltx_align_center">110M</span>
<span id="S4.T31.8.8.8.8.8.5" class="ltx_td ltx_align_center">Dynamic, WWM</span>
<span id="S4.T31.8.8.8.8.8.6" class="ltx_td ltx_align_center">1M</span>
<span id="S4.T31.8.8.8.8.8.7" class="ltx_td ltx_align_center">2048</span>
<span id="S4.T31.7.7.7.7.7.2" class="ltx_td ltx_align_center"><math id="S4.T31.7.7.7.7.7.2.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.T31.7.7.7.7.7.2.m1.1a"><msup id="S4.T31.7.7.7.7.7.2.m1.1.1" xref="S4.T31.7.7.7.7.7.2.m1.1.1.cmml"><mn id="S4.T31.7.7.7.7.7.2.m1.1.1.2" xref="S4.T31.7.7.7.7.7.2.m1.1.1.2.cmml">10</mn><mrow id="S4.T31.7.7.7.7.7.2.m1.1.1.3" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3.cmml"><mo id="S4.T31.7.7.7.7.7.2.m1.1.1.3a" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3.cmml">−</mo><mn id="S4.T31.7.7.7.7.7.2.m1.1.1.3.2" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T31.7.7.7.7.7.2.m1.1b"><apply id="S4.T31.7.7.7.7.7.2.m1.1.1.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.7.7.7.7.7.2.m1.1.1.1.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T31.7.7.7.7.7.2.m1.1.1.2.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1.2">10</cn><apply id="S4.T31.7.7.7.7.7.2.m1.1.1.3.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3"><minus id="S4.T31.7.7.7.7.7.2.m1.1.1.3.1.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3"></minus><cn type="integer" id="S4.T31.7.7.7.7.7.2.m1.1.1.3.2.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.7.7.7.7.7.2.m1.1c">10^{-4}</annotation></semantics></math></span>
<span id="S4.T31.8.8.8.8.8.3" class="ltx_td ltx_align_center">8<math id="S4.T31.8.8.8.8.8.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T31.8.8.8.8.8.3.m1.1a"><mo id="S4.T31.8.8.8.8.8.3.m1.1.1" xref="S4.T31.8.8.8.8.8.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T31.8.8.8.8.8.3.m1.1b"><times id="S4.T31.8.8.8.8.8.3.m1.1.1.cmml" xref="S4.T31.8.8.8.8.8.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.8.8.8.8.8.3.m1.1c">\times</annotation></semantics></math> V100 GPUs</span></span>
<span id="S4.T31.11.11.11.11.11" class="ltx_tr">
<span id="S4.T31.9.9.9.9.9.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T31.9.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" display="inline"><semantics id="S4.T31.9.9.9.9.9.1.m1.1a"><msub id="S4.T31.9.9.9.9.9.1.m1.1.1" xref="S4.T31.9.9.9.9.9.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T31.9.9.9.9.9.1.m1.1.1.2" xref="S4.T31.9.9.9.9.9.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S4.T31.9.9.9.9.9.1.m1.1.1.3" xref="S4.T31.9.9.9.9.9.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T31.9.9.9.9.9.1.m1.1b"><apply id="S4.T31.9.9.9.9.9.1.m1.1.1.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.9.9.9.9.9.1.m1.1.1.1.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1">subscript</csymbol><ci id="S4.T31.9.9.9.9.9.1.m1.1.1.2a.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T31.9.9.9.9.9.1.m1.1.1.2.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S4.T31.9.9.9.9.9.1.m1.1.1.3a.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.T31.9.9.9.9.9.1.m1.1.1.3.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.9.9.9.9.9.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math></span>
<span id="S4.T31.11.11.11.11.11.4" class="ltx_td ltx_align_center ltx_border_bb">337M</span>
<span id="S4.T31.11.11.11.11.11.5" class="ltx_td ltx_align_center ltx_border_bb">Dynamic, WWM</span>
<span id="S4.T31.11.11.11.11.11.6" class="ltx_td ltx_align_center ltx_border_bb">500k</span>
<span id="S4.T31.11.11.11.11.11.7" class="ltx_td ltx_align_center ltx_border_bb">2048</span>
<span id="S4.T31.10.10.10.10.10.2" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T31.10.10.10.10.10.2.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.T31.10.10.10.10.10.2.m1.1a"><msup id="S4.T31.10.10.10.10.10.2.m1.1.1" xref="S4.T31.10.10.10.10.10.2.m1.1.1.cmml"><mn id="S4.T31.10.10.10.10.10.2.m1.1.1.2" xref="S4.T31.10.10.10.10.10.2.m1.1.1.2.cmml">10</mn><mrow id="S4.T31.10.10.10.10.10.2.m1.1.1.3" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3.cmml"><mo id="S4.T31.10.10.10.10.10.2.m1.1.1.3a" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3.cmml">−</mo><mn id="S4.T31.10.10.10.10.10.2.m1.1.1.3.2" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T31.10.10.10.10.10.2.m1.1b"><apply id="S4.T31.10.10.10.10.10.2.m1.1.1.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.10.10.10.10.10.2.m1.1.1.1.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T31.10.10.10.10.10.2.m1.1.1.2.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1.2">10</cn><apply id="S4.T31.10.10.10.10.10.2.m1.1.1.3.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3"><minus id="S4.T31.10.10.10.10.10.2.m1.1.1.3.1.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3"></minus><cn type="integer" id="S4.T31.10.10.10.10.10.2.m1.1.1.3.2.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.10.10.10.10.10.2.m1.1c">10^{-4}</annotation></semantics></math></span>
<span id="S4.T31.11.11.11.11.11.3" class="ltx_td ltx_align_center ltx_border_bb">8<math id="S4.T31.11.11.11.11.11.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T31.11.11.11.11.11.3.m1.1a"><mo id="S4.T31.11.11.11.11.11.3.m1.1.1" xref="S4.T31.11.11.11.11.11.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T31.11.11.11.11.11.3.m1.1b"><times id="S4.T31.11.11.11.11.11.3.m1.1.1.cmml" xref="S4.T31.11.11.11.11.11.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.11.11.11.11.11.3.m1.1c">\times</annotation></semantics></math> V100 GPUs</span></span>
</span></span></p>
</span></div>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Existing Language Models</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In addition to our own language models,
we evaluate the following two existing multilingual language models and two Korean monolingual language models on our benchmark:</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">mBERT</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> : A multilingual BERT introduced and released by <cite class="ltx_cite ltx_citemacro_citet">Devlin et&nbsp;al. [<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. It is trained with the MLM and NSP objectives on a multilingual corpus covering 104 languages including Korean.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">XLM-R</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> : A RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> trained on a large multilingual corpus by using the MLM objective.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p"><span id="S4.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">KR-BERT</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> : An open-sourced character-level Korean language model based on BERT.
We use the <span id="S4.I2.i3.p1.1.2" class="ltx_text ltx_font_typewriter">KR-BERT character WordPiece</span> which uses a vocabulary of 16,424 unique tokens.</p>
</div>
</li>
<li id="S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i4.p1" class="ltx_para">
<p id="S4.I2.i4.p1.1" class="ltx_p"><span id="S4.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">KoELECTRA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> : An open-source Korean language model trained with the MLM and replaced token detection objectives, as was done by <cite class="ltx_cite ltx_citemacro_citet">Clark et&nbsp;al. [<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. For training corpora, <cite class="ltx_cite ltx_citemacro_citet">Park [<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> uses own crawled news data and MODU corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Fine-tuning Language Models</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Task-Specific Architectures</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">8 main tasks of KLUE benchmark can be categorized into 4 types based on the fine-tuning strategy.
Topic classification (TC) and relation extraction (RE) are single sentence classification tasks. Sentence textual similarity (STS) and natural language inference (NLI) are sentence pair classification / regression tasks. Dialogue state tracking (DST) is a multiple-sentence slot-value prediction task. Finally, named entity recognition (NER), dependency parsing (DP) and machine reading comprehension (MRC) are sequence tagging tasks.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.5" class="ltx_p">We use <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><msub id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mi id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">x</mi><mi id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">𝑥</ci><ci id="S5.SS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">x_{i}</annotation></semantics></math> to refer to the <math id="S5.SS1.p2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><mi id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><ci id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">i</annotation></semantics></math>-th token of input and <math id="S5.SS1.p2.3.m3.1" class="ltx_Math" alttext="h_{i}\in\mathbb{R}^{H}" display="inline"><semantics id="S5.SS1.p2.3.m3.1a"><mrow id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml"><msub id="S5.SS1.p2.3.m3.1.1.2" xref="S5.SS1.p2.3.m3.1.1.2.cmml"><mi id="S5.SS1.p2.3.m3.1.1.2.2" xref="S5.SS1.p2.3.m3.1.1.2.2.cmml">h</mi><mi id="S5.SS1.p2.3.m3.1.1.2.3" xref="S5.SS1.p2.3.m3.1.1.2.3.cmml">i</mi></msub><mo id="S5.SS1.p2.3.m3.1.1.1" xref="S5.SS1.p2.3.m3.1.1.1.cmml">∈</mo><msup id="S5.SS1.p2.3.m3.1.1.3" xref="S5.SS1.p2.3.m3.1.1.3.cmml"><mi id="S5.SS1.p2.3.m3.1.1.3.2" xref="S5.SS1.p2.3.m3.1.1.3.2.cmml">ℝ</mi><mi id="S5.SS1.p2.3.m3.1.1.3.3" xref="S5.SS1.p2.3.m3.1.1.3.3.cmml">H</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><apply id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1"><in id="S5.SS1.p2.3.m3.1.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1.1"></in><apply id="S5.SS1.p2.3.m3.1.1.2.cmml" xref="S5.SS1.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.p2.3.m3.1.1.2.1.cmml" xref="S5.SS1.p2.3.m3.1.1.2">subscript</csymbol><ci id="S5.SS1.p2.3.m3.1.1.2.2.cmml" xref="S5.SS1.p2.3.m3.1.1.2.2">ℎ</ci><ci id="S5.SS1.p2.3.m3.1.1.2.3.cmml" xref="S5.SS1.p2.3.m3.1.1.2.3">𝑖</ci></apply><apply id="S5.SS1.p2.3.m3.1.1.3.cmml" xref="S5.SS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p2.3.m3.1.1.3.1.cmml" xref="S5.SS1.p2.3.m3.1.1.3">superscript</csymbol><ci id="S5.SS1.p2.3.m3.1.1.3.2.cmml" xref="S5.SS1.p2.3.m3.1.1.3.2">ℝ</ci><ci id="S5.SS1.p2.3.m3.1.1.3.3.cmml" xref="S5.SS1.p2.3.m3.1.1.3.3">𝐻</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">h_{i}\in\mathbb{R}^{H}</annotation></semantics></math> to its corresponding final hidden state from a pretrained language models (PLM), where <math id="S5.SS1.p2.4.m4.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S5.SS1.p2.4.m4.1a"><mi id="S5.SS1.p2.4.m4.1.1" xref="S5.SS1.p2.4.m4.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.4.m4.1b"><ci id="S5.SS1.p2.4.m4.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.4.m4.1c">H</annotation></semantics></math> is the hidden dimensionality. Following the conventional fine-tuning setup <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, we use <span id="S5.SS1.p2.5.1" class="ltx_text ltx_font_typewriter">[CLS]</span> as the first input token <math id="S5.SS1.p2.5.m5.1" class="ltx_Math" alttext="x_{0}" display="inline"><semantics id="S5.SS1.p2.5.m5.1a"><msub id="S5.SS1.p2.5.m5.1.1" xref="S5.SS1.p2.5.m5.1.1.cmml"><mi id="S5.SS1.p2.5.m5.1.1.2" xref="S5.SS1.p2.5.m5.1.1.2.cmml">x</mi><mn id="S5.SS1.p2.5.m5.1.1.3" xref="S5.SS1.p2.5.m5.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.5.m5.1b"><apply id="S5.SS1.p2.5.m5.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.5.m5.1.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.p2.5.m5.1.1.2.cmml" xref="S5.SS1.p2.5.m5.1.1.2">𝑥</ci><cn type="integer" id="S5.SS1.p2.5.m5.1.1.3.cmml" xref="S5.SS1.p2.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.5.m5.1c">x_{0}</annotation></semantics></math> and <span id="S5.SS1.p2.5.2" class="ltx_text ltx_font_typewriter">[SEP]</span> as a delimiter token to separate inputs (e.g., two sentences in STS and NLI, a passage and a question in the case of MRC, and dialogue turns for DST.)</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Single Sentence Classification</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.3" class="ltx_p">In the single sentence classification task, such as TC and RE, a classifier classifies a single sentence into a set of predefined labels. Following the convention, the last hidden state of <span id="S5.SS1.SSS1.p1.3.1" class="ltx_text ltx_font_typewriter">[CLS]</span> token <math id="S5.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="h_{0}" display="inline"><semantics id="S5.SS1.SSS1.p1.1.m1.1a"><msub id="S5.SS1.SSS1.p1.1.m1.1.1" xref="S5.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S5.SS1.SSS1.p1.1.m1.1.1.2" xref="S5.SS1.SSS1.p1.1.m1.1.1.2.cmml">h</mi><mn id="S5.SS1.SSS1.p1.1.m1.1.1.3" xref="S5.SS1.SSS1.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p1.1.m1.1b"><apply id="S5.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.SSS1.p1.1.m1.1.1.2">ℎ</ci><cn type="integer" id="S5.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S5.SS1.SSS1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p1.1.m1.1c">h_{0}</annotation></semantics></math> is linearly mapped to the number of labels (<math id="S5.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.SS1.SSS1.p1.2.m2.1a"><mi id="S5.SS1.SSS1.p1.2.m2.1.1" xref="S5.SS1.SSS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p1.2.m2.1b"><ci id="S5.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p1.2.m2.1c">K</annotation></semantics></math>) with <math id="S5.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="W\in\mathbb{R}^{K\times H}" display="inline"><semantics id="S5.SS1.SSS1.p1.3.m3.1a"><mrow id="S5.SS1.SSS1.p1.3.m3.1.1" xref="S5.SS1.SSS1.p1.3.m3.1.1.cmml"><mi id="S5.SS1.SSS1.p1.3.m3.1.1.2" xref="S5.SS1.SSS1.p1.3.m3.1.1.2.cmml">W</mi><mo id="S5.SS1.SSS1.p1.3.m3.1.1.1" xref="S5.SS1.SSS1.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S5.SS1.SSS1.p1.3.m3.1.1.3" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.cmml"><mi id="S5.SS1.SSS1.p1.3.m3.1.1.3.2" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S5.SS1.SSS1.p1.3.m3.1.1.3.3" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.cmml"><mi id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.2" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.2.cmml">K</mi><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.1" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.3" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.3.cmml">H</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p1.3.m3.1b"><apply id="S5.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1"><in id="S5.SS1.SSS1.p1.3.m3.1.1.1.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.1"></in><ci id="S5.SS1.SSS1.p1.3.m3.1.1.2.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.2">𝑊</ci><apply id="S5.SS1.SSS1.p1.3.m3.1.1.3.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS1.p1.3.m3.1.1.3.1.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S5.SS1.SSS1.p1.3.m3.1.1.3.2.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.2">ℝ</ci><apply id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3"><times id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.1.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.1"></times><ci id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.2.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.2">𝐾</ci><ci id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.3.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.3">𝐻</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p1.3.m3.1c">W\in\mathbb{R}^{K\times H}</annotation></semantics></math> and the entire model is trained to minimize the cross entropy loss.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para">
<p id="S5.SS1.SSS1.p2.1" class="ltx_p"><span id="S5.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_bold">YNAT</span> is a single sentence classification task where <math id="S5.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.SS1.SSS1.p2.1.m1.1a"><mi id="S5.SS1.SSS1.p2.1.m1.1.1" xref="S5.SS1.SSS1.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p2.1.m1.1b"><ci id="S5.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p2.1.m1.1c">K</annotation></semantics></math> is 7 for predefined topic labels, and does not require any special treatment of each input. <span id="S5.SS1.SSS1.p2.1.2" class="ltx_text ltx_font_bold">KLUE-RE</span> on the other hand requires a special procedure to indicate entities within the input sentence.
We use <span id="S5.SS1.SSS1.p2.1.3" class="ltx_text ltx_font_typewriter">&lt;subj&gt;</span>, <span id="S5.SS1.SSS1.p2.1.4" class="ltx_text ltx_font_typewriter">&lt;/subj&gt;</span>, <span id="S5.SS1.SSS1.p2.1.5" class="ltx_text ltx_font_typewriter">&lt;obj&gt;</span>, and <span id="S5.SS1.SSS1.p2.1.6" class="ltx_text ltx_font_typewriter">&lt;/obj&gt;</span> to mark the beginnings and the ends of subject and object entities, respectively, following <cite class="ltx_cite ltx_citemacro_citet">Baldini&nbsp;Soares et&nbsp;al. [<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. We expand the embedding matrix to add these four extra tokens.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Sentence Pair Classification / Regression</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">In the sentence pair classification / regression task, a model is asked to determine the relationship between two sentences. A pair of input sentences are concatenated with a special separator token, often <span id="S5.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_typewriter">[SEP]</span>, in-between.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p id="S5.SS1.SSS2.p2.1" class="ltx_p">In <span id="S5.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_bold">KLUE-STS</span>, each sentence pair is annotated with a real-valued similarity <math id="S5.SS1.SSS2.p2.1.m1.2" class="ltx_Math" alttext="[0,5]" display="inline"><semantics id="S5.SS1.SSS2.p2.1.m1.2a"><mrow id="S5.SS1.SSS2.p2.1.m1.2.3.2" xref="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S5.SS1.SSS2.p2.1.m1.2.3.2.1" xref="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml">[</mo><mn id="S5.SS1.SSS2.p2.1.m1.1.1" xref="S5.SS1.SSS2.p2.1.m1.1.1.cmml">0</mn><mo id="S5.SS1.SSS2.p2.1.m1.2.3.2.2" xref="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml">,</mo><mn id="S5.SS1.SSS2.p2.1.m1.2.2" xref="S5.SS1.SSS2.p2.1.m1.2.2.cmml">5</mn><mo stretchy="false" id="S5.SS1.SSS2.p2.1.m1.2.3.2.3" xref="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.1.m1.2b"><interval closure="closed" id="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.2.3.2"><cn type="integer" id="S5.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1">0</cn><cn type="integer" id="S5.SS1.SSS2.p2.1.m1.2.2.cmml" xref="S5.SS1.SSS2.p2.1.m1.2.2">5</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.1.m1.2c">[0,5]</annotation></semantics></math>. The model is thus trained to map from the final hidden state of <span id="S5.SS1.SSS2.p2.1.2" class="ltx_text ltx_font_typewriter">[CLS]</span> to a real number, by minimizing the mean squared error (MSE). In the case of <span id="S5.SS1.SSS2.p2.1.3" class="ltx_text ltx_font_bold">KLUE-NLI</span>, each sentence pair, consisting of a premise and hypothesis, is coupled with one of three classes. The model thus maps the hidden state of <span id="S5.SS1.SSS2.p2.1.4" class="ltx_text ltx_font_typewriter">[CLS]</span> token to a three-dimensional real-valued vectors and is trained to minimize the cross-entropy loss.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>Multiple-Sentence Slot-Value Prediction</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p"><span id="S5.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_bold">WoS</span> is a slot-value prediction task for a given dialogue context, where the prediction should be considered across multiple turns instead of a single utterance. We employ an encoder-decoder model following the architecture of TRADE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>, which consists of an utterance encoder, a state generator, and a slot gate classifier (Figure&nbsp;<a href="#S5.F8" title="Figure 8 ‣ 5.1.3 Multiple-Sentence Slot-Value Prediction ‣ 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>). In our implementation, we change the utterance encoder from GRU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> to PLM to get better representations. Thus, the state generator takes the final hidden state of <span id="S5.SS1.SSS3.p1.1.2" class="ltx_text ltx_font_typewriter">[CLS]</span> token <math id="S5.SS1.SSS3.p1.1.m1.1" class="ltx_Math" alttext="h_{0}" display="inline"><semantics id="S5.SS1.SSS3.p1.1.m1.1a"><msub id="S5.SS1.SSS3.p1.1.m1.1.1" xref="S5.SS1.SSS3.p1.1.m1.1.1.cmml"><mi id="S5.SS1.SSS3.p1.1.m1.1.1.2" xref="S5.SS1.SSS3.p1.1.m1.1.1.2.cmml">h</mi><mn id="S5.SS1.SSS3.p1.1.m1.1.1.3" xref="S5.SS1.SSS3.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.1.m1.1b"><apply id="S5.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.1.m1.1.1.2.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1.2">ℎ</ci><cn type="integer" id="S5.SS1.SSS3.p1.1.m1.1.1.3.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.1.m1.1c">h_{0}</annotation></semantics></math> as the first decoder hidden state. We also modify the slot gate classifier to predict additional two slot gate labels (<span id="S5.SS1.SSS3.p1.1.3" class="ltx_text ltx_font_italic">yes</span>, <span id="S5.SS1.SSS3.p1.1.4" class="ltx_text ltx_font_italic">no</span>), since WoS contains relatively more Boolean type slots than MultiWOZ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. We jointly minimize the cross-entropy loss of the state generator and slot gate classifier.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2105.09680/assets/figs/wos_model_arch.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="275" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>A baseline architecture for WoS based on TRADE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>.</figcaption>
</figure>
</section>
<section id="S5.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.4 </span>Sequence Tagging</h4>

<figure id="S5.F9" class="ltx_figure"><img src="/html/2105.09680/assets/figs/ner_input_example.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="62" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>An input and label example of KLUE-NER. We realign original character-level label sequence of Figure&nbsp;<a href="#S3.F3" title="Figure 3 ‣ Final Dataset ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for tokens from our Morpheme-based subword tokenization.</figcaption>
</figure>
<div id="S5.SS1.SSS4.p1" class="ltx_para">
<p id="S5.SS1.SSS4.p1.1" class="ltx_p"><span id="S5.SS1.SSS4.p1.1.1" class="ltx_text ltx_font_bold">KLUE-NER</span> is a token-level tagging task, where each character is assigned a label. This requires a care in using tokenization, as the labels from the characters within each subword token must be aggregated, and the predicted label of each subword token must be properly distributed across the characters within it. See Figure&nbsp;<a href="#S5.F9" title="Figure 9 ‣ 5.1.4 Sequence Tagging ‣ 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> for an example. We linearly map each of the final hidden states from the encoder <math id="S5.SS1.SSS4.p1.1.m1.1" class="ltx_Math" alttext="h\in\mathbb{R}^{|x|\times H}" display="inline"><semantics id="S5.SS1.SSS4.p1.1.m1.1a"><mrow id="S5.SS1.SSS4.p1.1.m1.1.2" xref="S5.SS1.SSS4.p1.1.m1.1.2.cmml"><mi id="S5.SS1.SSS4.p1.1.m1.1.2.2" xref="S5.SS1.SSS4.p1.1.m1.1.2.2.cmml">h</mi><mo id="S5.SS1.SSS4.p1.1.m1.1.2.1" xref="S5.SS1.SSS4.p1.1.m1.1.2.1.cmml">∈</mo><msup id="S5.SS1.SSS4.p1.1.m1.1.2.3" xref="S5.SS1.SSS4.p1.1.m1.1.2.3.cmml"><mi id="S5.SS1.SSS4.p1.1.m1.1.2.3.2" xref="S5.SS1.SSS4.p1.1.m1.1.2.3.2.cmml">ℝ</mi><mrow id="S5.SS1.SSS4.p1.1.m1.1.1.1" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.cmml"><mrow id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.cmml"><mo stretchy="false" id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2.1" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.1.cmml">|</mo><mi id="S5.SS1.SSS4.p1.1.m1.1.1.1.1" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.1.cmml">x</mi><mo rspace="0.055em" stretchy="false" id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2.2" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.1.cmml">|</mo></mrow><mo rspace="0.222em" id="S5.SS1.SSS4.p1.1.m1.1.1.1.2" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.2.cmml">×</mo><mi id="S5.SS1.SSS4.p1.1.m1.1.1.1.4" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.4.cmml">H</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p1.1.m1.1b"><apply id="S5.SS1.SSS4.p1.1.m1.1.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2"><in id="S5.SS1.SSS4.p1.1.m1.1.2.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.1"></in><ci id="S5.SS1.SSS4.p1.1.m1.1.2.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.2">ℎ</ci><apply id="S5.SS1.SSS4.p1.1.m1.1.2.3.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.3"><csymbol cd="ambiguous" id="S5.SS1.SSS4.p1.1.m1.1.2.3.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.3">superscript</csymbol><ci id="S5.SS1.SSS4.p1.1.m1.1.2.3.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.3.2">ℝ</ci><apply id="S5.SS1.SSS4.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1"><times id="S5.SS1.SSS4.p1.1.m1.1.1.1.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.2"></times><apply id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2"><abs id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2.1"></abs><ci id="S5.SS1.SSS4.p1.1.m1.1.1.1.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.1">𝑥</ci></apply><ci id="S5.SS1.SSS4.p1.1.m1.1.1.1.4.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.4">𝐻</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p1.1.m1.1c">h\in\mathbb{R}^{|x|\times H}</annotation></semantics></math> into a 12-dimensional real-valued vectors, corresponding to the 12 named-entity categories. We then minimize the cross-entropy loss summed over all the tokens.</p>
</div>
<div id="S5.SS1.SSS4.p2" class="ltx_para">
<p id="S5.SS1.SSS4.p2.1" class="ltx_p"><span id="S5.SS1.SSS4.p2.1.1" class="ltx_text ltx_font_bold">KLUE-MRC</span> is a span prediction task in which a model tags the beginning and end tokens of the answer span within a passage, given a question. The input to the model is the concatenation of a tokenized passage and an associated question (separated by <span id="S5.SS1.SSS4.p2.1.2" class="ltx_text ltx_font_typewriter">[SEP]</span>). The final hidden state of each token in the passage is linearly projected to a 2-dimensional real-valued vector. The dimensions in this vector correspond to the logits of two binary classifiers, the start and end token classifiers. The special token <span id="S5.SS1.SSS4.p2.1.3" class="ltx_text ltx_font_typewriter">[CLS]</span> is considered as both the correct start and end tokens, when given question is unanswerable. We minimize the cross-entropy loss to train the model.</p>
</div>
<div id="S5.SS1.SSS4.p3" class="ltx_para">
<p id="S5.SS1.SSS4.p3.1" class="ltx_p">We frame <span id="S5.SS1.SSS4.p3.1.1" class="ltx_text ltx_font_bold">KLUE-DP</span> as a sequence tagging problem. Each token within an input sentence is tagged twice, once with its head token and the other with the type of the arc connecting the head and the current token. Our baseline architecture follows the model proposed by <cite class="ltx_cite ltx_citemacro_citet">Fernández-González and
Gómez-Rodríguez [<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, except word representation and attention mechanisms. Similarly to KLUE-NER, we must be careful in handling subword tokens, as the annotation is done at the word level. In our approach, we use a pretrained language model (to be fine-tuned) to extract subword representations and concatenate the first and last subword token representations of each word, to form word vector representations. Each of these word representations is optionally concatenated with the part-of-speech embedding. For the attention layers, we use biaffine attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> to predict HEAD, and bilinear attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> to predict arc type (DEPREL) for each word. Just like KLUE-NER and KLUE-MRC, we minimize the cross-entropy loss to fine-tune the entire model. See Figure&nbsp;<a href="#S5.F10" title="Figure 10 ‣ 5.1.4 Sequence Tagging ‣ 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> for a graphical illustration of the model architecture.</p>
</div>
<figure id="S5.F10" class="ltx_figure"><img src="/html/2105.09680/assets/figs/dp_model_fig1.png" id="S5.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="306" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>An overview of KLUE-DP baseline model architecture, which we take advantage of <cite class="ltx_cite ltx_citemacro_citet">Fernández-González and
Gómez-Rodríguez [<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</figcaption>
</figure>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Fine-Tuning Configurations</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.5" class="ltx_p">For all the experiments, we use <span id="S5.SS2.p1.5.1" class="ltx_text ltx_font_typewriter">Huggingface Transformers</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite> and <span id="S5.SS2.p1.5.2" class="ltx_text ltx_font_typewriter">PyTorch-Lightning</span>.<span id="footnote62" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">62</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">62</sup><span class="ltx_tag ltx_tag_note">62</span>
<a target="_blank" href="https://github.com/PyTorchLightning/pytorch-lightning" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/PyTorchLightning/pytorch-lightning</a>
</span></span></span>
We use AdamW optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite> with the learning rate selected from <math id="S5.SS2.p1.1.m1.4" class="ltx_Math" alttext="\{10^{-5},2\times 10^{-5},3\times 10^{-5},5\times 10^{-5}\}" display="inline"><semantics id="S5.SS2.p1.1.m1.4a"><mrow id="S5.SS2.p1.1.m1.4.4.4" xref="S5.SS2.p1.1.m1.4.4.5.cmml"><mo stretchy="false" id="S5.SS2.p1.1.m1.4.4.4.5" xref="S5.SS2.p1.1.m1.4.4.5.cmml">{</mo><msup id="S5.SS2.p1.1.m1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.1.1.2.cmml">10</mn><mrow id="S5.SS2.p1.1.m1.1.1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.1.1.3.cmml"><mo id="S5.SS2.p1.1.m1.1.1.1.1.3a" xref="S5.SS2.p1.1.m1.1.1.1.1.3.cmml">−</mo><mn id="S5.SS2.p1.1.m1.1.1.1.1.3.2" xref="S5.SS2.p1.1.m1.1.1.1.1.3.2.cmml">5</mn></mrow></msup><mo id="S5.SS2.p1.1.m1.4.4.4.6" xref="S5.SS2.p1.1.m1.4.4.5.cmml">,</mo><mrow id="S5.SS2.p1.1.m1.2.2.2.2" xref="S5.SS2.p1.1.m1.2.2.2.2.cmml"><mn id="S5.SS2.p1.1.m1.2.2.2.2.2" xref="S5.SS2.p1.1.m1.2.2.2.2.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.2.2.2.2.1" xref="S5.SS2.p1.1.m1.2.2.2.2.1.cmml">×</mo><msup id="S5.SS2.p1.1.m1.2.2.2.2.3" xref="S5.SS2.p1.1.m1.2.2.2.2.3.cmml"><mn id="S5.SS2.p1.1.m1.2.2.2.2.3.2" xref="S5.SS2.p1.1.m1.2.2.2.2.3.2.cmml">10</mn><mrow id="S5.SS2.p1.1.m1.2.2.2.2.3.3" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3.cmml"><mo id="S5.SS2.p1.1.m1.2.2.2.2.3.3a" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3.cmml">−</mo><mn id="S5.SS2.p1.1.m1.2.2.2.2.3.3.2" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3.2.cmml">5</mn></mrow></msup></mrow><mo id="S5.SS2.p1.1.m1.4.4.4.7" xref="S5.SS2.p1.1.m1.4.4.5.cmml">,</mo><mrow id="S5.SS2.p1.1.m1.3.3.3.3" xref="S5.SS2.p1.1.m1.3.3.3.3.cmml"><mn id="S5.SS2.p1.1.m1.3.3.3.3.2" xref="S5.SS2.p1.1.m1.3.3.3.3.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.3.3.3.3.1" xref="S5.SS2.p1.1.m1.3.3.3.3.1.cmml">×</mo><msup id="S5.SS2.p1.1.m1.3.3.3.3.3" xref="S5.SS2.p1.1.m1.3.3.3.3.3.cmml"><mn id="S5.SS2.p1.1.m1.3.3.3.3.3.2" xref="S5.SS2.p1.1.m1.3.3.3.3.3.2.cmml">10</mn><mrow id="S5.SS2.p1.1.m1.3.3.3.3.3.3" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3.cmml"><mo id="S5.SS2.p1.1.m1.3.3.3.3.3.3a" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3.cmml">−</mo><mn id="S5.SS2.p1.1.m1.3.3.3.3.3.3.2" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3.2.cmml">5</mn></mrow></msup></mrow><mo id="S5.SS2.p1.1.m1.4.4.4.8" xref="S5.SS2.p1.1.m1.4.4.5.cmml">,</mo><mrow id="S5.SS2.p1.1.m1.4.4.4.4" xref="S5.SS2.p1.1.m1.4.4.4.4.cmml"><mn id="S5.SS2.p1.1.m1.4.4.4.4.2" xref="S5.SS2.p1.1.m1.4.4.4.4.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.4.4.4.4.1" xref="S5.SS2.p1.1.m1.4.4.4.4.1.cmml">×</mo><msup id="S5.SS2.p1.1.m1.4.4.4.4.3" xref="S5.SS2.p1.1.m1.4.4.4.4.3.cmml"><mn id="S5.SS2.p1.1.m1.4.4.4.4.3.2" xref="S5.SS2.p1.1.m1.4.4.4.4.3.2.cmml">10</mn><mrow id="S5.SS2.p1.1.m1.4.4.4.4.3.3" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3.cmml"><mo id="S5.SS2.p1.1.m1.4.4.4.4.3.3a" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3.cmml">−</mo><mn id="S5.SS2.p1.1.m1.4.4.4.4.3.3.2" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3.2.cmml">5</mn></mrow></msup></mrow><mo stretchy="false" id="S5.SS2.p1.1.m1.4.4.4.9" xref="S5.SS2.p1.1.m1.4.4.5.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.4b"><set id="S5.SS2.p1.1.m1.4.4.5.cmml" xref="S5.SS2.p1.1.m1.4.4.4"><apply id="S5.SS2.p1.1.m1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.2">10</cn><apply id="S5.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3"><minus id="S5.SS2.p1.1.m1.1.1.1.1.3.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3"></minus><cn type="integer" id="S5.SS2.p1.1.m1.1.1.1.1.3.2.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3.2">5</cn></apply></apply><apply id="S5.SS2.p1.1.m1.2.2.2.2.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2"><times id="S5.SS2.p1.1.m1.2.2.2.2.1.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.2">2</cn><apply id="S5.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.2.2.2.2.3.1.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3">superscript</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.2.2.2.2.3.2.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3.2">10</cn><apply id="S5.SS2.p1.1.m1.2.2.2.2.3.3.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3"><minus id="S5.SS2.p1.1.m1.2.2.2.2.3.3.1.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3"></minus><cn type="integer" id="S5.SS2.p1.1.m1.2.2.2.2.3.3.2.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3.2">5</cn></apply></apply></apply><apply id="S5.SS2.p1.1.m1.3.3.3.3.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3"><times id="S5.SS2.p1.1.m1.3.3.3.3.1.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.3.3.3.3.2.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.2">3</cn><apply id="S5.SS2.p1.1.m1.3.3.3.3.3.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.3.3.3.3.3.1.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3">superscript</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.3.3.3.3.3.2.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3.2">10</cn><apply id="S5.SS2.p1.1.m1.3.3.3.3.3.3.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3"><minus id="S5.SS2.p1.1.m1.3.3.3.3.3.3.1.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3"></minus><cn type="integer" id="S5.SS2.p1.1.m1.3.3.3.3.3.3.2.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3.2">5</cn></apply></apply></apply><apply id="S5.SS2.p1.1.m1.4.4.4.4.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4"><times id="S5.SS2.p1.1.m1.4.4.4.4.1.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.4.4.4.4.2.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.2">5</cn><apply id="S5.SS2.p1.1.m1.4.4.4.4.3.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.4.4.4.4.3.1.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3">superscript</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.4.4.4.4.3.2.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3.2">10</cn><apply id="S5.SS2.p1.1.m1.4.4.4.4.3.3.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3"><minus id="S5.SS2.p1.1.m1.4.4.4.4.3.3.1.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3"></minus><cn type="integer" id="S5.SS2.p1.1.m1.4.4.4.4.3.3.2.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3.2">5</cn></apply></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.4c">\{10^{-5},2\times 10^{-5},3\times 10^{-5},5\times 10^{-5}\}</annotation></semantics></math>, the warm-up ratio from <math id="S5.SS2.p1.2.m2.1" class="ltx_math_unparsed" alttext="\{0.,0.1,0.2,0.6\}" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mrow id="S5.SS2.p1.2.m2.1b"><mo stretchy="false" id="S5.SS2.p1.2.m2.1.1">{</mo><mn id="S5.SS2.p1.2.m2.1.2">0</mn><mo lspace="0em" rspace="0.167em" id="S5.SS2.p1.2.m2.1.3">.</mo><mo id="S5.SS2.p1.2.m2.1.4">,</mo><mn id="S5.SS2.p1.2.m2.1.5">0.1</mn><mo id="S5.SS2.p1.2.m2.1.6">,</mo><mn id="S5.SS2.p1.2.m2.1.7">0.2</mn><mo id="S5.SS2.p1.2.m2.1.8">,</mo><mn id="S5.SS2.p1.2.m2.1.9">0.6</mn><mo stretchy="false" id="S5.SS2.p1.2.m2.1.10">}</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">\{0.,0.1,0.2,0.6\}</annotation></semantics></math> and the weight decay coefficient from <math id="S5.SS2.p1.3.m3.2" class="ltx_Math" alttext="\{0.0,0.01\}" display="inline"><semantics id="S5.SS2.p1.3.m3.2a"><mrow id="S5.SS2.p1.3.m3.2.3.2" xref="S5.SS2.p1.3.m3.2.3.1.cmml"><mo stretchy="false" id="S5.SS2.p1.3.m3.2.3.2.1" xref="S5.SS2.p1.3.m3.2.3.1.cmml">{</mo><mn id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">0.0</mn><mo id="S5.SS2.p1.3.m3.2.3.2.2" xref="S5.SS2.p1.3.m3.2.3.1.cmml">,</mo><mn id="S5.SS2.p1.3.m3.2.2" xref="S5.SS2.p1.3.m3.2.2.cmml">0.01</mn><mo stretchy="false" id="S5.SS2.p1.3.m3.2.3.2.3" xref="S5.SS2.p1.3.m3.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.2b"><set id="S5.SS2.p1.3.m3.2.3.1.cmml" xref="S5.SS2.p1.3.m3.2.3.2"><cn type="float" id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">0.0</cn><cn type="float" id="S5.SS2.p1.3.m3.2.2.cmml" xref="S5.SS2.p1.3.m3.2.2">0.01</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.2c">\{0.0,0.01\}</annotation></semantics></math>. We choose the batch size from <math id="S5.SS2.p1.4.m4.3" class="ltx_Math" alttext="\{8,16,32\}" display="inline"><semantics id="S5.SS2.p1.4.m4.3a"><mrow id="S5.SS2.p1.4.m4.3.4.2" xref="S5.SS2.p1.4.m4.3.4.1.cmml"><mo stretchy="false" id="S5.SS2.p1.4.m4.3.4.2.1" xref="S5.SS2.p1.4.m4.3.4.1.cmml">{</mo><mn id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml">8</mn><mo id="S5.SS2.p1.4.m4.3.4.2.2" xref="S5.SS2.p1.4.m4.3.4.1.cmml">,</mo><mn id="S5.SS2.p1.4.m4.2.2" xref="S5.SS2.p1.4.m4.2.2.cmml">16</mn><mo id="S5.SS2.p1.4.m4.3.4.2.3" xref="S5.SS2.p1.4.m4.3.4.1.cmml">,</mo><mn id="S5.SS2.p1.4.m4.3.3" xref="S5.SS2.p1.4.m4.3.3.cmml">32</mn><mo stretchy="false" id="S5.SS2.p1.4.m4.3.4.2.4" xref="S5.SS2.p1.4.m4.3.4.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.3b"><set id="S5.SS2.p1.4.m4.3.4.1.cmml" xref="S5.SS2.p1.4.m4.3.4.2"><cn type="integer" id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">8</cn><cn type="integer" id="S5.SS2.p1.4.m4.2.2.cmml" xref="S5.SS2.p1.4.m4.2.2">16</cn><cn type="integer" id="S5.SS2.p1.4.m4.3.3.cmml" xref="S5.SS2.p1.4.m4.3.3">32</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.3c">\{8,16,32\}</annotation></semantics></math> and the number of epochs from <math id="S5.SS2.p1.5.m5.4" class="ltx_Math" alttext="\{3,4,5,10\}" display="inline"><semantics id="S5.SS2.p1.5.m5.4a"><mrow id="S5.SS2.p1.5.m5.4.5.2" xref="S5.SS2.p1.5.m5.4.5.1.cmml"><mo stretchy="false" id="S5.SS2.p1.5.m5.4.5.2.1" xref="S5.SS2.p1.5.m5.4.5.1.cmml">{</mo><mn id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml">3</mn><mo id="S5.SS2.p1.5.m5.4.5.2.2" xref="S5.SS2.p1.5.m5.4.5.1.cmml">,</mo><mn id="S5.SS2.p1.5.m5.2.2" xref="S5.SS2.p1.5.m5.2.2.cmml">4</mn><mo id="S5.SS2.p1.5.m5.4.5.2.3" xref="S5.SS2.p1.5.m5.4.5.1.cmml">,</mo><mn id="S5.SS2.p1.5.m5.3.3" xref="S5.SS2.p1.5.m5.3.3.cmml">5</mn><mo id="S5.SS2.p1.5.m5.4.5.2.4" xref="S5.SS2.p1.5.m5.4.5.1.cmml">,</mo><mn id="S5.SS2.p1.5.m5.4.4" xref="S5.SS2.p1.5.m5.4.4.cmml">10</mn><mo stretchy="false" id="S5.SS2.p1.5.m5.4.5.2.5" xref="S5.SS2.p1.5.m5.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.4b"><set id="S5.SS2.p1.5.m5.4.5.1.cmml" xref="S5.SS2.p1.5.m5.4.5.2"><cn type="integer" id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">3</cn><cn type="integer" id="S5.SS2.p1.5.m5.2.2.cmml" xref="S5.SS2.p1.5.m5.2.2">4</cn><cn type="integer" id="S5.SS2.p1.5.m5.3.3.cmml" xref="S5.SS2.p1.5.m5.3.3">5</cn><cn type="integer" id="S5.SS2.p1.5.m5.4.4.cmml" xref="S5.SS2.p1.5.m5.4.4">10</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.4c">\{3,4,5,10\}</annotation></semantics></math>. We use the maximum sequence length of 512 for KLUE-MRC and WoS, and 128 for all the other tasks. We report the score obtained from the best hyperparameter configuration based on the dev set performance.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Evaluation Results</h3>

<figure id="S5.T32" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 32: </span>Evaluation results of our pretrained LMs and other baselines on KLUE benchmark. The F1 refers to a macro-F1 score. The F1<sup id="S5.T32.34.1" class="ltx_sup"><span id="S5.T32.34.1.1" class="ltx_text ltx_font_italic">E</span></sup> and F1<sup id="S5.T32.35.2" class="ltx_sup"><span id="S5.T32.35.2.1" class="ltx_text ltx_font_italic">C</span></sup> of KLUE-NER indicates entity-level and character-level macro-F1 score, respectively. The F1<sup id="S5.T32.36.3" class="ltx_sup"><span id="S5.T32.36.3.1" class="ltx_text ltx_font_italic">mic</span></sup> of KLUE-RE is micro-averaged F1 score ignoring the <span id="S5.T32.37.4" class="ltx_text ltx_font_italic">no_relation</span>. The F1<sup id="S5.T32.38.5" class="ltx_sup"><span id="S5.T32.38.5.1" class="ltx_text ltx_font_italic">S</span></sup> of WoS is an average of slot-value pair level micro-F1 scores. The R<sup id="S5.T32.39.6" class="ltx_sup"><span id="S5.T32.39.6.1" class="ltx_text ltx_font_italic">P</span></sup> of KLUE-STS denotes Pearson correlation. <span id="S5.T32.40.7" class="ltx_text ltx_font_bold">Bold</span> shows the best performance across the models, and <span id="S5.T32.41.8" class="ltx_text ltx_framed ltx_framed_underline">underline</span> indicates the best performance among <span id="S5.T32.42.9" class="ltx_text ltx_font_typewriter">BASE</span> models.</figcaption>
<div id="S5.T32.24" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:641.2pt;height:199pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T32.24.14" class="ltx_p"><span id="S5.T32.24.14.14" class="ltx_text">
<span id="S5.T32.24.14.14.14" class="ltx_tabular ltx_align_middle">
<span id="S5.T32.24.14.14.14.15" class="ltx_tr">
<span id="S5.T32.24.14.14.14.15.1" class="ltx_td ltx_border_tt"></span>
<span id="S5.T32.24.14.14.14.15.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T32.24.14.14.14.15.2.1" class="ltx_text ltx_font_bold">YNAT</span></span>
<span id="S5.T32.24.14.14.14.15.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.3.1" class="ltx_text ltx_font_bold">KLUE-STS</span></span>
<span id="S5.T32.24.14.14.14.15.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T32.24.14.14.14.15.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></span>
<span id="S5.T32.24.14.14.14.15.5" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.5.1" class="ltx_text ltx_font_bold">KLUE-NER</span></span>
<span id="S5.T32.24.14.14.14.15.6" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.6.1" class="ltx_text ltx_font_bold">KLUE-RE</span></span>
<span id="S5.T32.24.14.14.14.15.7" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.7.1" class="ltx_text ltx_font_bold">KLUE-DP</span></span>
<span id="S5.T32.24.14.14.14.15.8" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.8.1" class="ltx_text ltx_font_bold">KLUE-MRC</span></span>
<span id="S5.T32.24.14.14.14.15.9" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.9.1" class="ltx_text ltx_font_bold">WoS</span></span></span>
<span id="S5.T32.15.5.5.5.5" class="ltx_tr">
<span id="S5.T32.15.5.5.5.5.6" class="ltx_td ltx_align_left"><span id="S5.T32.15.5.5.5.5.6.1" class="ltx_text ltx_font_bold">Model</span></span>
<span id="S5.T32.15.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">F1</span>
<span id="S5.T32.11.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">R<sup id="S5.T32.11.1.1.1.1.1.1" class="ltx_sup"><span id="S5.T32.11.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">P</span></sup></span>
<span id="S5.T32.15.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">F1</span>
<span id="S5.T32.15.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t">ACC</span>
<span id="S5.T32.12.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T32.12.2.2.2.2.2.1" class="ltx_sup"><span id="S5.T32.12.2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">E</span></sup></span>
<span id="S5.T32.13.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T32.13.3.3.3.3.3.1" class="ltx_sup"><span id="S5.T32.13.3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">C</span></sup></span>
<span id="S5.T32.14.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T32.14.4.4.4.4.4.1" class="ltx_sup"><span id="S5.T32.14.4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">mic</span></sup></span>
<span id="S5.T32.15.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_t">AUC</span>
<span id="S5.T32.15.5.5.5.5.11" class="ltx_td ltx_align_center ltx_border_t">UAS</span>
<span id="S5.T32.15.5.5.5.5.12" class="ltx_td ltx_align_center ltx_border_t">LAS</span>
<span id="S5.T32.15.5.5.5.5.13" class="ltx_td ltx_align_center ltx_border_t">EM</span>
<span id="S5.T32.15.5.5.5.5.14" class="ltx_td ltx_align_center ltx_border_t">ROUGE</span>
<span id="S5.T32.15.5.5.5.5.15" class="ltx_td ltx_align_center ltx_border_t">JGA</span>
<span id="S5.T32.15.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T32.15.5.5.5.5.5.1" class="ltx_sup"><span id="S5.T32.15.5.5.5.5.5.1.1" class="ltx_text ltx_font_italic">S</span></sup></span></span>
<span id="S5.T32.16.6.6.6.6" class="ltx_tr">
<span id="S5.T32.16.6.6.6.6.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S5.T32.16.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\text{mBERT}_{\text{BASE}}" display="inline"><semantics id="S5.T32.16.6.6.6.6.1.m1.1a"><msub id="S5.T32.16.6.6.6.6.1.m1.1.1" xref="S5.T32.16.6.6.6.6.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.16.6.6.6.6.1.m1.1.1.2" xref="S5.T32.16.6.6.6.6.1.m1.1.1.2a.cmml">mBERT</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.16.6.6.6.6.1.m1.1.1.3" xref="S5.T32.16.6.6.6.6.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.16.6.6.6.6.1.m1.1b"><apply id="S5.T32.16.6.6.6.6.1.m1.1.1.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.16.6.6.6.6.1.m1.1.1.1.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1">subscript</csymbol><ci id="S5.T32.16.6.6.6.6.1.m1.1.1.2a.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.16.6.6.6.6.1.m1.1.1.2.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1.2">mBERT</mtext></ci><ci id="S5.T32.16.6.6.6.6.1.m1.1.1.3a.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.16.6.6.6.6.1.m1.1.1.3.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.16.6.6.6.6.1.m1.1c">\text{mBERT}_{\text{BASE}}</annotation></semantics></math></span>
<span id="S5.T32.16.6.6.6.6.2" class="ltx_td ltx_align_center ltx_border_t">81.55</span>
<span id="S5.T32.16.6.6.6.6.3" class="ltx_td ltx_align_center ltx_border_t">84.66</span>
<span id="S5.T32.16.6.6.6.6.4" class="ltx_td ltx_align_center ltx_border_t">76.00</span>
<span id="S5.T32.16.6.6.6.6.5" class="ltx_td ltx_align_center ltx_border_t">73.20</span>
<span id="S5.T32.16.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t">76.50</span>
<span id="S5.T32.16.6.6.6.6.7" class="ltx_td ltx_align_center ltx_border_t">89.23</span>
<span id="S5.T32.16.6.6.6.6.8" class="ltx_td ltx_align_center ltx_border_t">57.88</span>
<span id="S5.T32.16.6.6.6.6.9" class="ltx_td ltx_align_center ltx_border_t">53.82</span>
<span id="S5.T32.16.6.6.6.6.10" class="ltx_td ltx_align_center ltx_border_t">90.30</span>
<span id="S5.T32.16.6.6.6.6.11" class="ltx_td ltx_align_center ltx_border_t">86.66</span>
<span id="S5.T32.16.6.6.6.6.12" class="ltx_td ltx_align_center ltx_border_t">44.66</span>
<span id="S5.T32.16.6.6.6.6.13" class="ltx_td ltx_align_center ltx_border_t">55.92</span>
<span id="S5.T32.16.6.6.6.6.14" class="ltx_td ltx_align_center ltx_border_t">35.46</span>
<span id="S5.T32.16.6.6.6.6.15" class="ltx_td ltx_align_center ltx_border_t">88.63</span></span>
<span id="S5.T32.17.7.7.7.7" class="ltx_tr">
<span id="S5.T32.17.7.7.7.7.1" class="ltx_td ltx_align_left"><math id="S5.T32.17.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\text{XLM-R}_{\text{BASE}}" display="inline"><semantics id="S5.T32.17.7.7.7.7.1.m1.1a"><msub id="S5.T32.17.7.7.7.7.1.m1.1.1" xref="S5.T32.17.7.7.7.7.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.17.7.7.7.7.1.m1.1.1.2" xref="S5.T32.17.7.7.7.7.1.m1.1.1.2a.cmml">XLM-R</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.17.7.7.7.7.1.m1.1.1.3" xref="S5.T32.17.7.7.7.7.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.17.7.7.7.7.1.m1.1b"><apply id="S5.T32.17.7.7.7.7.1.m1.1.1.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.17.7.7.7.7.1.m1.1.1.1.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1">subscript</csymbol><ci id="S5.T32.17.7.7.7.7.1.m1.1.1.2a.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.17.7.7.7.7.1.m1.1.1.2.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1.2">XLM-R</mtext></ci><ci id="S5.T32.17.7.7.7.7.1.m1.1.1.3a.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.17.7.7.7.7.1.m1.1.1.3.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.17.7.7.7.7.1.m1.1c">\text{XLM-R}_{\text{BASE}}</annotation></semantics></math></span>
<span id="S5.T32.17.7.7.7.7.2" class="ltx_td ltx_align_center">83.52</span>
<span id="S5.T32.17.7.7.7.7.3" class="ltx_td ltx_align_center">89.16</span>
<span id="S5.T32.17.7.7.7.7.4" class="ltx_td ltx_align_center">82.01</span>
<span id="S5.T32.17.7.7.7.7.5" class="ltx_td ltx_align_center">77.33</span>
<span id="S5.T32.17.7.7.7.7.6" class="ltx_td ltx_align_center">80.37</span>
<span id="S5.T32.17.7.7.7.7.7" class="ltx_td ltx_align_center">92.12</span>
<span id="S5.T32.17.7.7.7.7.8" class="ltx_td ltx_align_center">57.46</span>
<span id="S5.T32.17.7.7.7.7.9" class="ltx_td ltx_align_center">54.98</span>
<span id="S5.T32.17.7.7.7.7.10" class="ltx_td ltx_align_center">89.20</span>
<span id="S5.T32.17.7.7.7.7.11" class="ltx_td ltx_align_center">87.69</span>
<span id="S5.T32.17.7.7.7.7.12" class="ltx_td ltx_align_center">27.48</span>
<span id="S5.T32.17.7.7.7.7.13" class="ltx_td ltx_align_center">53.93</span>
<span id="S5.T32.17.7.7.7.7.14" class="ltx_td ltx_align_center">39.82</span>
<span id="S5.T32.17.7.7.7.7.15" class="ltx_td ltx_align_center">89.61</span></span>
<span id="S5.T32.18.8.8.8.8" class="ltx_tr">
<span id="S5.T32.18.8.8.8.8.1" class="ltx_td ltx_align_left"><math id="S5.T32.18.8.8.8.8.1.m1.1" class="ltx_Math" alttext="\text{XLM-R}_{\text{LARGE}}" display="inline"><semantics id="S5.T32.18.8.8.8.8.1.m1.1a"><msub id="S5.T32.18.8.8.8.8.1.m1.1.1" xref="S5.T32.18.8.8.8.8.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.18.8.8.8.8.1.m1.1.1.2" xref="S5.T32.18.8.8.8.8.1.m1.1.1.2a.cmml">XLM-R</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.18.8.8.8.8.1.m1.1.1.3" xref="S5.T32.18.8.8.8.8.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.18.8.8.8.8.1.m1.1b"><apply id="S5.T32.18.8.8.8.8.1.m1.1.1.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.18.8.8.8.8.1.m1.1.1.1.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1">subscript</csymbol><ci id="S5.T32.18.8.8.8.8.1.m1.1.1.2a.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.18.8.8.8.8.1.m1.1.1.2.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1.2">XLM-R</mtext></ci><ci id="S5.T32.18.8.8.8.8.1.m1.1.1.3a.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.18.8.8.8.8.1.m1.1.1.3.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.18.8.8.8.8.1.m1.1c">\text{XLM-R}_{\text{LARGE}}</annotation></semantics></math></span>
<span id="S5.T32.18.8.8.8.8.2" class="ltx_td ltx_align_center"><span id="S5.T32.18.8.8.8.8.2.1" class="ltx_text ltx_font_bold">86.06</span></span>
<span id="S5.T32.18.8.8.8.8.3" class="ltx_td ltx_align_center">92.97</span>
<span id="S5.T32.18.8.8.8.8.4" class="ltx_td ltx_align_center">85.86</span>
<span id="S5.T32.18.8.8.8.8.5" class="ltx_td ltx_align_center">85.93</span>
<span id="S5.T32.18.8.8.8.8.6" class="ltx_td ltx_align_center">82.27</span>
<span id="S5.T32.18.8.8.8.8.7" class="ltx_td ltx_align_center"><span id="S5.T32.18.8.8.8.8.7.1" class="ltx_text ltx_font_bold">93.22</span></span>
<span id="S5.T32.18.8.8.8.8.8" class="ltx_td ltx_align_center">58.39</span>
<span id="S5.T32.18.8.8.8.8.9" class="ltx_td ltx_align_center">61.15</span>
<span id="S5.T32.18.8.8.8.8.10" class="ltx_td ltx_align_center">92.71</span>
<span id="S5.T32.18.8.8.8.8.11" class="ltx_td ltx_align_center"><span id="S5.T32.18.8.8.8.8.11.1" class="ltx_text ltx_font_bold">88.70</span></span>
<span id="S5.T32.18.8.8.8.8.12" class="ltx_td ltx_align_center">35.99</span>
<span id="S5.T32.18.8.8.8.8.13" class="ltx_td ltx_align_center">66.77</span>
<span id="S5.T32.18.8.8.8.8.14" class="ltx_td ltx_align_center">41.20</span>
<span id="S5.T32.18.8.8.8.8.15" class="ltx_td ltx_align_center">89.80</span></span>
<span id="S5.T32.19.9.9.9.9" class="ltx_tr">
<span id="S5.T32.19.9.9.9.9.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S5.T32.19.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\text{KR-BERT}_{\text{BASE}}" display="inline"><semantics id="S5.T32.19.9.9.9.9.1.m1.1a"><msub id="S5.T32.19.9.9.9.9.1.m1.1.1" xref="S5.T32.19.9.9.9.9.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.19.9.9.9.9.1.m1.1.1.2" xref="S5.T32.19.9.9.9.9.1.m1.1.1.2a.cmml">KR-BERT</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.19.9.9.9.9.1.m1.1.1.3" xref="S5.T32.19.9.9.9.9.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.19.9.9.9.9.1.m1.1b"><apply id="S5.T32.19.9.9.9.9.1.m1.1.1.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.19.9.9.9.9.1.m1.1.1.1.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1">subscript</csymbol><ci id="S5.T32.19.9.9.9.9.1.m1.1.1.2a.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.19.9.9.9.9.1.m1.1.1.2.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1.2">KR-BERT</mtext></ci><ci id="S5.T32.19.9.9.9.9.1.m1.1.1.3a.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.19.9.9.9.9.1.m1.1.1.3.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.19.9.9.9.9.1.m1.1c">\text{KR-BERT}_{\text{BASE}}</annotation></semantics></math></span>
<span id="S5.T32.19.9.9.9.9.2" class="ltx_td ltx_align_center ltx_border_t">84.58</span>
<span id="S5.T32.19.9.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t">88.61</span>
<span id="S5.T32.19.9.9.9.9.4" class="ltx_td ltx_align_center ltx_border_t">81.07</span>
<span id="S5.T32.19.9.9.9.9.5" class="ltx_td ltx_align_center ltx_border_t">77.17</span>
<span id="S5.T32.19.9.9.9.9.6" class="ltx_td ltx_align_center ltx_border_t">74.58</span>
<span id="S5.T32.19.9.9.9.9.7" class="ltx_td ltx_align_center ltx_border_t">90.13</span>
<span id="S5.T32.19.9.9.9.9.8" class="ltx_td ltx_align_center ltx_border_t">62.74</span>
<span id="S5.T32.19.9.9.9.9.9" class="ltx_td ltx_align_center ltx_border_t">60.94</span>
<span id="S5.T32.19.9.9.9.9.10" class="ltx_td ltx_align_center ltx_border_t">89.92</span>
<span id="S5.T32.19.9.9.9.9.11" class="ltx_td ltx_align_center ltx_border_t">87.48</span>
<span id="S5.T32.19.9.9.9.9.12" class="ltx_td ltx_align_center ltx_border_t">48.28</span>
<span id="S5.T32.19.9.9.9.9.13" class="ltx_td ltx_align_center ltx_border_t">58.54</span>
<span id="S5.T32.19.9.9.9.9.14" class="ltx_td ltx_align_center ltx_border_t">45.33</span>
<span id="S5.T32.19.9.9.9.9.15" class="ltx_td ltx_align_center ltx_border_t">90.70</span></span>
<span id="S5.T32.20.10.10.10.10" class="ltx_tr">
<span id="S5.T32.20.10.10.10.10.1" class="ltx_td ltx_align_left"><math id="S5.T32.20.10.10.10.10.1.m1.1" class="ltx_Math" alttext="\text{KoELECTRA}_{\text{BASE}}" display="inline"><semantics id="S5.T32.20.10.10.10.10.1.m1.1a"><msub id="S5.T32.20.10.10.10.10.1.m1.1.1" xref="S5.T32.20.10.10.10.10.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.20.10.10.10.10.1.m1.1.1.2" xref="S5.T32.20.10.10.10.10.1.m1.1.1.2a.cmml">KoELECTRA</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.20.10.10.10.10.1.m1.1.1.3" xref="S5.T32.20.10.10.10.10.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.20.10.10.10.10.1.m1.1b"><apply id="S5.T32.20.10.10.10.10.1.m1.1.1.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.20.10.10.10.10.1.m1.1.1.1.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1">subscript</csymbol><ci id="S5.T32.20.10.10.10.10.1.m1.1.1.2a.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.20.10.10.10.10.1.m1.1.1.2.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1.2">KoELECTRA</mtext></ci><ci id="S5.T32.20.10.10.10.10.1.m1.1.1.3a.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.20.10.10.10.10.1.m1.1.1.3.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.20.10.10.10.10.1.m1.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math></span>
<span id="S5.T32.20.10.10.10.10.2" class="ltx_td ltx_align_center">84.59</span>
<span id="S5.T32.20.10.10.10.10.3" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.3.1" class="ltx_text ltx_framed ltx_framed_underline">92.46</span></span>
<span id="S5.T32.20.10.10.10.10.4" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.4.1" class="ltx_text ltx_framed ltx_framed_underline">84.84</span></span>
<span id="S5.T32.20.10.10.10.10.5" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.5.1" class="ltx_text ltx_framed ltx_framed_underline">85.63</span></span>
<span id="S5.T32.20.10.10.10.10.6" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">86.11</span></span>
<span id="S5.T32.20.10.10.10.10.7" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.7.1" class="ltx_text ltx_framed ltx_framed_underline">92.56</span></span>
<span id="S5.T32.20.10.10.10.10.8" class="ltx_td ltx_align_center">62.85</span>
<span id="S5.T32.20.10.10.10.10.9" class="ltx_td ltx_align_center">58.94</span>
<span id="S5.T32.20.10.10.10.10.10" class="ltx_td ltx_align_center">92.90</span>
<span id="S5.T32.20.10.10.10.10.11" class="ltx_td ltx_align_center">87.77</span>
<span id="S5.T32.20.10.10.10.10.12" class="ltx_td ltx_align_center">59.82</span>
<span id="S5.T32.20.10.10.10.10.13" class="ltx_td ltx_align_center">66.05</span>
<span id="S5.T32.20.10.10.10.10.14" class="ltx_td ltx_align_center">41.58</span>
<span id="S5.T32.20.10.10.10.10.15" class="ltx_td ltx_align_center">89.60</span></span>
<span id="S5.T32.21.11.11.11.11" class="ltx_tr">
<span id="S5.T32.21.11.11.11.11.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S5.T32.21.11.11.11.11.1.m1.1" class="ltx_Math" alttext="\text{KLUE-BERT}_{\text{BASE}}" display="inline"><semantics id="S5.T32.21.11.11.11.11.1.m1.1a"><msub id="S5.T32.21.11.11.11.11.1.m1.1.1" xref="S5.T32.21.11.11.11.11.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.21.11.11.11.11.1.m1.1.1.2" xref="S5.T32.21.11.11.11.11.1.m1.1.1.2a.cmml">KLUE-BERT</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.21.11.11.11.11.1.m1.1.1.3" xref="S5.T32.21.11.11.11.11.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.21.11.11.11.11.1.m1.1b"><apply id="S5.T32.21.11.11.11.11.1.m1.1.1.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.21.11.11.11.11.1.m1.1.1.1.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1">subscript</csymbol><ci id="S5.T32.21.11.11.11.11.1.m1.1.1.2a.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.21.11.11.11.11.1.m1.1.1.2.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1.2">KLUE-BERT</mtext></ci><ci id="S5.T32.21.11.11.11.11.1.m1.1.1.3a.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.21.11.11.11.11.1.m1.1.1.3.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.21.11.11.11.11.1.m1.1c">\text{KLUE-BERT}_{\text{BASE}}</annotation></semantics></math></span>
<span id="S5.T32.21.11.11.11.11.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T32.21.11.11.11.11.2.1" class="ltx_text ltx_framed ltx_framed_underline">85.73</span></span>
<span id="S5.T32.21.11.11.11.11.3" class="ltx_td ltx_align_center ltx_border_t">90.85</span>
<span id="S5.T32.21.11.11.11.11.4" class="ltx_td ltx_align_center ltx_border_t">82.84</span>
<span id="S5.T32.21.11.11.11.11.5" class="ltx_td ltx_align_center ltx_border_t">81.63</span>
<span id="S5.T32.21.11.11.11.11.6" class="ltx_td ltx_align_center ltx_border_t">83.97</span>
<span id="S5.T32.21.11.11.11.11.7" class="ltx_td ltx_align_center ltx_border_t">91.39</span>
<span id="S5.T32.21.11.11.11.11.8" class="ltx_td ltx_align_center ltx_border_t">66.44</span>
<span id="S5.T32.21.11.11.11.11.9" class="ltx_td ltx_align_center ltx_border_t">66.17</span>
<span id="S5.T32.21.11.11.11.11.10" class="ltx_td ltx_align_center ltx_border_t">89.96</span>
<span id="S5.T32.21.11.11.11.11.11" class="ltx_td ltx_align_center ltx_border_t">88.05</span>
<span id="S5.T32.21.11.11.11.11.12" class="ltx_td ltx_align_center ltx_border_t">62.32</span>
<span id="S5.T32.21.11.11.11.11.13" class="ltx_td ltx_align_center ltx_border_t">68.51</span>
<span id="S5.T32.21.11.11.11.11.14" class="ltx_td ltx_align_center ltx_border_t">46.64</span>
<span id="S5.T32.21.11.11.11.11.15" class="ltx_td ltx_align_center ltx_border_t">91.61</span></span>
<span id="S5.T32.22.12.12.12.12" class="ltx_tr">
<span id="S5.T32.22.12.12.12.12.1" class="ltx_td ltx_align_left"><math id="S5.T32.22.12.12.12.12.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{SMALL}}" display="inline"><semantics id="S5.T32.22.12.12.12.12.1.m1.1a"><msub id="S5.T32.22.12.12.12.12.1.m1.1.1" xref="S5.T32.22.12.12.12.12.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.22.12.12.12.12.1.m1.1.1.2" xref="S5.T32.22.12.12.12.12.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.22.12.12.12.12.1.m1.1.1.3" xref="S5.T32.22.12.12.12.12.1.m1.1.1.3a.cmml">SMALL</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.22.12.12.12.12.1.m1.1b"><apply id="S5.T32.22.12.12.12.12.1.m1.1.1.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.22.12.12.12.12.1.m1.1.1.1.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1">subscript</csymbol><ci id="S5.T32.22.12.12.12.12.1.m1.1.1.2a.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.22.12.12.12.12.1.m1.1.1.2.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.T32.22.12.12.12.12.1.m1.1.1.3a.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.22.12.12.12.12.1.m1.1.1.3.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1.3">SMALL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.22.12.12.12.12.1.m1.1c">\text{KLUE-RoBERTa}_{\text{SMALL}}</annotation></semantics></math></span>
<span id="S5.T32.22.12.12.12.12.2" class="ltx_td ltx_align_center">84.98</span>
<span id="S5.T32.22.12.12.12.12.3" class="ltx_td ltx_align_center">91.54</span>
<span id="S5.T32.22.12.12.12.12.4" class="ltx_td ltx_align_center">85.16</span>
<span id="S5.T32.22.12.12.12.12.5" class="ltx_td ltx_align_center">79.33</span>
<span id="S5.T32.22.12.12.12.12.6" class="ltx_td ltx_align_center">83.65</span>
<span id="S5.T32.22.12.12.12.12.7" class="ltx_td ltx_align_center">91.14</span>
<span id="S5.T32.22.12.12.12.12.8" class="ltx_td ltx_align_center">60.89</span>
<span id="S5.T32.22.12.12.12.12.9" class="ltx_td ltx_align_center">58.96</span>
<span id="S5.T32.22.12.12.12.12.10" class="ltx_td ltx_align_center">90.04</span>
<span id="S5.T32.22.12.12.12.12.11" class="ltx_td ltx_align_center">88.14</span>
<span id="S5.T32.22.12.12.12.12.12" class="ltx_td ltx_align_center">57.32</span>
<span id="S5.T32.22.12.12.12.12.13" class="ltx_td ltx_align_center">62.70</span>
<span id="S5.T32.22.12.12.12.12.14" class="ltx_td ltx_align_center">46.62</span>
<span id="S5.T32.22.12.12.12.12.15" class="ltx_td ltx_align_center">91.44</span></span>
<span id="S5.T32.23.13.13.13.13" class="ltx_tr">
<span id="S5.T32.23.13.13.13.13.1" class="ltx_td ltx_align_left"><math id="S5.T32.23.13.13.13.13.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="S5.T32.23.13.13.13.13.1.m1.1a"><msub id="S5.T32.23.13.13.13.13.1.m1.1.1" xref="S5.T32.23.13.13.13.13.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.23.13.13.13.13.1.m1.1.1.2" xref="S5.T32.23.13.13.13.13.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.23.13.13.13.13.1.m1.1.1.3" xref="S5.T32.23.13.13.13.13.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.23.13.13.13.13.1.m1.1b"><apply id="S5.T32.23.13.13.13.13.1.m1.1.1.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.23.13.13.13.13.1.m1.1.1.1.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1">subscript</csymbol><ci id="S5.T32.23.13.13.13.13.1.m1.1.1.2a.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.23.13.13.13.13.1.m1.1.1.2.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.T32.23.13.13.13.13.1.m1.1.1.3a.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.23.13.13.13.13.1.m1.1.1.3.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.23.13.13.13.13.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math></span>
<span id="S5.T32.23.13.13.13.13.2" class="ltx_td ltx_align_center">85.07</span>
<span id="S5.T32.23.13.13.13.13.3" class="ltx_td ltx_align_center">92.50</span>
<span id="S5.T32.23.13.13.13.13.4" class="ltx_td ltx_align_center">85.40</span>
<span id="S5.T32.23.13.13.13.13.5" class="ltx_td ltx_align_center">84.83</span>
<span id="S5.T32.23.13.13.13.13.6" class="ltx_td ltx_align_center">84.60</span>
<span id="S5.T32.23.13.13.13.13.7" class="ltx_td ltx_align_center">91.44</span>
<span id="S5.T32.23.13.13.13.13.8" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.8.1" class="ltx_text ltx_framed ltx_framed_underline">67.65</span></span>
<span id="S5.T32.23.13.13.13.13.9" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.9.1" class="ltx_text ltx_framed ltx_framed_underline">68.55</span></span>
<span id="S5.T32.23.13.13.13.13.10" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.10.1" class="ltx_text ltx_framed ltx_framed_underline">93.04</span></span>
<span id="S5.T32.23.13.13.13.13.11" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.11.1" class="ltx_text ltx_framed ltx_framed_underline">88.32</span></span>
<span id="S5.T32.23.13.13.13.13.12" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.12.1" class="ltx_text ltx_framed ltx_framed_underline">68.67</span></span>
<span id="S5.T32.23.13.13.13.13.13" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.13.1" class="ltx_text ltx_framed ltx_framed_underline">73.98</span></span>
<span id="S5.T32.23.13.13.13.13.14" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.14.1" class="ltx_text ltx_framed ltx_framed_underline">47.49</span></span>
<span id="S5.T32.23.13.13.13.13.15" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.15.1" class="ltx_text ltx_framed ltx_framed_underline">91.64</span></span></span>
<span id="S5.T32.24.14.14.14.14" class="ltx_tr">
<span id="S5.T32.24.14.14.14.14.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="S5.T32.24.14.14.14.14.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" display="inline"><semantics id="S5.T32.24.14.14.14.14.1.m1.1a"><msub id="S5.T32.24.14.14.14.14.1.m1.1.1" xref="S5.T32.24.14.14.14.14.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.24.14.14.14.14.1.m1.1.1.2" xref="S5.T32.24.14.14.14.14.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.24.14.14.14.14.1.m1.1.1.3" xref="S5.T32.24.14.14.14.14.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.24.14.14.14.14.1.m1.1b"><apply id="S5.T32.24.14.14.14.14.1.m1.1.1.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.24.14.14.14.14.1.m1.1.1.1.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1">subscript</csymbol><ci id="S5.T32.24.14.14.14.14.1.m1.1.1.2a.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.24.14.14.14.14.1.m1.1.1.2.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.T32.24.14.14.14.14.1.m1.1.1.3a.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.24.14.14.14.14.1.m1.1.1.3.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.24.14.14.14.14.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math></span>
<span id="S5.T32.24.14.14.14.14.2" class="ltx_td ltx_align_center ltx_border_bb">85.69</span>
<span id="S5.T32.24.14.14.14.14.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.3.1" class="ltx_text ltx_font_bold">93.35</span></span>
<span id="S5.T32.24.14.14.14.14.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.4.1" class="ltx_text ltx_font_bold">86.63</span></span>
<span id="S5.T32.24.14.14.14.14.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.5.1" class="ltx_text ltx_font_bold">89.17</span></span>
<span id="S5.T32.24.14.14.14.14.6" class="ltx_td ltx_align_center ltx_border_bb">85.00</span>
<span id="S5.T32.24.14.14.14.14.7" class="ltx_td ltx_align_center ltx_border_bb">91.86</span>
<span id="S5.T32.24.14.14.14.14.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.8.1" class="ltx_text ltx_font_bold">71.13</span></span>
<span id="S5.T32.24.14.14.14.14.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.9.1" class="ltx_text ltx_font_bold">72.98</span></span>
<span id="S5.T32.24.14.14.14.14.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.10.1" class="ltx_text ltx_font_bold">93.48</span></span>
<span id="S5.T32.24.14.14.14.14.11" class="ltx_td ltx_align_center ltx_border_bb">88.36</span>
<span id="S5.T32.24.14.14.14.14.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.12.1" class="ltx_text ltx_font_bold">75.58</span></span>
<span id="S5.T32.24.14.14.14.14.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.13.1" class="ltx_text ltx_font_bold">80.59</span></span>
<span id="S5.T32.24.14.14.14.14.14" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.14.1" class="ltx_text ltx_font_bold">50.22</span></span>
<span id="S5.T32.24.14.14.14.14.15" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.15.1" class="ltx_text ltx_font_bold">92.23</span></span></span>
</span></span></p>
</span></div>
</figure>
<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.3" class="ltx_p">In this section, we present the evaluation results including our KLUE-PLMs and existing PLMs on the KLUE benchmark, in Table&nbsp;<a href="#S5.T32" title="Table 32 ‣ 5.3 Evaluation Results ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">32</span></a>.<span id="footnote63" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">63</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">63</sup><span class="ltx_tag ltx_tag_note">63</span>
See Appendix <a href="#A1" title="Appendix A Dev Set Results ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for the corresponding table however computed on the development set.
</span></span></span>
Different from other NLU benchmarks, we do not average the scores over tasks, since simple averaging of scores of different scales and interpretations could be highly misleading.
Rather, we describe and discuss the result of each task separately. Within the Korean <span id="S5.SS3.p1.3.1" class="ltx_text ltx_font_typewriter">BASE</span> models, <math id="S5.SS3.p1.1.m1.1" class="ltx_Math" alttext="\text{KLUE-BERT}_{\text{BASE}}" display="inline"><semantics id="S5.SS3.p1.1.m1.1a"><msub id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mtext id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2a.cmml">KLUE-BERT</mtext><mtext id="S5.SS3.p1.1.m1.1.1.3" xref="S5.SS3.p1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.p1.1.m1.1.1.2a.cmml" xref="S5.SS3.p1.1.m1.1.1.2"><mtext id="S5.SS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.p1.1.m1.1.1.2">KLUE-BERT</mtext></ci><ci id="S5.SS3.p1.1.m1.1.1.3a.cmml" xref="S5.SS3.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S5.SS3.p1.1.m1.1.1.3.cmml" xref="S5.SS3.p1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">\text{KLUE-BERT}_{\text{BASE}}</annotation></semantics></math> performs best for YNAT and WoS, <math id="S5.SS3.p1.2.m2.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="S5.SS3.p1.2.m2.1a"><msub id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><mtext id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.p1.2.m2.1.1.2a.cmml" xref="S5.SS3.p1.2.m2.1.1.2"><mtext id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.SS3.p1.2.m2.1.1.3a.cmml" xref="S5.SS3.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S5.SS3.p1.2.m2.1.1.3.cmml" xref="S5.SS3.p1.2.m2.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math> for KLUE-RE and KLUE-MRC, and <math id="S5.SS3.p1.3.m3.1" class="ltx_Math" alttext="\text{KoELECTRA}_{\text{BASE}}" display="inline"><semantics id="S5.SS3.p1.3.m3.1a"><msub id="S5.SS3.p1.3.m3.1.1" xref="S5.SS3.p1.3.m3.1.1.cmml"><mtext id="S5.SS3.p1.3.m3.1.1.2" xref="S5.SS3.p1.3.m3.1.1.2a.cmml">KoELECTRA</mtext><mtext id="S5.SS3.p1.3.m3.1.1.3" xref="S5.SS3.p1.3.m3.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.1b"><apply id="S5.SS3.p1.3.m3.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.3.m3.1.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS3.p1.3.m3.1.1.2a.cmml" xref="S5.SS3.p1.3.m3.1.1.2"><mtext id="S5.SS3.p1.3.m3.1.1.2.cmml" xref="S5.SS3.p1.3.m3.1.1.2">KoELECTRA</mtext></ci><ci id="S5.SS3.p1.3.m3.1.1.3a.cmml" xref="S5.SS3.p1.3.m3.1.1.3"><mtext mathsize="70%" id="S5.SS3.p1.3.m3.1.1.3.cmml" xref="S5.SS3.p1.3.m3.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m3.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math> for KLUE-STS and KLUE-NLI.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.3" class="ltx_p">We make two major observations.
First, we see that <math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><msub id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mtext id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.p2.1.m1.1.1.2a.cmml" xref="S5.SS3.p2.1.m1.1.1.2"><mtext id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.SS3.p2.1.m1.1.1.3a.cmml" xref="S5.SS3.p2.1.m1.1.1.3"><mtext mathsize="70%" id="S5.SS3.p2.1.m1.1.1.3.cmml" xref="S5.SS3.p2.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math>, which is the largest model among the baseline PLM’s we tested, outperforms all the other models across all the tasks except for KLUE-NER. This observation agrees well with the recent trend which has demonstrated the correlation between the model size and task performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. This indicates that KLUE will be useful for the future investigation into how much gain we can expect by simply increasing the model size further.
The second observation is that the monolingual models, which were specifically designed for and trained with a more carefully curated corpus in the target language (Korean), generally outperform the multilingual counterparts, especially when we compare models of similar sizes. We make this observation again across all the tasks, except for KLUE-NER, where the <math id="S5.SS3.p2.2.m2.1" class="ltx_Math" alttext="\text{XLM-R}_{\text{LARGE}}" display="inline"><semantics id="S5.SS3.p2.2.m2.1a"><msub id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mtext id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2a.cmml">XLM-R</mtext><mtext id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.p2.2.m2.1.1.2a.cmml" xref="S5.SS3.p2.2.m2.1.1.2"><mtext id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">XLM-R</mtext></ci><ci id="S5.SS3.p2.2.m2.1.1.3a.cmml" xref="S5.SS3.p2.2.m2.1.1.3"><mtext mathsize="70%" id="S5.SS3.p2.2.m2.1.1.3.cmml" xref="S5.SS3.p2.2.m2.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">\text{XLM-R}_{\text{LARGE}}</annotation></semantics></math> performs similarly to the best performer, <math id="S5.SS3.p2.3.m3.1" class="ltx_Math" alttext="\text{KoELECTRA}_{\text{BASE}}" display="inline"><semantics id="S5.SS3.p2.3.m3.1a"><msub id="S5.SS3.p2.3.m3.1.1" xref="S5.SS3.p2.3.m3.1.1.cmml"><mtext id="S5.SS3.p2.3.m3.1.1.2" xref="S5.SS3.p2.3.m3.1.1.2a.cmml">KoELECTRA</mtext><mtext id="S5.SS3.p2.3.m3.1.1.3" xref="S5.SS3.p2.3.m3.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.3.m3.1b"><apply id="S5.SS3.p2.3.m3.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS3.p2.3.m3.1.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S5.SS3.p2.3.m3.1.1.2a.cmml" xref="S5.SS3.p2.3.m3.1.1.2"><mtext id="S5.SS3.p2.3.m3.1.1.2.cmml" xref="S5.SS3.p2.3.m3.1.1.2">KoELECTRA</mtext></ci><ci id="S5.SS3.p2.3.m3.1.1.3a.cmml" xref="S5.SS3.p2.3.m3.1.1.3"><mtext mathsize="70%" id="S5.SS3.p2.3.m3.1.1.3.cmml" xref="S5.SS3.p2.3.m3.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.3.m3.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math>, in terms of character-level F1 score. This observation re-iterates the importance of investing effort in understanding a target language and customizing data, models and learning algorithms for the target language.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Analysis of Models</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">There were two major decisions we made in preparing the pretraining corpus and preprocessing data. They were 1) whether to pseudonymize PIIs and 2) the tokenzation strategy. In this section, we analyze the impact of our choices, using <math id="S5.SS4.p1.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="S5.SS4.p1.1.m1.1a"><msub id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml"><mtext id="S5.SS4.p1.1.m1.1.1.2" xref="S5.SS4.p1.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S5.SS4.p1.1.m1.1.1.3" xref="S5.SS4.p1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><apply id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.1.m1.1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS4.p1.1.m1.1.1.2a.cmml" xref="S5.SS4.p1.1.m1.1.1.2"><mtext id="S5.SS4.p1.1.m1.1.1.2.cmml" xref="S5.SS4.p1.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.SS4.p1.1.m1.1.1.3a.cmml" xref="S5.SS4.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S5.SS4.p1.1.m1.1.1.3.cmml" xref="S5.SS4.p1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math> by training it on the MODU corpus only.</p>
</div>
<section id="S5.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Corpus Pseudonymization</h5>

<div id="S5.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS4.SSS0.Px1.p1.1" class="ltx_p">It can be expected that noise introduced in the process of pseudonymization may have detrimental effect on the downstream task performance. Our finding, presented in Table&nbsp;<a href="#S5.T33" title="Table 33 ‣ Corpus Pseudonymization ‣ 5.4 Analysis of Models ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">33</span></a>, however shows that there is some drop in a subset of the tasks, but such drop is quite minimal. This suggests that the minimal level of pseudonymization, just like what we have done, is already a good way to balance the task performance and the risk of leaking private information.</p>
</div>
<figure id="S5.T33" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 33: </span>Evaluation results according to whether the corpus pseudonymization is conducted in the preprocessing step.</figcaption>
<div id="S5.T33.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:629.7pt;height:73pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T33.5.5" class="ltx_p"><span id="S5.T33.5.5.5" class="ltx_text">
<span id="S5.T33.5.5.5.5" class="ltx_tabular ltx_align_middle">
<span id="S5.T33.5.5.5.5.6" class="ltx_tr">
<span id="S5.T33.5.5.5.5.6.1" class="ltx_td ltx_border_tt"></span>
<span id="S5.T33.5.5.5.5.6.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T33.5.5.5.5.6.2.1" class="ltx_text ltx_font_bold">YNAT</span></span>
<span id="S5.T33.5.5.5.5.6.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.3.1" class="ltx_text ltx_font_bold">KLUE-STS</span></span>
<span id="S5.T33.5.5.5.5.6.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T33.5.5.5.5.6.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></span>
<span id="S5.T33.5.5.5.5.6.5" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.5.1" class="ltx_text ltx_font_bold">KLUE-NER</span></span>
<span id="S5.T33.5.5.5.5.6.6" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.6.1" class="ltx_text ltx_font_bold">KLUE-RE</span></span>
<span id="S5.T33.5.5.5.5.6.7" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.7.1" class="ltx_text ltx_font_bold">KLUE-DP</span></span>
<span id="S5.T33.5.5.5.5.6.8" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.8.1" class="ltx_text ltx_font_bold">KLUE-MRC</span></span>
<span id="S5.T33.5.5.5.5.6.9" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.9.1" class="ltx_text ltx_font_bold">WoS</span></span></span>
<span id="S5.T33.5.5.5.5.5" class="ltx_tr">
<span id="S5.T33.5.5.5.5.5.6" class="ltx_td ltx_align_left"><span id="S5.T33.5.5.5.5.5.6.1" class="ltx_text ltx_font_bold">Pretraining Corpus</span></span>
<span id="S5.T33.5.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">F1</span>
<span id="S5.T33.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">R<sup id="S5.T33.1.1.1.1.1.1.1" class="ltx_sup"><span id="S5.T33.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">P</span></sup></span>
<span id="S5.T33.5.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">F1</span>
<span id="S5.T33.5.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t">ACC</span>
<span id="S5.T33.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T33.2.2.2.2.2.2.1" class="ltx_sup"><span id="S5.T33.2.2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">E</span></sup></span>
<span id="S5.T33.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T33.3.3.3.3.3.3.1" class="ltx_sup"><span id="S5.T33.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">C</span></sup></span>
<span id="S5.T33.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T33.4.4.4.4.4.4.1" class="ltx_sup"><span id="S5.T33.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">mic</span></sup></span>
<span id="S5.T33.5.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_t">AUC</span>
<span id="S5.T33.5.5.5.5.5.11" class="ltx_td ltx_align_center ltx_border_t">UAS</span>
<span id="S5.T33.5.5.5.5.5.12" class="ltx_td ltx_align_center ltx_border_t">LAS</span>
<span id="S5.T33.5.5.5.5.5.13" class="ltx_td ltx_align_center ltx_border_t">EM</span>
<span id="S5.T33.5.5.5.5.5.14" class="ltx_td ltx_align_center ltx_border_t">ROUGE</span>
<span id="S5.T33.5.5.5.5.5.15" class="ltx_td ltx_align_center ltx_border_t">JGA</span>
<span id="S5.T33.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T33.5.5.5.5.5.5.1" class="ltx_sup"><span id="S5.T33.5.5.5.5.5.5.1.1" class="ltx_text ltx_font_italic">S</span></sup></span></span>
<span id="S5.T33.5.5.5.5.7" class="ltx_tr">
<span id="S5.T33.5.5.5.5.7.1" class="ltx_td ltx_align_left ltx_border_t">Original</span>
<span id="S5.T33.5.5.5.5.7.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.2.1" class="ltx_text ltx_font_bold">83.40</span></span>
<span id="S5.T33.5.5.5.5.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.3.1" class="ltx_text ltx_font_bold">92.06</span></span>
<span id="S5.T33.5.5.5.5.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.4.1" class="ltx_text ltx_font_bold">84.70</span></span>
<span id="S5.T33.5.5.5.5.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.5.1" class="ltx_text ltx_font_bold">81.60</span></span>
<span id="S5.T33.5.5.5.5.7.6" class="ltx_td ltx_align_center ltx_border_t">84.84</span>
<span id="S5.T33.5.5.5.5.7.7" class="ltx_td ltx_align_center ltx_border_t">91.03</span>
<span id="S5.T33.5.5.5.5.7.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.8.1" class="ltx_text ltx_font_bold">65.25</span></span>
<span id="S5.T33.5.5.5.5.7.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.9.1" class="ltx_text ltx_font_bold">64.79</span></span>
<span id="S5.T33.5.5.5.5.7.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.10.1" class="ltx_text ltx_font_bold">92.17</span></span>
<span id="S5.T33.5.5.5.5.7.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.11.1" class="ltx_text ltx_font_bold">88.34</span></span>
<span id="S5.T33.5.5.5.5.7.12" class="ltx_td ltx_align_center ltx_border_t">62.13</span>
<span id="S5.T33.5.5.5.5.7.13" class="ltx_td ltx_align_center ltx_border_t">67.46</span>
<span id="S5.T33.5.5.5.5.7.14" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.14.1" class="ltx_text ltx_font_bold">47.14</span></span>
<span id="S5.T33.5.5.5.5.7.15" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.15.1" class="ltx_text ltx_font_bold">91.60</span></span></span>
<span id="S5.T33.5.5.5.5.8" class="ltx_tr">
<span id="S5.T33.5.5.5.5.8.1" class="ltx_td ltx_align_left ltx_border_bb">Pseudonymized</span>
<span id="S5.T33.5.5.5.5.8.2" class="ltx_td ltx_align_center ltx_border_bb">83.39</span>
<span id="S5.T33.5.5.5.5.8.3" class="ltx_td ltx_align_center ltx_border_bb">91.11</span>
<span id="S5.T33.5.5.5.5.8.4" class="ltx_td ltx_align_center ltx_border_bb">82.85</span>
<span id="S5.T33.5.5.5.5.8.5" class="ltx_td ltx_align_center ltx_border_bb">78.50</span>
<span id="S5.T33.5.5.5.5.8.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T33.5.5.5.5.8.6.1" class="ltx_text ltx_font_bold">84.99</span></span>
<span id="S5.T33.5.5.5.5.8.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T33.5.5.5.5.8.7.1" class="ltx_text ltx_font_bold">91.22</span></span>
<span id="S5.T33.5.5.5.5.8.8" class="ltx_td ltx_align_center ltx_border_bb">62.79</span>
<span id="S5.T33.5.5.5.5.8.9" class="ltx_td ltx_align_center ltx_border_bb">62.96</span>
<span id="S5.T33.5.5.5.5.8.10" class="ltx_td ltx_align_center ltx_border_bb">92.02</span>
<span id="S5.T33.5.5.5.5.8.11" class="ltx_td ltx_align_center ltx_border_bb">88.02</span>
<span id="S5.T33.5.5.5.5.8.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T33.5.5.5.5.8.12.1" class="ltx_text ltx_font_bold">62.88</span></span>
<span id="S5.T33.5.5.5.5.8.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T33.5.5.5.5.8.13.1" class="ltx_text ltx_font_bold">67.58</span></span>
<span id="S5.T33.5.5.5.5.8.14" class="ltx_td ltx_align_center ltx_border_bb">46.21</span>
<span id="S5.T33.5.5.5.5.8.15" class="ltx_td ltx_align_center ltx_border_bb">91.23</span></span>
</span></span></p>
</span></div>
</figure>
<figure id="S5.T34" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 34: </span>Comparison our tokenization strategy with other baselines.</figcaption>
<div id="S5.T34.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:660.9pt;height:73pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T34.5.5" class="ltx_p"><span id="S5.T34.5.5.5" class="ltx_text">
<span id="S5.T34.5.5.5.5" class="ltx_tabular ltx_align_middle">
<span id="S5.T34.5.5.5.5.6" class="ltx_tr">
<span id="S5.T34.5.5.5.5.6.1" class="ltx_td ltx_border_tt"></span>
<span id="S5.T34.5.5.5.5.6.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T34.5.5.5.5.6.2.1" class="ltx_text ltx_font_bold">YNAT</span></span>
<span id="S5.T34.5.5.5.5.6.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.3.1" class="ltx_text ltx_font_bold">KLUE-STS</span></span>
<span id="S5.T34.5.5.5.5.6.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T34.5.5.5.5.6.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></span>
<span id="S5.T34.5.5.5.5.6.5" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.5.1" class="ltx_text ltx_font_bold">KLUE-NER</span></span>
<span id="S5.T34.5.5.5.5.6.6" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.6.1" class="ltx_text ltx_font_bold">KLUE-RE</span></span>
<span id="S5.T34.5.5.5.5.6.7" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.7.1" class="ltx_text ltx_font_bold">KLUE-DP</span></span>
<span id="S5.T34.5.5.5.5.6.8" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.8.1" class="ltx_text ltx_font_bold">KLUE-MRC</span></span>
<span id="S5.T34.5.5.5.5.6.9" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.9.1" class="ltx_text ltx_font_bold">WoS</span></span></span>
<span id="S5.T34.5.5.5.5.5" class="ltx_tr">
<span id="S5.T34.5.5.5.5.5.6" class="ltx_td ltx_align_left"><span id="S5.T34.5.5.5.5.5.6.1" class="ltx_text ltx_font_bold">Tokenization</span></span>
<span id="S5.T34.5.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">F1</span>
<span id="S5.T34.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">R<sup id="S5.T34.1.1.1.1.1.1.1" class="ltx_sup"><span id="S5.T34.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">P</span></sup></span>
<span id="S5.T34.5.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">F1</span>
<span id="S5.T34.5.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t">ACC</span>
<span id="S5.T34.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T34.2.2.2.2.2.2.1" class="ltx_sup"><span id="S5.T34.2.2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">E</span></sup></span>
<span id="S5.T34.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T34.3.3.3.3.3.3.1" class="ltx_sup"><span id="S5.T34.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">C</span></sup></span>
<span id="S5.T34.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T34.4.4.4.4.4.4.1" class="ltx_sup"><span id="S5.T34.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">mic</span></sup></span>
<span id="S5.T34.5.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_t">AUC</span>
<span id="S5.T34.5.5.5.5.5.11" class="ltx_td ltx_align_center ltx_border_t">UAS</span>
<span id="S5.T34.5.5.5.5.5.12" class="ltx_td ltx_align_center ltx_border_t">LAS</span>
<span id="S5.T34.5.5.5.5.5.13" class="ltx_td ltx_align_center ltx_border_t">EM</span>
<span id="S5.T34.5.5.5.5.5.14" class="ltx_td ltx_align_center ltx_border_t">ROUGE</span>
<span id="S5.T34.5.5.5.5.5.15" class="ltx_td ltx_align_center ltx_border_t">JGA</span>
<span id="S5.T34.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T34.5.5.5.5.5.5.1" class="ltx_sup"><span id="S5.T34.5.5.5.5.5.5.1.1" class="ltx_text ltx_font_italic">S</span></sup></span></span>
<span id="S5.T34.5.5.5.5.7" class="ltx_tr">
<span id="S5.T34.5.5.5.5.7.1" class="ltx_td ltx_align_left ltx_border_t">BPE</span>
<span id="S5.T34.5.5.5.5.7.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.2.1" class="ltx_text ltx_font_bold">83.40</span></span>
<span id="S5.T34.5.5.5.5.7.3" class="ltx_td ltx_align_center ltx_border_t">91.91</span>
<span id="S5.T34.5.5.5.5.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.4.1" class="ltx_text ltx_font_bold">85.19</span></span>
<span id="S5.T34.5.5.5.5.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.5.1" class="ltx_text ltx_font_bold">82.07</span></span>
<span id="S5.T34.5.5.5.5.7.6" class="ltx_td ltx_align_center ltx_border_t">68.75</span>
<span id="S5.T34.5.5.5.5.7.7" class="ltx_td ltx_align_center ltx_border_t">89.47</span>
<span id="S5.T34.5.5.5.5.7.8" class="ltx_td ltx_align_center ltx_border_t">64.39</span>
<span id="S5.T34.5.5.5.5.7.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.9.1" class="ltx_text ltx_font_bold">65.04</span></span>
<span id="S5.T34.5.5.5.5.7.10" class="ltx_td ltx_align_center ltx_border_t">89.89</span>
<span id="S5.T34.5.5.5.5.7.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.11.1" class="ltx_text ltx_font_bold">89.47</span></span>
<span id="S5.T34.5.5.5.5.7.12" class="ltx_td ltx_align_center ltx_border_t">51.12</span>
<span id="S5.T34.5.5.5.5.7.13" class="ltx_td ltx_align_center ltx_border_t">65.79</span>
<span id="S5.T34.5.5.5.5.7.14" class="ltx_td ltx_align_center ltx_border_t">21.38</span>
<span id="S5.T34.5.5.5.5.7.15" class="ltx_td ltx_align_center ltx_border_t">77.68</span></span>
<span id="S5.T34.5.5.5.5.8" class="ltx_tr">
<span id="S5.T34.5.5.5.5.8.1" class="ltx_td ltx_align_left ltx_border_bb">Morpheme-based Subword</span>
<span id="S5.T34.5.5.5.5.8.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.2.1" class="ltx_text ltx_font_bold">83.40</span></span>
<span id="S5.T34.5.5.5.5.8.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.3.1" class="ltx_text ltx_font_bold">92.06</span></span>
<span id="S5.T34.5.5.5.5.8.4" class="ltx_td ltx_align_center ltx_border_bb">84.70</span>
<span id="S5.T34.5.5.5.5.8.5" class="ltx_td ltx_align_center ltx_border_bb">81.60</span>
<span id="S5.T34.5.5.5.5.8.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.6.1" class="ltx_text ltx_font_bold">84.84</span></span>
<span id="S5.T34.5.5.5.5.8.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.7.1" class="ltx_text ltx_font_bold">91.03</span></span>
<span id="S5.T34.5.5.5.5.8.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.8.1" class="ltx_text ltx_font_bold">65.25</span></span>
<span id="S5.T34.5.5.5.5.8.9" class="ltx_td ltx_align_center ltx_border_bb">64.79</span>
<span id="S5.T34.5.5.5.5.8.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.10.1" class="ltx_text ltx_font_bold">92.17</span></span>
<span id="S5.T34.5.5.5.5.8.11" class="ltx_td ltx_align_center ltx_border_bb">88.34</span>
<span id="S5.T34.5.5.5.5.8.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.12.1" class="ltx_text ltx_font_bold">62.13</span></span>
<span id="S5.T34.5.5.5.5.8.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.13.1" class="ltx_text ltx_font_bold">67.46</span></span>
<span id="S5.T34.5.5.5.5.8.14" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.14.1" class="ltx_text ltx_font_bold">47.14</span></span>
<span id="S5.T34.5.5.5.5.8.15" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.15.1" class="ltx_text ltx_font_bold">91.60</span></span></span>
</span></span></p>
</span></div>
</figure>
</section>
<section id="S5.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Tokenization Strategy</h5>

<div id="S5.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS4.SSS0.Px2.p1.1" class="ltx_p">We contrast our tokenization scheme, <span id="S5.SS4.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">morpheme-based subword</span> tokenization, against the standard byte pair encoding (BPE). First, we investigate the difference in how words are segmented into subword tokens. Following <cite class="ltx_cite ltx_citemacro_citet">Rust et&nbsp;al. [<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>, we consider subword fertility, proportion of continued words, and <span id="S5.SS4.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_typewriter">UNK</span> ratio. On the subword fertility, which measures the average number of subwords produced per word, the proposed tokenization scheme ends up slightly higher than BPE does. However, when we look at the proportion of continued words, which measures the number of words that were split into at least two subwords, we observe the opposite trend. This implies that our algorithm maintains the original words as much as it can, and only when it is necessary, it splits each word into potentially more subword pieces. The efficacy of the proposed scheme over BPE is evident from the <span id="S5.SS4.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_typewriter">UNK</span> ratio, as it produces fewer <span id="S5.SS4.SSS0.Px2.p1.1.4" class="ltx_text ltx_font_typewriter">UNK</span> tokens compared to BPE when the vocabulary size was controlled to be 32k for both methods. See Table&nbsp;<a href="#S5.T35" title="Table 35 ‣ Tokenization Strategy ‣ 5.4 Analysis of Models ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">35</span></a>.</p>
</div>
<figure id="S5.T35" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 35: </span>Overview of tokenization metrics. We build each vocabs using MODU corpus and compare them on WIKIPEDIA corpus.</figcaption>
<div id="S5.T35.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:371.9pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T35.3.3" class="ltx_p"><span id="S5.T35.3.3.3" class="ltx_text">
<span id="S5.T35.3.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S5.T35.3.3.3.3.3" class="ltx_tr">
<span id="S5.T35.3.3.3.3.3.4" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T35.3.3.3.3.3.4.1" class="ltx_text ltx_font_bold">Tokenization</span></span>
<span id="S5.T35.3.3.3.3.3.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T35.3.3.3.3.3.5.1" class="ltx_text ltx_font_bold"># Vocabs</span></span>
<span id="S5.T35.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T35.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Fertility <math id="S5.T35.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T35.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T35.1.1.1.1.1.1.1.m1.1.1" xref="S5.T35.1.1.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T35.1.1.1.1.1.1.1.m1.1b"><ci id="S5.T35.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T35.1.1.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T35.1.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
<span id="S5.T35.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T35.2.2.2.2.2.2.1" class="ltx_text ltx_font_bold">% Continued Word <math id="S5.T35.2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T35.2.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T35.2.2.2.2.2.2.1.m1.1.1" xref="S5.T35.2.2.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T35.2.2.2.2.2.2.1.m1.1b"><ci id="S5.T35.2.2.2.2.2.2.1.m1.1.1.cmml" xref="S5.T35.2.2.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T35.2.2.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></span>
<span id="S5.T35.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T35.3.3.3.3.3.3.1" class="ltx_text ltx_font_bold">UNK Ratio <math id="S5.T35.3.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T35.3.3.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S5.T35.3.3.3.3.3.3.1.m1.1.1" xref="S5.T35.3.3.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T35.3.3.3.3.3.3.1.m1.1b"><ci id="S5.T35.3.3.3.3.3.3.1.m1.1.1.cmml" xref="S5.T35.3.3.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T35.3.3.3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></span></span>
<span id="S5.T35.3.3.3.3.4" class="ltx_tr">
<span id="S5.T35.3.3.3.3.4.1" class="ltx_td ltx_align_left ltx_border_t">BPE</span>
<span id="S5.T35.3.3.3.3.4.2" class="ltx_td ltx_align_center ltx_border_t">32k</span>
<span id="S5.T35.3.3.3.3.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T35.3.3.3.3.4.3.1" class="ltx_text ltx_font_bold">2.073</span></span>
<span id="S5.T35.3.3.3.3.4.4" class="ltx_td ltx_align_center ltx_border_t">0.578</span>
<span id="S5.T35.3.3.3.3.4.5" class="ltx_td ltx_align_center ltx_border_t">0.011</span></span>
<span id="S5.T35.3.3.3.3.5" class="ltx_tr">
<span id="S5.T35.3.3.3.3.5.1" class="ltx_td ltx_align_left ltx_border_bb">Morpheme-based Subword</span>
<span id="S5.T35.3.3.3.3.5.2" class="ltx_td ltx_align_center ltx_border_bb">32k</span>
<span id="S5.T35.3.3.3.3.5.3" class="ltx_td ltx_align_center ltx_border_bb">2.468</span>
<span id="S5.T35.3.3.3.3.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T35.3.3.3.3.5.4.1" class="ltx_text ltx_font_bold">0.765</span></span>
<span id="S5.T35.3.3.3.3.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T35.3.3.3.3.5.5.1" class="ltx_text ltx_font_bold">0.009</span></span></span>
</span></span></p>
</span></div>
</figure>
<div id="S5.SS4.SSS0.Px2.p2" class="ltx_para">
<p id="S5.SS4.SSS0.Px2.p2.1" class="ltx_p">We find these qualitative differences between two schemes lead to significant differences in the task performance in the cases of KLUE-NER, KLUE-MRC and WoS. These tasks often involve tagging, detection and even generation at the morpheme level, and we suspect that morphologically consistent tokenization facilitates better prediction overall. On the other hand, the difference in the tokenization strategy does not manifest itself in the performance of classification or word-level tagging, likely as a corresponding NLU system can more readily overcome inconsistencies in subword segmentation when merging subword token representations into that of a larger unit. Overall, we recommend future researchers use the proposed tokenization strategy as a default option.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Ethical Considerations</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In building KLUE and accompanying baseline models, we have incorporated various mechanisms to avoid any harmful and negative consequences from releasing both data and models. These mechanisms are described in detail wherever they were introduced and used, but in this section, we summarize these mechanisms, considerations and our principles behind them.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Copyright and Accessibility</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Most NLP datasets are built upon the existing text sources. This raises a question on the terms of using such datasets, especially when the underlying source datasets are not well-specified nor carefully investigated. In order to avoid any such doubt on the terms of using KLUE and to accelerate NLP research in Korean, we fully adhere to the copyright act of Korea, which went effective on Dec. 8, 2020.<span id="footnote64" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">64</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">64</sup><span class="ltx_tag ltx_tag_note">64</span>
<a target="_blank" href="https://www.law.go.kr/%EB%B2%95%EB%A0%B9/%EC%A0%80%EC%9E%91%EA%B6%8C%EB%B2%95" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.law.go.kr/%EB%B2%95%EB%A0%B9/%EC%A0%80%EC%9E%91%EA%B6%8C%EB%B2%95</a>
</span></span></span>
and include only text for which we know we can release under a license that permits both redistribution and re-mix without any restriction on the use.</p>
</div>
<section id="S6.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S6.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p1.1" class="ltx_p">Our goal is to secure and maximize the continued availability and usefulness of the benchmark. In other words, we must guarantee the possibility of derive new work and redistribute it freely, which comes together with CC BY-SA. To release KLUE under CC BY-SA, we have built a source corpus set by including only text that is either 1) not protected by copyright or 2) under CC0, CC BY, CC BY-SA or KOGL Type 1 license. In the case of news articles, which are copyrighted, we have signed contracts with the providers, Korean Economics Daily (KED) news media and Acrofan, that allow us to make KLUE-MRC and release them under CC BY-SA.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task-Specific (Annotated) Datasets</h5>

<div id="S6.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p1.1" class="ltx_p">We subsample and annotate the source corpus for each KLUE benchmark task. We release each under CC BY-SA. This allows users of KLUE benchamrk to copy, redistribute, remix, transform and build upon it for both commercial and non-commercial purposes, as long as derivatives are distributed under the same license (CC BY-SA). We expect this to greatly facilitate future NLP research and development.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretraining Corpora and Language Models</h5>

<div id="S6.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p1.1" class="ltx_p">As was discussed earlier&nbsp;<a href="#S4.SS1.SSS0.Px1" title="Pretraining Corpora ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we cannot guarantee that our pretraining corpus, built using MODU, CC-100-Kor and NEWSCRAWL, does not contain any copyrighted work, although these are all created from publicly available text.
Unfortunately without these corpora, it is not possible to find a sufficiently large resource to train large-scale language models for Korean. We thus use them for pretraining but do not publicly release the pretraining corpora in order to avoid any issues in the future, which is in contrast to KLUE. Instead, we openly release pretrained language models to facilitate future research. As the parameters of a language model does not <span id="S6.SS1.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">[express] human thoughts and emotions</span>, they do not meet the requirement of being copyrighted.</p>
</div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Toxic Content</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Although large-scale, accessible benchmark datasets advance machine learning and its applications to adjacent fields, such as natural language processing, toxic and unwanted contents within these datasets may be amplified via large-scale models we train on them. We have been aware of this issue from the beginning of the project, and here we describe how we have addressed these toxic contents in KLUE.</p>
</div>
<section id="S6.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task-Specific Datasets</h5>

<div id="S6.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p1.1" class="ltx_p">For each task-specific dataset, we apply three stages to minimize the introduction of toxic contents. First, we automatically detect hate speech and gender-biased sentences using toxicity classifiers and remove those even before sending these sentences for annotation (see Section&nbsp;<a href="#S2.SS3.SSS0.Px3" title="PII Removal ‣ 2.3 Preprocessing ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>).
Second, we explicitly and clearly instruct annotators to mark any instance that exhibits social biases and/or is toxic (see Section&nbsp;<a href="#S3" title="3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), after providing them with clear definitions of bias and hate speech. Finally, we manually examine these marked sentences and exclude them from the final dataset.
This three-stage process may not catch all possible such instances, and we plan to use an online forum<span id="footnote65" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">65</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">65</sup><span class="ltx_tag ltx_tag_note">65</span><a target="_blank" href="https://github.com/KLUE-benchmark/KLUE/issues" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/KLUE-benchmark/KLUE/issues</a></span></span></span> to receive feedback and complaints from users of KLUE.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretrained Language Models</h5>

<div id="S6.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px2.p1.1" class="ltx_p">We use our pretraining corpora (see Section&nbsp;<a href="#S4.SS1.SSS0.Px1" title="Pretraining Corpora ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>) as they are, for three reasons. First, manual inspection is simply not tractable due to the sheer scale. Second, it is challenging to build an automated tool to detect hate speech and biased sentences. This issue is made even more severe for Korean, because there is only one known hate speech dataset of limited size <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>.
Lastly, we envision the future in which these pretrained language models are used to build better tools for automatically detecting various toxic contents as well as undesirable social biases. In order for such pretrained models to be aware of these issues, they must have been trained with such toxic contents as well.</p>
</div>
</section>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Personally Identifiable Information</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">It has recently been discovered by that a large-scale, pretrained language model memorizes a large amount of personally identifiable information (PII) and that an algorithm can be designed to retrieved those private information. We thus design two different approaches for pseudonymizing task-specific datasets and pretraining corpora, respectively.</p>
</div>
<section id="S6.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task-Specific Datasets</h5>

<div id="S6.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS3.SSS0.Px1.p1.1" class="ltx_p">In the case of task-specific datasets, we rely on manual inspection during annotation to detect PII. We discard any sentences that was reported to contain PII after manual inspection. In the case of DST, which relies on simulated dialogues, we pseudonymize the database entries rather than actual text, using the <span id="S6.SS3.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_typewriter">faker</span> library.<span id="footnote66" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">66</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">66</sup><span class="ltx_tag ltx_tag_note">66</span>
<a target="_blank" href="https://github.com/joke2k/faker" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/joke2k/faker</a>
</span></span></span></p>
</div>
</section>
<section id="S6.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretraining Corpora</h5>

<div id="S6.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS3.SSS0.Px2.p1.1" class="ltx_p">There is a trade-off between removing PII and the performance of a pretrained language model, as we will demonstrate later in this paper. We thus pseudonymize 16 PII types that are detectable purely by regular expressions. See Section&nbsp;<a href="#S4.SS1.SSS0.Px2" title="Preprocessing ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a></p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Related Work</h2>

<section id="S7.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">General-Purpose NLU Benchmarks</h5>

<div id="S7.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px1.p1.1" class="ltx_p">General Language Understanding Evaluation (GLUE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> benchmark, a collection of evaluation dataset for English, was the first general-purpose evaluation benchmarks for NLU. It is general-purpose in that it is not limited to a single task. It consists of 11 downstream tasks, including tasks that measures the capability of capturing semantic textual similarity (QQP, MRPC, STS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, measures the capability of inference (MNLI, QNLI, RTE, WNLI) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite> and that evaluates the capability of classifying a single sentence into a predefined set of categories (CoLA, SST) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>, <a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite>.
GLUE exclusively focused on English, and its variants in different languages have been built and released over the past couple of years, including CLUE in Chinese&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>, a French version&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>, an Indonesian version&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>]</cite>, a version for Indic languages&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, Russian SuperGLUE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>, and Persian GLUE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. In all these cases, substantial efforts were carried out to follow the philosophy of the original GLUE, covering a broad spectrum of domains and tasks, while incorporating language-specific characteristics.
On the other hand, there have been efforts to build a multilingual version of such benchmark, largely relying on automated methods, such as XGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> and XTREME <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. Korean as a language has been included in subsets of these latter benchmarks, but there has not been a serious attempt at building a general-purpose language understanding evaluation suite for Korean, until this paper.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Absence of a Standard NLU Benchmark in Korean</h5>

<div id="S7.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px2.p1.1" class="ltx_p">Until this paper, a number of task-specific benchmarks in Korean have been proposed and released. For example, NSMC is used for sentiment classification, PAWS-X <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite> for paraphrase detection, KorNLI and KorSTS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> for NLI and STS, KorQuAD 1 and 2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> for MRC, and BEEP! <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> for hate speech detection. At this point, one may wonder whether it would have been easier and more convenient to simply aggregate these datasets to build KLUE. After all, this has been a popular strategy for constructing monolingual <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> as well as multilingual <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> benchmarks. Unfortunately this approach comes with two major issues that we directly address in this paper.</p>
</div>
<div id="S7.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S7.SS0.SSS0.Px2.p2.1" class="ltx_p">First, the existing datasets are constructed individually without considering other datasets and their properties. In other words, the aggregate of these individual datasets is unlikely to cover a broad spectrum of domains and writing styles, unlike KLUE for which we carefully curate the source corpora as well as subsets for downstream tasks to have broad coverage of domains and styles.
This goes beyond domains and styles, but also the coverage of linguistic phenomena under evaluation. Most of the existing benchmarks, listed above, focus on semantics rather than syntax, and it is difficult to find any widely-available benchmark that captures pragmatics. We address this issue by carefully selecting a set of downstream tasks.</p>
</div>
<div id="S7.SS0.SSS0.Px2.p3" class="ltx_para">
<p id="S7.SS0.SSS0.Px2.p3.1" class="ltx_p">Second, these existing datasets are not always publicly available,<span id="footnote67" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">67</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">67</sup><span class="ltx_tag ltx_tag_note">67</span>
Some of these are publicly available in Korea but not internationally.
</span></span></span>
and some are distributed with a highly restrictive license that prohibits redistribution nor the transformation of the original. These are often the ones published and released by government-affiliated institutes. In some cases, it is necessary to obtain a special permission to access datasets, which is often not easily accessible by non-Korean researchers. We address all these issues with KLUE by releaseing the entire benchmark data under CC BY-SA, both by careful curation of source corpora and by direct agreements with publishers.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretrained Language Models (PLMs)</h5>

<div id="S7.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px3.p1.1" class="ltx_p">The recent trend of large-scale pretrained language models was sparked by the success of earlier models, such as ELMo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>, GPT-2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite> and BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, on the GLUE and other similar NLU benchmarks. This earlier success has led to a series of advances in large-scale language models, including XLNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite>, ALBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>, RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>, ELECTRA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, and Deberta <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, again largely driven by the availability of standardized benchmarks.
This advance in language models, not only in terms of the model size but also in learning algorithms, in turn also sparked the interest in building and improving existing language understanding benchmarks. Some of the recently released, challenging benchmarks include SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> and KILT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>. The availability of such a standard language understanding benchmark, such as KLUE from this paper, is expected to start such a virtuous cycle for Korean language understanding.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretrained Language Models for Korean</h5>

<div id="S7.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px4.p1.1" class="ltx_p">Inspired by the development in other languages and multilingual models, PLM’s for the Korean language have been trained and released by multiple research groups and individuals. SKT released KoBERT,<span id="footnote68" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">68</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">68</sup><span class="ltx_tag ltx_tag_note">68</span>
<a target="_blank" href="https://github.com/SKTBrain/KoBERT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/SKTBrain/KoBERT</a>
</span></span></span>
followed by KorBERT<span id="footnote69" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">69</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">69</sup><span class="ltx_tag ltx_tag_note">69</span>
<a target="_blank" href="https://aiopen.etri.re.kr/service_dataset.php" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aiopen.etri.re.kr/service_dataset.php</a>
</span></span></span>
from ETRI,
HanBERT<span id="footnote70" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">70</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">70</sup><span class="ltx_tag ltx_tag_note">70</span>
<a target="_blank" href="https://github.com/tbai2019/HanBert-54k-N" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tbai2019/HanBert-54k-N</a>
</span></span></span>
from TwoBlock AI, KR-BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> from Seoul National University. There are a few pretrained models released by individual researchers, such as KoELECTRA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> and KcBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>.</p>
</div>
<div id="S7.SS0.SSS0.Px4.p2" class="ltx_para">
<p id="S7.SS0.SSS0.Px4.p2.1" class="ltx_p">Unfortunately, it is unclear how we should compare this stream of pretrained language models in Korean, due to the lack of a standarded benchmark in Korean. Subsets of these models have been compared based on subsets of a few downtream NLP tasks in Korean above, but because these are not standardized, it is not easy to draw solid conclusions from these limited experiments. We expect the proposed KLUE benchmark will serve as a standard way to track the progress of research in language models for Korean.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Discussion</h2>

<section id="S8.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Open Access</h5>

<div id="S8.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S8.SS0.SSS0.Px1.p1.1" class="ltx_p">We distribute KLUE under CC BY-SA. The license allows everyone to freely copy and redistribute our benchmarks in any medium or format. In addition, one can improve our benchmark to build more challenging datasets after performance saturation. To function as a NLU <span id="S8.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">benchmark</span>, open access is a must. If the original author does not allow derivative development of the benchmark, other researchers cannot improve it, for example by removing toxic content, or building a more challenging dataset to accelerate research for technical improvements. If commercial use is not allowed, researchers working at for-profit organizations would not be able to benefit from nor to (easily) contribute to the benchmark. Redistribution is another crucial factor because it significantly limits research if, for example, sharing the datasets with another researcher is prohibited. Another existing practice that limits research is transferring the responsibility of copyright infringement of related conflicts to researchers. To set a good precedent for open access of data, we allow using our datasets for 1) any purpose, 2) derivative work, and 3) redistribution, as long as the existing copyrights in our benchmark datasets are respected. We also open our pretrained Korean language models and the implementation of pretraining and fine-tuning pipelines. This enhances reproducibility of our work, and allows anyone to fix and improve our data and models. We hope to contribute to the Korean NLP research community as well the wider NLP community.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Facilitating Korean NLP Research</h5>

<div id="S8.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S8.SS0.SSS0.Px2.p1.1" class="ltx_p">We developed KLUE with the aim of facilitating Korean NLP research, in response to the recent active development efforts of large Korean language models. The entire NLP community has seen BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and its variants outperforming the previous NLU models for GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> and SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite>, as well as the more recent GPT3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> with outstanding performance without fine-tuning (and with <span id="S8.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">in-context learning</span>) in natural language understanding and generation. Motivated by these models, many Korean researchers at various institutions rushed to pretrain large-scale Transformer-based Korean language models. Consequently, a number of nearly identical pretrained language models have been released to open-source communities. However, we could not systematically understand the behaviors and characteristics of these models because of the lack of well-designed general-purpose benchmarks like GLUE for Korean. KLUE will allow us to conduct controlled experiments to understand how and why various Korean LMs perform on certain tasks and thus obtain detailed insights into those models. Furthermore, since KLUE includes many representative NLU tasks that are also conducted in other languages, KLUE will function as a fundamental resource to NLP researchers who aim to conduct multilingual research with Korean and other languages.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Measuring Overall Performance of NLU models</h5>

<div id="S8.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S8.SS0.SSS0.Px3.p1.1" class="ltx_p">We do not average all scores gained from each task in KLUE. The performance of all tasks are measured by different evaluation metrics. This is because we carefully choose the metric for each task with considering its own characteristics. Their granularity differs by tasks, for example, KLUE-MRC and KLUE-NER employ character-level metrics because an entity can exist within a word in Korean whereas KLUE-STS and KLUE-NLI use sentence-level metrics. Furthermore, we use various metrics across tasks, such as F1 score, accuracy, area under the curve, UAS, LAS, ROUGE-W, joint goal accuracy, and Pearson’s correlation. In this situation, simply computing the average of all tasks as in GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> results in misleading overall performance measure. The average will lose its interpretability as well as giving higher weights to a certain task in unintended ways. Accordingly, an alternative way to estimating a model’s NLU capability is necessary. Recently, analyzing correctness of a model’s prediction by using Item Response Theory (IRT) framework to estimate such capability is proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>, however, we find that it is not clear how it should be applied precisely in our benchmark. As of now, we thus decide to evaluate a model for each task separately without any summarization of overall performance measure. This is our limitation, and we leave this problem for the future.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Rapid Saturation of KLUE</h5>

<div id="S8.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S8.SS0.SSS0.Px4.p1.1" class="ltx_p">We expect fast saturation of KLUE based on our observations of for instance GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. However, we do not artificially make our benchmark challenging by e.g. filtering out easy examples for models. Because the main purpose of KLUE is to properly evaluate models in terms of various aspects of NLU, we avoid focusing on enlarging headrooms for improvement over our baseline pretrained language models. We expect our license policy would positively affect the advancement of our benchmark after saturation by collectively developing more challenging tasks with other researchers, such as building the first open-domain question answering for Korean.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Analysis of Korean Language Models</h5>

<div id="S8.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="S8.SS0.SSS0.Px5.p1.1" class="ltx_p">We observe various patterns when comparing performances of the baseline models on each tasks, however, most of them are understudied to precisely explain the phenomena. With more thorough investigations, we hope to enhance understanding of the complex interaction of a model, corpus, linguistic properties of Korean and training mechanisms in future work.</p>
</div>
</section>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Conclusion</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">We present KLUE, a suite of Korean NLU benchmarks that includes diverse tasks. We open KLUE to everyone, and we also provide Korean language models trained to outperform multilingual models and other existing open-sourced Korean language models. We set high standards from the outset, as we built the benchmark and trained the models from scratch. We designed the benchmark datasets and trained the annotators rigorously to consider potential ethical issues including private information and hate speech. We documented in detail all of the benchmark construction and testing processes. We also discussed broader impacts and limitations of KLUE and our models. Despite the limitations, KLUE and the accompanying language models will facilitate future Korean NLP research by setting a valuable precedent describing how datasets and language models should be created and spread to a wider community.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments and Disclosure of Funding</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Upstage sponsored annotation cost and built the leaderboard. NAVER CLOVA provided data annotation cost and GPU cloud computing infrastructure (NSML). We also thank to Google’s TensorFlow Research Cloud (TFRC) and Kakao Enterprise’s BrainCloud. The three computing resources were used to pretrain and fine-tune language models. Scatter Lab, SelectStar, Riiid!, DeepNatural and KAIST sponsored data annotation cost. In addition, we appreciate The Korea Economy Daily and Acrofan for supporting their news articles for MRC datasets.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">The authors thank Cheoneum Park for discussions about task selection and DP task, Jinhyuk Lee and Minjoon Seo for discussions on MRC task, Sujeong Kim and DongYeon Kim for considerable efforts to manage annotators in MRC dataset, and Sangah Park for careful consideration of data construction in DP, NER, and RE. We appreciate Junyeop Lee, Geonhee Lee, Jiho Lee, Daehyun Nam, and Yongjin Cho for the leaderboard and evaluation system implementation.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p id="Sx1.p3.1" class="ltx_p">This study is reviewed and approved by the KAIST Institutional Review Board (#KH2020-173).</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agency [2018]</span>
<span class="ltx_bibblock">
National Information&nbsp;Society Agency.

</span>
<span class="ltx_bibblock">MRC AI Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aihub.or.kr/aidata/86" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aihub.or.kr/aidata/86</a>, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agirre et&nbsp;al. [2015]</span>
<span class="ltx_bibblock">
Eneko Agirre, Carmen Banea, Claire Cardie, Daniel Cer, Mona Diab, Aitor
Gonzalez-Agirre, Weiwei Guo, Iñigo Lopez-Gazpio, Montse Maritxalar, Rada
Mihalcea, German Rigau, Larraitz Uria, and Janyce Wiebe.

</span>
<span class="ltx_bibblock">SemEval-2015 task 2: Semantic textual similarity, English,
Spanish and pilot on interpretability.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 9th International Workshop on Semantic
Evaluation (SemEval 2015)</em>, pages 252–263, Denver, Colorado, June 2015.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/S15-2045</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S15-2045" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S15-2045</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agirre et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Eneko Agirre, Carmen Banea, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, Rada
Mihalcea, German Rigau, and Janyce Wiebe.

</span>
<span class="ltx_bibblock">SemEval-2016 task 1: Semantic textual similarity, monolingual and
cross-lingual evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 10th International Workshop on Semantic
Evaluation (SemEval-2016)</em>, pages 497–511, San Diego, California, June
2016. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/S16-1081</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S16-1081" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S16-1081</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allwood [2000]</span>
<span class="ltx_bibblock">
Jens Allwood.

</span>
<span class="ltx_bibblock">An activity based approach to pragmatics.

</span>
<span class="ltx_bibblock">In Harry Bunt and William Black, editors, <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Abduction, belief and
context in dialogue: Studies in computational pragmatics</em>, chapter&nbsp;2, pages
47–80. John Benjamins, Amsterdam, Netherlands, 2000.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baldini&nbsp;Soares et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Livio Baldini&nbsp;Soares, Nicholas FitzGerald, Jeffrey Ling, and Tom Kwiatkowski.

</span>
<span class="ltx_bibblock">Matching the blanks: Distributional similarity for relation learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 2895–2905, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1279</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1279" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1279</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender and Friedman [2018]</span>
<span class="ltx_bibblock">
Emily&nbsp;M. Bender and Batya Friedman.

</span>
<span class="ltx_bibblock">Data statements for natural language processing: Toward mitigating
system bias and enabling better science.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
6:587–604, 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00041</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q18-1041" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q18-1041</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowman and Dahl [2021]</span>
<span class="ltx_bibblock">
Samuel&nbsp;R Bowman and George&nbsp;E Dahl.

</span>
<span class="ltx_bibblock">What will it take to fix benchmarking in natural language
understanding?

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.02145</em>, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowman et&nbsp;al. [2015]</span>
<span class="ltx_bibblock">
Samuel&nbsp;R. Bowman, Gabor Angeli, Christopher Potts, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">A large annotated corpus for learning natural language inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 Conference on Empirical Methods in
Natural Language Processing</em>, pages 632–642, Lisbon, Portugal, September
2015. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D15-1075</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D15-1075" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D15-1075</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
and Dario Amodei.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.&nbsp;F. Balcan, and H.&nbsp;Lin,
editors, <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume&nbsp;33,
pages 1877–1901. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Budzianowski et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Iñigo Casanueva,
Stefan Ultes, Osman Ramadan, and Milica Gašić.

</span>
<span class="ltx_bibblock">MultiWOZ - a large-scale multi-domain Wizard-of-Oz dataset
for task-oriented dialogue modelling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 5016–5026, Brussels, Belgium,
October-November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-1547</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D18-1547" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D18-1547</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Byrne et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Bill Byrne, Karthik Krishnamoorthi, Chinnadhurai Sankar, Arvind Neelakantan,
Ben Goodrich, Daniel Duckworth, Semih Yavuz, Amit Dubey, Kyu-Young Kim, and
Andy Cedilnik.

</span>
<span class="ltx_bibblock">Taskmaster-1: Toward a realistic and diverse dialog dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 4516–4525, Hong Kong,
China, November 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D19-1459</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D19-1459" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D19-1459</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel
Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar
Erlingsson, et&nbsp;al.

</span>
<span class="ltx_bibblock">Extracting training data from large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.07805</em>, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cer et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Daniel Cer, Mona Diab, Eneko Agirre, Iñigo Lopez-Gazpio, and Lucia Specia.

</span>
<span class="ltx_bibblock">SemEval-2017 task 1: Semantic textual similarity multilingual and
crosslingual focused evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 11th International Workshop on Semantic
Evaluation (SemEval-2017)</em>, pages 1–14, Vancouver, Canada, August 2017.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/S17-2001</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S17-2001" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S17-2001</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang Tang.

</span>
<span class="ltx_bibblock">A survey on dialogue systems: Recent advances and new frontiers.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">SIGKDD Explor. Newsl.</em>, 19(2):25–35,
November 2017.

</span>
<span class="ltx_bibblock">ISSN 1931-0145.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3166054.3166058</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/3166054.3166058" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3166054.3166058</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Pengyu Cheng, Weituo Hao, Siyang Yuan, Shijing Si, and Lawrence Carin.

</span>
<span class="ltx_bibblock">FairFil: Contrastive neural debiasing method for pretrained text
encoders.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=N6JECD-PI5w" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=N6JECD-PI5w</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chinchor [1998]</span>
<span class="ltx_bibblock">
Nancy&nbsp;A. Chinchor.

</span>
<span class="ltx_bibblock">Overview of MUC-7.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Seventh Message Understanding Conference (MUC-7):
Proceedings of a Conference Held in Fairfax, Virginia, April 29 - May 1,
1998</em>, 1998.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/M98-1001" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/M98-1001</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et&nbsp;al. [2014]</span>
<span class="ltx_bibblock">
Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Learning phrase representations using RNN encoder–decoder for
statistical machine translation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2014 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 1724–1734, Doha, Qatar,
October 2014. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3115/v1/D14-1179</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D14-1179" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D14-1179</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et&nbsp;al. [2020a]</span>
<span class="ltx_bibblock">
Won&nbsp;Ik Cho, Jong&nbsp;In Kim, Young&nbsp;Ki Moon, and Nam&nbsp;Soo Kim.

</span>
<span class="ltx_bibblock">Discourse component to sentence (DC2S): An efficient human-aided
construction of paraphrase and sentence similarity dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 6819–6826, Marseille, France, May 2020a.
European Language Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.842" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.842</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et&nbsp;al. [2020b]</span>
<span class="ltx_bibblock">
Won&nbsp;Ik Cho, Sangwhan Moon, and Youngsook Song.

</span>
<span class="ltx_bibblock">Open Korean corpora: A practical report.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of Second Workshop for NLP Open Source Software
(NLP-OSS)</em>, pages 85–93, Online, November 2020b. Association
for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.nlposs-1.12" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.nlposs-1.12</a>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chun et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Jayeol Chun, Na-Rae Han, Jena&nbsp;D. Hwang, and Jinho&nbsp;D. Choi.

</span>
<span class="ltx_bibblock">Building Universal Dependency treebanks in Korean.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh International Conference on
Language Resources and Evaluation (LREC 2018)</em>, Miyazaki, Japan, May 2018.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/L18-1347" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/L18-1347</a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael
Collins, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BoolQ: Exploring the surprising difficulty of natural yes/no
questions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 2924–2936,
Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1300</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N19-1300" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1300</a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Kevin Clark, Minh-Thang Luong, Quoc&nbsp;V. Le, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">ELECTRA: Pre-training text encoders as discriminators rather than
generators.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/pdf?id=r1xMH1BtvB" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/pdf?id=r1xMH1BtvB</a>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Commission [2009]</span>
<span class="ltx_bibblock">
Korea&nbsp;Copyright Commission.

</span>
<span class="ltx_bibblock">Newspapers and copyright, 2009.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Alexis Conneau, Douwe Kiela, Holger Schwenk, Loïc Barrault, and Antoine
Bordes.

</span>
<span class="ltx_bibblock">Supervised learning of universal sentence representations from
natural language inference data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pages 670–680, Copenhagen, Denmark, September
2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D17-1070</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D17-1070" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D17-1070</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel Bowman,
Holger Schwenk, and Veselin Stoyanov.

</span>
<span class="ltx_bibblock">XNLI: Evaluating cross-lingual sentence representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2475–2485, Brussels, Belgium,
October-November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-1269</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D18-1269" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D18-1269</a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and
Veselin Stoyanov.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning at scale.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 8440–8451, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.747</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.acl-main.747" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.acl-main.747</a>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dagan et&nbsp;al. [2006]</span>
<span class="ltx_bibblock">
Ido Dagan, Oren Glickman, and Bernardo Magnini.

</span>
<span class="ltx_bibblock">The PASCAL recognising textual entailment challenge.

</span>
<span class="ltx_bibblock">In Joaquin Quiñonero-Candela, Ido Dagan, Bernardo Magnini, and
Florence d’Alché Buc, editors, <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Machine Learning Challenges.
Evaluating Predictive Uncertainty, Visual Object Classification, and
Recognising Tectual Entailment</em>, pages 177–190, Berlin, Heidelberg, 2006.
Springer Berlin Heidelberg.

</span>
<span class="ltx_bibblock">ISBN 978-3-540-33428-6.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de&nbsp;Marneffe and Manning [2008]</span>
<span class="ltx_bibblock">
Marie-Catherine de&nbsp;Marneffe and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">The Stanford typed dependencies representation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Coling 2008: Proceedings of the workshop on Cross-Framework
and Cross-Domain Parser Evaluation</em>, pages 1–8, Manchester, UK, August 2008.
Coling 2008 Organizing Committee.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W08-1301" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W08-1301</a>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de&nbsp;Marneffe et&nbsp;al. [2006]</span>
<span class="ltx_bibblock">
Marie-Catherine de&nbsp;Marneffe, Bill MacCartney, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">Generating typed dependency parses from phrase structure parses.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifth International Conference on
Language Resources and Evaluation (LREC’06)</em>, Genoa, Italy, May 2006.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="http://www.lrec-conf.org/proceedings/lrec2006/pdf/440_pdf.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.lrec-conf.org/proceedings/lrec2006/pdf/440_pdf.pdf</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171–4186,
Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1423</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N19-1423" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1423</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Doddington et&nbsp;al. [2004]</span>
<span class="ltx_bibblock">
George Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie
Strassel, and Ralph Weischedel.

</span>
<span class="ltx_bibblock">The automatic content extraction (ACE) program – tasks, data,
and evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fourth International Conference on
Language Resources and Evaluation (LREC’04)</em>, Lisbon, Portugal, May 2004.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://www.lrec-conf.org/proceedings/lrec2004/pdf/5.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.lrec-conf.org/proceedings/lrec2004/pdf/5.pdf</a>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dolan and Brockett [2005]</span>
<span class="ltx_bibblock">
William&nbsp;B. Dolan and Chris Brockett.

</span>
<span class="ltx_bibblock">Automatically constructing a corpus of sentential paraphrases.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third International Workshop on
Paraphrasing (IWP2005)</em>, 2005.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/I05-5002" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/I05-5002</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dozat and Manning [2017]</span>
<span class="ltx_bibblock">
Timothy Dozat and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">Deep biaffine attention for neural dependency parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=Hk95PK9le" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=Hk95PK9le</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eberhard and Simons [2021]</span>
<span class="ltx_bibblock">
David&nbsp;M. Eberhard and Charles&nbsp;D. Simons, Gary F.&nbsp;Fenning.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Ethnologue: Languages of the World</em>.

</span>
<span class="ltx_bibblock">SIL International, Dallas, Texas, 24 edition, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://www.ethnologue.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.ethnologue.com</a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El&nbsp;Asri et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Layla El&nbsp;Asri, Hannes Schulz, Shikhar Sharma, Jeremie Zumer, Justin Harris,
Emery Fine, Rahul Mehrotra, and Kaheer Suleman.

</span>
<span class="ltx_bibblock">Frames: a corpus for adding memory to goal-oriented dialogue
systems.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 18th Annual SIGdial Meeting on
Discourse and Dialogue</em>, pages 207–219, Saarbrücken, Germany, August
2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/W17-5526</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W17-5526" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W17-5526</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eric et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Mihail Eric, Lakshmi Krishnan, Francois Charette, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">Key-value retrieval networks for task-oriented dialogue.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 18th Annual SIGdial Meeting on
Discourse and Dialogue</em>, pages 37–49, Saarbrücken, Germany, August 2017.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/W17-5506</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W17-5506" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W17-5506</a>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eric et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit Agarwal, Shuyang
Gao, Adarsh Kumar, Anuj Goyal, Peter Ku, and Dilek Hakkani-Tur.

</span>
<span class="ltx_bibblock">MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with
state corrections and state tracking baselines.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 422–428, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.53" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.53</a>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and
Michael Auli.

</span>
<span class="ltx_bibblock">ELI5: Long form question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 3558–3567, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1346</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1346" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1346</a>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernández-González and
Gómez-Rodríguez [2019]</span>
<span class="ltx_bibblock">
Daniel Fernández-González and Carlos Gómez-Rodríguez.

</span>
<span class="ltx_bibblock">Left-to-right dependency parsing with pointer networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 710–716, Minneapolis,
Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1076</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N19-1076" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1076</a>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Finkel et&nbsp;al. [2005]</span>
<span class="ltx_bibblock">
Jenny&nbsp;Rose Finkel, Trond Grenager, and Christopher Manning.

</span>
<span class="ltx_bibblock">Incorporating non-local information into information extraction
systems by Gibbs sampling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 43rd Annual Meeting of the Association
for Computational Linguistics (ACL’05)</em>, pages 363–370, Ann Arbor,
Michigan, June 2005. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3115/1219840.1219885</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P05-1045" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P05-1045</a>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gebru et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer&nbsp;Wortman Vaughan,
Hanna Wallach, Hal Daumé&nbsp;III, and Kate Crawford.

</span>
<span class="ltx_bibblock">Datasheets for datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1803.09010</em>, 2018.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glockner et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Max Glockner, Vered Shwartz, and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Breaking NLI systems with sentences that require simple lexical
inferences.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers)</em>, pages 650–655,
Melbourne, Australia, July 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P18-2103</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P18-2103" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P18-2103</a>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grishman and Sundheim [1996]</span>
<span class="ltx_bibblock">
Ralph Grishman and Beth Sundheim.

</span>
<span class="ltx_bibblock">Message Understanding Conference- 6: A brief history.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">COLING 1996 Volume 1: The 16th International Conference on
Computational Linguistics</em>, 1996.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/C96-1079" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/C96-1079</a>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman,
and Noah&nbsp;A. Smith.

</span>
<span class="ltx_bibblock">Annotation artifacts in natural language inference data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 2 (Short Papers)</em>, pages 107–112, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N18-2017</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N18-2017" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N18-2017</a>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ham et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jiyeon Ham, Yo&nbsp;Joong Choe, Kyubyong Park, Ilji Choi, and Hyungjoon Soh.

</span>
<span class="ltx_bibblock">KorNLI and KorSTS: New benchmark datasets for Korean
natural language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020</em>, pages 422–430, Online, November 2020. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.findings-emnlp.39</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.findings-emnlp.39" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.findings-emnlp.39</a>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Ji&nbsp;Yoon Han, Tae&nbsp;Hwan Oh, Lee Jin, and Hansaem Kim.

</span>
<span class="ltx_bibblock">Annotation issues in Universal Dependencies for Korean and
Japanese.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fourth Workshop on Universal Dependencies
(UDW 2020)</em>, pages 99–108, Barcelona, Spain (Online), December 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.udw-1.12" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.udw-1.12</a>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. [2006]</span>
<span class="ltx_bibblock">
Na-Rae Han, Shijong Ryu, Sook-Hee Chae, Seung-yun Yang, Seunghun Lee, and
Martha Palmer.

</span>
<span class="ltx_bibblock">Korean treebank annotations version 2.0.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Linguistic Data Consortium (LDC), Philadelphia</em>, 2006.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Xu&nbsp;Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, and Maosong
Sun.

</span>
<span class="ltx_bibblock">FewRel: A large-scale supervised few-shot relation classification
dataset with state-of-the-art evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 4803–4809, Brussels, Belgium,
October-November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-1514</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D18-1514" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D18-1514</a>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen.

</span>
<span class="ltx_bibblock">DeBERTa: Decoding-enhanced BERT with disentangled attention.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=XPZIaotutsD" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=XPZIaotutsD</a>.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et&nbsp;al. [2014a]</span>
<span class="ltx_bibblock">
Matthew Henderson, Blaise Thomson, and Jason&nbsp;D. Williams.

</span>
<span class="ltx_bibblock">The second dialog state tracking challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th Annual Meeting of the Special
Interest Group on Discourse and Dialogue (SIGDIAL)</em>, pages 263–272,
Philadelphia, PA, U.S.A., June 2014a. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3115/v1/W14-4337</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W14-4337" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W14-4337</a>.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et&nbsp;al. [2014b]</span>
<span class="ltx_bibblock">
Matthew Henderson, Blaise Thomson, and Jason&nbsp;D Williams.

</span>
<span class="ltx_bibblock">The third dialog state tracking challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">2014 IEEE Spoken Language Technology Workshop (SLT)</em>, pages
324–329. IEEE, 2014b.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrickx et&nbsp;al. [2010]</span>
<span class="ltx_bibblock">
Iris Hendrickx, Su&nbsp;Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid
Ó&nbsp;Séaghdha, Sebastian Padó, Marco Pennacchiotti, Lorenza Romano,
and Stan Szpakowicz.

</span>
<span class="ltx_bibblock">SemEval-2010 task 8: Multi-way classification of semantic
relations between pairs of nominals.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 5th International Workshop on Semantic
Evaluation</em>, pages 33–38, Uppsala, Sweden, July 2010. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S10-1006" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S10-1006</a>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. [2020a]</span>
<span class="ltx_bibblock">
Hai Hu, Kyle Richardson, Liang Xu, Lu&nbsp;Li, Sandra Kübler, and Lawrence Moss.

</span>
<span class="ltx_bibblock">OCNLI: Original Chinese Natural Language Inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020</em>, pages 3512–3526, Online, November 2020a.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.findings-emnlp.314</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.findings-emnlp.314" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.findings-emnlp.314</a>.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. [2020b]</span>
<span class="ltx_bibblock">
Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, and
Melvin Johnson.

</span>
<span class="ltx_bibblock">XTREME: A massively multilingual multi-task benchmark for
evaluating cross-lingual generalisation.

</span>
<span class="ltx_bibblock">In Hal&nbsp;Daumé III and Aarti Singh, editors, <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
37th International Conference on Machine Learning</em>, volume 119 of
<em id="bib.bib54.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 4411–4421. PMLR,
13–18 Jul 2020b.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://proceedings.mlr.press/v119/hu20b.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://proceedings.mlr.press/v119/hu20b.html</a>.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jabbari et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Ali Jabbari, Olivier Sauvage, Hamada Zeine, and Hamza Chergui.

</span>
<span class="ltx_bibblock">A French corpus and annotation schema for named entity recognition
and relation extraction of financial news.

</span>
<span class="ltx_bibblock">In <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 2293–2299, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.279" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.279</a>.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">TriviaQA: A large scale distantly supervised challenge dataset
for reading comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1601–1611,
Vancouver, Canada, July 2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P17-1147</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P17-1147" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P17-1147</a>.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kakwani et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Divyanshu Kakwani, Anoop Kunchukuttan, Satish Golla, Gokul N.C., Avik
Bhattacharyya, Mitesh&nbsp;M. Khapra, and Pratyush Kumar.

</span>
<span class="ltx_bibblock">IndicNLPSuite: Monolingual corpora, evaluation benchmarks and
pre-trained multilingual language models for Indian languages.

</span>
<span class="ltx_bibblock">In <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020</em>, pages 4948–4961, Online, November 2020. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.findings-emnlp.445</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.findings-emnlp.445" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.findings-emnlp.445</a>.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaplan et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom&nbsp;B Brown, Benjamin Chess, Rewon
Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.

</span>
<span class="ltx_bibblock">Scaling laws for neural language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.08361</em>, 2020.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kelley [1984]</span>
<span class="ltx_bibblock">
J.&nbsp;F. Kelley.

</span>
<span class="ltx_bibblock">An iterative design methodology for user-friendly natural language
office information applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Inf. Syst.</em>, 2(1):26–41,
January 1984.

</span>
<span class="ltx_bibblock">ISSN 1046-8188.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/357417.357420</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/357417.357420" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/357417.357420</a>.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khashabi et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan
Roth.

</span>
<span class="ltx_bibblock">Looking beyond the surface: A challenge set for reading comprehension
over multiple sentences.

</span>
<span class="ltx_bibblock">In <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 252–262, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N18-1023</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N18-1023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N18-1023</a>.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khashabi et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Daniel Khashabi, Arman Cohan, Siamak Shakeri, Pedram Hosseini, Pouya
Pezeshkpour, Malihe Alikhani, Moin Aminnaseri, Marzieh Bitaab, Faeze Brahman,
Sarik Ghazarian, et&nbsp;al.

</span>
<span class="ltx_bibblock">ParsiNLU: a suite of language understanding challenges for persian.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.06154</em>, 2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kiela et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Douwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, Amanpreet Singh,
Pratik Ringshia, and Davide Testuggine.

</span>
<span class="ltx_bibblock">The hateful memes challenge: Detecting hate speech in multimodal
memes.

</span>
<span class="ltx_bibblock">In H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.&nbsp;F. Balcan, and H.&nbsp;Lin,
editors, <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume&nbsp;33,
pages 2611–2624. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/1b84c4cee2b8b3d823b30e2d604b1878-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/1b84c4cee2b8b3d823b30e2d604b1878-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Youngmin Kim, Seungyoung Lim, Hyunjeong Lee, Soyoon Park, and Myungji Kim.

</span>
<span class="ltx_bibblock">KorQuAD 2.0: Korean QA dataset for web document machine
comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Journal of KIISE</em>, 47:577–586, 2020.

</span>
<span class="ltx_bibblock">ISSN 2383-630X.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NART99691770&amp;dbt=NART" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NART99691770&amp;dbt=NART</a>.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kiperwasser and Goldberg [2016]</span>
<span class="ltx_bibblock">
Eliyahu Kiperwasser and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Simple and accurate dependency parsing using bidirectional LSTM
feature representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
4:313–327, 2016.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00101</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q16-1023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q16-1023</a>.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klein and Manning [2003]</span>
<span class="ltx_bibblock">
Dan Klein and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">Accurate unlexicalized parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 41st Annual Meeting of the Association
for Computational Linguistics</em>, pages 423–430, Sapporo, Japan, July 2003.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3115/1075096.1075150</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P03-1054" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P03-1054</a>.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ko et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Miyoung Ko, Jinhyuk Lee, Hyunjae Kim, Gangwoo Kim, and Jaewoo Kang.

</span>
<span class="ltx_bibblock">Look at the first sentence: Position bias in question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 1109–1121, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.84</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.84" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.84</a>.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krippendorff [2011]</span>
<span class="ltx_bibblock">
K.&nbsp;Krippendorff.

</span>
<span class="ltx_bibblock">Computing Krippendorff’s alpha-reliability.

</span>
<span class="ltx_bibblock">2011.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo [2006]</span>
<span class="ltx_bibblock">
Taku Kudo.

</span>
<span class="ltx_bibblock">MeCab: Yet another part-of-speech and morphological analyzer, 2006.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://taku910.github.io/mecab/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://taku910.github.io/mecab/</a>.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur
Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin,
Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang,
Andrew&nbsp;M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.

</span>
<span class="ltx_bibblock">Natural questions: A benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
7:452–466, March 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00276</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q19-1026" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q19-1026</a>.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lalor and Yu [2020]</span>
<span class="ltx_bibblock">
John&nbsp;P. Lalor and Hong Yu.

</span>
<span class="ltx_bibblock">Dynamic data selection for curriculum learning via ability
estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020</em>, pages 545–555, Online, November 2020. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.findings-emnlp.48</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.findings-emnlp.48" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.findings-emnlp.48</a>.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lan et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and
Radu Soricut.

</span>
<span class="ltx_bibblock">ALBERT: A lite BERT for self-supervised learning of language
representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=H1eA7AEtvS" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=H1eA7AEtvS</a>.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Le et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Hang Le, Loïc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux,
Benjamin Lecouteux, Alexandre Allauzen, Benoit Crabbé, Laurent Besacier,
and Didier Schwab.

</span>
<span class="ltx_bibblock">FlauBERT: Unsupervised language model pre-training for French.

</span>
<span class="ltx_bibblock">In <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 2479–2490, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.302" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.302</a>.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee [2020]</span>
<span class="ltx_bibblock">
Junbum Lee.

</span>
<span class="ltx_bibblock">KcBERT: Korean comments BERT.

</span>
<span class="ltx_bibblock">In <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd Annual Conference on Human and
Cognitive Language Technology</em>, pages 437–440, 2020.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Kyungjae Lee, Kyoungho Yoon, Sunghyun Park, and Seung-won Hwang.

</span>
<span class="ltx_bibblock">Semi-supervised training data generation for multilingual question
answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh International Conference on
Language Resources and Evaluation (LREC 2018)</em>, Miyazaki, Japan, May 2018.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/L18-1437" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/L18-1437</a>.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Sangah Lee, Hansol Jang, Yunmee Baik, Suzi Park, and Hyopil Shin.

</span>
<span class="ltx_bibblock">KR-BERT: A small-scale Korean-specific language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.03979</em>, 2020.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">BART: Denoising sequence-to-sequence pre-training for natural
language generation, translation, and comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 7871–7880, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.703</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.acl-main.703" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.acl-main.703</a>.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Shiyang Li, Semih Yavuz, Kazuma Hashimoto, Jia Li, Tong Niu, Nazneen Rajani,
Xifeng Yan, Yingbo Zhou, and Caiming Xiong.

</span>
<span class="ltx_bibblock">CoCo: Controllable counterfactuals for evaluating dialogue state
trackers.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.12850</em>, 2020.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Yaobo Liang, Nan Duan, Yeyun Gong, Ning Wu, Fenfei Guo, Weizhen Qi, Ming Gong,
Linjun Shou, Daxin Jiang, Guihong Cao, Xiaodong Fan, Ruofei Zhang, Rahul
Agrawal, Edward Cui, Sining Wei, Taroon Bharti, Ying Qiao, Jiun-Hung Chen,
Winnie Wu, Shuguang Liu, Fan Yang, Daniel Campos, Rangan Majumder, and Ming
Zhou.

</span>
<span class="ltx_bibblock">XGLUE: A new benchmark datasetfor cross-lingual pre-training,
understanding and generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 6008–6018, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.484</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.484" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.484</a>.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Seungyoung Lim, Myungji Kim, and Jooyoul Lee.

</span>
<span class="ltx_bibblock">KorQuAD1.0: Korean QA dataset for machine reading
comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.07005</em>, 2019.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin [2004]</span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">Text Summarization Branches Out</em>, pages 74–81, Barcelona,
Spain, July 2004. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W04-1013" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W04-1013</a>.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Alisa Liu, Maarten Sap, Ximing Lu, Swabha Swayamdipta, Chandra Bhagavatula,
Noah&nbsp;A. Smith, and Yejin Choi.

</span>
<span class="ltx_bibblock">On-the-fly controlled text generation with experts and anti-experts,
2021.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.

</span>
<span class="ltx_bibblock">RoBERTa: A robustly optimized BERT pretraining approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.11692</em>, 2019.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter [2019]</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=Bkg6RiCqY7" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=Bkg6RiCqY7</a>.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marcus et&nbsp;al. [1993]</span>
<span class="ltx_bibblock">
Mitchell&nbsp;P. Marcus, Beatrice Santorini, and Mary&nbsp;Ann Marcinkiewicz.

</span>
<span class="ltx_bibblock">Building a large annotated corpus of English: The Penn
Treebank.

</span>
<span class="ltx_bibblock"><em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">Computational Linguistics</em>, 19(2):313–330,
1993.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/J93-2004" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/J93-2004</a>.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCann et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Bryan McCann, Nitish&nbsp;Shirish Keskar, Caiming Xiong, and Richard Socher.

</span>
<span class="ltx_bibblock">The natural language decathlon: Multitask learning as question
answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.08730</em>, 2018.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McDonald et&nbsp;al. [2013]</span>
<span class="ltx_bibblock">
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan
Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar
Täckström, Claudia Bedini, Núria Bertomeu&nbsp;Castelló, and
Jungmee Lee.

</span>
<span class="ltx_bibblock">Universal Dependency annotation for multilingual parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers)</em>, pages 92–97, Sofia,
Bulgaria, August 2013. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P13-2017" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P13-2017</a>.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McNamee and Dang [2009]</span>
<span class="ltx_bibblock">
Paul McNamee and Hoa&nbsp;Trang Dang.

</span>
<span class="ltx_bibblock">Overview of the TAC 2009 knowledge base population track.

</span>
<span class="ltx_bibblock">In <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">Text Analysis Conference (TAC)</em>, volume&nbsp;17, pages 111–113,
2009.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehri et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Shikib Mehri, Mihail Eric, and Dilek Hakkani-Tur.

</span>
<span class="ltx_bibblock">DialoGLUE: A natural language understanding benchmark for
task-oriented dialogue.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.13570</em>, 2020.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Junghyun Min, R.&nbsp;Thomas McCoy, Dipanjan Das, Emily Pitler, and Tal Linzen.

</span>
<span class="ltx_bibblock">Syntactic data augmentation increases robustness to inference
heuristics.

</span>
<span class="ltx_bibblock">In <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 2339–2352, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.212</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.acl-main.212" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.acl-main.212</a>.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Sewon Min, Eric Wallace, Sameer Singh, Matt Gardner, Hannaneh Hajishirzi, and
Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Compositional questions do not necessitate multi-hop reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4249–4257, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1416</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1416" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1416</a>.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mintz et&nbsp;al. [2009]</span>
<span class="ltx_bibblock">
Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky.

</span>
<span class="ltx_bibblock">Distant supervision for relation extraction without labeled data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint Conference on Natural
Language Processing of the AFNLP</em>, pages 1003–1011, Suntec, Singapore,
August 2009. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P09-1113" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P09-1113</a>.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moon et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jihyung Moon, Won&nbsp;Ik Cho, and Junbum Lee.

</span>
<span class="ltx_bibblock">BEEP! Korean corpus of online news comments for toxic speech
detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighth International Workshop on Natural
Language Processing for Social Media</em>, pages 25–31, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.socialnlp-1.4</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.socialnlp-1.4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.socialnlp-1.4</a>.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nam et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Sangha Nam, Minho Lee, Donghwan Kim, Kijong Han, Kuntae Kim, Sooji Yoon,
Eun-kyung Kim, and Key-Sun Choi.

</span>
<span class="ltx_bibblock">Effective crowdsourcing of multiple tasks for comprehensive knowledge
extraction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 212–219, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.27" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.27</a>.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nangia and Bowman [2019]</span>
<span class="ltx_bibblock">
Nikita Nangia and Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">Human vs. muppet: A conservative estimate of human performance on the
GLUE benchmark.

</span>
<span class="ltx_bibblock">In <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4566–4575, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1449</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1449" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1449</a>.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nangia et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Nikita Nangia, Clara Vania, Rasika Bhalerao, and Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">CrowS-pairs: A challenge dataset for measuring social biases in
masked language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 1953–1967, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.154</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.154" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.154</a>.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan
Majumder, and Li&nbsp;Deng.

</span>
<span class="ltx_bibblock">MS MARCO: A human generated MAchine reading COmprehension
dataset.

</span>
<span class="ltx_bibblock">November 2016.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.microsoft.com/en-us/research/publication/ms-marco-human-generated-machine-reading-comprehension-dataset/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.microsoft.com/en-us/research/publication/ms-marco-human-generated-machine-reading-comprehension-dataset/</a>.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nivre et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Joakim Nivre, Marie-Catherine de&nbsp;Marneffe, Filip Ginter, Yoav Goldberg, Jan
Hajič, Christopher&nbsp;D. Manning, Ryan McDonald, Slav Petrov, Sampo
Pyysalo, Natalia Silveira, Reut Tsarfaty, and Daniel Zeman.

</span>
<span class="ltx_bibblock">Universal Dependencies v1: A multilingual treebank collection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Tenth International Conference on
Language Resources and Evaluation (LREC’16)</em>, pages 1659–1666,
Portorož, Slovenia, May 2016. European Language Resources Association
(ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/L16-1262" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/L16-1262</a>.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">of&nbsp;Korean&nbsp;Languages [2020]</span>
<span class="ltx_bibblock">
National&nbsp;Institute of&nbsp;Korean&nbsp;Languages.

</span>
<span class="ltx_bibblock">NIKL CORPORA 2020 (v.1.0), 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://corpus.korean.go.kr" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://corpus.korean.go.kr</a>.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oh et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Tae&nbsp;Hwan Oh, Ji&nbsp;Yoon Han, Hyonsu Choe, Seokwon Park, Han He, Jinho&nbsp;D. Choi,
Na-Rae Han, Jena&nbsp;D. Hwang, and Hansaem Kim.

</span>
<span class="ltx_bibblock">Analysis of the Penn Korean Universal Dependency treebank
(PKT-UD): Manual revision to build robust parsing model in Korean.

</span>
<span class="ltx_bibblock">In <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th International Conference on Parsing
Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal
Dependencies</em>, pages 122–131, Online, July 2020. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.iwpt-1.13</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.iwpt-1.13" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.iwpt-1.13</a>.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Xiaoman Pan, Boliang Zhang, Jonathan May, Joel Nothman, Kevin Knight, and Heng
Ji.

</span>
<span class="ltx_bibblock">Cross-lingual name tagging and linking for 282 languages.

</span>
<span class="ltx_bibblock">In <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1946–1958,
Vancouver, Canada, July 2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P17-1178</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P17-1178" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P17-1178</a>.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park and Cho [2014]</span>
<span class="ltx_bibblock">
Eunjeong&nbsp;L. Park and Sungzoon Cho.

</span>
<span class="ltx_bibblock">KoNLPy: Korean natural language processing in Python.

</span>
<span class="ltx_bibblock">In <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th Annual Conference on Human &amp;
Cognitive Language Technology</em>, Chuncheon, Korea, October 2014.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park [2020]</span>
<span class="ltx_bibblock">
Jangwon Park.

</span>
<span class="ltx_bibblock">KoELECTRA: Pretrained ELECTRA model for Korean.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/monologg/KoELECTRA" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/monologg/KoELECTRA</a>, 2020.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Kyubyong Park, Joohong Lee, Seongbo Jang, and Dawoon Jung.

</span>
<span class="ltx_bibblock">An empirical study of tokenization strategies for various Korean
NLP tasks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st Conference of the Asia-Pacific
Chapter of the Association for Computational Linguistics and the 10th
International Joint Conference on Natural Language Processing</em>, pages
133–142, Suzhou, China, December 2020. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.aacl-main.17" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.aacl-main.17</a>.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peters et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
Kenton Lee, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Deep contextualized word representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 2227–2237, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N18-1202</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N18-1202" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N18-1202</a>.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani,
Nicola De&nbsp;Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean
Maillard, et&nbsp;al.

</span>
<span class="ltx_bibblock">KILT: a benchmark for knowledge intensive language tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.02252</em>, 2020.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrov et&nbsp;al. [2012]</span>
<span class="ltx_bibblock">
Slav Petrov, Dipanjan Das, and Ryan McDonald.

</span>
<span class="ltx_bibblock">A universal part-of-speech tagset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighth International Conference on
Language Resources and Evaluation (LREC’12)</em>, pages 2089–2096, Istanbul,
Turkey, May 2012. European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf</a>.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Phang et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Jason Phang, Thibault Févry, and Samuel&nbsp;R Bowman.

</span>
<span class="ltx_bibblock">Sentence encoders on stilts: Supplementary training on intermediate
labeled-data tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.01088</em>, 2018.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poliak et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, and Benjamin
Van&nbsp;Durme.

</span>
<span class="ltx_bibblock">Hypothesis only baselines in natural language inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Joint Conference on Lexical and
Computational Semantics</em>, pages 180–191, New Orleans, Louisiana, June 2018.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/S18-2023</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S18-2023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S18-2023</a>.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Quan et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jun Quan, Shian Zhang, Qian Cao, Zizhong Li, and Deyi Xiong.

</span>
<span class="ltx_bibblock">RiSAWOZ: A large-scale multi-domain Wizard-of-Oz dataset with
rich semantic annotations for task-oriented dialogue modeling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 930–940, Online, November 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.67</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.67" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.67</a>.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock">2019.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J. Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 21(140):1–67, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://jmlr.org/papers/v21/20-074.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://jmlr.org/papers/v21/20-074.html</a>.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.

</span>
<span class="ltx_bibblock">SQuAD: 100,000+ questions for machine comprehension of text.

</span>
<span class="ltx_bibblock">In <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2383–2392, Austin, Texas, November 2016.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D16-1264</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D16-1264" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D16-1264</a>.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Robin Jia, and Percy Liang.

</span>
<span class="ltx_bibblock">Know what you don’t know: Unanswerable questions for SQuAD.

</span>
<span class="ltx_bibblock">In <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers)</em>, pages 784–789,
Melbourne, Australia, July 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P18-2124</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P18-2124" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P18-2124</a>.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rastogi et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav
Khaitan.

</span>
<span class="ltx_bibblock">Towards scalable multi-domain conversational agents: The
schema-guided dialogue dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>,
34(05):8689–8696, Apr. 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1609/aaai.v34i05.6394</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/6394" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ojs.aaai.org/index.php/AAAI/article/view/6394</a>.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych [2019]</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych.

</span>
<span class="ltx_bibblock">Sentence-BERT: Sentence embeddings using Siamese BERT-networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 3982–3992, Hong Kong,
China, November 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D19-1410</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D19-1410" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D19-1410</a>.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Riedel et&nbsp;al. [2010]</span>
<span class="ltx_bibblock">
Sebastian Riedel, Limin Yao, and Andrew McCallum.

</span>
<span class="ltx_bibblock">Modeling relations and their mentions without labeled text.

</span>
<span class="ltx_bibblock">In José&nbsp;Luis Balcázar, Francesco Bonchi, Aristides Gionis,
and Michèle Sebag, editors, <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">Machine Learning and Knowledge
Discovery in Databases</em>, pages 148–163, Berlin, Heidelberg, 2010. Springer
Berlin Heidelberg.

</span>
<span class="ltx_bibblock">ISBN 978-3-642-15939-8.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ritter et&nbsp;al. [2011]</span>
<span class="ltx_bibblock">
Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.

</span>
<span class="ltx_bibblock">Named entity recognition in tweets: An experimental study.

</span>
<span class="ltx_bibblock">In <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2011 Conference on Empirical Methods in
Natural Language Processing</em>, pages 1524–1534, Edinburgh, Scotland, UK.,
July 2011. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D11-1141" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D11-1141</a>.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson et&nbsp;al. [1995]</span>
<span class="ltx_bibblock">
Stephen&nbsp;E Robertson, Steve Walker, Susan Jones, Micheline&nbsp;M Hancock-Beaulieu,
Mike Gatford, et&nbsp;al.

</span>
<span class="ltx_bibblock">Okapi at trec-3.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">Nist Special Publication Sp</em>, 109:109, 1995.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rust et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Phillip Rust, Jonas Pfeiffer, Ivan Vulić, Sebastian Ruder, and Iryna
Gurevych.

</span>
<span class="ltx_bibblock">How good is your tokenizer? on the monolingual performance of
multilingual language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.15613</em>, 2020.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saha et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Amrita Saha, Rahul Aralikatte, Mitesh&nbsp;M. Khapra, and Karthik Sankaranarayanan.

</span>
<span class="ltx_bibblock">DuoRC: Towards complex language understanding with paraphrased
reading comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1683–1693,
Melbourne, Australia, July 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P18-1156</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P18-1156" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P18-1156</a>.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schiersch et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Martin Schiersch, Veselina Mironova, Maximilian Schmitt, Philippe Thomas,
Aleksandra Gabryszak, and Leonhard Hennig.

</span>
<span class="ltx_bibblock">A German corpus for fine-grained named entity recognition and
relation extraction of traffic and industry events.

</span>
<span class="ltx_bibblock">In <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh International Conference on
Language Resources and Evaluation (LREC 2018)</em>, Miyazaki, Japan, May 2018.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/L18-1703" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/L18-1703</a>.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sen and Saffari [2020]</span>
<span class="ltx_bibblock">
Priyanka Sen and Amir Saffari.

</span>
<span class="ltx_bibblock">What do models learn from question answering datasets?

</span>
<span class="ltx_bibblock">In <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 2429–2438, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.190</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.190" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.190</a>.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch.

</span>
<span class="ltx_bibblock">Neural machine translation of rare words with subword units.

</span>
<span class="ltx_bibblock">In <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 54th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1715–1725,
Berlin, Germany, August 2016. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P16-1162</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P16-1162" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P16-1162</a>.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shah et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Pararth Shah, Dilek Hakkani-Tür, Gokhan Tür, Abhinav Rastogi, Ankur
Bapna, Neha Nayak, and Larry Heck.

</span>
<span class="ltx_bibblock">Building a conversational agent overnight with dialogue self-play.

</span>
<span class="ltx_bibblock"><em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1801.04871</em>, 2018.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shavrina et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Tatiana Shavrina, Alena Fenogenova, Emelyanov Anton, Denis Shevelev, Ekaterina
Artemova, Valentin Malykh, Vladislav Mikhailov, Maria Tikhonova, Andrey
Chertok, and Andrey Evlampiev.

</span>
<span class="ltx_bibblock">RussianSuperGLUE: A Russian language understanding evaluation
benchmark.

</span>
<span class="ltx_bibblock">In <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 4717–4726, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.381</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.381" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.381</a>.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Socher et&nbsp;al. [2013]</span>
<span class="ltx_bibblock">
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher&nbsp;D. Manning,
Andrew Ng, and Christopher Potts.

</span>
<span class="ltx_bibblock">Recursive deep models for semantic compositionality over a sentiment
treebank.

</span>
<span class="ltx_bibblock">In <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2013 Conference on Empirical Methods in
Natural Language Processing</em>, pages 1631–1642, Seattle, Washington, USA,
October 2013. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D13-1170" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D13-1170</a>.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strauss et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Benjamin Strauss, Bethany Toma, Alan Ritter, Marie-Catherine de&nbsp;Marneffe, and
Wei Xu.

</span>
<span class="ltx_bibblock">Results of the WNUT16 named entity recognition shared task.

</span>
<span class="ltx_bibblock">In <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd Workshop on Noisy User-generated Text
(WNUT)</em>, pages 138–144, Osaka, Japan, December 2016. The COLING 2016
Organizing Committee.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W16-3919" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W16-3919</a>.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">sun Choi et&nbsp;al. [1994]</span>
<span class="ltx_bibblock">
Key sun Choi, Young&nbsp;S. Han, Young&nbsp;G. Han, and Oh&nbsp;W. Kwon.

</span>
<span class="ltx_bibblock">KAIST tree bank project for Korean: Present and future
development.

</span>
<span class="ltx_bibblock">In <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">In Proceedings of the International Workshop on Sharable
Natural Language Resources</em>, pages 7–14, 1994.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tjong Kim&nbsp;Sang and
De&nbsp;Meulder [2003]</span>
<span class="ltx_bibblock">
Erik&nbsp;F. Tjong Kim&nbsp;Sang and Fien De&nbsp;Meulder.

</span>
<span class="ltx_bibblock">Introduction to the CoNLL-2003 shared task: Language-independent
named entity recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Conference on Natural Language
Learning at HLT-NAACL 2003</em>, pages 142–147, 2003.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W03-0419" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W03-0419</a>.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trischler et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni,
Philip Bachman, and Kaheer Suleman.

</span>
<span class="ltx_bibblock">NewsQA: A machine comprehension dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd Workshop on Representation Learning
for NLP</em>, pages 191–200, Vancouver, Canada, August 2017. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/W17-2623</span>.

</span>
<span class="ltx_bibblock">URL <a href="<https://www.aclweb.org/anthology/W17-2623>" title="" class="ltx_ref ltx_url ltx_font_typewriter">&lt;https://www.aclweb.org/anthology/W17-2623&gt;</a>.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vania et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Clara Vania, Ruijie Chen, and Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">Asking Crowdworkers to Write Entailment Examples: The
Best of Bad options.

</span>
<span class="ltx_bibblock">In <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st Conference of the Asia-Pacific
Chapter of the Association for Computational Linguistics and the 10th
International Joint Conference on Natural Language Processing</em>, pages
672–686, Suzhou, China, December 2020. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.aacl-main.68" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.aacl-main.68</a>.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2019a]</span>
<span class="ltx_bibblock">
Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael,
Felix Hill, Omer Levy, and Samuel Bowman.

</span>
<span class="ltx_bibblock">SuperGLUE: A stickier benchmark for general-purpose language
understanding systems.

</span>
<span class="ltx_bibblock">In H.&nbsp;Wallach, H.&nbsp;Larochelle, A.&nbsp;Beygelzimer, F.&nbsp;d'Alché-Buc, E.&nbsp;Fox, and R.&nbsp;Garnett, editors, <em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, volume&nbsp;32. Curran Associates, Inc.,
2019a.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2019b]</span>
<span class="ltx_bibblock">
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and
Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">GLUE: A multi-task benchmark and analysis platform for natural
language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>,
2019b.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=rJ4km2R5t7" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=rJ4km2R5t7</a>.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warstadt et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Alex Warstadt, Amanpreet Singh, and Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">Neural network acceptability judgments.

</span>
<span class="ltx_bibblock"><em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
7:625–641, March 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00290</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q19-1040" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q19-1040</a>.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Tsung-Hsien Wen, David Vandyke, Nikola Mrkšić, Milica
Gašić, Lina&nbsp;M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, and Steve
Young.

</span>
<span class="ltx_bibblock">A network-based end-to-end trainable task-oriented dialogue system.

</span>
<span class="ltx_bibblock">In <em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th Conference of the European Chapter
of the Association for Computational Linguistics: Volume 1, Long Papers</em>,
pages 438–449, Valencia, Spain, April 2017. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/E17-1042" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/E17-1042</a>.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wenzek et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary,
Francisco Guzmán, Armand Joulin, and Edouard Grave.

</span>
<span class="ltx_bibblock">CCNet: Extracting high quality monolingual datasets from web crawl
data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 4003–4012, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.494" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.494</a>.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilie et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Bryan Wilie, Karissa Vincentio, Genta&nbsp;Indra Winata, Samuel Cahyawijaya,
Xiaohong Li, Zhi&nbsp;Yuan Lim, Sidik Soleman, Rahmad Mahendra, Pascale Fung,
Syafri Bahar, and Ayu Purwarianti.

</span>
<span class="ltx_bibblock">IndoNLU: Benchmark and resources for evaluating Indonesian
natural language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st Conference of the Asia-Pacific
Chapter of the Association for Computational Linguistics and the 10th
International Joint Conference on Natural Language Processing</em>, pages
843–857, Suzhou, China, December 2020. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.aacl-main.85" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.aacl-main.85</a>.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Adina Williams, Nikita Nangia, and Samuel Bowman.

</span>
<span class="ltx_bibblock">A broad-coverage challenge corpus for sentence understanding through
inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 1112–1122, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N18-1101</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N18-1101" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N18-1101</a>.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe
Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
Plu, Canwen Xu, Teven Le&nbsp;Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
and Alexander Rush.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing: System Demonstrations</em>, pages 38–45, Online,
October 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-demos.6</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-demos.6" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-demos.6</a>.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard
Socher, and Pascale Fung.

</span>
<span class="ltx_bibblock">Transferable multi-domain state generator for task-oriented dialogue
systems.

</span>
<span class="ltx_bibblock">In <em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 808–819, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1078</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1078" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1078</a>.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Jingjing Xu, Ji&nbsp;Wen, Xu&nbsp;Sun, and Qi&nbsp;Su.

</span>
<span class="ltx_bibblock">A discourse-level named entity recognition and relation extraction
dataset for Chinese literature text.

</span>
<span class="ltx_bibblock"><em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.07010</em>, 2017.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Liang Xu, Hai Hu, Xuanwei Zhang, Lu&nbsp;Li, Chenjie Cao, Yudong Li, Yechen Xu, Kai
Sun, Dian Yu, Cong Yu, Yin Tian, Qianqian Dong, Weitang Liu, Bo&nbsp;Shi, Yiming
Cui, Junyi Li, Jun Zeng, Rongzhao Wang, Weijian Xie, Yanting Li, Yina
Patterson, Zuoyu Tian, Yiwen Zhang, He&nbsp;Zhou, Shaoweihua Liu, Zhe Zhao, Qipeng
Zhao, Cong Yue, Xinrui Zhang, Zhengliang Yang, Kyle Richardson, and Zhenzhong
Lan.

</span>
<span class="ltx_bibblock">CLUE: A Chinese language understanding evaluation benchmark.

</span>
<span class="ltx_bibblock">In <em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on
Computational Linguistics</em>, pages 4762–4772, Barcelona, Spain (Online),
December 2020. International Committee on Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.coling-main.419</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.coling-main.419" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.coling-main.419</a>.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. [2015]</span>
<span class="ltx_bibblock">
Yi&nbsp;Yang, Wen-tau Yih, and Christopher Meek.

</span>
<span class="ltx_bibblock">WikiQA: A challenge dataset for open-domain question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2013–2018, Lisbon, Portugal, September
2015. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D15-1237</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D15-1237" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D15-1237</a>.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. [2019a]</span>
<span class="ltx_bibblock">
Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge.

</span>
<span class="ltx_bibblock">PAWS-X: A cross-lingual adversarial dataset for paraphrase
identification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 3687–3692, Hong Kong,
China, November 2019a. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D19-1382</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D19-1382" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D19-1382</a>.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan
Salakhutdinov, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">HotpotQA: A dataset for diverse, explainable multi-hop question
answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2369–2380, Brussels, Belgium,
October-November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-1259</span>.

</span>
<span class="ltx_bibblock">URL <a href="<https://www.aclweb.org/anthology/D18-1259>" title="" class="ltx_ref ltx_url ltx_font_typewriter">&lt;https://www.aclweb.org/anthology/D18-1259&gt;</a>.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. [2019b]</span>
<span class="ltx_bibblock">
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ&nbsp;R Salakhutdinov,
and Quoc&nbsp;V Le.

</span>
<span class="ltx_bibblock">XLNet: Generalized autoregressive pretraining for language
understanding.

</span>
<span class="ltx_bibblock">In H.&nbsp;Wallach, H.&nbsp;Larochelle, A.&nbsp;Beygelzimer, F.&nbsp;d'Alché-Buc, E.&nbsp;Fox, and R.&nbsp;Garnett, editors, <em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, volume&nbsp;32. Curran Associates, Inc.,
2019b.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Yuan Yao, Deming Ye, Peng Li, Xu&nbsp;Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu,
Lixin Huang, Jie Zhou, and Maosong Sun.

</span>
<span class="ltx_bibblock">DocRED: A large-scale document-level relation extraction dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 764–777, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1074</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1074" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1074</a>.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Young et&nbsp;al. [2014]</span>
<span class="ltx_bibblock">
Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier.

</span>
<span class="ltx_bibblock">From image descriptions to visual denotations: New similarity metrics
for semantic inference over event descriptions.

</span>
<span class="ltx_bibblock"><em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
2:67–78, 2014.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00166</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q14-1006" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q14-1006</a>.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Dian Yu, Kai Sun, Claire Cardie, and Dong Yu.

</span>
<span class="ltx_bibblock">Dialogue-based relation extraction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4927–4940, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.444</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.acl-main.444" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.acl-main.444</a>.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, and Benjamin
Van&nbsp;Durme.

</span>
<span class="ltx_bibblock">ReCoRD: Bridging the gap between human and machine commonsense
reading comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.12885</em>, 2018.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. [2015]</span>
<span class="ltx_bibblock">
Xiang Zhang, Junbo Zhao, and Yann LeCun.

</span>
<span class="ltx_bibblock">Character-level convolutional networks for text classification.

</span>
<span class="ltx_bibblock">In C.&nbsp;Cortes, N.&nbsp;Lawrence, D.&nbsp;Lee, M.&nbsp;Sugiyama, and R.&nbsp;Garnett,
editors, <em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume&nbsp;28.
Curran Associates, Inc., 2015.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Yuan Zhang, Jason Baldridge, and Luheng He.

</span>
<span class="ltx_bibblock">PAWS: Paraphrase adversaries from word scrambling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 1298–1308,
Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1131</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N19-1131" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1131</a>.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, and Christopher&nbsp;D.
Manning.

</span>
<span class="ltx_bibblock">Position-aware attention and supervised data improve slot filling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pages 35–45, Copenhagen, Denmark, September
2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D17-1004</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D17-1004" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D17-1004</a>.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Qi&nbsp;Zhu, Kaili Huang, Zheng Zhang, Xiaoyan Zhu, and Minlie Huang.

</span>
<span class="ltx_bibblock">CrossWOZ: A large-scale Chinese cross-domain task-oriented
dialogue dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
8:281–295, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00314</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.tacl-1.19" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.tacl-1.19</a>.

</span>
</li>
</ul>
</section>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined">\printindex</span>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">Contribution</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p"><span id="Sx2.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Sungjoon Park</span><span id="Sx2.p1.1.2" class="ltx_text" style="font-size:90%;"> led the project as project manager, initiated the project, made decisions on overall progress of this project, secured financial resources, signed up with ACROFAN for the articles, and organized IRB submission and research paper.</span></p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p id="Sx2.p2.1" class="ltx_p"><span id="Sx2.p2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Jihyung Moon</span><span id="Sx2.p2.1.2" class="ltx_text" style="font-size:90%;"> led the project as project manager, managed overall datasets, models, and ethical concerns, signed up with ACROFAN for the articles, prepared IRB, as well as contributed to NER, STS, NLI, MRC dataset constructions, AIRBNB, POLICY corpora collection, and leaderboard design.</span></p>
</div>
<div id="Sx2.p3" class="ltx_para">
<p id="Sx2.p3.1" class="ltx_p"><span id="Sx2.p3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Sungdong Kim</span><span id="Sx2.p3.1.2" class="ltx_text" style="font-size:90%;"> managed overall fine-tuning of language models, served as a person in charge (PIC) of DST, and contributed to the dataset construction of TC, STS, and RE.</span></p>
</div>
<div id="Sx2.p4" class="ltx_para">
<p id="Sx2.p4.1" class="ltx_p"><span id="Sx2.p4.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Won Ik Cho</span><span id="Sx2.p4.1.2" class="ltx_text" style="font-size:90%;"> managed the overall dataset construction of TC, STS, NLI, RE, MRC, and DST, provided the original corpus of PARAKQC, and served as a PIC of STS.</span></p>
</div>
<div id="Sx2.p5" class="ltx_para">
<p id="Sx2.p5.1" class="ltx_p"><span id="Sx2.p5.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Jiyoon Han</span><span id="Sx2.p5.1.2" class="ltx_text" style="font-size:90%;"> managed the overall dataset construction of DP and NER, served as a PIC of NLI, contributed to the dataset construction of STS, and took part in preparing IRB.</span></p>
</div>
<div id="Sx2.p6" class="ltx_para">
<p id="Sx2.p6.1" class="ltx_p"><span id="Sx2.p6.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Jangwon Park</span><span id="Sx2.p6.1.2" class="ltx_text" style="font-size:90%;"> served as a PIC of model pretraining, contributed to the text collection of YNA, collected and pre-processed MODU, CC-100-Kor, NAMUWIKI, NEWSCRAWL, and PETITION, and conducted the fine-tuning of TC.</span></p>
</div>
<div id="Sx2.p7" class="ltx_para">
<p id="Sx2.p7.1" class="ltx_p"><span id="Sx2.p7.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Chisung Song</span><span id="Sx2.p7.1.2" class="ltx_text" style="font-size:90%;"> served as a PIC of NER and contributed to the dataset construction of DP and DST.</span></p>
</div>
<div id="Sx2.p8" class="ltx_para">
<p id="Sx2.p8.1" class="ltx_p"><span id="Sx2.p8.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Junseong Kim</span><span id="Sx2.p8.1.2" class="ltx_text" style="font-size:90%;"> served as a PIC of MRC, conducted the fine-tuning of MRC, and contributed to the text collection of WIKITREE and WIKIPEDIA.</span></p>
</div>
<div id="Sx2.p9" class="ltx_para">
<p id="Sx2.p9.1" class="ltx_p"><span id="Sx2.p9.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Youngsook Song</span><span id="Sx2.p9.1.2" class="ltx_text" style="font-size:90%;"> served as a PIC of TC and contributed to the dataset construction of NER and DST.</span></p>
</div>
<div id="Sx2.p10" class="ltx_para">
<p id="Sx2.p10.1" class="ltx_p"><span id="Sx2.p10.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Taehwan Oh</span><span id="Sx2.p10.1.2" class="ltx_text" style="font-size:90%;"> served as a PIC of DP, contributed to the dataset construction of NER and NLI, and took part in preparing IRB.</span></p>
</div>
<div id="Sx2.p11" class="ltx_para">
<p id="Sx2.p11.1" class="ltx_p"><span id="Sx2.p11.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Joohong Lee</span><span id="Sx2.p11.1.2" class="ltx_text" style="font-size:90%;"> served as a PIC of RE, and conducted the fine-tuning of RE.</span></p>
</div>
<div id="Sx2.p12" class="ltx_para">
<p id="Sx2.p12.1" class="ltx_p"><span id="Sx2.p12.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Juhyun Oh</span><span id="Sx2.p12.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of NLI, NER, DP and STS, took part in ethical considerations, IRB preparation and setup for model pretraining.</span></p>
</div>
<div id="Sx2.p13" class="ltx_para">
<p id="Sx2.p13.1" class="ltx_p"><span id="Sx2.p13.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Sungwon Lyu</span><span id="Sx2.p13.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of STS, NLI, RE, and MRC, taking part in the overall model pretraining and task-wise fine-tuning.</span></p>
</div>
<div id="Sx2.p14" class="ltx_para">
<p id="Sx2.p14.1" class="ltx_p"><span id="Sx2.p14.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Younghoon Jeong</span><span id="Sx2.p14.1.2" class="ltx_text" style="font-size:90%;"> contributed to the text collection of WIKINEWS, modeling of DP, and pre-processing of the pretraining corpus.</span></p>
</div>
<div id="Sx2.p15" class="ltx_para">
<p id="Sx2.p15.1" class="ltx_p"><span id="Sx2.p15.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Inkwon Lee</span><span id="Sx2.p15.1.2" class="ltx_text" style="font-size:90%;"> contributed to the text collection, modeling of DP and pre-processing of the pretraining corpus.</span></p>
</div>
<div id="Sx2.p16" class="ltx_para">
<p id="Sx2.p16.1" class="ltx_p"><span id="Sx2.p16.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Sangwoo Seo</span><span id="Sx2.p16.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of RE, and took part in preparing IRB.</span></p>
</div>
<div id="Sx2.p17" class="ltx_para">
<p id="Sx2.p17.1" class="ltx_p"><span id="Sx2.p17.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Dongjun Lee</span><span id="Sx2.p17.1.2" class="ltx_text" style="font-size:90%;"> contributed to the construction of the fine-tuning pipeline and the modeling of STS.</span></p>
</div>
<div id="Sx2.p18" class="ltx_para">
<p id="Sx2.p18.1" class="ltx_p"><span id="Sx2.p18.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Hyunwoo Kim</span><span id="Sx2.p18.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of MRC, and took part in preparing IRB.</span></p>
</div>
<div id="Sx2.p19" class="ltx_para">
<p id="Sx2.p19.1" class="ltx_p"><span id="Sx2.p19.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Myeonghwa Lee</span><span id="Sx2.p19.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of STS and TC.</span></p>
</div>
<div id="Sx2.p20" class="ltx_para">
<p id="Sx2.p20.1" class="ltx_p"><span id="Sx2.p20.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Seongbo Jang</span><span id="Sx2.p20.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of RE, and took part in preparing IRB.</span></p>
</div>
<div id="Sx2.p21" class="ltx_para">
<p id="Sx2.p21.1" class="ltx_p"><span id="Sx2.p21.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Seungwon Do</span><span id="Sx2.p21.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of DST and text collection.</span></p>
</div>
<div id="Sx2.p22" class="ltx_para">
<p id="Sx2.p22.1" class="ltx_p"><span id="Sx2.p22.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Sunkyoung Kim</span><span id="Sx2.p22.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of RE and MRC, and modeling of MRC.</span></p>
</div>
<div id="Sx2.p23" class="ltx_para">
<p id="Sx2.p23.1" class="ltx_p"><span id="Sx2.p23.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Kyungtae Lim</span><span id="Sx2.p23.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of DP.</span></p>
</div>
<div id="Sx2.p24" class="ltx_para">
<p id="Sx2.p24.1" class="ltx_p"><span id="Sx2.p24.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Jongwon Lee</span><span id="Sx2.p24.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction and modeling of DST.</span></p>
</div>
<div id="Sx2.p25" class="ltx_para">
<p id="Sx2.p25.1" class="ltx_p"><span id="Sx2.p25.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Kyumin Park</span><span id="Sx2.p25.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of DST, and took part in preparing IRB.</span></p>
</div>
<div id="Sx2.p26" class="ltx_para">
<p id="Sx2.p26.1" class="ltx_p"><span id="Sx2.p26.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Jamin Shin</span><span id="Sx2.p26.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of DST.</span></p>
</div>
<div id="Sx2.p27" class="ltx_para">
<p id="Sx2.p27.1" class="ltx_p"><span id="Sx2.p27.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Seonghyun Kim</span><span id="Sx2.p27.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction and modeling of NER.</span></p>
</div>
<div id="Sx2.p28" class="ltx_para">
<p id="Sx2.p28.1" class="ltx_p"><span id="Sx2.p28.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Lucy Park</span><span id="Sx2.p28.1.2" class="ltx_text" style="font-size:90%;"> contributed to the dataset construction of MRC and provided the original corpus of NSMC.</span></p>
</div>
<div id="Sx2.p29" class="ltx_para">
<p id="Sx2.p29.1" class="ltx_p"><span id="Sx2.p29.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Alice Oh</span><span id="Sx2.p29.1.2" class="ltx_text" style="font-size:90%;"> advised the project, sponsored the project via KAIST, provided feedback and suggested better way to improve the quality of our dataset and models, and helped with the final manuscript.</span></p>
</div>
<div id="Sx2.p30" class="ltx_para">
<p id="Sx2.p30.1" class="ltx_p"><span id="Sx2.p30.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Jung-Woo Ha</span><span id="Sx2.p30.1.2" class="ltx_text" style="font-size:90%;"> advised the project, sponsored annotation cost and computing cloud credits the project via NAVER, provided license-free news articles from The Korea Economy Daily, and helped with the final manuscript.</span></p>
</div>
<div id="Sx2.p31" class="ltx_para">
<p id="Sx2.p31.1" class="ltx_p"><span id="Sx2.p31.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Kyunghyun Cho</span><span id="Sx2.p31.1.2" class="ltx_text" style="font-size:90%;"> advised the project, provided critical feedback, suggested better way to improve the quality of our dataset and models, and helped a lot with polishing and rewriting the final manuscript.</span></p>
</div>
<div id="Sx2.p32" class="ltx_para">
<p id="Sx2.p32.1" class="ltx_p"><span id="Sx2.p32.1.1" class="ltx_text" style="font-size:90%;">All participants contributed to this manuscript.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Dev Set Results</h2>

<figure id="A1.T36" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 36: </span>Performances of our pretrained LMs and other baselines on KLUE benchmark dev set. The notations are same with Table <a href="#S5.T32" title="Table 32 ‣ 5.3 Evaluation Results ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">32</span></a>.</figcaption>
<div id="A1.T36.14" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:595.1pt;height:199pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="A1.T36.14.14" class="ltx_p"><span id="A1.T36.14.14.14" class="ltx_text" style="font-size:90%;">
<span id="A1.T36.14.14.14.14" class="ltx_tabular ltx_align_middle">
<span id="A1.T36.14.14.14.14.15" class="ltx_tr">
<span id="A1.T36.14.14.14.14.15.1" class="ltx_td ltx_border_tt"></span>
<span id="A1.T36.14.14.14.14.15.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T36.14.14.14.14.15.2.1" class="ltx_text ltx_font_bold">YNAT</span></span>
<span id="A1.T36.14.14.14.14.15.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.3.1" class="ltx_text ltx_font_bold">KLUE-STS</span></span>
<span id="A1.T36.14.14.14.14.15.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T36.14.14.14.14.15.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></span>
<span id="A1.T36.14.14.14.14.15.5" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.5.1" class="ltx_text ltx_font_bold">KLUE-NER</span></span>
<span id="A1.T36.14.14.14.14.15.6" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.6.1" class="ltx_text ltx_font_bold">KLUE-RE</span></span>
<span id="A1.T36.14.14.14.14.15.7" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.7.1" class="ltx_text ltx_font_bold">KLUE-DP</span></span>
<span id="A1.T36.14.14.14.14.15.8" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.8.1" class="ltx_text ltx_font_bold">KLUE-MRC</span></span>
<span id="A1.T36.14.14.14.14.15.9" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.9.1" class="ltx_text ltx_font_bold">WoS</span></span></span>
<span id="A1.T36.5.5.5.5.5" class="ltx_tr">
<span id="A1.T36.5.5.5.5.5.6" class="ltx_td ltx_align_left"><span id="A1.T36.5.5.5.5.5.6.1" class="ltx_text ltx_font_bold">Model</span></span>
<span id="A1.T36.5.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">F1</span>
<span id="A1.T36.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">R<sup id="A1.T36.1.1.1.1.1.1.1" class="ltx_sup"><span id="A1.T36.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">P</span></sup></span>
<span id="A1.T36.5.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">F1</span>
<span id="A1.T36.5.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t">ACC</span>
<span id="A1.T36.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="A1.T36.2.2.2.2.2.2.1" class="ltx_sup"><span id="A1.T36.2.2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">E</span></sup></span>
<span id="A1.T36.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="A1.T36.3.3.3.3.3.3.1" class="ltx_sup"><span id="A1.T36.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">C</span></sup></span>
<span id="A1.T36.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="A1.T36.4.4.4.4.4.4.1" class="ltx_sup"><span id="A1.T36.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">mic</span></sup></span>
<span id="A1.T36.5.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_t">AUC</span>
<span id="A1.T36.5.5.5.5.5.11" class="ltx_td ltx_align_center ltx_border_t">UAS</span>
<span id="A1.T36.5.5.5.5.5.12" class="ltx_td ltx_align_center ltx_border_t">LAS</span>
<span id="A1.T36.5.5.5.5.5.13" class="ltx_td ltx_align_center ltx_border_t">EM</span>
<span id="A1.T36.5.5.5.5.5.14" class="ltx_td ltx_align_center ltx_border_t">ROUGE</span>
<span id="A1.T36.5.5.5.5.5.15" class="ltx_td ltx_align_center ltx_border_t">JGA</span>
<span id="A1.T36.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="A1.T36.5.5.5.5.5.5.1" class="ltx_sup"><span id="A1.T36.5.5.5.5.5.5.1.1" class="ltx_text ltx_font_italic">S</span></sup></span></span>
<span id="A1.T36.6.6.6.6.6" class="ltx_tr">
<span id="A1.T36.6.6.6.6.6.1" class="ltx_td ltx_align_left ltx_border_t"><math id="A1.T36.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\text{mBERT}_{\text{BASE}}" display="inline"><semantics id="A1.T36.6.6.6.6.6.1.m1.1a"><msub id="A1.T36.6.6.6.6.6.1.m1.1.1" xref="A1.T36.6.6.6.6.6.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.6.6.6.6.6.1.m1.1.1.2" xref="A1.T36.6.6.6.6.6.1.m1.1.1.2a.cmml">mBERT</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.6.6.6.6.6.1.m1.1.1.3" xref="A1.T36.6.6.6.6.6.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.6.6.6.6.6.1.m1.1b"><apply id="A1.T36.6.6.6.6.6.1.m1.1.1.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.6.6.6.6.6.1.m1.1.1.1.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1">subscript</csymbol><ci id="A1.T36.6.6.6.6.6.1.m1.1.1.2a.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.6.6.6.6.6.1.m1.1.1.2.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1.2">mBERT</mtext></ci><ci id="A1.T36.6.6.6.6.6.1.m1.1.1.3a.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.6.6.6.6.6.1.m1.1.1.3.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.6.6.6.6.6.1.m1.1c">\text{mBERT}_{\text{BASE}}</annotation></semantics></math></span>
<span id="A1.T36.6.6.6.6.6.2" class="ltx_td ltx_align_center ltx_border_t">82.64</span>
<span id="A1.T36.6.6.6.6.6.3" class="ltx_td ltx_align_center ltx_border_t">82.97</span>
<span id="A1.T36.6.6.6.6.6.4" class="ltx_td ltx_align_center ltx_border_t">75.93</span>
<span id="A1.T36.6.6.6.6.6.5" class="ltx_td ltx_align_center ltx_border_t">72.90</span>
<span id="A1.T36.6.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t">75.56</span>
<span id="A1.T36.6.6.6.6.6.7" class="ltx_td ltx_align_center ltx_border_t">88.81</span>
<span id="A1.T36.6.6.6.6.6.8" class="ltx_td ltx_align_center ltx_border_t">58.39</span>
<span id="A1.T36.6.6.6.6.6.9" class="ltx_td ltx_align_center ltx_border_t">56.41</span>
<span id="A1.T36.6.6.6.6.6.10" class="ltx_td ltx_align_center ltx_border_t">88.53</span>
<span id="A1.T36.6.6.6.6.6.11" class="ltx_td ltx_align_center ltx_border_t">86.04</span>
<span id="A1.T36.6.6.6.6.6.12" class="ltx_td ltx_align_center ltx_border_t">49.96</span>
<span id="A1.T36.6.6.6.6.6.13" class="ltx_td ltx_align_center ltx_border_t">55.57</span>
<span id="A1.T36.6.6.6.6.6.14" class="ltx_td ltx_align_center ltx_border_t">35.27</span>
<span id="A1.T36.6.6.6.6.6.15" class="ltx_td ltx_align_center ltx_border_t">88.60</span></span>
<span id="A1.T36.7.7.7.7.7" class="ltx_tr">
<span id="A1.T36.7.7.7.7.7.1" class="ltx_td ltx_align_left"><math id="A1.T36.7.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\text{XLM-R}_{\text{BASE}}" display="inline"><semantics id="A1.T36.7.7.7.7.7.1.m1.1a"><msub id="A1.T36.7.7.7.7.7.1.m1.1.1" xref="A1.T36.7.7.7.7.7.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.7.7.7.7.7.1.m1.1.1.2" xref="A1.T36.7.7.7.7.7.1.m1.1.1.2a.cmml">XLM-R</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.7.7.7.7.7.1.m1.1.1.3" xref="A1.T36.7.7.7.7.7.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.7.7.7.7.7.1.m1.1b"><apply id="A1.T36.7.7.7.7.7.1.m1.1.1.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.7.7.7.7.7.1.m1.1.1.1.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1">subscript</csymbol><ci id="A1.T36.7.7.7.7.7.1.m1.1.1.2a.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.7.7.7.7.7.1.m1.1.1.2.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1.2">XLM-R</mtext></ci><ci id="A1.T36.7.7.7.7.7.1.m1.1.1.3a.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.7.7.7.7.7.1.m1.1.1.3.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.7.7.7.7.7.1.m1.1c">\text{XLM-R}_{\text{BASE}}</annotation></semantics></math></span>
<span id="A1.T36.7.7.7.7.7.2" class="ltx_td ltx_align_center">84.52</span>
<span id="A1.T36.7.7.7.7.7.3" class="ltx_td ltx_align_center">88.88</span>
<span id="A1.T36.7.7.7.7.7.4" class="ltx_td ltx_align_center">81.20</span>
<span id="A1.T36.7.7.7.7.7.5" class="ltx_td ltx_align_center">78.23</span>
<span id="A1.T36.7.7.7.7.7.6" class="ltx_td ltx_align_center">80.48</span>
<span id="A1.T36.7.7.7.7.7.7" class="ltx_td ltx_align_center">92.14</span>
<span id="A1.T36.7.7.7.7.7.8" class="ltx_td ltx_align_center">57.62</span>
<span id="A1.T36.7.7.7.7.7.9" class="ltx_td ltx_align_center">57.05</span>
<span id="A1.T36.7.7.7.7.7.10" class="ltx_td ltx_align_center">93.12</span>
<span id="A1.T36.7.7.7.7.7.11" class="ltx_td ltx_align_center">87.23</span>
<span id="A1.T36.7.7.7.7.7.12" class="ltx_td ltx_align_center">26.76</span>
<span id="A1.T36.7.7.7.7.7.13" class="ltx_td ltx_align_center">53.36</span>
<span id="A1.T36.7.7.7.7.7.14" class="ltx_td ltx_align_center">41.54</span>
<span id="A1.T36.7.7.7.7.7.15" class="ltx_td ltx_align_center">89.81</span></span>
<span id="A1.T36.8.8.8.8.8" class="ltx_tr">
<span id="A1.T36.8.8.8.8.8.1" class="ltx_td ltx_align_left"><math id="A1.T36.8.8.8.8.8.1.m1.1" class="ltx_Math" alttext="\text{XLM-R}_{\text{LARGE}}" display="inline"><semantics id="A1.T36.8.8.8.8.8.1.m1.1a"><msub id="A1.T36.8.8.8.8.8.1.m1.1.1" xref="A1.T36.8.8.8.8.8.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.8.8.8.8.8.1.m1.1.1.2" xref="A1.T36.8.8.8.8.8.1.m1.1.1.2a.cmml">XLM-R</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.8.8.8.8.8.1.m1.1.1.3" xref="A1.T36.8.8.8.8.8.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.8.8.8.8.8.1.m1.1b"><apply id="A1.T36.8.8.8.8.8.1.m1.1.1.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.8.8.8.8.8.1.m1.1.1.1.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1">subscript</csymbol><ci id="A1.T36.8.8.8.8.8.1.m1.1.1.2a.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.8.8.8.8.8.1.m1.1.1.2.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1.2">XLM-R</mtext></ci><ci id="A1.T36.8.8.8.8.8.1.m1.1.1.3a.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.8.8.8.8.8.1.m1.1.1.3.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.8.8.8.8.8.1.m1.1c">\text{XLM-R}_{\text{LARGE}}</annotation></semantics></math></span>
<span id="A1.T36.8.8.8.8.8.2" class="ltx_td ltx_align_center"><span id="A1.T36.8.8.8.8.8.2.1" class="ltx_text ltx_font_bold">87.30</span></span>
<span id="A1.T36.8.8.8.8.8.3" class="ltx_td ltx_align_center">93.08</span>
<span id="A1.T36.8.8.8.8.8.4" class="ltx_td ltx_align_center"><span id="A1.T36.8.8.8.8.8.4.1" class="ltx_text ltx_font_bold">87.17</span></span>
<span id="A1.T36.8.8.8.8.8.5" class="ltx_td ltx_align_center">86.40</span>
<span id="A1.T36.8.8.8.8.8.6" class="ltx_td ltx_align_center">82.18</span>
<span id="A1.T36.8.8.8.8.8.7" class="ltx_td ltx_align_center"><span id="A1.T36.8.8.8.8.8.7.1" class="ltx_text ltx_font_bold">93.20</span></span>
<span id="A1.T36.8.8.8.8.8.8" class="ltx_td ltx_align_center">58.75</span>
<span id="A1.T36.8.8.8.8.8.9" class="ltx_td ltx_align_center">63.53</span>
<span id="A1.T36.8.8.8.8.8.10" class="ltx_td ltx_align_center">92.87</span>
<span id="A1.T36.8.8.8.8.8.11" class="ltx_td ltx_align_center">87.82</span>
<span id="A1.T36.8.8.8.8.8.12" class="ltx_td ltx_align_center">35.23</span>
<span id="A1.T36.8.8.8.8.8.13" class="ltx_td ltx_align_center">66.55</span>
<span id="A1.T36.8.8.8.8.8.14" class="ltx_td ltx_align_center">42.44</span>
<span id="A1.T36.8.8.8.8.8.15" class="ltx_td ltx_align_center">89.88</span></span>
<span id="A1.T36.9.9.9.9.9" class="ltx_tr">
<span id="A1.T36.9.9.9.9.9.1" class="ltx_td ltx_align_left ltx_border_t"><math id="A1.T36.9.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\text{KR-BERT}_{\text{BASE}}" display="inline"><semantics id="A1.T36.9.9.9.9.9.1.m1.1a"><msub id="A1.T36.9.9.9.9.9.1.m1.1.1" xref="A1.T36.9.9.9.9.9.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.9.9.9.9.9.1.m1.1.1.2" xref="A1.T36.9.9.9.9.9.1.m1.1.1.2a.cmml">KR-BERT</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.9.9.9.9.9.1.m1.1.1.3" xref="A1.T36.9.9.9.9.9.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.9.9.9.9.9.1.m1.1b"><apply id="A1.T36.9.9.9.9.9.1.m1.1.1.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.9.9.9.9.9.1.m1.1.1.1.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1">subscript</csymbol><ci id="A1.T36.9.9.9.9.9.1.m1.1.1.2a.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.9.9.9.9.9.1.m1.1.1.2.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1.2">KR-BERT</mtext></ci><ci id="A1.T36.9.9.9.9.9.1.m1.1.1.3a.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.9.9.9.9.9.1.m1.1.1.3.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.9.9.9.9.9.1.m1.1c">\text{KR-BERT}_{\text{BASE}}</annotation></semantics></math></span>
<span id="A1.T36.9.9.9.9.9.2" class="ltx_td ltx_align_center ltx_border_t">85.36</span>
<span id="A1.T36.9.9.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t">87.50</span>
<span id="A1.T36.9.9.9.9.9.4" class="ltx_td ltx_align_center ltx_border_t">77.92</span>
<span id="A1.T36.9.9.9.9.9.5" class="ltx_td ltx_align_center ltx_border_t">77.10</span>
<span id="A1.T36.9.9.9.9.9.6" class="ltx_td ltx_align_center ltx_border_t">74.97</span>
<span id="A1.T36.9.9.9.9.9.7" class="ltx_td ltx_align_center ltx_border_t">90.46</span>
<span id="A1.T36.9.9.9.9.9.8" class="ltx_td ltx_align_center ltx_border_t">62.83</span>
<span id="A1.T36.9.9.9.9.9.9" class="ltx_td ltx_align_center ltx_border_t">65.42</span>
<span id="A1.T36.9.9.9.9.9.10" class="ltx_td ltx_align_center ltx_border_t">92.87</span>
<span id="A1.T36.9.9.9.9.9.11" class="ltx_td ltx_align_center ltx_border_t">87.13</span>
<span id="A1.T36.9.9.9.9.9.12" class="ltx_td ltx_align_center ltx_border_t">48.95</span>
<span id="A1.T36.9.9.9.9.9.13" class="ltx_td ltx_align_center ltx_border_t">58.38</span>
<span id="A1.T36.9.9.9.9.9.14" class="ltx_td ltx_align_center ltx_border_t">45.60</span>
<span id="A1.T36.9.9.9.9.9.15" class="ltx_td ltx_align_center ltx_border_t">90.82</span></span>
<span id="A1.T36.10.10.10.10.10" class="ltx_tr">
<span id="A1.T36.10.10.10.10.10.1" class="ltx_td ltx_align_left"><math id="A1.T36.10.10.10.10.10.1.m1.1" class="ltx_Math" alttext="\text{KoELECTRA}_{\text{BASE}}" display="inline"><semantics id="A1.T36.10.10.10.10.10.1.m1.1a"><msub id="A1.T36.10.10.10.10.10.1.m1.1.1" xref="A1.T36.10.10.10.10.10.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.10.10.10.10.10.1.m1.1.1.2" xref="A1.T36.10.10.10.10.10.1.m1.1.1.2a.cmml">KoELECTRA</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.10.10.10.10.10.1.m1.1.1.3" xref="A1.T36.10.10.10.10.10.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.10.10.10.10.10.1.m1.1b"><apply id="A1.T36.10.10.10.10.10.1.m1.1.1.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.10.10.10.10.10.1.m1.1.1.1.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1">subscript</csymbol><ci id="A1.T36.10.10.10.10.10.1.m1.1.1.2a.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.10.10.10.10.10.1.m1.1.1.2.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1.2">KoELECTRA</mtext></ci><ci id="A1.T36.10.10.10.10.10.1.m1.1.1.3a.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.10.10.10.10.10.1.m1.1.1.3.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.10.10.10.10.10.1.m1.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math></span>
<span id="A1.T36.10.10.10.10.10.2" class="ltx_td ltx_align_center">85.99</span>
<span id="A1.T36.10.10.10.10.10.3" class="ltx_td ltx_align_center"><span id="A1.T36.10.10.10.10.10.3.1" class="ltx_text ltx_framed ltx_framed_underline">93.14</span></span>
<span id="A1.T36.10.10.10.10.10.4" class="ltx_td ltx_align_center">85.89</span>
<span id="A1.T36.10.10.10.10.10.5" class="ltx_td ltx_align_center"><span id="A1.T36.10.10.10.10.10.5.1" class="ltx_text ltx_framed ltx_framed_underline">86.87</span></span>
<span id="A1.T36.10.10.10.10.10.6" class="ltx_td ltx_align_center"><span id="A1.T36.10.10.10.10.10.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">86.06</span></span>
<span id="A1.T36.10.10.10.10.10.7" class="ltx_td ltx_align_center"><span id="A1.T36.10.10.10.10.10.7.1" class="ltx_text ltx_framed ltx_framed_underline">92.75</span></span>
<span id="A1.T36.10.10.10.10.10.8" class="ltx_td ltx_align_center">62.67</span>
<span id="A1.T36.10.10.10.10.10.9" class="ltx_td ltx_align_center">57.46</span>
<span id="A1.T36.10.10.10.10.10.10" class="ltx_td ltx_align_center">90.93</span>
<span id="A1.T36.10.10.10.10.10.11" class="ltx_td ltx_align_center">87.07</span>
<span id="A1.T36.10.10.10.10.10.12" class="ltx_td ltx_align_center">59.54</span>
<span id="A1.T36.10.10.10.10.10.13" class="ltx_td ltx_align_center">65.64</span>
<span id="A1.T36.10.10.10.10.10.14" class="ltx_td ltx_align_center">39.83</span>
<span id="A1.T36.10.10.10.10.10.15" class="ltx_td ltx_align_center">88.91</span></span>
<span id="A1.T36.11.11.11.11.11" class="ltx_tr">
<span id="A1.T36.11.11.11.11.11.1" class="ltx_td ltx_align_left ltx_border_t"><math id="A1.T36.11.11.11.11.11.1.m1.1" class="ltx_Math" alttext="\text{KLUE-BERT}_{\text{BASE}}" display="inline"><semantics id="A1.T36.11.11.11.11.11.1.m1.1a"><msub id="A1.T36.11.11.11.11.11.1.m1.1.1" xref="A1.T36.11.11.11.11.11.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.11.11.11.11.11.1.m1.1.1.2" xref="A1.T36.11.11.11.11.11.1.m1.1.1.2a.cmml">KLUE-BERT</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.11.11.11.11.11.1.m1.1.1.3" xref="A1.T36.11.11.11.11.11.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.11.11.11.11.11.1.m1.1b"><apply id="A1.T36.11.11.11.11.11.1.m1.1.1.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.11.11.11.11.11.1.m1.1.1.1.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1">subscript</csymbol><ci id="A1.T36.11.11.11.11.11.1.m1.1.1.2a.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.11.11.11.11.11.1.m1.1.1.2.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1.2">KLUE-BERT</mtext></ci><ci id="A1.T36.11.11.11.11.11.1.m1.1.1.3a.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.11.11.11.11.11.1.m1.1.1.3.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.11.11.11.11.11.1.m1.1c">\text{KLUE-BERT}_{\text{BASE}}</annotation></semantics></math></span>
<span id="A1.T36.11.11.11.11.11.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T36.11.11.11.11.11.2.1" class="ltx_text ltx_framed ltx_framed_underline">86.95</span></span>
<span id="A1.T36.11.11.11.11.11.3" class="ltx_td ltx_align_center ltx_border_t">91.01</span>
<span id="A1.T36.11.11.11.11.11.4" class="ltx_td ltx_align_center ltx_border_t">83.44</span>
<span id="A1.T36.11.11.11.11.11.5" class="ltx_td ltx_align_center ltx_border_t">79.87</span>
<span id="A1.T36.11.11.11.11.11.6" class="ltx_td ltx_align_center ltx_border_t">83.71</span>
<span id="A1.T36.11.11.11.11.11.7" class="ltx_td ltx_align_center ltx_border_t">91.17</span>
<span id="A1.T36.11.11.11.11.11.8" class="ltx_td ltx_align_center ltx_border_t">65.58</span>
<span id="A1.T36.11.11.11.11.11.9" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T36.11.11.11.11.11.9.1" class="ltx_text ltx_framed ltx_framed_underline">68.11</span></span>
<span id="A1.T36.11.11.11.11.11.10" class="ltx_td ltx_align_center ltx_border_t">93.07</span>
<span id="A1.T36.11.11.11.11.11.11" class="ltx_td ltx_align_center ltx_border_t">87.25</span>
<span id="A1.T36.11.11.11.11.11.12" class="ltx_td ltx_align_center ltx_border_t">62.42</span>
<span id="A1.T36.11.11.11.11.11.13" class="ltx_td ltx_align_center ltx_border_t">68.15</span>
<span id="A1.T36.11.11.11.11.11.14" class="ltx_td ltx_align_center ltx_border_t">46.72</span>
<span id="A1.T36.11.11.11.11.11.15" class="ltx_td ltx_align_center ltx_border_t">91.59</span></span>
<span id="A1.T36.12.12.12.12.12" class="ltx_tr">
<span id="A1.T36.12.12.12.12.12.1" class="ltx_td ltx_align_left"><math id="A1.T36.12.12.12.12.12.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{SMALL}}" display="inline"><semantics id="A1.T36.12.12.12.12.12.1.m1.1a"><msub id="A1.T36.12.12.12.12.12.1.m1.1.1" xref="A1.T36.12.12.12.12.12.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.12.12.12.12.12.1.m1.1.1.2" xref="A1.T36.12.12.12.12.12.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.12.12.12.12.12.1.m1.1.1.3" xref="A1.T36.12.12.12.12.12.1.m1.1.1.3a.cmml">SMALL</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.12.12.12.12.12.1.m1.1b"><apply id="A1.T36.12.12.12.12.12.1.m1.1.1.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.12.12.12.12.12.1.m1.1.1.1.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1">subscript</csymbol><ci id="A1.T36.12.12.12.12.12.1.m1.1.1.2a.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.12.12.12.12.12.1.m1.1.1.2.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="A1.T36.12.12.12.12.12.1.m1.1.1.3a.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.12.12.12.12.12.1.m1.1.1.3.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1.3">SMALL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.12.12.12.12.12.1.m1.1c">\text{KLUE-RoBERTa}_{\text{SMALL}}</annotation></semantics></math></span>
<span id="A1.T36.12.12.12.12.12.2" class="ltx_td ltx_align_center">85.95</span>
<span id="A1.T36.12.12.12.12.12.3" class="ltx_td ltx_align_center">91.70</span>
<span id="A1.T36.12.12.12.12.12.4" class="ltx_td ltx_align_center">85.42</span>
<span id="A1.T36.12.12.12.12.12.5" class="ltx_td ltx_align_center">81.00</span>
<span id="A1.T36.12.12.12.12.12.6" class="ltx_td ltx_align_center">83.55</span>
<span id="A1.T36.12.12.12.12.12.7" class="ltx_td ltx_align_center">91.20</span>
<span id="A1.T36.12.12.12.12.12.8" class="ltx_td ltx_align_center">61.26</span>
<span id="A1.T36.12.12.12.12.12.9" class="ltx_td ltx_align_center">60.89</span>
<span id="A1.T36.12.12.12.12.12.10" class="ltx_td ltx_align_center">93.47</span>
<span id="A1.T36.12.12.12.12.12.11" class="ltx_td ltx_align_center">87.50</span>
<span id="A1.T36.12.12.12.12.12.12" class="ltx_td ltx_align_center">58.28</span>
<span id="A1.T36.12.12.12.12.12.13" class="ltx_td ltx_align_center">63.56</span>
<span id="A1.T36.12.12.12.12.12.14" class="ltx_td ltx_align_center">46.65</span>
<span id="A1.T36.12.12.12.12.12.15" class="ltx_td ltx_align_center">91.50</span></span>
<span id="A1.T36.13.13.13.13.13" class="ltx_tr">
<span id="A1.T36.13.13.13.13.13.1" class="ltx_td ltx_align_left"><math id="A1.T36.13.13.13.13.13.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="A1.T36.13.13.13.13.13.1.m1.1a"><msub id="A1.T36.13.13.13.13.13.1.m1.1.1" xref="A1.T36.13.13.13.13.13.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.13.13.13.13.13.1.m1.1.1.2" xref="A1.T36.13.13.13.13.13.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.13.13.13.13.13.1.m1.1.1.3" xref="A1.T36.13.13.13.13.13.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.13.13.13.13.13.1.m1.1b"><apply id="A1.T36.13.13.13.13.13.1.m1.1.1.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.13.13.13.13.13.1.m1.1.1.1.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1">subscript</csymbol><ci id="A1.T36.13.13.13.13.13.1.m1.1.1.2a.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.13.13.13.13.13.1.m1.1.1.2.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="A1.T36.13.13.13.13.13.1.m1.1.1.3a.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.13.13.13.13.13.1.m1.1.1.3.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.13.13.13.13.13.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math></span>
<span id="A1.T36.13.13.13.13.13.2" class="ltx_td ltx_align_center">86.19</span>
<span id="A1.T36.13.13.13.13.13.3" class="ltx_td ltx_align_center">92.91</span>
<span id="A1.T36.13.13.13.13.13.4" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.4.1" class="ltx_text ltx_framed ltx_framed_underline">86.78</span></span>
<span id="A1.T36.13.13.13.13.13.5" class="ltx_td ltx_align_center">86.30</span>
<span id="A1.T36.13.13.13.13.13.6" class="ltx_td ltx_align_center">83.81</span>
<span id="A1.T36.13.13.13.13.13.7" class="ltx_td ltx_align_center">91.09</span>
<span id="A1.T36.13.13.13.13.13.8" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.8.1" class="ltx_text ltx_framed ltx_framed_underline">66.73</span></span>
<span id="A1.T36.13.13.13.13.13.9" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.9.1" class="ltx_text ltx_framed ltx_framed_underline">68.11</span></span>
<span id="A1.T36.13.13.13.13.13.10" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.10.1" class="ltx_text ltx_framed ltx_framed_underline">93.75</span></span>
<span id="A1.T36.13.13.13.13.13.11" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.11.1" class="ltx_text ltx_framed ltx_framed_underline">87.77</span></span>
<span id="A1.T36.13.13.13.13.13.12" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.12.1" class="ltx_text ltx_framed ltx_framed_underline">69.56</span></span>
<span id="A1.T36.13.13.13.13.13.13" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.13.1" class="ltx_text ltx_framed ltx_framed_underline">74.64</span></span>
<span id="A1.T36.13.13.13.13.13.14" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.14.1" class="ltx_text ltx_framed ltx_framed_underline">47.41</span></span>
<span id="A1.T36.13.13.13.13.13.15" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.15.1" class="ltx_text ltx_framed ltx_framed_underline">91.60</span></span></span>
<span id="A1.T36.14.14.14.14.14" class="ltx_tr">
<span id="A1.T36.14.14.14.14.14.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="A1.T36.14.14.14.14.14.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" display="inline"><semantics id="A1.T36.14.14.14.14.14.1.m1.1a"><msub id="A1.T36.14.14.14.14.14.1.m1.1.1" xref="A1.T36.14.14.14.14.14.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.14.14.14.14.14.1.m1.1.1.2" xref="A1.T36.14.14.14.14.14.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.14.14.14.14.14.1.m1.1.1.3" xref="A1.T36.14.14.14.14.14.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.14.14.14.14.14.1.m1.1b"><apply id="A1.T36.14.14.14.14.14.1.m1.1.1.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.14.14.14.14.14.1.m1.1.1.1.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1">subscript</csymbol><ci id="A1.T36.14.14.14.14.14.1.m1.1.1.2a.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.14.14.14.14.14.1.m1.1.1.2.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="A1.T36.14.14.14.14.14.1.m1.1.1.3a.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.14.14.14.14.14.1.m1.1.1.3.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.14.14.14.14.14.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math></span>
<span id="A1.T36.14.14.14.14.14.2" class="ltx_td ltx_align_center ltx_border_bb">85.88</span>
<span id="A1.T36.14.14.14.14.14.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.3.1" class="ltx_text ltx_font_bold">93.20</span></span>
<span id="A1.T36.14.14.14.14.14.4" class="ltx_td ltx_align_center ltx_border_bb">86.13</span>
<span id="A1.T36.14.14.14.14.14.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.5.1" class="ltx_text ltx_font_bold">89.50</span></span>
<span id="A1.T36.14.14.14.14.14.6" class="ltx_td ltx_align_center ltx_border_bb">84.54</span>
<span id="A1.T36.14.14.14.14.14.7" class="ltx_td ltx_align_center ltx_border_bb">91.45</span>
<span id="A1.T36.14.14.14.14.14.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.8.1" class="ltx_text ltx_font_bold">71.06</span></span>
<span id="A1.T36.14.14.14.14.14.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.9.1" class="ltx_text ltx_font_bold">73.33</span></span>
<span id="A1.T36.14.14.14.14.14.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.10.1" class="ltx_text ltx_font_bold">93.84</span></span>
<span id="A1.T36.14.14.14.14.14.11" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.11.1" class="ltx_text ltx_font_bold">87.93</span></span>
<span id="A1.T36.14.14.14.14.14.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.12.1" class="ltx_text ltx_font_bold">75.26</span></span>
<span id="A1.T36.14.14.14.14.14.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.13.1" class="ltx_text ltx_font_bold">80.30</span></span>
<span id="A1.T36.14.14.14.14.14.14" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.14.1" class="ltx_text ltx_font_bold">49.39</span></span>
<span id="A1.T36.14.14.14.14.14.15" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.15.1" class="ltx_text ltx_font_bold">92.19</span></span></span>
</span></span></p>
</span></div>
</figure>
<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p"><span id="A1.p1.1.1" class="ltx_text" style="font-size:90%;">In order to prevent early saturation of KLUE benchmark, we limit users to submit their models once per day. We thus present the dev set results to provide a reference for future work and local tests, in Table </span><a href="#A1.T36" title="Table 36 ‣ Appendix A Dev Set Results ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">36</span></a><span id="A1.p1.1.2" class="ltx_text" style="font-size:90%;">. Models we used are same as in test set.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2105.09679" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2105.09680" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2105.09680">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2105.09680" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2105.09682" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  8 00:24:06 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>