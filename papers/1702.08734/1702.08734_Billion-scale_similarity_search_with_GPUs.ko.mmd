# GPU를 사용한 수십억 규모 유사성 검색

 제프 제프

페이스북 AI 연구소

Matthijs Douze

페이스북 AI 연구소

Paris

Herve Jegou

페이스북 AI 연구소

###### Abstract

유사도 검색은 일반적으로 고차원 특징으로 표현되고 특정 인덱싱 구조를 필요로 하는 이미지나 비디오와 같은 복잡한 데이터를 다루는 전문 데이터베이스 시스템에서 응용 프로그램을 찾는다. 본 논문은 이 작업을 위해 GPU를 더 잘 활용하는 문제를 다룬다. GPU는 데이터 병렬 작업에서 탁월하지만 이전 접근법은 \(k\)-min 선택과 같은 병렬성을 덜 노출하거나 메모리 계층 구조를 제대로 사용하지 않는 알고리즘에 의해 병목 현상이 발생한다.

본 논문에서는 이론적인 최대 성능에서 최대 55%까지 동작하는 \(k\)-선택을 위한 설계를 제안하여 기존의 GPU 상태보다 8.5\(\times\) 빠른 최근접 이웃 구현을 가능하게 한다. 우리는 제품 양자화를 기반으로 브루트-포스, 근사 및 압축 도메인 검색을 위한 최적화된 설계를 제안하여 다양한 유사성 검색 시나리오에 적용한다. 이 모든 설정에서 우리는 큰 여백으로 최신 기술을 능가합니다. 구현을 통해 Yfcc100M 데이터셋의 9,500만 개의 영상에 대해 35분 만에 높은 정확도의 \(k\)-NN 그래프를 구축하고, Maxwell Titan X GPU 4개에 대해 12시간 이내에 10억 개의 벡터를 연결하는 그래프를 구축할 수 있다. 비교 및 재현성을 위해 접근법 1을 오픈소싱했다.

각주 1: [https://github.com/facebookresearch/faiss](https://github.com/facebookresearch/faiss)

1

## 1 Introduction

이미지와 비디오는 인덱싱 및 검색을 위한 새로운 대용량 데이터 소스를 구성합니다. 이 콘텐츠에 대한 광범위한 메타데이터는 종종 이용가능하지 않다. 텍스트와 같이 이와 다른 인간 생성 콘텐츠의 검색과 해석은 어렵고 중요하다. 이러한 복잡한 실세계 엔티티를 해석하고 분류하기 위해 다양한 머신 러닝 및 딥 러닝 알고리즘이 사용되고 있다. 인기 있는 예들은 word2vec[32]로 알려진 텍스트 표현, 컨볼루션 신경망들에 의한 이미지들의 표현들[39, 19] 및 인스턴스 검색을 위한 이미지 기술자들[20]을 포함한다. 그러한 표현들 또는 _임베딩들_ 은 일반적으로 50 내지 1000+ 차원들의 실수값, 고차원 벡터들이다. 기본 프로세스들이 높은 산술 복잡도 및/또는 높은 데이터 대역폭 요구를 가지거나 [28] 통신 오버헤드 또는 표현 품질로 인해 실패하지 않고 효과적으로 분할될 수 없기 때문에, 이러한 벡터 표현들 중 다수는 GPU 시스템 상에서만 효과적으로 생성될 수 있다[38]. 일단 생산되면, 그들의 조작은 그 자체로 산술적으로 집약적이다. 그러나 GPU 자산을 활용하는 방법은 간단하지 않습니다. 보다 일반적으로, 새로운 이종 아키텍처를 이용하는 방법은 데이터베이스 커뮤니티의 핵심 주제이다[9].

이러한 맥락에서 구조화된 관계를 통한 검색보다는 수치 _유사도_로 검색하는 것이 더 적합하다. 이는 그림과 가장 유사한 내용을 찾거나, 컬렉션의 모든 벡터에서 선형 분류기에 대한 응답이 가장 높은 벡터를 찾는 것일 수 있다.

대규모 컬렉션에서 수행되어야 하는 가장 비싼 연산 중 하나는 \(k\)-NN 그래프를 계산하는 것이다. 이것은 데이터베이스의 각 벡터가 노드이고 각 에지가 노드를 \(k\) 가장 가까운 이웃에 연결하는 방향 그래프이다. 이것은 우리의 주력 애플리케이션입니다. NN-Descent [15]와 같은 최신 방법은 데이터 세트 자체의 상단에 큰 메모리 오버헤드를 가지며 우리가 고려하는 10억 크기의 데이터베이스로 쉽게 확장할 수 없다.

이러한 응용 프로그램은 **차원의 저주_[46]** 를 처리 해야 하며, 10억 규모의 데이터베이스에서 비배분 검색에 대 한 철저한 검색 또는 정확한 인덱싱을 모두 실행 하지 않습니다. 이것이 근사 검색 및/또는 그래프 구성에 대한 많은 작업이 있는 이유이다. RAM에 맞지 않는 거대한 데이터 세트를 처리하기 위해, 몇몇 접근법들은 인코딩을 사용하여 벡터들의 내부 압축 표현을 채용한다. GPU와 같은 메모리 제한 장치에 특히 편리합니다. 최소 정확도 손실을 받아들이는 것은 압축의 크기 차수를 초래한다는 것이 밝혀졌다[21]. 가장 인기 있는 벡터 압축 방법은 이진 코드[18, 22], 또는 양자화 방법[25, 37]으로 분류될 수 있다. 둘 다 이웃을 검색하는 것이 벡터를 재구성할 필요가 없다는 바람직한 속성을 가지고 있다.

본 논문은 PQ(Product Quantization) 코드를 기반으로 하는 방법에 초점을 맞추고 있으며, 이는 이진 코드보다 더 효과적인 것으로 나타났다[34]. 또한, 바이너리 코드는 비-배타적인 탐색 방법들에 대해 중요한 오버헤드를 발생시킨다[35]. IVFADC[25]로 알려진 원래 제품 양자화 제안 후에 몇 가지 개선 사항이 제안되었으며 대부분은 GPU에서 효율적으로 구현하기가 어렵다. 예를 들어, 고속/저품질 작동점에 유용한 역 다중 인덱스 [4]는 복잡한 "다중 시퀀스" 알고리즘에 의존한다. 최적화된 제품 양자화 또는 OPQ[17]는 제품 양자화의 정확도를 향상시키는 입력 벡터들에 대한 선형 변환이며, 전처리로서 적용될 수 있다. [2]로부터의 SIMD-최적화된 IVFADC 구현은 차-최적 파라미터들(few coarse quantization centroids)만으로 동작한다. LOPQ 및 Polyseymous 코드 [27, 16]와 같은 많은 다른 방법은 GPU에서 효율적으로 구현하기에는 너무 복잡하다.

GPU에서 유사성 검색의 많은 구현이 있지만, 대부분 이진 코드[36], 작은 데이터 세트[44], 또는 철저한 검색[14, 40, 41]을 사용한다. 우리가 아는 한, Wieschollek et al. [47]의 작업만이 양자화 코드가 있는 10억 규모의 데이터 세트에 적합한 것으로 판단된다. 이것은 GPU에 대한 이전 기술이며, 우리는 섹션 6.4와 비교한다.

본 논문은 다음과 같은 공헌을 한다.

* GPU \(k\)-선택 알고리즘, 빠른 레지스터 메모리에서 작동하며 다른 커널과 융합할 수 있을 만큼 충분히 유연한 복잡성 분석을 제공합니다.
* GPU에서 정확하고 근사적인 \(k\)-최근접 이웃 검색을 위한 거의 최적 알고리즘 레이아웃;
* 단일 또는 다중 GPU 구성에서, 이러한 개선들이 중간 내지 대규모 최근접 이웃 탐색 태스크들에 대해 큰 마진만큼 이전 기술을 능가한다는 것을 보여주는 다양한 실험들.

논문을 정리하면 다음과 같다. 2절에서는 맥락과 표기법을 소개한다. 섹션 3에서는 GPU 아키텍처를 검토하고 유사성 검색에 사용할 때 나타나는 문제에 대해 논의한다. 섹션 4에서는 GPU에 대한 주요 기여 중 하나인 _즉_ k-선택 방법을 소개하고 섹션 5에서는 알고리즘 계산 레이아웃에 대한 세부 정보를 제공한다. 마지막으로 섹션 6은 접근법에 대한 광범위한 실험을 제공하고 이를 최신 기술과 비교하고 이미지 컬렉션에 대한 구체적인 사용 사례를 보여준다.

## 2 Problem Statement

우리는 벡터 모음에서 유사성 검색에 관심이 있다. 쿼리 벡터 \(x\in\mathbb{R}^{d}\)와 컬렉션 2\([y_{i}]_{i=0:\ell}\) (\(y_{i}\in\mathbb{R}^{d}\))를 사용하여 검색합니다.

각주 2: 0 기반 인덱싱에서 클러터를 방지 하기 위해 배열 표기 \(0:\ell\)을 사용 하 여 범위 \(\{0,...,\ell-1\}\) 포함을 표시 합니다.

\[L=k\text{-}\text{argmin}_{i=0:\ell}\|x-y_{i}\|_{2}, \tag{1}\]

_i.e._는 L2 거리 측면에서 \(x\)의 \(k\) 가장 가까운 이웃을 검색한다. L2 거리는 매력적인 선형 대수 특성으로 인해 여러 임베딩(_e.g._, [20])을 학습할 때 설계에 의해 최적화되기 때문에 가장 자주 사용된다.

가장 낮은 거리는 \(k\)-선택에 의해 수집된다. 배열 \([a_{i}]_{i=0:\ell}\)의 경우, \(k\)-선택은 입력 배열에서 나온 원소들의 인덱스 \([a_{s_{i}}]_{i=0:k}\), \(a_{s_{i}}\leq a_{s_{i+1}}\)과 함께 \([a_{i}]_{i=0:k}\), \(0\leq s_{i}<\ell\) 가장 낮은 값을 갖는 원소들을 찾는다. \(a_{i}\)은 32비트 부동소수점 값이고, \(s_{i}\)은 32비트 또는 64비트 정수이다. 다른 비교기가 필요한 경우가 있습니다. _예:_ 코사인 유사성에 대해 _가장 높은_ 값을 검색합니다. 등가키 \(a_{s_{i}}=a_{s_{j}}\) 사이의 순서는 지정되지 않는다.

**배칭.** 일반적으로 검색은 \(n_{\text{q}}\) 쿼리 벡터 \([x_{j}]_{j=0:n_{\text{q}}}\) (\(x_{j}\in\mathbb{R}^{d}\))의 일괄 처리로 병렬로 수행되므로 여러 CPU 스레드 또는 GPU에서 실행할 때 더 유연합니다. \(k\)-선택에 대한 배치는 \(n_{\text{q}}\times k\)개의 개별 배열에서 \(n_{\text{q}}\times k\)개의 요소 및 인덱스를 선택하는 것을 수반하며, 여기서 각 배열은 잠재적으로 다른 길이 \(\ell_{i}\geq k\)이다.

**정확한 검색.** 정확한 솔루션은 전체 쌍별 거리 행렬 \(D=[\|x_{j}-y_{i}\|_{2}^{2}]_{j=0:n_{\text{q}},i=0:\ell}\in\mathbb{R}^{n_{\text {q}}\times\ell}\)을 계산합니다. 실제로 우리는 분해를 사용한다.

\[\|x_{j}-y_{i}\|_{2}^{2}=\|x_{j}\|^{2}+\|y_{i}\|^{2}-2\langle x_{j},y_{i}\rangle. \tag{2}\]

첫 번째 두 항은 행이 \([x_{j}]\)과 \([y_{i}]\)인 행렬 \(X\)과 \(Y\)을 한 번에 통과하여 미리 계산될 수 있다. 병목현상은 행렬 곱셈 \(XY^{\top}\)과 같은 \(\langle x_{j},y_{i}\rangle\)을 계산하는 것이다. 각각의 \(n_{\text{q}}\) 질의에 대한 \(k\)-근접 이웃은 \(D\)의 각 행을 따라 \(k\)-선택된다.

**압축 도메인 검색.** 이제부터 근사 최근접 이웃 검색에 중점을 둡니다. 특히 _IVFADC_ 인덱싱 구조[25]를 고려한다. IVFADC 인덱스는 두 단계의 양자화에 의존하며, 데이터베이스 벡터는 인코딩된다. 데이터베이스 벡터 \(y\)는 다음과 같이 근사화된다:

\[y\approx q(y)=q_{1}(y)+q_{2}(y-q_{1}(y)) \tag{3}\]

여기서 \(q_{1}:\mathbb{R}^{d}\to\mathcal{C}_{1}\subset\mathbb{R}^{d}\)과 \(q_{2}:\mathbb{R}^{d}\to\mathcal{C}_{2}\subset\mathbb{R}^{d}\)은 양자화기이다. _i.e._는 유한집합에서 원소를 출력하는 함수이다. 집합은 유한하므로 \(q(y)\)는 \(q_{1}(y)\)의 인덱스로 인코딩되고 \(q_{2}(y-q_{1}(y))\의 인덱스로 인코딩된다. 첫 번째 레벨 양자화기는 _coarse 양자화기_이고 두 번째 레벨 _fine 양자화기_는 첫 번째 레벨 이후의 잔차 벡터를 부호화한다.

ADC(Asymmetric Distance Computation) 탐색 방법은 근사 결과를 반환한다:

\[L_{\text{ADC}}=k\text{-}\text{argmin}_{i=0:\ell}\|x-q(y_{i})\|_{2}. \tag{4}\]

IVFADC의 경우 검색이 철저하지 않습니다. 거리가 계산되는 벡터는 첫 번째 레벨 양자화기 \(q_{1}\):에 따라 미리 선택된다.

\[L_{\text{IVF}}=\tau\text{-}\text{argmin}_{c\in\mathcal{C}_{1}}\|x-c\|_{2}. \tag{5}\]

다중 프로브 매개 변수_\(\tau\)는 우리가 고려 하는 거친 수준 중심 수입니다. 양자화기는 재생 값들의 세트 내에서, 정확한 거리들을 갖는 최근접 이웃 탐색을 동작시킨다. 그리고, IVFADC 검색은

\[L_{\text{IVFADC}}=\underset{i=0:\ell\text{ s.t. }q_{1}(y_{i})\in L_{\text{IVF}}}{k \text{-}\text{argmin}}\|x-q(y_{i})\|_{2}. \tag{6}\]

따라서 IVFADC는 ADC의 2단계 양자화와 동일한 거리 추정에 의존하지만 벡터의 하위 집합에서만 계산한다.

해당 데이터 구조인 _inverted file_은 벡터 \(y_{i}\)을 \(|\mathcal{C}_{1}|\)_inverted lists_\(\mathcal{I}_{1},...,\mathcal{I}_{\mathcal{C}_{1}|}\)과 균질 \(q_{1}(y_{i})\)으로 묶는다. 따라서 가장 메모리 집약적인 연산은 연산 \(L_{\text{IVFADC}}\)이며, 선형 스캐닝 \(\tau\) 반전 리스트로 귀결된다.

**양자화기.** 양자화기 \(q_{1}\)와 \(q_{2}\)는 서로 다른 속성을 가지고 있습니다. \ (q_{1}\)는 반전 리스트의 개수가 폭발하지 않도록 재생값의 개수가 상대적으로 적을 필요가 있다. 우리는 일반적으로 \(|C_{1}|\approx\sqrt{t}\), \(k\)-평균을 통해 훈련된 \(|C_{1}|\approx\sqrt{t}\)을 사용한다. \(q_{2}\)의 경우 보다 광범위한 표현을 위해 더 많은 메모리를 사용할 수 있다. 벡터의 ID(a - 또는 8바이트 정수)는 또한 반전된 목록에 저장되므로, _i.e._, \(\log_{2}|\mathcal{C}_{2}|>4\times 8\)보다 짧은 코드를 갖는 것은 의미가 없다.

**제품 양자화기.** \(q_{2}\)에 대해 _제품 양자화기_[25]를 사용 하 여 처리 비용을 증가시키지 않고 많은 수의 재생 값을 제공 합니다. 그것은 벡터 \(y\)를 \(b\)의 하위 벡터 \(y=[y^{0}...y^{b-1}]\)으로 해석하며, 여기서 \(b\)는 차원 \(d\)의 짝수이다. 각각의 서브-벡터는 자체 양자화기로 양자화되어 튜플(\(q^{0}(y^{0})\),..., \(q^{b-1}(y^{b-1})\))을 산출한다. 서브 양자화기는 일반적으로 하나의 바이트에 맞추기 위해 256개의 재생 값을 갖는다. 곱 양자화기의 양자화 값은 \(q_{2}(y)=q^{0}(y^{0})+256\times q^{1}(y^{1})+...+256^{b-1}\times q^{b-1}\)이다. 이는 저장 관점에서 각각의 서브 양자화기에 의해 생성된 바이트들의 연접일 뿐이다. 따라서 곱 양자화기는 \(|\mathcal{C}_{2}|=256^{b}\) 재생 값을 갖는 \(b\)-바이트 부호를 생성한다. 양자화기의 \(k\)-평균 사전은 작고 양자화는 계산적으로 저렴하다.

## 3 GPU: 개요 및 K-선택

이 섹션에서는 Nvidia의 범용 GPU 아키텍처 및 프로그래밍 모델에 대한 주요 세부 사항을 검토한다. 그런 다음 유사성 검색과 관련된 GPU를 덜 준수하는 부분 중 하나인 \(k\)-선택에 초점을 맞추고 문헌 및 문제에 대해 논의한다.

### Architecture

**GPU 차선 및 warps.** Nvidia GPU는 _CUDA 스레드_ ( _warp_)의 32 너비 벡터를 사용 하 여 명령 스트림을 실행 하는 범용 컴퓨터입니다. warp의 개별 스레드는 _lanes_ 라고 하며, _lane ID_는 0 - 31입니다. "thread" 용어에도 불구하고 최신 벡터화된 멀티코어 CPU에 대 한 최상의 유추는 warp가 명령 카운터를 공유 하기 때문에 각 warp가 별도의 CPU 하드웨어 스레드라는 것입니다. 다른 실행 경로를 사용 하는 워프 차선은 _워프 발산_ 을 발생 하 여 성능을 감소시킵니다. 각 레인은 공유 레지스터 파일에 최대 255개의 32비트 레지스터가 있습니다. CPU 비유는 너비 32의 최대 255개의 벡터 레지스터가 있으며, 워프 레인은 SIMD 벡터 레인이다.

** warps 컬렉션.** 1~32 warps의 사용자 구성 가능 컬렉션은 _block_ 또는 _협력 스레드 배열_ (CTA)로 구성 됩니다. 각 블록에는 최대 48 KiB 크기의 고속 _공유 메모리_가 있습니다. 개별 CUDA 스레드에는 작업을 분할하고 할당하는 데 사용할 수 있는 _thread id_ 라는 블록 상대 ID가 있습니다. 각 블록은 _스트리밍 다중 프로세서_ (SM) 라고 하는 GPU의 단일 코어에서 실행 됩니다. 각 SM에는 ALU, 메모리 로드/스토어 단위 및 다양한 특수 명령 단위를 포함 하는 _기능 단위_가 있습니다. GPU는 모든 SM에 걸쳐 워프에서 비행 중 많은 작업을 수행하여 실행 대기 시간을 숨깁니다. 각 개별 워프 레인 명령 처리량은 낮고 지연 시간은 높지만 모든 SM의 총 산술 처리량은 일반적인 CPU보다 5-10\(\times\) 높다.

**그리드 및 커널.** 블록은 _커널_에 있는 블록의 _그리드_에 구성됩니다. 각 블록에는 그리드 상대 ID가 할당됩니다. 커널은 GPU가 실행하기 위해 호스트 CPU에 의해 스케줄링된 작업 유닛(인수를 갖는 명령 스트림)이다. 블록이 완료될 때까지 실행되면 새 블록을 예약할 수 있습니다. 다른 커널의 블록은 동시에 실행할 수 있습니다. 커널들 사이의 오더링은 _streams_ 및 _events_ 와 같은 프리미티브들을 오더링함으로써 제어가능하다.

**리소스 및 점유.** 동시에 실행하는 블록 수는 각 블록에서 사용하는 공유 메모리 및 레지스터 리소스에 따라 달라집니다. CUDA 당 스레드 레지스터 사용량은 컴파일 시간에 결정되는 반면, 공유 메모리 사용량은 런타임에 선택될 수 있다. 이 사용은 GPU의 _점유_ 에 영향을 줍니다. 블록이 자신의 개인 사용을 위해 공유 메모리의 48 KiB, 또는 32와 대조적으로 스레드당 128개의 레지스터를 모두 요구하는 경우, 1-2개의 다른 블록만이 동일한 SM 상에서 동시에 실행될 수 있어, 낮은 점유율을 초래한다. 높은 점유율 아래 모든 SM에 더 많은 블록이 존재하여 더 많은 작업을 한 번에 비행할 수 있습니다.

**메모리 유형.** 다른 블록 및 커널은 일반적으로 CPU 메인 메모리보다 5 - 10\(\times\) 더 높은 대역폭으로 _글로벌 메모리_ 를 통해 통신 합니다. 공유 메모리는 CPU L1 캐시와 속도 면에서 유사합니다. GPU 레지스터 파일 메모리는 가장 높은 대역폭 메모리입니다. GPU에서 비행 중인 많은 수의 명령어를 유지하기 위해서는 CPU의 수십 KB와 대조적으로 최신 Pascal P100에서 14MB인 방대한 레지스터 파일도 필요하다. 전역 메모리 집합 횡단면 대역폭에 대한 레지스터에 대한 250 : 6.25 : 1의 비율은 GPU에서 전형적이며, 레지스터 파일에 대해 10 - 100s TB/s를 산출한다[10].

### GPU 레지스터 파일 사용량

**구조화된 레지스터 데이터.** 공유 및 레지스터 메모리 사용에는 효율성 절충이 포함되며, 점유율은 낮지만 더 빠른 메모리에 더 큰 작업 세트를 유지하여 전반적인 성능을 높일 수 있습니다. 점유를 희생하거나 공유 메모리 대신에 레지스터-거주 데이터를 과하게 사용하는 것은 종종 수익성이 있다[43].

GPU 레지스터 파일이 매우 크기 때문에, 구조화된 데이터(임시 피연산자뿐만 아니라)를 저장하는 것이 유용하다. 단일 차선은 로컬 태스크를 해결하기 위해 그것의 (스칼라) 레지스터들을 사용할 수 있지만, 제한된 병렬성 및 저장을 갖는다. 대신 GPU warp의 차선은 _warp shuffle_ 명령을 사용 하 여 레지스터 데이터를 교환 하 여 warp-wide 병렬 처리 및 저장소를 사용할 수 있습니다.

**차선-가닥 레지스터 배열입니다.* *이를 달성하기 위한 일반적인 패턴은 _차선-가닥 레지스터 배열_ 입니다. 즉, 요소 \([a_{i}]_{i=0:\ell}\)이 주어지면, 각각의 연속적인 값은 이웃하는 차선에 의해 레지스터에 유지된다. 배열은 32의 배수인 \(\ell\)과 함께 차선당 \(\ell/32\) 레지스터에 저장된다. 차선 \(j\)은 \(\{a_{j},a_{32+j},...,a_{\ell-32+j}\}\)을 저장하고, 레지스터 \(r\)은 \(\{a_{32r},a_{32r+1},...,a_{32r+31}\}\)을 유지한다.

([a_{i}]\)을 조작하기 위해, \(a_{i}\)이 저장된 레지스터(_i, \(\lfloor i/32\rfloor\)_)와 \(\ell\)는 조립 시간에 알아야 하며, 차선(_i, i_ mod 32)은 런타임 지식이 될 수 있다. 다양한 접근 패턴(이동, 임의 대 임의)이 제공되며, 우리는 나비 치환[29]을 광범위하게 사용한다.

### k-selection on CPU versus GPU

\(k\)-선택 알고리즘은 종종 임의로 큰 \(\ell\) 및 \(k\)에 대해, _radix selection_ 및 _bucket selection_[1], _probabilistic selection_[33], _quickselect_[14], _truncated sort_[40]을 포함하는 GPU로 번역될 수 있다. 이들의 성능은 글로벌 메모리에서의 입력에 대한 다중 패스에 의해 지배된다. 때때로 유사성 검색을 위해 입력 거리는 즉시 계산되거나 전체가 아닌 작은 블록에만 저장된다. 완전한 명시적 배열은 너무 커서 어떤 메모리에도 적합하지 않을 수 있으며, 처리 시작 시 크기를 알 수 없으며, 여러 번 통과해야 하는 렌더링 알고리즘은 비실용적이다. 그들은 다른 문제들도 겪습니다. Quickselect는 데이터 종속적인 메모리 이동인 크기 \(\mathcal{O}(\ell)\)의 저장소에 분할을 필요로 한다. 이는 동기화 오버헤드와 함께 과도한 메모리 트랜잭션을 초래하거나, 쓰기 오프셋을 결정하기 위해 병렬 프리픽스 합을 요구할 수 있다. 기수 선택에는 분할이 없지만 여러 번 통과해야 합니다.

**힙 병렬 처리.** 유사성 검색 애플리케이션에서 일반적으로 1000개 정도의 소수의 결과에만 관심이 있습니다. 이 체제에서, max-heap을 통한 선택은 CPU에서의 전형적인 선택이지만, 힙은 (직렬 트리 업데이트로 인해) 많은 데이터 병렬성을 노출시키지 않으며 SIMD 실행 유닛을 포화시킬 수 없다. _ad-heap_[31]은 이기종 시스템에서 사용할 수 있는 병렬성을 더 잘 활용하지만 적절한 실행 단위 간에 직렬 및 병렬 작업을 분할하려고 시도합니다. 힙 업데이트의 직렬성에도 불구하고, 작은 \(k\)의 CPU는 적은 노력으로 모든 상태를 L1 캐시에서 유지할 수 있으며, L1 캐시 지연 시간과 대역폭은 제한 요소로 남아 있다. PQ 코드 조작과 같은 다른 유사성 검색 컴포넌트들은 CPU 성능에 더 큰 영향을 미치는 경향이 있다[2].

**GPU 힙.** 힙은 GPU [7]에서 유사하게 구현할 수 있습니다. 그러나, 간단한 GPU 힙 구현은 각각의 삽입된 엘리먼트에 대해 취해진 경로가 힙 내의 다른 값들에 의존하기 때문에 높은 워프 발산과 불규칙하고 데이터 의존적인 메모리 이동을 겪는다.

GPU 병렬 우선 순위 큐 [24]는 여러 동시 업데이트를 허용 하 여 직렬 힙 업데이트보다 개선 되지만 각 삽입 및 데이터 종속 메모리 이동에 대 한 잠재적인 수의 작은 정렬이 필요 합니다. 또한, 서로 다른 스트림에서 커널 런치를 통해 다중 동기화 장벽을 사용하고, 연속 커널 런치의 추가 지연 시간과 CPU 호스트와의 조정을 사용한다.

다른 더 새로운 GPU 알고리즘이 작은 \(k\), 즉 _fgknn_ 라이브러리의 선택 알고리즘에 대해 이용 가능하다[41]. 이것은 너무 많은 동기화 포인트, 더 큰 커널 런칭 오버헤드, 더 느린 메모리의 사용, 계층 구조의 과도한 사용, 분할 및 버퍼링으로 인해 발생할 수 있는 복잡한 알고리즘이다. 그러나 _merge 큐_ 구조에서 볼 수 있듯이 병렬 병합을 사용 하 여이 특정 알고리즘에서 영감을 얻습니다.

## GPU에서 4 빠른 K-선택

모든 CPU 또는 GPU 알고리즘의 경우 _루프라인 성능 모델_[48]에 따라 메모리 또는 연산 처리량이 제한 요인이어야 합니다. 글로벌 메모리에서 입력의 경우 \(k\)-선택은 최대 메모리 대역폭에서 입력을 한 번 스캔하는 데 필요한 시간보다 빠르게 실행할 수 없습니다. 우리는 가능한 한 이 한계에 근접하는 것을 목표로 합니다. 따라서, (글로벌 메모리로부터 또는 온-더-플라이로 생성된, 아마도 데이터를 생성하는 커널과 융합된) 입력 데이터에 대한 단일 패스를 수행하고자 한다.

우리는 중간 상태를 가장 빠른 메모리인 레지스터 파일에 유지하고 싶습니다. 레지스터 메모리의 주요 단점은 어셈블리 시간에 레지스터 파일로의 인덱싱을 알아야 한다는 것이며, 이는 알고리즘의 강력한 제약이다.

### In-register sorting

우리는 등록자 내 분류 프리미티브를 빌딩 블록으로 사용한다. 정렬 네트워크는 벡터 병렬성을 이용하기 때문에 SIMD 아키텍처에서 일반적으로 사용된다[13]. GPU에서 쉽게 구현되며, 차선-스트라이드 레지스터 어레이를 사용하여 정렬 네트워크를 구축한다.

우리는 크기 \(2^{k}\)의 배열에 병렬 병합 집합인 _Batcher's bitonic sorting network_[8]의 변형을 사용한다. 각 병합은 \(\log_{2}(t)\) 병렬 단계를 사용하여 \(s\) 길이 배열 \(t\)(\(s\) 및 \(t\) 전력 2)에서 \(s/2\) 길이 배열 \(s/2\)로 변환한다. 비토닉 정렬은 이 병합을 재귀적으로 적용한다: 길이 배열 \(\ell\), 길이 배열 1부터 길이 배열 2까지 병합, 길이 배열 4까지 병합, 길이 배열 1부터 길이 배열 4까지 차례로 병합하여 \(\frac{1}{2}(\log_{2}(\ell)^{2}+\log_{2}(\ell))\) 병렬 병합 단계로 이어진다.

**홀수 크기 병합 및 정렬 네트워크입니다.* * 일부 입력 데이터가 이미 정렬된 경우 병합 단계를 피하기 위해 네트워크를 수정할 수 있습니다. 우리는 또한 데이터의 완전한 파워-of-2 세트를 가지고 있지 않을 수 있으며, 이 경우 더 작은 크기를 처리하기 위해 효율적으로 단축할 수 있다.

알고리즘 1은 이미 정렬된 _좌측_ 및 _우측_ 어레이를 병합하는 홀수 크기의 병합 네트워크로서, 각각의 임의의 길이이다. 비토닉 네트워크가 _비토닉_ 시퀀스를 병합하는 동안, 우리는 _단조_ 시퀀스: 단조롭게 정렬된 시퀀스로 시작한다. 비토닉 병합은 첫 번째 비교기 스테이지를 반전시켜 단조롭게 만든다.

```
functionmerge-odd(\([L_{i}]_{i=0:\ell_{L}},[R_{i}]_{i=0:\ell_{R}})\)do\(\triangleright\) inverted 1st stage; input is already sorted compare-swap(\(L_{\ell_{L}]_{i=0:\ell_{L}}\), left) merge-odd-continue(\([R_{i}]_{i=0:\ell_{R}}\), left) enddo endfunctionfunctionmerge-odd-continue(\([x_{i}]_{i=0:\ell-h}\)\(i\gets 0:\ell-h\)do\(\triangleright\)) if\(p=1\)leftthen\(2<\ell\rceil-1}\)\(i\gets 0:\ell-h\)do\(\triangleright\) inverter by warp shuffle butterfly compare-swap(\(x_{i},x_{i+h}\)) endfor paralleld
```

**알고리즘 1** Odd-size 병합 네트워크

홀수 크기 알고리즘은 패딩될 어레이를 더미와 함께 다음으로 높은 파워-of-2 크기에 고려하여 도출된다.

도 1: 크기 5 및 3의 홀수-크기 네트워크 병합 어레이. 벌릿은 병렬 비교/스왑을 나타낸다. 점선은 엘리티드 요소 또는 비교입니다.

스왑되지 않고(병합은 단조롭음) 이미 올바르게 배치된 요소입니다. 더미 요소와의 비교는 모두 제거됩니다. 왼쪽 배열은 처음에 더미 요소로 패딩된 것으로 간주되고 오른쪽 배열은 끝에 더미 요소를 포함한다. 길이 \(\ell_{L}\)과 \(\ell_{R}\)의 두 정렬된 배열을 \(\ell_{L}+\ell_{R}\)의 정렬된 배열로 병합하려면 \(\lceil\log_{2}(\max(\ell_{L},\ell_{R}))\rceil+1\) 병렬 단계가 필요하다. 그림 1은 4개의 병렬 단계를 가진 크기 5와 3의 배열에 대한 알고리즘 1의 병합 네트워크를 보여준다.

비교 스왑은 차선-스트라이드 레지스터 어레이 상의 와프 셔플을 사용하여 구현된다. 보폭 32의 배수로 스왑은 차선이 두 요소를 국부적으로 보유함에 따라 차선 내에서 직접 발생한다. 보폭의 스왑 \(\leq 16\) 또는 32의 비-다중은 워프 셔플과 함께 발생한다. 실제로, 사용된 배열 길이는 차선-스트라이드 배열에 유지됨에 따라 32의 배수이다.

```
function sort-odd(\([x_{i}]_{i=0:t}\)) if\(\ell>1\)then parallel do  sort-odd(\([x_{i}]_{i=0:\lfloor\ell/2\rfloor}\))  sort-odd(\([x_{i}]_{i=\lfloor\ell/2\rfloor:t}\))  end do  merge-odd(\([x_{i}]_{i=0:\lfloor\ell/2\rfloor},[x_{i}]_{i=\lfloor\ell/2\rfloor:t}\)) endif endfunction
```

**알고리즘 2** 홀수 크기 정렬 네트워크

알고리즘 2는 병합을 전체 정렬로 확장합니다. 입력 데이터에 구조가 존재하지 않는다고 가정하면, 길이 \(\ell\)의 데이터를 정렬하기 위해서는 \(\frac{1}{2}(\lceil\log_{2}(\ell)\rceil^{2}+\lceil\log_{2}(\ell)\rceil)\) 병렬 단계가 필요하다.

### WarpSelect

우리의 \(k\)-선택 구현인 WarpSelect는 레지스터에서 상태를 완전히 유지하며, 데이터를 통한 단일 패스만 요구하며 크로스워프 동기화를 피한다. 병합-홀수 및 정렬-홀수를 기본값으로 사용합니다. 레지스터 파일은 공유 메모리보다 훨씬 많은 저장 공간을 제공하기 때문에 \(k\leq 1024\)을 지원한다. 각 warp는 \(k\)-n\ 배열 중 하나의 배열로 선택된다 \([a_{i}]\). \(n\)이 충분히 크면 각 \([a_{i}]\)당 단일 warp가 전체 GPU 점유로 이어집니다. Warp당 큰 \(\ell\)은 미리 알려진 경우 재귀적 분해에 의해 처리된다.

**개요.** 우리의 접근 방식(알고리즘 3 및 그림 2)은 (단순화를 위해 설명에서 생략된) 관련 인덱스가 포함된 값으로 작동합니다. 그 값을 제공하는 다른 커널에 융합된 경우 전역 메모리 또는 중간 값 레지스터에서 나오는 \(k\) 최소 값을 선택한다. \([a_{i}]_{i=0:\ell}\)을 선택을 위해 제공된 시퀀스로 가정합니다.

요소들(도 2의 좌측)은 워프 크기인 32의 그룹으로 처리된다. 레인 \(j\)은 \(\{a_{j},a_{32+j},...\}\); 따라서, 엘리먼트들이 글로벌 메모리로부터 나온다면, 판독들은 인접하고 최소 수의 메모리 트랜잭션들로 합체된다.

**데이터 구조.** 각 레인 \(j\)은 _thread queues_\([T_{i}^{j}]_{i=0:t}\)라고 하는 레지스터에 \(t\) 요소의 작은 큐를 유지 합니다 (\(T_{i}^{j}\geq T_{i+1}^{j}\)). \(t\)의 선택은 \(k\)에 대해 이루어집니다. 섹션 4.3을 참조하세요. 스레드 큐는 새로 들어오는 값에 대한 첫 번째 수준 필터입니다. f. 새로운 \(a_{32i+j}\)는 현재 큐에 있는 가장 큰 키인 \(T_{0}^{j}\)보다 크므로 \(k\) 가장 작은 최종 결과가 되지 않을 것임을 보장한다.

Warp 큐라고 불리는 \(k\)개의 가장 작은 볼 수 있는 요소들, \([W_{i}]_{i=0:k}\)의 레인-스트라이드 레지스터 어레이를 공유한다. 가장 작은 것부터 가장 큰 것(\(W_{i}\leq W_{i+1}\))으로 정렬하고, 요청된 \(k\)이 32의 배수가 아니면 반올림한다. 이는 \(k\) 가장 작은 warp-wide 보기 값을 모두 유지 하는 데 사용 되는 두 번째 수준 데이터 구조입니다. 스레드와 warp 큐는 최대 센티널 값 _예:_, \(+\infty\)으로 초기화됩니다.

**업데이트.** 유지 관리 되는 세 가지 불변은 다음과 같습니다.

* 모든 레인당 \(T_{0}^{j}\)은 min-\(k\)에 없습니다.
* 모든 차간 \(T_{0}^{j}\)은 모든 warp 큐 키 \(W_{i}\)보다 큽니다.
* min-\(k\)에서 지금까지 볼 수 있는 모든 \(a_{i}\)은 일부 차선의 스레드 큐(\([T_{i}^{j}]_{i=0:t,j=0:32}\)) 또는 와프 큐에 포함되어 있다.

차선 \(j\)은 새로운 \(a_{32i+j}\)을 수신하여 스레드 큐에 삽입을 시도한다. 만약 \(a_{32i+j}>T_{0}^{j}\)이면, 새로운 쌍은 정의상 \(k\) 최소가 아니며 거절될 수 있다.

그렇지 않으면 스레드 큐의 정렬된 위치에 삽입되어 이전 \(T_{0}^{j}\)을 내보낸다. 모든 차선은 새로운 수신 쌍과 스레드 큐로 이 작업을 완료하지만, 이제 두 번째 불변수가 위반되었을 가능성이 있다. `warp ballot` 명령을 사용 하 여 차선이 두 번째 불변수를 위반 했는지 확인 합니다. 그렇지 않으면 새로운 요소를 계속 처리할 수 있습니다.

**불변수를 복원 합니다.* * 차선에 불변수가 위반 된 경우 와프는 홀수 병합을 사용 하 여 스레드와 와프 큐를 병합 하 고 정렬 합니다. 새 워프 큐

```
function WarpSelect(\(a\)) if\(a<T_{0}^{j}\)then insert \(a\) if\(\textsc{warp-ballot}(T_{0}^{j}<W_{k-1})then \(\triangleright\) then \(\alpha_{i}]_{i=0:32t}\leftarrow\textsc{cast}([T_{i}^{j}]_{i=0:t,j=0:32t})\) \(\triangleright\) concatenate and sort thread queues \(\textsc{sort-odd}([\alpha_{i}]_{i=0:32t})\) \(\triangleright\) merge-odd(\([W_{i}]_{i=0:k},[\alpha_{i}]_{i=0:32t})\) \(\triangleright\) thread-stride array as thread queues \([T_{i}^{j}]_{i=0:t,
```

**알고리즘 3** WarpSelect pseudocode for lane \(j\)

도 2: WarpSelect의 개요. 입력값들은 좌측에서 스트림 인되고, 우측의 워프 큐는 출력 결과를 유지한다.

병합된 정렬된 큐에 걸쳐 최소-\(k\) 요소가 되고, 새로운 스레드 큐는 최소-\((k+1)\)에서 최소-\((k+32t+1)\)까지의 나머지가 된다. 이렇게 하면 불변수가 복원되고 후속 요소를 계속 처리할 수 있습니다.

스레드와 워프 큐는 이미 정렬되어 있기 때문에 32개의 정렬된 길이 배열 \(t\)과 길이 \(k\)의 정렬된 워프 큐를 병합한다. 홀수 크기의 병합을 지원하는 것은 Batcher의 공식은 \(32t=k\)이 필요하고 2의 거듭제곱이므로 \(k=1024\)이면 \(t\)이 32가 되어야 하기 때문에 중요하다.

32개의 이미 정렬된 스레드 큐를 병합하기 위해 홀수 병합을 사용하면 \(t\)개의 연속적인 정렬된 값이 차선 가닥 배열이 아닌 동일한 차선의 다른 레지스터에 유지되기 때문에 워프를 가로지르는 레지스터에서 _구조 배열_ 전위를 위해 _구조 배열_이 필요하다. 이것은 [12] 가능하지만, 비슷한 수의 워프 셔플을 사용할 것이므로, 우리는 스레드 큐 레지스터들을 (정렬되지 않은) 레인-스트라이드 어레이로서 재해석하고 처음부터 정렬할 뿐이다. 와프 큐와 집계 정렬된 스레드 큐의 병합을 위해 홀수 병합을 사용하여 상당한 속도 향상을 실현할 수 있다.

**나머지를 처리 합니다.* * \(\ell\)이 32의 배수가 아니기 때문에 나머지 요소가 있는 경우 해당 요소가 있는 레인에 대 한 스레드 큐에 삽입 된 후 출력 단계로 진행 합니다.

**출력.** 스레드와 warp 큐로 최종 정렬 및 병합이 이루어지며, 이후 warp 큐는 모든 min-\(k\) 값을 보유합니다.

### 복잡성 및 매개 변수 선택

32개의 엘리먼트들의 각각의 들어오는 그룹에 대해, WarpSelect는 1, 2 또는 3개의 일정한-시간 동작들을 수행할 수 있으며, 이들은 모두 warp-wide 병렬 시간에서 일어난다:

1. 읽기 32 요소, 모든 스레드 큐 헤드와 비교 \(T_{0}^{j}\), 비용 \(C_{1}\), 발생 \(N_{1}\);
2. \(\exists j\in\{0,...,31\}\), \(a_{32n+j}<T_{0}^{j}\)이 특정 스레드 큐에 삽입 정렬을 수행하면 비용 \(C_{2}=\mathcal{O}(t)\), 발생 \(N_{2}\);
3. \(\exists j,T_{0}^{j}<W_{k-1}\), 정렬 및 병합 큐, 비용 \(C_{3}=\mathcal{O}(t\log(32t)^{2}+k\log(\max(k,32t))))\), 발생횟수는 \(N_{3}\)이다.

따라서 총비용은 \(N_{1}C_{1}+N_{2}C_{2}+N_{3}C_{3}\)이다. \ (N_{1}=\ell/32\), 그리고 독립적으로 그려진 랜덤 데이터에 대해, \(N_{2}=\mathcal{O}(k\log(\ell))\)와 \(N_{3}=\mathcal{O}(k\log(\ell)/t)\은 전체 도출을 위해 부록을 참조한다. 따라서 절충안은 \(N_{2}C_{2}\)과 \(N_{3}C_{3}\)의 비용 균형을 맞추는 것이다. \(k\)과\(ell\)이 주어진 \(t\)에 대한 실용적인 선택은 다양한 \(k\)-NN 데이터에 대한 실험을 통해 이루어졌다. \(k\leq 32\)의 경우 \(t=2\), \(k\leq 128\)은 \(t=3\), \(k\leq 256\)은 \(t=4\), \(k\leq 1024\)은 \(t=8\)을 사용한다.

## 5 계산 레이아웃

이 섹션은 원래 제품 양자화[25]에 기초하여 구축된 인덱싱 방법들 중 하나인 IVFADC가 어떻게 효율적으로 구현되는지를 설명한다. 거리 계산 및 \(k\)-선택을 통한 조음에 대한 자세한 내용은 이 방법이 더 최근의 GPU 준수 근사 최근접 이웃 전략을 능가할 수 있는 이유를 이해하는 열쇠이다[47].

### Exact search

우리는 종종 정확한 무차별 힘이라고 불리는 철저한 탐색 방법으로 간단히 돌아간다. 작은 데이터 세트에서 정확한 가장 가까운 이웃 검색을 위해 자체적으로 흥미롭다. 또한 문헌에 있는 많은 인덱스의 구성 요소이기도 합니다. 본 논문에서는 이를 IVFADC coarse 양자화기 \(q_{1}\)에 사용한다.

2절에서 언급했듯이 거리 계산은 행렬 곱셈으로 귀결된다. CuBLAS 라이브러리에서 최적화된 GEMM 루틴을 사용하여 L2 거리에 대한 \(-2\langle x_{j},y_{i}\rangle\) 항을 계산하여 부분 거리 행렬 \(D^{\prime}\)을 생성한다. 거리 계산을 완료하기 위해 거리 행렬의 각 엔트리에 \(\|y_{i}\|^{2}\)항을 추가한 융합된 \(k\)-선택 커널을 사용하여 레지스터에서 \(k\)-선택에 값을 즉시 제출한다. \(k\)-선택 전에 \(\|x_{j}\|^{2}\)항을 고려할 필요가 없다. 따라서 커널 융합은 3개 이상의 구현이 필요할 수 있는 다른 구현과 비교하여 \(D^{\prime}\)에 대해 2개의 패스(GEMM 쓰기, \(k\)-선택 읽기)만 허용한다. 행 방향 \(k\)-선택은 잘 조정된 GEMM 커널과 융합할 수 없거나 전체 효율성을 낮출 수 있다.

D^{\prime\(D^{\prime}\)이 GPU 메모리에 적합하지 않기 때문에, 문제는 질의의 배치 위에 타일링되며, \(t_{q}\leq n_{q}\) 질의는 단일 타일에서 실행된다. 각각의 \(\lceil n_{q}/t_{q}\rceil\) 타일은 독립적인 문제이지만 GPU를 더 잘 차지하기 위해 서로 다른 스트림에서 병렬로 두 개를 실행하므로 \(D\)의 유효 메모리 요구량은 \(\mathcal{O}(2\ell t_{q})\이다. 계산은 마찬가지로 \(\ell\)에 타일링될 수 있습니다. CPU에서 들어오는 매우 큰 입력의 경우 고정 메모리를 사용 하 여 CPU를 겹치도록 버퍼링을 지원 하 여 GPU 계산을 사용 하 여 GPU 복사를 수행 합니다.

### IVFADC indexing

**PQ 조회 테이블.** 핵심에서 IVFADC는 벡터에서 제품 양자화 재생 값 집합까지의 거리를 계산해야 합니다. 데이터베이스 벡터 \(y\)에 대한 수학식 6을 개발함으로써, 다음을 얻는다:

\[\|x-q(y)\|_{2}^{2}=\|x-q_{1}(y)-q_{2}(y-q_{1}(y))\|_{2}^{2}. \tag{7}\]

다음과 같이 \(q_{1}\) 뒤에 남겨진 잔차 벡터를 분해하면 다음과 같습니다.

\[y-q_{1}(y) = [\widetilde{y^{1}}\cdots\widetilde{y^{b}}]\text{ and } \tag{8}\] \[x-q_{1}(y) = [\widetilde{x^{1}}\cdots\widetilde{x^{b}}] \tag{9}\]

그런 다음 거리를 다음과 같이 다시 씁니다.

\[\|x-q(y)\|_{2}^{2}=\|\widetilde{x^{1}}-q^{1}(\widetilde{y^{1}})\|_{2}^{2}+...+ \|\widetilde{x^{b}}-q^{b}(\widetilde{y^{b}})\|_{2}^{2}. \tag{10}\]

각 양자화기 \(q^{1},...,q^{b}\)는 256개의 재생값을 가지므로 \(x\)과 \(q_{1}(y)\)이 알려진 경우 모든 거리를 미리 계산하여 256[25] 크기의 테이블 \(T_{1},...,T_{b}\)에 저장할 수 있다. 합(10)을 계산하는 것은 \(b\) 룩업 및 덧셈으로 구성된다. \(n\) 거리를 계산하는 비용을 비교하는 것은 다음과 같습니다.

* 명시적 계산: \(n\times d\) multiply-adds;
* 조회 테이블: \(256\times d\) multiply-adds 및 \(n\times b\) lookup-adds입니다.

이것이 제품 양자화기의 효율성의 핵심입니다. GPU 구현에 있어서, \(b\)는 최대 4에서 64까지의 임의의 배수이다. 코드들은 리스트 내에서 벡터당 \(b\)바이트의 순차적인 그룹으로 저장된다.

**IVFADC 조회 테이블.** 반전된 목록의 요소를 검색 하는 경우 \(\mathcal{I}_{L}\)(정의상 \(q_{1}(y)\)는 상수) \(x\) 및 \(q_{1}(y)\)이 알려져 있으므로 조회 테이블 방법을 적용할 수 있습니다.

또한 테이블 \(T_{1}\ldots T_{b}\)의 계산은 [5]를 더욱 최적화하였다. 식 (7)에서 \(\|x-q(y)\|_{2}^{2}\)의 표현은 다음과 같이 분해될 수 있다:

\[\underbrace{\|q_{2}(...)\|_{2}^{2}+2\langle q_{1}(y),q_{2}(...)\rangle}_{\text {term 1}}+\underbrace{\|x-q_{1}(y)\|_{2}^{2}}_{\text{term 2}}-2\underbrace{\langle x,q_{2}(...)\rangle}_{\text{term 3}}. \tag{11}\]

목적은 내부 루프 계산을 최소화하는 것이다. 미리 계산하여 룩업 테이블에 저장할 수 있는 계산은 다음과 같습니다.

* 용어 1은 쿼리와 무관합니다. 양자화기로부터 미리 계산되어 크기 \(|\mathcal{C}_{1}|\times 256\times b\)의 테이블 \(\mathcal{T}\)에 저장될 수 있으며;
* Term 2는 \(q_{1}\)'의 재생값까지의 거리이다. 따라서 첫 번째 레벨 양자화기 \(q_{1}\)의 부산물이다;
* 항 3은 반전된 목록과 독립적으로 계산할 수 있습니다. 계산 비용은 \(d\times 256\) 곱하기-adds이다.

이 분해는 반전된 리스트의 스캔 동안 사용되는 룩업 테이블 \(T_{1}\ldots T_{b}\)을 생성하는 데 사용된다. 단일 질의의 경우, 스크래치로부터 \(\tau\times b\) 테이블을 계산하는 것은 \(\tau\times d\times 256\) 곱하기-adds를 소모하고, 이 분해는 \(256\times d\) 곱하기-adds와 \(\tau\times b\times 256\) 덧셈을 소모한다. GPU에서는 \(\mathcal{T}\)의 메모리 사용이 금지될 수 있으므로 메모리가 중요하지 않은 경우에만 분해를 가능하게 한다.

### GPU implementation

알고리즘 4는 CPU에서 구현하는 프로세스를 요약한다. 반전된 리스트들은 PQ 코드들 및 연관된 ID들에 대해, 두 개의 별개의 어레이들로서 저장된다. ID는 \(k\)-선택이 \(k\)-최근 멤버 자격을 결정 하는 경우에만 해결 됩니다. 이러한 룩업은 큰 어레이에서 몇 개의 희소 메모리 판독을 산출하므로, ID는 선택적으로 작은 성능 비용을 위해 CPU에 저장될 수 있다.

**목록 검색.** 커널은 각 쿼리에 대해 \(\tau\) 가장 가까운 반전된 목록을 검색하고 룩업 테이블 \(T_{i}\)을 사용하여 벡터당 쌍 거리를 계산하는 역할을 합니다. 이 \(T_{i}\)는 공유 메모리에 저장된다. \(n_{q}\times\tau\times\max_{i}|\mathcal{I}_{i}|\times b\)의 검색은 질의 집합(실제로 수조 번의 접근)에 필요하며, 임의 접근이다. 이것은 \(b\)를 현재 아키텍처를 갖는 최대 48개(32비트 부동 소수점) 또는 96개(16비트 부동 소수점)로 제한한다. 식 (11)의 분해를 사용하지 않을 경우 \(T_{i}\)은 스캐닝 전에 별도의 커널에 의해 계산된다.

**다중 패스 커널.** 반전 된 목록에 대 한 쿼리의 각 \(n_{q}\times\tau\) 쌍은 독립적으로 처리 될 수 있습니다. 한 극단에서, 블록은 이들 각각에 전용되고, 최대 \(n_{q}\times\tau\times\max_{i}|\mathcal{I}_{i}|\) 부분 결과들은 글로벌 메모리에 다시 기록되고, 이어서 \(k\)-선택된 결과는 \(n_{q}\times k\) 최종 결과들로 이어진다. 이는 높은 병렬성을 제공하지만 GPU 전역 메모리를 능가할 수 있다. 정확한 검색과 마찬가지로 메모리 소모를 줄이기 위해 타일 크기 \(t_{q}\leq n_{q}\)를 선택하며, 다중 스트리밍으로 복잡도를 \(\mathcal{O}(2t_{q}\tau\max_{i}|\mathcal{I}_{i}|)\)로 제한한다.

단일 워프는 \(k\)-각 \(t_{q}\) 목록 집합을 선택하는 데 전용될 수 있으며, 이는 낮은 병렬성을 초래할 수 있다. 본 논문에서는 2-pass \(k\)-선택을 도입하여 부분구분인자 \(f\)에 대하여 \(t_{q}\times\tau\times\max_{i}|\mathcal{I}_{i}|\)을 \(t_{q}\times f\times k\)으로 축소시켰다. 이것은 \(k\)-선택을 통해 최종 \(t_{q}\times k\) 결과로 다시 감소된다.

**융합된 커널.** 정확한 검색과 마찬가지로 단일 쿼리에 대 한 모든 \(\tau\) 목록을 검색 하는 데 단일 블록을 전용 하는 커널을 사용 하 여 \(k\)-선택을 거리 계산과 융합 했습니다. 이것은 WarpSelect가 심각하게 제한된 공유 메모리 자원을 위해 싸우지 않기 때문에 가능하다. 이것은 거의 모든 중간 결과들이 제거될 수 있기 때문에, 글로벌 메모리 기록-백을 감소시킨다. 그러나 정확한 계산을 위한 \(k\)-선택 오버헤드와 달리, 런타임의 상당 부분은 공유 메모리의 \(T_{i}\)과 전역 메모리의 \(\mathcal{I}_{i}\)의 선형 스캐닝에서 수집되며, 쓰기-백은 지배적인 기여자가 아니다. 융합된 커널의 타이밍은 최대 15% 향상되며, 일부 문제 크기의 경우 후속 분해 없이 병렬성이 낮고 성능이 더 나빠질 수 있다. 그러므로, 그리고 구현 단순성의 이유로, 우리는 이 레이아웃을 사용하지 않는다.

```
functionifpPQ-search(\([x_{1},...,x_{n_{q}}]\), \(\mathcal{I}_{1},...,\mathcal{I}_{|\mathcal{C}_{1}|\)) for 5.1\(L_{\text{UF}}^{i}\leftarrow\tau\text{-}\text{argmin}_{c\in\mathcal{C}_{1}\|x-c \|_{2}\) endfor for\(i\gets 0:n_{q}\)do\(L\leftarrow[]\)\(\triangleright\) distance table  \(L_{\text{UF}}^{L}\)do\(\triangleright\) loop  \(\mathcal{I}_{L}\)do\(\triangleright\) distance estimation, Equation (10) \(d\leftarrow\|x_{i}-q(y_{j})\|_{2}^{2}\)  Append \(
```

**알고리즘 4** IVFPQ 일괄 검색 루틴

### Multi-GPU parallelism

최신 서버는 여러 GPU를 지원할 수 있습니다. 우리는 계산 능력과 메모리 모두에 이 기능을 사용합니다.

**복제.** 인덱스 인스턴스가 단일 GPU의 메모리에 적합하면 \(\mathcal{R}\) 다른 GPU에서 복제할 수 있습니다. \(n_{\text{q}}\) 벡터를 쿼리 하려면 각 복제본은 쿼리의 분수 \(n_{\text{q}}/\mathcal{R}\)를 처리 하 여 단일 GPU 또는 CPU 메모리에서 결과를 다시 결합 합니다. 복제는 작은 \(n_{\text{q}}\)에 대한 효율의 잠재적 손실을 제외하고 거의 선형 속도 향상을 갖는다.

**Sharding.** 인덱스 인스턴스가 단일 GPU의 메모리에 맞지 않는 경우 인덱스를 \(\mathcal{S}\) 다른 GPU에 분할할 수 있습니다. \(\ell\) 벡터를 추가하기 위해, 각 샤드는 벡터들의 \(\ell/\mathcal{S}\)을 수신하고, 질의의 경우, 각 샤드는 전체 질의 집합 \(n_{\text{q}}\)을 처리하며, 단일 GPU 또는 CPU 메모리에서 부분 결과를 결합(\(k\)-선택의 추가 라운드가 여전히 필요하다)한다. 주어진 인덱스 크기 \(\ell\)의 경우, 샤딩은 \(\ell/\mathcal{S}\)에 대해 \(n_{\text{q}\)의 질의를 갖는 반면 \(\ell\)에 대해 \(n_{\text{q}}/\mathcal{R}\)의 질의를 갖는 복제는 속도를 향상시키지만, 일반적으로 고정된 오버헤드와 후속 \(k\)-선택의 비용으로 인해 순수 복제보다 적다.

복제 및 샤딩은 함께 사용할 수 있습니다 (\(\mathcal{S}\) 샤드, 각각 \(\mathcal{R}\) 복제본과 함께 \(\mathcal{S}\times\mathcal{R}\) GPU를 모두 사용할 수 있습니다. 공유 또는 복제는 모두 상당히 사소하며 동일한 원칙을 사용하여 여러 컴퓨터에 인덱스를 배포할 수 있습니다.

## 6 실험 및 응용 프로그램

이 섹션에서는 GPU \(k\)-선택 및 최근접 이웃 접근 방식을 기존 라이브러리와 비교 합니다. 달리 명시되지 않는 한, CUDA 8.0에서 4개의 맥스웰 타이탄 X GPU를 사용하여 2\(\times\)2.8GHz 인텔 제온 E5-2680v2에서 실험이 수행된다.

### k-selection performance

Tang et al. [41]의 _fgbnn_ 라이브러리와 Sismanis et al. [40]의 Truncated Bitonic Sort (_TBiS_)에서 추출한 Buffered Search와 Hierarchical Partition을 이용한 행 기반 병합 큐(row-based Merge Queue with Buffered Search and Hierarchical Partition)를 다른 두 GPU 소형 \(k\)-선택 구현과 비교한다. 둘 다 각각의 정확한 검색 라이브러리에서 추출되었다.

단일 타이탄 X에서 랜덤 32비트 부동소수점 값의 행-주 행렬 \(n_{q}\times\ell\)에서 각 행의 \(k=100\)과 \(1000\)에 대한 \(k\)-선택을 평가한다. 배치 크기 \(n_{q}\)는 \(10000\)으로 고정되고 배열 길이 \(\ell\)은 \(1000\)에서 \(128000\)까지 다양하다. 문제에 대한 입력과 출력은 GPU 메모리에 상주하며 출력은 크기 \(n_{q}\times k\)이고 해당 인덱스가 있다. 따라서 입력 문제 크기는 \(40\,\text{MB}\) (\(\ell\!=\!) 범위입니다. 1000\)) to \(5.12\,\text{GB}\)(\(\ell\!=\!128\)k). TBiS는 대용량의 보조 저장장치를 필요로 하며, 본 연구에서는 \(\ell\leq 48000\)으로 제한하였다.

그림 3은 TBiS 및 fignn에 대한 상대적 성능을 보여준다. 또한 타이탄 X의 메모리 대역폭 제한에 의해 주어진 최대 가능한 성능을 포함한다. WarpSelect의 상대적 성능은 무화과보다 큰 \(k\)에 대해 증가하며, TBiS도 \(k=1000\)에서 더 큰 \(\ell\)에 대해 무화과보다 성능이 향상되기 시작한다. 우리는 특히 가장 큰 \(\ell=128000\)을 본다. WarpSelect는 \(k=100\), \(k=1000\)에서 \(1.62\times\) 더 빠르다. 최대 가능한 성능에 대한 성능은 더 큰 \(k\)에서 모든 구현에 대해 떨어진다. WarpSelect는 \(k=100\)에서는 \(55\%\) 피크에서 동작하지만 \(k=1000\)에서는 \(16\%\) 피크에서만 동작한다. 이는 큰 \(k\)에 대 한 더 큰 스레드 큐 및 병합/정렬 네트워크와 연결 된 추가 오버헤드 때문입니다.

**무화과와의 차이점.** WarpSelect는 무화과의 영향을 받지만 몇 가지 개선 사항이 있습니다. 모든 상태는 레지스터에 유지 됩니다 (공유 메모리 없음), 워프 간 동기화 또는 버퍼링 사용 안 함, "계층적 파티션" 사용 안 함 \(k\)-선택은 다른 커널에 융합할 수 있으며 효율적인 병합 및 정렬을 위해 홀수 크기 네트워크를 사용 합니다.

### k-means clustering

\(k=1\)의 정확한 탐색 방법은 할당 단계에서 \(k\)-평균 클러스터링 방법을 사용하여 \(n_{\text{q}}\) 훈련 벡터를 \(|\mathcal{C}_{1}|\) 센트로이드에 할당할 수 있다. IVFADC를 사용하지 않고 \(k=1\)선택이 간단함에도 불구하고 (WarpSelect가 아닌 \(k=1\)의 경우 병렬 축소가 사용됨) \(k\)-평균은 양자화기 \(q_{1}\)을 훈련하는 데 사용되는 클러스터링에 좋은 벤치마크이다.

제안된 알고리즘을 MNIST8m 영상에 적용하였다. 8.1M 이미지는 784-d의 벡터로 선형화된 28x28 픽셀의 그레이레벨 디지트이다. 본 논문에서는 이 \(k\)-평균의 구현과 BIDMach [11]의 GPU \(k\)-평균을 비교하여 수십 대의 머신 3을 필요로 하는 여러 분산 \(k\)-평균 구현보다 더 효율적인 것으로 나타났다. 두 알고리즘 모두 20번의 반복에 대해 실행되었다. 표 1은 두 가지 모두 cuBLAS를 기반으로 하지만 우리의 구현이 \(\mathbf{2}\times\)**보다 빠르다는 것을 보여준다. 이 구현은 L2 거리 계산에 \(k\)-선택 융합을 통해 이점을 얻는다. 복제본을 통한 다중 GPU 실행의 경우 4096 센트로이드가 있는 4개의 GPU에 대해 충분히 큰 문제 (\(3.16\times\)에 대해 속도 향상은 선형에 가깝습니다. 이 벤치마크는 일반적으로 적은 수의 중심이 요청될 때 데이터 세트를 무작위로 하위 샘플링하기 때문에 다소 비현실적입니다.

각주 3: [https://github.com/BIDData/BIDMach/wiki/Benchmarks#KMeans](https://github.com/BIDData/BIDMach/wiki/Benchmarks#KMeans)의 BIDMach 번호입니다.

**대규모.** \(10^{8}\) 128-d 벡터를 85k centroids로 클러스터링하는 근사 CPU 방법인 [3]과 비교할 수도 있습니다. 그들의 클러스터링 방법은 46분 내에 실행되지만, 벡터를 인코딩하기 위해 56분(적어도)의 사전 처리가 필요하다. 이 방법은 사전 처리 없이 52분 안에 4개의 GPU에 대해 _exact_ k-means를 수행합니다.

### Exact nearest neighbor search

우리는 최근접 이웃 검색: Sift1M[25]을 평가하기 위해 사용되는 고전적인 데이터세트를 고려한다. 특징적인 크기는 \(\ell=10^{6}\), \(d=128\), \(n_{\text{q}}=10^{4}\)이다. 부분 거리 행렬 \(D^{\prime}\)을 계산하면 \(n_{\text{q}}\times\ell\times d=1.28\) Tflop이 소요되며, 이는 현재 GPU에서 1초 이내에 실행된다. 그림 4는 식 2의 \(-2\left\langle x_{j},y_{\text{t}}\right\rangle\) 항에 대한 GEMM의 타일링 비용에 대한 거리 계산 비용과 피크 메모리 대역폭에서 타일링된 결과 행렬 \(D^{\prime}\)을 추가로 설명하는 크기 \(n_{\text{q}}\times\ell\)의 거리 행렬에 대한 최대 가능 \(k\)-선택 성능을 보여준다.

섹션 5의 방법 외에도 섹션 6.1에서 \(k\)-선택 성능에 대해 평가된 두 GPU 라이브러리의 시간을 포함한다.

* for \(k\)-선택, thrust::sort_by_key를 사용하여 각 쿼리에 대한 전체 결과 배열을 정렬하는 naive 알고리즘은 비교 방법보다 속도가 \(10\times\) 이상 느립니다.
* L2 거리 및 \(k\)-선택 비용이 GEMM 사용량과 타일링을 가정 하 여 **85 %의 피크** 가능한 성능을 갖는 방법을 제외한 모든 방법에 대해 우세 합니다.

\begin{table}
\begin{tabular}{l c c c} \hline \hline  & & \multicolumn{2}{c}{\# centroids} \\ method & \# GPUs & 256 & 4096 \\ \hline BIDMach [11] & 1 & 320 s & 735 s \\ Ours & 1 & 140 s & 316 s \\ Ours & 4 & 84 s & 100 s \\ \hline \hline \end{tabular}
\end{table}
표 1: MNIST8m \(k\)-수단 성능

그림 3: 배열 길이 \(\ell\)의 함수로 다른 \(k\)-선택 방법에 대한 런타임. 처리된 동시 배열은 \(n_{q}=10000\)입니다. \ (k=100\), \(k=1000\).

GEMM 상단의 부분거리 행렬 \(D^{\prime}\)이 최적에 가깝다. cuBLAS GEMM 자체는 작은 감소 크기에 대해 낮은 효율을 갖는다(\(d=128\));
* 융합된 L2/\(k\)-선택 커널이 중요합니다. 융합이 없는 동일한 정확한 알고리즘(\(D^{\prime}\)을 추가로 통과해야 함)은 최소 25% 더 느리다.

거리 계산에 대한 \(k\)-선택의 상대적 비용이 증가하기 때문에 대략적인 방법을 사용하여 거리를 계산하는 상황에서는 효율적인 \(k\)-선택이 훨씬 더 중요하다.

### Billion-scale 근사 검색

대규모 데이터셋(\(\ell\gg 10^{6}\))에 대한 GPU 기반 근사 최근접 이웃 탐색에 대한 연구는 거의 없다. 이 분야의 표준 데이터 세트와 평가 프로토콜을 사용하여 인덱스 검색에 대한 몇 가지 비교 지점을 보고한다.

**SIFT1M.** 완전성을 위해 먼저 Sift1M에서 GPU 검색 속도를 Wieschollek 등의 구현과 비교합니다. [47]. 그들은 R@1 = 0.51의 1(진정한 가장 가까운 이웃이 상위 1 결과에 있는 쿼리의 부분)에서 가장 가까운 이웃 리콜을 얻고, 타이탄 X의 쿼리당 0.02ms에서 R@100 = 0.86을 얻는다. 동일한 시간 버짓에 대해, 우리의 구현은 R@1 = 0.80 및 R@100 = 0.95를 얻는다.

**SIFT1B.** \(n_{\mathrm{q}}=10^{4}\)에서 10억 SIFT 이미지 특징의 Sift1B 데이터 세트 [26]에서 Wieschollek 등과 다시 비교 합니다. 유사한 정확도에 대해 동일한 메모리 사용량 측면에서 검색 성능을 비교한다(더 정확한 방법은 더 큰 검색 시간 또는 메모리 사용량을 수반할 수 있다). 단일 GPU에서 벡터당 \(m=8\) 바이트로 쿼리 벡터당 17.7 \(\mu\)s에서 R@10 = 0.376인 반면 쿼리 벡터당 150 \(\mu\)s에서 보고된 R@10 = 0.35입니다. 따라서 구현은 **8.5\(\times\) 더 빠른** 속도로 더 정확합니다.

**DEEP1B.** \(\ell\)=10억 CNN 표현의 Deep1B 데이터 집합 [6]을 \(n_{\mathrm{q}}=10^{4}\)에서 실험했습니다. 데이터세트를 소개하는 논문은 CPU 결과(1 thread): R@1 = 0.45를 벡터당 20ms 탐색 시간으로 보고한다. 본 논문에서는 OPQ [17]을 통해 \(m=20\), \(d=80\), \(|\mathcal{C}_{1}|=2^{18}\)의 PQ 인코딩을 사용하며, 원본 논문(20 GB)과 유사한 데이터셋 저장소를 사용한다. 이는 단일 GPU의 전역 메모리에 비해 너무 커서 여러 개의 GPU가 필요하므로, \(\mathcal{S}=2\), \(\mathcal{R}=2\)의 4개의 GPU를 고려한다. 우리는 벡터당 0.0133 ms에서 R@1 = 0.4517을 얻는다. 하드웨어 플랫폼은 다르지만 GPU에서 검색을 하는 것은 단일 컴퓨터에서 달성할 수 있는 속도 측면에서 게임 체인저임을 보여준다.

### k-NN 그래프

유사도 검색 방법의 예는 brute force(전체 인덱스에 대해 질의된 모든 벡터)를 통해 데이터 세트의 \(k\)_-최근접 이웃 그래프_를 구성하는 것이다.

**실험 설정.** Yfcc100M 데이터 집합 [42] 및 Deep1B의 9500만 이미지 두 데이터 집합에서 속도, 정밀도 및 메모리 간의 균형을 평가 합니다. Yfcc100M의 경우 PCA를 사용하여 \(d\) = 128로 축소된 ResNet [23]의 마지막 계층으로 CNN 기술자를 계산한다.

평가는 다음과 같은 트레이드오프를 측정합니다.

* 속도: 처음부터 IVFADC 인덱스를 빌드하고 데이터 세트의 모든 벡터에 대해 가장 가까운 이웃을 검색하여 전체 \(k\)-NN 그래프(\(k=10\))를 구성하는 데 걸리는 시간입니다. 따라서, 이것은 검색 시간뿐만 아니라 인덱싱을 포함하는 엔드 투 엔드 테스트;
* 품질: 정확한 가장 가까운 이웃을 계산하는 10,000개의 이미지를 샘플링합니다. 우리의 정확도 측정은 지상-진실 10개의 가장 가까운 이웃 내에 있는 10개의 발견된 가장 가까운 이웃의 분수이다.

Yfcc100M의 경우 거친 양자화기(\(2^{16}\) centroids)를 사용하고 각 벡터에 대해 \(m=16\), 32 및 64 바이트 PQ 부호화를 고려한다. Deep1B의 경우 OPQ를 통해 \(d=120\)으로 벡터를 전처리하고 \(|\mathcal{C}_{1}|=2^{18}\)을 사용하며 \(m=20\), 40을 고려한다. 주어진 인코딩의 경우 그림 5와 같이 \(\tau\)을 1에서 256까지 변화시켜 효율성과 품질 간의 절충점을 구한다.

도 4: 1 Titan X GPU에서 \(k\)이 변하는 SIFT1M 데이터세트에 대한 정확한 검색 \(k\)-NN 시간.

그림 5: YFCC100M 및 DEEP1B 데이터 세트에 대한 브루트 포스 10-NN 그래프 구성의 속도/정확도 절충.

**토론.** Yfcc100M의 경우 \(\mathcal{S}=1\), \(\mathcal{R}=4\)을 사용했습니다. 35분 만에 0.8 이상의 정확도를 얻을 수 있습니다. Deep1B의 경우 6시간 안에 더 낮은 품질의 그래프를 구축할 수 있으며, 반나절 정도면 더 높은 품질을 얻을 수 있다. 또한 8개의 맥스웰 M40을 사용하여 복제 세트를 두 배로 늘려 더 많은 GPU를 실험했다(M40은 타이탄 X와 성능이 대략 동일하다). 성능은 \(m=20\)의 경우 \(\sim 1.6\times\), \(m=40\)의 경우 \(\sim 1.7\times\)의 부선형으로 개선되었다.

비교를 위해 가장 큰 \(k\)-NN 그래프 구성은 NN-Descent [15]를 사용하여 108.7시간 동안 128개의 CPU 서버로 구성된 클러스터가 필요한 3650만 384-d 벡터로 구성된 데이터 세트를 사용했음을 알 수 있다. NN-Descent는 우리가 고려하는 데이터 세트에 대해 \(k\)-NN 그래프를 빌드하거나 정제할 수도 있지만, Deep1B의 경우 이미 80GB인 그래프 스토리지에 대한 메모리 오버헤드가 큽니다. 또한 모든 벡터(Deep1B의 경우 384GB)에 걸쳐 랜덤 액세스가 필요합니다.

가장 큰 GPU \(k\)-NN 그래프 구성은 10일 동안 32개의 테슬라 C2050 GPU 클러스터를 가진 2천만 개의 15,000-d 벡터 데이터 세트의 GEMM으로 정확한 검색을 사용하는 무차별 힘 구성이다[14]. 거리 행렬에 대한 GEMM 비용으로 계산 규모를 가정하면 Deep1B에 대한 이 접근법은 클러스터에서 200일의 계산 시간이 비실용적이다.

### k-NN 그래프 사용

이미지 데이터셋에 대해 \(k\)-NN 그래프가 구성되었을 때, 단일 연결 컴포넌트가 있는 경우 두 이미지 사이의 그래프에서 경로를 찾을 수 있다. 예를 들어, 출발 영상에서 목적지 영상으로 이웃을 전파하여 꽃의 두 영상 사이의 최단 경로를 탐색할 수 있다. 원본과 목적지의 영상을 \(S\)와 \(D\)로 표시하고, 노드간의 거리를 \(d_{ij}\)으로 하여 경로 \(P=\{p_{1},...,p_{n}\}\)을 \(p_{1}=S\)과 \(p_{n}=D\)으로 탐색하여 경로 \(P=\{p_{1},...,p_{n}\}\)을 \(p_{1}=S\)과 \(p_{n}=D\)으로 검색한다.

\[\min_{P}\,\max_{i=1..n}\,d_{p_{i}p_{i+1}}, \tag{12}\]

_i.e._, 우리는 원활한 전환을 선호합니다. 예시 결과는 Yfcc100M4에서 그림 6에 나와 있다. \(k\)-NN 그래프에서 \(k=15\) 이웃을 사용하여 20초 동안 전파한 후에 얻었다. 데이터셋에는 꽃 이미지가 많기 때문에 전환이 원활하다.

각주 4: 벡터로부터 이미지로의 매핑은 Deep1B에 대해 이용 가능하지 않음

## 7 Conclusion

GPU의 연산 처리량과 메모리 대역폭은 테라플롭과 초당 수백 기가바이트이다. 그러나 이러한 성능 수준에 접근하는 알고리즘을 구현하는 것은 복잡하고 직관적이지 않다. 본 논문에서는 GPU에서 거의 최적의 성능을 얻을 수 있는 유사도 검색 방법의 알고리즘 구조를 제시하였다.

이 작업은 이전에 복잡한 근사 알고리즘이 필요했던 응용 프로그램을 가능하게 한다. 예를 들어, 여기에 제시된 접근법은 정확한 \(k\)-평균 클러스터링을 수행하거나 CPU(또는 이들의 클러스터)보다 짧은 시간에 간단한 brute-force 접근법으로 \(k\)-NN 그래프를 계산하는 것을 가능하게 한다.

GPU 하드웨어는 이제 기계 학습 알고리즘에 대한 인기 때문에 과학 워크스테이션에서 매우 일반적이다. 우리는 우리의 작업이 데이터베이스 응용 프로그램에 대한 그들의 관심을 더욱 입증한다고 믿는다. 이 작업과 함께, 우리는 이 GPU가 이제 효율적인 유사성 검색에도 사용될 수 있도록 본 논문의 알고리즘을 신중하게 엔지니어링한 구현을 출판하고 있다.

## References

* [1] T. Alabi, J. D. Blanchard, B. Gordon, and R. Steinbach. Fast k-selection algorithms for graphics processing units. _ACM Journal of Experimental Algorithmics_, 17:4.2:4.1-4.2:4.29, October 2012.
* [2] F. Andre, A.-M. Kermarrec, and N. L. Scouarnec. Cache locality is not enough: High-performance nearest neighbor search with product quantization fast scan. In _Proc. International Conference on Very Large DataBases_, pages 288-299, 2015.
* [3] Y. Avrithis, Y. Kalantidis, E. Anagnostopoulos, and I. Z. Emiris. Web-scale image clustering revisited. In _Proc. International Conference on Computer Vision_, pages 1502-1510, 2015.
* [4] A. Babenko and V. Lempitsky. The inverted multi-index. In _Proc. IEEE Conference on Computer Vision and Pattern Recognition_, pages 3069-3076, June 2012.
* [5] A. Babenko and V. Lempitsky. Improving bilayer product quantization for billion-scale approximate nearest neighbors in high dimensions. _arXiv preprint arXiv:1404.1831_, 2014.
* [6] A. Babenko and V. Lempitsky. Efficient indexing of billion-scale datasets of deep descriptors. In _Proc. IEEE Conference on Computer Vision and Pattern Recognition_, pages 2055-2063, June 2016.
* [7] R. Barrientos, J. Gomez, C. Tenllado, M. Prieto, and M. Marin. knn query processing in metric spaces using GPUs. In _International European Conference on Parallel and Distributed Computing_, volume 6852 of _Lecture Notes

그림 6: YFCC100M에서 9,500만 이미지의 \(k\)-NN 그래프의 경로. 첫 번째와 마지막 이미지가 주어지며, 알고리즘은 이들 사이의 가장 부드러운 경로를 계산한다.

in Computer Science_, pages 380-392, Bordeaux, France, September 2011. Springer.
* [18] K. E. Batcher. Sorting networks and their applications. In _Proc. Spring Joint Computer Conference_, AFIPS '68 (Spring), pages 307-314, New York, NY, USA, 1968. ACM.
* [19] P. Boncz, W. Lehner, and T. Neumann. Special issue: Modern hardware. _The VLDB Journal_, 25(5):623-624, 2016.
* [20] J. Canny, D. L. W. Hall, and D. Klein. A multi-teraflop constituency parser using GPUs. In _Proc. Empirical Methods on Natural Language Processing_, pages 1898-1907. ACL, 2013.
* [21] J. Canny and H. Zhao. Bidmach: Large-scale learning with zero memory allocation. In _BigLearn workshop, NIPS_, 2013.
* [22] B. Catanzaro, A. Keller, and M. Garland. A decomposition for in-place matrix transposition. In _Proc. ACM Symposium on Principles and Practice of Parallel Programming_, PpPP '14, pages 193-206, 2014.
* [23] J. Chhugani, A. D. Nguyen, V. W. Lee, W. Macy, M. Hagog, Y.-K. Chen, A. Baransi, S. Kumar, and P. Dubey. Efficient implementation of sorting on multi-core simd cpu architecture. _Proc. VLDB Endow._, 1(2):1313-1324, August 2008.
* [24] A. Dashti. Efficient computation of k-nearest neighbor graphs for large high-dimensional data sets on gpu clusters. Master's thesis, University of Wisconsin Milwaukee, August 2013.
* [25] W. Dong, M. Charikar, and K. Li. Efficient k-nearest neighbor graph construction for generic similarity measures. In _WWW: Proceeding of the International Conference on World Wide Web_, pages 577-586, March 2011.
* [26] M. Douze, H. Jegou, and F. Perronnin. Polysemous codes. In _Proc. European Conference on Computer Vision_, pages 785-801. Springer, October 2016.
* [27] T. Ge, K. He, Q. Ke, and J. Sun. Optimized product quantization. _IEEE Trans. PAMI_, 36(4):744-755, 2014.
* [28] Y. Gong and S. Lazebnik. Iterative quantization: A procrustean approach to learning binary codes. In _Proc. IEEE Conference on Computer Vision and Pattern Recognition_, pages 817-824, June 2011.
* [29] Y. Gong, L. Wang, R. Guo, and S. Lazebnik. Multi-scale orderless pooling of deep convolutional activation features. In _Proc. European Conference on Computer Vision_, pages 392-407, 2014.
* [30] A. Gordo, J. Almazan, J. Revaud, and D. Larlus. Deep image retrieval: Learning global representations for image search. In _Proc. European Conference on Computer Vision_, pages 241-257, 2016.
* [31] S. Han, H. Mao, and W. J. Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. _arXiv preprint arXiv:1510.00149_, 2015.
* [32] K. He, F. Wen, and J. Sun. K-means hashing: An affinity-preserving quantization method for learning binary compact codes. In _Proc. IEEE Conference on Computer Vision and Pattern Recognition_, pages 2938-2945, June 2013.
* [33] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In _Proc. IEEE Conference on Computer Vision and Pattern Recognition_, pages 770-778, June 2016.
* [34] X. He, D. Agarwal, and S. K. Prasad. Design and implementation of a parallel priority queue on many-core architectures. _IEEE International Conference on High Performance Computing_, pages 1-10, 2012.
* [35] H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. _IEEE Trans. PAMI_, 33(1):117-128, January 2011.
* [36] H. Jegou, R. Tavenard, M. Douze, and L. Amsaleg. Searching in one billion vectors: re-rank with source coding. In _International Conference on Acoustics, Speech, and Signal Processing_, pages 861-864, May 2011.
* [37] Y. Kalantidis and Y. Avrithis. Locally optimized product quantization for approximate nearest neighbor search. In _Proc. IEEE Conference on Computer Vision and Pattern Recognition_, pages 2329-2336, June 2014.
* [38] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In _Advances in Neural Information Processing Systems_, pages 1097-1105, 2012.
* [39] F. T. Leighton. _Introduction to Parallel Algorithms and Architectures: Array, Trees, Hypercubes_. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1992.
* [40] E. Lindholm, J. Nickolls, S. Oberman, and J. Montrym. NVIDIA Tesla: a unified graphics and computing architecture. _IEEE Micro_, 28(2):39-55, March 2008.
* [41] W. Liu and B. Vinter. Ad-heap: An efficient heap data structure for asymmetric multicore processors. In _Proc. of Workshop on General Purpose Processing Using GPUs_, pages 54:54-54:63. ACM, 2014.
* [42] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In _Advances in Neural Information Processing Systems_, pages 3111-3119, 2013.
* [43] L. Monroe, J. Wendelberger, and S. Michalak. Randomized selection on the GPU. In _Proc. ACM Symposium on High Performance Graphics_, pages 89-98, 2011.
* [44] M. Norouzi and D. Fleet. Cartesian k-means. In _Proc. IEEE Conference on Computer Vision and Pattern Recognition_, pages 3017-3024, June 2013.
* [45] M. Norouzi, A. Punjani, and D. J. Fleet. Fast search in Hamming space with multi-index hashing. In _Proc. IEEE Conference on Computer Vision and Pattern Recognition_, pages 3108-3115, 2012.
* [46] J. Pan and D. Manocha. Fast GPU-based locality sensitive hashing for k-nearest neighbor computation. In _Proc. ACM International Conference on Advances in Geographic Information Systems_, pages 211-220, 2011.
* [47] L. Pauleve, H. Jegou, and L. Amsaleg. Locality sensitive hashing: a comparison of hash function types and querying mechanisms. _Pattern recognition letters_, 31(11):1348-1358, August 2010.
* [48] O. Shamir. Fundamental limits of online and distributed algorithms for statistical learning and estimation. In _Advances in Neural Information Processing Systems_, pages 163-171, 2014.
* [49] A. Sharif Razavian, H. Azizpour, J. Sullivan, and S. Carlsson. CNN features off-the-shelf: an astounding baseline for recognition. In _CVPR workshops_, pages 512-519, 2014.
* [50] N. Sismanis, N. Pitsianis, and X. Sun. Parallel search of k-nearest neighbors with synchronous operations. In _IEEE High Performance Extreme Computing Conference_, pages 1-6, 2012.
* [51] X. Tang, Z. Huang, D. M. Evers, S. Mills, and M. Guo. Efficient selection algorithm for fast k-nn search on GPUs. In _IEEE International Parallel & Distributed Processing Symposium_, pages 397-406, 2015.
* [52] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li. YFCC100M: The new data in multimedia research. _Communications of the ACM_, 59(2):64-73, January 2016.
* [53] V. Volkov and J. W. Demmel. Benchmarking GPUs to tune dense linear algebra. In _Proc. ACM/IEEE Conference on Supercomputing_, pages 31:1-31:11, 2008.
* [54] A. Wakatani and A. Murakami. GPGPU implementation of nearest neighbor search with product quantization. In _IEEE International Symposium on Parallel and Distributed Processing with Applications_, pages 248-253, 2014.
* [55] T. Warashina, K. Aoyama, H. Sawada, and T. Hattori. Efficient k-nearest neighbor graph construction using mapreduce for large-scale data sets. _IEICE Transactions_,97-D(12):3142-3154, 2014.
* [46] R. Weber, H.-J. Schek, and S. Blott. A quantitative analysis and performance study for similarity-search methods in high-dimensional spaces. In _Proc. International Conference on Very Large DataBases_, pages 194-205, 1998.
* [47] P. Wieschollek, O. Wang, A. Sorkine-Horunung, and H. P. A. Lensch. Efficient large-scale approximate nearest neighbor search on the GPU. In _Proc. IEEE Conference on Computer Vision and Pattern Recognition_, pages 2027-2035, June 2016.
* [48] S. Williams, A. Waterman, and D. Patterson. Roofline: An insightful visual performance model for multicore architectures. _Communications of the ACM_, 52(4):65-76, April 2009.

## 부록: WarpSelect의 복잡도 분석

우리는 섹션 4.3에서 사용하기 위해 WarpSelect에서 업데이트가 트리거되는 평균 횟수를 도출한다.

\(k\)-선택에 대한 입력은 시퀀스 \(\{a_{1},a_{2},...,a_{\ell}\}\)(1-기반 인덱싱)이라고 하자. 요소들은 크기 \(w\)의 \(c\) 그룹들에서 순차적으로 읽혀진다 (wp; 이 경우, \(w=32\)). \(\ell\)은 \(w\)의 배수라고 가정하면 \(c=\ell/w\). \(t\)이 스레드 큐 길이임을 기억하십시오. 우리는 지금까지 본 min-\(k\)의 위치 \(n\) 이전 또는 위치에 있는 요소를 _연속 min-\(k\)(n\))_라고 부른다. \(a_{n}\)이 \(n\)에서 연속 min-\(k\)에 있을 가능성은:

\[\alpha(n,k):=\begin{cases}1&\text{if }n\leq k\\ k/n&\text{if }n>k\end{cases} \tag{13}\]

각 \(a_{n}\), \(n>k\)은 모든 순열이 동일하고 첫 번째 \(k\)의 모든 원소가 적합하기 때문에 \(k/n\)의 기회를 갖는다.

**삽입 정렬을 카운트합니다.* * 지정된 차선에서 들어오는 값이 연속하는 min-\(k+t\) 값인 경우 삽입 정렬이 트리거되지만 차선은 "보기" \(wc_{0}+(c-c_{0})\) 값만 있습니다. 여기서 \(c_{0}\)은 이전 원 워프 투표입니다. 이러한 현상이 발생할 확률은 다음과 같다:

\[\alpha(wc_{0}+(c-c_{0}),k+t)\approx\frac{k+t}{wc}\text{ for }c>k. \tag{14}\]

근사는 스레드 큐가 차선에 할당된 값뿐만 아니라 _모든_ \(wc\) 값을 봤다고 간주합니다. 그러면 _any_ 차선이 삽입 정렬을 트리거할 확률은 다음과 같습니다.

\[1-\left(1-\frac{k+t}{wc}\right)^{w}\approx\frac{k+t}{c}. \tag{15}\]

여기서 근사치는 1차 테일러 전개이다. \(c\)에 대한 확률을 합산하면 \(N_{2}\approx(k+t)\log(c)=\mathcal{O}(k\log(\ell/w))\의 예상 삽입 수를 얻을 수 있다.

**전체 정렬을 카운트합니다.* * WarpSelect에 필요한 예상 전체 정렬 수 \(N_{3}=\pi(\ell,k,t,w)\)를 찾습니다.

**단일 차선.** 현재로서는 \(w=1\)이므로 \(c=\ell\)을 가정합니다. \(\gamma(\ell,m,k)\)을 순차 스캐너가 접한 요소의 수열 \(\{a_{1},...,a_{\ell}\}\)에서 정확히 \(m\)이 연속적인 min-\(k\)에 있을 확률로 하자. \(m\)이 주어지면, 이러한 연속적인 min-\(k\) 원소가 발생할 수 있는 \(\binom{\ell}{m}\) 장소가 있다. 그것은 재발 관계로 주어진다:

\[\gamma(\ell,m,k):=\begin{cases}1&\ell=0\text{ and }m=0\\ 0&\ell=0\text{ and }m>0\\ 0&\ell>0\text{ and }m=0\\ (\gamma(\ell-1,m-1,k)\cdot\alpha(\ell,k)+\\ \gamma(\ell-1,m,k)\cdot(1-\alpha(\ell,k)))&\text{otherwise.}\end{cases} \tag{16}\]

마지막 경우는 다음과 같다. \(m-1\)개의 연속된 min-\(k\)개의 원소가 앞에 있는 \(\ell-1\)개의 수열이 있고, 현재 원소는 연속된 min-\(k\)에 있거나, 현재 원소는 연속된 min-\(k\)에 없거나, \(m\)개의 원소가 앞에 있다. 그런 다음 \(\pi(\ell,k,t,1)\)에 대한 반복 관계를 개발할 수 있다. 주목해

\[\delta(\ell,b,k,t):=\sum_{m=bt}^{\min((bt+\max(0,t-1)),\ell)}\gamma(\ell,m,k) \tag{17}\]

(b\)의 경우, \(0\leq bt\leq\ell\)은 스레드 큐 투표에서 승리하여 \(b\) 종류의 데이터를 강제할 수 있는 길이 \(\ell\)의 모든 시퀀스의 분수이며, 이러한 정렬이 일어나기 위해서는 연속적인 min-\(k\)에 \(bt\)에서 \((bt+\max(0,t-1))\) 요소가 있어야 하기 때문이다(min-\(k\) 요소는 스레드 큐를 넘치게 된다). 투표에서 승리하기 위해서는 \(t\)개의 순차적인 전류분-k\이 필요하므로 발생할 수 있는 대부분의 \(\lfloor\ell/t\rfloor\) 원투표가 있다. \ (\pi(\ell,k,t,1)\)는 따라서 가능한 모든 \(b\):

\[\pi(\ell,k,t,1)=\sum_{b=1}^{\lfloor\ell/t\rfloor}b\cdot\delta(\ell,b,k,t). \tag{18}\]

이는 동적 프로그래밍에 의해 계산될 수 있다. 해석적으로, \(t=1\), \(k=1\), \(\pi(\ell,1,1,1)\)의 경우 조화수 \(H_{\ell}=1+\frac{1}{2}+\frac{1}{3}+...+\ frac{1}{2}\)는 \(\ln(\ell)+\gamma\)(오일러-마스케로니 상수 \(\gamma\))으로 수렴한다 \(\ell\에서\infty\).

\(t=1,k>1,\ell>k\), \(\pi(\ell,k,1,1)=k+k(H_{\ell}-H_{k})\) 또는 \(\mathcal{O}(k\log(\ell))\)의 경우, 첫 번째 \(k\) 원소는 연속된 min-\(k\)에 있고, 나머지에 대한 기대치는 \(\frac{k}{k+1}+\frac{k}{k+2}+...+\frac{k}{\ell}\)이다.

\(t>1,k>1,\ell>k\)의 경우, 각 가능한 \(\{a_{1},...,a_{\ell}\}\)에 대해 몇 개의 수 \(D\), \(k\leq D\leq\ell\)의 연속적인 min-\(k\) 결정 \(D\)이 있음을 유의하라. 각 경우에 대한 원화 투표의 수는 정의상 \(\lfloor D/t\rfloor\)이며, 스레드 큐는 \(t\) 횟수를 채워야 하기 때문이다. 따라서, \(\pi(\ell,k,t,1)=\mathcal{O}(k\log(\ell)/t)\).

**여러 차선.** \(w>1\) 경우는 고려할 공동 확률이 있다는 사실로 인해 복잡합니다 ( \(w\) 작업자 중 하나 이상이 지정된 그룹에 대한 정렬을 트리거하는 경우 하나의 정렬만 발생합니다). 그러나, 가능성은 제한될 수 있다. (\pi^{\prime}(\ell,k,t,w)\)는 단일 단계에서 독립적으로 투표하는 \(b\leq w\) 근로자들이 존재하지만 공동 서열에서 각 정렬 후에 공유된 min-\(k\)을 설정하여 투표에 대한 \(w\) 근로자들 간의 상호 간섭이 없다고 가정하여 예상되는 원화 투표로 한다. \(k\geq w\)이라고 가정합니다. 그러면:

\[\pi^{\prime}(\ell,k,1,w) \leq w\Bigg{(}\left\lceil\frac{k}{w}\right\rceil+\sum_{i=1}^{\lceil \ell/w\rceil-\lceil k/w\rceil}\frac{k}{w(\lceil k/w\rceil+i)}\Bigg{)} \tag{19}\] \[\leq w\pi(\lceil\ell/w\rceil,k,1,1)=\mathcal{O}(wk\log(\ell/w))\]

여기서 \(w\) 작업자가 연속된 min-\(k\) 요소를 볼 가능성은 각 단계에서 첫 번째 작업자의 상한을 갖는다. 기존과 같이 원화투표건수는 \(t\)만큼 스케일링되므로 \(\pi^{\prime}(\ell,k,t,w)=\mathcal{O}(wk\log(\ell/w)/t)\이다. 상호 간섭은 투표의 수를 줄일 수 있기 때문에 우리는 \(\pi(\ell,k,t,w)\)에 대한 동일한 상한을 얻는다.
