<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models</title>
<!--Generated on Thu Feb 22 17:11:50 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/addons.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="https://arxiv.org/html/2402.14714v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2402.14714v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2402.14714v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2402.14714v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC mobile collapse" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S1" title="1 Introduction ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S2" title="2 Efficient and Effective Vocabulary Expansion ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Efficient and Effective Vocabulary Expansion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S2.SS1" title="2.1 Preliminary 1: Tokenizer Training ‣ 2 Efficient and Effective Vocabulary Expansion ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Preliminary 1: Tokenizer Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S2.SS2" title="2.2 Preliminary 2: Subword-based Embeddings Initialization ‣ 2 Efficient and Effective Vocabulary Expansion ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Preliminary 2: Subword-based Embeddings Initialization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S2.SS3" title="2.3 Multi-stage Training ‣ 2 Efficient and Effective Vocabulary Expansion ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Multi-stage Training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S3" title="3 Implementation Details ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S3.SS1" title="3.1 Datasets ‣ 3 Implementation Details ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S3.SS2" title="3.2 Training ‣ 3 Implementation Details ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S4" title="4 Evaluations ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S4.SS1" title="4.1 Benchmarks ‣ 4 Evaluations ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S4.SS2" title="4.2 Results ‣ 4 Evaluations ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S5" title="5 Conclusion &amp; Future Work ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion &amp; Future Work</span></a></li>
</ol></nav>

<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewBox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: inconsolata</li>
<li>failed: kotex</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2402.14714v1 [cs.CL] 22 Feb 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Efficient and Effective Vocabulary Expansion 
<br class="ltx_break">Towards Multilingual Large Language Models</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
 Seungduk Kim
 Seungtaek Choi<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
 <span class="ltx_text ltx_font_bold" id="id1.1.id1">Myeongho Jeong</span>
<br class="ltx_break">Yanolja, South Korea 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">{seungduk.kim, seungtaek.choi, myeongho.jeong}@yanolja.com</span>
<br class="ltx_break">
</span><span class="ltx_author_notes"> Equal Contribution.</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id3.id1">이 보고서는 영어와 한국어 텍스트 이해에 걸쳐 놀라운 능력을 나타내는 대형 언어 모델의 한국어 각색인 <span class="ltx_text ltx_font_typewriter" id="id3.id1.1">EEVE-Korean-v1.0</span>을 소개한다. SOLAR-10.7B, Phi-2와 같이 영어가 아닌 텍스트가 영어가 아닌 토큰사이저로 비효율적으로 처리되는 최근의 매우 유능하지만 영어가 중심이 되는 LLM을 기반으로 하여, 본 논문에서는 파라미터 동결 및 서브워드 초기화를 포함하는 효율적이고 효과적인 어휘 확장(EEVE) 방법을 제시한다. 새로운 임베딩이 수조 개의 트레이닝 토큰을 필요로 한다는 이전의 노력과 대조적으로, 우리는 우리의 방법이 단지 20억 토큰 내에서 비영어 능력을 크게 향상시킬 수 있다는 것을 보여준다. Open Ko-LLM 리더보드에서 대부분의 명령어 조정 LLM을 통과하면 2024년 1월 현재 모델 <span class="ltx_text ltx_font_typewriter" id="id3.id1.2">EEVE-Korean-10.8B-v1.0</span>은 오픈 소스 커뮤니티에서 한국 사전 훈련 모델 선두로 랭크된다. 우리는 다양한 언어로 열린 연구 커뮤니티에 힘을 실어주기 위해 Huggingface에 모델을 오픈 소스합니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p ltx_align_center ltx_align_bottom" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1">Efficient and Effective Vocabulary Expansion 
<br class="ltx_break">Towards Multilingual Large Language Models</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="p2">
<br class="ltx_break">
<p class="ltx_p" id="p2.1"><span class="ltx_text" id="p2.1.1" style="width:433.6pt;"><span class="ltx_text" id="p2.1.1.1.1.1.1.1.1"><span class="ltx_tabular ltx_align_top" id="p2.1.1.1.1"><span class="ltx_tr" id="p2.1.1.1.1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p2.1.1.1.1.1.1.1"><span class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks:</span> Equal Contribution. <span></span><span class="ltx_note_type">1</sup><span class="ltx_note_type">footnotemark:</sup><span class="ltx_note_outer"><span class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="p2.1.1.1.2.2"><span class="ltx_td ltx_align_center" id="p2.1.1.1.1.2.2">Yanolja, South Korea</span></span></span></span></span></span><span class="ltx_tr" id="p2.1.1.1.1.1.2.3.1"><span class="ltx_td ltx_align_center" id="p2.1.1.1.1.3.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">GPT-4<cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib21" title="">2023</a>)</cite>, Gemini<cite class="ltx_cite ltx_citemacro_cite">Team et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib27" title="">2023a</a>)</cite>, Claude<cite class="ltx_cite ltx_citemacro_cite">Anthropic (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib2" title="">2023</a>)</cite>와 같은 대형 언어 모델 분야의 최근 발전은 여러 언어를 처리하고 이해하는 데 놀라운 능력을 보여주었다. 반면에 오픈 소스 커뮤니티에서 주목할 만한 모델인 LLaMA <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib29" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib30" title="">b</a>)</cite>, MPT <cite class="ltx_cite ltx_citemacro_cite">Team et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib28" title="">2023b</a>)</cite>, Falcon <cite class="ltx_cite ltx_citemacro_cite">Almazrouei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib1" title="">2023</a>)</cite>, Mistral <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib10" title="">2023</a>)</cite>, Mixtral <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib11" title="">2024</a>)</cite>, SOLAR <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib12" title="">2023</a>)</cite>, Phi-1.5 <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib17" title="">2023b</a>)</cite>는 영어 태스크에서 벤치마크를 설정했지만, 이러한 개발은 주로 영어를 선호하여 비영어 언어의 성능 격차를 초래했다.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">이러한 디스패리티는 그들의 언어 능력뿐만 아니라 계산 효율에서도 발견될 수 있는데, 여기서 한국어 같은 비영어 언어는 동등한 의미 콘텐츠에 대해서도 영어보다 훨씬 더 많은 토큰을 필요로 한다(그림<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S2.T1" title="Table 1 ‣ 2.1 Preliminary 1: Tokenizer Training ‣ 2 Efficient and Effective Vocabulary Expansion ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>). 그리고 물론 이것은 더 긴 응답 시간, 더 짧은 컨텍스트 길이 및 더 높은 API 비용 <cite class="ltx_cite ltx_citemacro_cite">Petrov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib23" title="">2023</a>)</cite>와 같은 사용자 경험에 부정적인 영향을 미친다. 빈번히 사용되지만 긴 단어를 추가 토큰으로 소개하는 토큰나이저 어휘를 확장하는 것은 비영어권 사용자에게 필수적이지만, 새로운 임베딩에는 수조 개의 훈련 토큰 <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib34" title="">2024</a>)</cite>가 필요하기 때문에 어휘 확장은 매우 어려운 작업이다.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">이를 위해 이 기술 보고서는 새로 추가된 토큰의 임베딩을 더 잘 훈련할 수 있는 <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">e</span>fficient and <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">e</span>ffective <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">v</span>ocabulary <span class="ltx_text ltx_font_bold" id="S1.p3.1.4">e</span>expansion, 즉 EEVE에 대한 새로운 접근 방식을 제시한다. 적응의 용이성을 위해 서브워드 기반 임베딩 초기화를 활용하고, 훈련될 파라미터들의 순서와 양을 정교하게 조정하는 파라미터 동결을 갖는 7개의 훈련 단계를 설계한다. 우리는 처음에 입력 임베딩만 훈련하는 데 집중하고 최종 단계에서 전체 매개변수를 포함하도록 점진적으로 확장함으로써 기초 모델의 고급 기능을 영어에서 한국어로 꼼꼼하게 전달한다.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text ltx_font_typewriter" id="S1.p4.1.1">EEVE</span>을 사용하여 한국어 LLMs의 패밀리를 공식적으로 릴리스합니다. <span class="ltx_text ltx_font_typewriter" id="S1.p4.1.2">EEVE-Korean-10.8B-v1.0<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote1.1.1.1">1</span></span><a class="ltx_ref ltx_url" href="https://huggingface.co/yanolja/EEVE-Korean-10.8B-v1.0" title="">https://huggingface.co/yanolja/EEVE-Korean-10.8B-v1.0</a></span></span></span></span> 및 <span class="ltx_text ltx_font_typewriter" id="S1.p4.1.3">EEVE-Korean-2.8B-v1.0<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote2.1.1.1">2</span></span><a class="ltx_ref ltx_url" href="https://huggingface.co/yanolja/EEVE-Korean-2.8B-v1.0" title="">https://huggingface.co/yanolja/EEVE-Korean-2.8B-v1.0</a></span></span></span></span>은 최근 영어 중심 LLMs, 구체적으로 SOLAR-10.7B <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib12" title="">2023</a>)</cite> 및 Phi-2 <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib17" title="">2023b</a>)</cite>와 함께 한국어 중심 사전 학습입니다. 우리는 부울 질문 응답(BoolQ; <cite class="ltx_cite ltx_citemacro_citet">Clark et al. <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib3" title="">2019</a></cite>), 커먼센스 인과 추론(COPA; <cite class="ltx_cite ltx_citemacro_citet">Roemmele et al. <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib26" title="">2011</a></cite>, 문맥 민감 단어 이해(WiC; <cite class="ltx_cite ltx_citemacro_citet">Pilehvar and Camacho-Collados <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib24" title="">2019</a></cite>), 커먼센스 추론(HellaSwag; <cite class="ltx_cite ltx_citemacro_citet">Zellers et al. <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib32" title="">2019</a></cite>), 감정 부정 인식(SentiNeg)과 같은 영어 및 한국어 태스크 모두에 대해 <span class="ltx_text ltx_font_typewriter" id="S1.p4.1.4">lm-evaluation-harness<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote3.1.1.1">3</span></span><a class="ltx_ref ltx_url" href="https://github.com/EleutherAI/lm-evaluation-harness" title="">https://github.com/EleutherAI/lm-evaluation-harness</a></span></span></span></span><cite class="ltx_cite ltx_citemacro_cite">Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib6" title="">2023</a>)</cite> 모델을 평가한다. 평가 결과, Open Ko-LLM 리더보드 <cite class="ltx_cite ltx_citemacro_cite">Park et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib22" title="">2023</a>)</cite>에서 기본 영어 중심 LLM의 강력한 영어 능력을 유지하면서, OPEN-SOLAR-KO-10.7B<cite class="ltx_cite ltx_citemacro_cite">L. Junbum (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib15" title="">2024</a>)</cite>, Polyglot-Ko<cite class="ltx_cite ltx_citemacro_cite">Ko et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib14" title="">2023</a>)</cite>, KoGPT<cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib13" title="">2021</a>)</cite>와 같은 최근 오픈 한국어 사전 학습 LLM보다 우수한 성능을 보였다.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Efficient and Effective Vocabulary Expansion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">영어 중심 언어 모델(LLM)을 비영어 언어를 포함하도록 효율적으로 확장하는 문제를 해결하기 위해 어휘 확장을 위한 새로운 방법론을 소개한다. 이 방법은 매개변수 동결과 서브워드 기반 임베딩 초기화를 결합하여 초기 학습 범위를 넘어 언어로부터의 새로운 언어 토큰을 효과적으로 통합하고 적응함으로써 다양한 언어 컨텍스트에 걸쳐 적용 가능성을 향상시킨다. 우리의 접근법은 그림 <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S2.F1" title="Figure 1 ‣ 2.1 Preliminary 1: Tokenizer Training ‣ 2 Efficient and Effective Vocabulary Expansion ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>와 같이 새로운 토큰을 모델의 어휘에 효과적으로 통합하도록 세심하게 설계된 구조화된 7단계 훈련 프로세스를 설명한다. 사전 훈련 동안 우리의 목표는 인과적 언어 모델링이다.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">우리의 핵심 가정은 영어 텍스트에서 광범위하게 훈련된 기초 모델이 상당한 수준의 이해 및 추론 능력을 가지고 있다는 것이다. 이러한 능력을 영어에서 한국어와 같은 다른 언어로 옮기는 것은 독립형 한국어 사전 훈련에서 성능을 개발하는 것보다 더 효율적일 수 있다.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Preliminary 1: Tokenizer Training</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S2.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T1.18" style="width:398.9pt;height:142.3pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-21.1pt,7.5pt) scale(0.90437232719092,0.90437232719092) ;">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.18.18">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.18.18.19.1">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.18.18.19.1.1" style="width:411.9pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S2.T1.18.18.19.1.1.1">English (<span class="ltx_text ltx_font_italic" id="S2.T1.18.18.19.1.1.1.1">8 tokens</span>)</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.18.18.20.2">
<td class="ltx_td ltx_align_justify" id="S2.T1.18.18.20.2.1" style="width:411.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.18.18.20.2.1.1">“<span class="ltx_text ltx_font_italic" id="S2.T1.18.18.20.2.1.1.1">Hello, the weather is nice today.</span>”</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.18.18.21.3">
<td class="ltx_td ltx_align_justify" id="S2.T1.18.18.21.3.1" style="width:411.9pt;"><span class="ltx_text ltx_font_typewriter ltx_align_top" id="S2.T1.18.18.21.3.1.1">[‘_Hello’, ‘,’, ‘_the’, ‘_weather’, ‘_is’, ‘_nice’, ‘_today’, ‘.’]</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.18.18.22.4">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.18.18.22.4.1" style="width:411.9pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S2.T1.18.18.22.4.1.1">Korean (<span class="ltx_text ltx_font_italic" id="S2.T1.18.18.22.4.1.1.1">26 tokens</span>)</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.18.18.23.5">
<td class="ltx_td ltx_align_justify" id="S2.T1.18.18.23.5.1" style="width:411.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.18.18.23.5.1.1">“<span class="ltx_text ltx_font_italic" id="S2.T1.18.18.23.5.1.1.1">안녕하세요, 오늘은 날씨가 좋네요.</span>”</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.18.18.18">
<td class="ltx_td ltx_align_justify" id="S2.T1.18.18.18.18" style="width:411.9pt;"><span class="ltx_text ltx_font_typewriter ltx_align_top" id="S2.T1.18.18.18.18.18.18.18">[‘_’, ‘안’, ‘<math alttext="<" class="ltx_Math" display="inline" id="S2.T1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.T1.1.1.1.1.1.1.1.m1.1a"><mo id="S2.T1.1.1.1.1.1.1.1.m1.1.1" mathvariant="normal" xref="S2.T1.1.1.1.1.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.1.1.1.1.m1.1b"><lt id="S2.T1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.1.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.1.1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.1.1.1.1.1.1.1.m1.1d">&lt;</annotation></semantics></math>0xEB<math alttext=">" class="ltx_Math" display="inline" id="S2.T1.2.2.2.2.2.2.2.m2.1"><semantics id="S2.T1.2.2.2.2.2.2.2.m2.1a"><mo id="S2.T1.2.2.2.2.2.2.2.m2.1.1" mathvariant="normal" xref="S2.T1.2.2.2.2.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.2.2.2.2.m2.1b"><gt id="S2.T1.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S2.T1.2.2.2.2.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.2.2.2.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.2.2.2.2.2.2.2.m2.1d">&gt;</annotation></semantics></math>’, ‘<math alttext="<" class="ltx_Math" display="inline" id="S2.T1.3.3.3.3.3.3.3.m3.1"><semantics id="S2.T1.3.3.3.3.3.3.3.m3.1a"><mo id="S2.T1.3.3.3.3.3.3.3.m3.1.1" mathvariant="normal" xref="S2.T1.3.3.3.3.3.3.3.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.3.3.3.3.3.m3.1b"><lt id="S2.T1.3.3.3.3.3.3.3.m3.1.1.cmml" xref="S2.T1.3.3.3.3.3.3.3.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.3.3.3.3.3.m3.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.3.3.3.3.3.3.3.m3.1d">&lt;</annotation></semantics></math>0x85<math alttext=">" class="ltx_Math" display="inline" id="S2.T1.4.4.4.4.4.4.4.m4.1"><semantics id="S2.T1.4.4.4.4.4.4.4.m4.1a"><mo id="S2.T1.4.4.4.4.4.4.4.m4.1.1" mathvariant="normal" xref="S2.T1.4.4.4.4.4.4.4.m4.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.4.4.4.4.4.m4.1b"><gt id="S2.T1.4.4.4.4.4.4.4.m4.1.1.cmml" xref="S2.T1.4.4.4.4.4.4.4.m4.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.4.4.4.4.4.m4.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.4.4.4.4.4.4.4.m4.1d">&gt;</annotation></semantics></math>’, ‘<math alttext="<" class="ltx_Math" display="inline" id="S2.T1.5.5.5.5.5.5.5.m5.1"><semantics id="S2.T1.5.5.5.5.5.5.5.m5.1a"><mo id="S2.T1.5.5.5.5.5.5.5.m5.1.1" mathvariant="normal" xref="S2.T1.5.5.5.5.5.5.5.m5.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.5.5.5.5.5.m5.1b"><lt id="S2.T1.5.5.5.5.5.5.5.m5.1.1.cmml" xref="S2.T1.5.5.5.5.5.5.5.m5.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.5.5.5.5.5.m5.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.5.5.5.5.5.5.5.m5.1d">&lt;</annotation></semantics></math>0x95<math alttext=">" class="ltx_Math" display="inline" id="S2.T1.6.6.6.6.6.6.6.m6.1"><semantics id="S2.T1.6.6.6.6.6.6.6.m6.1a"><mo id="S2.T1.6.6.6.6.6.6.6.m6.1.1" mathvariant="normal" xref="S2.T1.6.6.6.6.6.6.6.m6.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.6.6.6.6.6.m6.1b"><gt id="S2.T1.6.6.6.6.6.6.6.m6.1.1.cmml" xref="S2.T1.6.6.6.6.6.6.6.m6.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.6.6.6.6.6.m6.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.6.6.6.6.6.6.6.m6.1d">&gt;</annotation></semantics></math>’, ‘하’, ‘세’, ‘요’, ‘,’, ‘_’, ‘오’, ‘<math alttext="<" class="ltx_Math" display="inline" id="S2.T1.7.7.7.7.7.7.7.m7.1"><semantics id="S2.T1.7.7.7.7.7.7.7.m7.1a"><mo id="S2.T1.7.7.7.7.7.7.7.m7.1.1" mathvariant="normal" xref="S2.T1.7.7.7.7.7.7.7.m7.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.7.7.7.7.7.m7.1b"><lt id="S2.T1.7.7.7.7.7.7.7.m7.1.1.cmml" xref="S2.T1.7.7.7.7.7.7.7.m7.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.7.7.7.7.7.m7.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.7.7.7.7.7.7.7.m7.1d">&lt;</annotation></semantics></math>0xEB<math alttext=">" class="ltx_Math" display="inline" id="S2.T1.8.8.8.8.8.8.8.m8.1"><semantics id="S2.T1.8.8.8.8.8.8.8.m8.1a"><mo id="S2.T1.8.8.8.8.8.8.8.m8.1.1" mathvariant="normal" xref="S2.T1.8.8.8.8.8.8.8.m8.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.8.8.8.8.8.8.8.m8.1b"><gt id="S2.T1.8.8.8.8.8.8.8.m8.1.1.cmml" xref="S2.T1.8.8.8.8.8.8.8.m8.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.8.8.8.8.8.8.m8.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.8.8.8.8.8.8.8.m8.1d">&gt;</annotation></semantics></math>’, ‘<math alttext="<" class="ltx_Math" display="inline" id="S2.T1.9.9.9.9.9.9.9.m9.1"><semantics id="S2.T1.9.9.9.9.9.9.9.m9.1a"><mo id="S2.T1.9.9.9.9.9.9.9.m9.1.1" mathvariant="normal" xref="S2.T1.9.9.9.9.9.9.9.m9.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.9.9.9.9.9.9.9.m9.1b"><lt id="S2.T1.9.9.9.9.9.9.9.m9.1.1.cmml" xref="S2.T1.9.9.9.9.9.9.9.m9.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.9.9.9.9.9.9.m9.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.9.9.9.9.9.9.9.m9.1d">&lt;</annotation></semantics></math>0x8A<math alttext=">" class="ltx_Math" display="inline" id="S2.T1.10.10.10.10.10.10.10.m10.1"><semantics id="S2.T1.10.10.10.10.10.10.10.m10.1a"><mo id="S2.T1.10.10.10.10.10.10.10.m10.1.1" mathvariant="normal" xref="S2.T1.10.10.10.10.10.10.10.m10.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.10.10.10.10.10.10.10.m10.1b"><gt id="S2.T1.10.10.10.10.10.10.10.m10.1.1.cmml" xref="S2.T1.10.10.10.10.10.10.10.m10.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.10.10.10.10.10.10.m10.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.10.10.10.10.10.10.10.m10.1d">&gt;</annotation></semantics></math>’, ‘<math alttext="<" class="ltx_Math" display="inline" id="S2.T1.11.11.11.11.11.11.11.m11.1"><semantics id="S2.T1.11.11.11.11.11.11.11.m11.1a"><mo id="S2.T1.11.11.11.11.11.11.11.m11.1.1" mathvariant="normal" xref="S2.T1.11.11.11.11.11.11.11.m11.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.11.11.11.11.11.11.11.m11.1b"><lt id="S2.T1.11.11.11.11.11.11.11.m11.1.1.cmml" xref="S2.T1.11.11.11.11.11.11.11.m11.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.11.11.11.11.11.11.m11.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.11.11.11.11.11.11.11.m11.1d">&lt;</annotation></semantics></math>0x98<math alttext=">" class="ltx_Math" display="inline" id="S2.T1.12.12.12.12.12.12.12.m12.1"><semantics id="S2.T1.12.12.12.12.12.12.12.m12.1a"><mo id="S2.T1.12.12.12.12.12.12.12.m12.1.1" mathvariant="normal" xref="S2.T1.12.12.12.12.12.12.12.m12.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.12.12.12.12.12.12.12.m12.1b"><gt id="S2.T1.12.12.12.12.12.12.12.m12.1.1.cmml" xref="S2.T1.12.12.12.12.12.12.12.m12.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.12.12.12.12.12.12.m12.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.12.12.12.12.12.12.12.m12.1d">&gt;</annotation></semantics></math>’, ‘은’, ‘_’, ‘날’, ‘<math alttext="<" class="ltx_Math" display="inline" id="S2.T1.13.13.13.13.13.13.13.m13.1"><semantics id="S2.T1.13.13.13.13.13.13.13.m13.1a"><mo id="S2.T1.13.13.13.13.13.13.13.m13.1.1" mathvariant="normal" xref="S2.T1.13.13.13.13.13.13.13.m13.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.13.13.13.13.13.13.13.m13.1b"><lt id="S2.T1.13.13.13.13.13.13.13.m13.1.1.cmml" xref="S2.T1.13.13.13.13.13.13.13.m13.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.13.13.13.13.13.13.m13.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.13.13.13.13.13.13.13.m13.1d">&lt;</annotation></semantics></math>0xEC<math alttext=">" class="ltx_Math" display="inline" id="S2.T1.14.14.14.14.14.14.14.m14.1"><semantics id="S2.T1.14.14.14.14.14.14.14.m14.1a"><mo id="S2.T1.14.14.14.14.14.14.14.m14.1.1" mathvariant="normal" xref="S2.T1.14.14.14.14.14.14.14.m14.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.14.14.14.14.14.14.14.m14.1b"><gt id="S2.T1.14.14.14.14.14.14.14.m14.1.1.cmml" xref="S2.T1.14.14.14.14.14.14.14.m14.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.14.14.14.14.14.14.m14.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.14.14.14.14.14.14.14.m14.1d">&gt;</annotation></semantics></math>’, ‘<math alttext="<" class="ltx_Math" display="inline" id="S2.T1.15.15.15.15.15.15.15.m15.1"><semantics id="S2.T1.15.15.15.15.15.15.15.m15.1a"><mo id="S2.T1.15.15.15.15.15.15.15.m15.1.1" mathvariant="normal" xref="S2.T1.15.15.15.15.15.15.15.m15.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.15.15.15.15.15.15.15.m15.1b"><lt id="S2.T1.15.15.15.15.15.15.15.m15.1.1.cmml" xref="S2.T1.15.15.15.15.15.15.15.m15.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.15.15.15.15.15.15.m15.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.15.15.15.15.15.15.15.m15.1d">&lt;</annotation></semantics></math>0x94<math alttext=">" class="ltx_Math" display="inline" id="S2.T1.16.16.16.16.16.16.16.m16.1"><semantics id="S2.T1.16.16.16.16.16.16.16.m16.1a"><mo id="S2.T1.16.16.16.16.16.16.16.m16.1.1" mathvariant="normal" xref="S2.T1.16.16.16.16.16.16.16.m16.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.16.16.16.16.16.16.16.m16.1b"><gt id="S2.T1.16.16.16.16.16.16.16.m16.1.1.cmml" xref="S2.T1.16.16.16.16.16.16.16.m16.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.16.16.16.16.16.16.16.m16.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.16.16.16.16.16.16.16.m16.1d">&gt;</annotation></semantics></math>’, ‘<math alttext="<" class="ltx_Math" display="inline" id="S2.T1.17.17.17.17.17.17.17.m17.1"><semantics id="S2.T1.17.17.17.17.17.17.17.m17.1a"><mo id="S2.T1.17.17.17.17.17.17.17.m17.1.1" mathvariant="normal" xref="S2.T1.17.17.17.17.17.17.17.m17.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.17.17.17.17.17.17.17.m17.1b"><lt id="S2.T1.17.17.17.17.17.17.17.m17.1.1.cmml" xref="S2.T1.17.17.17.17.17.17.17.m17.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.17.17.17.17.17.17.17.m17.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.17.17.17.17.17.17.17.m17.1d">&lt;</annotation></semantics></math>0xA8<math alttext=">" class="ltx_Math" display="inline" id="S2.T1.18.18.18.18.18.18.18.m18.1"><semantics id="S2.T1.18.18.18.18.18.18.18.m18.1a"><mo id="S2.T1.18.18.18.18.18.18.18.m18.1.1" mathvariant="normal" xref="S2.T1.18.18.18.18.18.18.18.m18.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.T1.18.18.18.18.18.18.18.m18.1b"><gt id="S2.T1.18.18.18.18.18.18.18.m18.1.1.cmml" xref="S2.T1.18.18.18.18.18.18.18.m18.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.18.18.18.18.18.18.18.m18.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.T1.18.18.18.18.18.18.18.m18.1d">&gt;</annotation></semantics></math>’, ‘가’, ‘_’, ‘좋’, ‘네’, ‘요’, ‘.’]</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.18.18.24.6">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.18.18.24.6.1" style="width:411.9pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S2.T1.18.18.24.6.1.1">Expanded Tokenizer (<span class="ltx_text ltx_font_italic" id="S2.T1.18.18.24.6.1.1.1">9 tokens</span>)</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.18.18.25.7">
<td class="ltx_td ltx_align_justify ltx_border_b" id="S2.T1.18.18.25.7.1" style="width:411.9pt;"><span class="ltx_text ltx_font_typewriter ltx_align_top" id="S2.T1.18.18.25.7.1.1">[‘_안’, ‘녕’, ‘하세요’, ‘,’, ‘_오늘은’, ‘_날씨가’, ‘_좋’, ‘네요’, ‘.’]</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 1:</span>영어와 한국어의 토큰 소비 비교. SOLAR <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib12" title="">2023</a>)</cite>의 tokenizers와 <span class="ltx_text ltx_font_typewriter" id="S2.T1.20.1">EEVE-Korean-10.8B-v1.0</span>을 사용하였다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">한국어 코퍼스에서 새로운 토크나이저를 훈련했습니다. 우리의 목표는 기본 모델의 성능의 레버리지를 최대화하는 것이기 때문에 기본 모델의 어휘를 유지하고 최소 6,000번 출현한 말뭉치에서 8,960개의 토큰을 추가하여 빈도가 가장 높은 것을 우선시했다. 궁극적으로, 토큰나이저의 어휘는 <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p1.1.1">EEVE-Korean-10.8B-v1.0</span>에 대해 40,960개의 토큰으로 확장되었다. 이 프로세스에는 토큰 빈도 분석을 기반으로 여러 라운드의 토큰화기 훈련과 토큰의 수동 큐레이션이 수반되어 모델에 대한 포괄적이고 관련된 어휘를 보장한다. <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S2.T1" title="Table 1 ‣ 2.1 Preliminary 1: Tokenizer Training ‣ 2 Efficient and Effective Vocabulary Expansion ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>와 같이 한국어 텍스트에 대한 전체 토큰 소비는 거의 3배 정도로 크게 향상되어 전체 교육 과정에서의 계산 비용 절감에 기여한다.</p>
</div>
<figure class="ltx_figure" id="S2.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_flex_size_4" id="S2.F0.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="142" id="S2.F0.sf1.g1" src="https://arxiv.org/html/2402.14714v1/extracted/5424172/figure_latex/figures/figure-stages-0.png" width="117">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a)</span>Stage 0</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_flex_size_4" id="S2.F0.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="142" id="S2.F0.sf2.g1" src="https://arxiv.org/html/2402.14714v1/extracted/5424172/figure_latex/figures/figure-stages-1.png" width="134">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b)</span>Stage 1</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_flex_size_4" id="S2.F0.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="142" id="S2.F0.sf3.g1" src="https://arxiv.org/html/2402.14714v1/extracted/5424172/figure_latex/figures/figure-stages-2.png" width="134">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c)</span>Stage 2</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_flex_size_4" id="S2.F0.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="142" id="S2.F0.sf4.g1" src="https://arxiv.org/html/2402.14714v1/extracted/5424172/figure_latex/figures/figure-stages-3.png" width="134">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d)</span>Stage 3</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_flex_size_4" id="S2.F0.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="142" id="S2.F0.sf5.g1" src="https://arxiv.org/html/2402.14714v1/extracted/5424172/figure_latex/figures/figure-stages-4.png" width="134">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e)</span>Stage 4</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_flex_size_4" id="S2.F0.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="142" id="S2.F0.sf6.g1" src="https://arxiv.org/html/2402.14714v1/extracted/5424172/figure_latex/figures/figure-stages-5.png" width="134">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f)</span>Stage 5</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_flex_size_4" id="S2.F0.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="142" id="S2.F0.sf7.g1" src="https://arxiv.org/html/2402.14714v1/extracted/5424172/figure_latex/figures/figure-stages-6.png" width="134">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(g)</span>Stage 6</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_flex_size_4" id="S2.F0.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="142" id="S2.F0.sf8.g1" src="https://arxiv.org/html/2402.14714v1/extracted/5424172/figure_latex/figures/figure-stages-7.png" width="134">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(h)</span>Stage 7</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1:</span>Training stages with parameter freezing. 화재 및 눈송이 이모지는 각각 훈련 가능한 매개변수와 동결 매개변수를 나타낸다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Preliminary 2: Subword-based Embeddings Initialization</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">통합 프로세스는 실제 훈련 전에 시작되어 모델의 매개 변수에 <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p1.1.1">embed_tokens</span> 및 <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p1.1.2">lm_head</span>이라고 하는 새로운 입력 및 출력 임베딩을 도입합니다. 이 사전 단계는 뒤따르는 정교한 학습 과정을 준비하는 데 중요하다.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">새로 추가된 토큰의 입력 임베딩을 위해 <cite class="ltx_cite ltx_citemacro_cite">Hewitt (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib7" title="">2021</a>); Welch et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib31" title="">2020</a>)</cite>와 같이 이러한 새로운 토큰을 구성하는 서브워드 토큰의 평균 임베딩을 사용하는 방식을 채택한다. 이 방법은 모델의 기존 서브워드 임베딩의 의미적 풍부함을 활용하여 새로운 토큰 표현의 의미 있는 출발점을 제공한다.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">반대로, 새로 추가된 토큰들에 대한 출력 임베딩들은 새로운 토큰을 구성하는 제1 서브워드 토큰의 임베딩들로 초기화된다. 이 전략은 새로운 토큰의 출력 표현을 구성 하위 단어의 의미적 특성과 밀접하게 정렬하여 모델의 예측 프레임워크에 더 부드럽게 통합할 수 있도록 하는 것을 목표로 한다. 이러한 초기화의 의의는 더 논의될 것이다.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Multi-stage Training</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">여기서는 효율적인 어휘 확장을 위한 7단계 훈련 방법론의 미묘한 접근법을 설명하며, 초기 영어 중심 훈련 범위를 넘어 언어에서 파생된 새로운 토큰을 통합하는 세심한 과정을 강조한다.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="498" id="S2.F2.g1" src="https://arxiv.org/html/2402.14714v1/extracted/5424172/figure_latex/figures/figure-subword.png" width="449">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 2:</span>우리의 서브워드 기반 임베딩 초기화가 스테이지 1에서 오래된 토큰과 새로운 토큰을 조화시키는 것을 가능하게 하는 방법을 보여주는 예시적인 예시이다. 스테이지 1에서, 새롭게 추가된 토큰의 출력 임베딩은 이러한 새로운 토큰을 구성하는 그들의 첫 번째 서브워드 토큰의 출력 임베딩으로 초기화되며, 따라서 "하세요"를 예측하기 위한 마지막 숨겨진 표현은 다음과 같다. 새로 추가된 토큰 "하세요"에 대해 동일한 로짓값을 산출합니다. 첫 번째 하위 단어 토큰 "하"와 함께. 우리가 새로운 토큰 "하세요"를 준다고 해도. 금 토큰으로서, 구배들은 결국 그것의 서브워드 토큰 "하"에 기초하여 계산되고, 따라서 모델은 "하세요"의 입력 임베딩들을 취한다. 하위 단어 "하"를 예측하다</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p2.1.1">Stage 1 (new input embeddings):</span> Initially, our focus is narrow yet critical: to learn the input embeddings of the newly added tokens while freezing all other model parameters. 이 단계는 기반이 되어 모델이 처음부터 이러한 토큰에 대한 인식과 처리를 조정할 수 있다. 사전 초기화된 임베딩은 모델이 기존 프레임워크에서 이러한 새로운 토큰을 더 잘 활용하도록 안내하는 출발점 역할을 한다. 우리의 주요 가설은 인과적 언어 모델링에서 입력 및 출력 토큰 시퀀스를 구별할 수 있다면 구형 토큰과 새로운 토큰화기를 동시에 활용함으로써 모델이 구형 토큰의 임베딩 공간에서 확립된 지식을 활용할 수 있기 때문에 새로운 어휘 임베딩을 보다 효율적이고 효과적으로 학습할 수 있다는 것이다. 그러나 입력 및 출력 시퀀스에 고유한 토큰라이저를 한 번에 사용하는 것은 일치하지 않는 입력/출력 시퀀스로 인한 교사 강제 적용의 어려움과 같은 구현 문제를 제기한다. 여기서, 서브워드 기반 임베딩 초기화(Sec<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S2.SS2" title="2.2 Preliminary 2: Subword-based Embeddings Initialization ‣ 2 Efficient and Effective Vocabulary Expansion ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_tag">2.2</span></a>)는 출력 시퀀스들에 대해 구 토큰화기를 사용하기 위한 프록시를 제공하여, 모델이 전체 워드 토큰(new)이 주어진 서브워드 토큰(old)을 생성하도록 태스크된다. 즉, 모델은 그림 <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S2.F2" title="Figure 2 ‣ 2.3 Multi-stage Training ‣ 2 Efficient and Effective Vocabulary Expansion ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에 설명된 바와 같이 입력/출력 토큰 시퀀스의 수정 없이 입력 임베딩만을 최적화함으로써 새로운 토큰을 생성하기 위한 표현과 첫 번째 서브워드 토큰을 생성하기 위한 표현을 정렬하는 것을 학습할 수 있다. 그러나 이 단계에서 모델은 아직 동일한 은닉 상태를 공유하는 토큰을 구분할 수 없다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p3.1.1">Stage 2 (new output embeddings):</span> 우리의 목표는 출력 embeddings만을 조정함으로써 다양한 컨텍스트에 걸쳐 새로운 토큰을 정확하게 생성하는 모델의 숙련도를 향상시키는 것이다(<span class="ltx_text ltx_font_typewriter" id="S2.SS3.p3.1.2">lm_head</span>). 다른 모든 매개변수를 동결하기로 한 결정은 모델의 현재 불안정한 상태에서 비롯된다. 입력 임베딩과 출력 임베딩을 동시에 학습하도록 하는 것은 수렴을 달성하는 것을 복잡하게 하여 최적의 성능을 향한 모델의 진행을 방해할 수 있다. 대부분의 매개변수를 동결함으로써 보다 안정적인 수렴을 달성한다. 더욱이, 이 접근법은 다른 층들을 통한 역전파의 필요성을 제거하기 때문에 트레이닝 시간을 상당히 감소시킨다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p4.1.1">Stage 3 (새로운 입력 및 출력 임베딩):</span> 이 단계에서 입력 임베딩(<span class="ltx_text ltx_font_typewriter" id="S2.SS3.p4.1.2">embed_tokens</span>)은 여전히 출력 임베딩의 초기 임베딩에 기초하여 최적화 상태를 유지한다. 이 스테이지는 새로 추가된 토큰의 입력 및 출력 임베딩 모두의 업데이트를 동시에 허용한다. 입력 임베딩과 출력 임베딩 사이의 정렬을 통해, 모델은 이해와 예측 모두에서 새로운 토큰을 사용하도록 학습한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p5">
<p class="ltx_p" id="S2.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p5.1.1">Stage 4 (모든 출력 임베딩):</span> 기본 모델의 모든 원래 매개 변수가 이 단계까지 동결되었기 때문에 이전 토큰과 새 토큰izer 간의 로짓이 다르게 스케일링되거나 전체 어휘로 사용되도록 덜 최적화되었다고 가정했다. 이를 위해 이전 매개 변수, 특히 여기에서 이전 토큰의 출력 임베딩을 허용하여 모델이 새 토큰을 더 잘 생성할 수 있도록 한다. 예비 실험에서 우리는 이 단계가 모델의 생성 능력을 향상시키는 데 중요하다는 것을 발견했다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p6">
<p class="ltx_p" id="S2.SS3.p6.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p6.1.1">Stage 5 (새로운 입력 및 모든 출력 임베딩):</span> 이 단계에서 훈련은 새로 추가된 토큰에 대한 입력 임베딩을 계속 정제하면서 모델의 어휘 전체에 걸쳐 모든 출력 임베딩을 미세 조정하기까지 확장됩니다. 목표는 모델이 확장된 어휘 내에서 어떤 토큰도 정확하게 예측할 수 있도록 하는 것이다. 이 단계는 모델의 언어적 이해의 광범위한 맥락 내에서 새로운 토큰의 통합을 강조하여 두 토큰이 모두 입력으로 잘 표현되고 출력으로 정확하게 생성되도록 한다. 이 이중 초점은 모델의 전체 성능을 조화시키는 데 도움이 되며 확장된 어휘가 언어 생성 과정에 원활하게 엮이도록 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p7">
<p class="ltx_p" id="S2.SS3.p7.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p7.1.1">Stage 6 (all layers):</span> 최종 단계인 것과는 반대로, 이 단계는 어휘 확장 프로세스에서 진보된 단계를 나타내며, 여기서 모든 모델 파라미터는 새로 도입되고 미리 존재하는 파라미터 모두를 포함하여 최적화의 대상이 된다. 여기서의 초점은 모델의 전체 매개변수 내에서 임베딩 레이어에 대한 개선 사항을 통합하는 데 있다. QLoRA와 같은 기법은 효율성뿐만 아니라 모델의 강력한 역량의 보존을 최대한 보장하는 동시에 확장된 어휘를 효과적으로 통합할 수 있도록 활용된다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p8">
<p class="ltx_p" id="S2.SS3.p8.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p8.1.1">Stage 7 (내부 계층):</span> 광범위한 통합 및 최적화 노력에 따라 이 단계는 입력 및 출력 임베딩 계층을 제외한 모든 계층을 포함하는 모델의 내부 계층을 업데이트하는 데 초점을 맞춘 "냉각" 단계 역할을 합니다. 어휘 확장 과정에서 향상된 내용이 모델의 핵심 처리 능력에 깊이 내재되도록 하는 것이 목적이다. 이 단계는 강력한 성능을 위한 모델을 준비하여 새로운 토큰을 인식하고 생성할 뿐만 아니라 다양한 언어 컨텍스트에서 토큰의 사용에 대한 미묘한 이해로 그렇게 하도록 한다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Implementation Details</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Datasets</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">pre-training</span>의 경우 한국어 웹 콘텐츠, 영어 어휘, 한국어 AI Hub의 병렬 말뭉치 <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aihub.or.kr/" title="">https://aihub.or.kr/</a></span></span></span> 등 다양한 소스에서 공개적으로 사용 가능한 한국어 말뭉치를 선별했다. 고품질 사전 학습 코퍼스를 구성하기 위해 1) 복잡도 기반 필터링, 2) n-gram 반복 <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib16" title="">2023a</a>)</cite> 기반 필터링, 3) 불용어 기반 필터링의 전처리 규칙을 적용하였다. 새로 추가된 한국어 토큰의 효율적인 훈련을 위해 의도적으로 이러한 토큰이 많이 포함되지 않은 문서를 필터링했다. 그 후, 우리는 총 3.2M 문서(또는 6.7GB)의 사전 훈련 코퍼스를 획득했다.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.1" style="width:398.9pt;height:237.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(104.3pt,-62.1pt) scale(2.09503048839611,2.09503048839611) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.1.1">Model</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.1.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.1.1.1.1.2.1">
<tbody><tr class="ltx_tr" id="S3.T2.1.1.1.1.2.1.1">
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.1.1.2.1.1.1">Total</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.1.1.2.1.2">
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.1.1.2.1.2.1">(tokens)</td>
</tr>
</tbody></table>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.3">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.1.1.1.1.3.1">
<tbody><tr class="ltx_tr" id="S3.T2.1.1.1.1.3.1.1">
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.1.1.3.1.1.1">Average</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.1.1.3.1.2">
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.1.1.3.1.2.1">(tokens)</td>
</tr>
</tbody></table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.1.1.2.1.1">SOLAR-10.7B</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.1.1.2.1.2">3.1B</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.1.2.1.3">964</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.1.1.3.2.1">EEVE-Korean-10.8B-v1.0</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.1.1.3.2.2">1.6B</td>
<td class="ltx_td ltx_align_left" id="S3.T2.1.1.3.2.3">500</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.1.1.4.3.1">Phi-2</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.1.1.4.3.2">5.6B</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.1.4.3.3">1748</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S3.T2.1.1.5.4.1">EEVE-Korean-2.8B-v1.0</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S3.T2.1.1.5.4.2">1.6B</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.1.1.5.4.3">484</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2:</span>Comparison of tokenizers for our 6.7GB pre-training corpus of the total 3.2M documents.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">표 <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S3.T2" title="Table 2 ‣ 3.1 Datasets ‣ 3 Implementation Details ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에서 볼 수 있듯이 전체 코퍼스에 대해 SOLAR 토큰화기는 3.1B 토큰을 사용하여 이를 나타내는 데 필요했지만 우리의 새로운 토큰화기는 1.6B 토큰만 사용하여 거의 절반으로 그렇게 할 수 있다. 이러한 차이는 Phi-2 및 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.1.1">EEVE-Korean-2.8B</span> 모델의 경우 더욱 두드러지며, 여기서 각각 5.6B 토큰 및 1.6B 토큰이 필요하다. 변압기가 토큰 길이와 관련하여 2차 증가하는 계산 복잡도를 갖는다는 점을 고려할 때, 이는 두 가지 중요한 방식으로 해석될 수 있다. 첫째, 동일한 GPU에서 4배 이상 더 긴 시퀀스를 처리할 수 있습니다. 또는 두 번째, 이는 우리의 모델이 동일한 데이터 세트에서 거의 4배 더 계산적으로 효율적으로 훈련될 수 있음을 의미한다. 이러한 차이는 Phi-2 및 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.1.2">EEVE-Korean-2.8B</span> tokenizers의 경우에 더욱 두드러지게 나타난다.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_italic" id="S3.SS1.p3.1.1">fine-tuning</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p3.1.2">EEVE-Korean</span> 모델들의 경우, LLaMA-Factory 구현 기반의 Direct Preference Optimization (DPO; <cite class="ltx_cite ltx_citemacro_citet">Rafailov et al. <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib25" title="">2023</a></cite>)을 채택하였다. 모델의 한국어 명령어 수행 능력을 더욱 향상시키기 위해 공개적으로 사용 가능한 명령어 데이터 세트, 특히 Orca<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup" title="">https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Mukherjee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib20" title="">2023</a>); Lian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib18" title="">2023</a>)</cite> 및 UltraFeedback<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/argilla/ultrafeedback-binarized-preferences-cleaned" title="">https://huggingface.co/datasets/argilla/ultrafeedback-binarized-preferences-cleaned</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Cui et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib5" title="">2023</a>)</cite>를 한국어로 번역했다. 이러한 데이터 세트를 한국어로 번역하는 과정에서 소스 언어와 타겟 언어가 모두 실수로 한국어로 번역되는 경우와 같이 프로그래밍 코드 형식의 무결성을 보장하고 번역 오류를 수정하는 것이 미세 조정 모델의 품질과 효율성을 유지하는 데 중요했다. 미세 조정된 모델을 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p3.1.3">EEVE-Korean-Instruct</span>으로 명명했다.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Training</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">기본 아키텍처로서 SOLAR-10.7B <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib12" title="">2023</a>)</cite>와 Phi-2 <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib17" title="">2023b</a>)</cite>를 선택하였는데, 이는 둘 다 비슷한 크기의 LLMs 사이에서 뛰어난 성능을 보였기 때문이다. 이러한 기초 아키텍처의 선택은 우리의 전략적 훈련 목표와 일치하며, 우리의 새로운 모델이 한국어에서 유사한 수준의 언어 이해 및 추론 능력을 달성할 수 있도록 입증된 장점을 활용한다.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">모델 변형의 학습을 위해 초기 사전 학습 단계에서는 Axolotl<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/OpenAccess-AI-Collective/axolotl" title="">https://github.com/OpenAccess-AI-Collective/axolotl</a></span></span></span>과 후속 미세 조정을 위해 LLaMA-Factory<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/hiyouga/LLaMA-Factory" title="">https://github.com/hiyouga/LLaMA-Factory</a></span></span></span><cite class="ltx_cite ltx_citemacro_cite">hiyouga (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib8" title="">2023</a>)</cite>의 두 가지 별개의 코드베이스를 활용했다. 이러한 코드베이스는 우리의 훈련 과정에 강력하고 신뢰할 수 있는 기반을 제공했다.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">특히, 64개의 CPU 코어를 사용하여 각각 80GB 메모리가 있는 8 x NVIDIA H100 GPU의 설정으로 모델을 훈련한다. <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.1.1">EEVE-Korean-10.8B-v1.0</span>의 경우, bf16 정밀도에서 훈련 프로세스는 길이 4096의 시퀀스, 기울기 축적 단계를 4로 설정하고 마이크로 배치 크기를 8로 구성한 반면, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.1.2">EEVE-Korean-2.8B-v1.0</span>은 시퀀스 길이 2048, 기울기 축적 16, 마이크로 배치 크기를 16으로 채택한다. 10단계의 웜업 단계를 포함하는 코사인 학습 속도 스케줄러와 쌍을 이루는 AdamW<cite class="ltx_cite ltx_citemacro_cite">Loshchilov and Hutter (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib19" title="">2018</a>)</cite> optimizer를 사용한다. 10.8B 변형에 대한 학습률은 4e-5로 설정된 반면, 작은 모델에 대해서는 2e-4를 사용했다. 우리는 손실이 수렴될 때까지 각 단계에서 훈련을 계속하여 400개의 글로벌 단계에 도달하기 전에 손실이 수렴되는 것을 관찰했으며 이는 훈련 전략의 효율성을 나타낸다. 훈련 전략은 7개의 다른 단계를 포함하지만, 2.8B 변형의 경우 출력 임베딩만을 최적화해도 많은 계산이 발생하지 않기 때문에 전체 사전 훈련을 이틀 이내에 수행할 수 있다는 점은 주목할 만하다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.6" style="width:424.9pt;height:282.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.5pt,14.9pt) scale(0.904308479588229,0.904308479588229) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T3.6.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.6.6.7.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T3.6.6.7.1.1" rowspan="2"><span class="ltx_text" id="S4.T3.6.6.7.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.6.6.7.1.2" rowspan="2"><span class="ltx_text" id="S4.T3.6.6.7.1.2.1">Types</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T3.6.6.7.1.3">English</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S4.T3.6.6.7.1.4">Korean</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.6.6.7.1.5" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.7.1.5.1">Avg.</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.8.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.8.2.1"><span class="ltx_text" id="S4.T3.6.6.8.2.1.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.8.2.1.1.1">
<span class="ltx_tr" id="S4.T3.6.6.8.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.1.1.1.1.1">BQ</span></span>
<span class="ltx_tr" id="S4.T3.6.6.8.2.1.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.1.1.1.2.1">(0)</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.8.2.2"><span class="ltx_text" id="S4.T3.6.6.8.2.2.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.8.2.2.1.1">
<span class="ltx_tr" id="S4.T3.6.6.8.2.2.1.1.1">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.2.1.1.1.1">CP</span></span>
<span class="ltx_tr" id="S4.T3.6.6.8.2.2.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.2.1.1.2.1">(0)</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.8.2.3"><span class="ltx_text" id="S4.T3.6.6.8.2.3.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.8.2.3.1.1">
<span class="ltx_tr" id="S4.T3.6.6.8.2.3.1.1.1">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.3.1.1.1.1">HS</span></span>
<span class="ltx_tr" id="S4.T3.6.6.8.2.3.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.3.1.1.2.1">(0)</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.8.2.4"><span class="ltx_text" id="S4.T3.6.6.8.2.4.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.8.2.4.1.1">
<span class="ltx_tr" id="S4.T3.6.6.8.2.4.1.1.1">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.4.1.1.1.1">BQ</span></span>
<span class="ltx_tr" id="S4.T3.6.6.8.2.4.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.4.1.1.2.1">(0)</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.8.2.5"><span class="ltx_text" id="S4.T3.6.6.8.2.5.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.8.2.5.1.1">
<span class="ltx_tr" id="S4.T3.6.6.8.2.5.1.1.1">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.5.1.1.1.1">CP</span></span>
<span class="ltx_tr" id="S4.T3.6.6.8.2.5.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.5.1.1.2.1">(0)</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.8.2.6"><span class="ltx_text" id="S4.T3.6.6.8.2.6.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.8.2.6.1.1">
<span class="ltx_tr" id="S4.T3.6.6.8.2.6.1.1.1">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.6.1.1.1.1">HS</span></span>
<span class="ltx_tr" id="S4.T3.6.6.8.2.6.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.6.1.1.2.1">(0)</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.8.2.7"><span class="ltx_text" id="S4.T3.6.6.8.2.7.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.8.2.7.1.1">
<span class="ltx_tr" id="S4.T3.6.6.8.2.7.1.1.1">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.7.1.1.1.1">SN</span></span>
<span class="ltx_tr" id="S4.T3.6.6.8.2.7.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.7.1.1.2.1">(0)</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.8.2.8"><span class="ltx_text" id="S4.T3.6.6.8.2.8.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.8.2.8.1.1">
<span class="ltx_tr" id="S4.T3.6.6.8.2.8.1.1.1">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.8.1.1.1.1">WIC</span></span>
<span class="ltx_tr" id="S4.T3.6.6.8.2.8.1.1.2">
<span class="ltx_td ltx_align_center" id="S4.T3.6.6.8.2.8.1.1.2.1">(0)</span></span>
</span></span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.9.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.6.6.9.3.1">meta-llama/Llama-2-7b-hf</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.2">PT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.3">0.7774</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.4">0.8700</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.5">0.5714</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.6">0.5242</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.7">0.5700</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.8">0.4420</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.9">0.4610</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.10">0.4881</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.9.3.11">0.5880</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.10.4">
<td class="ltx_td ltx_align_left" id="S4.T3.6.6.10.4.1">meta-llama/Llama-2-13b-hf</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.2">PT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.3">0.8055</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.4">0.9100</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.5">0.6006</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.6">0.5214</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.7">0.6010</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.8">0.4380</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.9">0.5038</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.10">0.4881</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.10.4.11">0.6086</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.11.5">
<td class="ltx_td ltx_align_left" id="S4.T3.6.6.11.5.1">mistralai/Mistral-7B-v0.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.2">PT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.3">0.8379</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.4">0.9200</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.5">0.6129</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.6">0.6282</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.7">0.5880</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.8">0.4300</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.9">0.5365</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.10">0.4881</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.11.5.11">0.6302</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.12.6">
<td class="ltx_td ltx_align_left" id="S4.T3.6.6.12.6.1">meta-llama/Llama-2-7b-chat-hf</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.2">FT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.3">0.7976</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.4">0.8700</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.5">0.5779</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.6">0.5157</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.7">0.5530</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.8">0.4160</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.9">0.4987</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.10">0.4881</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.12.6.11">0.5896</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.13.7">
<td class="ltx_td ltx_align_left" id="S4.T3.6.6.13.7.1">meta-llama/Llama-2-13b-chat-hf</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.2">FT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.3">0.8165</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.4">0.8800</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.5">0.6072</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.6">0.5057</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.7">0.5760</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.8">0.4040</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.9">0.4685</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.10">0.4881</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.13.7.11">0.5933</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.14.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.6.6.14.8.1">upstage/SOLAR-10.7B-v1.0 (base)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.2">PT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.3">0.8257</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.4">0.8700</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.5">0.6393</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.6">0.5057</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.7">0.5750</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.8">0.4320</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.9">0.6146</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.10">0.4881</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.14.8.11">0.6188</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.15.9">
<td class="ltx_td ltx_align_left" id="S4.T3.6.6.15.9.1">upstage/SOLAR-10.7B-Instruct-v1.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.2">FT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.3"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.15.9.3.1">0.8853</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.4"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.15.9.4.1">0.9400</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.5"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.15.9.5.1">0.6866</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.6">0.8184</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.7">0.6370</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.8">0.4560</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.9">0.5668</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.10">0.4921</td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.15.9.11">0.6853</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.1">
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.1.1">beomi/OPEN-SOLAR-KO-10.7B<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.m1.1a"><msup id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml"><mi id="S4.T3.1.1.1.1.m1.1.1a" xref="S4.T3.1.1.1.1.m1.1.1.cmml"></mi><mo id="S4.T3.1.1.1.1.m1.1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1"><times id="S4.T3.1.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.2">PT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.3">0.8187</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.4">0.8800</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.5">0.5570</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.6">0.8355</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.7.1">0.8010</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.8.1">0.5040</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.9">0.6952</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.10">0.4897</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.11">0.6976</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.2">
<td class="ltx_td ltx_align_left" id="S4.T3.2.2.2.1">yanolja/EEVE-Korean-10.8B-v1.0<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S4.T3.2.2.2.1.m1.1"><semantics id="S4.T3.2.2.2.1.m1.1a"><msup id="S4.T3.2.2.2.1.m1.1.1" xref="S4.T3.2.2.2.1.m1.1.1.cmml"><mi id="S4.T3.2.2.2.1.m1.1.1a" xref="S4.T3.2.2.2.1.m1.1.1.cmml"></mi><mo id="S4.T3.2.2.2.1.m1.1.1.1" xref="S4.T3.2.2.2.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.1.m1.1b"><apply id="S4.T3.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.1.m1.1.1"><times id="S4.T3.2.2.2.1.m1.1.1.1.cmml" xref="S4.T3.2.2.2.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.2">PT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.3">0.8492</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.4">0.9000</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.5">0.6203</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.6">0.8568</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.7">0.7530</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.8">0.4900</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.9">0.6675</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.10"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.10.1">0.4992</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.11">0.7045</td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.3.3">
<td class="ltx_td ltx_align_left" id="S4.T3.3.3.3.1">yanolja/EEVE-Korean-Instruct-10.8B-v1.0<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S4.T3.3.3.3.1.m1.1"><semantics id="S4.T3.3.3.3.1.m1.1a"><msup id="S4.T3.3.3.3.1.m1.1.1" xref="S4.T3.3.3.3.1.m1.1.1.cmml"><mi id="S4.T3.3.3.3.1.m1.1.1a" xref="S4.T3.3.3.3.1.m1.1.1.cmml"></mi><mo id="S4.T3.3.3.3.1.m1.1.1.1" xref="S4.T3.3.3.3.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.1.m1.1b"><apply id="S4.T3.3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.3.1.m1.1.1"><times id="S4.T3.3.3.3.1.m1.1.1.1.cmml" xref="S4.T3.3.3.3.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.2">FT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.3">0.8810</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.4">0.9300</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.5">0.6502</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.6"><span class="ltx_text ltx_font_bold" id="S4.T3.3.3.3.6.1">0.8860</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.7">0.7610</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.8">0.4700</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.9"><span class="ltx_text ltx_font_bold" id="S4.T3.3.3.3.9.1">0.9521</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.10">0.4937</td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.3.11"><span class="ltx_text ltx_font_bold" id="S4.T3.3.3.3.11.1">0.7530</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.16.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.6.6.16.10.1">microsoft/Phi-2 (base)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.2">PT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.3"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.16.10.3.1">0.8336</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.4"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.16.10.4.1">0.9000</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.5"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.16.10.5.1">0.5583</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.6">0.5021</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.7">0.4770</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.8">0.3280</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.9">0.5063</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.10">0.4881</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.16.10.11">0.5742</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.4.4">
<td class="ltx_td ltx_align_left" id="S4.T3.4.4.4.1">daekeun-ml/phi-2-ko-v0.1<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S4.T3.4.4.4.1.m1.1"><semantics id="S4.T3.4.4.4.1.m1.1a"><msup id="S4.T3.4.4.4.1.m1.1.1" xref="S4.T3.4.4.4.1.m1.1.1.cmml"><mi id="S4.T3.4.4.4.1.m1.1.1a" xref="S4.T3.4.4.4.1.m1.1.1.cmml"></mi><mo id="S4.T3.4.4.4.1.m1.1.1.1" xref="S4.T3.4.4.4.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.1.m1.1b"><apply id="S4.T3.4.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.4.1.m1.1.1"><times id="S4.T3.4.4.4.1.m1.1.1.1.cmml" xref="S4.T3.4.4.4.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.4.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.2">PT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.3">0.6141</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.4">0.5800</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.5">0.3257</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.6">0.5164</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.7"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.7.1">0.6100</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.8"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.8.1">0.3860</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.9">0.4484</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.10">0.4881</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.4.11">0.4961</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.5">
<td class="ltx_td ltx_align_left" id="S4.T3.5.5.5.1">yanolja/EEVE-Korean-2.8B-v1.0<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S4.T3.5.5.5.1.m1.1"><semantics id="S4.T3.5.5.5.1.m1.1a"><msup id="S4.T3.5.5.5.1.m1.1.1" xref="S4.T3.5.5.5.1.m1.1.1.cmml"><mi id="S4.T3.5.5.5.1.m1.1.1a" xref="S4.T3.5.5.5.1.m1.1.1.cmml"></mi><mo id="S4.T3.5.5.5.1.m1.1.1.1" xref="S4.T3.5.5.5.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.1.m1.1b"><apply id="S4.T3.5.5.5.1.m1.1.1.cmml" xref="S4.T3.5.5.5.1.m1.1.1"><times id="S4.T3.5.5.5.1.m1.1.1.1.cmml" xref="S4.T3.5.5.5.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.5.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.2">PT</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.3">0.7404</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.4">0.8900</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.5">0.5247</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.6">0.5299</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.7">0.5820</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.8">0.3800</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.9">0.5164</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.10">0.4881</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.5.11">0.5814</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.6.6.6.1">yanolja/EEVE-Korean-Instruct-2.8B-v1.0<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S4.T3.6.6.6.1.m1.1"><semantics id="S4.T3.6.6.6.1.m1.1a"><msup id="S4.T3.6.6.6.1.m1.1.1" xref="S4.T3.6.6.6.1.m1.1.1.cmml"><mi id="S4.T3.6.6.6.1.m1.1.1a" xref="S4.T3.6.6.6.1.m1.1.1.cmml"></mi><mo id="S4.T3.6.6.6.1.m1.1.1.1" xref="S4.T3.6.6.6.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.1.m1.1b"><apply id="S4.T3.6.6.6.1.m1.1.1.cmml" xref="S4.T3.6.6.6.1.m1.1.1"><times id="S4.T3.6.6.6.1.m1.1.1.1.cmml" xref="S4.T3.6.6.6.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.6.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.2">FT</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.3">0.8248</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.4">0.8700</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.5">0.5392</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.6"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.6.1">0.7066</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.7">0.5640</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.8">0.3660</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.9"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.9.1">0.5290</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.10"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.10.1">0.5230</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.6.6.11"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.11.1">0.6153</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 3:</span> <span class="ltx_text ltx_font_typewriter" id="S4.T3.11.1">lm-evaluation-harness</span>에 기반한 주요 평가 결과. 데이터 세트 이름은 간결함을 위해 약칭됩니다. BoolQ의 경우 BQ, COPA의 경우 CP, HellaSwag의 경우 HS, SentiNeg의 경우 SN입니다. Korean tasks is from <cite class="ltx_cite ltx_citemacro_cite">Jang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib9" title="">2022</a>)</cite>. 정확도(<span class="ltx_text ltx_font_typewriter" id="S4.T3.12.2">acc</span>)는 모든 작업에 대한 평가 메트릭으로 사용됩니다. '유형' 열에서 모델은 사전 훈련(PT)과 미세 조정(FT)의 두 그룹으로 분류된다. 우리는 <math alttext="{}^{*}" class="ltx_Math" display="inline" id="S4.T3.8.m1.1"><semantics id="S4.T3.8.m1.1b"><msup id="S4.T3.8.m1.1.1" xref="S4.T3.8.m1.1.1.cmml"><mi id="S4.T3.8.m1.1.1b" xref="S4.T3.8.m1.1.1.cmml"></mi><mo id="S4.T3.8.m1.1.1.1" xref="S4.T3.8.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.8.m1.1c"><apply id="S4.T3.8.m1.1.1.cmml" xref="S4.T3.8.m1.1.1"><times id="S4.T3.8.m1.1.1.1.cmml" xref="S4.T3.8.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.m1.1d">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.8.m1.1e">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>로 한국어 데이터셋에서 학습된 모델을 나타낸다. 번식을 쉽게 하기 위해 HuggingFace에서 공식 이름을 사용합니다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">한국어 및 영어 LLM 벤치마크에 대한 모델을 평가하여 기본 기본 모델의 강력한 다국어 기능을 효율적으로 활용할 수 있는 어휘 확장 방법의 이점을 강조한다. 바람직하게는 한국어 과제에서는 향상된 성능을 보이고 영어 과제에서는 비슷한 성능을 보일 수 있는 모델을 기대한다.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Benchmarks</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">한국어 과제를 위해 KoBEST 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">Jang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib9" title="">2022</a>)</cite>를 채택하였으며, 이 과제들은 언어 이해와 추론의 다양한 측면을 평가하도록 설계되었다. 구체적으로, 이 벤치마크는 한국어 번역 버전의 언어 이해 태스크를 제공한다: 부울 질문 응답(BoolQ; <cite class="ltx_cite ltx_citemacro_citet">Clark et al. <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib3" title="">2019</a></cite>), 커먼센스 인과 추론(COPA; <cite class="ltx_cite ltx_citemacro_citet">Roemmele et al. <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib26" title="">2011</a></cite>, 문맥 민감 단어 이해(WiC; <cite class="ltx_cite ltx_citemacro_citet">Pilehvar and Camacho-Collados <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib24" title="">2019</a></cite>), 커먼센스 추론(HellaSwag; <cite class="ltx_cite ltx_citemacro_citet">Zellers et al. <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib32" title="">2019</a></cite>), 및 감정 부정 인식(SentiNeg). 영어 과제의 경우 KoBEST, BoolQ, COPA 및 HellaSwag의 다음과 같은 원래 과제를 사용하며, 이는 LLM의 영어와 한국어 능력 간의 정렬을 더 잘 강조할 수 있다. 일관된 비교를 보장하기 위해 오픈 소스 LLM 평가 프레임워크인 <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.1">lm-evaluation-harness<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote9.1.1.1">9</span></span><a class="ltx_ref ltx_url" href="https://github.com/EleutherAI/lm-evaluation-harness" title="">https://github.com/EleutherAI/lm-evaluation-harness</a></span></span></span></span></cite idx=5></cite>를 사용합니다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">이제 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.1">EEVE-Korean</span> 및 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.2">EEVE-Korean-Instruct</span> variants with other top-performing models in Table <a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#S4.T3" title="Table 3 ‣ 4 Evaluations ‣ Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>. <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.3">EEVE-Korean-10.8B-v1.0</span>은 평균 성능에서 비슷한 크기의 다른 사전 학습된 모델을 능가한다. 주목할 점은 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.4">EEVE-Korean</span>이 영어로 된 성능을 손상시키지 않으면서 한국어로 된 성능이 향상된 유일한 경우라는 것이다. 예를 들어, 우리와 동일한 기본 모델에 구축된 OPEN-SOLAR-KO-10.7B는 우리의 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.5">EEVE-Korean-Instruct-10.8B-v1.0</span>보다 영어 능력을 약간 더 잘 보존하지 못하여 기본 모델인 SOLAR-10.7B-v1.0보다 영어 작업에서 낮은 성능을 보인다. 우리는 작은 모델인 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.6">EEVE-Korean-2.8B-v1.0</span>에서도 Phi-2를 기본 모델로 공유하는 phi-2-ko-v0.1 모델과 비교하여 유사한 경향을 관찰한다. 이는 특히 경쟁사보다 훨씬 적은 수의 훈련 토큰을 사용했다는 점을 고려할 때 훈련 전략의 효과를 보여줍니다.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.2">특히, 놀랍지 않게, 영어 데이터 세트에 대한 선호도 튜닝은 심지어 모델이 한국어 작업에서 저조하게 성능을 발휘하게 한다. 예를 들어, LLaMA-2 체크포인트의 선호도 조정 버전인 LLaMA-2-chat 변형은 영어 태스크에서 향상된 성능을 보여주며(Llama-2-7b 0.7774 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mo id="S4.SS2.p2.1.m1.1.1" stretchy="false" xref="S4.SS2.p2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">→</annotation></semantics></math> Llama-2-7b-chat 0.7976 in English BoolQ), 한국어 태스크에서는 낮은 성능을 보여주며(Llama-2-7b 0.5242 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1"><semantics id="S4.SS2.p2.2.m2.1a"><mo id="S4.SS2.p2.2.m2.1.1" stretchy="false" xref="S4.SS2.p2.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m2.1d">→</annotation></semantics></math> Llama-2-7b-chat 0.5157 in Korean BoolQ), 이는 LLMs에 대한 한국어별 훈련의 중요성을 강조한다. 반면에, 우리는 한국어 명령어 데이터 세트에서 우리의 모델을 선호하는 조정이 영어 작업에서 모델 성능에 해를 끼치지 않고 오히려 개선한다는 것을 관찰한다. 우리는 임베딩 공간이 이미 한국어 토큰과 영어 토큰 사이에 잘 정렬되어 있기 때문에 특정 언어에 대한 미세 조정이 모델 매개변수에 큰 변화를 일으키지 않기 때문이라고 가정한다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion &amp; Future Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">이 보고서는 한국어 텍스트 처리 능력을 크게 향상시키기 위해 EEEVE( Efficient and Effective Vocabulary Expansion) 방법을 활용하는 대형 언어 모델의 한국어 적응 <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.1">EEVE-Korean-v1.0</span>을 소개한다. 파라미터 동결 및 서브워드 초기화에 기반한 이 방법은 <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.2">EEVE-Korean-10.8B-v1.0</span> 모델이 강력한 영어 능력을 유지하면서 한국어 작업을 능가할 수 있도록 한다. 단 20억 토큰의 코퍼스로 달성된 이 접근법은 언어 모델 훈련 효율성과 효율성에서 주목할만한 발전을 나타낸다. 이 프로젝트는 이러한 모델을 연구 커뮤니티에서 사용할 수 있도록 함으로써 보다 포괄적이고 효율적인 언어 처리 기술의 개발에 기여하는 것을 목표로 한다.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">비전을 확장하면 향후 노력은 어휘 확장 방법론을 추가 언어에 적용하여 일반화 가능성과 효율성을 평가하는 것을 탐구할 것이다. <span class="ltx_text ltx_font_typewriter" id="S5.p2.1.1">EEVE-Korean</span> 모델의 언어 범위를 확장할 뿐만 아니라 GSM8K <cite class="ltx_cite ltx_citemacro_cite">Cobbe et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib4" title="">2021</a>)</cite>와 같은 복잡한 수학적 추론 테스트와 채팅봇 <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib35" title="">2023</a>)</cite>와 같은 대화형 설정에서의 인간 평가를 포함하여 다양한 작업을 통해 추론 및 생성 능력을 더 깊이 평가하는 것을 목표로 한다. 또한 사전 훈련 데이터 품질을 높이고 코드 전환 시나리오에서 성능을 분석하려는 노력<cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.14714v1#bib.bib33" title="">2023</a>)</cite>는 모델의 견고성과 다양성을 개선하려는 우리의 의지를 뒷받침할 것이다. 이러한 이니셔티브는 모델의 적용 가능성과 효율성을 넓히기 위해 고안되었으며 고급 언어 모델로 달성할 수 있는 것의 경계를 확장한다.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Almazrouei et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Mérouane Debbah, Étienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">The falcon series of open language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2311.16867</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anthropic. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.anthropic.com/news/claude-2" title="">Model card and evaluations for claude models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Anthropic technical Report</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">Boolq: Exploring the surprising difficulty of natural yes/no questions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 2924–2936.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et&nbsp;al. 2021.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2110.14168</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Wei Zhu, Yuan Ni, Guotong Xie, Zhiyuan Liu, and Maosong Sun. 2023.

</span>
<span class="ltx_bibblock">Ultrafeedback: Boosting language models with high-quality feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2310.01377</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le&nbsp;Noac’h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.5281/zenodo.10256836" title="">A framework for few-shot language model evaluation</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hewitt (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
John Hewitt. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https:/nlp.stanford.edu/~johnhew//vocab-expansion.html" title="">Initializing new word embeddings for pretrained language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">hiyouga (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
hiyouga. 2023.

</span>
<span class="ltx_bibblock">Llama factory.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/hiyouga/LLaMA-Factory" title="">https://github.com/hiyouga/LLaMA-Factory</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Myeongjun Jang, Dohyung Kim, Deuk&nbsp;Sin Kwon, and Eric Davis. 2022.

</span>
<span class="ltx_bibblock">Kobest: Korean balanced evaluation of significant tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 29th International Conference on Computational Linguistics</em>, pages 3697–3708.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert&nbsp;Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2310.06825</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert&nbsp;Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Emma&nbsp;Bou Hanna, Florian Bressand, et&nbsp;al. 2024.

</span>
<span class="ltx_bibblock">Mixtral of experts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2401.04088</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dahyun Kim, Chanjun Park, Sanghoon Kim, Wonsung Lee, Wonho Song, Yunsu Kim, Hyeonwoo Kim, Yungi Kim, Hyeonju Lee, Jihoo Kim, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Solar 10.7 b: Scaling large language models with simple yet effective depth up-scaling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2312.15166</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ildoo Kim, Gunsoo Han, Jiyeon Ham, and Woonhyuk Baek. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/kakaobrain/kogpt" title="">Kogpt: Kakaobrain korean(hangul) generative pretrained transformer</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ko et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hyunwoong Ko, Kichang Yang, Minho Ryu, Taekyoon Choi, Seungmu Yang, Sungho Park, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">A technical report for polyglot-ko: Open-source large-scale korean language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2306.02254</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">L. Junbum (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
L. Junbum. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://huggingface.co/beomi/SOLAR-KO-10.7B" title="">Solar-ko-10.7b</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Huayang Li, Tian Lan, Zihao Fu, Deng Cai, Lemao Liu, Nigel Collier, Taro Watanabe, and Yixuan Su. 2023a.

</span>
<span class="ltx_bibblock">Repetition in repetition out: Towards understanding neural text degeneration from the data perspective.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Thirty-seventh Conference on Neural Information Processing Systems</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Allie Del&nbsp;Giorno, Suriya Gunasekar, and Yin&nbsp;Tat Lee. 2023b.

</span>
<span class="ltx_bibblock">Textbooks are all you need ii: phi-1.5 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2309.05463</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lian et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wing Lian, Guan Wang, Bleys Goodson, Eugene Pentland, Austin Cook, Chanvichet Vong, "Teknium", and Nathan Hoos. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/Open-Orca/SlimOrca-Dedup/" title="">Slimorca dedup: A deduplicated subset of slimorca</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2018.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mukherjee et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock">Orca: Progressive learning from complex explanation traces of gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2306.02707</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chanjun Park, Hwalsuk Lee, Hyunbyung Park, Hyeonwoo Kim, Sanghoon Kim, Seonghwan Cho, Sunghun Kim, and Sukyung Lee. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard" title="">Open ko-llm leaderboard</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrov et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aleksandar Petrov, Emanuele La&nbsp;Malfa, Philip&nbsp;HS Torr, and Adel Bibi. 2023.

</span>
<span class="ltx_bibblock">Language model tokenizers introduce unfairness between languages.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2305.15425</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pilehvar and Camacho-Collados (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mohammad&nbsp;Taher Pilehvar and Jose Camacho-Collados. 2019.

</span>
<span class="ltx_bibblock">Wic: the word-in-context dataset for evaluating context-sensitive meaning representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 1267–1273.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher&nbsp;D Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2305.18290</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roemmele et&nbsp;al. (2011)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Melissa Roemmele, Cosmin&nbsp;Adrian Bejan, and Andrew&nbsp;S Gordon. 2011.

</span>
<span class="ltx_bibblock">Choice of plausible alternatives: An evaluation of commonsense causal reasoning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">2011 AAAI Spring Symposium Series</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew&nbsp;M Dai, Anja Hauth, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2312.11805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
MosaicML&nbsp;NLP Team et&nbsp;al. 2023b.

</span>
<span class="ltx_bibblock">Introducing mpt-30b: Raising the bar for open-source foundation models.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et&nbsp;al. 2023b.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2307.09288</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Welch et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Charles Welch, Rada Mihalcea, and Jonathan&nbsp;K Kummerfeld. 2020.

</span>
<span class="ltx_bibblock">Improving low compute language modeling with in-domain embedding initialisation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 8625–8634.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019.

</span>
<span class="ltx_bibblock">Hellaswag: Can a machine really finish your sentence?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 4791–4800.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ruochen Zhang, Samuel Cahyawijaya, Jan Christian&nbsp;Blaise Cruz, and Alham&nbsp;Fikri Aji. 2023.

</span>
<span class="ltx_bibblock">Multilingual large language models are not (yet) code-switchers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2305.14235</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jun Zhao, Zhihao Zhang, Qi&nbsp;Zhang, Tao Gui, and Xuanjing Huang. 2024.

</span>
<span class="ltx_bibblock">Llama beyond english: An empirical study on language capability transfer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2401.01055</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi&nbsp;Lin, Zhuohan Li, Dacheng Li, Eric Xing, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2306.05685</em>.

</span>
</li>
</ul>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>