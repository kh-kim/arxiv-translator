<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.05875] CodecLM: Aligning Language Models with Tailored Synthetic Data</title><meta property="og:description" content="Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next-token prediction objective and usersâ€™ actual goalsâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CodecLM: Aligning Language Models with Tailored Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="CodecLM: Aligning Language Models with Tailored Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.05875">

<!--Generated on Sun May  5 16:42:54 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">CodecLM: Aligning Language Models with Tailored Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zifeng Wang<sup id="id12.12.id1" class="ltx_sup">â€ </sup>, Chun-Liang Li<sup id="id13.13.id2" class="ltx_sup">â€ </sup>, Vincent Perot<sup id="id14.14.id3" class="ltx_sup">âˆ—</sup>, Long T. Le<sup id="id15.15.id4" class="ltx_sup">â€ </sup>, 
<br class="ltx_break"><span id="id11.11.7" class="ltx_text ltx_font_bold">Jin Miao<sup id="id11.11.7.1" class="ltx_sup"><span id="id11.11.7.1.1" class="ltx_text ltx_font_medium">â€¡</span></sup>, Zizhao Zhang<sup id="id11.11.7.2" class="ltx_sup"><span id="id11.11.7.2.1" class="ltx_text ltx_font_medium">â€¡</span></sup>, Chen-Yu Lee<sup id="id11.11.7.3" class="ltx_sup"><span id="id11.11.7.3.1" class="ltx_text ltx_font_medium">â€ </span></sup>, Tomas Pfister<sup id="id11.11.7.4" class="ltx_sup"><span id="id11.11.7.4.1" class="ltx_text ltx_font_medium">â€ </span></sup> 
<br class="ltx_break"><sup id="id11.11.7.5" class="ltx_sup"><span id="id11.11.7.5.1" class="ltx_text ltx_font_medium">â€ </span></sup>Google Cloud AI Research, <sup id="id11.11.7.6" class="ltx_sup"><span id="id11.11.7.6.1" class="ltx_text ltx_font_medium">â€¡</span></sup>Google Cloud AI, <sup id="id11.11.7.7" class="ltx_sup"><span id="id11.11.7.7.1" class="ltx_text ltx_font_medium">âˆ—</span></sup>Google Research
<br class="ltx_break"></span><span id="id16.16.id5" class="ltx_text ltx_font_typewriter">{zifengw, chunliang, vperot, longtle,</span><span id="id17.17.id6" class="ltx_text ltx_font_bold"> 
<br class="ltx_break"></span><span id="id18.18.id7" class="ltx_text ltx_font_typewriter">jinmiao, zizhaoz, chenyulee, tpfister}@google.com</span><span id="id19.19.id8" class="ltx_text ltx_font_bold">
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id20.id1" class="ltx_p">Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next-token prediction objective and usersâ€™ actual goals. To reduce the labor and time cost to collect or annotate data by humans, researchers start to explore the use of LLMs to generate instruction-aligned synthetic data.
Recent works focus on generating diverse instructions and applying LLM to increase instruction complexity, often neglecting downstream use cases. It remains unclear how to <em id="id20.id1.1" class="ltx_emph ltx_font_italic">tailor</em> high-quality data to elicit better instruction-following abilities in different target instruction distributions and LLMs. To this end, we introduce <span id="id20.id1.2" class="ltx_text ltx_font_bold">CodecLM</span>, a general framework for adaptively generating high-quality synthetic data for LLM alignment with different downstream instruction distributions and LLMs. Drawing on the Encode-Decode principles, we use LLMs as codecs to guide the data generation process.
We first <em id="id20.id1.3" class="ltx_emph ltx_font_italic">encode</em> seed instructions into metadata, which are concise keywords generated on-the-fly to capture the target instruction distribution, and then <em id="id20.id1.4" class="ltx_emph ltx_font_italic">decode</em> metadata to create tailored instructions. We also introduce Self-Rubrics and Contrastive Filtering during decoding to tailor data-efficient samples. Extensive experiments on four open-domain instruction following benchmarks validate the effectiveness of CodecLM over the current state-of-the-arts.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.11" class="ltx_block ltx_align_bottom">
<p id="p1.11.12" class="ltx_p"><span id="p1.11.12.1" class="ltx_text ltx_font_bold">CodecLM: Aligning Language Models with Tailored Synthetic Data</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.11.11" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.11.11.11" class="ltx_text ltx_inline-block" style="width:0.0pt;">

<span id="p1.11.11.11.11" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.4.4.4.4.4" class="ltx_tr">
<span id="p1.4.4.4.4.4.4" class="ltx_td ltx_align_center"><span id="p1.4.4.4.4.4.4.4" class="ltx_text ltx_font_bold">Zifeng Wang<sup id="p1.4.4.4.4.4.4.4.1" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_medium">â€ </span></sup>, Chun-Liang Li<sup id="p1.4.4.4.4.4.4.4.2" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.2.1" class="ltx_text ltx_font_medium">â€ </span></sup>, Vincent Perot<sup id="p1.4.4.4.4.4.4.4.3" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.3.1" class="ltx_text ltx_font_medium">âˆ—</span></sup>, Long T. Le<sup id="p1.4.4.4.4.4.4.4.4" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.4.1" class="ltx_text ltx_font_medium">â€ </span></sup>,</span></span></span>
<span id="p1.8.8.8.8.8" class="ltx_tr">
<span id="p1.8.8.8.8.8.4" class="ltx_td ltx_align_center"><span id="p1.8.8.8.8.8.4.4" class="ltx_text ltx_font_bold">Jin Miao<sup id="p1.8.8.8.8.8.4.4.1" class="ltx_sup"><span id="p1.8.8.8.8.8.4.4.1.1" class="ltx_text ltx_font_medium">â€¡</span></sup>, Zizhao Zhang<sup id="p1.8.8.8.8.8.4.4.2" class="ltx_sup"><span id="p1.8.8.8.8.8.4.4.2.1" class="ltx_text ltx_font_medium">â€¡</span></sup>, Chen-Yu Lee<sup id="p1.8.8.8.8.8.4.4.3" class="ltx_sup"><span id="p1.8.8.8.8.8.4.4.3.1" class="ltx_text ltx_font_medium">â€ </span></sup>, Tomas Pfister<sup id="p1.8.8.8.8.8.4.4.4" class="ltx_sup"><span id="p1.8.8.8.8.8.4.4.4.1" class="ltx_text ltx_font_medium">â€ </span></sup></span></span></span>
<span id="p1.11.11.11.11.11" class="ltx_tr">
<span id="p1.11.11.11.11.11.3" class="ltx_td ltx_align_center"><sup id="p1.11.11.11.11.11.3.1" class="ltx_sup">â€ </sup>Google Cloud AI Research, <sup id="p1.11.11.11.11.11.3.2" class="ltx_sup">â€¡</sup>Google Cloud AI, <sup id="p1.11.11.11.11.11.3.3" class="ltx_sup">âˆ—</sup>Google Research</span></span>
<span id="p1.11.11.11.11.12.1" class="ltx_tr">
<span id="p1.11.11.11.11.12.1.1" class="ltx_td ltx_align_center"><span id="p1.11.11.11.11.12.1.1.1" class="ltx_text ltx_font_typewriter">{zifengw, chunliang, vperot, longtle,</span></span></span>
<span id="p1.11.11.11.11.13.2" class="ltx_tr">
<span id="p1.11.11.11.11.13.2.1" class="ltx_td ltx_align_center"><span id="p1.11.11.11.11.13.2.1.1" class="ltx_text ltx_font_typewriter">jinmiao, zizhaoz, chenyulee, tpfister}@google.com</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2404.05875/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="438" height="391" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of CodecLM. We first <span id="S1.F1.3.1" class="ltx_text ltx_font_bold">encode</span> seed instructions into metadata to capture the underlying distribution of instructions. This metadata is then <span id="S1.F1.4.2" class="ltx_text ltx_font_bold">decoded</span> through Self-Rubrics and Contrastive Filtering to tailor high-quality synthetic instructions that are aligned with the target instruction distribution. Intermediate instructions and responses are omitted in the figure for clarity.</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Large language models (LLMs) have exhibited remarkable capabilities across a wide array of natural language processing (NLP) tasks <cite class="ltx_cite ltx_citemacro_citep">(Brown et&nbsp;al., <a href="#bib.bib6" title="" class="ltx_ref">2020</a>; Ouyang et&nbsp;al., <a href="#bib.bib36" title="" class="ltx_ref">2022</a>; OpenAI, <a href="#bib.bib34" title="" class="ltx_ref">2023a</a>; Anil et&nbsp;al., <a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite>. In particular, LLMs can be trained for improved instruction-following through various methods, including fine-tuning on human-annotated data&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a href="#bib.bib44" title="" class="ltx_ref">2023</a>; Bai et&nbsp;al., <a href="#bib.bib3" title="" class="ltx_ref">2022</a>)</cite> or extracted knowledge from stronger LLMs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2022</a>; Taori et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>; Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>; Peng et&nbsp;al., <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite>. Recent progress in this area highlights the critical role of high-quality data in enhancing LLMsâ€™ instruction-following capabilities&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a href="#bib.bib55" title="" class="ltx_ref">2023a</a>; KÃ¶pf et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2023</a>; Chen et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023b</a>)</cite>. However, acquiring such data through human annotation remains cost-prohibitive and difficult to scale, hindering further progress.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">As an alternative solution to human annotation, recent work explores generating instruction-response pairs for LLM alignment by prompting them with example data or prompts and iteratively refining the results&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Honovich et&nbsp;al., <a href="#bib.bib20" title="" class="ltx_ref">2022</a>; Wang et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2022</a>; Li et&nbsp;al., <a href="#bib.bib27" title="" class="ltx_ref">2023</a>; Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>. While these methods are effective at generating diverse and complex instructions for LLM alignment broadly, real-world applications often prioritize tailoring the LLM to specific downstream tasks such as individual enterprise applications or personal assistant agents&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib35" title="" class="ltx_ref">2023b</a>)</cite>, which often involve different instruction distributions. This desideratum for task-specific alignment brings us to a core question for data synthesis: <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">how can we tailor synthetic data to align LLMs for different instruction-following tasks?</em></p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Specifically, current data synthesis approaches fall short of providing effective solutions for task-specific LLM alignment. While prior works by
<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite> emphasize diversity and complexity as hallmarks of high-quality data, these approaches stumble when facing different downstream tasks that may involve specific instruction distributions. A diverse dataset for one task might not effectively cover the instruction distribution for another. Furthermore, the definition of â€œcomplexâ€ instructions can be subjective and vary across tasks. To complicate matters further, an LLM might excel at some seemingly complex instructions while struggling with others that appear simple according to human-crafted criteria. These limitations underscore the need for a unified data synthesis framework that can generate tailored data to align LLMs on specific downstream tasks.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this work, we present a novel framework, <span id="S1.p4.1.1" class="ltx_text ltx_font_bold">CodecLM</span>, which systematically generates tailored high-quality data to align LLMs for different downstream tasks. A high-level overview of CodecLM is shown in Figure&nbsp;<a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Inspired by the principles of Encode-Decode process&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kramer, <a href="#bib.bib25" title="" class="ltx_ref">1991</a>; Kingma and Welling, <a href="#bib.bib23" title="" class="ltx_ref">2013</a>)</cite>, we leverage a strong LLM as a codec to â€œencodeâ€ seed instructions from our target task into instruction <em id="S1.p4.1.2" class="ltx_emph ltx_font_italic">metadata</em> and then â€œdecodeâ€ the metadata into tailored synthetic instructions.
The metadata serves as a word-level abstraction of the input instruction distribution, including the <em id="S1.p4.1.3" class="ltx_emph ltx_font_italic">use case</em> and <em id="S1.p4.1.4" class="ltx_emph ltx_font_italic">skills</em> for effective instruction following. It can be automatically generated by encoding seed instructions, or directly provided by users with a high-level anticipation of the downstream task.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Once the metadata is extracted, we then â€œdecodeâ€ them to generate tailored instructions. We begin by prompting a LLM with the metadata as constraints, creating basic instructions. To elevate the instruction quality, we introduce <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">Self-Rubrics</em>. It samples appropriate actions from strong LLMs to make the basic instruction more complex or challenging based on the rubrics it generates for different metadata.
Intuitively, a general knowledge QA instruction about math would differ in complexity rubrics from one in creative writing about sports. With self-generated rubrics and actions based on metadata, the strong LLM crafts instructions that better align the target LLM with specific knowledge required for the downstream task. We can run Self-Rubrics iteratively to control the instruction complexity, similar to &nbsp;<cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>, and finally generate the corresponding responses.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">We also introduce <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">Contrastive Filtering</em> during decoding to further identify the most effective instruction-response pairs by leveraging the quality discrepancy between the target and a stronger LLM. This strategy identifies two key instruction sets: (a) those the target LLM struggles with, pushing it to improve in its weak areas for more significant gains, and (b) those the target LLM excels at, feeding them back into the Self-Rubrics process for improved data efficiency.
Contrastive Filtering serves as a response-level analogy of contrastive decoding&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a href="#bib.bib28" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">CodecLM sets a new state-of-the-art on four open-domain instruction-following benchmarks with various LLM choices, demonstrating its effectiveness in LLM alignment for diverse instruction distributions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Instruction Tuning for LLM Alignment.</span> Tuning LLM to faithfully follow instructions and align with diverse human preferences remains a significant challenge&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Efrat and Levy, <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>. Early research primarily focused on cross-task generalization, where models were fine-tuned on various public NLP datasets to improve performance on diverse tasks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al., <a href="#bib.bib38" title="" class="ltx_ref">2020</a>; Wei et&nbsp;al., <a href="#bib.bib48" title="" class="ltx_ref">2021</a>; Aribandi et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2021</a>; Victor et&nbsp;al., <a href="#bib.bib45" title="" class="ltx_ref">2022</a>; Chung et&nbsp;al., <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>.
More recently, researchers have extended instruction tuning to open-domains, characterized by a wider range of formats and task types. This shift has been driven by crowdsourcing human-generated instruction-response pairs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ouyang et&nbsp;al., <a href="#bib.bib36" title="" class="ltx_ref">2022</a>; KÃ¶pf et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2023</a>; Zhou et&nbsp;al., <a href="#bib.bib55" title="" class="ltx_ref">2023a</a>)</cite> and LLM-generated data&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>; Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite>.
Unlike prior work, CodecLM presents a unique approach for tailoring synthetic data to specific downstream tasks without human annotation, utilizing the concept of instruction metadata.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Data Generation for Instruction Tuning.</span> To address the high cost of human annotation for high-quality instruction-response pairs, several studies advocate for automating the data generation process&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Schick and SchÃ¼tze, <a href="#bib.bib39" title="" class="ltx_ref">2021</a>; Liu et&nbsp;al., <a href="#bib.bib30" title="" class="ltx_ref">2022</a>; Meng et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2023</a>)</cite>. Leveraging the in-context learning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Brown et&nbsp;al., <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> ability of LLMs, &nbsp;<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib47" title="" class="ltx_ref">2022</a>); Honovich et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite> prompt LLMs with seed instructions to generate synthetic ones. These are then fed to stronger LLMs, <span id="S2.p2.1.2" class="ltx_text ltx_font_italic">e.g.</span>, ChatGPT, to generate responses for training the target (often smaller) LLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>)</cite>. As a representative work, WizardLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>, designs a fixed set of human-crafted operations to increase complexity of instructions and control difficulty of generated data. <cite class="ltx_cite ltx_citemacro_citet">Zhao et&nbsp;al. (<a href="#bib.bib53" title="" class="ltx_ref">2023</a>); Zhou et&nbsp;al. (<a href="#bib.bib55" title="" class="ltx_ref">2023a</a>)</cite> further confirm the importance of instruction complexity for LLM alignment through empirical studies. Different from these works that rely on pre-defined rules without considering the downstream tasks, CodecLM enables automatically tailoring instructions for different downstream tasks and target LLMs. We also introduce Self-Rubrics and Contrastive Filtering to further identify the most effective instruction-response pairs.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Distillation.</span> Alternatively, tuning the target LLM with responses generated from another LLM can be viewed as knowledge distillation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hinton et&nbsp;al., <a href="#bib.bib19" title="" class="ltx_ref">2015</a>; Beyer et&nbsp;al., <a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite>. However, our focus remains on instruction generation, while still being flexible to readily integrate with existing distillation techniques&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hsieh et&nbsp;al., <a href="#bib.bib21" title="" class="ltx_ref">2023</a>; Liang et&nbsp;al., <a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Finally, we discuss some of the most relevant recent work. AttrPrompt&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al., <a href="#bib.bib52" title="" class="ltx_ref">2023</a>)</cite> leverages LLM as attributed data generator by extracting attributes within instructions. However, it focuses solely on classification tasks and requires human intervention for attribute selection. In contrast, our work focuses on the broader context of aligning LLMs to follow open-domain instructions, eliminating the need for human efforts. MSP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib7" title="" class="ltx_ref">2023a</a>)</cite> utilizes trainable soft prompts to control generation, but requires gradient access to the LLM. Our method, on the other hand, is readily compatible with black-box LLMs that only offer API access for high-quality data generation. SteerLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dong et&nbsp;al., <a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite> analyzes quality-related aspects of responses, instead of the instructions, to capture human preference. Therefore, SteerLM can be used alongside CodecLM as a parallel approach for enhancing response quality.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2404.05875/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of the proposed CodecLM. First, the strong LLM <math id="S2.F2.7.m1.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S2.F2.7.m1.1b"><msub id="S2.F2.7.m1.1.1" xref="S2.F2.7.m1.1.1.cmml"><mi id="S2.F2.7.m1.1.1.2" xref="S2.F2.7.m1.1.1.2.cmml">f</mi><mi id="S2.F2.7.m1.1.1.3" xref="S2.F2.7.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.7.m1.1c"><apply id="S2.F2.7.m1.1.1.cmml" xref="S2.F2.7.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.7.m1.1.1.1.cmml" xref="S2.F2.7.m1.1.1">subscript</csymbol><ci id="S2.F2.7.m1.1.1.2.cmml" xref="S2.F2.7.m1.1.1.2">ğ‘“</ci><ci id="S2.F2.7.m1.1.1.3.cmml" xref="S2.F2.7.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.7.m1.1d">f_{s}</annotation></semantics></math> encodes the seed instruction into instruction metadata, specifying its use case and skills required for responses. Next, <math id="S2.F2.8.m2.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S2.F2.8.m2.1b"><msub id="S2.F2.8.m2.1.1" xref="S2.F2.8.m2.1.1.cmml"><mi id="S2.F2.8.m2.1.1.2" xref="S2.F2.8.m2.1.1.2.cmml">f</mi><mi id="S2.F2.8.m2.1.1.3" xref="S2.F2.8.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.8.m2.1c"><apply id="S2.F2.8.m2.1.1.cmml" xref="S2.F2.8.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.8.m2.1.1.1.cmml" xref="S2.F2.8.m2.1.1">subscript</csymbol><ci id="S2.F2.8.m2.1.1.2.cmml" xref="S2.F2.8.m2.1.1.2">ğ‘“</ci><ci id="S2.F2.8.m2.1.1.3.cmml" xref="S2.F2.8.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.8.m2.1d">f_{s}</annotation></semantics></math> decodes metadata into basic instructions. Meanwhile, Self-Rubrics leverages <math id="S2.F2.9.m3.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S2.F2.9.m3.1b"><msub id="S2.F2.9.m3.1.1" xref="S2.F2.9.m3.1.1.cmml"><mi id="S2.F2.9.m3.1.1.2" xref="S2.F2.9.m3.1.1.2.cmml">f</mi><mi id="S2.F2.9.m3.1.1.3" xref="S2.F2.9.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.9.m3.1c"><apply id="S2.F2.9.m3.1.1.cmml" xref="S2.F2.9.m3.1.1"><csymbol cd="ambiguous" id="S2.F2.9.m3.1.1.1.cmml" xref="S2.F2.9.m3.1.1">subscript</csymbol><ci id="S2.F2.9.m3.1.1.2.cmml" xref="S2.F2.9.m3.1.1.2">ğ‘“</ci><ci id="S2.F2.9.m3.1.1.3.cmml" xref="S2.F2.9.m3.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.9.m3.1d">f_{s}</annotation></semantics></math> to generate rubrics and actions to improve the basic instruction, tailoring them for the downstream task. Finally, Contrastive Filtering uses a scoring function <math id="S2.F2.10.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.F2.10.m4.1b"><mi id="S2.F2.10.m4.1.1" xref="S2.F2.10.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.F2.10.m4.1c"><ci id="S2.F2.10.m4.1.1.cmml" xref="S2.F2.10.m4.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.10.m4.1d">S</annotation></semantics></math> to compares <math id="S2.F2.11.m5.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S2.F2.11.m5.1b"><msub id="S2.F2.11.m5.1.1" xref="S2.F2.11.m5.1.1.cmml"><mi id="S2.F2.11.m5.1.1.2" xref="S2.F2.11.m5.1.1.2.cmml">f</mi><mi id="S2.F2.11.m5.1.1.3" xref="S2.F2.11.m5.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.11.m5.1c"><apply id="S2.F2.11.m5.1.1.cmml" xref="S2.F2.11.m5.1.1"><csymbol cd="ambiguous" id="S2.F2.11.m5.1.1.1.cmml" xref="S2.F2.11.m5.1.1">subscript</csymbol><ci id="S2.F2.11.m5.1.1.2.cmml" xref="S2.F2.11.m5.1.1.2">ğ‘“</ci><ci id="S2.F2.11.m5.1.1.3.cmml" xref="S2.F2.11.m5.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.11.m5.1d">f_{s}</annotation></semantics></math> and <math id="S2.F2.12.m6.1" class="ltx_Math" alttext="f_{t}" display="inline"><semantics id="S2.F2.12.m6.1b"><msub id="S2.F2.12.m6.1.1" xref="S2.F2.12.m6.1.1.cmml"><mi id="S2.F2.12.m6.1.1.2" xref="S2.F2.12.m6.1.1.2.cmml">f</mi><mi id="S2.F2.12.m6.1.1.3" xref="S2.F2.12.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.12.m6.1c"><apply id="S2.F2.12.m6.1.1.cmml" xref="S2.F2.12.m6.1.1"><csymbol cd="ambiguous" id="S2.F2.12.m6.1.1.1.cmml" xref="S2.F2.12.m6.1.1">subscript</csymbol><ci id="S2.F2.12.m6.1.1.2.cmml" xref="S2.F2.12.m6.1.1.2">ğ‘“</ci><ci id="S2.F2.12.m6.1.1.3.cmml" xref="S2.F2.12.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.12.m6.1d">f_{t}</annotation></semantics></math>â€™s responses. The most effective pairs are selected for aligning the LLM, while less effective instructions are sent for further improvement. In this figure, the strong LLMâ€™s response is winning against the target oneâ€™s, so we select the corresponding pair for instruction tuning the target LLM.</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Problem Statement</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.4" class="ltx_p">We study the open-domain instruction following problem&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2022</a>; Taori et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>; Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>, where instructions vary in input format and tasks. Specifically, we consider two practical scenarios: (1) Starting with a given set of <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">n</annotation></semantics></math> seed instructions <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}" display="inline"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><msub id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.2.m2.1.1.3.2" xref="S3.p1.2.m2.1.1.3.2.cmml">ğ’Ÿ</mi><mi id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml">s</mi></msub><mo id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">=</mo><msubsup id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml"><mrow id="S3.p1.2.m2.1.1.1.1.1.1" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p1.2.m2.1.1.1.1.1.1.2" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml">{</mo><msub id="S3.p1.2.m2.1.1.1.1.1.1.1" xref="S3.p1.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S3.p1.2.m2.1.1.1.1.1.1.1.2" xref="S3.p1.2.m2.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S3.p1.2.m2.1.1.1.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.p1.2.m2.1.1.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p1.2.m2.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.3.cmml"><mi id="S3.p1.2.m2.1.1.1.1.3.2" xref="S3.p1.2.m2.1.1.1.1.3.2.cmml">i</mi><mo id="S3.p1.2.m2.1.1.1.1.3.1" xref="S3.p1.2.m2.1.1.1.1.3.1.cmml">=</mo><mn id="S3.p1.2.m2.1.1.1.1.3.3" xref="S3.p1.2.m2.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p1.2.m2.1.1.1.3" xref="S3.p1.2.m2.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><eq id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2"></eq><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.p1.2.m2.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.3.2">ğ’Ÿ</ci><ci id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3">ğ‘ </ci></apply><apply id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1">superscript</csymbol><apply id="S3.p1.2.m2.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1">subscript</csymbol><set id="S3.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1"><apply id="S3.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1.2">ğ¼</ci><ci id="S3.p1.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></set><apply id="S3.p1.2.m2.1.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.1.3"><eq id="S3.p1.2.m2.1.1.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.1.1.3.1"></eq><ci id="S3.p1.2.m2.1.1.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S3.p1.2.m2.1.1.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p1.2.m2.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}</annotation></semantics></math>, each drawn from some underlying distribution <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="P_{I}" display="inline"><semantics id="S3.p1.3.m3.1a"><msub id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">P</mi><mi id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">ğ‘ƒ</ci><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">P_{I}</annotation></semantics></math>. For our experiments, we create a set of seed instructions using a held-out validation set. Practically, such instructions can be collected from the usage traffic of users. (2) In the absence of seed instructions, but with prior knowledge of downstream tasks, we directly start with a given set of instruction metadata <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">\mathcal{M}</annotation></semantics></math> (see Section&nbsp;<a href="#S4.SS1" title="4.1 LLM as Codec for Instructions â€£ 4 CodecLM â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> for definition). The latter scenario is especially useful for end users who lack existing instruction data but wish to jumpstart LLM tailored to specific applications, similar to the concept of GPTs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib35" title="" class="ltx_ref">2023b</a>)</cite>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.6" class="ltx_p">We focus on the first scenario for clarity, though the second can be derived similarly by leveraging an LLM as the encoder (Section&nbsp;<a href="#S4.SS1" title="4.1 LLM as Codec for Instructions â€£ 4 CodecLM â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>). Our goal is to generate a set of high-quality instruction-response pairs <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{g}=\{(I^{{}^{\prime}}_{j},R^{{}^{\prime}}_{j})\}_{j=1}^{m}" display="inline"><semantics id="S3.p2.1.m1.1a"><mrow id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><msub id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.1.m1.1.1.3.2" xref="S3.p2.1.m1.1.1.3.2.cmml">ğ’Ÿ</mi><mi id="S3.p2.1.m1.1.1.3.3" xref="S3.p2.1.m1.1.1.3.3.cmml">g</mi></msub><mo id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">=</mo><msubsup id="S3.p2.1.m1.1.1.1" xref="S3.p2.1.m1.1.1.1.cmml"><mrow id="S3.p2.1.m1.1.1.1.1.1.1" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p2.1.m1.1.1.1.1.1.1.2" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml">{</mo><mrow id="S3.p2.1.m1.1.1.1.1.1.1.1.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml">(</mo><msubsup id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">I</mi><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi><msup id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3a" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"></mi><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">â€²</mo></msup></msubsup><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.2.4" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml">,</mo><msubsup id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml">R</mi><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3.cmml">j</mi><msup id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3a" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml"></mi><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1.cmml">â€²</mo></msup></msubsup><mo stretchy="false" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.5" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S3.p2.1.m1.1.1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p2.1.m1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.3.cmml"><mi id="S3.p2.1.m1.1.1.1.1.3.2" xref="S3.p2.1.m1.1.1.1.1.3.2.cmml">j</mi><mo id="S3.p2.1.m1.1.1.1.1.3.1" xref="S3.p2.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S3.p2.1.m1.1.1.1.1.3.3" xref="S3.p2.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p2.1.m1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.3.cmml">m</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><eq id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2"></eq><apply id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.3.1.cmml" xref="S3.p2.1.m1.1.1.3">subscript</csymbol><ci id="S3.p2.1.m1.1.1.3.2.cmml" xref="S3.p2.1.m1.1.1.3.2">ğ’Ÿ</ci><ci id="S3.p2.1.m1.1.1.3.3.cmml" xref="S3.p2.1.m1.1.1.3.3">ğ‘”</ci></apply><apply id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1">superscript</csymbol><apply id="S3.p2.1.m1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1">subscript</csymbol><set id="S3.p2.1.m1.1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1"><interval closure="open" id="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2"><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2">ğ¼</ci><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3"><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1">â€²</ci></apply></apply><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2">subscript</csymbol><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2">ğ‘…</ci><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3"><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1">â€²</ci></apply></apply><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3">ğ‘—</ci></apply></interval></set><apply id="S3.p2.1.m1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.3"><eq id="S3.p2.1.m1.1.1.1.1.3.1.cmml" xref="S3.p2.1.m1.1.1.1.1.3.1"></eq><ci id="S3.p2.1.m1.1.1.1.1.3.2.cmml" xref="S3.p2.1.m1.1.1.1.1.3.2">ğ‘—</ci><cn type="integer" id="S3.p2.1.m1.1.1.1.1.3.3.cmml" xref="S3.p2.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p2.1.m1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.3">ğ‘š</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\mathcal{D}_{g}=\{(I^{{}^{\prime}}_{j},R^{{}^{\prime}}_{j})\}_{j=1}^{m}</annotation></semantics></math>, using a strong LLM <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">f</mi><mi id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">ğ‘“</ci><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">f_{s}</annotation></semantics></math>, and then use <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{g}" display="inline"><semantics id="S3.p2.3.m3.1a"><msub id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.3.m3.1.1.2" xref="S3.p2.3.m3.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.p2.3.m3.1.1.3" xref="S3.p2.3.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><apply id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p2.3.m3.1.1.1.cmml" xref="S3.p2.3.m3.1.1">subscript</csymbol><ci id="S3.p2.3.m3.1.1.2.cmml" xref="S3.p2.3.m3.1.1.2">ğ’Ÿ</ci><ci id="S3.p2.3.m3.1.1.3.cmml" xref="S3.p2.3.m3.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">\mathcal{D}_{g}</annotation></semantics></math> to fine-tune the target LLM <math id="S3.p2.4.m4.1" class="ltx_Math" alttext="f_{t}" display="inline"><semantics id="S3.p2.4.m4.1a"><msub id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml"><mi id="S3.p2.4.m4.1.1.2" xref="S3.p2.4.m4.1.1.2.cmml">f</mi><mi id="S3.p2.4.m4.1.1.3" xref="S3.p2.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p2.4.m4.1.1.1.cmml" xref="S3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.p2.4.m4.1.1.2.cmml" xref="S3.p2.4.m4.1.1.2">ğ‘“</ci><ci id="S3.p2.4.m4.1.1.3.cmml" xref="S3.p2.4.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">f_{t}</annotation></semantics></math>. We evaluate the performance of the fine-tuned LLM <math id="S3.p2.5.m5.1" class="ltx_Math" alttext="f_{t}" display="inline"><semantics id="S3.p2.5.m5.1a"><msub id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml"><mi id="S3.p2.5.m5.1.1.2" xref="S3.p2.5.m5.1.1.2.cmml">f</mi><mi id="S3.p2.5.m5.1.1.3" xref="S3.p2.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><apply id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.1.cmml" xref="S3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.p2.5.m5.1.1.2.cmml" xref="S3.p2.5.m5.1.1.2">ğ‘“</ci><ci id="S3.p2.5.m5.1.1.3.cmml" xref="S3.p2.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">f_{t}</annotation></semantics></math> on test instructions from the target distribution <math id="S3.p2.6.m6.1" class="ltx_Math" alttext="P_{I}" display="inline"><semantics id="S3.p2.6.m6.1a"><msub id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml"><mi id="S3.p2.6.m6.1.1.2" xref="S3.p2.6.m6.1.1.2.cmml">P</mi><mi id="S3.p2.6.m6.1.1.3" xref="S3.p2.6.m6.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1b"><apply id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p2.6.m6.1.1.1.cmml" xref="S3.p2.6.m6.1.1">subscript</csymbol><ci id="S3.p2.6.m6.1.1.2.cmml" xref="S3.p2.6.m6.1.1.2">ğ‘ƒ</ci><ci id="S3.p2.6.m6.1.1.3.cmml" xref="S3.p2.6.m6.1.1.3">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1c">P_{I}</annotation></semantics></math>, to which we are aligning.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>CodecLM</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We propose CodecLM, a general framework for generating high-quality instruction-response pairs tailored to different downstream tasks and LLMs, eliminating the need for human annotation. See Figure&nbsp;<a href="#S2.F2" title="Figure 2 â€£ 2 Related Work â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> for method overview.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>LLM as Codec for Instructions</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In this section, we introduce the concept of using a strong LLM as a codec, <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, both encoder and decoder, for instruction generation.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.3" class="ltx_p"><span id="S4.SS1.p2.3.1" class="ltx_text ltx_font_bold">LLM as Encoder with Instruction Metadata.</span>
We begin by encoding the given seed instructions <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><msub id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.1.m1.1.1.3.2" xref="S4.SS1.p2.1.m1.1.1.3.2.cmml">ğ’Ÿ</mi><mi id="S4.SS1.p2.1.m1.1.1.3.3" xref="S4.SS1.p2.1.m1.1.1.3.3.cmml">s</mi></msub><mo id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">=</mo><msubsup id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml"><mrow id="S4.SS1.p2.1.m1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS1.p2.1.m1.1.1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S4.SS1.p2.1.m1.1.1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS1.p2.1.m1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.3.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.3.2" xref="S4.SS1.p2.1.m1.1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS1.p2.1.m1.1.1.1.1.3.1" xref="S4.SS1.p2.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS1.p2.1.m1.1.1.1.1.3.3" xref="S4.SS1.p2.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS1.p2.1.m1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><eq id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2"></eq><apply id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2">ğ’Ÿ</ci><ci id="S4.SS1.p2.1.m1.1.1.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3">ğ‘ </ci></apply><apply id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1">superscript</csymbol><apply id="S4.SS1.p2.1.m1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1">subscript</csymbol><set id="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1"><apply id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2">ğ¼</ci><ci id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></set><apply id="S4.SS1.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3"><eq id="S4.SS1.p2.1.m1.1.1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3.1"></eq><ci id="S4.SS1.p2.1.m1.1.1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S4.SS1.p2.1.m1.1.1.1.1.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS1.p2.1.m1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}</annotation></semantics></math> into instruction <em id="S4.SS1.p2.3.2" class="ltx_emph ltx_font_italic">metadata</em> <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\mathcal{M}</annotation></semantics></math>, <span id="S4.SS1.p2.3.3" class="ltx_text ltx_font_italic">i.e.</span>, keywords that capture the underlying target instruction distribution. Inspired by the task pool by&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> and the post-hoc analysis on skill distribution by&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>, we define the metadata as encompassing two key aspects: <em id="S4.SS1.p2.3.4" class="ltx_emph ltx_font_italic">use case</em> and <em id="S4.SS1.p2.3.5" class="ltx_emph ltx_font_italic">skills</em>. Use case describes the intended task (<span id="S4.SS1.p2.3.6" class="ltx_text ltx_font_italic">e.g.</span>, question answering or creative writing), while Skills are the knowledge the LLM required to have to successfully respond to the given instruction (<span id="S4.SS1.p2.3.7" class="ltx_text ltx_font_italic">e.g.</span>, algorithms or communication). Skills are often generalizable to different use cases. Therefore, each instruction has a single use case and may involve multiple skills.
To extract this metadata, we leverage the strong LLM <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><msub id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">f</mi><mi id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">ğ‘“</ci><ci id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">f_{s}</annotation></semantics></math> following the prompt template in Figure&nbsp;<a href="#A1.F7" title="Figure 7 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, Appendix&nbsp;<a href="#A1.SS9" title="A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.9</span></a>. While richer definitions are possible based on finer-grained instruction-following metrics&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a href="#bib.bib56" title="" class="ltx_ref">2023b</a>)</cite>, we prioritize use case and skills for their broad applicability across diverse instruction distributions. Future work can explore extending this metadata further.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.6" class="ltx_p">For each instruction <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="I_{i}" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><msub id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mi id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">I</mi><mi id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">ğ¼</ci><ci id="S4.SS1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">I_{i}</annotation></semantics></math>, we extract the corresponding use case <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="u_{i}" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><msub id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mi id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">u</mi><mi id="S4.SS1.p3.2.m2.1.1.3" xref="S4.SS1.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">ğ‘¢</ci><ci id="S4.SS1.p3.2.m2.1.1.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">u_{i}</annotation></semantics></math> and set of skills <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="{\bm{s}}_{i}" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><msub id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">ğ’”</mi><mi id="S4.SS1.p3.3.m3.1.1.3" xref="S4.SS1.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">ğ’”</ci><ci id="S4.SS1.p3.3.m3.1.1.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">{\bm{s}}_{i}</annotation></semantics></math>. We then have the set of metadata as <math id="S4.SS1.p3.4.m4.1" class="ltx_Math" alttext="\mathcal{M}=\{(u_{i},{\bm{s}}_{i})\}_{i=1}^{n}" display="inline"><semantics id="S4.SS1.p3.4.m4.1a"><mrow id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p3.4.m4.1.1.3" xref="S4.SS1.p3.4.m4.1.1.3.cmml">â„³</mi><mo id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml">=</mo><msubsup id="S4.SS1.p3.4.m4.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.cmml"><mrow id="S4.SS1.p3.4.m4.1.1.1.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml">{</mo><mrow id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.3" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2.cmml">u</mi><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.4" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml">,</mo><msub id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2.cmml">ğ’”</mi><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.5" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS1.p3.4.m4.1.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.1.3.cmml"><mi id="S4.SS1.p3.4.m4.1.1.1.1.3.2" xref="S4.SS1.p3.4.m4.1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS1.p3.4.m4.1.1.1.1.3.1" xref="S4.SS1.p3.4.m4.1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS1.p3.4.m4.1.1.1.1.3.3" xref="S4.SS1.p3.4.m4.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS1.p3.4.m4.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><eq id="S4.SS1.p3.4.m4.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2"></eq><ci id="S4.SS1.p3.4.m4.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.3">â„³</ci><apply id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1">superscript</csymbol><apply id="S4.SS1.p3.4.m4.1.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1">subscript</csymbol><set id="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1"><interval closure="open" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2"><apply id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2">ğ‘¢</ci><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2">ğ’”</ci><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3">ğ‘–</ci></apply></interval></set><apply id="S4.SS1.p3.4.m4.1.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3"><eq id="S4.SS1.p3.4.m4.1.1.1.1.3.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3.1"></eq><ci id="S4.SS1.p3.4.m4.1.1.1.1.3.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S4.SS1.p3.4.m4.1.1.1.1.3.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS1.p3.4.m4.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">\mathcal{M}=\{(u_{i},{\bm{s}}_{i})\}_{i=1}^{n}</annotation></semantics></math>. Instructions may share or partially overlap in their <math id="S4.SS1.p3.5.m5.1" class="ltx_Math" alttext="u_{i}" display="inline"><semantics id="S4.SS1.p3.5.m5.1a"><msub id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml"><mi id="S4.SS1.p3.5.m5.1.1.2" xref="S4.SS1.p3.5.m5.1.1.2.cmml">u</mi><mi id="S4.SS1.p3.5.m5.1.1.3" xref="S4.SS1.p3.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><apply id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.5.m5.1.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.p3.5.m5.1.1.2.cmml" xref="S4.SS1.p3.5.m5.1.1.2">ğ‘¢</ci><ci id="S4.SS1.p3.5.m5.1.1.3.cmml" xref="S4.SS1.p3.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">u_{i}</annotation></semantics></math>â€™s and <math id="S4.SS1.p3.6.m6.1" class="ltx_Math" alttext="{\bm{s}}_{i}" display="inline"><semantics id="S4.SS1.p3.6.m6.1a"><msub id="S4.SS1.p3.6.m6.1.1" xref="S4.SS1.p3.6.m6.1.1.cmml"><mi id="S4.SS1.p3.6.m6.1.1.2" xref="S4.SS1.p3.6.m6.1.1.2.cmml">ğ’”</mi><mi id="S4.SS1.p3.6.m6.1.1.3" xref="S4.SS1.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m6.1b"><apply id="S4.SS1.p3.6.m6.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.6.m6.1.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p3.6.m6.1.1.2.cmml" xref="S4.SS1.p3.6.m6.1.1.2">ğ’”</ci><ci id="S4.SS1.p3.6.m6.1.1.3.cmml" xref="S4.SS1.p3.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m6.1c">{\bm{s}}_{i}</annotation></semantics></math>, reflecting the distribution of tasks and capabilities within the seed instructions.
Use cases and skills are generated on-the-fly, not limited to some predefined sets, enabling broader applicability. However, we can always provide such constraints with our prior knowledge, or even directly write out metadata without any seed instructions.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.3" class="ltx_p"><span id="S4.SS1.p4.3.1" class="ltx_text ltx_font_bold">LLM as Decoder for Instruction Generation.</span> Given the metadata <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">\mathcal{M}</annotation></semantics></math>, we decode metadata into synthetic instructions, following a generation and tailoring paradigm. For each use case and skills pair in <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><ci id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">\mathcal{M}</annotation></semantics></math>, we list them as constraints to prompt the strong LLM <math id="S4.SS1.p4.3.m3.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S4.SS1.p4.3.m3.1a"><msub id="S4.SS1.p4.3.m3.1.1" xref="S4.SS1.p4.3.m3.1.1.cmml"><mi id="S4.SS1.p4.3.m3.1.1.2" xref="S4.SS1.p4.3.m3.1.1.2.cmml">f</mi><mi id="S4.SS1.p4.3.m3.1.1.3" xref="S4.SS1.p4.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><apply id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.3.m3.1.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p4.3.m3.1.1.2.cmml" xref="S4.SS1.p4.3.m3.1.1.2">ğ‘“</ci><ci id="S4.SS1.p4.3.m3.1.1.3.cmml" xref="S4.SS1.p4.3.m3.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">f_{s}</annotation></semantics></math> to generate multiple instructions. Therefore, the generated instructions are for the given use case, and require the given skills to be responded.
Moreover, to prevent the LLM from generating repetitive instructions, we encourage its generation to be diverse in the prompt, and do not provide any demonstrations that the LLM might copy from. The example prompt template for generating basic instructions is in Figure&nbsp;<a href="#A1.F8" title="Figure 8 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, Appendix&nbsp;<a href="#A1.SS9" title="A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.9</span></a>. Continuing the decoding process, we then tailor the basic instructions for more effective alignment through Self-Rubrics (Section&nbsp;<a href="#S4.SS2" title="4.2 Instruction Tailoring via Self-Rubrics â€£ 4 CodecLM â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>) and Contrastive Filtering (Section&nbsp;<a href="#S4.SS3" title="4.3 Instruction Selection via Contrastive Filtering â€£ 4 CodecLM â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Instruction Tailoring via Self-Rubrics</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Metadata-conditioned instructions lay the groundwork for aligning the target LLM to desired tasks. Studies suggest that more complex instructions can improve alignment performance&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>; Zhao et&nbsp;al., <a href="#bib.bib53" title="" class="ltx_ref">2023</a>)</cite>. A common practice is to involve human experts crafting general guidance to complicate instructions, such as adding reasoning steps or constraints. However, this one-size-fits-all strategy falls short for diverse instructions. Tailoring guidance to different tasks, like solving calculus problems versus writing news articles, requires distinct approaches.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.2" class="ltx_p">Therefore, we introduce Self-Rubrics, which leverages the strong LLM to tailor instructions by adjusting their complexity according to the extracted metadata.
Self-Rubrics first guides the LLM to generate metadata-specific rubrics for assessing instruction complexity. Then, informed by these rubrics, the LLM generates a corresponding set of actions to enhance the instructionâ€™s complexity.
For metadata <math id="S4.SS2.p2.1.m1.2" class="ltx_Math" alttext="(u_{i},{\bm{s}}_{i})" display="inline"><semantics id="S4.SS2.p2.1.m1.2a"><mrow id="S4.SS2.p2.1.m1.2.2.2" xref="S4.SS2.p2.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.SS2.p2.1.m1.2.2.2.3" xref="S4.SS2.p2.1.m1.2.2.3.cmml">(</mo><msub id="S4.SS2.p2.1.m1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.1.1.2.cmml">u</mi><mi id="S4.SS2.p2.1.m1.1.1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS2.p2.1.m1.2.2.2.4" xref="S4.SS2.p2.1.m1.2.2.3.cmml">,</mo><msub id="S4.SS2.p2.1.m1.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.cmml"><mi id="S4.SS2.p2.1.m1.2.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.2.cmml">ğ’”</mi><mi id="S4.SS2.p2.1.m1.2.2.2.2.3" xref="S4.SS2.p2.1.m1.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.SS2.p2.1.m1.2.2.2.5" xref="S4.SS2.p2.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.2b"><interval closure="open" id="S4.SS2.p2.1.m1.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2"><apply id="S4.SS2.p2.1.m1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2">ğ‘¢</ci><ci id="S4.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S4.SS2.p2.1.m1.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.2.2.2.2.1.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2">ğ’”</ci><ci id="S4.SS2.p2.1.m1.2.2.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.3">ğ‘–</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.2c">(u_{i},{\bm{s}}_{i})</annotation></semantics></math>, the corresponding set of generated actions is <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="{\bm{a}}_{i}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><msub id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">ğ’‚</mi><mi id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">ğ’‚</ci><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">{\bm{a}}_{i}</annotation></semantics></math>. Our generated actions are more domain-specific, and unambiguous than generic rules crafted by human, making the complicated instructions better tailored towards the target distribution captured by the metadata. For example, for the use case of â€œbusiness plan developmentâ€ and skills of â€œmarket research and planningâ€, generic rules like â€œadd reasoning stepsâ€ is vague and inappropriate. On the contrary, Self-Rubrics is able to generate actions like â€œadd SWOT analyisisâ€ and â€œinclude comparison with market competitorsâ€ (see Appendix&nbsp;<a href="#A1.SS8" title="A.8 Case Study â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.8</span></a> for the full details) to complicate the instruction.
The prompt template to generate rubrics and actions for instruction improvement is shown in Figure&nbsp;<a href="#A1.F9" title="Figure 9 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, Appendix&nbsp;<a href="#A1.SS9" title="A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.9</span></a>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.3" class="ltx_p">With the obtained actions <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="\{{\bm{a}}_{i}\}_{i=1}^{n}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><msubsup id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mrow id="S4.SS2.p3.1.m1.1.1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS2.p3.1.m1.1.1.1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.1.1.2.cmml">{</mo><msub id="S4.SS2.p3.1.m1.1.1.1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1.1.1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.2.cmml">ğ’‚</mi><mi id="S4.SS2.p3.1.m1.1.1.1.1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S4.SS2.p3.1.m1.1.1.1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS2.p3.1.m1.1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.1.3.cmml"><mi id="S4.SS2.p3.1.m1.1.1.1.3.2" xref="S4.SS2.p3.1.m1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS2.p3.1.m1.1.1.1.3.1" xref="S4.SS2.p3.1.m1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS2.p3.1.m1.1.1.1.3.3" xref="S4.SS2.p3.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1">superscript</csymbol><apply id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1">subscript</csymbol><set id="S4.SS2.p3.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1"><apply id="S4.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.2">ğ’‚</ci><ci id="S4.SS2.p3.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.3">ğ‘–</ci></apply></set><apply id="S4.SS2.p3.1.m1.1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3"><eq id="S4.SS2.p3.1.m1.1.1.1.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3.1"></eq><ci id="S4.SS2.p3.1.m1.1.1.1.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S4.SS2.p3.1.m1.1.1.1.3.3.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\{{\bm{a}}_{i}\}_{i=1}^{n}</annotation></semantics></math>, we can iteratively prompt <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><msub id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">f</mi><mi id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">ğ‘“</ci><ci id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">f_{s}</annotation></semantics></math> to complicate the basic instructions, following the prompt template in Figure&nbsp;<a href="#A1.F10" title="Figure 10 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. We randomly sample an action <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="{\bm{a}}_{i}" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><msub id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml"><mi id="S4.SS2.p3.3.m3.1.1.2" xref="S4.SS2.p3.3.m3.1.1.2.cmml">ğ’‚</mi><mi id="S4.SS2.p3.3.m3.1.1.3" xref="S4.SS2.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><apply id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.1.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p3.3.m3.1.1.2.cmml" xref="S4.SS2.p3.3.m3.1.1.2">ğ’‚</ci><ci id="S4.SS2.p3.3.m3.1.1.3.cmml" xref="S4.SS2.p3.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">{\bm{a}}_{i}</annotation></semantics></math> from the multiple actions generated for a pair of use case and skills. This design choice not only enables controlled complexity&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>, but also prevents potential confusion between different actions for the LLM.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Instruction Selection via Contrastive Filtering</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">While Self-Rubrics tailors complex instructions based on instruction metadata, not all instructions are equally effective for instruction tuning, regardless of their complexity&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023b</a>; Zhou et&nbsp;al., <a href="#bib.bib55" title="" class="ltx_ref">2023a</a>)</cite>. Intuitively, exposing the target LLM to instructions it finds challenging can effectively identify its areas for improvement. Therefore, it is crucial to select the most impactful instructions for aligning the target LLM.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.13" class="ltx_p">We therefore introduce Contrastive Filtering, a method to select the instructions that can effectively enhance the target LLM <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="f_{t}" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><msub id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">f</mi><mi id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">ğ‘“</ci><ci id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">f_{t}</annotation></semantics></math>. For clarity, we define the space of all natural language sequences as <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">ğ’©</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">ğ’©</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">\mathcal{N}</annotation></semantics></math>. We have the strong LLM <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="f_{s}:\mathcal{N}\to\mathcal{N}" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><msub id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2.2" xref="S4.SS3.p2.3.m3.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.3.m3.1.1.2.3" xref="S4.SS3.p2.3.m3.1.1.2.3.cmml">s</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.3.m3.1.1.3.2" xref="S4.SS3.p2.3.m3.1.1.3.2.cmml">ğ’©</mi><mo stretchy="false" id="S4.SS3.p2.3.m3.1.1.3.1" xref="S4.SS3.p2.3.m3.1.1.3.1.cmml">â†’</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.3.m3.1.1.3.3" xref="S4.SS3.p2.3.m3.1.1.3.3.cmml">ğ’©</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><ci id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1">:</ci><apply id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.2.1.cmml" xref="S4.SS3.p2.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.2.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2.2">ğ‘“</ci><ci id="S4.SS3.p2.3.m3.1.1.2.3.cmml" xref="S4.SS3.p2.3.m3.1.1.2.3">ğ‘ </ci></apply><apply id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3"><ci id="S4.SS3.p2.3.m3.1.1.3.1.cmml" xref="S4.SS3.p2.3.m3.1.1.3.1">â†’</ci><ci id="S4.SS3.p2.3.m3.1.1.3.2.cmml" xref="S4.SS3.p2.3.m3.1.1.3.2">ğ’©</ci><ci id="S4.SS3.p2.3.m3.1.1.3.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3">ğ’©</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">f_{s}:\mathcal{N}\to\mathcal{N}</annotation></semantics></math>, the target LLM <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="f_{t}:\mathcal{N}\to\mathcal{N}" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mrow id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><msub id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2.2" xref="S4.SS3.p2.4.m4.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.4.m4.1.1.2.3" xref="S4.SS3.p2.4.m4.1.1.2.3.cmml">t</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.4.m4.1.1.1" xref="S4.SS3.p2.4.m4.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.4.m4.1.1.3.2" xref="S4.SS3.p2.4.m4.1.1.3.2.cmml">ğ’©</mi><mo stretchy="false" id="S4.SS3.p2.4.m4.1.1.3.1" xref="S4.SS3.p2.4.m4.1.1.3.1.cmml">â†’</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.4.m4.1.1.3.3" xref="S4.SS3.p2.4.m4.1.1.3.3.cmml">ğ’©</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><ci id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1.1">:</ci><apply id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.1.1.2.1.cmml" xref="S4.SS3.p2.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.4.m4.1.1.2.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2.2">ğ‘“</ci><ci id="S4.SS3.p2.4.m4.1.1.2.3.cmml" xref="S4.SS3.p2.4.m4.1.1.2.3">ğ‘¡</ci></apply><apply id="S4.SS3.p2.4.m4.1.1.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3"><ci id="S4.SS3.p2.4.m4.1.1.3.1.cmml" xref="S4.SS3.p2.4.m4.1.1.3.1">â†’</ci><ci id="S4.SS3.p2.4.m4.1.1.3.2.cmml" xref="S4.SS3.p2.4.m4.1.1.3.2">ğ’©</ci><ci id="S4.SS3.p2.4.m4.1.1.3.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3.3">ğ’©</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">f_{t}:\mathcal{N}\to\mathcal{N}</annotation></semantics></math>, and a scoring function <math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="S:\mathcal{N}\to\mathbb{R}" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mrow id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml"><mi id="S4.SS3.p2.5.m5.1.1.2" xref="S4.SS3.p2.5.m5.1.1.2.cmml">S</mi><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.5.m5.1.1.1" xref="S4.SS3.p2.5.m5.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.5.m5.1.1.3" xref="S4.SS3.p2.5.m5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.5.m5.1.1.3.2" xref="S4.SS3.p2.5.m5.1.1.3.2.cmml">ğ’©</mi><mo stretchy="false" id="S4.SS3.p2.5.m5.1.1.3.1" xref="S4.SS3.p2.5.m5.1.1.3.1.cmml">â†’</mo><mi id="S4.SS3.p2.5.m5.1.1.3.3" xref="S4.SS3.p2.5.m5.1.1.3.3.cmml">â„</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"><ci id="S4.SS3.p2.5.m5.1.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1.1">:</ci><ci id="S4.SS3.p2.5.m5.1.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.2">ğ‘†</ci><apply id="S4.SS3.p2.5.m5.1.1.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3"><ci id="S4.SS3.p2.5.m5.1.1.3.1.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1">â†’</ci><ci id="S4.SS3.p2.5.m5.1.1.3.2.cmml" xref="S4.SS3.p2.5.m5.1.1.3.2">ğ’©</ci><ci id="S4.SS3.p2.5.m5.1.1.3.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">S:\mathcal{N}\to\mathbb{R}</annotation></semantics></math> to evaluate response quality.
In practice, <math id="S4.SS3.p2.6.m6.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS3.p2.6.m6.1a"><mi id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><ci id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">S</annotation></semantics></math> is obtained by reusing the strong LLM <math id="S4.SS3.p2.7.m7.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S4.SS3.p2.7.m7.1a"><msub id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml"><mi id="S4.SS3.p2.7.m7.1.1.2" xref="S4.SS3.p2.7.m7.1.1.2.cmml">f</mi><mi id="S4.SS3.p2.7.m7.1.1.3" xref="S4.SS3.p2.7.m7.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><apply id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.7.m7.1.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1">subscript</csymbol><ci id="S4.SS3.p2.7.m7.1.1.2.cmml" xref="S4.SS3.p2.7.m7.1.1.2">ğ‘“</ci><ci id="S4.SS3.p2.7.m7.1.1.3.cmml" xref="S4.SS3.p2.7.m7.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">f_{s}</annotation></semantics></math> with a prompt template (Figure&nbsp;<a href="#A1.F11" title="Figure 11 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, Appendix&nbsp;<a href="#A1.SS9" title="A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.9</span></a>) adapted from the Vicuna pairwise evaluation template&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>; Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite>.
To mitigate potential position bias, we average the scores obtained by exchanging the positions of two responses&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite>.
We observe using <math id="S4.SS3.p2.8.m8.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S4.SS3.p2.8.m8.1a"><msub id="S4.SS3.p2.8.m8.1.1" xref="S4.SS3.p2.8.m8.1.1.cmml"><mi id="S4.SS3.p2.8.m8.1.1.2" xref="S4.SS3.p2.8.m8.1.1.2.cmml">f</mi><mi id="S4.SS3.p2.8.m8.1.1.3" xref="S4.SS3.p2.8.m8.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.8.m8.1b"><apply id="S4.SS3.p2.8.m8.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.8.m8.1.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1">subscript</csymbol><ci id="S4.SS3.p2.8.m8.1.1.2.cmml" xref="S4.SS3.p2.8.m8.1.1.2">ğ‘“</ci><ci id="S4.SS3.p2.8.m8.1.1.3.cmml" xref="S4.SS3.p2.8.m8.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.8.m8.1c">f_{s}</annotation></semantics></math> for scoring works quite well in practice, so we prioritize this option for simplicity.
Given an input instruction <math id="S4.SS3.p2.9.m9.1" class="ltx_Math" alttext="I\in\mathcal{N}" display="inline"><semantics id="S4.SS3.p2.9.m9.1a"><mrow id="S4.SS3.p2.9.m9.1.1" xref="S4.SS3.p2.9.m9.1.1.cmml"><mi id="S4.SS3.p2.9.m9.1.1.2" xref="S4.SS3.p2.9.m9.1.1.2.cmml">I</mi><mo id="S4.SS3.p2.9.m9.1.1.1" xref="S4.SS3.p2.9.m9.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.9.m9.1.1.3" xref="S4.SS3.p2.9.m9.1.1.3.cmml">ğ’©</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.9.m9.1b"><apply id="S4.SS3.p2.9.m9.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1"><in id="S4.SS3.p2.9.m9.1.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1.1"></in><ci id="S4.SS3.p2.9.m9.1.1.2.cmml" xref="S4.SS3.p2.9.m9.1.1.2">ğ¼</ci><ci id="S4.SS3.p2.9.m9.1.1.3.cmml" xref="S4.SS3.p2.9.m9.1.1.3">ğ’©</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.9.m9.1c">I\in\mathcal{N}</annotation></semantics></math>, we obtain responses from both LLMs as <math id="S4.SS3.p2.10.m10.1" class="ltx_Math" alttext="f_{s}(I)" display="inline"><semantics id="S4.SS3.p2.10.m10.1a"><mrow id="S4.SS3.p2.10.m10.1.2" xref="S4.SS3.p2.10.m10.1.2.cmml"><msub id="S4.SS3.p2.10.m10.1.2.2" xref="S4.SS3.p2.10.m10.1.2.2.cmml"><mi id="S4.SS3.p2.10.m10.1.2.2.2" xref="S4.SS3.p2.10.m10.1.2.2.2.cmml">f</mi><mi id="S4.SS3.p2.10.m10.1.2.2.3" xref="S4.SS3.p2.10.m10.1.2.2.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p2.10.m10.1.2.1" xref="S4.SS3.p2.10.m10.1.2.1.cmml">â€‹</mo><mrow id="S4.SS3.p2.10.m10.1.2.3.2" xref="S4.SS3.p2.10.m10.1.2.cmml"><mo stretchy="false" id="S4.SS3.p2.10.m10.1.2.3.2.1" xref="S4.SS3.p2.10.m10.1.2.cmml">(</mo><mi id="S4.SS3.p2.10.m10.1.1" xref="S4.SS3.p2.10.m10.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.10.m10.1.2.3.2.2" xref="S4.SS3.p2.10.m10.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.10.m10.1b"><apply id="S4.SS3.p2.10.m10.1.2.cmml" xref="S4.SS3.p2.10.m10.1.2"><times id="S4.SS3.p2.10.m10.1.2.1.cmml" xref="S4.SS3.p2.10.m10.1.2.1"></times><apply id="S4.SS3.p2.10.m10.1.2.2.cmml" xref="S4.SS3.p2.10.m10.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.10.m10.1.2.2.1.cmml" xref="S4.SS3.p2.10.m10.1.2.2">subscript</csymbol><ci id="S4.SS3.p2.10.m10.1.2.2.2.cmml" xref="S4.SS3.p2.10.m10.1.2.2.2">ğ‘“</ci><ci id="S4.SS3.p2.10.m10.1.2.2.3.cmml" xref="S4.SS3.p2.10.m10.1.2.2.3">ğ‘ </ci></apply><ci id="S4.SS3.p2.10.m10.1.1.cmml" xref="S4.SS3.p2.10.m10.1.1">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.10.m10.1c">f_{s}(I)</annotation></semantics></math> and <math id="S4.SS3.p2.11.m11.1" class="ltx_Math" alttext="f_{t}(I)" display="inline"><semantics id="S4.SS3.p2.11.m11.1a"><mrow id="S4.SS3.p2.11.m11.1.2" xref="S4.SS3.p2.11.m11.1.2.cmml"><msub id="S4.SS3.p2.11.m11.1.2.2" xref="S4.SS3.p2.11.m11.1.2.2.cmml"><mi id="S4.SS3.p2.11.m11.1.2.2.2" xref="S4.SS3.p2.11.m11.1.2.2.2.cmml">f</mi><mi id="S4.SS3.p2.11.m11.1.2.2.3" xref="S4.SS3.p2.11.m11.1.2.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p2.11.m11.1.2.1" xref="S4.SS3.p2.11.m11.1.2.1.cmml">â€‹</mo><mrow id="S4.SS3.p2.11.m11.1.2.3.2" xref="S4.SS3.p2.11.m11.1.2.cmml"><mo stretchy="false" id="S4.SS3.p2.11.m11.1.2.3.2.1" xref="S4.SS3.p2.11.m11.1.2.cmml">(</mo><mi id="S4.SS3.p2.11.m11.1.1" xref="S4.SS3.p2.11.m11.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.11.m11.1.2.3.2.2" xref="S4.SS3.p2.11.m11.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.11.m11.1b"><apply id="S4.SS3.p2.11.m11.1.2.cmml" xref="S4.SS3.p2.11.m11.1.2"><times id="S4.SS3.p2.11.m11.1.2.1.cmml" xref="S4.SS3.p2.11.m11.1.2.1"></times><apply id="S4.SS3.p2.11.m11.1.2.2.cmml" xref="S4.SS3.p2.11.m11.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.11.m11.1.2.2.1.cmml" xref="S4.SS3.p2.11.m11.1.2.2">subscript</csymbol><ci id="S4.SS3.p2.11.m11.1.2.2.2.cmml" xref="S4.SS3.p2.11.m11.1.2.2.2">ğ‘“</ci><ci id="S4.SS3.p2.11.m11.1.2.2.3.cmml" xref="S4.SS3.p2.11.m11.1.2.2.3">ğ‘¡</ci></apply><ci id="S4.SS3.p2.11.m11.1.1.cmml" xref="S4.SS3.p2.11.m11.1.1">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.11.m11.1c">f_{t}(I)</annotation></semantics></math>, respectively. We then define the <em id="S4.SS3.p2.13.1" class="ltx_emph ltx_font_italic">quality gap</em> <math id="S4.SS3.p2.12.m12.1" class="ltx_Math" alttext="G:\mathcal{N}\to\mathbb{R}" display="inline"><semantics id="S4.SS3.p2.12.m12.1a"><mrow id="S4.SS3.p2.12.m12.1.1" xref="S4.SS3.p2.12.m12.1.1.cmml"><mi id="S4.SS3.p2.12.m12.1.1.2" xref="S4.SS3.p2.12.m12.1.1.2.cmml">G</mi><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.12.m12.1.1.1" xref="S4.SS3.p2.12.m12.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.12.m12.1.1.3" xref="S4.SS3.p2.12.m12.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.12.m12.1.1.3.2" xref="S4.SS3.p2.12.m12.1.1.3.2.cmml">ğ’©</mi><mo stretchy="false" id="S4.SS3.p2.12.m12.1.1.3.1" xref="S4.SS3.p2.12.m12.1.1.3.1.cmml">â†’</mo><mi id="S4.SS3.p2.12.m12.1.1.3.3" xref="S4.SS3.p2.12.m12.1.1.3.3.cmml">â„</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.12.m12.1b"><apply id="S4.SS3.p2.12.m12.1.1.cmml" xref="S4.SS3.p2.12.m12.1.1"><ci id="S4.SS3.p2.12.m12.1.1.1.cmml" xref="S4.SS3.p2.12.m12.1.1.1">:</ci><ci id="S4.SS3.p2.12.m12.1.1.2.cmml" xref="S4.SS3.p2.12.m12.1.1.2">ğº</ci><apply id="S4.SS3.p2.12.m12.1.1.3.cmml" xref="S4.SS3.p2.12.m12.1.1.3"><ci id="S4.SS3.p2.12.m12.1.1.3.1.cmml" xref="S4.SS3.p2.12.m12.1.1.3.1">â†’</ci><ci id="S4.SS3.p2.12.m12.1.1.3.2.cmml" xref="S4.SS3.p2.12.m12.1.1.3.2">ğ’©</ci><ci id="S4.SS3.p2.12.m12.1.1.3.3.cmml" xref="S4.SS3.p2.12.m12.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.12.m12.1c">G:\mathcal{N}\to\mathbb{R}</annotation></semantics></math> between these responses to estimate the <em id="S4.SS3.p2.13.2" class="ltx_emph ltx_font_italic">effectiveness</em> of the instruction: <math id="S4.SS3.p2.13.m13.5" class="ltx_Math" alttext="G(I)=S(f_{s}(I))-S(f_{t}(I))" display="inline"><semantics id="S4.SS3.p2.13.m13.5a"><mrow id="S4.SS3.p2.13.m13.5.5" xref="S4.SS3.p2.13.m13.5.5.cmml"><mrow id="S4.SS3.p2.13.m13.5.5.4" xref="S4.SS3.p2.13.m13.5.5.4.cmml"><mi id="S4.SS3.p2.13.m13.5.5.4.2" xref="S4.SS3.p2.13.m13.5.5.4.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.5.5.4.1" xref="S4.SS3.p2.13.m13.5.5.4.1.cmml">â€‹</mo><mrow id="S4.SS3.p2.13.m13.5.5.4.3.2" xref="S4.SS3.p2.13.m13.5.5.4.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.4.3.2.1" xref="S4.SS3.p2.13.m13.5.5.4.cmml">(</mo><mi id="S4.SS3.p2.13.m13.1.1" xref="S4.SS3.p2.13.m13.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.4.3.2.2" xref="S4.SS3.p2.13.m13.5.5.4.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p2.13.m13.5.5.3" xref="S4.SS3.p2.13.m13.5.5.3.cmml">=</mo><mrow id="S4.SS3.p2.13.m13.5.5.2" xref="S4.SS3.p2.13.m13.5.5.2.cmml"><mrow id="S4.SS3.p2.13.m13.4.4.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.cmml"><mi id="S4.SS3.p2.13.m13.4.4.1.1.3" xref="S4.SS3.p2.13.m13.4.4.1.1.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.4.4.1.1.2" xref="S4.SS3.p2.13.m13.4.4.1.1.2.cmml">â€‹</mo><mrow id="S4.SS3.p2.13.m13.4.4.1.1.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml"><msub id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.cmml"><mi id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.3.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.3.2.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">(</mo><mi id="S4.SS3.p2.13.m13.2.2" xref="S4.SS3.p2.13.m13.2.2.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.3.2.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.3" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p2.13.m13.5.5.2.3" xref="S4.SS3.p2.13.m13.5.5.2.3.cmml">âˆ’</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.cmml"><mi id="S4.SS3.p2.13.m13.5.5.2.2.3" xref="S4.SS3.p2.13.m13.5.5.2.2.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.5.5.2.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.2.cmml">â€‹</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2.1.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">(</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml"><msub id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.cmml"><mi id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1.cmml">â€‹</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.3.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.3.2.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">(</mo><mi id="S4.SS3.p2.13.m13.3.3" xref="S4.SS3.p2.13.m13.3.3.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.3.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.3" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.13.m13.5b"><apply id="S4.SS3.p2.13.m13.5.5.cmml" xref="S4.SS3.p2.13.m13.5.5"><eq id="S4.SS3.p2.13.m13.5.5.3.cmml" xref="S4.SS3.p2.13.m13.5.5.3"></eq><apply id="S4.SS3.p2.13.m13.5.5.4.cmml" xref="S4.SS3.p2.13.m13.5.5.4"><times id="S4.SS3.p2.13.m13.5.5.4.1.cmml" xref="S4.SS3.p2.13.m13.5.5.4.1"></times><ci id="S4.SS3.p2.13.m13.5.5.4.2.cmml" xref="S4.SS3.p2.13.m13.5.5.4.2">ğº</ci><ci id="S4.SS3.p2.13.m13.1.1.cmml" xref="S4.SS3.p2.13.m13.1.1">ğ¼</ci></apply><apply id="S4.SS3.p2.13.m13.5.5.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2"><minus id="S4.SS3.p2.13.m13.5.5.2.3.cmml" xref="S4.SS3.p2.13.m13.5.5.2.3"></minus><apply id="S4.SS3.p2.13.m13.4.4.1.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1"><times id="S4.SS3.p2.13.m13.4.4.1.1.2.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.2"></times><ci id="S4.SS3.p2.13.m13.4.4.1.1.3.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.3">ğ‘†</ci><apply id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1"><times id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1"></times><apply id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2">ğ‘“</ci><ci id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3">ğ‘ </ci></apply><ci id="S4.SS3.p2.13.m13.2.2.cmml" xref="S4.SS3.p2.13.m13.2.2">ğ¼</ci></apply></apply><apply id="S4.SS3.p2.13.m13.5.5.2.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2"><times id="S4.SS3.p2.13.m13.5.5.2.2.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.2"></times><ci id="S4.SS3.p2.13.m13.5.5.2.2.3.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.3">ğ‘†</ci><apply id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1"><times id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1"></times><apply id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.1.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2">ğ‘“</ci><ci id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S4.SS3.p2.13.m13.3.3.cmml" xref="S4.SS3.p2.13.m13.3.3">ğ¼</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.13.m13.5c">G(I)=S(f_{s}(I))-S(f_{t}(I))</annotation></semantics></math>.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.11" class="ltx_p">The quality gap metric <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">G</annotation></semantics></math> reflects how much the target LLM benefits from the strong LLM for each instruction <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mi id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><ci id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">I</annotation></semantics></math>.
As demonstrated in Figure&nbsp;<a href="#S2.F2" title="Figure 2 â€£ 2 Related Work â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, here are two possible cases: (1) <math id="S4.SS3.p3.3.m3.2" class="ltx_Math" alttext="|G(I)|>\theta" display="inline"><semantics id="S4.SS3.p3.3.m3.2a"><mrow id="S4.SS3.p3.3.m3.2.2" xref="S4.SS3.p3.3.m3.2.2.cmml"><mrow id="S4.SS3.p3.3.m3.2.2.1.1" xref="S4.SS3.p3.3.m3.2.2.1.2.cmml"><mo stretchy="false" id="S4.SS3.p3.3.m3.2.2.1.1.2" xref="S4.SS3.p3.3.m3.2.2.1.2.1.cmml">|</mo><mrow id="S4.SS3.p3.3.m3.2.2.1.1.1" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml"><mi id="S4.SS3.p3.3.m3.2.2.1.1.1.2" xref="S4.SS3.p3.3.m3.2.2.1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p3.3.m3.2.2.1.1.1.1" xref="S4.SS3.p3.3.m3.2.2.1.1.1.1.cmml">â€‹</mo><mrow id="S4.SS3.p3.3.m3.2.2.1.1.1.3.2" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.3.m3.2.2.1.1.1.3.2.1" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml">(</mo><mi id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p3.3.m3.2.2.1.1.1.3.2.2" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p3.3.m3.2.2.1.1.3" xref="S4.SS3.p3.3.m3.2.2.1.2.1.cmml">|</mo></mrow><mo id="S4.SS3.p3.3.m3.2.2.2" xref="S4.SS3.p3.3.m3.2.2.2.cmml">&gt;</mo><mi id="S4.SS3.p3.3.m3.2.2.3" xref="S4.SS3.p3.3.m3.2.2.3.cmml">Î¸</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.2b"><apply id="S4.SS3.p3.3.m3.2.2.cmml" xref="S4.SS3.p3.3.m3.2.2"><gt id="S4.SS3.p3.3.m3.2.2.2.cmml" xref="S4.SS3.p3.3.m3.2.2.2"></gt><apply id="S4.SS3.p3.3.m3.2.2.1.2.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1"><abs id="S4.SS3.p3.3.m3.2.2.1.2.1.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.2"></abs><apply id="S4.SS3.p3.3.m3.2.2.1.1.1.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.1"><times id="S4.SS3.p3.3.m3.2.2.1.1.1.1.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.1.1"></times><ci id="S4.SS3.p3.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.1.2">ğº</ci><ci id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">ğ¼</ci></apply></apply><ci id="S4.SS3.p3.3.m3.2.2.3.cmml" xref="S4.SS3.p3.3.m3.2.2.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.2c">|G(I)|&gt;\theta</annotation></semantics></math>, where <math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="\theta\in\mathbb{R}" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><mrow id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml"><mi id="S4.SS3.p3.4.m4.1.1.2" xref="S4.SS3.p3.4.m4.1.1.2.cmml">Î¸</mi><mo id="S4.SS3.p3.4.m4.1.1.1" xref="S4.SS3.p3.4.m4.1.1.1.cmml">âˆˆ</mo><mi id="S4.SS3.p3.4.m4.1.1.3" xref="S4.SS3.p3.4.m4.1.1.3.cmml">â„</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><apply id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1"><in id="S4.SS3.p3.4.m4.1.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1.1"></in><ci id="S4.SS3.p3.4.m4.1.1.2.cmml" xref="S4.SS3.p3.4.m4.1.1.2">ğœƒ</ci><ci id="S4.SS3.p3.4.m4.1.1.3.cmml" xref="S4.SS3.p3.4.m4.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">\theta\in\mathbb{R}</annotation></semantics></math> is a certain threshold. This indicates that: Either the strong LLM has a much better response than the target LLM, we add <math id="S4.SS3.p3.5.m5.3" class="ltx_Math" alttext="(I,f_{s}(I))" display="inline"><semantics id="S4.SS3.p3.5.m5.3a"><mrow id="S4.SS3.p3.5.m5.3.3.1" xref="S4.SS3.p3.5.m5.3.3.2.cmml"><mo stretchy="false" id="S4.SS3.p3.5.m5.3.3.1.2" xref="S4.SS3.p3.5.m5.3.3.2.cmml">(</mo><mi id="S4.SS3.p3.5.m5.2.2" xref="S4.SS3.p3.5.m5.2.2.cmml">I</mi><mo id="S4.SS3.p3.5.m5.3.3.1.3" xref="S4.SS3.p3.5.m5.3.3.2.cmml">,</mo><mrow id="S4.SS3.p3.5.m5.3.3.1.1" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml"><msub id="S4.SS3.p3.5.m5.3.3.1.1.2" xref="S4.SS3.p3.5.m5.3.3.1.1.2.cmml"><mi id="S4.SS3.p3.5.m5.3.3.1.1.2.2" xref="S4.SS3.p3.5.m5.3.3.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p3.5.m5.3.3.1.1.2.3" xref="S4.SS3.p3.5.m5.3.3.1.1.2.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p3.5.m5.3.3.1.1.1" xref="S4.SS3.p3.5.m5.3.3.1.1.1.cmml">â€‹</mo><mrow id="S4.SS3.p3.5.m5.3.3.1.1.3.2" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.5.m5.3.3.1.1.3.2.1" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml">(</mo><mi id="S4.SS3.p3.5.m5.1.1" xref="S4.SS3.p3.5.m5.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p3.5.m5.3.3.1.1.3.2.2" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p3.5.m5.3.3.1.4" xref="S4.SS3.p3.5.m5.3.3.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.3b"><interval closure="open" id="S4.SS3.p3.5.m5.3.3.2.cmml" xref="S4.SS3.p3.5.m5.3.3.1"><ci id="S4.SS3.p3.5.m5.2.2.cmml" xref="S4.SS3.p3.5.m5.2.2">ğ¼</ci><apply id="S4.SS3.p3.5.m5.3.3.1.1.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1"><times id="S4.SS3.p3.5.m5.3.3.1.1.1.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.1"></times><apply id="S4.SS3.p3.5.m5.3.3.1.1.2.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p3.5.m5.3.3.1.1.2.1.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2">subscript</csymbol><ci id="S4.SS3.p3.5.m5.3.3.1.1.2.2.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2.2">ğ‘“</ci><ci id="S4.SS3.p3.5.m5.3.3.1.1.2.3.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2.3">ğ‘ </ci></apply><ci id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1">ğ¼</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.3c">(I,f_{s}(I))</annotation></semantics></math> to our high-quality instruction-response pool <math id="S4.SS3.p3.6.m6.1" class="ltx_Math" alttext="\mathcal{D}_{g}" display="inline"><semantics id="S4.SS3.p3.6.m6.1a"><msub id="S4.SS3.p3.6.m6.1.1" xref="S4.SS3.p3.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p3.6.m6.1.1.2" xref="S4.SS3.p3.6.m6.1.1.2.cmml">ğ’Ÿ</mi><mi id="S4.SS3.p3.6.m6.1.1.3" xref="S4.SS3.p3.6.m6.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.6.m6.1b"><apply id="S4.SS3.p3.6.m6.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.6.m6.1.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1">subscript</csymbol><ci id="S4.SS3.p3.6.m6.1.1.2.cmml" xref="S4.SS3.p3.6.m6.1.1.2">ğ’Ÿ</ci><ci id="S4.SS3.p3.6.m6.1.1.3.cmml" xref="S4.SS3.p3.6.m6.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.6.m6.1c">\mathcal{D}_{g}</annotation></semantics></math> to fill the gap; Or rarely, the target LLM gives much better response than the strong LLM, we add <math id="S4.SS3.p3.7.m7.3" class="ltx_Math" alttext="(I,f_{t}(I))" display="inline"><semantics id="S4.SS3.p3.7.m7.3a"><mrow id="S4.SS3.p3.7.m7.3.3.1" xref="S4.SS3.p3.7.m7.3.3.2.cmml"><mo stretchy="false" id="S4.SS3.p3.7.m7.3.3.1.2" xref="S4.SS3.p3.7.m7.3.3.2.cmml">(</mo><mi id="S4.SS3.p3.7.m7.2.2" xref="S4.SS3.p3.7.m7.2.2.cmml">I</mi><mo id="S4.SS3.p3.7.m7.3.3.1.3" xref="S4.SS3.p3.7.m7.3.3.2.cmml">,</mo><mrow id="S4.SS3.p3.7.m7.3.3.1.1" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml"><msub id="S4.SS3.p3.7.m7.3.3.1.1.2" xref="S4.SS3.p3.7.m7.3.3.1.1.2.cmml"><mi id="S4.SS3.p3.7.m7.3.3.1.1.2.2" xref="S4.SS3.p3.7.m7.3.3.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p3.7.m7.3.3.1.1.2.3" xref="S4.SS3.p3.7.m7.3.3.1.1.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p3.7.m7.3.3.1.1.1" xref="S4.SS3.p3.7.m7.3.3.1.1.1.cmml">â€‹</mo><mrow id="S4.SS3.p3.7.m7.3.3.1.1.3.2" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.7.m7.3.3.1.1.3.2.1" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml">(</mo><mi id="S4.SS3.p3.7.m7.1.1" xref="S4.SS3.p3.7.m7.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p3.7.m7.3.3.1.1.3.2.2" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p3.7.m7.3.3.1.4" xref="S4.SS3.p3.7.m7.3.3.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.7.m7.3b"><interval closure="open" id="S4.SS3.p3.7.m7.3.3.2.cmml" xref="S4.SS3.p3.7.m7.3.3.1"><ci id="S4.SS3.p3.7.m7.2.2.cmml" xref="S4.SS3.p3.7.m7.2.2">ğ¼</ci><apply id="S4.SS3.p3.7.m7.3.3.1.1.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1"><times id="S4.SS3.p3.7.m7.3.3.1.1.1.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.1"></times><apply id="S4.SS3.p3.7.m7.3.3.1.1.2.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p3.7.m7.3.3.1.1.2.1.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2">subscript</csymbol><ci id="S4.SS3.p3.7.m7.3.3.1.1.2.2.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2.2">ğ‘“</ci><ci id="S4.SS3.p3.7.m7.3.3.1.1.2.3.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2.3">ğ‘¡</ci></apply><ci id="S4.SS3.p3.7.m7.1.1.cmml" xref="S4.SS3.p3.7.m7.1.1">ğ¼</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.7.m7.3c">(I,f_{t}(I))</annotation></semantics></math> to <math id="S4.SS3.p3.8.m8.1" class="ltx_Math" alttext="\mathcal{D}_{g}" display="inline"><semantics id="S4.SS3.p3.8.m8.1a"><msub id="S4.SS3.p3.8.m8.1.1" xref="S4.SS3.p3.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p3.8.m8.1.1.2" xref="S4.SS3.p3.8.m8.1.1.2.cmml">ğ’Ÿ</mi><mi id="S4.SS3.p3.8.m8.1.1.3" xref="S4.SS3.p3.8.m8.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.8.m8.1b"><apply id="S4.SS3.p3.8.m8.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.8.m8.1.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1">subscript</csymbol><ci id="S4.SS3.p3.8.m8.1.1.2.cmml" xref="S4.SS3.p3.8.m8.1.1.2">ğ’Ÿ</ci><ci id="S4.SS3.p3.8.m8.1.1.3.cmml" xref="S4.SS3.p3.8.m8.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.8.m8.1c">\mathcal{D}_{g}</annotation></semantics></math> as as an implicit regularization to keep the target LLMâ€™s desirable behavior to certain instructions. (2) <math id="S4.SS3.p3.9.m9.2" class="ltx_Math" alttext="|G(I)|\leq\theta" display="inline"><semantics id="S4.SS3.p3.9.m9.2a"><mrow id="S4.SS3.p3.9.m9.2.2" xref="S4.SS3.p3.9.m9.2.2.cmml"><mrow id="S4.SS3.p3.9.m9.2.2.1.1" xref="S4.SS3.p3.9.m9.2.2.1.2.cmml"><mo stretchy="false" id="S4.SS3.p3.9.m9.2.2.1.1.2" xref="S4.SS3.p3.9.m9.2.2.1.2.1.cmml">|</mo><mrow id="S4.SS3.p3.9.m9.2.2.1.1.1" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml"><mi id="S4.SS3.p3.9.m9.2.2.1.1.1.2" xref="S4.SS3.p3.9.m9.2.2.1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p3.9.m9.2.2.1.1.1.1" xref="S4.SS3.p3.9.m9.2.2.1.1.1.1.cmml">â€‹</mo><mrow id="S4.SS3.p3.9.m9.2.2.1.1.1.3.2" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.9.m9.2.2.1.1.1.3.2.1" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml">(</mo><mi id="S4.SS3.p3.9.m9.1.1" xref="S4.SS3.p3.9.m9.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p3.9.m9.2.2.1.1.1.3.2.2" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p3.9.m9.2.2.1.1.3" xref="S4.SS3.p3.9.m9.2.2.1.2.1.cmml">|</mo></mrow><mo id="S4.SS3.p3.9.m9.2.2.2" xref="S4.SS3.p3.9.m9.2.2.2.cmml">â‰¤</mo><mi id="S4.SS3.p3.9.m9.2.2.3" xref="S4.SS3.p3.9.m9.2.2.3.cmml">Î¸</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.9.m9.2b"><apply id="S4.SS3.p3.9.m9.2.2.cmml" xref="S4.SS3.p3.9.m9.2.2"><leq id="S4.SS3.p3.9.m9.2.2.2.cmml" xref="S4.SS3.p3.9.m9.2.2.2"></leq><apply id="S4.SS3.p3.9.m9.2.2.1.2.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1"><abs id="S4.SS3.p3.9.m9.2.2.1.2.1.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.2"></abs><apply id="S4.SS3.p3.9.m9.2.2.1.1.1.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.1"><times id="S4.SS3.p3.9.m9.2.2.1.1.1.1.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.1.1"></times><ci id="S4.SS3.p3.9.m9.2.2.1.1.1.2.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.1.2">ğº</ci><ci id="S4.SS3.p3.9.m9.1.1.cmml" xref="S4.SS3.p3.9.m9.1.1">ğ¼</ci></apply></apply><ci id="S4.SS3.p3.9.m9.2.2.3.cmml" xref="S4.SS3.p3.9.m9.2.2.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.9.m9.2c">|G(I)|\leq\theta</annotation></semantics></math>, where the quality of responses from both LLMs is similar, so learning from <math id="S4.SS3.p3.10.m10.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S4.SS3.p3.10.m10.1a"><mi id="S4.SS3.p3.10.m10.1.1" xref="S4.SS3.p3.10.m10.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.10.m10.1b"><ci id="S4.SS3.p3.10.m10.1.1.cmml" xref="S4.SS3.p3.10.m10.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.10.m10.1c">I</annotation></semantics></math> does not lead to much gain. We then send <math id="S4.SS3.p3.11.m11.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S4.SS3.p3.11.m11.1a"><mi id="S4.SS3.p3.11.m11.1.1" xref="S4.SS3.p3.11.m11.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.11.m11.1b"><ci id="S4.SS3.p3.11.m11.1.1.cmml" xref="S4.SS3.p3.11.m11.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.11.m11.1c">I</annotation></semantics></math> to the next Self-Rubrics iteration for further improvement.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">Contrastive Filtering complements Self-Rubrics to select effective instruction-response pairs by calibrating the target LLMâ€™s instruction-following capability with the strong LLMâ€™s. Analogous to Constrastive Decoding&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a href="#bib.bib28" title="" class="ltx_ref">2022</a>)</cite> at response-level, Contrastive Filtering can also be regarded as LLM-feedback&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Madaan et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite> with the interaction of two LLMs. While we adopt the strong LLM as scoring function to measure the quality gap, our framework can be compatible with and potentially benefit from the advances in more reliable and comprehensive scoring and feedback systems&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lee et&nbsp;al., <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite>, and we leave it as promising future work.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We conduct comprehensive experiments to evaluate CodecLM using different LLMs on multiple representative benchmarks, closely following well-established evaluation settings for open-domain instruction following in prior work&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>; Chen et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023b</a>)</cite>.
We also conduct a case study in Appendix&nbsp;<a href="#A1.SS8" title="A.8 Case Study â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.8</span></a> to illustrate how CodecLM tailors an instruction step by step.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation Benchmarks</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We evaluate CodecLM on four widely-used open-domain instruction-following benchmarks with diverse instruction distributions to reduce evaluation bias. Our test benchmarks include Evol-Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>, Vicuna&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite>, Self-Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> and Koala&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Geng et&nbsp;al., <a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite>.
To complement the evaluation, we also evaluate on two standard NLP benchmarks MMLU&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite> and BBH&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et&nbsp;al., <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite> in Appendix&nbsp;<a href="#A1.SS7" title="A.7 Additional Benchmark Results â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.7</span></a>.
Please refer to Appendix&nbsp;<a href="#A1.SS1" title="A.1 Benchmark Details â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a> for benchmark details.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Baseline Methods</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We compare our method against state-of-the-art data generation approaches for instruction tuning. For fair comparison, we provide all methods the same LLM backbones when possible. Moreover, we control the number of instruction-response pairs the same for all methods to ablate the effect of data quantity.
Baseline methods include <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_bold">Self-Instruct</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite>, <span id="S5.SS2.p1.1.2" class="ltx_text ltx_font_bold">Alpagasus</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023b</a>)</cite>, &nbsp;<span id="S5.SS2.p1.1.3" class="ltx_text ltx_font_bold">Tree-Instruct</span>, <span id="S5.SS2.p1.1.4" class="ltx_text ltx_font_bold">WizardLM</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>, and <span id="S5.SS2.p1.1.5" class="ltx_text ltx_font_bold">WizardLM+</span>, an enhanced version of WizardLM using the same basic instructions generated from CodecLM as seed instructions. Baseline details are presented in Appendix&nbsp;<a href="#A1.SS2" title="A.2 Baseline Details â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Experiment and Evaluation Details</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p"><span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_bold">LLM Backbones.</span> We adopt LLaMA-based&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a href="#bib.bib44" title="" class="ltx_ref">2023</a>)</cite> and PaLM-based&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Anil et&nbsp;al., <a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite> LLMs as our target LLMs in our experiments. For LLaMA-based target LLMs, we use Gemini-Pro&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Team et&nbsp;al., <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite> as the strong LLM, and LLaMA-7B, -13B as the target LLMs. For PaLM-based target LLMs, we use text-unicorn as the strong LLM, and text-bison as the target LLM. PaLM-based models and Gemini-Pro are accessible through Google Cloud API<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://cloud.google.com/vertex-ai" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cloud.google.com/vertex-ai</a></span></span></span>.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para ltx_noindent">
<p id="S5.SS3.p2.1" class="ltx_p"><span id="S5.SS3.p2.1.1" class="ltx_text ltx_font_bold">Implementation Details of CodecLM.</span> We split all benchmarks into 20% validation set and 80% evaluation set. We extract the instruction metadata from the validation set, see Appendix&nbsp;<a href="#A1.SS3" title="A.3 Additional Implementation Details â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a> for more details. Depending on the specified total data size, we prompt the strong LLM to generate equal number of base instruction per metadata. We generate 500-8000 synthetic data throughout the experiments. We generate 4 rubrics and corresponding actions. At each iteration, we randomly choose 1 action for improving instruction. We run Self-Rubrics at most 4 iterations. For Contrastive Filtering, We set the scoring scale to 10 and the filtering threshold to 3 for all experiments. We align these configurations with&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>
and leave more detailed rationales of these configurations, additional hyperparameter settings, and training details in Appendix&nbsp;<a href="#A1.SS3" title="A.3 Additional Implementation Details â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a>-<a href="#A1.SS4" title="A.4 Training Details â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.4</span></a>.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results with LLaMA-based target models on four open-domain instruction following benchmarks. Each method trains a target model based on LLaMA-7B or -13B, and compares against the strong model, Gemini-Pro. The reported metric Capacity Recovery Ratio (%), <math id="S5.T1.2.m1.1" class="ltx_Math" alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" display="inline"><semantics id="S5.T1.2.m1.1b"><mrow id="S5.T1.2.m1.1.1" xref="S5.T1.2.m1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.2" xref="S5.T1.2.m1.1.1.2a.cmml">CRR</mtext><mo id="S5.T1.2.m1.1.1.1" xref="S5.T1.2.m1.1.1.1.cmml">=</mo><mfrac id="S5.T1.2.m1.1.1.3" xref="S5.T1.2.m1.1.1.3.cmml"><mrow id="S5.T1.2.m1.1.1.3.2" xref="S5.T1.2.m1.1.1.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.2.2" xref="S5.T1.2.m1.1.1.3.2.2a.cmml">wins</mtext><mo id="S5.T1.2.m1.1.1.3.2.1" xref="S5.T1.2.m1.1.1.3.2.1.cmml">+</mo><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.2.3" xref="S5.T1.2.m1.1.1.3.2.3a.cmml">ties</mtext></mrow><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.3" xref="S5.T1.2.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.m1.1c"><apply id="S5.T1.2.m1.1.1.cmml" xref="S5.T1.2.m1.1.1"><eq id="S5.T1.2.m1.1.1.1.cmml" xref="S5.T1.2.m1.1.1.1"></eq><ci id="S5.T1.2.m1.1.1.2a.cmml" xref="S5.T1.2.m1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.2.cmml" xref="S5.T1.2.m1.1.1.2">CRR</mtext></ci><apply id="S5.T1.2.m1.1.1.3.cmml" xref="S5.T1.2.m1.1.1.3"><divide id="S5.T1.2.m1.1.1.3.1.cmml" xref="S5.T1.2.m1.1.1.3"></divide><apply id="S5.T1.2.m1.1.1.3.2.cmml" xref="S5.T1.2.m1.1.1.3.2"><plus id="S5.T1.2.m1.1.1.3.2.1.cmml" xref="S5.T1.2.m1.1.1.3.2.1"></plus><ci id="S5.T1.2.m1.1.1.3.2.2a.cmml" xref="S5.T1.2.m1.1.1.3.2.2"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S5.T1.2.m1.1.1.3.2.2.cmml" xref="S5.T1.2.m1.1.1.3.2.2">wins</mtext></ci><ci id="S5.T1.2.m1.1.1.3.2.3a.cmml" xref="S5.T1.2.m1.1.1.3.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S5.T1.2.m1.1.1.3.2.3.cmml" xref="S5.T1.2.m1.1.1.3.2.3">ties</mtext></ci></apply><ci id="S5.T1.2.m1.1.1.3.3a.cmml" xref="S5.T1.2.m1.1.1.3.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S5.T1.2.m1.1.1.3.3.cmml" xref="S5.T1.2.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.m1.1d">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation></semantics></math>. Larger CRR means better performance.
</figcaption>
<div id="S5.T1.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:557.7pt;height:126.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.0pt,8.6pt) scale(0.88,0.88) ;">
<table id="S5.T1.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.3.1.1.1" class="ltx_tr">
<th id="S5.T1.3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" rowspan="2"><span id="S5.T1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="S5.T1.3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_tt" colspan="4"><span id="S5.T1.3.1.1.1.2.1" class="ltx_text ltx_font_bold">LLaMA-7B vs. Gemini-Pro</span></th>
<th id="S5.T1.3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S5.T1.3.1.1.1.3.1" class="ltx_text ltx_font_bold">LLaMA-13B vs. Gemini-Pro</span></th>
</tr>
<tr id="S5.T1.3.1.2.2" class="ltx_tr">
<th id="S5.T1.3.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.1.1" class="ltx_text ltx_font_bold">Evol-Ins.</span></th>
<th id="S5.T1.3.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.2.1" class="ltx_text ltx_font_bold">Vicuna</span></th>
<th id="S5.T1.3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.3.1" class="ltx_text ltx_font_bold">Koala</span></th>
<th id="S5.T1.3.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t"><span id="S5.T1.3.1.2.2.4.1" class="ltx_text ltx_font_bold">Self-Ins.</span></th>
<th id="S5.T1.3.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.5.1" class="ltx_text ltx_font_bold">Evol-Ins.</span></th>
<th id="S5.T1.3.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.6.1" class="ltx_text ltx_font_bold">Vicuna</span></th>
<th id="S5.T1.3.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.7.1" class="ltx_text ltx_font_bold">Koala</span></th>
<th id="S5.T1.3.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.8.1" class="ltx_text ltx_font_bold">Self-Ins.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.3.1.3.1" class="ltx_tr">
<th id="S5.T1.3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t">Self-Instruct</th>
<td id="S5.T1.3.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">72.02</td>
<td id="S5.T1.3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">81.25</td>
<td id="S5.T1.3.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">67.78</td>
<td id="S5.T1.3.1.3.1.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">65.87</td>
<td id="S5.T1.3.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">75.69</td>
<td id="S5.T1.3.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">86.25</td>
<td id="S5.T1.3.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">77.22</td>
<td id="S5.T1.3.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">69.05</td>
</tr>
<tr id="S5.T1.3.1.4.2" class="ltx_tr">
<th id="S5.T1.3.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Alpagasus</th>
<td id="S5.T1.3.1.4.2.2" class="ltx_td ltx_align_center">75.23 <span id="S5.T1.3.1.4.2.2.1" class="ltx_text" style="color:#006B3D;">(+3.2)</span>
</td>
<td id="S5.T1.3.1.4.2.3" class="ltx_td ltx_align_center">81.25 <span id="S5.T1.3.1.4.2.3.1" class="ltx_text" style="color:#006B3D;">(+0.0)</span>
</td>
<td id="S5.T1.3.1.4.2.4" class="ltx_td ltx_align_center">71.11 <span id="S5.T1.3.1.4.2.4.1" class="ltx_text" style="color:#006B3D;">(+3.3)</span>
</td>
<td id="S5.T1.3.1.4.2.5" class="ltx_td ltx_align_center ltx_border_rr">70.24 <span id="S5.T1.3.1.4.2.5.1" class="ltx_text" style="color:#006B3D;">(+4.4)</span>
</td>
<td id="S5.T1.3.1.4.2.6" class="ltx_td ltx_align_center">79.82 <span id="S5.T1.3.1.4.2.6.1" class="ltx_text" style="color:#006B3D;">(+4.1)</span>
</td>
<td id="S5.T1.3.1.4.2.7" class="ltx_td ltx_align_center">87.50 <span id="S5.T1.3.1.4.2.7.1" class="ltx_text" style="color:#006B3D;">(+1.3)</span>
</td>
<td id="S5.T1.3.1.4.2.8" class="ltx_td ltx_align_center">77.78 <span id="S5.T1.3.1.4.2.8.1" class="ltx_text" style="color:#006B3D;">(+0.6)</span>
</td>
<td id="S5.T1.3.1.4.2.9" class="ltx_td ltx_align_center">71.03 <span id="S5.T1.3.1.4.2.9.1" class="ltx_text" style="color:#006B3D;">(+2.0)</span>
</td>
</tr>
<tr id="S5.T1.3.1.5.3" class="ltx_tr">
<th id="S5.T1.3.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Tree-Instruct</th>
<td id="S5.T1.3.1.5.3.2" class="ltx_td ltx_align_center">75.23 <span id="S5.T1.3.1.5.3.2.1" class="ltx_text" style="color:#006B3D;">(+3.2)</span>
</td>
<td id="S5.T1.3.1.5.3.3" class="ltx_td ltx_align_center">81.25 <span id="S5.T1.3.1.5.3.3.1" class="ltx_text" style="color:#006B3D;">(+0.0)</span>
</td>
<td id="S5.T1.3.1.5.3.4" class="ltx_td ltx_align_center">72.78 <span id="S5.T1.3.1.5.3.4.1" class="ltx_text" style="color:#006B3D;">(+5.0)</span>
</td>
<td id="S5.T1.3.1.5.3.5" class="ltx_td ltx_align_center ltx_border_rr">68.65 <span id="S5.T1.3.1.5.3.5.1" class="ltx_text" style="color:#006B3D;">(+2.8)</span>
</td>
<td id="S5.T1.3.1.5.3.6" class="ltx_td ltx_align_center">82.57 <span id="S5.T1.3.1.5.3.6.1" class="ltx_text" style="color:#006B3D;">(+6.9)</span>
</td>
<td id="S5.T1.3.1.5.3.7" class="ltx_td ltx_align_center">87.50 <span id="S5.T1.3.1.5.3.7.1" class="ltx_text" style="color:#006B3D;">(+1.3)</span>
</td>
<td id="S5.T1.3.1.5.3.8" class="ltx_td ltx_align_center">80.56 <span id="S5.T1.3.1.5.3.8.1" class="ltx_text" style="color:#006B3D;">(+3.3)</span>
</td>
<td id="S5.T1.3.1.5.3.9" class="ltx_td ltx_align_center">79.37 <span id="S5.T1.3.1.5.3.9.1" class="ltx_text" style="color:#006B3D;">(+10.3)</span>
</td>
</tr>
<tr id="S5.T1.3.1.6.4" class="ltx_tr">
<th id="S5.T1.3.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM</th>
<td id="S5.T1.3.1.6.4.2" class="ltx_td ltx_align_center">74.31 <span id="S5.T1.3.1.6.4.2.1" class="ltx_text" style="color:#006B3D;">(+2.3)</span>
</td>
<td id="S5.T1.3.1.6.4.3" class="ltx_td ltx_align_center">76.25 <span id="S5.T1.3.1.6.4.3.1" class="ltx_text" style="color:#FF0000;">(-5.0)</span>
</td>
<td id="S5.T1.3.1.6.4.4" class="ltx_td ltx_align_center">65.56 <span id="S5.T1.3.1.6.4.4.1" class="ltx_text" style="color:#FF0000;">(-2.2)</span>
</td>
<td id="S5.T1.3.1.6.4.5" class="ltx_td ltx_align_center ltx_border_rr">71.43 <span id="S5.T1.3.1.6.4.5.1" class="ltx_text" style="color:#006B3D;">(+5.6)</span>
</td>
<td id="S5.T1.3.1.6.4.6" class="ltx_td ltx_align_center">82.11 <span id="S5.T1.3.1.6.4.6.1" class="ltx_text" style="color:#006B3D;">(+6.4)</span>
</td>
<td id="S5.T1.3.1.6.4.7" class="ltx_td ltx_align_center">86.25 <span id="S5.T1.3.1.6.4.7.1" class="ltx_text" style="color:#006B3D;">(+0.0)</span>
</td>
<td id="S5.T1.3.1.6.4.8" class="ltx_td ltx_align_center">78.89 <span id="S5.T1.3.1.6.4.8.1" class="ltx_text" style="color:#006B3D;">(+1.7)</span>
</td>
<td id="S5.T1.3.1.6.4.9" class="ltx_td ltx_align_center">76.19 <span id="S5.T1.3.1.6.4.9.1" class="ltx_text" style="color:#006B3D;">(+7.1)</span>
</td>
</tr>
<tr id="S5.T1.3.1.7.5" class="ltx_tr">
<th id="S5.T1.3.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM+</th>
<td id="S5.T1.3.1.7.5.2" class="ltx_td ltx_align_center">75.69 <span id="S5.T1.3.1.7.5.2.1" class="ltx_text" style="color:#006B3D;">(+3.7)</span>
</td>
<td id="S5.T1.3.1.7.5.3" class="ltx_td ltx_align_center">83.75 <span id="S5.T1.3.1.7.5.3.1" class="ltx_text" style="color:#006B3D;">(+2.5)</span>
</td>
<td id="S5.T1.3.1.7.5.4" class="ltx_td ltx_align_center">68.33 <span id="S5.T1.3.1.7.5.4.1" class="ltx_text" style="color:#006B3D;">(+0.6)</span>
</td>
<td id="S5.T1.3.1.7.5.5" class="ltx_td ltx_align_center ltx_border_rr">72.22 <span id="S5.T1.3.1.7.5.5.1" class="ltx_text" style="color:#006B3D;">(+6.4)</span>
</td>
<td id="S5.T1.3.1.7.5.6" class="ltx_td ltx_align_center">84.40 <span id="S5.T1.3.1.7.5.6.1" class="ltx_text" style="color:#006B3D;">(+8.7)</span>
</td>
<td id="S5.T1.3.1.7.5.7" class="ltx_td ltx_align_center">88.75 <span id="S5.T1.3.1.7.5.7.1" class="ltx_text" style="color:#006B3D;">(+2.5)</span>
</td>
<td id="S5.T1.3.1.7.5.8" class="ltx_td ltx_align_center">81.11 <span id="S5.T1.3.1.7.5.8.1" class="ltx_text" style="color:#006B3D;">(+3.9)</span>
</td>
<td id="S5.T1.3.1.7.5.9" class="ltx_td ltx_align_center">79.76 <span id="S5.T1.3.1.7.5.9.1" class="ltx_text" style="color:#006B3D;">(+10.7)</span>
</td>
</tr>
<tr id="S5.T1.3.1.8.6" class="ltx_tr">
<th id="S5.T1.3.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr">CodecLM (ours)</th>
<td id="S5.T1.3.1.8.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.2.1" class="ltx_text ltx_font_bold">79.82 <span id="S5.T1.3.1.8.6.2.1.1" class="ltx_text" style="color:#006B3D;">(+7.8)</span></span></td>
<td id="S5.T1.3.1.8.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.3.1" class="ltx_text ltx_font_bold">88.75 <span id="S5.T1.3.1.8.6.3.1.1" class="ltx_text" style="color:#006B3D;">(+7.5)</span></span></td>
<td id="S5.T1.3.1.8.6.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.4.1" class="ltx_text ltx_font_bold">74.44 <span id="S5.T1.3.1.8.6.4.1.1" class="ltx_text" style="color:#006B3D;">(+6.7)</span></span></td>
<td id="S5.T1.3.1.8.6.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr"><span id="S5.T1.3.1.8.6.5.1" class="ltx_text ltx_font_bold">78.17 <span id="S5.T1.3.1.8.6.5.1.1" class="ltx_text" style="color:#006B3D;">(+12.3)</span></span></td>
<td id="S5.T1.3.1.8.6.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.6.1" class="ltx_text ltx_font_bold">86.70 <span id="S5.T1.3.1.8.6.6.1.1" class="ltx_text" style="color:#006B3D;">(+11.0)</span></span></td>
<td id="S5.T1.3.1.8.6.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.7.1" class="ltx_text ltx_font_bold">90.00 <span id="S5.T1.3.1.8.6.7.1.1" class="ltx_text" style="color:#006B3D;">(+3.8)</span></span></td>
<td id="S5.T1.3.1.8.6.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.8.1" class="ltx_text ltx_font_bold">82.22 <span id="S5.T1.3.1.8.6.8.1.1" class="ltx_text" style="color:#006B3D;">(+5.0)</span></span></td>
<td id="S5.T1.3.1.8.6.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.9.1" class="ltx_text ltx_font_bold">83.33 <span id="S5.T1.3.1.8.6.9.1.1" class="ltx_text" style="color:#006B3D;">(+14.3)</span></span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.SS3.p3" class="ltx_para ltx_noindent">
<p id="S5.SS3.p3.1" class="ltx_p"><span id="S5.SS3.p3.1.1" class="ltx_text ltx_font_bold">Evaluation.</span>
Assessing how well LLMs follow instructions is complex, arising from the fact that an instruction has various valid responses, and the challenge of replicating human evaluation. Recent advances in automatic evaluation on instruction following&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dubois et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2023</a>; Zheng et&nbsp;al., <a href="#bib.bib54" title="" class="ltx_ref">2023</a>)</cite> demonstrate that LLM-based evaluators are scalable, explainable, and consistent with human evaluations. Therefore, we adopt widely-used Vicuna pairwise evaluator&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite> based on ChatGPT to compare the response quality from two LLMs for its accessibility in price and efficiency. The evaluation prompt template is in Figure&nbsp;<a href="#A1.F12" title="Figure 12 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, Appendix&nbsp;<a href="#A1.SS9" title="A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.9</span></a>. We include GPT-4 based evaluation results in Appendix&nbsp;<a href="#A1.SS6" title="A.6 Consistency between LLM-based Evaluators â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.6</span></a> to demonstrate the consistency of LLM-based evaluators. To mitigate position bias that the LLM evaluator may have, we conduct every evaluation twice by exchanging response orders. A response is considered better only if it wins twice. Following&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023b</a>)</cite>, we set the temperature to 0.0 to reduce evaluation randomness, and left other parameters as default.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p">Similar to prior work&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>; Zhao et&nbsp;al., <a href="#bib.bib53" title="" class="ltx_ref">2023</a>)</cite>, we compute the total ratio of wins and ties of a target LLM against the strong LLM, to indicate how much model capacity the target LLM recovers from the strong LLM (often treated as the upper bound performer). CRR simplifies the combinatorial pairwise comparisons between all target LLMs. We name the metric as <em id="S5.SS3.p4.1.1" class="ltx_emph ltx_font_italic">Capacity Recovery Ratio</em> (CRR), where <math id="S5.SS3.p4.1.m1.1" class="ltx_Math" alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" display="inline"><semantics id="S5.SS3.p4.1.m1.1a"><mrow id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.2" xref="S5.SS3.p4.1.m1.1.1.2a.cmml">CRR</mtext><mo id="S5.SS3.p4.1.m1.1.1.1" xref="S5.SS3.p4.1.m1.1.1.1.cmml">=</mo><mfrac id="S5.SS3.p4.1.m1.1.1.3" xref="S5.SS3.p4.1.m1.1.1.3.cmml"><mrow id="S5.SS3.p4.1.m1.1.1.3.2" xref="S5.SS3.p4.1.m1.1.1.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.3.2.2" xref="S5.SS3.p4.1.m1.1.1.3.2.2a.cmml">wins</mtext><mo id="S5.SS3.p4.1.m1.1.1.3.2.1" xref="S5.SS3.p4.1.m1.1.1.3.2.1.cmml">+</mo><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.3.2.3" xref="S5.SS3.p4.1.m1.1.1.3.2.3a.cmml">ties</mtext></mrow><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.3.3" xref="S5.SS3.p4.1.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><apply id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1"><eq id="S5.SS3.p4.1.m1.1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1.1"></eq><ci id="S5.SS3.p4.1.m1.1.1.2a.cmml" xref="S5.SS3.p4.1.m1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.2.cmml" xref="S5.SS3.p4.1.m1.1.1.2">CRR</mtext></ci><apply id="S5.SS3.p4.1.m1.1.1.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3"><divide id="S5.SS3.p4.1.m1.1.1.3.1.cmml" xref="S5.SS3.p4.1.m1.1.1.3"></divide><apply id="S5.SS3.p4.1.m1.1.1.3.2.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2"><plus id="S5.SS3.p4.1.m1.1.1.3.2.1.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.1"></plus><ci id="S5.SS3.p4.1.m1.1.1.3.2.2a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.2"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S5.SS3.p4.1.m1.1.1.3.2.2.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.2">wins</mtext></ci><ci id="S5.SS3.p4.1.m1.1.1.3.2.3a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S5.SS3.p4.1.m1.1.1.3.2.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.3">ties</mtext></ci></apply><ci id="S5.SS3.p4.1.m1.1.1.3.3a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S5.SS3.p4.1.m1.1.1.3.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation></semantics></math>. In experiments, we observe that the number of ties often dominates the number of wins, since the strong LLM is much capable than the target model. So we do not put additional weights on wins in the calculation. To demonstrate CRR faithfully reflects model performance, we show the exact number of wins, ties and losses in Appendix&nbsp;<a href="#A1.SS5" title="A.5 Detailed Comparison Results â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.5</span></a> on Evol-Instruct. We would like to emphasize our focus on the gap in CRR between different methods instead of the absolute value, since the absolute value may based on the specific LLM evaluator we choose.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Open-Domain Instruction Following</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p"><span id="S5.SS4.p1.1.1" class="ltx_text ltx_font_bold">Results with LLaMA-based Target LLMs.</span> Table&nbsp;<a href="#S5.T1" title="Table 1 â€£ 5.3 Experiment and Evaluation Details â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the performance of CodecLM and the comparing baselines with 2000 synthetic data for instruction tuning. All methods are trained on LLaMA-7B or -13B as the target LLM and compared against Gemini-Pro, the strong LLM that generates the data. CodecLM outperforms comparing methods consistently on all benchmarks, with two target LLMs of different sizes. The consistently superior performance of CodecLM highlights its generalizability to different downstream instruction distributions and target LLMs. Both Tree-Instruct and variants of WizardLM focus on the importance of instruction complexity, however, their performances are not always better than Alpagasus with simple instructions, especially with larger target LLM. This observation indicates that the effectiveness of data cannot be solely determined by instruction complexity, and validates the motivation of our design of Self-Rubrics and Contrastive Filtering. Moreover, the win of WizardLM+ over WizardLM confirms the efficacy of instruction distribution matching via instruction metadata. When shifting the target LLM from LLaMA-7B to -13B, all methods get a significant performance boost, which accords with prior discoveries on scaling model size&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a href="#bib.bib48" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para ltx_noindent">
<p id="S5.SS4.p2.1" class="ltx_p"><span id="S5.SS4.p2.1.1" class="ltx_text ltx_font_bold">Results with PaLM-based Models.</span> Table&nbsp;<a href="#S5.T2" title="Table 2 â€£ 5.4 Open-Domain Instruction Following â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes the results of CodecLM and the best performing baselines in LLaMA-based experiments. We generate 1000 synthetic data due to computation budget. Since text-bison is a proprietary model that has been aligned with various techniques including instruction tuning, we also include it as a baseline approach. Interestingly, text-bison obtains strong performance across different benchmarks. Both Alpagasus and WizardLM+ underperform text-bison, suggesting it is non-trivial to improve upon a well-tuned LLM continually. CodecLM, on the contrary, outperforms text-bison in most cases, thanks to our core designs that adaptively tailor high quality data pairs to improve the target LLM.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>CRR Results on PaLM-based models. Each method trains a target model based on text-bison, and compares against the strong model, text-unicorn.
</figcaption>
<div id="S5.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:274.0pt;height:92.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.3pt,7.6pt) scale(0.86,0.86) ;">
<table id="S5.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="S5.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="S5.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="4"><span id="S5.T2.1.1.1.1.2.1" class="ltx_text ltx_font_bold">text-bison vs. text-unicorn</span></th>
</tr>
<tr id="S5.T2.1.1.2.2" class="ltx_tr">
<th id="S5.T2.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.2.2.1.1" class="ltx_text ltx_font_bold">Evol-Ins.</span></th>
<th id="S5.T2.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.2.2.2.1" class="ltx_text ltx_font_bold">Vicuna</span></th>
<th id="S5.T2.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.2.2.3.1" class="ltx_text ltx_font_bold">Self-Ins.</span></th>
<th id="S5.T2.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.2.2.4.1" class="ltx_text ltx_font_bold">Koala</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.1.3.1" class="ltx_tr">
<th id="S5.T2.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">text-bison</th>
<td id="S5.T2.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">87.16</td>
<td id="S5.T2.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">81.25</td>
<td id="S5.T2.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.3.1.4.1" class="ltx_text ltx_font_bold">74.21</span></td>
<td id="S5.T2.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">77.47</td>
</tr>
<tr id="S5.T2.1.1.4.2" class="ltx_tr">
<th id="S5.T2.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" style="padding-left:3.0pt;padding-right:3.0pt;">Alpagasus</th>
<td id="S5.T2.1.1.4.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">82.11<span id="S5.T2.1.1.4.2.2.1" class="ltx_text" style="color:#FF0000;">(-5.1)</span>
</td>
<td id="S5.T2.1.1.4.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">81.25 <span id="S5.T2.1.1.4.2.3.1" class="ltx_text" style="color:#006B3D;">(+0.0)</span>
</td>
<td id="S5.T2.1.1.4.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">67.86 <span id="S5.T2.1.1.4.2.4.1" class="ltx_text" style="color:#FF0000;">(-6.4)</span>
</td>
<td id="S5.T2.1.1.4.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">73.33 <span id="S5.T2.1.1.4.2.5.1" class="ltx_text" style="color:#FF0000;">(-4.1)</span>
</td>
</tr>
<tr id="S5.T2.1.1.5.3" class="ltx_tr">
<th id="S5.T2.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" style="padding-left:3.0pt;padding-right:3.0pt;">WizardLM+</th>
<td id="S5.T2.1.1.5.3.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">84.40 <span id="S5.T2.1.1.5.3.2.1" class="ltx_text" style="color:#FF0000;">(-2.8)</span>
</td>
<td id="S5.T2.1.1.5.3.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">78.75 <span id="S5.T2.1.1.5.3.3.1" class="ltx_text" style="color:#FF0000;">(-2.5)</span>
</td>
<td id="S5.T2.1.1.5.3.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">69.44 <span id="S5.T2.1.1.5.3.4.1" class="ltx_text" style="color:#FF0000;">(-4.8)</span>
</td>
<td id="S5.T2.1.1.5.3.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">73.89 <span id="S5.T2.1.1.5.3.5.1" class="ltx_text" style="color:#FF0000;">(-3.6)</span>
</td>
</tr>
<tr id="S5.T2.1.1.6.4" class="ltx_tr">
<th id="S5.T2.1.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" style="padding-left:3.0pt;padding-right:3.0pt;">CodecLM (ours)</th>
<td id="S5.T2.1.1.6.4.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.6.4.2.1" class="ltx_text ltx_font_bold">88.53 <span id="S5.T2.1.1.6.4.2.1.1" class="ltx_text" style="color:#006B3D;">(+1.4)</span></span></td>
<td id="S5.T2.1.1.6.4.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.6.4.3.1" class="ltx_text ltx_font_bold">86.25 <span id="S5.T2.1.1.6.4.3.1.1" class="ltx_text" style="color:#006B3D;">(+5.0)</span></span></td>
<td id="S5.T2.1.1.6.4.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">72.22 <span id="S5.T2.1.1.6.4.4.1" class="ltx_text" style="color:#FF0000;">(-2.0)</span>
</td>
<td id="S5.T2.1.1.6.4.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.6.4.5.1" class="ltx_text ltx_font_bold">80.56 <span id="S5.T2.1.1.6.4.5.1.1" class="ltx_text" style="color:#006B3D;">(+3.1)</span></span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Ablation Study</h3>

<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation study of CodecLMâ€™s core designs. All components contribute to the final performance.</figcaption>
<div id="S5.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:224.0pt;height:76.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-19.8pt,6.8pt) scale(0.85,0.85) ;">
<table id="S5.T3.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.1.1.1.1" class="ltx_tr">
<td id="S5.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Metadata</span></td>
<td id="S5.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Self-Rubrics</span></td>
<td id="S5.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S5.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Contrastive Filtering</span></td>
<td id="S5.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.1.1.1.1.4.1" class="ltx_text ltx_font_bold">CRR</span></td>
</tr>
<tr id="S5.T3.1.1.2.2" class="ltx_tr">
<td id="S5.T3.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S5.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S5.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">âœ—</td>
<td id="S5.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">72.02</td>
</tr>
<tr id="S5.T3.1.1.3.3" class="ltx_tr">
<td id="S5.T3.1.1.3.3.1" class="ltx_td ltx_align_center">âœ“</td>
<td id="S5.T3.1.1.3.3.2" class="ltx_td ltx_align_center">âœ—</td>
<td id="S5.T3.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_rr">âœ—</td>
<td id="S5.T3.1.1.3.3.4" class="ltx_td ltx_align_center">75.23</td>
</tr>
<tr id="S5.T3.1.1.4.4" class="ltx_tr">
<td id="S5.T3.1.1.4.4.1" class="ltx_td ltx_align_center">âœ“</td>
<td id="S5.T3.1.1.4.4.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S5.T3.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_rr">âœ—</td>
<td id="S5.T3.1.1.4.4.4" class="ltx_td ltx_align_center">77.52</td>
</tr>
<tr id="S5.T3.1.1.5.5" class="ltx_tr">
<td id="S5.T3.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S5.T3.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S5.T3.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr">âœ“</td>
<td id="S5.T3.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_bb">79.82</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">In this section, we conduct comprehensive ablation studies to empirically explore the effectiveness of CodecLM. We mainly conduct experiments with LLaMA-7B model as the target LLM, Gemini-Pro as the strong LLM, and report the CRR on the Evol-Instruct benchmark.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para ltx_noindent">
<p id="S5.SS5.p2.1" class="ltx_p"><span id="S5.SS5.p2.1.1" class="ltx_text ltx_font_bold">Effectiveness of Core Designs.</span>
We show component-wise contributions in our framework in Table&nbsp;<a href="#S5.T3" title="Table 3 â€£ 5.5 Ablation Study â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The 1st row has the result from Self-Instruct as a baseline; In the 2nd row, we only align the LLM with basic instructions from instruction metadata; We gradually add Self-Rubrics and Contrastive Filtering in the 3rd and 4th rows, respectively. We clearly observe that every component contributes to the final performance. Interesting, the performance of using basic instructions from metadata is even on par with that of WizardLM+ in Table&nbsp;<a href="#S5.T1" title="Table 1 â€£ 5.3 Experiment and Evaluation Details â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. This observation indicates that human-crafted strategies for complicating instructions may not fit different types of instructions. On the contrary, Self-Rubrics adaptively generates instruction improving actions based on different metadata, resulting in better tailored instructions for the target LLM. Further improvements from Contrastive Filtering demonstrate that selected data are indeed more effective for alignment.</p>
</div>
<div id="S5.SS5.p3" class="ltx_para ltx_noindent">
<p id="S5.SS5.p3.2" class="ltx_p"><span id="S5.SS5.p3.2.1" class="ltx_text ltx_font_bold">Effect of Number of Iterations.</span> We demonstrate the effect of number of CodecLM iterations in Figure&nbsp;<a href="#S5.F3" title="Figure 3 â€£ 5.5 Ablation Study â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. In particular, we count the proportion of data from each iteration in all synthesized data <math id="S5.SS5.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{g}" display="inline"><semantics id="S5.SS5.p3.1.m1.1a"><msub id="S5.SS5.p3.1.m1.1.1" xref="S5.SS5.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p3.1.m1.1.1.2" xref="S5.SS5.p3.1.m1.1.1.2.cmml">ğ’Ÿ</mi><mi id="S5.SS5.p3.1.m1.1.1.3" xref="S5.SS5.p3.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.1.m1.1b"><apply id="S5.SS5.p3.1.m1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS5.p3.1.m1.1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1">subscript</csymbol><ci id="S5.SS5.p3.1.m1.1.1.2.cmml" xref="S5.SS5.p3.1.m1.1.1.2">ğ’Ÿ</ci><ci id="S5.SS5.p3.1.m1.1.1.3.cmml" xref="S5.SS5.p3.1.m1.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.1.m1.1c">\mathcal{D}_{g}</annotation></semantics></math> and show it in the blue bar chart with left y-axis. We also draw the target model performance in CRR after training on the synthetic data up until the current iteration in the yellow line chart with right y-axis. From the data proportion bar chart, we observe that more than <math id="S5.SS5.p3.2.m2.1" class="ltx_Math" alttext="70\%" display="inline"><semantics id="S5.SS5.p3.2.m2.1a"><mrow id="S5.SS5.p3.2.m2.1.1" xref="S5.SS5.p3.2.m2.1.1.cmml"><mn id="S5.SS5.p3.2.m2.1.1.2" xref="S5.SS5.p3.2.m2.1.1.2.cmml">70</mn><mo id="S5.SS5.p3.2.m2.1.1.1" xref="S5.SS5.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.2.m2.1b"><apply id="S5.SS5.p3.2.m2.1.1.cmml" xref="S5.SS5.p3.2.m2.1.1"><csymbol cd="latexml" id="S5.SS5.p3.2.m2.1.1.1.cmml" xref="S5.SS5.p3.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S5.SS5.p3.2.m2.1.1.2.cmml" xref="S5.SS5.p3.2.m2.1.1.2">70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.2.m2.1c">70\%</annotation></semantics></math> of the data comes from the first iteration. This indicates Contrastive Filtering successfully collects less complex yet challenging instructions, which are critical for building up the instruction-following ability of the target LLM. Starting from the second iteration, the data proportion gets increasingly small. However, similar to the <em id="S5.SS5.p3.2.2" class="ltx_emph ltx_font_italic">less is more for alignment</em> observation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a href="#bib.bib55" title="" class="ltx_ref">2023a</a>)</cite>, high-quality and more complex instructions indeed contribute to the final performance despite less in quantity.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2404.05875/assets/x3.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="205" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Data proportion from each iteration and the corresponding CRR performance at each iteration.</figcaption>
</figure>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2404.05875/assets/x4.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="133" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Metadata matching proportion vs. CRR.</figcaption>
</figure>
<div id="S5.SS5.p4" class="ltx_para ltx_noindent">
<p id="S5.SS5.p4.4" class="ltx_p"><span id="S5.SS5.p4.4.1" class="ltx_text ltx_font_bold">Exploration on Distribution Matching.</span> As shown by previous results, generating metadata extracted from the downstream instruction distribution indeed helps. However, in practice, the extracted or human-written metadata may not be able to precisely characterize the instruction distribution. Therefore, it is necessary to explore the performance of CodecLM when the distribution represented by instruction metadata does not fully match the test distribution. As the true test distribution is complicated and not known as a prior, we approximate various extent of distribution matching by random subsampling from the set of metadata <math id="S5.SS5.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S5.SS5.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p4.1.m1.1.1" xref="S5.SS5.p4.1.m1.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.1.m1.1b"><ci id="S5.SS5.p4.1.m1.1.1.cmml" xref="S5.SS5.p4.1.m1.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.1.m1.1c">\mathcal{M}</annotation></semantics></math>.
To control the effect of data quantity, we keep the total number of instruction-response pairs the same for each case. For example, when subsampling <math id="S5.SS5.p4.2.m2.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S5.SS5.p4.2.m2.1a"><mrow id="S5.SS5.p4.2.m2.1.1" xref="S5.SS5.p4.2.m2.1.1.cmml"><mn id="S5.SS5.p4.2.m2.1.1.2" xref="S5.SS5.p4.2.m2.1.1.2.cmml">20</mn><mo id="S5.SS5.p4.2.m2.1.1.1" xref="S5.SS5.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.2.m2.1b"><apply id="S5.SS5.p4.2.m2.1.1.cmml" xref="S5.SS5.p4.2.m2.1.1"><csymbol cd="latexml" id="S5.SS5.p4.2.m2.1.1.1.cmml" xref="S5.SS5.p4.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S5.SS5.p4.2.m2.1.1.2.cmml" xref="S5.SS5.p4.2.m2.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.2.m2.1c">20\%</annotation></semantics></math> of <math id="S5.SS5.p4.3.m3.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S5.SS5.p4.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p4.3.m3.1.1" xref="S5.SS5.p4.3.m3.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.3.m3.1b"><ci id="S5.SS5.p4.3.m3.1.1.cmml" xref="S5.SS5.p4.3.m3.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.3.m3.1c">\mathcal{M}</annotation></semantics></math>, we prompt the strong LLM to generate 5 times more instructions for each metadata accordingly. The result is shown in the upper part of Figure&nbsp;<a href="#S5.F4" title="Figure 4 â€£ 5.5 Ablation Study â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, and we did observe the trend that the better instruction metadata captures the underlying distribution, the better performance the target LLM can achieve. Moreover, when the metadata matching proportion is equal or greater than <math id="S5.SS5.p4.4.m4.1" class="ltx_Math" alttext="60\%" display="inline"><semantics id="S5.SS5.p4.4.m4.1a"><mrow id="S5.SS5.p4.4.m4.1.1" xref="S5.SS5.p4.4.m4.1.1.cmml"><mn id="S5.SS5.p4.4.m4.1.1.2" xref="S5.SS5.p4.4.m4.1.1.2.cmml">60</mn><mo id="S5.SS5.p4.4.m4.1.1.1" xref="S5.SS5.p4.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.4.m4.1b"><apply id="S5.SS5.p4.4.m4.1.1.cmml" xref="S5.SS5.p4.4.m4.1.1"><csymbol cd="latexml" id="S5.SS5.p4.4.m4.1.1.1.cmml" xref="S5.SS5.p4.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S5.SS5.p4.4.m4.1.1.2.cmml" xref="S5.SS5.p4.4.m4.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.4.m4.1c">60\%</annotation></semantics></math>, we obtain close performance as the fully-matched result. This observation highlights CodecLMâ€™s robustness under potential instruction metadata mismatch.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2404.05875/assets/x5.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="297" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Scaling with model size and data quantity.</figcaption>
</figure>
<div id="S5.SS5.p5" class="ltx_para">
<p id="S5.SS5.p5.1" class="ltx_p"><span id="S5.SS5.p5.1.1" class="ltx_text ltx_font_bold">Scaling with Model Size and Data Quantity.</span> To explore how our method scales with different synthetic data quantities and model sizes, we conduct experiments by comparing CodecLM with WizardLM+, the most competitive baseline. The experiment results on Evol-Instruct with LLaMA-7B and -13B as the target LLM are presented in Figure&nbsp;<a href="#S5.F5" title="Figure 5 â€£ 5.5 Ablation Study â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Both methods get increasingly better performance with more synthetic data and larger target models. CodecLM consistently outperforms WizardLM+ under all cases, demonstrating its great data efficiency and scalability. We expect the gain will gradually diminish after we generate more than 8k synthetic data, due to the intrinsic ability gap between the target models and the strong LLM.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we propose CodecLM to tailor synthetic data for LLM alignment with different target instruction distributions and LLMs. We show that CodecLM effectively captures the underlying instruction distribution via instruction metadata, and further tailor the most effective instruction-response pairs through Self-Rubrics and Contrastive Filtering. CodecLM provides a potent solution towards adapting LLMs for customized uses, without the necessity of human annotation. We believe CodecLM serves as a general framework for targeted LLM alignment, which opens the door to multiple promising research directions within the framework, such as richer metadata definition, better prompt design, and more reliable LLM-based scorer. CodecLM can also benefit from orthogonal research fields, and we continue the discussion in Ethical Considerations and Limitations sections.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethical Considerations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Although CodecLM serves as an effective data synthesis framework for LLM alignment, we should also reflect on the ethical impact of our work. Our method leverages LLMs to generate instruction-response pairs. Similar to human annotators who might make unconscious mistakes during the data annotation process, LLMs also sometimes generate unethical, toxic or misleading instructions and responses&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Bender et&nbsp;al., <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>. Moreover, as we train a target LLM using the generated data, the resulting instruction-tuned LLM might also carry the bias and fairness issues&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gallegos et&nbsp;al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> from the original model. Although we conducted manual inspection as specified in Appendix&nbsp;<a href="#A1.SS3" title="A.3 Additional Implementation Details â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a>, in practice, we should adopt existing techniques &nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hanu and Unitary team, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>; Thakur et&nbsp;al., <a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite> to detoxify and mitigate bias from LLMs used in CodecLM, and design more strict inspection and filtering rules to clean up the generated data. Due to the flexibility of our framework, we envision future progress in the domain of reducing bias and fairness issues can be complementary to CodecLM.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">We acknowledge the limitations of CodecLM from the following aspects to inspire future research opportunities in the field of LLM alignment.</p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p id="Sx2.p2.1" class="ltx_p">First of all, as discussed in the Ethical Considerations, our method requires a strong LLM to generate the data, so the performance of our method depends on the quality of the LLM and may inherit bias and fairness issues from it. On the other hand, CodecLM can benefit from stronger LLMs improved with advanced bias-reducing and fairness-enhancing approaches.</p>
</div>
<div id="Sx2.p3" class="ltx_para">
<p id="Sx2.p3.1" class="ltx_p">Secondly, as an orthogonal direction, our method did not explore robustness of the instruction-tuned model towards adversarial attacks such as prompt injection&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2023</a>)</cite> and jailbreaking&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zou et&nbsp;al., <a href="#bib.bib57" title="" class="ltx_ref">2023</a>)</cite>. In practice, we should apply adversarial defense techniques&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Jain et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2023</a>)</cite> accordingly to the instruction-tuned LLM from our method.</p>
</div>
<div id="Sx2.p4" class="ltx_para">
<p id="Sx2.p4.1" class="ltx_p">Moreover, we mainly use LLM-based automatic evaluation methods following recent works in data synthesis for alignment. Although recent studies&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>; Dubois et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite> demonstrate LLM-based evaluation is largely consistent with human evaluation, the scalability and reliability of LLM-based evaluators still have room for improvements. Although we include some standard benchmark results in Appendix&nbsp;<a href="#A1.SS7" title="A.7 Additional Benchmark Results â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.7</span></a> to complement LLM-based evaluation results, we still believe the progress in better evaluating LLMs can lead to a more reliable demonstration of the effectiveness of our method.</p>
</div>
<div id="Sx2.p5" class="ltx_para">
<p id="Sx2.p5.1" class="ltx_p">Finally, as shown in Section&nbsp;<a href="#S5.SS5" title="5.5 Ablation Study â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.5</span></a>, although CodecLM is robust to moderate distribution mismatch, its performance still depends on how well the metadata captures the underlying instruction distribution. In practice, our collected seed instruction might differ from the actual test instructions. Or in the case that we directly create metadata from user specification, the users might change their mind at test time to send the model out-of-distribution instructions beyond the original metadata. As a consequence, CodecLM may suffer performance degradation under distribution mismatch. As a remedy, we can constantly collect user instruction traffic or user feedback to update the generated data from CodecLM, and continuously update the target LLM.</p>
</div>
<div id="Sx2.p6" class="ltx_para">
<p id="Sx2.p6.1" class="ltx_p">We hope future work can leverage CodecLM as a flexible data synthesis framework for LLM alignment, so that advances in the field can be integrated into CodecLM to reduce its current limitations.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rohan Anil, Andrew&nbsp;M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,
Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen,
et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Palm 2 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.10403</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aribandi et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Vamsi Aribandi, Yi&nbsp;Tay, Tal Schuster, Jinfeng Rao, Huaixiu&nbsp;Steven Zheng,
Sanket&nbsp;Vaibhav Mehta, Honglei Zhuang, Vinh&nbsp;Q Tran, Dara Bahri, Jianmo Ni,
et&nbsp;al. 2021.

</span>
<span class="ltx_bibblock">Ext5: Towards extreme multi-task scaling for transfer learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.10952</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Training a helpful and harmless assistant with reinforcement learning
from human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.05862</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Emily&nbsp;M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
Shmitchell. 2021.

</span>
<span class="ltx_bibblock">On the dangers of stochastic parrots: Can language models be too big?

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 ACM conference on fairness,
accountability, and transparency</em>, pages 610â€“623.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beyer et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Lucas Beyer, Xiaohua Zhai, AmÃ©lie Royer, Larisa Markeeva, Rohan Anil, and
Alexander Kolesnikov. 2022.

</span>
<span class="ltx_bibblock">Knowledge distillation: A good teacher is patient and consistent.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pages 10925â€“10934.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
33:1877â€“1901.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Derek Chen, Celine Lee, Yunan Lu, Domenic Rosati, and Zhou Yu.
2023a.

</span>
<span class="ltx_bibblock">Mixture of soft prompts for controllable data generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.01580</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav,
Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et&nbsp;al.
2023b.

</span>
<span class="ltx_bibblock">Alpagasus: Training a better alpaca with fewer data.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.08701</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Zhuohan Li, Zi&nbsp;Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph&nbsp;E. Gonzalez, Ion Stoica, and
Eric&nbsp;P. Xing. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://lmsys.org/blog/2023-03-30-vicuna/" title="" class="ltx_ref ltx_href">Vicuna: An
open-source chatbot impressing gpt-4 with 90%* chatgpt quality</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus,
Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11416</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yi&nbsp;Dong, Zhilin Wang, Makesh&nbsp;Narsimhan Sreedhar, Xianchao Wu, and Oleksii
Kuchaiev. 2023.

</span>
<span class="ltx_bibblock">Steerlm: Attribute conditioned sft as an (user-steerable) alternative
to rlhf.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.05344</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubois et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba,
Carlos Guestrin, Percy Liang, and Tatsunori&nbsp;B Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Alpacafarm: A simulation framework for methods that learn from human
feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14387</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Efrat and Levy (2020)</span>
<span class="ltx_bibblock">
Avia Efrat and Omer Levy. 2020.

</span>
<span class="ltx_bibblock">The turking test: Can language models understand instructions?

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11982</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernando et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim
RocktÃ¤schel. 2023.

</span>
<span class="ltx_bibblock">Promptbreeder: Self-referential self-improvement via prompt
evolution.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.16797</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gallegos et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Isabel&nbsp;O Gallegos, Ryan&nbsp;A Rossi, Joe Barrow, Md&nbsp;Mehrab Tanjim, Sungchul Kim,
Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen&nbsp;K Ahmed. 2023.

</span>
<span class="ltx_bibblock">Bias and fairness in large language models: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.00770</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wallace, Pieter Abbeel, Sergey
Levine, and Dawn Song. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://bair.berkeley.edu/blog/2023/04/03/koala/" title="" class="ltx_ref ltx_href">Koala: A
dialogue model for academic research</a>.

</span>
<span class="ltx_bibblock">Blog post.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanu and Unitary team (2020)</span>
<span class="ltx_bibblock">
Laura Hanu and Unitary team. 2020.

</span>
<span class="ltx_bibblock">Detoxify.

</span>
<span class="ltx_bibblock">Github. https://github.com/unitaryai/detoxify.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn
Song, and Jacob Steinhardt. 2020.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.03300</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et&nbsp;al. (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1503.02531</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Or&nbsp;Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022.

</span>
<span class="ltx_bibblock">Unnatural instructions: Tuning language models with (almost) no human
labor.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.09689</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsieh et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii,
Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023.

</span>
<span class="ltx_bibblock">Distilling step-by-step! outperforming larger language models with
less training data and smaller model sizes.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.02301</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer,
Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, and Tom
Goldstein. 2023.

</span>
<span class="ltx_bibblock">Baseline defenses for adversarial attacks against aligned language
models.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.00614</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Welling (2013)</span>
<span class="ltx_bibblock">
Diederik&nbsp;P Kingma and Max Welling. 2013.

</span>
<span class="ltx_bibblock">Auto-encoding variational bayes.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6114</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">KÃ¶pf et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Andreas KÃ¶pf, Yannic Kilcher, Dimitri von RÃ¼tte, Sotiris Anagnostidis,
Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen&nbsp;Minh Duc, Oliver
Stanley, RichÃ¡rd Nagyfi, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Openassistant conversationsâ€“democratizing large language model
alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.07327</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kramer (1991)</span>
<span class="ltx_bibblock">
Mark&nbsp;A Kramer. 1991.

</span>
<span class="ltx_bibblock">Nonlinear principal component analysis using autoassociative neural
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">AIChE journal</em>, 37(2):233â€“243.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Gyeong-Geon Lee, Ehsan Latif, Xuansheng Wu, Ninghao Liu, and Xiaoming Zhai.
2023.

</span>
<span class="ltx_bibblock">Applying large language models and chain-of-thought for automatic
scoring.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.03748</em>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy,
Jason Weston, and Mike Lewis. 2023.

</span>
<span class="ltx_bibblock">Self-alignment with instruction backtranslation.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.06259</em>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Xiang&nbsp;Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori
Hashimoto, Luke Zettlemoyer, and Mike Lewis. 2022.

</span>
<span class="ltx_bibblock">Contrastive decoding: Open-ended text generation as optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.15097</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chen Liang, Simiao Zuo, Qingru Zhang, Pengcheng He, Weizhu Chen, and Tuo Zhao.
2023.

</span>
<span class="ltx_bibblock">Less is more: Task-aware layer-wise distillation for language model
compression.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
20852â€“20867. PMLR.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Alisa Liu, Swabha Swayamdipta, Noah&nbsp;A Smith, and Yejin Choi. 2022.

</span>
<span class="ltx_bibblock">Wanli: Worker and ai collaboration for natural language inference
dataset creation.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.05955</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yi&nbsp;Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu
Wang, Yan Zheng, and Yang Liu. 2023.

</span>
<span class="ltx_bibblock">Prompt injection attack against llm-integrated applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.05499</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaan et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah
Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et&nbsp;al.
2023.

</span>
<span class="ltx_bibblock">Self-refine: Iterative refinement with self-feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.17651</em>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yu&nbsp;Meng, Martin Michalski, Jiaxin Huang, Yu&nbsp;Zhang, Tarek Abdelzaher, and Jiawei
Han. 2023.

</span>
<span class="ltx_bibblock">Tuning language models as training data generators for
augmentation-enhanced few-shot learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
24457â€“24477. PMLR.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023a)</span>
<span class="ltx_bibblock">
OpenAI. 2023a.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2303.08774.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023b)</span>
<span class="ltx_bibblock">
OpenAI. 2023b.

</span>
<span class="ltx_bibblock">Introducing gpts.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openai.com/blog/introducing-gpts" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/blog/introducing-gpts</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
35:27730â€“27744.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023.

</span>
<span class="ltx_bibblock">Instruction tuning with gpt-4.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.03277</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">The Journal of Machine Learning Research</em>, 21(1):5485â€“5551.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick and SchÃ¼tze (2021)</span>
<span class="ltx_bibblock">
Timo Schick and Hinrich SchÃ¼tze. 2021.

</span>
<span class="ltx_bibblock">Generating datasets with pretrained language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.07540</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suzgun et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Mirac Suzgun, Nathan Scales, Nathanael SchÃ¤rli, Sebastian Gehrmann, Yi&nbsp;Tay,
Hyung&nbsp;Won Chung, Aakanksha Chowdhery, Quoc&nbsp;V Le, Ed&nbsp;H Chi, Denny Zhou, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock">Challenging big-bench tasks and whether chain-of-thought can solve
them.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.09261</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac,
Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew&nbsp;M Dai, Anja Hauth, et&nbsp;al.
2023.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.11805</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thakur et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, Paul&nbsp;Pu Liang, and
Louis-Philippe Morency. 2023.

</span>
<span class="ltx_bibblock">Language models get a gender makeover: Mitigating gender bias with
few-shot data interventions.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.04597</em>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric
Hambro, Faisal Azhar, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Victor et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Sanh Victor, Webson Albert, Raffel Colin, Bach Stephen, Sutawika Lintang,
Alyafeai Zaid, Chaffin Antoine, Stiegler Arnaud, Raja Arun, Dey Manan, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock">Multitask prompted training enables zero-shot task generalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot,
Khyathi&nbsp;Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah&nbsp;A Smith,
Iz&nbsp;Beltagy, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">How far can camels go? exploring the state of instruction tuning on
open resources.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.04751</em>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A Smith, Daniel
Khashabi, and Hannaneh Hajishirzi. 2022.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language model with self generated
instructions.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.10560</em>.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent&nbsp;Y Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian
Lester, Nan Du, Andrew&nbsp;M Dai, and Quoc&nbsp;V Le. 2021.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.01652</em>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed&nbsp;Chi, Quoc&nbsp;V
Le, Denny Zhou, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
35:24824â€“24837.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu&nbsp;Zhao, Jiazhan Feng, Chongyang
Tao, and Daxin Jiang. 2023.

</span>
<span class="ltx_bibblock">Wizardlm: Empowering large language models to follow complex
instructions.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.12244</em>.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc&nbsp;V Le, Denny Zhou, and
Xinyun Chen. 2023.

</span>
<span class="ltx_bibblock">Large language models as optimizers.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.03409</em>.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu&nbsp;Meng, Alexander Ratner, Ranjay Krishna,
Jiaming Shen, and Chao Zhang. 2023.

</span>
<span class="ltx_bibblock">Large language model as attributed training data generator: A tale of
diversity and bias.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.15895</em>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yingxiu Zhao, Bowen Yu, Binyuan Hui, Haiyang Yu, Fei Huang, Yongbin Li, and
Nevin&nbsp;L Zhang. 2023.

</span>
<span class="ltx_bibblock">A preliminary study of the intrinsic relationship between complexity
and alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.05696</em>.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao
Zhuang, Zi&nbsp;Lin, Zhuohan Li, Dacheng Li, Eric Xing, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.05685</em>.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe
Ma, Avia Efrat, Ping Yu, Lili Yu, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.11206</em>.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu,
Yi&nbsp;Luan, Denny Zhou, and Le&nbsp;Hou. 2023b.

</span>
<span class="ltx_bibblock">Instruction-following evaluation for large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.07911</em>.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Andy Zou, Zifan Wang, J.&nbsp;Zico Kolter, and Matt Fredrikson. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2307.15043" title="" class="ltx_ref ltx_href">Universal and transferable
adversarial attacks on aligned language models</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Benchmark Details</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">The details of the open-instruction following benchmarks are included below:</p>
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.1" class="ltx_p">Evol-Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite> includes 218 real-world human instructions from diverse sources such as online open-source projects, platforms, and forums.</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p">Vicuna&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite> includes 80 diverse instructions generated by GPT-4 through prompt engineering.</p>
</div>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i3.p1" class="ltx_para">
<p id="A1.I1.i3.p1.1" class="ltx_p">Self-Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> includes 252 expert-written instructions motivated by user-oriented applications.</p>
</div>
</li>
<li id="A1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i4.p1" class="ltx_para">
<p id="A1.I1.i4.p1.1" class="ltx_p">Koala&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Geng et&nbsp;al., <a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite> includes 180 conversation-style real user instructions that were posted online.</p>
</div>
</li>
</ul>
<p id="A1.SS1.p1.2" class="ltx_p">All these benchmarks consist of English instructions from multiple categories or tasks. However, though sharing some common use cases such as general knowledge QA and coding, the coverage of the instructions in different benchmarks are indeed different. For example, &nbsp;<cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite> discuss in detail how Evol-Instruct is different from Vicuna in instruction distribution. The difference between instruction distributions effectively mimic the practical scenario where we have different downstream tasks.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para">
<p id="A1.SS1.p2.1" class="ltx_p">The details of the additional standard NLP benchmarks are included below:</p>
<ul id="A1.I2" class="ltx_itemize">
<li id="A1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I2.i1.p1" class="ltx_para">
<p id="A1.I2.i1.p1.1" class="ltx_p">MMLU&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>, Massive Multitask Language Understanding, is a benchmark designed to measure capability of language models. It covers 57 subjects across STEM, the humanities, the social sciences, and more areas. We only use the test split for reporting the test results, and report the average score across all tasks.</p>
</div>
</li>
<li id="A1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I2.i2.p1" class="ltx_para">
<p id="A1.I2.i2.p1.1" class="ltx_p">BBH&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et&nbsp;al., <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite>, BIG-Bench-Hard, includes 23 challenging BIG-Bench tasks that prior language models did not outperform average human-raters.</p>
</div>
</li>
</ul>
</div>
<div id="A1.SS1.p3" class="ltx_para">
<p id="A1.SS1.p3.1" class="ltx_p">All benchmarks are publicly available for non-commercial research purposes, and we strictly limit their usage in this research work. We also carefully check these datasets and make sure that no personal information is involved.</p>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Baseline Details</h3>

<div id="A1.SS2.p1" class="ltx_para ltx_noindent">
<p id="A1.SS2.p1.1" class="ltx_p"><span id="A1.SS2.p1.1.1" class="ltx_text ltx_font_bold">Self-Instruct</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> generates instructions by prompting LLM with existing seed instructions as few-shot demonstrations. Here we randomly subsample the Alpaca&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>)</cite> dataset as seed instructions. Since Alpaca itself is based on Self-Instruct, using its subset as seed is a natural continuation of the Self-Instruct method.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para ltx_noindent">
<p id="A1.SS2.p2.1" class="ltx_p"><span id="A1.SS2.p2.1.1" class="ltx_text ltx_font_bold">Alpagasus</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023b</a>)</cite> selectively filters data using ChatGPT-based response quality evaluator. Closely following the original approach, we adopt the strategy upon instruction-response pairs generated by Self-Instruct.</p>
</div>
<div id="A1.SS2.p3" class="ltx_para ltx_noindent">
<p id="A1.SS2.p3.1" class="ltx_p"><span id="A1.SS2.p3.1.1" class="ltx_text ltx_font_bold">Tree-Instruct</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhao et&nbsp;al., <a href="#bib.bib53" title="" class="ltx_ref">2023</a>)</cite> improves instruction quality by prompting the LLM to implicitly complicate instruction through its semantic tree. Following the original paper, we use the subsampled Alpaca dataset as seed data. We set the number of tree nodes to 10 for best possible performance.</p>
</div>
<div id="A1.SS2.p4" class="ltx_para ltx_noindent">
<p id="A1.SS2.p4.1" class="ltx_p"><span id="A1.SS2.p4.1.1" class="ltx_text ltx_font_bold">WizardLM</span> <cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite> iteratively complicates instructions by prompting the LLM with a set of pre-defined evolution operations. Given the popularity and effectiveness of WizardLM, we experiment it with two variants: the original version using Alpaca as seed data, and the enhanced version uses the same set of basic instructions generated from CodecLM as seed data. We name the later variant as <span id="A1.SS2.p4.1.2" class="ltx_text ltx_font_bold">WizardLM+</span> as its enhanced by components of our framework.</p>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Additional Implementation Details</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.2" class="ltx_p">We augment the metadata to 200 by mix-and-matching use cases and skills from different instructions. We randomly sample one use case from <math id="A1.SS3.p1.1.m1.1" class="ltx_Math" alttext="\{u_{i}\}_{i=1}^{n}" display="inline"><semantics id="A1.SS3.p1.1.m1.1a"><msubsup id="A1.SS3.p1.1.m1.1.1" xref="A1.SS3.p1.1.m1.1.1.cmml"><mrow id="A1.SS3.p1.1.m1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="A1.SS3.p1.1.m1.1.1.1.1.1.2" xref="A1.SS3.p1.1.m1.1.1.1.1.2.cmml">{</mo><msub id="A1.SS3.p1.1.m1.1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.cmml"><mi id="A1.SS3.p1.1.m1.1.1.1.1.1.1.2" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.2.cmml">u</mi><mi id="A1.SS3.p1.1.m1.1.1.1.1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="A1.SS3.p1.1.m1.1.1.1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="A1.SS3.p1.1.m1.1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.1.3.cmml"><mi id="A1.SS3.p1.1.m1.1.1.1.3.2" xref="A1.SS3.p1.1.m1.1.1.1.3.2.cmml">i</mi><mo id="A1.SS3.p1.1.m1.1.1.1.3.1" xref="A1.SS3.p1.1.m1.1.1.1.3.1.cmml">=</mo><mn id="A1.SS3.p1.1.m1.1.1.1.3.3" xref="A1.SS3.p1.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="A1.SS3.p1.1.m1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.3.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.1.m1.1b"><apply id="A1.SS3.p1.1.m1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1">superscript</csymbol><apply id="A1.SS3.p1.1.m1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1">subscript</csymbol><set id="A1.SS3.p1.1.m1.1.1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1"><apply id="A1.SS3.p1.1.m1.1.1.1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="A1.SS3.p1.1.m1.1.1.1.1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.2">ğ‘¢</ci><ci id="A1.SS3.p1.1.m1.1.1.1.1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.3">ğ‘–</ci></apply></set><apply id="A1.SS3.p1.1.m1.1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3"><eq id="A1.SS3.p1.1.m1.1.1.1.3.1.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3.1"></eq><ci id="A1.SS3.p1.1.m1.1.1.1.3.2.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="A1.SS3.p1.1.m1.1.1.1.3.3.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="A1.SS3.p1.1.m1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.1.m1.1c">\{u_{i}\}_{i=1}^{n}</annotation></semantics></math>, and pair it with one or more skills sampled without replacement from <math id="A1.SS3.p1.2.m2.1" class="ltx_Math" alttext="\bigcup_{i=1}^{n}{\bm{s}}_{i}" display="inline"><semantics id="A1.SS3.p1.2.m2.1a"><mrow id="A1.SS3.p1.2.m2.1.1" xref="A1.SS3.p1.2.m2.1.1.cmml"><msubsup id="A1.SS3.p1.2.m2.1.1.1" xref="A1.SS3.p1.2.m2.1.1.1.cmml"><mo id="A1.SS3.p1.2.m2.1.1.1.2.2" xref="A1.SS3.p1.2.m2.1.1.1.2.2.cmml">â‹ƒ</mo><mrow id="A1.SS3.p1.2.m2.1.1.1.2.3" xref="A1.SS3.p1.2.m2.1.1.1.2.3.cmml"><mi id="A1.SS3.p1.2.m2.1.1.1.2.3.2" xref="A1.SS3.p1.2.m2.1.1.1.2.3.2.cmml">i</mi><mo id="A1.SS3.p1.2.m2.1.1.1.2.3.1" xref="A1.SS3.p1.2.m2.1.1.1.2.3.1.cmml">=</mo><mn id="A1.SS3.p1.2.m2.1.1.1.2.3.3" xref="A1.SS3.p1.2.m2.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="A1.SS3.p1.2.m2.1.1.1.3" xref="A1.SS3.p1.2.m2.1.1.1.3.cmml">n</mi></msubsup><msub id="A1.SS3.p1.2.m2.1.1.2" xref="A1.SS3.p1.2.m2.1.1.2.cmml"><mi id="A1.SS3.p1.2.m2.1.1.2.2" xref="A1.SS3.p1.2.m2.1.1.2.2.cmml">ğ’”</mi><mi id="A1.SS3.p1.2.m2.1.1.2.3" xref="A1.SS3.p1.2.m2.1.1.2.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.2.m2.1b"><apply id="A1.SS3.p1.2.m2.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1"><apply id="A1.SS3.p1.2.m2.1.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1">superscript</csymbol><apply id="A1.SS3.p1.2.m2.1.1.1.2.cmml" xref="A1.SS3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.1.2.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1">subscript</csymbol><union id="A1.SS3.p1.2.m2.1.1.1.2.2.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.2"></union><apply id="A1.SS3.p1.2.m2.1.1.1.2.3.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3"><eq id="A1.SS3.p1.2.m2.1.1.1.2.3.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3.1"></eq><ci id="A1.SS3.p1.2.m2.1.1.1.2.3.2.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3.2">ğ‘–</ci><cn type="integer" id="A1.SS3.p1.2.m2.1.1.1.2.3.3.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3.3">1</cn></apply></apply><ci id="A1.SS3.p1.2.m2.1.1.1.3.cmml" xref="A1.SS3.p1.2.m2.1.1.1.3">ğ‘›</ci></apply><apply id="A1.SS3.p1.2.m2.1.1.2.cmml" xref="A1.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.2.1.cmml" xref="A1.SS3.p1.2.m2.1.1.2">subscript</csymbol><ci id="A1.SS3.p1.2.m2.1.1.2.2.cmml" xref="A1.SS3.p1.2.m2.1.1.2.2">ğ’”</ci><ci id="A1.SS3.p1.2.m2.1.1.2.3.cmml" xref="A1.SS3.p1.2.m2.1.1.2.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.2.m2.1c">\bigcup_{i=1}^{n}{\bm{s}}_{i}</annotation></semantics></math>. Although most skills are generalizable between use cases, we still conduct manual sanity check to exclude unreasonable use case and skills pairs.
We align our hyperparameters for iteratively improving instructions via Self-Rubrics with prior work&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>: We generate 4 rubrics and corresponding actions, and at each iteration, we randomly choose 1 action for improving instruction. For fair comparison with WizardLM, we also use at most 4 improve iterations for each instruction (we count basic prompt generation as the first iteration). For Contrastive Filtering, we always use the strong LLM itself as the scorer. We set the scoring scale to 10 and the filtering threshold to 3 for all experiments. We obtain the threshold by developing on the AlpacaEval&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dubois et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite> dataset. And we find this threshold works generally well across different settings. Moreover, for LLaMA-based models, using their Alpaca&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>)</cite> counterparts as the target LLM for response generation in Contrastive Filtering works better than the original model that is not instruction tuned. For metadata extraction, base instruction generation and Self-Rubrics, we use a inference temperature of 0.7. We set the maximum number of tokens for generation to 2048 for LLaMA-based models, and 1024 for PaLM-based models due to API constraints. Moreover, although we set aside 20% validation set for metadata extraction, we still report the performance on the full test set in the main paper, the reasons are as follows: (1) We observe removing the validation set from the full test benchmark will not change the relative superior performance of our method, the performance gap between our method and baselines remains almost the same. Therefore, we keep them in for better reproducibility. (2) By carefully checking the generated instructions, we notice that none of the generated instructions overlap with the original validation instructions, so no data leaking happens during the data generation process.</p>
</div>
<div id="A1.SS3.p2" class="ltx_para">
<p id="A1.SS3.p2.1" class="ltx_p">We conduct manual inspection on the generated data to make sure no personal information or offensive contents are generated.</p>
</div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Training Details</h3>

<div id="A1.SS4.p1" class="ltx_para">
<p id="A1.SS4.p1.3" class="ltx_p">For LLaMA-based models, we follow the practices in instruction tuning in prior works&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a href="#bib.bib55" title="" class="ltx_ref">2023a</a>; Chen et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023b</a>)</cite>. We use AdamW optimizer with <math id="A1.SS4.p1.1.m1.2" class="ltx_Math" alttext="\beta_{1}=0.9,\beta_{2}=0.95" display="inline"><semantics id="A1.SS4.p1.1.m1.2a"><mrow id="A1.SS4.p1.1.m1.2.2.2" xref="A1.SS4.p1.1.m1.2.2.3.cmml"><mrow id="A1.SS4.p1.1.m1.1.1.1.1" xref="A1.SS4.p1.1.m1.1.1.1.1.cmml"><msub id="A1.SS4.p1.1.m1.1.1.1.1.2" xref="A1.SS4.p1.1.m1.1.1.1.1.2.cmml"><mi id="A1.SS4.p1.1.m1.1.1.1.1.2.2" xref="A1.SS4.p1.1.m1.1.1.1.1.2.2.cmml">Î²</mi><mn id="A1.SS4.p1.1.m1.1.1.1.1.2.3" xref="A1.SS4.p1.1.m1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="A1.SS4.p1.1.m1.1.1.1.1.1" xref="A1.SS4.p1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="A1.SS4.p1.1.m1.1.1.1.1.3" xref="A1.SS4.p1.1.m1.1.1.1.1.3.cmml">0.9</mn></mrow><mo id="A1.SS4.p1.1.m1.2.2.2.3" xref="A1.SS4.p1.1.m1.2.2.3a.cmml">,</mo><mrow id="A1.SS4.p1.1.m1.2.2.2.2" xref="A1.SS4.p1.1.m1.2.2.2.2.cmml"><msub id="A1.SS4.p1.1.m1.2.2.2.2.2" xref="A1.SS4.p1.1.m1.2.2.2.2.2.cmml"><mi id="A1.SS4.p1.1.m1.2.2.2.2.2.2" xref="A1.SS4.p1.1.m1.2.2.2.2.2.2.cmml">Î²</mi><mn id="A1.SS4.p1.1.m1.2.2.2.2.2.3" xref="A1.SS4.p1.1.m1.2.2.2.2.2.3.cmml">2</mn></msub><mo id="A1.SS4.p1.1.m1.2.2.2.2.1" xref="A1.SS4.p1.1.m1.2.2.2.2.1.cmml">=</mo><mn id="A1.SS4.p1.1.m1.2.2.2.2.3" xref="A1.SS4.p1.1.m1.2.2.2.2.3.cmml">0.95</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.1.m1.2b"><apply id="A1.SS4.p1.1.m1.2.2.3.cmml" xref="A1.SS4.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.2.2.3a.cmml" xref="A1.SS4.p1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="A1.SS4.p1.1.m1.1.1.1.1.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1"><eq id="A1.SS4.p1.1.m1.1.1.1.1.1.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.1"></eq><apply id="A1.SS4.p1.1.m1.1.1.1.1.2.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.1.1.1.1.2.1.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2">subscript</csymbol><ci id="A1.SS4.p1.1.m1.1.1.1.1.2.2.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2.2">ğ›½</ci><cn type="integer" id="A1.SS4.p1.1.m1.1.1.1.1.2.3.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2.3">1</cn></apply><cn type="float" id="A1.SS4.p1.1.m1.1.1.1.1.3.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.3">0.9</cn></apply><apply id="A1.SS4.p1.1.m1.2.2.2.2.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2"><eq id="A1.SS4.p1.1.m1.2.2.2.2.1.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.1"></eq><apply id="A1.SS4.p1.1.m1.2.2.2.2.2.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.2.2.2.2.2.1.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="A1.SS4.p1.1.m1.2.2.2.2.2.2.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2.2">ğ›½</ci><cn type="integer" id="A1.SS4.p1.1.m1.2.2.2.2.2.3.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2.3">2</cn></apply><cn type="float" id="A1.SS4.p1.1.m1.2.2.2.2.3.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.3">0.95</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.1.m1.2c">\beta_{1}=0.9,\beta_{2}=0.95</annotation></semantics></math> to finetune the target model for 15 epochs, as suggested by <cite class="ltx_cite ltx_citemacro_citet">Zhou et&nbsp;al. (<a href="#bib.bib55" title="" class="ltx_ref">2023a</a>)</cite> for smaller data size.
We set the initial learning rate to <math id="A1.SS4.p1.2.m2.1" class="ltx_Math" alttext="1\times 10^{-5}" display="inline"><semantics id="A1.SS4.p1.2.m2.1a"><mrow id="A1.SS4.p1.2.m2.1.1" xref="A1.SS4.p1.2.m2.1.1.cmml"><mn id="A1.SS4.p1.2.m2.1.1.2" xref="A1.SS4.p1.2.m2.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS4.p1.2.m2.1.1.1" xref="A1.SS4.p1.2.m2.1.1.1.cmml">Ã—</mo><msup id="A1.SS4.p1.2.m2.1.1.3" xref="A1.SS4.p1.2.m2.1.1.3.cmml"><mn id="A1.SS4.p1.2.m2.1.1.3.2" xref="A1.SS4.p1.2.m2.1.1.3.2.cmml">10</mn><mrow id="A1.SS4.p1.2.m2.1.1.3.3" xref="A1.SS4.p1.2.m2.1.1.3.3.cmml"><mo id="A1.SS4.p1.2.m2.1.1.3.3a" xref="A1.SS4.p1.2.m2.1.1.3.3.cmml">âˆ’</mo><mn id="A1.SS4.p1.2.m2.1.1.3.3.2" xref="A1.SS4.p1.2.m2.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.2.m2.1b"><apply id="A1.SS4.p1.2.m2.1.1.cmml" xref="A1.SS4.p1.2.m2.1.1"><times id="A1.SS4.p1.2.m2.1.1.1.cmml" xref="A1.SS4.p1.2.m2.1.1.1"></times><cn type="integer" id="A1.SS4.p1.2.m2.1.1.2.cmml" xref="A1.SS4.p1.2.m2.1.1.2">1</cn><apply id="A1.SS4.p1.2.m2.1.1.3.cmml" xref="A1.SS4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="A1.SS4.p1.2.m2.1.1.3.1.cmml" xref="A1.SS4.p1.2.m2.1.1.3">superscript</csymbol><cn type="integer" id="A1.SS4.p1.2.m2.1.1.3.2.cmml" xref="A1.SS4.p1.2.m2.1.1.3.2">10</cn><apply id="A1.SS4.p1.2.m2.1.1.3.3.cmml" xref="A1.SS4.p1.2.m2.1.1.3.3"><minus id="A1.SS4.p1.2.m2.1.1.3.3.1.cmml" xref="A1.SS4.p1.2.m2.1.1.3.3"></minus><cn type="integer" id="A1.SS4.p1.2.m2.1.1.3.3.2.cmml" xref="A1.SS4.p1.2.m2.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.2.m2.1c">1\times 10^{-5}</annotation></semantics></math> and linearly decaying to <math id="A1.SS4.p1.3.m3.1" class="ltx_Math" alttext="1\times 10^{-6}" display="inline"><semantics id="A1.SS4.p1.3.m3.1a"><mrow id="A1.SS4.p1.3.m3.1.1" xref="A1.SS4.p1.3.m3.1.1.cmml"><mn id="A1.SS4.p1.3.m3.1.1.2" xref="A1.SS4.p1.3.m3.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS4.p1.3.m3.1.1.1" xref="A1.SS4.p1.3.m3.1.1.1.cmml">Ã—</mo><msup id="A1.SS4.p1.3.m3.1.1.3" xref="A1.SS4.p1.3.m3.1.1.3.cmml"><mn id="A1.SS4.p1.3.m3.1.1.3.2" xref="A1.SS4.p1.3.m3.1.1.3.2.cmml">10</mn><mrow id="A1.SS4.p1.3.m3.1.1.3.3" xref="A1.SS4.p1.3.m3.1.1.3.3.cmml"><mo id="A1.SS4.p1.3.m3.1.1.3.3a" xref="A1.SS4.p1.3.m3.1.1.3.3.cmml">âˆ’</mo><mn id="A1.SS4.p1.3.m3.1.1.3.3.2" xref="A1.SS4.p1.3.m3.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.3.m3.1b"><apply id="A1.SS4.p1.3.m3.1.1.cmml" xref="A1.SS4.p1.3.m3.1.1"><times id="A1.SS4.p1.3.m3.1.1.1.cmml" xref="A1.SS4.p1.3.m3.1.1.1"></times><cn type="integer" id="A1.SS4.p1.3.m3.1.1.2.cmml" xref="A1.SS4.p1.3.m3.1.1.2">1</cn><apply id="A1.SS4.p1.3.m3.1.1.3.cmml" xref="A1.SS4.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A1.SS4.p1.3.m3.1.1.3.1.cmml" xref="A1.SS4.p1.3.m3.1.1.3">superscript</csymbol><cn type="integer" id="A1.SS4.p1.3.m3.1.1.3.2.cmml" xref="A1.SS4.p1.3.m3.1.1.3.2">10</cn><apply id="A1.SS4.p1.3.m3.1.1.3.3.cmml" xref="A1.SS4.p1.3.m3.1.1.3.3"><minus id="A1.SS4.p1.3.m3.1.1.3.3.1.cmml" xref="A1.SS4.p1.3.m3.1.1.3.3"></minus><cn type="integer" id="A1.SS4.p1.3.m3.1.1.3.3.2.cmml" xref="A1.SS4.p1.3.m3.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.3.m3.1c">1\times 10^{-6}</annotation></semantics></math> by the end of training. We set per GPU batch size to 8, which is equivalent to a total batch size of 64,
as we use 8 A100 GPUs for training. The maximum token length is set to 2048.</p>
</div>
<div id="A1.SS4.p2" class="ltx_para">
<p id="A1.SS4.p2.1" class="ltx_p">For PaLM-based models, we follow the default instruction tuning setting on Google Cloudâ€™s LLM tuning web UI. We set the number of tuning steps to 2000, the learning rate multiplier to 1, and use the TPU training option.</p>
</div>
<figure id="A1.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Additional results on standard benchmarks.</figcaption>
<div id="A1.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:212.4pt;height:88.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.2pt,0.9pt) scale(0.98,0.98) ;">
<table id="A1.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T4.1.1.1.1" class="ltx_tr">
<th id="A1.T4.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt"><span id="A1.T4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="A1.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.1.1.1.1.2.1" class="ltx_text ltx_font_bold">BBH</span></th>
<th id="A1.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.1.1.1.1.3.1" class="ltx_text ltx_font_bold">MMLU</span></th>
<th id="A1.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Average</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T4.1.1.2.1" class="ltx_tr">
<th id="A1.T4.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t">LLaMA-7B</th>
<td id="A1.T4.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">30.93</td>
<td id="A1.T4.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">35.17</td>
<td id="A1.T4.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">33.05</td>
</tr>
<tr id="A1.T4.1.1.3.2" class="ltx_tr">
<th id="A1.T4.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr">Alpagasus</th>
<td id="A1.T4.1.1.3.2.2" class="ltx_td ltx_align_center">31.55</td>
<td id="A1.T4.1.1.3.2.3" class="ltx_td ltx_align_center">36.46</td>
<td id="A1.T4.1.1.3.2.4" class="ltx_td ltx_align_center">34.01</td>
</tr>
<tr id="A1.T4.1.1.4.3" class="ltx_tr">
<th id="A1.T4.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr">WizardLM+</th>
<td id="A1.T4.1.1.4.3.2" class="ltx_td ltx_align_center">31.72</td>
<td id="A1.T4.1.1.4.3.3" class="ltx_td ltx_align_center">37.89</td>
<td id="A1.T4.1.1.4.3.4" class="ltx_td ltx_align_center">34.81</td>
</tr>
<tr id="A1.T4.1.1.5.4" class="ltx_tr">
<th id="A1.T4.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_rr">CodecLM (ours)</th>
<td id="A1.T4.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T4.1.1.5.4.2.1" class="ltx_text ltx_font_bold">32.60</span></td>
<td id="A1.T4.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T4.1.1.5.4.3.1" class="ltx_text ltx_font_bold">42.67</span></td>
<td id="A1.T4.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T4.1.1.5.4.4.1" class="ltx_text ltx_font_bold">37.64</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Detailed Comparison Results</h3>

<div id="A1.SS5.p1" class="ltx_para">
<p id="A1.SS5.p1.1" class="ltx_p">We show the details of pairwise comparison on Evol-Instruct benchmark with LLaMA-based models, as a demonstration of how CRR faithfully reflects the capability of the target LLMs trained by different methods. In Table&nbsp;<a href="#A1.T5" title="Table 5 â€£ A.5 Detailed Comparison Results â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we observe that number of ties dominates the results and the number of wins are scarce. We attribute it to the fact that the target model is essentially distilling knowledge from the strong model. As a result, most of the time, the instruction-tuned target model is only able to respond as good as the strong model, through the lens of the LLM-based evaluator.</p>
</div>
<figure id="A1.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Detailed comparison results with LLaMA-based models on Evol-Instruct benchmark. Each method trains a target model based on LLaMA-7B or -13B, and compares against the strong model, Gemini-Pro. Capacity Recovery Ratio (%), <math id="A1.T5.2.m1.1" class="ltx_Math" alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" display="inline"><semantics id="A1.T5.2.m1.1b"><mrow id="A1.T5.2.m1.1.1" xref="A1.T5.2.m1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.2" xref="A1.T5.2.m1.1.1.2a.cmml">CRR</mtext><mo id="A1.T5.2.m1.1.1.1" xref="A1.T5.2.m1.1.1.1.cmml">=</mo><mfrac id="A1.T5.2.m1.1.1.3" xref="A1.T5.2.m1.1.1.3.cmml"><mrow id="A1.T5.2.m1.1.1.3.2" xref="A1.T5.2.m1.1.1.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.2.2" xref="A1.T5.2.m1.1.1.3.2.2a.cmml">wins</mtext><mo id="A1.T5.2.m1.1.1.3.2.1" xref="A1.T5.2.m1.1.1.3.2.1.cmml">+</mo><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.2.3" xref="A1.T5.2.m1.1.1.3.2.3a.cmml">ties</mtext></mrow><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.3" xref="A1.T5.2.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.2.m1.1c"><apply id="A1.T5.2.m1.1.1.cmml" xref="A1.T5.2.m1.1.1"><eq id="A1.T5.2.m1.1.1.1.cmml" xref="A1.T5.2.m1.1.1.1"></eq><ci id="A1.T5.2.m1.1.1.2a.cmml" xref="A1.T5.2.m1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.2.cmml" xref="A1.T5.2.m1.1.1.2">CRR</mtext></ci><apply id="A1.T5.2.m1.1.1.3.cmml" xref="A1.T5.2.m1.1.1.3"><divide id="A1.T5.2.m1.1.1.3.1.cmml" xref="A1.T5.2.m1.1.1.3"></divide><apply id="A1.T5.2.m1.1.1.3.2.cmml" xref="A1.T5.2.m1.1.1.3.2"><plus id="A1.T5.2.m1.1.1.3.2.1.cmml" xref="A1.T5.2.m1.1.1.3.2.1"></plus><ci id="A1.T5.2.m1.1.1.3.2.2a.cmml" xref="A1.T5.2.m1.1.1.3.2.2"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="A1.T5.2.m1.1.1.3.2.2.cmml" xref="A1.T5.2.m1.1.1.3.2.2">wins</mtext></ci><ci id="A1.T5.2.m1.1.1.3.2.3a.cmml" xref="A1.T5.2.m1.1.1.3.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="A1.T5.2.m1.1.1.3.2.3.cmml" xref="A1.T5.2.m1.1.1.3.2.3">ties</mtext></ci></apply><ci id="A1.T5.2.m1.1.1.3.3a.cmml" xref="A1.T5.2.m1.1.1.3.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="A1.T5.2.m1.1.1.3.3.cmml" xref="A1.T5.2.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.2.m1.1d">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation></semantics></math>.
</figcaption>
<div id="A1.T5.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:336.5pt;height:132.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.6pt,5.8pt) scale(0.92,0.92) ;">
<table id="A1.T5.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T5.3.1.1.1" class="ltx_tr">
<th id="A1.T5.3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt" rowspan="2"><span id="A1.T5.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<td id="A1.T5.3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="4"><span id="A1.T5.3.1.1.1.2.1" class="ltx_text ltx_font_bold">LLaMA-7B vs. Gemini-Pro</span></td>
<td id="A1.T5.3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="A1.T5.3.1.1.1.3.1" class="ltx_text ltx_font_bold">LLaMA-13B vs. Gemini-Pro</span></td>
</tr>
<tr id="A1.T5.3.1.2.2" class="ltx_tr">
<td id="A1.T5.3.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.1.1" class="ltx_text ltx_font_bold">Wins</span></td>
<td id="A1.T5.3.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.2.1" class="ltx_text ltx_font_bold">Ties</span></td>
<td id="A1.T5.3.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.3.1" class="ltx_text ltx_font_bold">Losses</span></td>
<td id="A1.T5.3.1.2.2.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="A1.T5.3.1.2.2.4.1" class="ltx_text ltx_font_bold">CRR</span></td>
<td id="A1.T5.3.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.5.1" class="ltx_text ltx_font_bold">Wins</span></td>
<td id="A1.T5.3.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.6.1" class="ltx_text ltx_font_bold">Ties</span></td>
<td id="A1.T5.3.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.7.1" class="ltx_text ltx_font_bold">Losses</span></td>
<td id="A1.T5.3.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.8.1" class="ltx_text ltx_font_bold">CRR</span></td>
</tr>
<tr id="A1.T5.3.1.3.3" class="ltx_tr">
<th id="A1.T5.3.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t">Self-Instruct</th>
<td id="A1.T5.3.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">17</td>
<td id="A1.T5.3.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">140</td>
<td id="A1.T5.3.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">61</td>
<td id="A1.T5.3.1.3.3.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">72.02</td>
<td id="A1.T5.3.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">29</td>
<td id="A1.T5.3.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">136</td>
<td id="A1.T5.3.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">53</td>
<td id="A1.T5.3.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t">75.69</td>
</tr>
<tr id="A1.T5.3.1.4.4" class="ltx_tr">
<th id="A1.T5.3.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Alpagasus</th>
<td id="A1.T5.3.1.4.4.2" class="ltx_td ltx_align_center">17</td>
<td id="A1.T5.3.1.4.4.3" class="ltx_td ltx_align_center">147</td>
<td id="A1.T5.3.1.4.4.4" class="ltx_td ltx_align_center">54</td>
<td id="A1.T5.3.1.4.4.5" class="ltx_td ltx_align_center ltx_border_rr">75.23</td>
<td id="A1.T5.3.1.4.4.6" class="ltx_td ltx_align_center">26</td>
<td id="A1.T5.3.1.4.4.7" class="ltx_td ltx_align_center">148</td>
<td id="A1.T5.3.1.4.4.8" class="ltx_td ltx_align_center">44</td>
<td id="A1.T5.3.1.4.4.9" class="ltx_td ltx_align_center">79.82</td>
</tr>
<tr id="A1.T5.3.1.5.5" class="ltx_tr">
<th id="A1.T5.3.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Tree-Instruct</th>
<td id="A1.T5.3.1.5.5.2" class="ltx_td ltx_align_center">23</td>
<td id="A1.T5.3.1.5.5.3" class="ltx_td ltx_align_center">141</td>
<td id="A1.T5.3.1.5.5.4" class="ltx_td ltx_align_center">54</td>
<td id="A1.T5.3.1.5.5.5" class="ltx_td ltx_align_center ltx_border_rr">75.23</td>
<td id="A1.T5.3.1.5.5.6" class="ltx_td ltx_align_center">26</td>
<td id="A1.T5.3.1.5.5.7" class="ltx_td ltx_align_center">154</td>
<td id="A1.T5.3.1.5.5.8" class="ltx_td ltx_align_center">38</td>
<td id="A1.T5.3.1.5.5.9" class="ltx_td ltx_align_center">82.57</td>
</tr>
<tr id="A1.T5.3.1.6.6" class="ltx_tr">
<th id="A1.T5.3.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM</th>
<td id="A1.T5.3.1.6.6.2" class="ltx_td ltx_align_center">19</td>
<td id="A1.T5.3.1.6.6.3" class="ltx_td ltx_align_center">143</td>
<td id="A1.T5.3.1.6.6.4" class="ltx_td ltx_align_center">56</td>
<td id="A1.T5.3.1.6.6.5" class="ltx_td ltx_align_center ltx_border_rr">74.31</td>
<td id="A1.T5.3.1.6.6.6" class="ltx_td ltx_align_center">30</td>
<td id="A1.T5.3.1.6.6.7" class="ltx_td ltx_align_center">149</td>
<td id="A1.T5.3.1.6.6.8" class="ltx_td ltx_align_center">39</td>
<td id="A1.T5.3.1.6.6.9" class="ltx_td ltx_align_center">82.11</td>
</tr>
<tr id="A1.T5.3.1.7.7" class="ltx_tr">
<th id="A1.T5.3.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM+</th>
<td id="A1.T5.3.1.7.7.2" class="ltx_td ltx_align_center">19</td>
<td id="A1.T5.3.1.7.7.3" class="ltx_td ltx_align_center">146</td>
<td id="A1.T5.3.1.7.7.4" class="ltx_td ltx_align_center">53</td>
<td id="A1.T5.3.1.7.7.5" class="ltx_td ltx_align_center ltx_border_rr">75.69</td>
<td id="A1.T5.3.1.7.7.6" class="ltx_td ltx_align_center">31</td>
<td id="A1.T5.3.1.7.7.7" class="ltx_td ltx_align_center">153</td>
<td id="A1.T5.3.1.7.7.8" class="ltx_td ltx_align_center">34</td>
<td id="A1.T5.3.1.7.7.9" class="ltx_td ltx_align_center">84.40</td>
</tr>
<tr id="A1.T5.3.1.8.8" class="ltx_tr">
<th id="A1.T5.3.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr">CodecLM (ours)</th>
<td id="A1.T5.3.1.8.8.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.2.1" class="ltx_text ltx_font_bold">29</span></td>
<td id="A1.T5.3.1.8.8.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.3.1" class="ltx_text ltx_font_bold">145</span></td>
<td id="A1.T5.3.1.8.8.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.4.1" class="ltx_text ltx_font_bold">44</span></td>
<td id="A1.T5.3.1.8.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr"><span id="A1.T5.3.1.8.8.5.1" class="ltx_text ltx_font_bold">79.82</span></td>
<td id="A1.T5.3.1.8.8.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.6.1" class="ltx_text ltx_font_bold">35</span></td>
<td id="A1.T5.3.1.8.8.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.7.1" class="ltx_text ltx_font_bold">154</span></td>
<td id="A1.T5.3.1.8.8.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.8.1" class="ltx_text ltx_font_bold">29</span></td>
<td id="A1.T5.3.1.8.8.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.9.1" class="ltx_text ltx_font_bold">86.70</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="A1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Consistency between LLM-based Evaluators</h3>

<figure id="A1.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance gap to Self-Instruct in terms of CRR on Evol-Instruct, evaluated by ChatGPT and GPT4, respectively. Each method trains a target model based on LLaMA-7B or -13B, and compares against the strong model, Gemini-Pro. We observe two LLM-based automatic evaluators yields consistent results.
</figcaption>
<div id="A1.T6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:254.0pt;height:132.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.0pt,5.8pt) scale(0.92,0.92) ;">
<table id="A1.T6.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T6.1.1.1.1" class="ltx_tr">
<th id="A1.T6.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" rowspan="2"><span id="A1.T6.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="A1.T6.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_tt" colspan="2"><span id="A1.T6.1.1.1.1.2.1" class="ltx_text ltx_font_bold">LLaMA-7B vs. Gemini-Pro</span></th>
<th id="A1.T6.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="A1.T6.1.1.1.1.3.1" class="ltx_text ltx_font_bold">LLaMA-13B vs. Gemini-Pro</span></th>
</tr>
<tr id="A1.T6.1.1.2.2" class="ltx_tr">
<th id="A1.T6.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T6.1.1.2.2.1.1" class="ltx_text ltx_font_bold">ChatGPT</span></th>
<th id="A1.T6.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t"><span id="A1.T6.1.1.2.2.2.1" class="ltx_text ltx_font_bold">GPT4</span></th>
<th id="A1.T6.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T6.1.1.2.2.3.1" class="ltx_text ltx_font_bold">ChatGPT</span></th>
<th id="A1.T6.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T6.1.1.2.2.4.1" class="ltx_text ltx_font_bold">GPT4</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T6.1.1.3.1" class="ltx_tr">
<th id="A1.T6.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t">Self-Instruct</th>
<td id="A1.T6.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="A1.T6.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.00</td>
<td id="A1.T6.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="A1.T6.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
</tr>
<tr id="A1.T6.1.1.4.2" class="ltx_tr">
<th id="A1.T6.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Alpagasus</th>
<td id="A1.T6.1.1.4.2.2" class="ltx_td ltx_align_center">+3.21</td>
<td id="A1.T6.1.1.4.2.3" class="ltx_td ltx_align_center ltx_border_rr">+1.38</td>
<td id="A1.T6.1.1.4.2.4" class="ltx_td ltx_align_center">+4.13</td>
<td id="A1.T6.1.1.4.2.5" class="ltx_td ltx_align_center">+1.83</td>
</tr>
<tr id="A1.T6.1.1.5.3" class="ltx_tr">
<th id="A1.T6.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Tree-Instruct</th>
<td id="A1.T6.1.1.5.3.2" class="ltx_td ltx_align_center">+3.21</td>
<td id="A1.T6.1.1.5.3.3" class="ltx_td ltx_align_center ltx_border_rr">+2.29</td>
<td id="A1.T6.1.1.5.3.4" class="ltx_td ltx_align_center">+6.88</td>
<td id="A1.T6.1.1.5.3.5" class="ltx_td ltx_align_center">+4.59</td>
</tr>
<tr id="A1.T6.1.1.6.4" class="ltx_tr">
<th id="A1.T6.1.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM</th>
<td id="A1.T6.1.1.6.4.2" class="ltx_td ltx_align_center">+2.29</td>
<td id="A1.T6.1.1.6.4.3" class="ltx_td ltx_align_center ltx_border_rr">+0.46</td>
<td id="A1.T6.1.1.6.4.4" class="ltx_td ltx_align_center">+6.42</td>
<td id="A1.T6.1.1.6.4.5" class="ltx_td ltx_align_center">+3.21</td>
</tr>
<tr id="A1.T6.1.1.7.5" class="ltx_tr">
<th id="A1.T6.1.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM+</th>
<td id="A1.T6.1.1.7.5.2" class="ltx_td ltx_align_center">+3.67</td>
<td id="A1.T6.1.1.7.5.3" class="ltx_td ltx_align_center ltx_border_rr">+2.29</td>
<td id="A1.T6.1.1.7.5.4" class="ltx_td ltx_align_center">+8.72</td>
<td id="A1.T6.1.1.7.5.5" class="ltx_td ltx_align_center">+5.50</td>
</tr>
<tr id="A1.T6.1.1.8.6" class="ltx_tr">
<th id="A1.T6.1.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr">CodecLM (ours)</th>
<td id="A1.T6.1.1.8.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T6.1.1.8.6.2.1" class="ltx_text ltx_font_bold">+7.80</span></td>
<td id="A1.T6.1.1.8.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr"><span id="A1.T6.1.1.8.6.3.1" class="ltx_text ltx_font_bold">+8.26</span></td>
<td id="A1.T6.1.1.8.6.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T6.1.1.8.6.4.1" class="ltx_text ltx_font_bold">+11.01</span></td>
<td id="A1.T6.1.1.8.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T6.1.1.8.6.5.1" class="ltx_text ltx_font_bold">+8.72</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="A1.SS6.p1" class="ltx_para">
<p id="A1.SS6.p1.1" class="ltx_p">In the main paper, we use ChatGPT as the LLM judge for final evaluation, for its efficiency, price and accessibility for the community to reproduce our results. As pointed out in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite>, LLMs evaluators, although largely consistent with human preferences, may have their own biases. Therefore, to make sure our experimental results are solid, we also use GPT-4 as the judge and compare against the performance gap in CRR between different baselines and the Self-Instruct method. The comparison results in Table&nbsp;<a href="#A1.T6" title="Table 6 â€£ A.6 Consistency between LLM-based Evaluators â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> demonstrates the agreement of two LLM-based judges and confirms the superior performance of CodecLM against comparing methods.</p>
</div>
</section>
<section id="A1.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.7 </span>Additional Benchmark Results</h3>

<div id="A1.SS7.p1" class="ltx_para">
<p id="A1.SS7.p1.1" class="ltx_p">To complement the performance result using LLM-based automatic evaluator, we also evaluate LLMs tuned with the top methods presented in Section&nbsp;<a href="#S5.SS4" title="5.4 Open-Domain Instruction Following â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.4</span></a> on standard NLP benchmarks, MMLU&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite> and BBH&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et&nbsp;al., <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite>. We follow the same settings introduced in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite> without demonstrations or CoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a href="#bib.bib49" title="" class="ltx_ref">2022</a>)</cite> prompt for evaluating the target models based on LLaMA-7B. For our method, we follow the same setting as in Evol-Instruction benchmark evaluation. We present the evaluation results in Table&nbsp;<a href="#A1.T4" title="Table 4 â€£ A.4 Training Details â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and use the performance of vanilla LLaMA-7B as a reference. We observe the same performance ranking of all methods as that in Table&nbsp;<a href="#S5.T1" title="Table 1 â€£ 5.3 Experiment and Evaluation Details â€£ 5 Experiments â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> where we use LLM-based automatic evaluator. The consistency between two different evaluation approaches indicates the reliability of LLM-based evaluator in terms of demonstrating relative performance of competing methods.</p>
</div>
<figure id="A1.F6" class="ltx_figure"><img src="/html/2404.05875/assets/x6.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="358" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Case study on the instruction improvement process of CodecLM. Repetitive instructions are omitted to save space.</figcaption>
</figure>
</section>
<section id="A1.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.8 </span>Case Study</h3>

<div id="A1.SS8.p1" class="ltx_para">
<p id="A1.SS8.p1.1" class="ltx_p">We present a case study in Figure&nbsp;<a href="#A1.F6" title="Figure 6 â€£ A.7 Additional Benchmark Results â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> to show an iterative tailoring process from instruction metadata to the final high-quality prompt. In practice, the iteration may terminate earlier by the Contrastive Filtering process. We observe that Self-Rubrics is able to tailor rubrics and actions according to the given metadata. Interestingly, the actions generated by LLM seems very domain-specific. For example, the <em id="A1.SS8.p1.1.1" class="ltx_emph ltx_font_italic">SWOT analysis</em> in the last action may even be hard for non-expert human annotators to come up with. Moreover, the colored texts in instructions demonstrate that LLM is able to follow the actions quite precisely to refine the instructions.</p>
</div>
</section>
<section id="A1.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.9 </span>Prompt Templates for CodecLM</h3>

<div id="A1.SS9.p1" class="ltx_para">
<p id="A1.SS9.p1.1" class="ltx_p">We present all prompt templates here in the appendix for better reproducibility. In particular, we list the correspondence between prompt templates and their usages as follows for quick reference:</p>
<ul id="A1.I3" class="ltx_itemize">
<li id="A1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I3.i1.p1" class="ltx_para">
<p id="A1.I3.i1.p1.1" class="ltx_p">Figure&nbsp;<a href="#A1.F7" title="Figure 7 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>: Encoding instructions into metadata, including use case and transferable skills.</p>
</div>
</li>
<li id="A1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I3.i2.p1" class="ltx_para">
<p id="A1.I3.i2.p1.1" class="ltx_p">Figure&nbsp;<a href="#A1.F8" title="Figure 8 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>: Decoding instruction metadata into basic instructions that are relatively simple in structure.</p>
</div>
</li>
<li id="A1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I3.i3.p1" class="ltx_para">
<p id="A1.I3.i3.p1.1" class="ltx_p">Figure&nbsp;<a href="#A1.F9" title="Figure 9 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>: Generating rubrics to judge how challenging an instruction is, and actions to improve the instruction based on the given metadata.</p>
</div>
</li>
<li id="A1.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I3.i4.p1" class="ltx_para">
<p id="A1.I3.i4.p1.1" class="ltx_p">Figure&nbsp;<a href="#A1.F10" title="Figure 10 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>: Improving the input instruction by following one of the generated actions.</p>
</div>
</li>
<li id="A1.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I3.i5.p1" class="ltx_para">
<p id="A1.I3.i5.p1.1" class="ltx_p">Figure&nbsp;<a href="#A1.F11" title="Figure 11 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>: Comparing the responses quality from the target and strong LLMs. Adapted from the Vicuna-style pairwise comparison prompt by removing the explanation part.</p>
</div>
</li>
<li id="A1.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I3.i6.p1" class="ltx_para">
<p id="A1.I3.i6.p1.1" class="ltx_p">Figure&nbsp;<a href="#A1.F12" title="Figure 12 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>: Automatic evaluation using LLM (<span id="A1.I3.i6.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, ChatGPT, GPT-4) as the judge. Following the templates in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>; Chen et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023b</a>)</cite></p>
</div>
</li>
</ul>
<p id="A1.SS9.p1.2" class="ltx_p">All prompts are zero-shot except for the first encoding prompt in Figure&nbsp;<a href="#A1.F7" title="Figure 7 â€£ A.9 Prompt Templates for CodecLM â€£ Appendix A Appendix â€£ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, which utilizes few-shot demonstrations to showcase the LLM a rough granularity of the task and skills. Also, we choose these prompts as they work quite well in practice. And we believe recent prompt optimization techniques&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Fernando et&nbsp;al., <a href="#bib.bib14" title="" class="ltx_ref">2023</a>; Yang et&nbsp;al., <a href="#bib.bib51" title="" class="ltx_ref">2023</a>)</cite> can be incorporated seamlessly into our framework, and we leave them as future work.</p>
</div>
<figure id="A1.F7" class="ltx_figure">
<div id="A1.F7.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGFuIGluc3RydWN0aW9uIGFuYWx5emVyLgpHaXZlbiBhbiBpbnN0cnVjdGlvbiwgeW91IHNob3VsZCByZWNvZ25pemUgaXRzIHVzZSBjYXNlIGFuZCB0aGUgc2tpbGxzIChvciBrbm93bGVkZ2UpCnJlcXVpcmVkIGZvciBhIGxhcmdlIGxhbmd1YWdlIG1vZGVsIChMTE0pIHRvIGFuc3dlciB0aGUgcXVlc3Rpb24uCkdlbmVyYXRlIHRoZSB1c2UgY2FzZSBhbmQgc2tpbGxzIHJlcXVpcmVkIHdpdGhvdXQgYW55IGV4cGxhbmF0aW9uLgpMaXN0IGF0IG1vc3QgMyBza2lsbHMsIGVhY2ggc2tpbGwgc2hvdWxkIGJlIHRyYW5zZmVyYWJsZSwgc28gdGhhdCBMTE0gY2FuIGxldmVyYWdlIHRoZW0gdG8gYW5zd2VyCnNpbWlsYXIgcXVlc3Rpb25zLgpBdm9pZCB1c2luZyAic2tpbGwiLCAia25vd2xlZGdlIiB0byBkZXNjcmliZSBhIHNraWxsLCBhbmQgZWFjaCBza2lsbCBzaG91bGQgYmUgY29uY2lzZSAoMi0zIHdvcmRzKS4KRm9sbG93IHRoZSBleGFtcGxlcyBiZWxvdyB0byBhbmFseXplIHRoZSBnaXZlbiBpbnN0cnVjdGlvbi4KXHBhciNFeGFtcGxlIDEjCkFzIGEgc3BvcnRzIGNvbW1lbnRhdG9yLCBkZXNjcmliZSB0aGUgd2lubmluZyBwbGF5IGluIHRoZSBmaW5hbCBzZWNvbmRzIG9mIGEgY2hhbXBpb25zaGlwIGdhbWUuClVzZSBjYXNlOiBjcmVhdGl2ZSB3cml0aW5nClNraWxsczogcm9sZS1wbGF5LCBzcG9ydHMKXHBhciNFeGFtcGxlIDIjCkhvdyB0byByZWFkIGEgbGFyZ2UgZmlsZSAoPiAyVCkgdXNpbmcgcHl0aG9uPwpUYXNrOiBjb2RlIGdlbmVyYXRpb24KU2tpbGxzOiBweXRob24KXHBhciNFeGFtcGxlIDMjClRoZSBtZXRob2Qgc2VjdGlvbiBvZiB5b3VyIHBhcGVyIGlzIHRvbyBicmllZiBhbmQgZG9lcyBub3QgZXhwbGFpbiBob3cgeW91ciBwcm9wb3NlZCBtb2RlbCB3b3JrcwppbiBkZXRhaWwuIEhvdyBjYW4geW91IHByb3ZpZGUgbW9yZSBkZXRhaWxzIG9mIHRoZSBoaWVyYXJjaGljYWwgZW5jb2RlciBhbmQgdGhlIGNhc2NhZGVkIHNlbGVjdG9ycywKc3VjaCBhcyB0aGVpciBhcmNoaXRlY3R1cmVzLCBpbnB1dHMsIG91dHB1dHMsIGFuZCBwYXJhbWV0ZXJzPwpUYXNrOiBnZW5lcmFsIGtub3dsZWRnZSBxdWVzdGlvbiBhbnN3ZXJpbmcKU2tpbGxzOiBhY2FkZW1pYyB3cml0aW5nLCBtYWNoaW5lIGxlYXJuaW5nClxwYXI8aW5wdXQgaW5zdHJ1Y3Rpb24+CjxvdXRwdXQgbWV0YWRhdGE+Cg==" download="">â¬‡</a></div>
<div id="lstnumberx1" class="ltx_listingline">
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_lst_identifier">I</span><span id="lstnumberx2.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.3" class="ltx_text ltx_lst_identifier">want</span><span id="lstnumberx2.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.5" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx2.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx2.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.9" class="ltx_text ltx_lst_identifier">act</span><span id="lstnumberx2.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.11" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx2.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.13" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx2.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx2.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.17" class="ltx_text ltx_lst_identifier">analyzer</span>.
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span id="lstnumberx3.1" class="ltx_text ltx_lst_identifier">Given</span><span id="lstnumberx3.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.3" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx3.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.5" class="ltx_text ltx_lst_identifier">instruction</span>,<span id="lstnumberx3.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.7" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx3.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.9" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx3.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.11" class="ltx_text ltx_lst_identifier">recognize</span><span id="lstnumberx3.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.13" class="ltx_text ltx_lst_identifier">its</span><span id="lstnumberx3.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.15" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx3.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.17" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx3.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.19" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx3.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.21" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx3.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.23" class="ltx_text ltx_lst_identifier">skills</span><span id="lstnumberx3.24" class="ltx_text ltx_lst_space"> </span>(<span id="lstnumberx3.25" class="ltx_text ltx_lst_identifier">or</span><span id="lstnumberx3.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.27" class="ltx_text ltx_lst_identifier">knowledge</span>)
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span id="lstnumberx4.1" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx4.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.3" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx4.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.5" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx4.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.7" class="ltx_text ltx_lst_identifier">large</span><span id="lstnumberx4.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.9" class="ltx_text ltx_lst_identifier">language</span><span id="lstnumberx4.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.11" class="ltx_text ltx_lst_identifier">model</span><span id="lstnumberx4.12" class="ltx_text ltx_lst_space"> </span>(<span id="lstnumberx4.13" class="ltx_text ltx_lst_identifier">LLM</span>)<span id="lstnumberx4.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.15" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx4.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.17" class="ltx_text ltx_lst_identifier">answer</span><span id="lstnumberx4.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx4.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.21" class="ltx_text ltx_lst_identifier">question</span>.
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_lst_identifier">Generate</span><span id="lstnumberx5.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.3" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx5.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.5" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx5.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.7" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx5.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.9" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx5.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.11" class="ltx_text ltx_lst_identifier">skills</span><span id="lstnumberx5.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.13" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx5.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.15" class="ltx_text ltx_lst_identifier">without</span><span id="lstnumberx5.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.17" class="ltx_text ltx_lst_identifier">any</span><span id="lstnumberx5.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.19" class="ltx_text ltx_lst_identifier">explanation</span>.
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span id="lstnumberx6.1" class="ltx_text ltx_lst_identifier">List</span><span id="lstnumberx6.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.3" class="ltx_text ltx_lst_identifier">at</span><span id="lstnumberx6.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.5" class="ltx_text ltx_lst_identifier">most</span><span id="lstnumberx6.6" class="ltx_text ltx_lst_space"> </span>3<span id="lstnumberx6.7" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.8" class="ltx_text ltx_lst_identifier">skills</span>,<span id="lstnumberx6.9" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.10" class="ltx_text ltx_lst_identifier">each</span><span id="lstnumberx6.11" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.12" class="ltx_text ltx_lst_identifier">skill</span><span id="lstnumberx6.13" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.14" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx6.15" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.16" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx6.17" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.18" class="ltx_text ltx_lst_identifier">transferable</span>,<span id="lstnumberx6.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.20" class="ltx_text ltx_lst_identifier">so</span><span id="lstnumberx6.21" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.22" class="ltx_text ltx_lst_identifier">that</span><span id="lstnumberx6.23" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.24" class="ltx_text ltx_lst_identifier">LLM</span><span id="lstnumberx6.25" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.26" class="ltx_text ltx_lst_identifier">can</span><span id="lstnumberx6.27" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.28" class="ltx_text ltx_lst_identifier">leverage</span><span id="lstnumberx6.29" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.30" class="ltx_text ltx_lst_identifier">them</span><span id="lstnumberx6.31" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.32" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx6.33" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.34" class="ltx_text ltx_lst_identifier">answer</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span id="lstnumberx7.1" class="ltx_text ltx_lst_identifier">similar</span><span id="lstnumberx7.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx7.3" class="ltx_text ltx_lst_identifier">questions</span>.
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span id="lstnumberx8.1" class="ltx_text ltx_lst_identifier">Avoid</span><span id="lstnumberx8.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.3" class="ltx_text ltx_lst_identifier">using</span><span id="lstnumberx8.4" class="ltx_text ltx_lst_space"> </span>"<span id="lstnumberx8.5" class="ltx_text ltx_lst_identifier">skill</span>",<span id="lstnumberx8.6" class="ltx_text ltx_lst_space"> </span>"<span id="lstnumberx8.7" class="ltx_text ltx_lst_identifier">knowledge</span>"<span id="lstnumberx8.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.9" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx8.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.11" class="ltx_text ltx_lst_identifier">describe</span><span id="lstnumberx8.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx8.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.15" class="ltx_text ltx_lst_identifier">skill</span>,<span id="lstnumberx8.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.17" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx8.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.19" class="ltx_text ltx_lst_identifier">each</span><span id="lstnumberx8.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.21" class="ltx_text ltx_lst_identifier">skill</span><span id="lstnumberx8.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.23" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx8.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.25" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx8.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.27" class="ltx_text ltx_lst_identifier">concise</span><span id="lstnumberx8.28" class="ltx_text ltx_lst_space"> </span>(2-3<span id="lstnumberx8.29" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.30" class="ltx_text ltx_lst_identifier">words</span>).
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span id="lstnumberx9.1" class="ltx_text ltx_lst_identifier">Follow</span><span id="lstnumberx9.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.3" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx9.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.5" class="ltx_text ltx_lst_identifier">examples</span><span id="lstnumberx9.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.7" class="ltx_text ltx_lst_identifier">below</span><span id="lstnumberx9.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.9" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx9.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.11" class="ltx_text ltx_lst_identifier">analyze</span><span id="lstnumberx9.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.13" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx9.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.15" class="ltx_text ltx_lst_identifier">given</span><span id="lstnumberx9.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.17" class="ltx_text ltx_lst_identifier">instruction</span>.
</div>
<div id="lstnumberx10" class="ltx_listingline">\<span id="lstnumberx10.1" class="ltx_text ltx_lst_identifier">par</span>#<span id="lstnumberx10.2" class="ltx_text ltx_lst_identifier">Example</span><span id="lstnumberx10.3" class="ltx_text ltx_lst_space"> </span>1#
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span id="lstnumberx11.1" class="ltx_text ltx_lst_identifier">As</span><span id="lstnumberx11.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.3" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx11.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.5" class="ltx_text ltx_lst_identifier">sports</span><span id="lstnumberx11.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.7" class="ltx_text ltx_lst_identifier">commentator</span>,<span id="lstnumberx11.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.9" class="ltx_text ltx_lst_identifier">describe</span><span id="lstnumberx11.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.11" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx11.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.13" class="ltx_text ltx_lst_identifier">winning</span><span id="lstnumberx11.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.15" class="ltx_text ltx_lst_identifier">play</span><span id="lstnumberx11.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.17" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx11.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx11.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.21" class="ltx_text ltx_lst_identifier">final</span><span id="lstnumberx11.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.23" class="ltx_text ltx_lst_identifier">seconds</span><span id="lstnumberx11.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.25" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx11.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.27" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx11.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.29" class="ltx_text ltx_lst_identifier">championship</span><span id="lstnumberx11.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.31" class="ltx_text ltx_lst_identifier">game</span>.
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span id="lstnumberx12.1" class="ltx_text ltx_lst_identifier">Use</span><span id="lstnumberx12.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx12.3" class="ltx_text ltx_lst_identifier">case</span>:<span id="lstnumberx12.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx12.5" class="ltx_text ltx_lst_identifier">creative</span><span id="lstnumberx12.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx12.7" class="ltx_text ltx_lst_identifier">writing</span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span id="lstnumberx13.1" class="ltx_text ltx_lst_identifier">Skills</span>:<span id="lstnumberx13.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx13.3" class="ltx_text ltx_lst_identifier">role</span>-<span id="lstnumberx13.4" class="ltx_text ltx_lst_identifier">play</span>,<span id="lstnumberx13.5" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx13.6" class="ltx_text ltx_lst_identifier">sports</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">\<span id="lstnumberx14.1" class="ltx_text ltx_lst_identifier">par</span>#<span id="lstnumberx14.2" class="ltx_text ltx_lst_identifier">Example</span><span id="lstnumberx14.3" class="ltx_text ltx_lst_space"> </span>2#
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span id="lstnumberx15.1" class="ltx_text ltx_lst_identifier">How</span><span id="lstnumberx15.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.3" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx15.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.5" class="ltx_text ltx_lst_identifier">read</span><span id="lstnumberx15.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.7" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx15.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.9" class="ltx_text ltx_lst_identifier">large</span><span id="lstnumberx15.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.11" class="ltx_text ltx_lst_identifier">file</span><span id="lstnumberx15.12" class="ltx_text ltx_lst_space"> </span>(&gt;<span id="lstnumberx15.13" class="ltx_text ltx_lst_space"> </span>2<span id="lstnumberx15.14" class="ltx_text ltx_lst_identifier">T</span>)<span id="lstnumberx15.15" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.16" class="ltx_text ltx_lst_identifier">using</span><span id="lstnumberx15.17" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.18" class="ltx_text ltx_lst_identifier">python</span>?
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span id="lstnumberx16.1" class="ltx_text ltx_lst_identifier">Task</span>:<span id="lstnumberx16.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx16.3" class="ltx_text ltx_lst_identifier">code</span><span id="lstnumberx16.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx16.5" class="ltx_text ltx_lst_identifier">generation</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span id="lstnumberx17.1" class="ltx_text ltx_lst_identifier">Skills</span>:<span id="lstnumberx17.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx17.3" class="ltx_text ltx_lst_identifier">python</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">\<span id="lstnumberx18.1" class="ltx_text ltx_lst_identifier">par</span>#<span id="lstnumberx18.2" class="ltx_text ltx_lst_identifier">Example</span><span id="lstnumberx18.3" class="ltx_text ltx_lst_space"> </span>3#
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span id="lstnumberx19.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx19.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.3" class="ltx_text ltx_lst_identifier">method</span><span id="lstnumberx19.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.5" class="ltx_text ltx_lst_identifier">section</span><span id="lstnumberx19.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.7" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx19.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.9" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx19.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.11" class="ltx_text ltx_lst_identifier">paper</span><span id="lstnumberx19.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.13" class="ltx_text ltx_lst_identifier">is</span><span id="lstnumberx19.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.15" class="ltx_text ltx_lst_identifier">too</span><span id="lstnumberx19.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.17" class="ltx_text ltx_lst_identifier">brief</span><span id="lstnumberx19.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.19" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx19.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.21" class="ltx_text ltx_lst_identifier">does</span><span id="lstnumberx19.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.23" class="ltx_text ltx_lst_identifier">not</span><span id="lstnumberx19.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.25" class="ltx_text ltx_lst_identifier">explain</span><span id="lstnumberx19.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.27" class="ltx_text ltx_lst_identifier">how</span><span id="lstnumberx19.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.29" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx19.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.31" class="ltx_text ltx_lst_identifier">proposed</span><span id="lstnumberx19.32" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.33" class="ltx_text ltx_lst_identifier">model</span><span id="lstnumberx19.34" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.35" class="ltx_text ltx_lst_identifier">works</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span id="lstnumberx20.1" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx20.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.3" class="ltx_text ltx_lst_identifier">detail</span>.<span id="lstnumberx20.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.5" class="ltx_text ltx_lst_identifier">How</span><span id="lstnumberx20.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.7" class="ltx_text ltx_lst_identifier">can</span><span id="lstnumberx20.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.9" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx20.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.11" class="ltx_text ltx_lst_identifier">provide</span><span id="lstnumberx20.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.13" class="ltx_text ltx_lst_identifier">more</span><span id="lstnumberx20.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.15" class="ltx_text ltx_lst_identifier">details</span><span id="lstnumberx20.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.17" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx20.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx20.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.21" class="ltx_text ltx_lst_identifier">hierarchical</span><span id="lstnumberx20.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.23" class="ltx_text ltx_lst_identifier">encoder</span><span id="lstnumberx20.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.25" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx20.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.27" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx20.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.29" class="ltx_text ltx_lst_identifier">cascaded</span><span id="lstnumberx20.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.31" class="ltx_text ltx_lst_identifier">selectors</span>,
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span id="lstnumberx21.1" class="ltx_text ltx_lst_identifier">such</span><span id="lstnumberx21.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.3" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx21.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.5" class="ltx_text ltx_lst_identifier">their</span><span id="lstnumberx21.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.7" class="ltx_text ltx_lst_identifier">architectures</span>,<span id="lstnumberx21.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.9" class="ltx_text ltx_lst_identifier">inputs</span>,<span id="lstnumberx21.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.11" class="ltx_text ltx_lst_identifier">outputs</span>,<span id="lstnumberx21.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.13" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx21.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.15" class="ltx_text ltx_lst_identifier">parameters</span>?
</div>
<div id="lstnumberx22" class="ltx_listingline">
<span id="lstnumberx22.1" class="ltx_text ltx_lst_identifier">Task</span>:<span id="lstnumberx22.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx22.3" class="ltx_text ltx_lst_identifier">general</span><span id="lstnumberx22.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx22.5" class="ltx_text ltx_lst_identifier">knowledge</span><span id="lstnumberx22.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx22.7" class="ltx_text ltx_lst_identifier">question</span><span id="lstnumberx22.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx22.9" class="ltx_text ltx_lst_identifier">answering</span>
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span id="lstnumberx23.1" class="ltx_text ltx_lst_identifier">Skills</span>:<span id="lstnumberx23.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx23.3" class="ltx_text ltx_lst_identifier">academic</span><span id="lstnumberx23.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx23.5" class="ltx_text ltx_lst_identifier">writing</span>,<span id="lstnumberx23.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx23.7" class="ltx_text ltx_lst_identifier">machine</span><span id="lstnumberx23.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx23.9" class="ltx_text ltx_lst_identifier">learning</span>
</div>
<div id="lstnumberx24" class="ltx_listingline">\<span id="lstnumberx24.1" class="ltx_text ltx_lst_identifier">par</span>&lt;<span id="lstnumberx24.2" class="ltx_text ltx_lst_identifier">input</span><span id="lstnumberx24.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx24.4" class="ltx_text ltx_lst_identifier">instruction</span>&gt;
</div>
<div id="lstnumberx25" class="ltx_listingline">&lt;<span id="lstnumberx25.1" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx25.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx25.3" class="ltx_text ltx_lst_identifier">metadata</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Prompt template to encode the input into metadata, consisting of its use case and transferable skills.</figcaption>
</figure>
<figure id="A1.F8" class="ltx_figure">
<div id="A1.F8.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGFuIGluc3RydWN0aW9uIHdyaXRlci4KWW91ciBvYmplY3RpdmUgaXMgdG8gd3JpdGUgPG51bWJlciBvZiBpbnN0cnVjdGlvbnM+IGluc3RydWN0aW9ucyB0aGF0IG11c3QgYmUgcmVhc29uYWJsZQphbmQgbXVzdCBiZSB1bmRlcnN0b29kIGFuZCByZXNwb25kZWQgYnkgaHVtYW5zLgpUaGUgZ2VuZXJhdGVkIGluc3RydWN0aW9ucyBzaG91bGQgYmUgZGl2ZXJzZSBlbm91Z2ggd2hpbGUgZm9sbG93aW5nIHRoZSBjb25zdHJhaW50cyBiZWxvdzoKXHBhclVzZSBjYXNlIG9mIHRoZSBpbnN0cnVjdGlvbnM6IDx1c2UgY2FzZT4KU2tpbGxzIHJlcXVpcmVkIHRvIHJlc3BvbmQgdG8gdGhlIGluc3RydWN0aW9uczogPHNraWxscz4KXHBhckdlbmVyYXRlIHRoZSBpbnN0cnVjdGlvbnMgd2l0aG91dCBhbnN3ZXJpbmcgaW4gbnVtYmVyZWQgYnVsbGV0aW4gcG9pbnRzLgpccGFyPG91dHB1dCBpbnN0cnVjdGlvbnM+Cg==" download="">â¬‡</a></div>
<div id="lstnumberx26" class="ltx_listingline">
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span id="lstnumberx27.1" class="ltx_text ltx_lst_identifier">I</span><span id="lstnumberx27.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.3" class="ltx_text ltx_lst_identifier">want</span><span id="lstnumberx27.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.5" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx27.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx27.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.9" class="ltx_text ltx_lst_identifier">act</span><span id="lstnumberx27.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.11" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx27.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.13" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx27.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx27.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.17" class="ltx_text ltx_lst_identifier">writer</span>.
</div>
<div id="lstnumberx28" class="ltx_listingline">
<span id="lstnumberx28.1" class="ltx_text ltx_lst_identifier">Your</span><span id="lstnumberx28.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.3" class="ltx_text ltx_lst_identifier">objective</span><span id="lstnumberx28.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.5" class="ltx_text ltx_lst_identifier">is</span><span id="lstnumberx28.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx28.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.9" class="ltx_text ltx_lst_identifier">write</span><span id="lstnumberx28.10" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx28.11" class="ltx_text ltx_lst_identifier">number</span><span id="lstnumberx28.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.13" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx28.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.15" class="ltx_text ltx_lst_identifier">instructions</span>&gt;<span id="lstnumberx28.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.17" class="ltx_text ltx_lst_identifier">instructions</span><span id="lstnumberx28.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.19" class="ltx_text ltx_lst_identifier">that</span><span id="lstnumberx28.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.21" class="ltx_text ltx_lst_identifier">must</span><span id="lstnumberx28.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.23" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx28.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.25" class="ltx_text ltx_lst_identifier">reasonable</span>
</div>
<div id="lstnumberx29" class="ltx_listingline">
<span id="lstnumberx29.1" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx29.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.3" class="ltx_text ltx_lst_identifier">must</span><span id="lstnumberx29.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.5" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx29.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.7" class="ltx_text ltx_lst_identifier">understood</span><span id="lstnumberx29.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.9" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx29.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.11" class="ltx_text ltx_lst_identifier">responded</span><span id="lstnumberx29.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.13" class="ltx_text ltx_lst_identifier">by</span><span id="lstnumberx29.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.15" class="ltx_text ltx_lst_identifier">humans</span>.
</div>
<div id="lstnumberx30" class="ltx_listingline">
<span id="lstnumberx30.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx30.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.3" class="ltx_text ltx_lst_identifier">generated</span><span id="lstnumberx30.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.5" class="ltx_text ltx_lst_identifier">instructions</span><span id="lstnumberx30.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.7" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx30.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.9" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx30.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.11" class="ltx_text ltx_lst_identifier">diverse</span><span id="lstnumberx30.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.13" class="ltx_text ltx_lst_identifier">enough</span><span id="lstnumberx30.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.15" class="ltx_text ltx_lst_identifier">while</span><span id="lstnumberx30.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.17" class="ltx_text ltx_lst_identifier">following</span><span id="lstnumberx30.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx30.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.21" class="ltx_text ltx_lst_identifier">constraints</span><span id="lstnumberx30.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.23" class="ltx_text ltx_lst_identifier">below</span>:
</div>
<div id="lstnumberx31" class="ltx_listingline">\<span id="lstnumberx31.1" class="ltx_text ltx_lst_identifier">parUse</span><span id="lstnumberx31.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.3" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx31.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx31.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.7" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx31.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.9" class="ltx_text ltx_lst_identifier">instructions</span>:<span id="lstnumberx31.10" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx31.11" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx31.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.13" class="ltx_text ltx_lst_identifier">case</span>&gt;
</div>
<div id="lstnumberx32" class="ltx_listingline">
<span id="lstnumberx32.1" class="ltx_text ltx_lst_identifier">Skills</span><span id="lstnumberx32.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.3" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx32.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.5" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx32.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.7" class="ltx_text ltx_lst_identifier">respond</span><span id="lstnumberx32.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.9" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx32.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.11" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx32.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.13" class="ltx_text ltx_lst_identifier">instructions</span>:<span id="lstnumberx32.14" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx32.15" class="ltx_text ltx_lst_identifier">skills</span>&gt;
</div>
<div id="lstnumberx33" class="ltx_listingline">\<span id="lstnumberx33.1" class="ltx_text ltx_lst_identifier">parGenerate</span><span id="lstnumberx33.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.3" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx33.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.5" class="ltx_text ltx_lst_identifier">instructions</span><span id="lstnumberx33.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.7" class="ltx_text ltx_lst_identifier">without</span><span id="lstnumberx33.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.9" class="ltx_text ltx_lst_identifier">answering</span><span id="lstnumberx33.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.11" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx33.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.13" class="ltx_text ltx_lst_identifier">numbered</span><span id="lstnumberx33.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.15" class="ltx_text ltx_lst_identifier">bulletin</span><span id="lstnumberx33.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.17" class="ltx_text ltx_lst_identifier">points</span>.
</div>
<div id="lstnumberx34" class="ltx_listingline">\<span id="lstnumberx34.1" class="ltx_text ltx_lst_identifier">par</span>&lt;<span id="lstnumberx34.2" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx34.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx34.4" class="ltx_text ltx_lst_identifier">instructions</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Prompt template to generate instructions from metadata.</figcaption>
</figure>
<figure id="A1.F9" class="ltx_figure">
<div id="A1.F9.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGEgaW5zdHJ1Y3Rpb24ganVkZ2Ugd2l0aCBkb21haW4gZXhwZXJ0aXNlLgpZb3VyIGpvYiBpcyB0byBnZW5lcmF0ZSA8bnVtYmVyX29mX3J1YnJpY3M+IGRvbWFpbiBzcGVjaWZpYyBydWJyaWNzIHRvIGFzc2VzcyB0aGUgZGlmZmljdWx0eSBhbmQKY29tcGxleGl0eSBiYXNlZCBvbiB0aGUgdXNlIGNhc2Ugb2YgdGhlIGluc3RydWN0aW9uLCBhbmQgc2tpbGxzIHJlcXVpcmVkIHRvIHJlc3BvbmQgdG8gaXQuClRoZSBnZW5lcmF0ZWQgcnVicmljcyBzaG91bGQgYmUgY2xlYXIsIGNvbmNpc2UgYW5kIHVuYW1iaWd1b3VzLgpCYXNlZCBvbiB0aGUgZ2VuZXJhdGVkIHJ1YnJpY3MsIGdlbmVyYXRlIGNvcnJlc3BvbmRpbmcgYWN0aW9ucyB0byBpbXByb3ZlIGFuIGluc3RydWN0aW9uIGJ5Cm1ha2luZyBpdCBtb3JlIGNoYWxsZW5naW5nLgpccGFyVGhlIHVzZSBjYXNlIG9mIHRoZSBpbnN0cnVjdGlvbjogPHVzZSBjYXNlPi4KVGhlIHNraWxscyByZXF1aXJlZCB0byBzb2x2ZSB0aGUgaW5zdHJ1Y3Rpb246IDxza2lsbHM+LgpccGFyR2VuZXJhdGUgdGhlIGRvbWFpbi1zcGVjaWZpYyBydWJyaWNzIGFuZCBhY3Rpb25zIHdpdGhvdXQgZXhwbGFuYXRpb24gaW4gbnVtYmVyZWQgYnVsbGV0aW4gcG9pbnRzOgpccGFyPG91dHB1dCBydWJyaWNzPgo8b3V0cHV0IGFjdGlvbnM+Cg==" download="">â¬‡</a></div>
<div id="lstnumberx35" class="ltx_listingline">
</div>
<div id="lstnumberx36" class="ltx_listingline">
<span id="lstnumberx36.1" class="ltx_text ltx_lst_identifier">I</span><span id="lstnumberx36.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.3" class="ltx_text ltx_lst_identifier">want</span><span id="lstnumberx36.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.5" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx36.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx36.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.9" class="ltx_text ltx_lst_identifier">act</span><span id="lstnumberx36.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.11" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx36.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx36.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx36.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.17" class="ltx_text ltx_lst_identifier">judge</span><span id="lstnumberx36.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.19" class="ltx_text ltx_lst_identifier">with</span><span id="lstnumberx36.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.21" class="ltx_text ltx_lst_identifier">domain</span><span id="lstnumberx36.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.23" class="ltx_text ltx_lst_identifier">expertise</span>.
</div>
<div id="lstnumberx37" class="ltx_listingline">
<span id="lstnumberx37.1" class="ltx_text ltx_lst_identifier">Your</span><span id="lstnumberx37.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.3" class="ltx_text ltx_lst_identifier">job</span><span id="lstnumberx37.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.5" class="ltx_text ltx_lst_identifier">is</span><span id="lstnumberx37.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx37.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.9" class="ltx_text ltx_lst_identifier">generate</span><span id="lstnumberx37.10" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx37.11" class="ltx_text ltx_lst_identifier">number_of_rubrics</span>&gt;<span id="lstnumberx37.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.13" class="ltx_text ltx_lst_identifier">domain</span><span id="lstnumberx37.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.15" class="ltx_text ltx_lst_identifier">specific</span><span id="lstnumberx37.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.17" class="ltx_text ltx_lst_identifier">rubrics</span><span id="lstnumberx37.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.19" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx37.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.21" class="ltx_text ltx_lst_identifier">assess</span><span id="lstnumberx37.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx37.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.25" class="ltx_text ltx_lst_identifier">difficulty</span><span id="lstnumberx37.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.27" class="ltx_text ltx_lst_identifier">and</span>
</div>
<div id="lstnumberx38" class="ltx_listingline">
<span id="lstnumberx38.1" class="ltx_text ltx_lst_identifier">complexity</span><span id="lstnumberx38.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.3" class="ltx_text ltx_lst_identifier">based</span><span id="lstnumberx38.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.5" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx38.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.7" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx38.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.9" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx38.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.11" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx38.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.13" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx38.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.15" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx38.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.17" class="ltx_text ltx_lst_identifier">instruction</span>,<span id="lstnumberx38.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.19" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx38.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.21" class="ltx_text ltx_lst_identifier">skills</span><span id="lstnumberx38.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.23" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx38.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.25" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx38.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.27" class="ltx_text ltx_lst_identifier">respond</span><span id="lstnumberx38.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.29" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx38.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.31" class="ltx_text ltx_lst_identifier">it</span>.
</div>
<div id="lstnumberx39" class="ltx_listingline">
<span id="lstnumberx39.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx39.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.3" class="ltx_text ltx_lst_identifier">generated</span><span id="lstnumberx39.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.5" class="ltx_text ltx_lst_identifier">rubrics</span><span id="lstnumberx39.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.7" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx39.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.9" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx39.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.11" class="ltx_text ltx_lst_identifier">clear</span>,<span id="lstnumberx39.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.13" class="ltx_text ltx_lst_identifier">concise</span><span id="lstnumberx39.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.15" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx39.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.17" class="ltx_text ltx_lst_identifier">unambiguous</span>.
</div>
<div id="lstnumberx40" class="ltx_listingline">
<span id="lstnumberx40.1" class="ltx_text ltx_lst_identifier">Based</span><span id="lstnumberx40.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.3" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx40.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.5" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx40.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.7" class="ltx_text ltx_lst_identifier">generated</span><span id="lstnumberx40.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.9" class="ltx_text ltx_lst_identifier">rubrics</span>,<span id="lstnumberx40.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.11" class="ltx_text ltx_lst_identifier">generate</span><span id="lstnumberx40.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.13" class="ltx_text ltx_lst_identifier">corresponding</span><span id="lstnumberx40.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.15" class="ltx_text ltx_lst_identifier">actions</span><span id="lstnumberx40.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.17" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx40.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.19" class="ltx_text ltx_lst_identifier">improve</span><span id="lstnumberx40.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.21" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx40.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.23" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx40.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.25" class="ltx_text ltx_lst_identifier">by</span>
</div>
<div id="lstnumberx41" class="ltx_listingline">
<span id="lstnumberx41.1" class="ltx_text ltx_lst_identifier">making</span><span id="lstnumberx41.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx41.3" class="ltx_text ltx_lst_identifier">it</span><span id="lstnumberx41.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx41.5" class="ltx_text ltx_lst_identifier">more</span><span id="lstnumberx41.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx41.7" class="ltx_text ltx_lst_identifier">challenging</span>.
</div>
<div id="lstnumberx42" class="ltx_listingline">\<span id="lstnumberx42.1" class="ltx_text ltx_lst_identifier">parThe</span><span id="lstnumberx42.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.3" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx42.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.5" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx42.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.7" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx42.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.9" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx42.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.11" class="ltx_text ltx_lst_identifier">instruction</span>:<span id="lstnumberx42.12" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx42.13" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx42.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.15" class="ltx_text ltx_lst_identifier">case</span>&gt;.
</div>
<div id="lstnumberx43" class="ltx_listingline">
<span id="lstnumberx43.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx43.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.3" class="ltx_text ltx_lst_identifier">skills</span><span id="lstnumberx43.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.5" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx43.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx43.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.9" class="ltx_text ltx_lst_identifier">solve</span><span id="lstnumberx43.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.11" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx43.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.13" class="ltx_text ltx_lst_identifier">instruction</span>:<span id="lstnumberx43.14" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx43.15" class="ltx_text ltx_lst_identifier">skills</span>&gt;.
</div>
<div id="lstnumberx44" class="ltx_listingline">\<span id="lstnumberx44.1" class="ltx_text ltx_lst_identifier">parGenerate</span><span id="lstnumberx44.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.3" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx44.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.5" class="ltx_text ltx_lst_identifier">domain</span>-<span id="lstnumberx44.6" class="ltx_text ltx_lst_identifier">specific</span><span id="lstnumberx44.7" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.8" class="ltx_text ltx_lst_identifier">rubrics</span><span id="lstnumberx44.9" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.10" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx44.11" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.12" class="ltx_text ltx_lst_identifier">actions</span><span id="lstnumberx44.13" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.14" class="ltx_text ltx_lst_identifier">without</span><span id="lstnumberx44.15" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.16" class="ltx_text ltx_lst_identifier">explanation</span><span id="lstnumberx44.17" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.18" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx44.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.20" class="ltx_text ltx_lst_identifier">numbered</span><span id="lstnumberx44.21" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.22" class="ltx_text ltx_lst_identifier">bulletin</span><span id="lstnumberx44.23" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.24" class="ltx_text ltx_lst_identifier">points</span>:
</div>
<div id="lstnumberx45" class="ltx_listingline">\<span id="lstnumberx45.1" class="ltx_text ltx_lst_identifier">par</span>&lt;<span id="lstnumberx45.2" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx45.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx45.4" class="ltx_text ltx_lst_identifier">rubrics</span>&gt;
</div>
<div id="lstnumberx46" class="ltx_listingline">&lt;<span id="lstnumberx46.1" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx46.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx46.3" class="ltx_text ltx_lst_identifier">actions</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Prompt template to generate actions to improve instructions based on instruction metadata.</figcaption>
</figure>
<figure id="A1.F10" class="ltx_figure">
<div id="A1.F10.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGEgaW5zdHJ1Y3Rpb24gaW1wcm92ZXIgd2l0aCBkb21haW4gZXhwZXJ0aXNlLgpZb3VyIGpvYiBpcyB0byBtYWtlIHRoZSBnaXZlbiBpbnN0cnVjdGlvbiBtb3JlIGNoYWxsZW5naW5nIGZvbGxvd2luZyB0aGUgZ2l2ZW4gaW1wcm92aW5nIGFjdGlvbgppdGVtLCBhbmQgdGhlIGdlbmVyYXRlZCBpbnN0cnVjdGlvbiBzaG91bGQgYmUgcmVhc29uYWJsZSBhbmQgc2VsZi1jb25zaXN0ZW50LgpEbyBub3QgZGlyZWN0bHkgY29weSB3b3JkcyBvciBwaHJhc2VzIGluIHRoZSBhY3Rpb24uClxwYXJJbXByb3ZpbmcgYWN0aW9uOiA8YWN0aW9uPgpJbnB1dCBpbnN0cnVjdGlvbjogPGlucHV0IGluc3RydWN0aW9uPgpccGFySW1wcm92ZWQgaW5zdHJ1Y3Rpb246IDxvdXRwdXQgaW5zdHJ1Y3Rpb24+Cg==" download="">â¬‡</a></div>
<div id="lstnumberx47" class="ltx_listingline">
</div>
<div id="lstnumberx48" class="ltx_listingline">
<span id="lstnumberx48.1" class="ltx_text ltx_lst_identifier">I</span><span id="lstnumberx48.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.3" class="ltx_text ltx_lst_identifier">want</span><span id="lstnumberx48.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.5" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx48.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx48.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.9" class="ltx_text ltx_lst_identifier">act</span><span id="lstnumberx48.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.11" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx48.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx48.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx48.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.17" class="ltx_text ltx_lst_identifier">improver</span><span id="lstnumberx48.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.19" class="ltx_text ltx_lst_identifier">with</span><span id="lstnumberx48.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.21" class="ltx_text ltx_lst_identifier">domain</span><span id="lstnumberx48.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.23" class="ltx_text ltx_lst_identifier">expertise</span>.
</div>
<div id="lstnumberx49" class="ltx_listingline">
<span id="lstnumberx49.1" class="ltx_text ltx_lst_identifier">Your</span><span id="lstnumberx49.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.3" class="ltx_text ltx_lst_identifier">job</span><span id="lstnumberx49.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.5" class="ltx_text ltx_lst_identifier">is</span><span id="lstnumberx49.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx49.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.9" class="ltx_text ltx_lst_identifier">make</span><span id="lstnumberx49.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.11" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx49.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.13" class="ltx_text ltx_lst_identifier">given</span><span id="lstnumberx49.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx49.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.17" class="ltx_text ltx_lst_identifier">more</span><span id="lstnumberx49.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.19" class="ltx_text ltx_lst_identifier">challenging</span><span id="lstnumberx49.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.21" class="ltx_text ltx_lst_identifier">following</span><span id="lstnumberx49.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx49.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.25" class="ltx_text ltx_lst_identifier">given</span><span id="lstnumberx49.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.27" class="ltx_text ltx_lst_identifier">improving</span><span id="lstnumberx49.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.29" class="ltx_text ltx_lst_identifier">action</span>
</div>
<div id="lstnumberx50" class="ltx_listingline">
<span id="lstnumberx50.1" class="ltx_text ltx_lst_identifier">item</span>,<span id="lstnumberx50.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.3" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx50.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.5" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx50.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.7" class="ltx_text ltx_lst_identifier">generated</span><span id="lstnumberx50.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.9" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx50.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.11" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx50.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.13" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx50.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.15" class="ltx_text ltx_lst_identifier">reasonable</span><span id="lstnumberx50.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.17" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx50.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.19" class="ltx_text ltx_lst_identifier">self</span>-<span id="lstnumberx50.20" class="ltx_text ltx_lst_identifier">consistent</span>.
</div>
<div id="lstnumberx51" class="ltx_listingline">
<span id="lstnumberx51.1" class="ltx_text ltx_lst_identifier">Do</span><span id="lstnumberx51.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.3" class="ltx_text ltx_lst_identifier">not</span><span id="lstnumberx51.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.5" class="ltx_text ltx_lst_identifier">directly</span><span id="lstnumberx51.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.7" class="ltx_text ltx_lst_identifier">copy</span><span id="lstnumberx51.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.9" class="ltx_text ltx_lst_identifier">words</span><span id="lstnumberx51.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.11" class="ltx_text ltx_lst_identifier">or</span><span id="lstnumberx51.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.13" class="ltx_text ltx_lst_identifier">phrases</span><span id="lstnumberx51.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.15" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx51.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.17" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx51.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.19" class="ltx_text ltx_lst_identifier">action</span>.
</div>
<div id="lstnumberx52" class="ltx_listingline">\<span id="lstnumberx52.1" class="ltx_text ltx_lst_identifier">parImproving</span><span id="lstnumberx52.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx52.3" class="ltx_text ltx_lst_identifier">action</span>:<span id="lstnumberx52.4" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx52.5" class="ltx_text ltx_lst_identifier">action</span>&gt;
</div>
<div id="lstnumberx53" class="ltx_listingline">
<span id="lstnumberx53.1" class="ltx_text ltx_lst_identifier">Input</span><span id="lstnumberx53.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx53.3" class="ltx_text ltx_lst_identifier">instruction</span>:<span id="lstnumberx53.4" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx53.5" class="ltx_text ltx_lst_identifier">input</span><span id="lstnumberx53.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx53.7" class="ltx_text ltx_lst_identifier">instruction</span>&gt;
</div>
<div id="lstnumberx54" class="ltx_listingline">\<span id="lstnumberx54.1" class="ltx_text ltx_lst_identifier">parImproved</span><span id="lstnumberx54.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx54.3" class="ltx_text ltx_lst_identifier">instruction</span>:<span id="lstnumberx54.4" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx54.5" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx54.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx54.7" class="ltx_text ltx_lst_identifier">instruction</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Prompt template to improve instructions following generated actions.</figcaption>
</figure>
<figure id="A1.F11" class="ltx_figure">
<div id="A1.F11.3" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,CllvdSBhcmUgYSBoZWxwZnVsIGFuZCBwcmVjaXNlIGFzc2lzdGFudCBmb3IgY2hlY2tpbmcgdGhlIHF1YWxpdHkgb2YgdGhlIGFuc3dlci4KXHBhcjxRdWVzdGlvbj4KW1RoZSBTdGFydCBvZiBBc3Npc3RhbnQgMSdzIEFuc3dlcl0KPGFuc3dlcl8xPgpbVGhlIEVuZCBvZiBBc3Npc3RhbnQgMSdzIEFuc3dlcl0KW1RoZSBTdGFydCBvZiBBc3Npc3RhbnQgMidzIEFuc3dlcl0KPGFuc3dlcl8yPgpbVGhlIEVuZCBvZiBBc3Npc3RhbnQgMidzIEFuc3dlcl0KXHBhcldlIHdvdWxkIGxpa2UgdG8gcmVxdWVzdCB5b3VyIGZlZWRiYWNrIG9uIHRoZSBwZXJmb3JtYW5jZSBvZiB0d28gQUkgYXNzaXN0YW50cyBpbiByZXNwb25zZSB0bwp0aGUgdXNlciBxdWVzdGlvbiBkaXNwbGF5ZWQgYWJvdmUuClBsZWFzZSByYXRlIHRoZSBoZWxwZnVsbmVzcywgcmVsZXZhbmNlLCBhY2N1cmFjeSwgbGV2ZWwgb2YgZGV0YWlscyBvZiB0aGVpciByZXNwb25zZXMuIEVhY2gKYXNzaXN0YW50IHJlY2VpdmVzIGFuIG92ZXJhbGwgc2NvcmUgb24gYSBzY2FsZSBvZiAxIHRvIDEwLCB3aGVyZSBhIGhpZ2hlciBzY29yZSBpbmRpY2F0ZXMKYmV0dGVyIG92ZXJhbGwgcGVyZm9ybWFuY2UuClBsZWFzZSBvbmx5IG91dHB1dCBhIHNpbmdsZSBsaW5lIGNvbnRhaW5pbmcgb25seSB0d28gdmFsdWVzIGluZGljYXRpbmcgdGhlIHNjb3JlcyBmb3IgQXNzaXN0YW50IDEKYW5kIDIsIHJlc3BlY3RpdmVseS4gVGhlIHR3byBzY29yZXMgYXJlIHNlcGFyYXRlZCBieSBhIHNwYWNlLgpQbGVhc2UgYXZvaWRpbmcgYW55IHBvdGVudGlhbCBiaWFzIGFuZCBlbnN1cmluZyB0aGF0IHRoZSBvcmRlciBpbiB3aGljaCB0aGUgcmVzcG9uc2VzIHdlcmUKcHJlc2VudGVkIGRvZXMgbm90IGFmZmVjdCB5b3VyIGp1ZGdtZW50Lgo=" download="">â¬‡</a></div>
<div id="lstnumberx55" class="ltx_listingline">
</div>
<div id="lstnumberx56" class="ltx_listingline">
<span id="lstnumberx56.1" class="ltx_text ltx_lst_identifier">You</span><span id="lstnumberx56.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.3" class="ltx_text ltx_lst_identifier">are</span><span id="lstnumberx56.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.5" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx56.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.7" class="ltx_text ltx_lst_identifier">helpful</span><span id="lstnumberx56.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.9" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx56.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.11" class="ltx_text ltx_lst_identifier">precise</span><span id="lstnumberx56.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.13" class="ltx_text ltx_lst_identifier">assistant</span><span id="lstnumberx56.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.15" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx56.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.17" class="ltx_text ltx_lst_identifier">checking</span><span id="lstnumberx56.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx56.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.21" class="ltx_text ltx_lst_identifier">quality</span><span id="lstnumberx56.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.23" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx56.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.25" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx56.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.27" class="ltx_text ltx_lst_identifier">answer</span>.
</div>
<div id="lstnumberx57" class="ltx_listingline">\<span id="lstnumberx57.1" class="ltx_text ltx_lst_identifier">par</span>&lt;<span id="lstnumberx57.2" class="ltx_text ltx_lst_identifier">Question</span>&gt;
</div>
<div id="lstnumberx58" class="ltx_listingline">[<span id="lstnumberx58.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx58.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx58.3" class="ltx_text ltx_lst_identifier">Start</span><span id="lstnumberx58.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx58.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx58.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx58.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx58.8" class="ltx_text ltx_lst_space"> </span>1â€™<span id="lstnumberx58.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx58.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx58.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx59" class="ltx_listingline">&lt;<span id="lstnumberx59.1" class="ltx_text ltx_lst_identifier">answer_1</span>&gt;
</div>
<div id="lstnumberx60" class="ltx_listingline">[<span id="lstnumberx60.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx60.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx60.3" class="ltx_text ltx_lst_identifier">End</span><span id="lstnumberx60.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx60.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx60.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx60.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx60.8" class="ltx_text ltx_lst_space"> </span>1â€™<span id="lstnumberx60.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx60.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx60.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx61" class="ltx_listingline">[<span id="lstnumberx61.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx61.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx61.3" class="ltx_text ltx_lst_identifier">Start</span><span id="lstnumberx61.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx61.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx61.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx61.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx61.8" class="ltx_text ltx_lst_space"> </span>2â€™<span id="lstnumberx61.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx61.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx61.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx62" class="ltx_listingline">&lt;<span id="lstnumberx62.1" class="ltx_text ltx_lst_identifier">answer_2</span>&gt;
</div>
<div id="lstnumberx63" class="ltx_listingline">[<span id="lstnumberx63.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx63.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx63.3" class="ltx_text ltx_lst_identifier">End</span><span id="lstnumberx63.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx63.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx63.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx63.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx63.8" class="ltx_text ltx_lst_space"> </span>2â€™<span id="lstnumberx63.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx63.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx63.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx64" class="ltx_listingline">\<span id="lstnumberx64.1" class="ltx_text ltx_lst_identifier">parWe</span><span id="lstnumberx64.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.3" class="ltx_text ltx_lst_identifier">would</span><span id="lstnumberx64.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.5" class="ltx_text ltx_lst_identifier">like</span><span id="lstnumberx64.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx64.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.9" class="ltx_text ltx_lst_identifier">request</span><span id="lstnumberx64.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.11" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx64.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.13" class="ltx_text ltx_lst_identifier">feedback</span><span id="lstnumberx64.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.15" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx64.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.17" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx64.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.19" class="ltx_text ltx_lst_identifier">performance</span><span id="lstnumberx64.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.21" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx64.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.23" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx64.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.25" class="ltx_text ltx_lst_identifier">AI</span><span id="lstnumberx64.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.27" class="ltx_text ltx_lst_identifier">assistants</span><span id="lstnumberx64.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.29" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx64.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.31" class="ltx_text ltx_lst_identifier">response</span><span id="lstnumberx64.32" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.33" class="ltx_text ltx_lst_identifier">to</span>
</div>
<div id="lstnumberx65" class="ltx_listingline">
<span id="lstnumberx65.1" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx65.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx65.3" class="ltx_text ltx_lst_identifier">user</span><span id="lstnumberx65.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx65.5" class="ltx_text ltx_lst_identifier">question</span><span id="lstnumberx65.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx65.7" class="ltx_text ltx_lst_identifier">displayed</span><span id="lstnumberx65.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx65.9" class="ltx_text ltx_lst_identifier">above</span>.
</div>
<div id="lstnumberx66" class="ltx_listingline">
<span id="lstnumberx66.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx66.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.3" class="ltx_text ltx_lst_identifier">rate</span><span id="lstnumberx66.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.5" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx66.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.7" class="ltx_text ltx_lst_identifier">helpfulness</span>,<span id="lstnumberx66.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.9" class="ltx_text ltx_lst_identifier">relevance</span>,<span id="lstnumberx66.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.11" class="ltx_text ltx_lst_identifier">accuracy</span>,<span id="lstnumberx66.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.13" class="ltx_text ltx_lst_identifier">level</span><span id="lstnumberx66.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.15" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx66.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.17" class="ltx_text ltx_lst_identifier">details</span><span id="lstnumberx66.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.19" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx66.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.21" class="ltx_text ltx_lst_identifier">their</span><span id="lstnumberx66.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.23" class="ltx_text ltx_lst_identifier">responses</span>.<span id="lstnumberx66.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.25" class="ltx_text ltx_lst_identifier">Each</span>
</div>
<div id="lstnumberx67" class="ltx_listingline">
<span id="lstnumberx67.1" class="ltx_text ltx_lst_identifier">assistant</span><span id="lstnumberx67.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.3" class="ltx_text ltx_lst_identifier">receives</span><span id="lstnumberx67.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.5" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx67.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.7" class="ltx_text ltx_lst_identifier">overall</span><span id="lstnumberx67.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.9" class="ltx_text ltx_lst_identifier">score</span><span id="lstnumberx67.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.11" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx67.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx67.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.15" class="ltx_text ltx_lst_identifier">scale</span><span id="lstnumberx67.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.17" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx67.18" class="ltx_text ltx_lst_space"> </span>1<span id="lstnumberx67.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.20" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx67.21" class="ltx_text ltx_lst_space"> </span>10,<span id="lstnumberx67.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.23" class="ltx_text ltx_lst_identifier">where</span><span id="lstnumberx67.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.25" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx67.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.27" class="ltx_text ltx_lst_identifier">higher</span><span id="lstnumberx67.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.29" class="ltx_text ltx_lst_identifier">score</span><span id="lstnumberx67.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.31" class="ltx_text ltx_lst_identifier">indicates</span>
</div>
<div id="lstnumberx68" class="ltx_listingline">
<span id="lstnumberx68.1" class="ltx_text ltx_lst_identifier">better</span><span id="lstnumberx68.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx68.3" class="ltx_text ltx_lst_identifier">overall</span><span id="lstnumberx68.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx68.5" class="ltx_text ltx_lst_identifier">performance</span>.
</div>
<div id="lstnumberx69" class="ltx_listingline">
<span id="lstnumberx69.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx69.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.3" class="ltx_text ltx_lst_identifier">only</span><span id="lstnumberx69.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.5" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx69.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.7" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx69.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.9" class="ltx_text ltx_lst_identifier">single</span><span id="lstnumberx69.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.11" class="ltx_text ltx_lst_identifier">line</span><span id="lstnumberx69.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.13" class="ltx_text ltx_lst_identifier">containing</span><span id="lstnumberx69.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.15" class="ltx_text ltx_lst_identifier">only</span><span id="lstnumberx69.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.17" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx69.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.19" class="ltx_text ltx_lst_identifier">values</span><span id="lstnumberx69.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.21" class="ltx_text ltx_lst_identifier">indicating</span><span id="lstnumberx69.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx69.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.25" class="ltx_text ltx_lst_identifier">scores</span><span id="lstnumberx69.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.27" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx69.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.29" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx69.30" class="ltx_text ltx_lst_space"> </span>1
</div>
<div id="lstnumberx70" class="ltx_listingline">
<span id="lstnumberx70.1" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx70.2" class="ltx_text ltx_lst_space"> </span>2,<span id="lstnumberx70.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.4" class="ltx_text ltx_lst_identifier">respectively</span>.<span id="lstnumberx70.5" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.6" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx70.7" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.8" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx70.9" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.10" class="ltx_text ltx_lst_identifier">scores</span><span id="lstnumberx70.11" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.12" class="ltx_text ltx_lst_identifier">are</span><span id="lstnumberx70.13" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.14" class="ltx_text ltx_lst_identifier">separated</span><span id="lstnumberx70.15" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.16" class="ltx_text ltx_lst_identifier">by</span><span id="lstnumberx70.17" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.18" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx70.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.20" class="ltx_text ltx_lst_identifier">space</span>.
</div>
<div id="lstnumberx71" class="ltx_listingline">
<span id="lstnumberx71.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx71.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.3" class="ltx_text ltx_lst_identifier">avoiding</span><span id="lstnumberx71.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.5" class="ltx_text ltx_lst_identifier">any</span><span id="lstnumberx71.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.7" class="ltx_text ltx_lst_identifier">potential</span><span id="lstnumberx71.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.9" class="ltx_text ltx_lst_identifier">bias</span><span id="lstnumberx71.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.11" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx71.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.13" class="ltx_text ltx_lst_identifier">ensuring</span><span id="lstnumberx71.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.15" class="ltx_text ltx_lst_identifier">that</span><span id="lstnumberx71.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.17" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx71.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.19" class="ltx_text ltx_lst_identifier">order</span><span id="lstnumberx71.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.21" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx71.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.23" class="ltx_text ltx_lst_identifier">which</span><span id="lstnumberx71.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.25" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx71.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.27" class="ltx_text ltx_lst_identifier">responses</span><span id="lstnumberx71.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.29" class="ltx_text ltx_lst_identifier">were</span>
</div>
<div id="lstnumberx72" class="ltx_listingline">
<span id="lstnumberx72.1" class="ltx_text ltx_lst_identifier">presented</span><span id="lstnumberx72.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.3" class="ltx_text ltx_lst_identifier">does</span><span id="lstnumberx72.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.5" class="ltx_text ltx_lst_identifier">not</span><span id="lstnumberx72.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.7" class="ltx_text ltx_lst_identifier">affect</span><span id="lstnumberx72.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.9" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx72.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.11" class="ltx_text ltx_lst_identifier">judgment</span>.
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Prompt template used in Contrastive Filtering to compare the responses of the strong and the target LLMs. We directly use the strong LLM with this template as the scorer <math id="A1.F11.2.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="A1.F11.2.m1.1b"><mi id="A1.F11.2.m1.1.1" xref="A1.F11.2.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="A1.F11.2.m1.1c"><ci id="A1.F11.2.m1.1.1.cmml" xref="A1.F11.2.m1.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F11.2.m1.1d">S</annotation></semantics></math> to avoid additional costs from calling a third-party LLM.</figcaption>
</figure>
<figure id="A1.F12" class="ltx_figure">
<div id="A1.F12.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ClN5c3RlbTogWW91IGFyZSBhIGhlbHBmdWwgYW5kIHByZWNpc2UgYXNzaXN0YW50IGZvciBjaGVja2luZyB0aGUgcXVhbGl0eSBvZiB0aGUgYW5zd2VyLgpccGFyVXNlcjoKPFF1ZXN0aW9uPgpbVGhlIFN0YXJ0IG9mIEFzc2lzdGFudCAxJ3MgQW5zd2VyXQo8YW5zd2VyXzE+CltUaGUgRW5kIG9mIEFzc2lzdGFudCAxJ3MgQW5zd2VyXQpbVGhlIFN0YXJ0IG9mIEFzc2lzdGFudCAyJ3MgQW5zd2VyXQo8YW5zd2VyXzI+CltUaGUgRW5kIG9mIEFzc2lzdGFudCAyJ3MgQW5zd2VyXQpccGFyV2Ugd291bGQgbGlrZSB0byByZXF1ZXN0IHlvdXIgZmVlZGJhY2sgb24gdGhlIHBlcmZvcm1hbmNlIG9mIHR3byBBSSBhc3Npc3RhbnRzIGluIHJlc3BvbnNlIHRvCnRoZSB1c2VyIHF1ZXN0aW9uIGRpc3BsYXllZCBhYm92ZS4KUGxlYXNlIHJhdGUgdGhlIGhlbHBmdWxuZXNzLCByZWxldmFuY2UsIGFjY3VyYWN5LCBsZXZlbCBvZiBkZXRhaWxzIG9mIHRoZWlyIHJlc3BvbnNlcy4gRWFjaAphc3Npc3RhbnQgcmVjZWl2ZXMgYW4gb3ZlcmFsbCBzY29yZSBvbiBhIHNjYWxlIG9mIDEgdG8gMTAsIHdoZXJlIGEgaGlnaGVyIHNjb3JlIGluZGljYXRlcwpiZXR0ZXIgb3ZlcmFsbCBwZXJmb3JtYW5jZS4KUGxlYXNlIGZpcnN0IG91dHB1dCBhIHNpbmdsZSBsaW5lIGNvbnRhaW5pbmcgb25seSB0d28gdmFsdWVzIGluZGljYXRpbmcgdGhlIHNjb3JlcyBmb3IgQXNzaXN0YW50IDEKYW5kIDIsIHJlc3BlY3RpdmVseS4KVGhlIHR3byBzY29yZXMgYXJlIHNlcGFyYXRlZCBieSBhIHNwYWNlLiBJbiB0aGUgc3Vic2VxdWVudCBsaW5lLCBwbGVhc2UgcHJvdmlkZSBhIGNvbXByZWhlbnNpdmUKZXhwbGFuYXRpb24gb2YgeW91ciBldmFsdWF0aW9uLCBhdm9pZGluZyBhbnkgcG90ZW50aWFsIGJpYXMgYW5kIGVuc3VyaW5nIHRoYXQgdGhlIG9yZGVyIGluIHdoaWNoCnRoZSByZXNwb25zZXMgd2VyZSBwcmVzZW50ZWQgZG9lcyBub3QgYWZmZWN0IHlvdXIganVkZ21lbnQuCg==" download="">â¬‡</a></div>
<div id="lstnumberx73" class="ltx_listingline">
</div>
<div id="lstnumberx74" class="ltx_listingline">
<span id="lstnumberx74.1" class="ltx_text ltx_lst_identifier">System</span>:<span id="lstnumberx74.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.3" class="ltx_text ltx_lst_identifier">You</span><span id="lstnumberx74.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.5" class="ltx_text ltx_lst_identifier">are</span><span id="lstnumberx74.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.7" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx74.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.9" class="ltx_text ltx_lst_identifier">helpful</span><span id="lstnumberx74.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.11" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx74.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.13" class="ltx_text ltx_lst_identifier">precise</span><span id="lstnumberx74.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.15" class="ltx_text ltx_lst_identifier">assistant</span><span id="lstnumberx74.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.17" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx74.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.19" class="ltx_text ltx_lst_identifier">checking</span><span id="lstnumberx74.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.21" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx74.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.23" class="ltx_text ltx_lst_identifier">quality</span><span id="lstnumberx74.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.25" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx74.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.27" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx74.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.29" class="ltx_text ltx_lst_identifier">answer</span>.
</div>
<div id="lstnumberx75" class="ltx_listingline">\<span id="lstnumberx75.1" class="ltx_text ltx_lst_identifier">parUser</span>:
</div>
<div id="lstnumberx76" class="ltx_listingline">&lt;<span id="lstnumberx76.1" class="ltx_text ltx_lst_identifier">Question</span>&gt;
</div>
<div id="lstnumberx77" class="ltx_listingline">[<span id="lstnumberx77.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx77.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx77.3" class="ltx_text ltx_lst_identifier">Start</span><span id="lstnumberx77.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx77.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx77.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx77.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx77.8" class="ltx_text ltx_lst_space"> </span>1â€™<span id="lstnumberx77.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx77.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx77.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx78" class="ltx_listingline">&lt;<span id="lstnumberx78.1" class="ltx_text ltx_lst_identifier">answer_1</span>&gt;
</div>
<div id="lstnumberx79" class="ltx_listingline">[<span id="lstnumberx79.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx79.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx79.3" class="ltx_text ltx_lst_identifier">End</span><span id="lstnumberx79.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx79.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx79.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx79.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx79.8" class="ltx_text ltx_lst_space"> </span>1â€™<span id="lstnumberx79.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx79.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx79.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx80" class="ltx_listingline">[<span id="lstnumberx80.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx80.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx80.3" class="ltx_text ltx_lst_identifier">Start</span><span id="lstnumberx80.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx80.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx80.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx80.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx80.8" class="ltx_text ltx_lst_space"> </span>2â€™<span id="lstnumberx80.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx80.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx80.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx81" class="ltx_listingline">&lt;<span id="lstnumberx81.1" class="ltx_text ltx_lst_identifier">answer_2</span>&gt;
</div>
<div id="lstnumberx82" class="ltx_listingline">[<span id="lstnumberx82.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx82.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx82.3" class="ltx_text ltx_lst_identifier">End</span><span id="lstnumberx82.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx82.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx82.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx82.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx82.8" class="ltx_text ltx_lst_space"> </span>2â€™<span id="lstnumberx82.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx82.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx82.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx83" class="ltx_listingline">\<span id="lstnumberx83.1" class="ltx_text ltx_lst_identifier">parWe</span><span id="lstnumberx83.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.3" class="ltx_text ltx_lst_identifier">would</span><span id="lstnumberx83.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.5" class="ltx_text ltx_lst_identifier">like</span><span id="lstnumberx83.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx83.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.9" class="ltx_text ltx_lst_identifier">request</span><span id="lstnumberx83.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.11" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx83.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.13" class="ltx_text ltx_lst_identifier">feedback</span><span id="lstnumberx83.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.15" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx83.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.17" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx83.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.19" class="ltx_text ltx_lst_identifier">performance</span><span id="lstnumberx83.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.21" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx83.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.23" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx83.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.25" class="ltx_text ltx_lst_identifier">AI</span><span id="lstnumberx83.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.27" class="ltx_text ltx_lst_identifier">assistants</span><span id="lstnumberx83.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.29" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx83.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.31" class="ltx_text ltx_lst_identifier">response</span><span id="lstnumberx83.32" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.33" class="ltx_text ltx_lst_identifier">to</span>
</div>
<div id="lstnumberx84" class="ltx_listingline">
<span id="lstnumberx84.1" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx84.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx84.3" class="ltx_text ltx_lst_identifier">user</span><span id="lstnumberx84.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx84.5" class="ltx_text ltx_lst_identifier">question</span><span id="lstnumberx84.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx84.7" class="ltx_text ltx_lst_identifier">displayed</span><span id="lstnumberx84.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx84.9" class="ltx_text ltx_lst_identifier">above</span>.
</div>
<div id="lstnumberx85" class="ltx_listingline">
<span id="lstnumberx85.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx85.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.3" class="ltx_text ltx_lst_identifier">rate</span><span id="lstnumberx85.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.5" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx85.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.7" class="ltx_text ltx_lst_identifier">helpfulness</span>,<span id="lstnumberx85.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.9" class="ltx_text ltx_lst_identifier">relevance</span>,<span id="lstnumberx85.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.11" class="ltx_text ltx_lst_identifier">accuracy</span>,<span id="lstnumberx85.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.13" class="ltx_text ltx_lst_identifier">level</span><span id="lstnumberx85.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.15" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx85.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.17" class="ltx_text ltx_lst_identifier">details</span><span id="lstnumberx85.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.19" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx85.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.21" class="ltx_text ltx_lst_identifier">their</span><span id="lstnumberx85.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.23" class="ltx_text ltx_lst_identifier">responses</span>.<span id="lstnumberx85.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.25" class="ltx_text ltx_lst_identifier">Each</span>
</div>
<div id="lstnumberx86" class="ltx_listingline">
<span id="lstnumberx86.1" class="ltx_text ltx_lst_identifier">assistant</span><span id="lstnumberx86.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.3" class="ltx_text ltx_lst_identifier">receives</span><span id="lstnumberx86.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.5" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx86.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.7" class="ltx_text ltx_lst_identifier">overall</span><span id="lstnumberx86.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.9" class="ltx_text ltx_lst_identifier">score</span><span id="lstnumberx86.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.11" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx86.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx86.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.15" class="ltx_text ltx_lst_identifier">scale</span><span id="lstnumberx86.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.17" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx86.18" class="ltx_text ltx_lst_space"> </span>1<span id="lstnumberx86.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.20" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx86.21" class="ltx_text ltx_lst_space"> </span>10,<span id="lstnumberx86.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.23" class="ltx_text ltx_lst_identifier">where</span><span id="lstnumberx86.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.25" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx86.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.27" class="ltx_text ltx_lst_identifier">higher</span><span id="lstnumberx86.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.29" class="ltx_text ltx_lst_identifier">score</span><span id="lstnumberx86.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.31" class="ltx_text ltx_lst_identifier">indicates</span>
</div>
<div id="lstnumberx87" class="ltx_listingline">
<span id="lstnumberx87.1" class="ltx_text ltx_lst_identifier">better</span><span id="lstnumberx87.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx87.3" class="ltx_text ltx_lst_identifier">overall</span><span id="lstnumberx87.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx87.5" class="ltx_text ltx_lst_identifier">performance</span>.
</div>
<div id="lstnumberx88" class="ltx_listingline">
<span id="lstnumberx88.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx88.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.3" class="ltx_text ltx_lst_identifier">first</span><span id="lstnumberx88.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.5" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx88.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.7" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx88.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.9" class="ltx_text ltx_lst_identifier">single</span><span id="lstnumberx88.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.11" class="ltx_text ltx_lst_identifier">line</span><span id="lstnumberx88.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.13" class="ltx_text ltx_lst_identifier">containing</span><span id="lstnumberx88.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.15" class="ltx_text ltx_lst_identifier">only</span><span id="lstnumberx88.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.17" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx88.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.19" class="ltx_text ltx_lst_identifier">values</span><span id="lstnumberx88.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.21" class="ltx_text ltx_lst_identifier">indicating</span><span id="lstnumberx88.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx88.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.25" class="ltx_text ltx_lst_identifier">scores</span><span id="lstnumberx88.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.27" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx88.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.29" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx88.30" class="ltx_text ltx_lst_space"> </span>1
</div>
<div id="lstnumberx89" class="ltx_listingline">
<span id="lstnumberx89.1" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx89.2" class="ltx_text ltx_lst_space"> </span>2,<span id="lstnumberx89.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx89.4" class="ltx_text ltx_lst_identifier">respectively</span>.
</div>
<div id="lstnumberx90" class="ltx_listingline">
<span id="lstnumberx90.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx90.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.3" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx90.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.5" class="ltx_text ltx_lst_identifier">scores</span><span id="lstnumberx90.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.7" class="ltx_text ltx_lst_identifier">are</span><span id="lstnumberx90.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.9" class="ltx_text ltx_lst_identifier">separated</span><span id="lstnumberx90.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.11" class="ltx_text ltx_lst_identifier">by</span><span id="lstnumberx90.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx90.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.15" class="ltx_text ltx_lst_identifier">space</span>.<span id="lstnumberx90.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.17" class="ltx_text ltx_lst_identifier">In</span><span id="lstnumberx90.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx90.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.21" class="ltx_text ltx_lst_identifier">subsequent</span><span id="lstnumberx90.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.23" class="ltx_text ltx_lst_identifier">line</span>,<span id="lstnumberx90.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.25" class="ltx_text ltx_lst_identifier">please</span><span id="lstnumberx90.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.27" class="ltx_text ltx_lst_identifier">provide</span><span id="lstnumberx90.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.29" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx90.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.31" class="ltx_text ltx_lst_identifier">comprehensive</span>
</div>
<div id="lstnumberx91" class="ltx_listingline">
<span id="lstnumberx91.1" class="ltx_text ltx_lst_identifier">explanation</span><span id="lstnumberx91.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.3" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx91.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.5" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx91.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.7" class="ltx_text ltx_lst_identifier">evaluation</span>,<span id="lstnumberx91.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.9" class="ltx_text ltx_lst_identifier">avoiding</span><span id="lstnumberx91.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.11" class="ltx_text ltx_lst_identifier">any</span><span id="lstnumberx91.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.13" class="ltx_text ltx_lst_identifier">potential</span><span id="lstnumberx91.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.15" class="ltx_text ltx_lst_identifier">bias</span><span id="lstnumberx91.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.17" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx91.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.19" class="ltx_text ltx_lst_identifier">ensuring</span><span id="lstnumberx91.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.21" class="ltx_text ltx_lst_identifier">that</span><span id="lstnumberx91.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx91.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.25" class="ltx_text ltx_lst_identifier">order</span><span id="lstnumberx91.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.27" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx91.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.29" class="ltx_text ltx_lst_identifier">which</span>
</div>
<div id="lstnumberx92" class="ltx_listingline">
<span id="lstnumberx92.1" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx92.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.3" class="ltx_text ltx_lst_identifier">responses</span><span id="lstnumberx92.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.5" class="ltx_text ltx_lst_identifier">were</span><span id="lstnumberx92.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.7" class="ltx_text ltx_lst_identifier">presented</span><span id="lstnumberx92.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.9" class="ltx_text ltx_lst_identifier">does</span><span id="lstnumberx92.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.11" class="ltx_text ltx_lst_identifier">not</span><span id="lstnumberx92.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.13" class="ltx_text ltx_lst_identifier">affect</span><span id="lstnumberx92.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.15" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx92.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.17" class="ltx_text ltx_lst_identifier">judgment</span>.
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Prompt template for automatic evaluation using LLM (<span id="A1.F12.3.1" class="ltx_text ltx_font_italic">e.g.</span>, ChatGPT, GPT-4) as the judge.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.05874" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.05875" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2404.05875">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.05875" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.05876" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 16:42:54 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>