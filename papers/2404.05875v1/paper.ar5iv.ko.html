<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.05875] CodecLM: Aligning Language Models with Tailored Synthetic Data</title><meta property="og:description" content="Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next-token prediction objective and users’ actual goals…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CodecLM: Aligning Language Models with Tailored Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="CodecLM: Aligning Language Models with Tailored Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.05875">

<!--Generated on Sun May  5 16:42:54 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">CodecLM: Aligning Language Models with Tailored Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zifeng Wang<sup id="id12.12.id1" class="ltx_sup">†</sup>, Chun-Liang Li<sup id="id13.13.id2" class="ltx_sup">†</sup>, Vincent Perot<sup id="id14.14.id3" class="ltx_sup">∗</sup>, Long T. Le<sup id="id15.15.id4" class="ltx_sup">†</sup>, 
<br class="ltx_break"><span id="id11.11.7" class="ltx_text ltx_font_bold">Jin Miao<sup id="id11.11.7.1" class="ltx_sup"><span id="id11.11.7.1.1" class="ltx_text ltx_font_medium">‡</span></sup>, Zizhao Zhang<sup id="id11.11.7.2" class="ltx_sup"><span id="id11.11.7.2.1" class="ltx_text ltx_font_medium">‡</span></sup>, Chen-Yu Lee<sup id="id11.11.7.3" class="ltx_sup"><span id="id11.11.7.3.1" class="ltx_text ltx_font_medium">†</span></sup>, Tomas Pfister<sup id="id11.11.7.4" class="ltx_sup"><span id="id11.11.7.4.1" class="ltx_text ltx_font_medium">†</span></sup> 
<br class="ltx_break"><sup id="id11.11.7.5" class="ltx_sup"><span id="id11.11.7.5.1" class="ltx_text ltx_font_medium">†</span></sup>Google Cloud AI Research, <sup id="id11.11.7.6" class="ltx_sup"><span id="id11.11.7.6.1" class="ltx_text ltx_font_medium">‡</span></sup>Google Cloud AI, <sup id="id11.11.7.7" class="ltx_sup"><span id="id11.11.7.7.1" class="ltx_text ltx_font_medium">∗</span></sup>Google Research
<br class="ltx_break"></span><span id="id16.16.id5" class="ltx_text ltx_font_typewriter">{zifengw, chunliang, vperot, longtle,</span><span id="id17.17.id6" class="ltx_text ltx_font_bold"> 
<br class="ltx_break"></span><span id="id18.18.id7" class="ltx_text ltx_font_typewriter">jinmiao, zizhaoz, chenyulee, tpfister}@google.com</span><span id="id19.19.id8" class="ltx_text ltx_font_bold">
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id20.id1">명령어 튜닝은 큰 언어 모델(LLM)과 특정 태스크 명령을 정렬하는 핵심으로 등장하여 다음 토큰 예측 목표와 사용자의 실제 목표 사이의 불일치를 완화한다. 인간이 데이터를 수집하거나 주석을 달기 위한 노동력과 시간 비용을 줄이기 위해 연구자들은 명령 정렬 합성 데이터를 생성하기 위해 LLM의 사용을 탐구하기 시작한다. 최근의 연구는 다양한 명령어를 생성하고 LLM을 적용하여 명령어 복잡도를 높이는 데 초점을 맞추고 있으며, 종종 다운스트림 사용 사례를 무시한다. 다른 타겟 명령어 분포 및 LLMs에서 더 나은 명령어 추종 능력을 이끌어내기 위해 <em class="ltx_emph ltx_font_italic" id="id20.id1.1">tailor</em> 고품질 데이터를 사용하는 방법은 여전히 불분명하다. 이를 위해 다운스트림 명령어 분포와 LLM이 다른 LLM 정렬을 위한 고품질 합성 데이터를 적응적으로 생성하기 위한 일반적인 프레임워크인 <span class="ltx_text ltx_font_bold" id="id20.id1.2">CodecLM</span>을 소개한다. Encode-Decode 원리를 바탕으로 LLMs을 코덱으로 사용하여 데이터 생성 과정을 안내한다. 먼저 <em class="ltx_emph ltx_font_italic" id="id20.id1.3">encode</em> seed instructions to metadata, which is concise keywords generated on the fly to capture the target instruction distribution, and <em class="ltx_emph ltx_font_italic" id="id20.id1.4">decode</em> metadata to create tailored instructions. 또한 데이터 효율이 높은 샘플에 맞게 디코딩하는 동안 Self-Rubrics와 Contrastive Filtering을 도입한다. 벤치마크에 이어 4개의 오픈 도메인 지침에 대한 광범위한 실험은 현재 최신 기술에 대한 CodecLM의 유효성을 검증한다.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.11" class="ltx_block ltx_align_bottom">
<p class="ltx_p" id="p1.11.12"><span class="ltx_text ltx_font_bold" id="p1.11.12.1">CodecLM: Aligning Language Models with Tailored Synthetic Data</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.11.11" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.11.11.11" class="ltx_text ltx_inline-block" style="width:0.0pt;">

<span id="p1.11.11.11.11" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.4.4.4.4.4" class="ltx_tr">
<span id="p1.4.4.4.4.4.4" class="ltx_td ltx_align_center"><span id="p1.4.4.4.4.4.4.4" class="ltx_text ltx_font_bold">Zifeng Wang<sup id="p1.4.4.4.4.4.4.4.1" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_medium">†</span></sup>, Chun-Liang Li<sup id="p1.4.4.4.4.4.4.4.2" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.2.1" class="ltx_text ltx_font_medium">†</span></sup>, Vincent Perot<sup id="p1.4.4.4.4.4.4.4.3" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.3.1" class="ltx_text ltx_font_medium">∗</span></sup>, Long T. Le<sup id="p1.4.4.4.4.4.4.4.4" class="ltx_sup"><span id="p1.4.4.4.4.4.4.4.4.1" class="ltx_text ltx_font_medium">†</span></sup>,</span></span></span>
<span id="p1.8.8.8.8.8" class="ltx_tr">
<span id="p1.8.8.8.8.8.4" class="ltx_td ltx_align_center"><span id="p1.8.8.8.8.8.4.4" class="ltx_text ltx_font_bold">Jin Miao<sup id="p1.8.8.8.8.8.4.4.1" class="ltx_sup"><span id="p1.8.8.8.8.8.4.4.1.1" class="ltx_text ltx_font_medium">‡</span></sup>, Zizhao Zhang<sup id="p1.8.8.8.8.8.4.4.2" class="ltx_sup"><span id="p1.8.8.8.8.8.4.4.2.1" class="ltx_text ltx_font_medium">‡</span></sup>, Chen-Yu Lee<sup id="p1.8.8.8.8.8.4.4.3" class="ltx_sup"><span id="p1.8.8.8.8.8.4.4.3.1" class="ltx_text ltx_font_medium">†</span></sup>, Tomas Pfister<sup id="p1.8.8.8.8.8.4.4.4" class="ltx_sup"><span id="p1.8.8.8.8.8.4.4.4.1" class="ltx_text ltx_font_medium">†</span></sup></span></span></span>
<span id="p1.11.11.11.11.11" class="ltx_tr">
<span id="p1.11.11.11.11.11.3" class="ltx_td ltx_align_center"><sup id="p1.11.11.11.11.11.3.1" class="ltx_sup">†</sup>Google Cloud AI Research, <sup id="p1.11.11.11.11.11.3.2" class="ltx_sup">‡</sup>Google Cloud AI, <sup id="p1.11.11.11.11.11.3.3" class="ltx_sup">∗</sup>Google Research</span></span>
<span id="p1.11.11.11.11.12.1" class="ltx_tr">
<span id="p1.11.11.11.11.12.1.1" class="ltx_td ltx_align_center"><span id="p1.11.11.11.11.12.1.1.1" class="ltx_text ltx_font_typewriter">{zifengw, chunliang, vperot, longtle,</span></span></span>
<span id="p1.11.11.11.11.13.2" class="ltx_tr">
<span id="p1.11.11.11.11.13.2.1" class="ltx_td ltx_align_center"><span id="p1.11.11.11.11.13.2.1.1" class="ltx_text ltx_font_typewriter">jinmiao, zizhaoz, chenyulee, tpfister}@google.com</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2404.05875/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="438" height="391" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1:</span>Overview of CodecLM. 먼저 <span class="ltx_text ltx_font_bold" id="S1.F1.3.1">encode</span> seed instructions into metadata to capture the underlying distribution of instructions. 이 메타데이터는 대상 명령어 분포와 정렬된 고품질 합성 명령어를 조정하기 위해 Self-Rubrics 및 Contrastive Filtering을 통해 <span class="ltx_text ltx_font_bold" id="S1.F1.4.2">decoded</span>입니다. 명확성을 위해 도면에는 중간 명령어 및 응답이 생략되어 있다.</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">대규모 언어 모델(LLM)은 광범위한 자연 언어 처리(NLP) 작업 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="#bib.bib6" title="">2020</a>; Ouyang et al., <a class="ltx_ref" href="#bib.bib36" title="">2022</a>; OpenAI, <a class="ltx_ref" href="#bib.bib34" title="">2023a</a>; Anil et al., <a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>에 걸쳐 현저한 능력을 나타냈다. 특히, LLMs은 사람이 주석한 데이터 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="#bib.bib44" title="">2023</a>; Bai et al., <a class="ltx_ref" href="#bib.bib3" title="">2022</a>)</cite>에 대한 미세 조정 또는 더 강한 LLMs<cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib47" title="">2022</a>; Taori et al., <a class="ltx_ref" href="#bib.bib41" title="">2023</a>; Chiang et al., <a class="ltx_ref" href="#bib.bib9" title="">2023</a>; Peng et al., <a class="ltx_ref" href="#bib.bib37" title="">2023</a>)</cite>에서 추출한 지식 등 다양한 방법을 통해 향상된 명령어 추종을 위해 훈련될 수 있다. 이 분야의 최근 발전은 LLMs의 명령어 수행 능력을 향상시키는 데 고품질 데이터의 중요한 역할을 강조한다. 그러나 인간 주석을 통해 이러한 데이터를 획득하는 것은 비용 억제적이며 규모 조정이 어려워 추가 진행을 방해한다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">인간 주석에 대한 대안적인 해결책으로서, 최근 연구는 LLM 정렬을 위한 명령-응답 쌍을 예제 데이터 또는 프롬프트로 프롬프트하고 결과 <cite class="ltx_cite ltx_citemacro_citep">(Honovich et al., <a class="ltx_ref" href="#bib.bib20" title="">2022</a>; Wang et al., <a class="ltx_ref" href="#bib.bib47" title="">2022</a>; Li et al., <a class="ltx_ref" href="#bib.bib27" title="">2023</a>; Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>를 반복적으로 정제함으로써 생성하는 것을 탐구한다. 이러한 방법들은 LLM 정렬을 위한 다양하고 복잡한 명령어들을 광범위하게 생성하는데 효과적이지만, 실제 애플리케이션들은 종종 상이한 명령어 분포들을 수반하는 개별 엔터프라이즈 애플리케이션들 또는 개인 어시스턴트 에이전트들 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib35" title="">2023b</a>)</cite>와 같은 특정 다운스트림 태스크들에 LLM을 맞춤화하는 것을 우선시한다. 작업별 정렬을 위한 이 desideratum은 데이터 합성을 위한 핵심 질문으로 이어집니다. <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">어떻게 하면 합성 데이터를 조정하여 다른 명령 후속 작업에 대해 LLM을 정렬할 수 있습니까? </em></p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.1">특히, 현재 데이터 합성 접근법은 태스크별 LLM 정렬을 위한 효과적인 솔루션을 제공하는 데 부족하다. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="#bib.bib47" title="">2022</a>)</cite> 및 <cite class="ltx_cite ltx_citemacro_citet">Xu et al. (<a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>의 이전 작업은 고품질 데이터의 특징으로 다양성과 복잡성을 강조하지만 이러한 접근법은 특정 명령 분포를 포함할 수 있는 다른 다운스트림 작업에 직면할 때 비틀거린다. 한 태스크에 대한 다양한 데이터 세트는 다른 태스크에 대한 명령 분포를 효과적으로 커버하지 못할 수 있다. 또한, "복잡한" 명령의 정의는 주관적일 수 있으며 작업에 따라 달라질 수 있다. 문제를 더 복잡하게 만들기 위해 LLM은 인간이 만든 기준에 따라 단순하게 보이는 다른 지침과 투쟁하면서 겉보기에는 복잡한 일부 지침에서 탁월할 수 있다. 이러한 한계는 특정 다운스트림 태스크에 LLM을 정렬하기 위해 맞춤형 데이터를 생성할 수 있는 통합 데이터 합성 프레임워크의 필요성을 강조한다.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1">이 작업에서는 다양한 다운스트림 작업에 대해 LLM을 정렬하기 위해 체계적으로 맞춤형 고품질 데이터를 생성하는 새로운 프레임워크인 <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">CodecLM</span>을 제시한다. CodecLM에 대한 높은 수준의 개요는 그림 <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">1</span></a>에 나와 있다. Encode-Decode 프로세스 <cite class="ltx_cite ltx_citemacro_citep">(Kramer, <a class="ltx_ref" href="#bib.bib25" title="">1991</a>; Kingma and Welling, <a class="ltx_ref" href="#bib.bib23" title="">2013</a>)</cite>의 원리에 영감을 받아 강력한 LLM을 코덱으로 활용하여 목표 태스크에서 시드 명령어를 명령어 <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">metadata</em>로 "encode"한 다음 메타데이터를 맞춤형 합성 명령어로 "decode"한다. 메타데이터는 다음 효과적인 명령을 위한 <em class="ltx_emph ltx_font_italic" id="S1.p4.1.3">use case</em> 및 <em class="ltx_emph ltx_font_italic" id="S1.p4.1.4">skills</em>을 포함하여 입력 명령어 분포의 단어 수준 추상화 역할을 한다. 시드 명령을 인코딩하여 자동으로 생성하거나 다운스트림 작업에 대한 높은 수준의 기대와 함께 사용자에 의해 직접 제공될 수 있다.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p" id="S1.p5.1">메타데이터가 추출되면, 우리는 그것들을 "디코딩"하여 맞춤형 명령어를 생성한다. 메타데이터를 제약 조건으로 LLM을 프롬프트하여 기본 지침을 만드는 것으로 시작합니다. 명령어 품질을 높이기 위해 <em class="ltx_emph ltx_font_italic" id="S1.p5.1.1">Self-Rubrics</em>을 소개합니다. 다양한 메타데이터에 대해 생성하는 루브릭을 기반으로 기본 명령어를 더 복잡하거나 어렵게 만들기 위해 강력한 LLM에서 적절한 동작을 샘플링한다. 직관적으로 수학에 대한 일반적인 지식 QA 수업은 스포츠에 대한 창의적인 글쓰기에서 복잡성 루브릭과 다를 것이다. 메타데이터에 기반한 자체 생성 루브릭 및 액션을 사용하여 대상 LLM을 다운스트림 작업에 필요한 특정 지식과 더 잘 정렬하는 강력한 LLM 공예 지침이다. <cite class="ltx_cite ltx_citemacro_citet">Xu et al. (<a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>와 유사하게 Self-Rubrics를 반복적으로 실행하여 명령어 복잡도를 제어할 수 있으며, 최종적으로 해당 응답을 생성할 수 있다.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p" id="S1.p6.1">또한 <em class="ltx_emph ltx_font_italic" id="S1.p6.1.1">Contrastive Filtering</em>을 도입하여 타겟과 더 강한 LLM 간의 품질 불일치를 활용하여 가장 효과적인 명령어-응답 쌍을 추가로 식별한다. 이 전략은 (a) 목표 LLM이 고군분투하는 것, 약한 영역에서 더 큰 이득을 위해 개선하도록 추진하는 것, (b) 목표 LLM이 뛰어난 것, 데이터 효율성 향상을 위해 셀프-루브릭 프로세스로 피드백하는 두 가지 주요 명령 세트를 식별한다. 대비 필터링은 대비 디코딩 <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="#bib.bib28" title="">2022</a>)</cite>의 응답 수준 유추 역할을 한다.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p class="ltx_p" id="S1.p7.1">코덱LM은 다양한 LLM 선택을 가진 4개의 개방형 도메인 명령어 후속 벤치마크에 새로운 최첨단 기술을 설정하여 다양한 명령어 분포에 대한 LLM 정렬의 효율성을 입증한다.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Instruction Tuning for LLM Alignment. 지침에 충실하게 따르고 다양한 인간의 선호도에 맞추기 위해 LLM을 조정하는 것은 여전히 중요한 과제이다. 초기 연구는 주로 교차 작업 일반화에 초점을 맞추었으며, 여기서 모델은 다양한 작업 <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="#bib.bib38" title="">2020</a>; Wei et al., <a class="ltx_ref" href="#bib.bib48" title="">2021</a>; Aribandi et al., <a class="ltx_ref" href="#bib.bib2" title="">2021</a>; Victor et al., <a class="ltx_ref" href="#bib.bib45" title="">2022</a>; Chung et al., <a class="ltx_ref" href="#bib.bib10" title="">2022</a>)</cite>에 대한 성능을 개선하기 위해 다양한 공개 NLP 데이터 세트에 대해 미세 조정되었다. 보다 최근에, 연구자들은 더 넓은 범위의 포맷 및 태스크 유형을 특징으로 하는 오픈 도메인으로 확장된 명령어 튜닝을 하였다. 이러한 변화는 인간 생성 명령-응답 쌍 <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="#bib.bib36" title="">2022</a>; Köpf et al., <a class="ltx_ref" href="#bib.bib24" title="">2023</a>; Zhou et al., <a class="ltx_ref" href="#bib.bib55" title="">2023a</a>)</cite> 및 LLM 생성 데이터 <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="#bib.bib41" title="">2023</a>; Chiang et al., <a class="ltx_ref" href="#bib.bib9" title="">2023</a>)</cite>를 크라우드소싱함으로써 주도되었다. 이전 작업과 달리 CodecLM은 명령어 메타데이터의 개념을 활용하여 인간 주석 없이 합성 데이터를 특정 다운스트림 작업에 맞춤화하는 독특한 접근법을 제시한다.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Data Generation for Instruction Tuning. </span> 고품질 명령-응답 쌍에 대한 인간 주석의 높은 비용을 해결하기 위해 여러 연구에서 데이터 생성 프로세스 <cite class="ltx_cite ltx_citemacro_citep">(Schick and Schütze, <a class="ltx_ref" href="#bib.bib39" title="">2021</a>; Liu et al., <a class="ltx_ref" href="#bib.bib30" title="">2022</a>; Meng et al., <a class="ltx_ref" href="#bib.bib33" title="">2023</a>)</cite>를 자동화하는 것을 옹호한다. LLMs의 문맥 내 학습 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="#bib.bib6" title="">2020</a>)</cite> 능력, <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="#bib.bib47" title="">2022</a>); Honovich et al. (<a class="ltx_ref" href="#bib.bib20" title="">2022</a>)</cite> 프롬프트 LLMs를 시드 명령어로 활용하여 합성 LMs를 생성한다. 그런 다음 더 강력한 LLM, <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">e.g.</span>, ChatGPT에 공급되어 타겟(종종 더 작은) LLM<cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="#bib.bib41" title="">2023</a>)</cite>를 훈련하기 위한 응답을 생성한다. 대표적인 작업인 WizardLM<cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>는 명령어의 복잡도를 높이고 생성된 데이터의 난이도 제어를 위해 사람이 만든 고정된 연산 세트를 설계한다. <cite class="ltx_cite ltx_citemacro_citet">Zhao et al. (<a class="ltx_ref" href="#bib.bib53" title="">2023</a>); Zhou et al. (<a class="ltx_ref" href="#bib.bib55" title="">2023a</a>)</cite>는 경험적 연구를 통해 LLM 정렬을 위한 명령어 복잡도의 중요성을 더욱 확인한다. 다운스트림 태스크를 고려하지 않고 미리 정의된 규칙에 의존하는 이러한 작업들과는 달리, CodecLM은 상이한 다운스트림 태스크들 및 타겟 LLMs에 대한 명령어들을 자동으로 맞춤화할 수 있게 한다. 또한 가장 효과적인 명령어-응답 쌍을 추가로 식별하기 위해 Self-Rubrics와 Contrastive Filtering을 도입한다.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Distillation. </span>또는 다른 LLM에서 생성된 응답으로 대상 LLM을 튜닝하는 것은 지식 증류<cite class="ltx_cite ltx_citemacro_citep">(Hinton et al., <a class="ltx_ref" href="#bib.bib19" title="">2015</a>; Beyer et al., <a class="ltx_ref" href="#bib.bib5" title="">2022</a>)</cite>로 볼 수 있다. 그러나, 우리의 초점은 명령어 생성에 머무르지만, 여전히 기존의 증류 기술들 <cite class="ltx_cite ltx_citemacro_citep">(Hsieh et al., <a class="ltx_ref" href="#bib.bib21" title="">2023</a>; Liang et al., <a class="ltx_ref" href="#bib.bib29" title="">2023</a>)</cite>와 쉽게 통합되도록 유연하다.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p" id="S2.p4.1">마지막으로 가장 관련성이 높은 최근 작업 중 몇 가지를 논의합니다. AttrPrompt <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib52" title="">2023</a>)</cite>는 명령 내에서 속성을 추출하여 LLM을 귀속 데이터 생성기로 활용한다. 그러나 이는 분류 작업에만 초점을 맞추고 속성 선택을 위해 인간의 개입이 필요하다. 대조적으로, 우리의 작업은 LLM을 개방형 도메인 지침을 따르도록 정렬하는 광범위한 맥락에 초점을 맞추어 인간의 노력이 필요하지 않다. MSP<cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib7" title="">2023a</a>)</cite>는 생성을 제어하기 위해 훈련 가능한 소프트 프롬프트를 활용하지만 LLM에 대한 그래디언트 액세스가 필요하다. 반면에, 우리의 방법은 고품질 데이터 생성을 위한 API 액세스만 제공하는 블랙박스 LLM과 쉽게 호환된다. SteerLM<cite class="ltx_cite ltx_citemacro_citep">(Dong et al., <a class="ltx_ref" href="#bib.bib11" title="">2023</a>)</cite>는 인간의 선호도를 포착하기 위해 명령 대신 응답의 품질 관련 측면을 분석한다. 따라서 SteerLM은 응답 품질을 향상시키기 위한 병렬 접근 방식으로 CodecLM과 함께 사용될 수 있다.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2404.05875/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2:</span>Overview of the proposed CodecLM. 첫째, 강한 LLM <math alttext="f_{s}" class="ltx_Math" display="inline" id="S2.F2.7.m1.1"><semantics id="S2.F2.7.m1.1b"><msub id="S2.F2.7.m1.1.1" xref="S2.F2.7.m1.1.1.cmml"><mi id="S2.F2.7.m1.1.1.2" xref="S2.F2.7.m1.1.1.2.cmml">f</mi><mi id="S2.F2.7.m1.1.1.3" xref="S2.F2.7.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.7.m1.1c"><apply id="S2.F2.7.m1.1.1.cmml" xref="S2.F2.7.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.7.m1.1.1.1.cmml" xref="S2.F2.7.m1.1.1">subscript</csymbol><ci id="S2.F2.7.m1.1.1.2.cmml" xref="S2.F2.7.m1.1.1.2">𝑓</ci><ci id="S2.F2.7.m1.1.1.3.cmml" xref="S2.F2.7.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.7.m1.1d">f_{s}</annotation></semantics></math>는 시드 명령어를 명령어 메타데이터로 인코딩하여 응답에 필요한 사용 사례와 스킬을 명시한다. 다음으로, <math alttext="f_{s}" class="ltx_Math" display="inline" id="S2.F2.8.m2.1"><semantics id="S2.F2.8.m2.1b"><msub id="S2.F2.8.m2.1.1" xref="S2.F2.8.m2.1.1.cmml"><mi id="S2.F2.8.m2.1.1.2" xref="S2.F2.8.m2.1.1.2.cmml">f</mi><mi id="S2.F2.8.m2.1.1.3" xref="S2.F2.8.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.8.m2.1c"><apply id="S2.F2.8.m2.1.1.cmml" xref="S2.F2.8.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.8.m2.1.1.1.cmml" xref="S2.F2.8.m2.1.1">subscript</csymbol><ci id="S2.F2.8.m2.1.1.2.cmml" xref="S2.F2.8.m2.1.1.2">𝑓</ci><ci id="S2.F2.8.m2.1.1.3.cmml" xref="S2.F2.8.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.8.m2.1d">f_{s}</annotation></semantics></math>는 메타 데이터를 기본 명령어로 디코딩한다. 한편 Self-Rubrics는 <math alttext="f_{s}" class="ltx_Math" display="inline" id="S2.F2.9.m3.1"><semantics id="S2.F2.9.m3.1b"><msub id="S2.F2.9.m3.1.1" xref="S2.F2.9.m3.1.1.cmml"><mi id="S2.F2.9.m3.1.1.2" xref="S2.F2.9.m3.1.1.2.cmml">f</mi><mi id="S2.F2.9.m3.1.1.3" xref="S2.F2.9.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.9.m3.1c"><apply id="S2.F2.9.m3.1.1.cmml" xref="S2.F2.9.m3.1.1"><csymbol cd="ambiguous" id="S2.F2.9.m3.1.1.1.cmml" xref="S2.F2.9.m3.1.1">subscript</csymbol><ci id="S2.F2.9.m3.1.1.2.cmml" xref="S2.F2.9.m3.1.1.2">𝑓</ci><ci id="S2.F2.9.m3.1.1.3.cmml" xref="S2.F2.9.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.9.m3.1d">f_{s}</annotation></semantics></math>를 활용하여 기본 명령어를 개선하기 위한 루브릭과 액션을 생성하여 다운스트림 태스크에 맞게 조정한다. 마지막으로 대조 필터링은 채점 함수 <math alttext="S" class="ltx_Math" display="inline" id="S2.F2.10.m4.1"><semantics id="S2.F2.10.m4.1b"><mi id="S2.F2.10.m4.1.1" xref="S2.F2.10.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.F2.10.m4.1c"><ci id="S2.F2.10.m4.1.1.cmml" xref="S2.F2.10.m4.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.10.m4.1d">S</annotation></semantics></math>를 사용하여 <math alttext="f_{s}" class="ltx_Math" display="inline" id="S2.F2.11.m5.1"><semantics id="S2.F2.11.m5.1b"><msub id="S2.F2.11.m5.1.1" xref="S2.F2.11.m5.1.1.cmml"><mi id="S2.F2.11.m5.1.1.2" xref="S2.F2.11.m5.1.1.2.cmml">f</mi><mi id="S2.F2.11.m5.1.1.3" xref="S2.F2.11.m5.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.11.m5.1c"><apply id="S2.F2.11.m5.1.1.cmml" xref="S2.F2.11.m5.1.1"><csymbol cd="ambiguous" id="S2.F2.11.m5.1.1.1.cmml" xref="S2.F2.11.m5.1.1">subscript</csymbol><ci id="S2.F2.11.m5.1.1.2.cmml" xref="S2.F2.11.m5.1.1.2">𝑓</ci><ci id="S2.F2.11.m5.1.1.3.cmml" xref="S2.F2.11.m5.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.11.m5.1d">f_{s}</annotation></semantics></math>와 <math alttext="f_{t}" class="ltx_Math" display="inline" id="S2.F2.12.m6.1"><semantics id="S2.F2.12.m6.1b"><msub id="S2.F2.12.m6.1.1" xref="S2.F2.12.m6.1.1.cmml"><mi id="S2.F2.12.m6.1.1.2" xref="S2.F2.12.m6.1.1.2.cmml">f</mi><mi id="S2.F2.12.m6.1.1.3" xref="S2.F2.12.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.12.m6.1c"><apply id="S2.F2.12.m6.1.1.cmml" xref="S2.F2.12.m6.1.1"><csymbol cd="ambiguous" id="S2.F2.12.m6.1.1.1.cmml" xref="S2.F2.12.m6.1.1">subscript</csymbol><ci id="S2.F2.12.m6.1.1.2.cmml" xref="S2.F2.12.m6.1.1.2">𝑓</ci><ci id="S2.F2.12.m6.1.1.3.cmml" xref="S2.F2.12.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.12.m6.1d">f_{t}</annotation></semantics></math>의 응답을 비교한다. 가장 효과적인 쌍은 LLM을 정렬하기 위해 선택되고, 덜 효과적인 지침은 추가 개선을 위해 전송된다. 이 그림에서 강한 LLM의 반응은 목표 LLM에 대해 이기고 있으므로 우리는 목표 LLM을 조정하는 지시를 위해 해당 쌍을 선택한다.</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Problem Statement</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p" id="S3.p1.4">본 논문에서는 입력 형식과 태스크에 따라 명령어가 달라지는 문제 <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib47" title="">2022</a>; Taori et al., <a class="ltx_ref" href="#bib.bib41" title="">2023</a>; Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>에 따른 오픈 도메인 명령어를 연구한다. 구체적으로, 우리는 두 가지 실제 시나리오를 고려한다: (1) 주어진 <math alttext="n" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">n</annotation></semantics></math> 시드 명령어 <math alttext="\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><msub id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.2.m2.1.1.3.2" xref="S3.p1.2.m2.1.1.3.2.cmml">𝒟</mi><mi id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml">s</mi></msub><mo id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">=</mo><msubsup id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml"><mrow id="S3.p1.2.m2.1.1.1.1.1.1" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml"><mo id="S3.p1.2.m2.1.1.1.1.1.1.2" stretchy="false" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml">{</mo><msub id="S3.p1.2.m2.1.1.1.1.1.1.1" xref="S3.p1.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S3.p1.2.m2.1.1.1.1.1.1.1.2" xref="S3.p1.2.m2.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S3.p1.2.m2.1.1.1.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.p1.2.m2.1.1.1.1.1.1.3" stretchy="false" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p1.2.m2.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.3.cmml"><mi id="S3.p1.2.m2.1.1.1.1.3.2" xref="S3.p1.2.m2.1.1.1.1.3.2.cmml">i</mi><mo id="S3.p1.2.m2.1.1.1.1.3.1" xref="S3.p1.2.m2.1.1.1.1.3.1.cmml">=</mo><mn id="S3.p1.2.m2.1.1.1.1.3.3" xref="S3.p1.2.m2.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p1.2.m2.1.1.1.3" xref="S3.p1.2.m2.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><eq id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2"></eq><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.p1.2.m2.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.3.2">𝒟</ci><ci id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3">𝑠</ci></apply><apply id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1">superscript</csymbol><apply id="S3.p1.2.m2.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1">subscript</csymbol><set id="S3.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1"><apply id="S3.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1.2">𝐼</ci><ci id="S3.p1.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S3.p1.2.m2.1.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.1.3"><eq id="S3.p1.2.m2.1.1.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.1.1.3.1"></eq><ci id="S3.p1.2.m2.1.1.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.1.1.3.2">𝑖</ci><cn id="S3.p1.2.m2.1.1.1.1.3.3.cmml" type="integer" xref="S3.p1.2.m2.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p1.2.m2.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}</annotation></semantics></math>의 집합으로 시작하며, 각각은 일부 기본 분포 <math alttext="P_{I}" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><msub id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">P</mi><mi id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">𝑃</ci><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">P_{I}</annotation></semantics></math>로부터 도출된다. 실험을 위해 보류된 유효성 검사 세트를 사용하여 시드 명령 세트를 만듭니다. 실질적으로, 그러한 지시들은 사용자들의 사용 트래픽으로부터 수집될 수 있다. (2) 시드 명령어가 없지만 다운스트림 작업에 대한 사전 지식이 있는 경우, 주어진 명령어 메타데이터 세트 <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S3.p1.4.m4.1"><semantics id="S3.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">\mathcal{M}</annotation></semantics></math>로 직접 시작한다(정의를 위해 섹션 <a class="ltx_ref" href="#S4.SS1" title="4.1 LLM as Codec for Instructions ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4.1</span></a> 참조). 후자의 시나리오는 GPTs<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib35" title="">2023b</a>)</cite>의 개념과 유사하게, 기존 명령 데이터가 부족하지만 특정 애플리케이션에 맞춰진 LLM을 점프 스타트하고자 하는 최종 사용자에게 특히 유용하다.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.6" class="ltx_p">We focus on the first scenario for clarity, though the second can be derived similarly by leveraging an LLM as the encoder (Section&nbsp;<a href="#S4.SS1" title="4.1 LLM as Codec for Instructions ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>). Our goal is to generate a set of high-quality instruction-response pairs <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{g}=\{(I^{{}^{\prime}}_{j},R^{{}^{\prime}}_{j})\}_{j=1}^{m}" display="inline"><semantics id="S3.p2.1.m1.1a"><mrow id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><msub id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.1.m1.1.1.3.2" xref="S3.p2.1.m1.1.1.3.2.cmml">𝒟</mi><mi id="S3.p2.1.m1.1.1.3.3" xref="S3.p2.1.m1.1.1.3.3.cmml">g</mi></msub><mo id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">=</mo><msubsup id="S3.p2.1.m1.1.1.1" xref="S3.p2.1.m1.1.1.1.cmml"><mrow id="S3.p2.1.m1.1.1.1.1.1.1" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p2.1.m1.1.1.1.1.1.1.2" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml">{</mo><mrow id="S3.p2.1.m1.1.1.1.1.1.1.1.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml">(</mo><msubsup id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">I</mi><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi><msup id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3a" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"></mi><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">′</mo></msup></msubsup><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.2.4" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml">,</mo><msubsup id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml">R</mi><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3.cmml">j</mi><msup id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3a" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml"></mi><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1.cmml">′</mo></msup></msubsup><mo stretchy="false" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.5" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S3.p2.1.m1.1.1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p2.1.m1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.3.cmml"><mi id="S3.p2.1.m1.1.1.1.1.3.2" xref="S3.p2.1.m1.1.1.1.1.3.2.cmml">j</mi><mo id="S3.p2.1.m1.1.1.1.1.3.1" xref="S3.p2.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S3.p2.1.m1.1.1.1.1.3.3" xref="S3.p2.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p2.1.m1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.3.cmml">m</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><eq id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2"></eq><apply id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.3.1.cmml" xref="S3.p2.1.m1.1.1.3">subscript</csymbol><ci id="S3.p2.1.m1.1.1.3.2.cmml" xref="S3.p2.1.m1.1.1.3.2">𝒟</ci><ci id="S3.p2.1.m1.1.1.3.3.cmml" xref="S3.p2.1.m1.1.1.3.3">𝑔</ci></apply><apply id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1">superscript</csymbol><apply id="S3.p2.1.m1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1">subscript</csymbol><set id="S3.p2.1.m1.1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1"><interval closure="open" id="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2"><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2">𝐼</ci><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3"><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1">′</ci></apply></apply><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3">𝑗</ci></apply><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2">subscript</csymbol><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2">𝑅</ci><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3"><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1">′</ci></apply></apply><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3">𝑗</ci></apply></interval></set><apply id="S3.p2.1.m1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.3"><eq id="S3.p2.1.m1.1.1.1.1.3.1.cmml" xref="S3.p2.1.m1.1.1.1.1.3.1"></eq><ci id="S3.p2.1.m1.1.1.1.1.3.2.cmml" xref="S3.p2.1.m1.1.1.1.1.3.2">𝑗</ci><cn type="integer" id="S3.p2.1.m1.1.1.1.1.3.3.cmml" xref="S3.p2.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p2.1.m1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.3">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\mathcal{D}_{g}=\{(I^{{}^{\prime}}_{j},R^{{}^{\prime}}_{j})\}_{j=1}^{m}</annotation></semantics></math>, using a strong LLM <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">f</mi><mi id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">𝑓</ci><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">f_{s}</annotation></semantics></math>, and then use <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{g}" display="inline"><semantics id="S3.p2.3.m3.1a"><msub id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.3.m3.1.1.2" xref="S3.p2.3.m3.1.1.2.cmml">𝒟</mi><mi id="S3.p2.3.m3.1.1.3" xref="S3.p2.3.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><apply id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p2.3.m3.1.1.1.cmml" xref="S3.p2.3.m3.1.1">subscript</csymbol><ci id="S3.p2.3.m3.1.1.2.cmml" xref="S3.p2.3.m3.1.1.2">𝒟</ci><ci id="S3.p2.3.m3.1.1.3.cmml" xref="S3.p2.3.m3.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">\mathcal{D}_{g}</annotation></semantics></math> to fine-tune the target LLM <math id="S3.p2.4.m4.1" class="ltx_Math" alttext="f_{t}" display="inline"><semantics id="S3.p2.4.m4.1a"><msub id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml"><mi id="S3.p2.4.m4.1.1.2" xref="S3.p2.4.m4.1.1.2.cmml">f</mi><mi id="S3.p2.4.m4.1.1.3" xref="S3.p2.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p2.4.m4.1.1.1.cmml" xref="S3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.p2.4.m4.1.1.2.cmml" xref="S3.p2.4.m4.1.1.2">𝑓</ci><ci id="S3.p2.4.m4.1.1.3.cmml" xref="S3.p2.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">f_{t}</annotation></semantics></math>. We evaluate the performance of the fine-tuned LLM <math id="S3.p2.5.m5.1" class="ltx_Math" alttext="f_{t}" display="inline"><semantics id="S3.p2.5.m5.1a"><msub id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml"><mi id="S3.p2.5.m5.1.1.2" xref="S3.p2.5.m5.1.1.2.cmml">f</mi><mi id="S3.p2.5.m5.1.1.3" xref="S3.p2.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><apply id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.1.cmml" xref="S3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.p2.5.m5.1.1.2.cmml" xref="S3.p2.5.m5.1.1.2">𝑓</ci><ci id="S3.p2.5.m5.1.1.3.cmml" xref="S3.p2.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">f_{t}</annotation></semantics></math> on test instructions from the target distribution <math id="S3.p2.6.m6.1" class="ltx_Math" alttext="P_{I}" display="inline"><semantics id="S3.p2.6.m6.1a"><msub id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml"><mi id="S3.p2.6.m6.1.1.2" xref="S3.p2.6.m6.1.1.2.cmml">P</mi><mi id="S3.p2.6.m6.1.1.3" xref="S3.p2.6.m6.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1b"><apply id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p2.6.m6.1.1.1.cmml" xref="S3.p2.6.m6.1.1">subscript</csymbol><ci id="S3.p2.6.m6.1.1.2.cmml" xref="S3.p2.6.m6.1.1.2">𝑃</ci><ci id="S3.p2.6.m6.1.1.3.cmml" xref="S3.p2.6.m6.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1c">P_{I}</annotation></semantics></math>, to which we are aligning.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>CodecLM</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1">우리는 다른 다운스트림 태스크와 LLMs에 맞춘 고품질 명령어-응답 쌍을 생성하기 위한 일반적인 프레임워크인 CodecLM을 제안하여 인간 주석의 필요성을 제거한다. 방법 개요는 Figure <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a>를 참조한다.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>LLM as Codec for Instructions</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1">이 섹션에서는 강력한 LLM을 코덱으로 사용하는 개념인 <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">i.e.</span>을 인코더와 디코더 모두 명령어 생성을 위해 도입한다.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p2.3"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.3.1">LLM as Encoder with Instruction Metadata. </span> 주어진 시드 명령어 <math alttext="\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><msub id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.1.m1.1.1.3.2" xref="S4.SS1.p2.1.m1.1.1.3.2.cmml">𝒟</mi><mi id="S4.SS1.p2.1.m1.1.1.3.3" xref="S4.SS1.p2.1.m1.1.1.3.3.cmml">s</mi></msub><mo id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">=</mo><msubsup id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml"><mrow id="S4.SS1.p2.1.m1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml"><mo id="S4.SS1.p2.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS1.p2.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS1.p2.1.m1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.3.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.3.2" xref="S4.SS1.p2.1.m1.1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS1.p2.1.m1.1.1.1.1.3.1" xref="S4.SS1.p2.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS1.p2.1.m1.1.1.1.1.3.3" xref="S4.SS1.p2.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS1.p2.1.m1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><eq id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2"></eq><apply id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2">𝒟</ci><ci id="S4.SS1.p2.1.m1.1.1.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3">𝑠</ci></apply><apply id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1">superscript</csymbol><apply id="S4.SS1.p2.1.m1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1">subscript</csymbol><set id="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1"><apply id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2">𝐼</ci><ci id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S4.SS1.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3"><eq id="S4.SS1.p2.1.m1.1.1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3.1"></eq><ci id="S4.SS1.p2.1.m1.1.1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3.2">𝑖</ci><cn id="S4.SS1.p2.1.m1.1.1.1.1.3.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS1.p2.1.m1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}</annotation></semantics></math>를 명령어 <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.3.2">metadata</em> <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\mathcal{M}</annotation></semantics></math>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.3.3">i.e.</span>, 기본 대상 명령어 분포를 캡처하는 키워드입니다. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="#bib.bib47" title="">2022</a>)</cite>에 의한 태스크 풀과 <cite class="ltx_cite ltx_citemacro_citet">Xu et al. (<a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>에 의한 기술 분포에 대한 사후 분석에서 영감을 받아 <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.3.4">use case</em> 및 <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.3.5">skills</em> 두 가지 주요 측면을 포괄하는 메타데이터로 정의한다. 유스 케이스는 의도된 태스크(<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.3.6">e.g.</span>, 질문 응답 또는 크리에이티브 쓰기)를 설명하지만, Skills는 주어진 명령어에 성공적으로 응답하기 위해 필요한 LLM이 지식입니다(<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.3.7">e.g.</span>, 알고리즘 또는 통신). 기술은 종종 다른 사용 사례에 일반화될 수 있다. 따라서, 각각의 인스트럭션은 하나의 유스 케이스를 가지며, 다수의 스킬을 수반할 수 있다. 이 메타데이터를 추출하기 위해 그림 <a class="ltx_ref" href="#A1.F7" title="Figure 7 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">7</span></a>, 부록 <a class="ltx_ref" href="#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.9</span></a>의 프롬프트 템플릿에 이어 강력한 LLM <math alttext="f_{s}" class="ltx_Math" display="inline" id="S4.SS1.p2.3.m3.1"><semantics id="S4.SS1.p2.3.m3.1a"><msub id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">f</mi><mi id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝑓</ci><ci id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">f_{s}</annotation></semantics></math>를 활용한다. 더 세분화된 명령어 후속 메트릭 <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="#bib.bib56" title="">2023b</a>)</cite>를 기반으로 더 풍부한 정의가 가능하지만, 다양한 명령어 분포에 걸쳐 광범위한 적용 가능성을 위해 사용 사례와 기술을 우선시한다. 향후 작업은 이 메타데이터를 더 확장하는 것을 탐색할 수 있다.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p3.6">각 인스트럭션 <math alttext="I_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><msub id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mi id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">I</mi><mi id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">𝐼</ci><ci id="S4.SS1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">I_{i}</annotation></semantics></math>에 대해 해당 유스케이스 <math alttext="u_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><msub id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mi id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">u</mi><mi id="S4.SS1.p3.2.m2.1.1.3" xref="S4.SS1.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">𝑢</ci><ci id="S4.SS1.p3.2.m2.1.1.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">u_{i}</annotation></semantics></math>와 스킬 세트 <math alttext="{\bm{s}}_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><msub id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">𝒔</mi><mi id="S4.SS1.p3.3.m3.1.1.3" xref="S4.SS1.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">𝒔</ci><ci id="S4.SS1.p3.3.m3.1.1.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">{\bm{s}}_{i}</annotation></semantics></math>를 추출한다. 그런 다음 메타데이터 집합을 <math alttext="\mathcal{M}=\{(u_{i},{\bm{s}}_{i})\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S4.SS1.p3.4.m4.1"><semantics id="S4.SS1.p3.4.m4.1a"><mrow id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p3.4.m4.1.1.3" xref="S4.SS1.p3.4.m4.1.1.3.cmml">ℳ</mi><mo id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml">=</mo><msubsup id="S4.SS1.p3.4.m4.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.cmml"><mrow id="S4.SS1.p3.4.m4.1.1.1.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml"><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml">{</mo><mrow id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml"><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.3" stretchy="false" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2.cmml">u</mi><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.4" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml">,</mo><msub id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2.cmml">𝒔</mi><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.5" stretchy="false" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS1.p3.4.m4.1.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.1.3.cmml"><mi id="S4.SS1.p3.4.m4.1.1.1.1.3.2" xref="S4.SS1.p3.4.m4.1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS1.p3.4.m4.1.1.1.1.3.1" xref="S4.SS1.p3.4.m4.1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS1.p3.4.m4.1.1.1.1.3.3" xref="S4.SS1.p3.4.m4.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS1.p3.4.m4.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><eq id="S4.SS1.p3.4.m4.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2"></eq><ci id="S4.SS1.p3.4.m4.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.3">ℳ</ci><apply id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1">superscript</csymbol><apply id="S4.SS1.p3.4.m4.1.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1">subscript</csymbol><set id="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1"><interval closure="open" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2"><apply id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2">𝑢</ci><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2">𝒔</ci><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply></interval></set><apply id="S4.SS1.p3.4.m4.1.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3"><eq id="S4.SS1.p3.4.m4.1.1.1.1.3.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3.1"></eq><ci id="S4.SS1.p3.4.m4.1.1.1.1.3.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3.2">𝑖</ci><cn id="S4.SS1.p3.4.m4.1.1.1.1.3.3.cmml" type="integer" xref="S4.SS1.p3.4.m4.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS1.p3.4.m4.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">\mathcal{M}=\{(u_{i},{\bm{s}}_{i})\}_{i=1}^{n}</annotation></semantics></math>로 갖는다. 명령어들은 시드 명령어들 내의 태스크들 및 능력들의 분포를 반영하는 그들의 <math alttext="u_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.5.m5.1"><semantics id="S4.SS1.p3.5.m5.1a"><msub id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml"><mi id="S4.SS1.p3.5.m5.1.1.2" xref="S4.SS1.p3.5.m5.1.1.2.cmml">u</mi><mi id="S4.SS1.p3.5.m5.1.1.3" xref="S4.SS1.p3.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><apply id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.5.m5.1.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.p3.5.m5.1.1.2.cmml" xref="S4.SS1.p3.5.m5.1.1.2">𝑢</ci><ci id="S4.SS1.p3.5.m5.1.1.3.cmml" xref="S4.SS1.p3.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">u_{i}</annotation></semantics></math> 및 <math alttext="{\bm{s}}_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.6.m6.1"><semantics id="S4.SS1.p3.6.m6.1a"><msub id="S4.SS1.p3.6.m6.1.1" xref="S4.SS1.p3.6.m6.1.1.cmml"><mi id="S4.SS1.p3.6.m6.1.1.2" xref="S4.SS1.p3.6.m6.1.1.2.cmml">𝒔</mi><mi id="S4.SS1.p3.6.m6.1.1.3" xref="S4.SS1.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m6.1b"><apply id="S4.SS1.p3.6.m6.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.6.m6.1.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p3.6.m6.1.1.2.cmml" xref="S4.SS1.p3.6.m6.1.1.2">𝒔</ci><ci id="S4.SS1.p3.6.m6.1.1.3.cmml" xref="S4.SS1.p3.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m6.1c">{\bm{s}}_{i}</annotation></semantics></math>에서 공유하거나 부분적으로 중첩할 수 있다. 유스 케이스 및 스킬은 일부 미리 정의된 세트에 국한되지 않고 즉시 생성되어 더 넓은 적용 가능성을 가능하게 한다. 그러나, 우리는 항상 사전 지식으로 그러한 제약들을 제공할 수 있거나, 심지어 어떠한 시드 명령도 없이 메타데이터를 직접 작성할 수 있다.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p4.3"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.3.1">LLM as Decoder for Instruction Generation. </span> 메타데이터 <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">\mathcal{M}</annotation></semantics></math>가 주어지면, 우리는 생성 및 맞춤 패러다임에 따라 메타데이터를 합성 명령어로 디코딩한다. <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S4.SS1.p4.2.m2.1"><semantics id="S4.SS1.p4.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><ci id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">\mathcal{M}</annotation></semantics></math>의 각 사용 사례 및 스킬 쌍에 대해, 우리는 강한 LLM <math alttext="f_{s}" class="ltx_Math" display="inline" id="S4.SS1.p4.3.m3.1"><semantics id="S4.SS1.p4.3.m3.1a"><msub id="S4.SS1.p4.3.m3.1.1" xref="S4.SS1.p4.3.m3.1.1.cmml"><mi id="S4.SS1.p4.3.m3.1.1.2" xref="S4.SS1.p4.3.m3.1.1.2.cmml">f</mi><mi id="S4.SS1.p4.3.m3.1.1.3" xref="S4.SS1.p4.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><apply id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.3.m3.1.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p4.3.m3.1.1.2.cmml" xref="S4.SS1.p4.3.m3.1.1.2">𝑓</ci><ci id="S4.SS1.p4.3.m3.1.1.3.cmml" xref="S4.SS1.p4.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">f_{s}</annotation></semantics></math>를 프롬프트하여 다중 명령어를 생성하기 위한 제약 조건으로 나열한다. 따라서, 생성된 명령어들은 주어진 사용 사례에 대한 것이며, 주어진 스킬들이 응답될 것을 요구한다. 또한 LLM이 반복적인 지침을 생성하는 것을 방지하기 위해 그 생성이 프롬프트에서 다양하도록 권장하고 LLM이 복사할 수 있는 데모를 제공하지 않는다. 기본 명령어를 생성하기 위한 예시적인 프롬프트 템플릿은 그림<a class="ltx_ref" href="#A1.F8" title="Figure 8 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">8</span></a>, 부록<a class="ltx_ref" href="#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.9</span></a>에 있다. 디코딩 과정을 계속하면서 Self-Rubrics (Section <a class="ltx_ref" href="#S4.SS2" title="4.2 Instruction Tailoring via Self-Rubrics ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4.2</span></a>)와 Contrastive Filtering (Section <a class="ltx_ref" href="#S4.SS3" title="4.3 Instruction Selection via Contrastive Filtering ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4.3</span></a>)을 통해 보다 효과적인 정렬을 위한 기본 명령어를 맞춤화한다.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Instruction Tailoring via Self-Rubrics</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p1.1">메타데이터 조건 명령어는 목표 LLM을 원하는 작업에 정렬하기 위한 토대를 마련합니다. 연구에 따르면 더 복잡한 지침이 정렬 성능<cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>; Zhao et al., <a class="ltx_ref" href="#bib.bib53" title="">2023</a>)</cite>를 향상시킬 수 있다. 일반적인 관행은 추론 단계 또는 제약 조건을 추가하는 것과 같은 복잡한 지침에 일반적인 지침을 만드는 인간 전문가를 포함하는 것이다. 그러나 이 만능 전략은 다양한 지침에 미치지 못한다. 미적분 문제 해결 대 뉴스 기사 작성과 같은 다양한 작업에 대한 지침을 조정하려면 뚜렷한 접근법이 필요하다.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p2.2">따라서 본 논문에서는 추출된 메타데이터에 따라 복잡도를 조절하여 강한 LLM을 맞춤 명령어에 활용하는 Self-Rubrics를 소개한다. 셀프-루브릭들은 먼저 LLM이 명령어 복잡도를 평가하기 위한 메타데이터-특정 루브릭들을 생성하도록 안내한다. 그런 다음 이러한 루브릭에 의해 알려지면 LLM은 명령어의 복잡성을 향상시키기 위해 대응하는 액션 세트를 생성한다. 메타데이터 <math alttext="(u_{i},{\bm{s}}_{i})" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.2"><semantics id="S4.SS2.p2.1.m1.2a"><mrow id="S4.SS2.p2.1.m1.2.2.2" xref="S4.SS2.p2.1.m1.2.2.3.cmml"><mo id="S4.SS2.p2.1.m1.2.2.2.3" stretchy="false" xref="S4.SS2.p2.1.m1.2.2.3.cmml">(</mo><msub id="S4.SS2.p2.1.m1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.1.1.2.cmml">u</mi><mi id="S4.SS2.p2.1.m1.1.1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS2.p2.1.m1.2.2.2.4" xref="S4.SS2.p2.1.m1.2.2.3.cmml">,</mo><msub id="S4.SS2.p2.1.m1.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.cmml"><mi id="S4.SS2.p2.1.m1.2.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.2.cmml">𝒔</mi><mi id="S4.SS2.p2.1.m1.2.2.2.2.3" xref="S4.SS2.p2.1.m1.2.2.2.2.3.cmml">i</mi></msub><mo id="S4.SS2.p2.1.m1.2.2.2.5" stretchy="false" xref="S4.SS2.p2.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.2b"><interval closure="open" id="S4.SS2.p2.1.m1.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2"><apply id="S4.SS2.p2.1.m1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2">𝑢</ci><ci id="S4.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.SS2.p2.1.m1.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.2.2.2.2.1.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2">𝒔</ci><ci id="S4.SS2.p2.1.m1.2.2.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.2c">(u_{i},{\bm{s}}_{i})</annotation></semantics></math>에 대해, 생성된 액션들의 대응하는 세트는 <math alttext="{\bm{a}}_{i}" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1"><semantics id="S4.SS2.p2.2.m2.1a"><msub id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">𝒂</mi><mi id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">𝒂</ci><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">{\bm{a}}_{i}</annotation></semantics></math>이다. 생성된 작업은 인간이 만든 일반 규칙보다 도메인에 더 적합하고 모호하지 않으므로 복잡한 지침이 메타데이터에 의해 캡처된 대상 배포에 더 잘 조정됩니다. 예를 들어, "사업 계획 개발"의 사용 사례와 "시장 조사 및 계획"의 기술에 대해 "추론 단계 추가"와 같은 일반적인 규칙은 모호하고 부적절하다. 반대로 Self-Rubrics는 "SWOT 분석 추가" 및 "시장 경쟁사와의 비교를 포함"(전체 세부 사항에 대해서는 부록 <a class="ltx_ref" href="#A1.SS8" title="A.8 Case Study ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.8</span></a> 참조)와 같은 액션을 생성하여 명령을 복잡하게 만들 수 있습니다. 명령어 개선을 위한 루브릭 및 액션을 생성하기 위한 프롬프트 템플릿은 그림 <a class="ltx_ref" href="#A1.F9" title="Figure 9 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">9</span></a>, 부록 <a class="ltx_ref" href="#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.9</span></a>와 같다.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p3.3">얻어진 동작 <math alttext="\{{\bm{a}}_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><msubsup id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mrow id="S4.SS2.p3.1.m1.1.1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.1.2.cmml"><mo id="S4.SS2.p3.1.m1.1.1.1.1.1.2" stretchy="false" xref="S4.SS2.p3.1.m1.1.1.1.1.2.cmml">{</mo><msub id="S4.SS2.p3.1.m1.1.1.1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1.1.1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.2.cmml">𝒂</mi><mi id="S4.SS2.p3.1.m1.1.1.1.1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS2.p3.1.m1.1.1.1.1.1.3" stretchy="false" xref="S4.SS2.p3.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS2.p3.1.m1.1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.1.3.cmml"><mi id="S4.SS2.p3.1.m1.1.1.1.3.2" xref="S4.SS2.p3.1.m1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS2.p3.1.m1.1.1.1.3.1" xref="S4.SS2.p3.1.m1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS2.p3.1.m1.1.1.1.3.3" xref="S4.SS2.p3.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1">superscript</csymbol><apply id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1">subscript</csymbol><set id="S4.SS2.p3.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1"><apply id="S4.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.2">𝒂</ci><ci id="S4.SS2.p3.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S4.SS2.p3.1.m1.1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3"><eq id="S4.SS2.p3.1.m1.1.1.1.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3.1"></eq><ci id="S4.SS2.p3.1.m1.1.1.1.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3.2">𝑖</ci><cn id="S4.SS2.p3.1.m1.1.1.1.3.3.cmml" type="integer" xref="S4.SS2.p3.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\{{\bm{a}}_{i}\}_{i=1}^{n}</annotation></semantics></math>로, 도<a class="ltx_ref" href="#A1.F10" title="Figure 10 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">10</span></a>의 프롬프트 템플릿에 이어서, 기본 명령어를 복잡하게 하기 위해 반복적으로 <math alttext="f_{s}" class="ltx_Math" display="inline" id="S4.SS2.p3.2.m2.1"><semantics id="S4.SS2.p3.2.m2.1a"><msub id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">f</mi><mi id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">𝑓</ci><ci id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">f_{s}</annotation></semantics></math>를 프롬프트할 수 있다. 우리는 한 쌍의 유스케이스 및 스킬에 대해 생성된 다중 액션으로부터 액션 <math alttext="{\bm{a}}_{i}" class="ltx_Math" display="inline" id="S4.SS2.p3.3.m3.1"><semantics id="S4.SS2.p3.3.m3.1a"><msub id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml"><mi id="S4.SS2.p3.3.m3.1.1.2" xref="S4.SS2.p3.3.m3.1.1.2.cmml">𝒂</mi><mi id="S4.SS2.p3.3.m3.1.1.3" xref="S4.SS2.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><apply id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.1.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p3.3.m3.1.1.2.cmml" xref="S4.SS2.p3.3.m3.1.1.2">𝒂</ci><ci id="S4.SS2.p3.3.m3.1.1.3.cmml" xref="S4.SS2.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">{\bm{a}}_{i}</annotation></semantics></math>를 무작위로 샘플링한다. 이 설계 선택은 제어된 복잡도 <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>를 가능하게 할 뿐만 아니라 LLM에 대한 상이한 동작들 사이의 잠재적인 혼동을 방지한다.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Instruction Selection via Contrastive Filtering</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.p1.1">Self-Rubrics는 명령어 메타데이터를 기반으로 복잡한 명령어를 조정하는 반면, 모든 명령어가 복잡도 <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib8" title="">2023b</a>; Zhou et al., <a class="ltx_ref" href="#bib.bib55" title="">2023a</a>)</cite>에 관계없이 명령어 튜닝에 동등하게 효과적인 것은 아니다. 직관적으로 목표 LLM을 도전적이라고 생각하는 지침에 노출하면 개선 영역을 효과적으로 식별할 수 있다. 따라서 대상 LLM을 정렬하기 위한 가장 효과적인 지침을 선택하는 것이 중요하다.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.13" class="ltx_p">We therefore introduce Contrastive Filtering, a method to select the instructions that can effectively enhance the target LLM <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="f_{t}" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><msub id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">f</mi><mi id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">𝑓</ci><ci id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">f_{t}</annotation></semantics></math>. For clarity, we define the space of all natural language sequences as <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">\mathcal{N}</annotation></semantics></math>. We have the strong LLM <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="f_{s}:\mathcal{N}\to\mathcal{N}" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><msub id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2.2" xref="S4.SS3.p2.3.m3.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.3.m3.1.1.2.3" xref="S4.SS3.p2.3.m3.1.1.2.3.cmml">s</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.3.m3.1.1.3.2" xref="S4.SS3.p2.3.m3.1.1.3.2.cmml">𝒩</mi><mo stretchy="false" id="S4.SS3.p2.3.m3.1.1.3.1" xref="S4.SS3.p2.3.m3.1.1.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.3.m3.1.1.3.3" xref="S4.SS3.p2.3.m3.1.1.3.3.cmml">𝒩</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><ci id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1">:</ci><apply id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.2.1.cmml" xref="S4.SS3.p2.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.2.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2.2">𝑓</ci><ci id="S4.SS3.p2.3.m3.1.1.2.3.cmml" xref="S4.SS3.p2.3.m3.1.1.2.3">𝑠</ci></apply><apply id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3"><ci id="S4.SS3.p2.3.m3.1.1.3.1.cmml" xref="S4.SS3.p2.3.m3.1.1.3.1">→</ci><ci id="S4.SS3.p2.3.m3.1.1.3.2.cmml" xref="S4.SS3.p2.3.m3.1.1.3.2">𝒩</ci><ci id="S4.SS3.p2.3.m3.1.1.3.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3">𝒩</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">f_{s}:\mathcal{N}\to\mathcal{N}</annotation></semantics></math>, the target LLM <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="f_{t}:\mathcal{N}\to\mathcal{N}" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mrow id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><msub id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2.2" xref="S4.SS3.p2.4.m4.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.4.m4.1.1.2.3" xref="S4.SS3.p2.4.m4.1.1.2.3.cmml">t</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.4.m4.1.1.1" xref="S4.SS3.p2.4.m4.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.4.m4.1.1.3.2" xref="S4.SS3.p2.4.m4.1.1.3.2.cmml">𝒩</mi><mo stretchy="false" id="S4.SS3.p2.4.m4.1.1.3.1" xref="S4.SS3.p2.4.m4.1.1.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.4.m4.1.1.3.3" xref="S4.SS3.p2.4.m4.1.1.3.3.cmml">𝒩</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><ci id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1.1">:</ci><apply id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.1.1.2.1.cmml" xref="S4.SS3.p2.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.4.m4.1.1.2.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2.2">𝑓</ci><ci id="S4.SS3.p2.4.m4.1.1.2.3.cmml" xref="S4.SS3.p2.4.m4.1.1.2.3">𝑡</ci></apply><apply id="S4.SS3.p2.4.m4.1.1.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3"><ci id="S4.SS3.p2.4.m4.1.1.3.1.cmml" xref="S4.SS3.p2.4.m4.1.1.3.1">→</ci><ci id="S4.SS3.p2.4.m4.1.1.3.2.cmml" xref="S4.SS3.p2.4.m4.1.1.3.2">𝒩</ci><ci id="S4.SS3.p2.4.m4.1.1.3.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3.3">𝒩</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">f_{t}:\mathcal{N}\to\mathcal{N}</annotation></semantics></math>, and a scoring function <math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="S:\mathcal{N}\to\mathbb{R}" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mrow id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml"><mi id="S4.SS3.p2.5.m5.1.1.2" xref="S4.SS3.p2.5.m5.1.1.2.cmml">S</mi><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.5.m5.1.1.1" xref="S4.SS3.p2.5.m5.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.5.m5.1.1.3" xref="S4.SS3.p2.5.m5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.5.m5.1.1.3.2" xref="S4.SS3.p2.5.m5.1.1.3.2.cmml">𝒩</mi><mo stretchy="false" id="S4.SS3.p2.5.m5.1.1.3.1" xref="S4.SS3.p2.5.m5.1.1.3.1.cmml">→</mo><mi id="S4.SS3.p2.5.m5.1.1.3.3" xref="S4.SS3.p2.5.m5.1.1.3.3.cmml">ℝ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"><ci id="S4.SS3.p2.5.m5.1.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1.1">:</ci><ci id="S4.SS3.p2.5.m5.1.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.2">𝑆</ci><apply id="S4.SS3.p2.5.m5.1.1.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3"><ci id="S4.SS3.p2.5.m5.1.1.3.1.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1">→</ci><ci id="S4.SS3.p2.5.m5.1.1.3.2.cmml" xref="S4.SS3.p2.5.m5.1.1.3.2">𝒩</ci><ci id="S4.SS3.p2.5.m5.1.1.3.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3.3">ℝ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">S:\mathcal{N}\to\mathbb{R}</annotation></semantics></math> to evaluate response quality. In practice, <math id="S4.SS3.p2.6.m6.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS3.p2.6.m6.1a"><mi id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><ci id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">S</annotation></semantics></math> is obtained by reusing the strong LLM <math id="S4.SS3.p2.7.m7.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S4.SS3.p2.7.m7.1a"><msub id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml"><mi id="S4.SS3.p2.7.m7.1.1.2" xref="S4.SS3.p2.7.m7.1.1.2.cmml">f</mi><mi id="S4.SS3.p2.7.m7.1.1.3" xref="S4.SS3.p2.7.m7.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><apply id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.7.m7.1.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1">subscript</csymbol><ci id="S4.SS3.p2.7.m7.1.1.2.cmml" xref="S4.SS3.p2.7.m7.1.1.2">𝑓</ci><ci id="S4.SS3.p2.7.m7.1.1.3.cmml" xref="S4.SS3.p2.7.m7.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">f_{s}</annotation></semantics></math> with a prompt template (Figure&nbsp;<a href="#A1.F11" title="Figure 11 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, Appendix&nbsp;<a href="#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.9</span></a>) adapted from the Vicuna pairwise evaluation template&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>; Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite>. To mitigate potential position bias, we average the scores obtained by exchanging the positions of two responses&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite>. We observe using <math id="S4.SS3.p2.8.m8.1" class="ltx_Math" alttext="f_{s}" display="inline"><semantics id="S4.SS3.p2.8.m8.1a"><msub id="S4.SS3.p2.8.m8.1.1" xref="S4.SS3.p2.8.m8.1.1.cmml"><mi id="S4.SS3.p2.8.m8.1.1.2" xref="S4.SS3.p2.8.m8.1.1.2.cmml">f</mi><mi id="S4.SS3.p2.8.m8.1.1.3" xref="S4.SS3.p2.8.m8.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.8.m8.1b"><apply id="S4.SS3.p2.8.m8.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.8.m8.1.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1">subscript</csymbol><ci id="S4.SS3.p2.8.m8.1.1.2.cmml" xref="S4.SS3.p2.8.m8.1.1.2">𝑓</ci><ci id="S4.SS3.p2.8.m8.1.1.3.cmml" xref="S4.SS3.p2.8.m8.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.8.m8.1c">f_{s}</annotation></semantics></math> for scoring works quite well in practice, so we prioritize this option for simplicity. Given an input instruction <math id="S4.SS3.p2.9.m9.1" class="ltx_Math" alttext="I\in\mathcal{N}" display="inline"><semantics id="S4.SS3.p2.9.m9.1a"><mrow id="S4.SS3.p2.9.m9.1.1" xref="S4.SS3.p2.9.m9.1.1.cmml"><mi id="S4.SS3.p2.9.m9.1.1.2" xref="S4.SS3.p2.9.m9.1.1.2.cmml">I</mi><mo id="S4.SS3.p2.9.m9.1.1.1" xref="S4.SS3.p2.9.m9.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.9.m9.1.1.3" xref="S4.SS3.p2.9.m9.1.1.3.cmml">𝒩</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.9.m9.1b"><apply id="S4.SS3.p2.9.m9.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1"><in id="S4.SS3.p2.9.m9.1.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1.1"></in><ci id="S4.SS3.p2.9.m9.1.1.2.cmml" xref="S4.SS3.p2.9.m9.1.1.2">𝐼</ci><ci id="S4.SS3.p2.9.m9.1.1.3.cmml" xref="S4.SS3.p2.9.m9.1.1.3">𝒩</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.9.m9.1c">I\in\mathcal{N}</annotation></semantics></math>, we obtain responses from both LLMs as <math id="S4.SS3.p2.10.m10.1" class="ltx_Math" alttext="f_{s}(I)" display="inline"><semantics id="S4.SS3.p2.10.m10.1a"><mrow id="S4.SS3.p2.10.m10.1.2" xref="S4.SS3.p2.10.m10.1.2.cmml"><msub id="S4.SS3.p2.10.m10.1.2.2" xref="S4.SS3.p2.10.m10.1.2.2.cmml"><mi id="S4.SS3.p2.10.m10.1.2.2.2" xref="S4.SS3.p2.10.m10.1.2.2.2.cmml">f</mi><mi id="S4.SS3.p2.10.m10.1.2.2.3" xref="S4.SS3.p2.10.m10.1.2.2.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p2.10.m10.1.2.1" xref="S4.SS3.p2.10.m10.1.2.1.cmml">​</mo><mrow id="S4.SS3.p2.10.m10.1.2.3.2" xref="S4.SS3.p2.10.m10.1.2.cmml"><mo stretchy="false" id="S4.SS3.p2.10.m10.1.2.3.2.1" xref="S4.SS3.p2.10.m10.1.2.cmml">(</mo><mi id="S4.SS3.p2.10.m10.1.1" xref="S4.SS3.p2.10.m10.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.10.m10.1.2.3.2.2" xref="S4.SS3.p2.10.m10.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.10.m10.1b"><apply id="S4.SS3.p2.10.m10.1.2.cmml" xref="S4.SS3.p2.10.m10.1.2"><times id="S4.SS3.p2.10.m10.1.2.1.cmml" xref="S4.SS3.p2.10.m10.1.2.1"></times><apply id="S4.SS3.p2.10.m10.1.2.2.cmml" xref="S4.SS3.p2.10.m10.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.10.m10.1.2.2.1.cmml" xref="S4.SS3.p2.10.m10.1.2.2">subscript</csymbol><ci id="S4.SS3.p2.10.m10.1.2.2.2.cmml" xref="S4.SS3.p2.10.m10.1.2.2.2">𝑓</ci><ci id="S4.SS3.p2.10.m10.1.2.2.3.cmml" xref="S4.SS3.p2.10.m10.1.2.2.3">𝑠</ci></apply><ci id="S4.SS3.p2.10.m10.1.1.cmml" xref="S4.SS3.p2.10.m10.1.1">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.10.m10.1c">f_{s}(I)</annotation></semantics></math> and <math id="S4.SS3.p2.11.m11.1" class="ltx_Math" alttext="f_{t}(I)" display="inline"><semantics id="S4.SS3.p2.11.m11.1a"><mrow id="S4.SS3.p2.11.m11.1.2" xref="S4.SS3.p2.11.m11.1.2.cmml"><msub id="S4.SS3.p2.11.m11.1.2.2" xref="S4.SS3.p2.11.m11.1.2.2.cmml"><mi id="S4.SS3.p2.11.m11.1.2.2.2" xref="S4.SS3.p2.11.m11.1.2.2.2.cmml">f</mi><mi id="S4.SS3.p2.11.m11.1.2.2.3" xref="S4.SS3.p2.11.m11.1.2.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p2.11.m11.1.2.1" xref="S4.SS3.p2.11.m11.1.2.1.cmml">​</mo><mrow id="S4.SS3.p2.11.m11.1.2.3.2" xref="S4.SS3.p2.11.m11.1.2.cmml"><mo stretchy="false" id="S4.SS3.p2.11.m11.1.2.3.2.1" xref="S4.SS3.p2.11.m11.1.2.cmml">(</mo><mi id="S4.SS3.p2.11.m11.1.1" xref="S4.SS3.p2.11.m11.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.11.m11.1.2.3.2.2" xref="S4.SS3.p2.11.m11.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.11.m11.1b"><apply id="S4.SS3.p2.11.m11.1.2.cmml" xref="S4.SS3.p2.11.m11.1.2"><times id="S4.SS3.p2.11.m11.1.2.1.cmml" xref="S4.SS3.p2.11.m11.1.2.1"></times><apply id="S4.SS3.p2.11.m11.1.2.2.cmml" xref="S4.SS3.p2.11.m11.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.11.m11.1.2.2.1.cmml" xref="S4.SS3.p2.11.m11.1.2.2">subscript</csymbol><ci id="S4.SS3.p2.11.m11.1.2.2.2.cmml" xref="S4.SS3.p2.11.m11.1.2.2.2">𝑓</ci><ci id="S4.SS3.p2.11.m11.1.2.2.3.cmml" xref="S4.SS3.p2.11.m11.1.2.2.3">𝑡</ci></apply><ci id="S4.SS3.p2.11.m11.1.1.cmml" xref="S4.SS3.p2.11.m11.1.1">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.11.m11.1c">f_{t}(I)</annotation></semantics></math>, respectively. We then define the <em id="S4.SS3.p2.13.1" class="ltx_emph ltx_font_italic">quality gap</em> <math id="S4.SS3.p2.12.m12.1" class="ltx_Math" alttext="G:\mathcal{N}\to\mathbb{R}" display="inline"><semantics id="S4.SS3.p2.12.m12.1a"><mrow id="S4.SS3.p2.12.m12.1.1" xref="S4.SS3.p2.12.m12.1.1.cmml"><mi id="S4.SS3.p2.12.m12.1.1.2" xref="S4.SS3.p2.12.m12.1.1.2.cmml">G</mi><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.12.m12.1.1.1" xref="S4.SS3.p2.12.m12.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.12.m12.1.1.3" xref="S4.SS3.p2.12.m12.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.12.m12.1.1.3.2" xref="S4.SS3.p2.12.m12.1.1.3.2.cmml">𝒩</mi><mo stretchy="false" id="S4.SS3.p2.12.m12.1.1.3.1" xref="S4.SS3.p2.12.m12.1.1.3.1.cmml">→</mo><mi id="S4.SS3.p2.12.m12.1.1.3.3" xref="S4.SS3.p2.12.m12.1.1.3.3.cmml">ℝ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.12.m12.1b"><apply id="S4.SS3.p2.12.m12.1.1.cmml" xref="S4.SS3.p2.12.m12.1.1"><ci id="S4.SS3.p2.12.m12.1.1.1.cmml" xref="S4.SS3.p2.12.m12.1.1.1">:</ci><ci id="S4.SS3.p2.12.m12.1.1.2.cmml" xref="S4.SS3.p2.12.m12.1.1.2">𝐺</ci><apply id="S4.SS3.p2.12.m12.1.1.3.cmml" xref="S4.SS3.p2.12.m12.1.1.3"><ci id="S4.SS3.p2.12.m12.1.1.3.1.cmml" xref="S4.SS3.p2.12.m12.1.1.3.1">→</ci><ci id="S4.SS3.p2.12.m12.1.1.3.2.cmml" xref="S4.SS3.p2.12.m12.1.1.3.2">𝒩</ci><ci id="S4.SS3.p2.12.m12.1.1.3.3.cmml" xref="S4.SS3.p2.12.m12.1.1.3.3">ℝ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.12.m12.1c">G:\mathcal{N}\to\mathbb{R}</annotation></semantics></math> between these responses to estimate the <em id="S4.SS3.p2.13.2" class="ltx_emph ltx_font_italic">effectiveness</em> of the instruction: <math id="S4.SS3.p2.13.m13.5" class="ltx_Math" alttext="G(I)=S(f_{s}(I))-S(f_{t}(I))" display="inline"><semantics id="S4.SS3.p2.13.m13.5a"><mrow id="S4.SS3.p2.13.m13.5.5" xref="S4.SS3.p2.13.m13.5.5.cmml"><mrow id="S4.SS3.p2.13.m13.5.5.4" xref="S4.SS3.p2.13.m13.5.5.4.cmml"><mi id="S4.SS3.p2.13.m13.5.5.4.2" xref="S4.SS3.p2.13.m13.5.5.4.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.5.5.4.1" xref="S4.SS3.p2.13.m13.5.5.4.1.cmml">​</mo><mrow id="S4.SS3.p2.13.m13.5.5.4.3.2" xref="S4.SS3.p2.13.m13.5.5.4.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.4.3.2.1" xref="S4.SS3.p2.13.m13.5.5.4.cmml">(</mo><mi id="S4.SS3.p2.13.m13.1.1" xref="S4.SS3.p2.13.m13.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.4.3.2.2" xref="S4.SS3.p2.13.m13.5.5.4.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p2.13.m13.5.5.3" xref="S4.SS3.p2.13.m13.5.5.3.cmml">=</mo><mrow id="S4.SS3.p2.13.m13.5.5.2" xref="S4.SS3.p2.13.m13.5.5.2.cmml"><mrow id="S4.SS3.p2.13.m13.4.4.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.cmml"><mi id="S4.SS3.p2.13.m13.4.4.1.1.3" xref="S4.SS3.p2.13.m13.4.4.1.1.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.4.4.1.1.2" xref="S4.SS3.p2.13.m13.4.4.1.1.2.cmml">​</mo><mrow id="S4.SS3.p2.13.m13.4.4.1.1.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml"><msub id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.cmml"><mi id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1.cmml">​</mo><mrow id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.3.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.3.2.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">(</mo><mi id="S4.SS3.p2.13.m13.2.2" xref="S4.SS3.p2.13.m13.2.2.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.3.2.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.3" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p2.13.m13.5.5.2.3" xref="S4.SS3.p2.13.m13.5.5.2.3.cmml">−</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.cmml"><mi id="S4.SS3.p2.13.m13.5.5.2.2.3" xref="S4.SS3.p2.13.m13.5.5.2.2.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.5.5.2.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.2.cmml">​</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2.1.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">(</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml"><msub id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.cmml"><mi id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1.cmml">​</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.3.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.3.2.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">(</mo><mi id="S4.SS3.p2.13.m13.3.3" xref="S4.SS3.p2.13.m13.3.3.cmml">I</mi><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.3.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.3" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.13.m13.5b"><apply id="S4.SS3.p2.13.m13.5.5.cmml" xref="S4.SS3.p2.13.m13.5.5"><eq id="S4.SS3.p2.13.m13.5.5.3.cmml" xref="S4.SS3.p2.13.m13.5.5.3"></eq><apply id="S4.SS3.p2.13.m13.5.5.4.cmml" xref="S4.SS3.p2.13.m13.5.5.4"><times id="S4.SS3.p2.13.m13.5.5.4.1.cmml" xref="S4.SS3.p2.13.m13.5.5.4.1"></times><ci id="S4.SS3.p2.13.m13.5.5.4.2.cmml" xref="S4.SS3.p2.13.m13.5.5.4.2">𝐺</ci><ci id="S4.SS3.p2.13.m13.1.1.cmml" xref="S4.SS3.p2.13.m13.1.1">𝐼</ci></apply><apply id="S4.SS3.p2.13.m13.5.5.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2"><minus id="S4.SS3.p2.13.m13.5.5.2.3.cmml" xref="S4.SS3.p2.13.m13.5.5.2.3"></minus><apply id="S4.SS3.p2.13.m13.4.4.1.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1"><times id="S4.SS3.p2.13.m13.4.4.1.1.2.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.2"></times><ci id="S4.SS3.p2.13.m13.4.4.1.1.3.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.3">𝑆</ci><apply id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1"><times id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1"></times><apply id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2">𝑓</ci><ci id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3">𝑠</ci></apply><ci id="S4.SS3.p2.13.m13.2.2.cmml" xref="S4.SS3.p2.13.m13.2.2">𝐼</ci></apply></apply><apply id="S4.SS3.p2.13.m13.5.5.2.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2"><times id="S4.SS3.p2.13.m13.5.5.2.2.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.2"></times><ci id="S4.SS3.p2.13.m13.5.5.2.2.3.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.3">𝑆</ci><apply id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1"><times id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1"></times><apply id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.1.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2">𝑓</ci><ci id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3">𝑡</ci></apply><ci id="S4.SS3.p2.13.m13.3.3.cmml" xref="S4.SS3.p2.13.m13.3.3">𝐼</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.13.m13.5c">G(I)=S(f_{s}(I))-S(f_{t}(I))</annotation></semantics></math>.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.11" class="ltx_p">The quality gap metric <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">G</annotation></semantics></math> reflects how much the target LLM benefits from the strong LLM for each instruction <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mi id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><ci id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">I</annotation></semantics></math>. As demonstrated in Figure&nbsp;<a href="#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, here are two possible cases: (1) <math id="S4.SS3.p3.3.m3.2" class="ltx_Math" alttext="|G(I)|>\theta" display="inline"><semantics id="S4.SS3.p3.3.m3.2a"><mrow id="S4.SS3.p3.3.m3.2.2" xref="S4.SS3.p3.3.m3.2.2.cmml"><mrow id="S4.SS3.p3.3.m3.2.2.1.1" xref="S4.SS3.p3.3.m3.2.2.1.2.cmml"><mo stretchy="false" id="S4.SS3.p3.3.m3.2.2.1.1.2" xref="S4.SS3.p3.3.m3.2.2.1.2.1.cmml">|</mo><mrow id="S4.SS3.p3.3.m3.2.2.1.1.1" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml"><mi id="S4.SS3.p3.3.m3.2.2.1.1.1.2" xref="S4.SS3.p3.3.m3.2.2.1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p3.3.m3.2.2.1.1.1.1" xref="S4.SS3.p3.3.m3.2.2.1.1.1.1.cmml">​</mo><mrow id="S4.SS3.p3.3.m3.2.2.1.1.1.3.2" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.3.m3.2.2.1.1.1.3.2.1" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml">(</mo><mi id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p3.3.m3.2.2.1.1.1.3.2.2" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p3.3.m3.2.2.1.1.3" xref="S4.SS3.p3.3.m3.2.2.1.2.1.cmml">|</mo></mrow><mo id="S4.SS3.p3.3.m3.2.2.2" xref="S4.SS3.p3.3.m3.2.2.2.cmml">&gt;</mo><mi id="S4.SS3.p3.3.m3.2.2.3" xref="S4.SS3.p3.3.m3.2.2.3.cmml">θ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.2b"><apply id="S4.SS3.p3.3.m3.2.2.cmml" xref="S4.SS3.p3.3.m3.2.2"><gt id="S4.SS3.p3.3.m3.2.2.2.cmml" xref="S4.SS3.p3.3.m3.2.2.2"></gt><apply id="S4.SS3.p3.3.m3.2.2.1.2.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1"><abs id="S4.SS3.p3.3.m3.2.2.1.2.1.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.2"></abs><apply id="S4.SS3.p3.3.m3.2.2.1.1.1.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.1"><times id="S4.SS3.p3.3.m3.2.2.1.1.1.1.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.1.1"></times><ci id="S4.SS3.p3.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.1.2">𝐺</ci><ci id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">𝐼</ci></apply></apply><ci id="S4.SS3.p3.3.m3.2.2.3.cmml" xref="S4.SS3.p3.3.m3.2.2.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.2c">|G(I)|&gt;\theta</annotation></semantics></math>, where <math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="\theta\in\mathbb{R}" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><mrow id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml"><mi id="S4.SS3.p3.4.m4.1.1.2" xref="S4.SS3.p3.4.m4.1.1.2.cmml">θ</mi><mo id="S4.SS3.p3.4.m4.1.1.1" xref="S4.SS3.p3.4.m4.1.1.1.cmml">∈</mo><mi id="S4.SS3.p3.4.m4.1.1.3" xref="S4.SS3.p3.4.m4.1.1.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><apply id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1"><in id="S4.SS3.p3.4.m4.1.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1.1"></in><ci id="S4.SS3.p3.4.m4.1.1.2.cmml" xref="S4.SS3.p3.4.m4.1.1.2">𝜃</ci><ci id="S4.SS3.p3.4.m4.1.1.3.cmml" xref="S4.SS3.p3.4.m4.1.1.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">\theta\in\mathbb{R}</annotation></semantics></math> is a certain threshold. This indicates that: Either the strong LLM has a much better response than the target LLM, we add <math id="S4.SS3.p3.5.m5.3" class="ltx_Math" alttext="(I,f_{s}(I))" display="inline"><semantics id="S4.SS3.p3.5.m5.3a"><mrow id="S4.SS3.p3.5.m5.3.3.1" xref="S4.SS3.p3.5.m5.3.3.2.cmml"><mo stretchy="false" id="S4.SS3.p3.5.m5.3.3.1.2" xref="S4.SS3.p3.5.m5.3.3.2.cmml">(</mo><mi id="S4.SS3.p3.5.m5.2.2" xref="S4.SS3.p3.5.m5.2.2.cmml">I</mi><mo id="S4.SS3.p3.5.m5.3.3.1.3" xref="S4.SS3.p3.5.m5.3.3.2.cmml">,</mo><mrow id="S4.SS3.p3.5.m5.3.3.1.1" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml"><msub id="S4.SS3.p3.5.m5.3.3.1.1.2" xref="S4.SS3.p3.5.m5.3.3.1.1.2.cmml"><mi id="S4.SS3.p3.5.m5.3.3.1.1.2.2" xref="S4.SS3.p3.5.m5.3.3.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p3.5.m5.3.3.1.1.2.3" xref="S4.SS3.p3.5.m5.3.3.1.1.2.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p3.5.m5.3.3.1.1.1" xref="S4.SS3.p3.5.m5.3.3.1.1.1.cmml">​</mo><mrow id="S4.SS3.p3.5.m5.3.3.1.1.3.2" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.5.m5.3.3.1.1.3.2.1" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml">(</mo><mi id="S4.SS3.p3.5.m5.1.1" xref="S4.SS3.p3.5.m5.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p3.5.m5.3.3.1.1.3.2.2" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p3.5.m5.3.3.1.4" xref="S4.SS3.p3.5.m5.3.3.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.3b"><interval closure="open" id="S4.SS3.p3.5.m5.3.3.2.cmml" xref="S4.SS3.p3.5.m5.3.3.1"><ci id="S4.SS3.p3.5.m5.2.2.cmml" xref="S4.SS3.p3.5.m5.2.2">𝐼</ci><apply id="S4.SS3.p3.5.m5.3.3.1.1.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1"><times id="S4.SS3.p3.5.m5.3.3.1.1.1.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.1"></times><apply id="S4.SS3.p3.5.m5.3.3.1.1.2.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p3.5.m5.3.3.1.1.2.1.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2">subscript</csymbol><ci id="S4.SS3.p3.5.m5.3.3.1.1.2.2.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2.2">𝑓</ci><ci id="S4.SS3.p3.5.m5.3.3.1.1.2.3.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2.3">𝑠</ci></apply><ci id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1">𝐼</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.3c">(I,f_{s}(I))</annotation></semantics></math> to our high-quality instruction-response pool <math id="S4.SS3.p3.6.m6.1" class="ltx_Math" alttext="\mathcal{D}_{g}" display="inline"><semantics id="S4.SS3.p3.6.m6.1a"><msub id="S4.SS3.p3.6.m6.1.1" xref="S4.SS3.p3.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p3.6.m6.1.1.2" xref="S4.SS3.p3.6.m6.1.1.2.cmml">𝒟</mi><mi id="S4.SS3.p3.6.m6.1.1.3" xref="S4.SS3.p3.6.m6.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.6.m6.1b"><apply id="S4.SS3.p3.6.m6.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.6.m6.1.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1">subscript</csymbol><ci id="S4.SS3.p3.6.m6.1.1.2.cmml" xref="S4.SS3.p3.6.m6.1.1.2">𝒟</ci><ci id="S4.SS3.p3.6.m6.1.1.3.cmml" xref="S4.SS3.p3.6.m6.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.6.m6.1c">\mathcal{D}_{g}</annotation></semantics></math> to fill the gap; Or rarely, the target LLM gives much better response than the strong LLM, we add <math id="S4.SS3.p3.7.m7.3" class="ltx_Math" alttext="(I,f_{t}(I))" display="inline"><semantics id="S4.SS3.p3.7.m7.3a"><mrow id="S4.SS3.p3.7.m7.3.3.1" xref="S4.SS3.p3.7.m7.3.3.2.cmml"><mo stretchy="false" id="S4.SS3.p3.7.m7.3.3.1.2" xref="S4.SS3.p3.7.m7.3.3.2.cmml">(</mo><mi id="S4.SS3.p3.7.m7.2.2" xref="S4.SS3.p3.7.m7.2.2.cmml">I</mi><mo id="S4.SS3.p3.7.m7.3.3.1.3" xref="S4.SS3.p3.7.m7.3.3.2.cmml">,</mo><mrow id="S4.SS3.p3.7.m7.3.3.1.1" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml"><msub id="S4.SS3.p3.7.m7.3.3.1.1.2" xref="S4.SS3.p3.7.m7.3.3.1.1.2.cmml"><mi id="S4.SS3.p3.7.m7.3.3.1.1.2.2" xref="S4.SS3.p3.7.m7.3.3.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p3.7.m7.3.3.1.1.2.3" xref="S4.SS3.p3.7.m7.3.3.1.1.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p3.7.m7.3.3.1.1.1" xref="S4.SS3.p3.7.m7.3.3.1.1.1.cmml">​</mo><mrow id="S4.SS3.p3.7.m7.3.3.1.1.3.2" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.7.m7.3.3.1.1.3.2.1" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml">(</mo><mi id="S4.SS3.p3.7.m7.1.1" xref="S4.SS3.p3.7.m7.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p3.7.m7.3.3.1.1.3.2.2" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p3.7.m7.3.3.1.4" xref="S4.SS3.p3.7.m7.3.3.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.7.m7.3b"><interval closure="open" id="S4.SS3.p3.7.m7.3.3.2.cmml" xref="S4.SS3.p3.7.m7.3.3.1"><ci id="S4.SS3.p3.7.m7.2.2.cmml" xref="S4.SS3.p3.7.m7.2.2">𝐼</ci><apply id="S4.SS3.p3.7.m7.3.3.1.1.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1"><times id="S4.SS3.p3.7.m7.3.3.1.1.1.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.1"></times><apply id="S4.SS3.p3.7.m7.3.3.1.1.2.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p3.7.m7.3.3.1.1.2.1.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2">subscript</csymbol><ci id="S4.SS3.p3.7.m7.3.3.1.1.2.2.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2.2">𝑓</ci><ci id="S4.SS3.p3.7.m7.3.3.1.1.2.3.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2.3">𝑡</ci></apply><ci id="S4.SS3.p3.7.m7.1.1.cmml" xref="S4.SS3.p3.7.m7.1.1">𝐼</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.7.m7.3c">(I,f_{t}(I))</annotation></semantics></math> to <math id="S4.SS3.p3.8.m8.1" class="ltx_Math" alttext="\mathcal{D}_{g}" display="inline"><semantics id="S4.SS3.p3.8.m8.1a"><msub id="S4.SS3.p3.8.m8.1.1" xref="S4.SS3.p3.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p3.8.m8.1.1.2" xref="S4.SS3.p3.8.m8.1.1.2.cmml">𝒟</mi><mi id="S4.SS3.p3.8.m8.1.1.3" xref="S4.SS3.p3.8.m8.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.8.m8.1b"><apply id="S4.SS3.p3.8.m8.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.8.m8.1.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1">subscript</csymbol><ci id="S4.SS3.p3.8.m8.1.1.2.cmml" xref="S4.SS3.p3.8.m8.1.1.2">𝒟</ci><ci id="S4.SS3.p3.8.m8.1.1.3.cmml" xref="S4.SS3.p3.8.m8.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.8.m8.1c">\mathcal{D}_{g}</annotation></semantics></math> as as an implicit regularization to keep the target LLM’s desirable behavior to certain instructions. (2) <math id="S4.SS3.p3.9.m9.2" class="ltx_Math" alttext="|G(I)|\leq\theta" display="inline"><semantics id="S4.SS3.p3.9.m9.2a"><mrow id="S4.SS3.p3.9.m9.2.2" xref="S4.SS3.p3.9.m9.2.2.cmml"><mrow id="S4.SS3.p3.9.m9.2.2.1.1" xref="S4.SS3.p3.9.m9.2.2.1.2.cmml"><mo stretchy="false" id="S4.SS3.p3.9.m9.2.2.1.1.2" xref="S4.SS3.p3.9.m9.2.2.1.2.1.cmml">|</mo><mrow id="S4.SS3.p3.9.m9.2.2.1.1.1" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml"><mi id="S4.SS3.p3.9.m9.2.2.1.1.1.2" xref="S4.SS3.p3.9.m9.2.2.1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p3.9.m9.2.2.1.1.1.1" xref="S4.SS3.p3.9.m9.2.2.1.1.1.1.cmml">​</mo><mrow id="S4.SS3.p3.9.m9.2.2.1.1.1.3.2" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.9.m9.2.2.1.1.1.3.2.1" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml">(</mo><mi id="S4.SS3.p3.9.m9.1.1" xref="S4.SS3.p3.9.m9.1.1.cmml">I</mi><mo stretchy="false" id="S4.SS3.p3.9.m9.2.2.1.1.1.3.2.2" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p3.9.m9.2.2.1.1.3" xref="S4.SS3.p3.9.m9.2.2.1.2.1.cmml">|</mo></mrow><mo id="S4.SS3.p3.9.m9.2.2.2" xref="S4.SS3.p3.9.m9.2.2.2.cmml">≤</mo><mi id="S4.SS3.p3.9.m9.2.2.3" xref="S4.SS3.p3.9.m9.2.2.3.cmml">θ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.9.m9.2b"><apply id="S4.SS3.p3.9.m9.2.2.cmml" xref="S4.SS3.p3.9.m9.2.2"><leq id="S4.SS3.p3.9.m9.2.2.2.cmml" xref="S4.SS3.p3.9.m9.2.2.2"></leq><apply id="S4.SS3.p3.9.m9.2.2.1.2.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1"><abs id="S4.SS3.p3.9.m9.2.2.1.2.1.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.2"></abs><apply id="S4.SS3.p3.9.m9.2.2.1.1.1.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.1"><times id="S4.SS3.p3.9.m9.2.2.1.1.1.1.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.1.1"></times><ci id="S4.SS3.p3.9.m9.2.2.1.1.1.2.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.1.2">𝐺</ci><ci id="S4.SS3.p3.9.m9.1.1.cmml" xref="S4.SS3.p3.9.m9.1.1">𝐼</ci></apply></apply><ci id="S4.SS3.p3.9.m9.2.2.3.cmml" xref="S4.SS3.p3.9.m9.2.2.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.9.m9.2c">|G(I)|\leq\theta</annotation></semantics></math>, where the quality of responses from both LLMs is similar, so learning from <math id="S4.SS3.p3.10.m10.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S4.SS3.p3.10.m10.1a"><mi id="S4.SS3.p3.10.m10.1.1" xref="S4.SS3.p3.10.m10.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.10.m10.1b"><ci id="S4.SS3.p3.10.m10.1.1.cmml" xref="S4.SS3.p3.10.m10.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.10.m10.1c">I</annotation></semantics></math> does not lead to much gain. We then send <math id="S4.SS3.p3.11.m11.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S4.SS3.p3.11.m11.1a"><mi id="S4.SS3.p3.11.m11.1.1" xref="S4.SS3.p3.11.m11.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.11.m11.1b"><ci id="S4.SS3.p3.11.m11.1.1.cmml" xref="S4.SS3.p3.11.m11.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.11.m11.1c">I</annotation></semantics></math> to the next Self-Rubrics iteration for further improvement.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS3.p4.1">Contrastive Filtering은 Self-Rubrics를 보완하여 강력한 LLM으로 목표 LLM의 명령어 수행 능력을 보정하여 효과적인 명령어-응답 쌍을 선택한다. Constrastive Decoding <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="#bib.bib28" title="">2022</a>)</cite>와 유사하게 응답 레벨에서 Contrastive Filtering은 두 LLM의 상호 작용을 LLM-feedback <cite class="ltx_cite ltx_citemacro_citep">(Madaan et al., <a class="ltx_ref" href="#bib.bib32" title="">2023</a>)</cite>로 간주할 수도 있다. 품질 격차를 측정하기 위해 강력한 LLM을 채점 기능으로 채택하지만, 프레임워크는 더 신뢰할 수 있고 포괄적인 채점 및 피드백 시스템<cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="#bib.bib26" title="">2023</a>)</cite>의 발전과 호환될 수 있으며 잠재적으로 이점을 얻을 수 있으며 유망한 미래 작업으로 남긴다.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p" id="S5.p1.1">여러 대표 벤치마크에서 서로 다른 LLM을 사용하여 CodecLM을 평가하기 위한 포괄적인 실험을 수행했으며, 이전 작업 <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>; Chen et al., <a class="ltx_ref" href="#bib.bib8" title="">2023b</a>)</cite>에 따라 오픈 도메인 지침에 대한 잘 확립된 평가 설정을 밀접하게 따랐다. 또한 부록 <a class="ltx_ref" href="#A1.SS8" title="A.8 Case Study ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.8</span></a>의 사례 연구를 수행하여 CodecLM이 명령어를 단계별로 조정하는 방법을 설명한다.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation Benchmarks</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.p1.1">평가 편향을 줄이기 위해 다양한 수업 분포를 가진 4개의 널리 사용되는 오픈 도메인 수업 후속 벤치마크에 대해 CodecLM을 평가한다. 테스트 벤치마크로는 Evol-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>, Vicuna <cite class="ltx_cite ltx_citemacro_citep">(Chiang et al., <a class="ltx_ref" href="#bib.bib9" title="">2023</a>)</cite>, Self-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib47" title="">2022</a>)</cite> 및 Koala <cite class="ltx_cite ltx_citemacro_citep">(Geng et al., <a class="ltx_ref" href="#bib.bib16" title="">2023</a>)</cite>가 있다. 평가를 보완하기 위해 부록 <a class="ltx_ref" href="#A1.SS7" title="A.7 Additional Benchmark Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.7</span></a>의 두 표준 NLP 벤치마크 MMLU <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="#bib.bib18" title="">2020</a>)</cite>와 BBH <cite class="ltx_cite ltx_citemacro_citep">(Suzgun et al., <a class="ltx_ref" href="#bib.bib40" title="">2022</a>)</cite>에 대해서도 평가한다. 벤치마크 세부사항은 부록 <a class="ltx_ref" href="#A1.SS1" title="A.1 Benchmark Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.1</span></a>를 참조해 주십시오.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Baseline Methods</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.p1.1">본 논문에서 제안하는 방법을 명령어 튜닝을 위한 최신 데이터 생성 방법과 비교한다. 공정한 비교를 위해 가능한 한 모든 방법에 동일한 LLM 백본을 제공한다. 또한, 데이터 양의 영향을 제거하기 위해 모든 방법에 대해 명령-응답 쌍의 수를 동일하게 제어한다. 기본 방법에는 <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">Self-Instruct</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib47" title="">2022</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.2">Alpagasus</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib8" title="">2023b</a>)</cite>,  <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.3">Tree-Instruct</span>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.4">WizardLM</span> <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.4">WizardLM</span> < 기준 세부 정보는 부록 <a class="ltx_ref" href="#A1.SS2" title="A.2 Baseline Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.2</span></a>에 제시되어 있다.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Experiment and Evaluation Details</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.1">LLM Backbones. </span> LLaMA 기반 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="#bib.bib44" title="">2023</a>)</cite>와 PaLM 기반 <cite class="ltx_cite ltx_citemacro_citep">(Anil et al., <a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite> LLMs를 대상 LLMs로 채택하였다. LLaMA 기반 표적 LLM의 경우 강력한 LLM으로 Gemini-Pro<cite class="ltx_cite ltx_citemacro_citep">(Team et al., <a class="ltx_ref" href="#bib.bib42" title="">2023</a>)</cite>를 사용하고 표적 LLM으로 LLaMA-7B, -13B를 사용한다. PaLM 기반 표적 LLM의 경우 텍스트 유니콘을 강력한 LLM으로 사용하고 텍스트 들소를 표적 LLM으로 사용한다. PaLM 기반 모델과 Gemini-Pro는 Google Cloud API<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cloud.google.com/vertex-ai" target="_blank" title="">https://cloud.google.com/vertex-ai</a></span></span></span>을 통해 접근할 수 있다.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p2.1.1">Implementation Details of CodecLM. </span> 모든 벤치마크를 20% 유효성 검사 집합과 80% 평가 집합으로 나눕니다. 유효성 검증 세트에서 명령어 메타데이터를 추출하고 자세한 내용은 부록 <a class="ltx_ref" href="#A1.SS3" title="A.3 Additional Implementation Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.3</span></a>를 참조하세요. 지정한 총 데이터 크기에 따라 강력한 LLM이 메타데이터당 동일한 수의 기본 명령어를 생성하도록 촉구한다. 실험 내내 500-8000개의 합성 데이터를 생성합니다. 우리는 4개의 루브릭과 그에 대응하는 액션들을 생성한다. 각 반복에서 우리는 수업을 개선하기 위해 무작위로 1개의 동작을 선택한다. 셀프 루브릭을 최대 4회 반복합니다. 대비 필터링의 경우 모든 실험에서 점수 척도를 10으로, 필터링 임계값을 3으로 설정했다. 이러한 구성을 <cite class="ltx_cite ltx_citemacro_citet">Xu et al. (<a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>와 정렬하고 부록 <a class="ltx_ref" href="#A1.SS3" title="A.3 Additional Implementation Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.3</span></a>-<a class="ltx_ref" href="#A1.SS4" title="A.4 Training Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.4</span></a>에서 이러한 구성, 추가 하이퍼파라미터 설정 및 훈련 세부 사항에 대한 보다 자세한 근거를 남긴다.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1:</span>Results with LLaMA-based target models on 4 open-domain instruction following benchmark. 각 방법은 LLaMA-7B 또는 -13B를 기반으로 목표 모델을 학습하고 강력한 모델인 제미니-프로와 비교한다. 보고된 메트릭 용량 복구 비율(%) <math alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" class="ltx_Math" display="inline" id="S5.T1.2.m1.1"><semantics id="S5.T1.2.m1.1b"><mrow id="S5.T1.2.m1.1.1" xref="S5.T1.2.m1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.2" xref="S5.T1.2.m1.1.1.2a.cmml">CRR</mtext><mo id="S5.T1.2.m1.1.1.1" xref="S5.T1.2.m1.1.1.1.cmml">=</mo><mfrac id="S5.T1.2.m1.1.1.3" xref="S5.T1.2.m1.1.1.3.cmml"><mrow id="S5.T1.2.m1.1.1.3.2" xref="S5.T1.2.m1.1.1.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.2.2" xref="S5.T1.2.m1.1.1.3.2.2a.cmml">wins</mtext><mo id="S5.T1.2.m1.1.1.3.2.1" xref="S5.T1.2.m1.1.1.3.2.1.cmml">+</mo><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.2.3" xref="S5.T1.2.m1.1.1.3.2.3a.cmml">ties</mtext></mrow><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.3" xref="S5.T1.2.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.m1.1c"><apply id="S5.T1.2.m1.1.1.cmml" xref="S5.T1.2.m1.1.1"><eq id="S5.T1.2.m1.1.1.1.cmml" xref="S5.T1.2.m1.1.1.1"></eq><ci id="S5.T1.2.m1.1.1.2a.cmml" xref="S5.T1.2.m1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.2.cmml" xref="S5.T1.2.m1.1.1.2">CRR</mtext></ci><apply id="S5.T1.2.m1.1.1.3.cmml" xref="S5.T1.2.m1.1.1.3"><divide id="S5.T1.2.m1.1.1.3.1.cmml" xref="S5.T1.2.m1.1.1.3"></divide><apply id="S5.T1.2.m1.1.1.3.2.cmml" xref="S5.T1.2.m1.1.1.3.2"><plus id="S5.T1.2.m1.1.1.3.2.1.cmml" xref="S5.T1.2.m1.1.1.3.2.1"></plus><ci id="S5.T1.2.m1.1.1.3.2.2a.cmml" xref="S5.T1.2.m1.1.1.3.2.2"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.2.2.cmml" mathsize="70%" xref="S5.T1.2.m1.1.1.3.2.2">wins</mtext></ci><ci id="S5.T1.2.m1.1.1.3.2.3a.cmml" xref="S5.T1.2.m1.1.1.3.2.3"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.2.3.cmml" mathsize="70%" xref="S5.T1.2.m1.1.1.3.2.3">ties</mtext></ci></apply><ci id="S5.T1.2.m1.1.1.3.3a.cmml" xref="S5.T1.2.m1.1.1.3.3"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.3.cmml" mathsize="70%" xref="S5.T1.2.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.m1.1d">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation></semantics></math>입니다. CRR이 클수록 성능이 향상됩니다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results with LLaMA-based target models on four open-domain instruction following benchmarks. Each method trains a target model based on LLaMA-7B or -13B, and compares against the strong model, Gemini-Pro. The reported metric Capacity Recovery Ratio (%), <math id="S5.T1.2.m1.1" class="ltx_Math" alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" display="inline"><semantics id="S5.T1.2.m1.1b"><mrow id="S5.T1.2.m1.1.1" xref="S5.T1.2.m1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.2" xref="S5.T1.2.m1.1.1.2a.cmml">CRR</mtext><mo id="S5.T1.2.m1.1.1.1" xref="S5.T1.2.m1.1.1.1.cmml">=</mo><mfrac id="S5.T1.2.m1.1.1.3" xref="S5.T1.2.m1.1.1.3.cmml"><mrow id="S5.T1.2.m1.1.1.3.2" xref="S5.T1.2.m1.1.1.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.2.2" xref="S5.T1.2.m1.1.1.3.2.2a.cmml">wins</mtext><mo id="S5.T1.2.m1.1.1.3.2.1" xref="S5.T1.2.m1.1.1.3.2.1.cmml">+</mo><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.2.3" xref="S5.T1.2.m1.1.1.3.2.3a.cmml">ties</mtext></mrow><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.3.3" xref="S5.T1.2.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.m1.1c"><apply id="S5.T1.2.m1.1.1.cmml" xref="S5.T1.2.m1.1.1"><eq id="S5.T1.2.m1.1.1.1.cmml" xref="S5.T1.2.m1.1.1.1"></eq><ci id="S5.T1.2.m1.1.1.2a.cmml" xref="S5.T1.2.m1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S5.T1.2.m1.1.1.2.cmml" xref="S5.T1.2.m1.1.1.2">CRR</mtext></ci><apply id="S5.T1.2.m1.1.1.3.cmml" xref="S5.T1.2.m1.1.1.3"><divide id="S5.T1.2.m1.1.1.3.1.cmml" xref="S5.T1.2.m1.1.1.3"></divide><apply id="S5.T1.2.m1.1.1.3.2.cmml" xref="S5.T1.2.m1.1.1.3.2"><plus id="S5.T1.2.m1.1.1.3.2.1.cmml" xref="S5.T1.2.m1.1.1.3.2.1"></plus><ci id="S5.T1.2.m1.1.1.3.2.2a.cmml" xref="S5.T1.2.m1.1.1.3.2.2"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S5.T1.2.m1.1.1.3.2.2.cmml" xref="S5.T1.2.m1.1.1.3.2.2">wins</mtext></ci><ci id="S5.T1.2.m1.1.1.3.2.3a.cmml" xref="S5.T1.2.m1.1.1.3.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S5.T1.2.m1.1.1.3.2.3.cmml" xref="S5.T1.2.m1.1.1.3.2.3">ties</mtext></ci></apply><ci id="S5.T1.2.m1.1.1.3.3a.cmml" xref="S5.T1.2.m1.1.1.3.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S5.T1.2.m1.1.1.3.3.cmml" xref="S5.T1.2.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.m1.1d">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation></semantics></math>. Larger CRR means better performance.
</figcaption>
<div id="S5.T1.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:557.7pt;height:126.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.0pt,8.6pt) scale(0.88,0.88) ;">
<table id="S5.T1.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.3.1.1.1" class="ltx_tr">
<th id="S5.T1.3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" rowspan="2"><span id="S5.T1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="S5.T1.3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_tt" colspan="4"><span id="S5.T1.3.1.1.1.2.1" class="ltx_text ltx_font_bold">LLaMA-7B vs. Gemini-Pro</span></th>
<th id="S5.T1.3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S5.T1.3.1.1.1.3.1" class="ltx_text ltx_font_bold">LLaMA-13B vs. Gemini-Pro</span></th>
</tr>
<tr id="S5.T1.3.1.2.2" class="ltx_tr">
<th id="S5.T1.3.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.1.1" class="ltx_text ltx_font_bold">Evol-Ins.</span></th>
<th id="S5.T1.3.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.2.1" class="ltx_text ltx_font_bold">Vicuna</span></th>
<th id="S5.T1.3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.3.1" class="ltx_text ltx_font_bold">Koala</span></th>
<th id="S5.T1.3.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t"><span id="S5.T1.3.1.2.2.4.1" class="ltx_text ltx_font_bold">Self-Ins.</span></th>
<th id="S5.T1.3.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.5.1" class="ltx_text ltx_font_bold">Evol-Ins.</span></th>
<th id="S5.T1.3.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.6.1" class="ltx_text ltx_font_bold">Vicuna</span></th>
<th id="S5.T1.3.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.7.1" class="ltx_text ltx_font_bold">Koala</span></th>
<th id="S5.T1.3.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.3.1.2.2.8.1" class="ltx_text ltx_font_bold">Self-Ins.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.3.1.3.1" class="ltx_tr">
<th id="S5.T1.3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t">Self-Instruct</th>
<td id="S5.T1.3.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">72.02</td>
<td id="S5.T1.3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">81.25</td>
<td id="S5.T1.3.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">67.78</td>
<td id="S5.T1.3.1.3.1.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">65.87</td>
<td id="S5.T1.3.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">75.69</td>
<td id="S5.T1.3.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">86.25</td>
<td id="S5.T1.3.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">77.22</td>
<td id="S5.T1.3.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">69.05</td>
</tr>
<tr id="S5.T1.3.1.4.2" class="ltx_tr">
<th id="S5.T1.3.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Alpagasus</th>
<td id="S5.T1.3.1.4.2.2" class="ltx_td ltx_align_center">75.23 <span id="S5.T1.3.1.4.2.2.1" class="ltx_text" style="color:#006B3D;">(+3.2)</span>
</td>
<td id="S5.T1.3.1.4.2.3" class="ltx_td ltx_align_center">81.25 <span id="S5.T1.3.1.4.2.3.1" class="ltx_text" style="color:#006B3D;">(+0.0)</span>
</td>
<td id="S5.T1.3.1.4.2.4" class="ltx_td ltx_align_center">71.11 <span id="S5.T1.3.1.4.2.4.1" class="ltx_text" style="color:#006B3D;">(+3.3)</span>
</td>
<td id="S5.T1.3.1.4.2.5" class="ltx_td ltx_align_center ltx_border_rr">70.24 <span id="S5.T1.3.1.4.2.5.1" class="ltx_text" style="color:#006B3D;">(+4.4)</span>
</td>
<td id="S5.T1.3.1.4.2.6" class="ltx_td ltx_align_center">79.82 <span id="S5.T1.3.1.4.2.6.1" class="ltx_text" style="color:#006B3D;">(+4.1)</span>
</td>
<td id="S5.T1.3.1.4.2.7" class="ltx_td ltx_align_center">87.50 <span id="S5.T1.3.1.4.2.7.1" class="ltx_text" style="color:#006B3D;">(+1.3)</span>
</td>
<td id="S5.T1.3.1.4.2.8" class="ltx_td ltx_align_center">77.78 <span id="S5.T1.3.1.4.2.8.1" class="ltx_text" style="color:#006B3D;">(+0.6)</span>
</td>
<td id="S5.T1.3.1.4.2.9" class="ltx_td ltx_align_center">71.03 <span id="S5.T1.3.1.4.2.9.1" class="ltx_text" style="color:#006B3D;">(+2.0)</span>
</td>
</tr>
<tr id="S5.T1.3.1.5.3" class="ltx_tr">
<th id="S5.T1.3.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Tree-Instruct</th>
<td id="S5.T1.3.1.5.3.2" class="ltx_td ltx_align_center">75.23 <span id="S5.T1.3.1.5.3.2.1" class="ltx_text" style="color:#006B3D;">(+3.2)</span>
</td>
<td id="S5.T1.3.1.5.3.3" class="ltx_td ltx_align_center">81.25 <span id="S5.T1.3.1.5.3.3.1" class="ltx_text" style="color:#006B3D;">(+0.0)</span>
</td>
<td id="S5.T1.3.1.5.3.4" class="ltx_td ltx_align_center">72.78 <span id="S5.T1.3.1.5.3.4.1" class="ltx_text" style="color:#006B3D;">(+5.0)</span>
</td>
<td id="S5.T1.3.1.5.3.5" class="ltx_td ltx_align_center ltx_border_rr">68.65 <span id="S5.T1.3.1.5.3.5.1" class="ltx_text" style="color:#006B3D;">(+2.8)</span>
</td>
<td id="S5.T1.3.1.5.3.6" class="ltx_td ltx_align_center">82.57 <span id="S5.T1.3.1.5.3.6.1" class="ltx_text" style="color:#006B3D;">(+6.9)</span>
</td>
<td id="S5.T1.3.1.5.3.7" class="ltx_td ltx_align_center">87.50 <span id="S5.T1.3.1.5.3.7.1" class="ltx_text" style="color:#006B3D;">(+1.3)</span>
</td>
<td id="S5.T1.3.1.5.3.8" class="ltx_td ltx_align_center">80.56 <span id="S5.T1.3.1.5.3.8.1" class="ltx_text" style="color:#006B3D;">(+3.3)</span>
</td>
<td id="S5.T1.3.1.5.3.9" class="ltx_td ltx_align_center">79.37 <span id="S5.T1.3.1.5.3.9.1" class="ltx_text" style="color:#006B3D;">(+10.3)</span>
</td>
</tr>
<tr id="S5.T1.3.1.6.4" class="ltx_tr">
<th id="S5.T1.3.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM</th>
<td id="S5.T1.3.1.6.4.2" class="ltx_td ltx_align_center">74.31 <span id="S5.T1.3.1.6.4.2.1" class="ltx_text" style="color:#006B3D;">(+2.3)</span>
</td>
<td id="S5.T1.3.1.6.4.3" class="ltx_td ltx_align_center">76.25 <span id="S5.T1.3.1.6.4.3.1" class="ltx_text" style="color:#FF0000;">(-5.0)</span>
</td>
<td id="S5.T1.3.1.6.4.4" class="ltx_td ltx_align_center">65.56 <span id="S5.T1.3.1.6.4.4.1" class="ltx_text" style="color:#FF0000;">(-2.2)</span>
</td>
<td id="S5.T1.3.1.6.4.5" class="ltx_td ltx_align_center ltx_border_rr">71.43 <span id="S5.T1.3.1.6.4.5.1" class="ltx_text" style="color:#006B3D;">(+5.6)</span>
</td>
<td id="S5.T1.3.1.6.4.6" class="ltx_td ltx_align_center">82.11 <span id="S5.T1.3.1.6.4.6.1" class="ltx_text" style="color:#006B3D;">(+6.4)</span>
</td>
<td id="S5.T1.3.1.6.4.7" class="ltx_td ltx_align_center">86.25 <span id="S5.T1.3.1.6.4.7.1" class="ltx_text" style="color:#006B3D;">(+0.0)</span>
</td>
<td id="S5.T1.3.1.6.4.8" class="ltx_td ltx_align_center">78.89 <span id="S5.T1.3.1.6.4.8.1" class="ltx_text" style="color:#006B3D;">(+1.7)</span>
</td>
<td id="S5.T1.3.1.6.4.9" class="ltx_td ltx_align_center">76.19 <span id="S5.T1.3.1.6.4.9.1" class="ltx_text" style="color:#006B3D;">(+7.1)</span>
</td>
</tr>
<tr id="S5.T1.3.1.7.5" class="ltx_tr">
<th id="S5.T1.3.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM+</th>
<td id="S5.T1.3.1.7.5.2" class="ltx_td ltx_align_center">75.69 <span id="S5.T1.3.1.7.5.2.1" class="ltx_text" style="color:#006B3D;">(+3.7)</span>
</td>
<td id="S5.T1.3.1.7.5.3" class="ltx_td ltx_align_center">83.75 <span id="S5.T1.3.1.7.5.3.1" class="ltx_text" style="color:#006B3D;">(+2.5)</span>
</td>
<td id="S5.T1.3.1.7.5.4" class="ltx_td ltx_align_center">68.33 <span id="S5.T1.3.1.7.5.4.1" class="ltx_text" style="color:#006B3D;">(+0.6)</span>
</td>
<td id="S5.T1.3.1.7.5.5" class="ltx_td ltx_align_center ltx_border_rr">72.22 <span id="S5.T1.3.1.7.5.5.1" class="ltx_text" style="color:#006B3D;">(+6.4)</span>
</td>
<td id="S5.T1.3.1.7.5.6" class="ltx_td ltx_align_center">84.40 <span id="S5.T1.3.1.7.5.6.1" class="ltx_text" style="color:#006B3D;">(+8.7)</span>
</td>
<td id="S5.T1.3.1.7.5.7" class="ltx_td ltx_align_center">88.75 <span id="S5.T1.3.1.7.5.7.1" class="ltx_text" style="color:#006B3D;">(+2.5)</span>
</td>
<td id="S5.T1.3.1.7.5.8" class="ltx_td ltx_align_center">81.11 <span id="S5.T1.3.1.7.5.8.1" class="ltx_text" style="color:#006B3D;">(+3.9)</span>
</td>
<td id="S5.T1.3.1.7.5.9" class="ltx_td ltx_align_center">79.76 <span id="S5.T1.3.1.7.5.9.1" class="ltx_text" style="color:#006B3D;">(+10.7)</span>
</td>
</tr>
<tr id="S5.T1.3.1.8.6" class="ltx_tr">
<th id="S5.T1.3.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr">CodecLM (ours)</th>
<td id="S5.T1.3.1.8.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.2.1" class="ltx_text ltx_font_bold">79.82 <span id="S5.T1.3.1.8.6.2.1.1" class="ltx_text" style="color:#006B3D;">(+7.8)</span></span></td>
<td id="S5.T1.3.1.8.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.3.1" class="ltx_text ltx_font_bold">88.75 <span id="S5.T1.3.1.8.6.3.1.1" class="ltx_text" style="color:#006B3D;">(+7.5)</span></span></td>
<td id="S5.T1.3.1.8.6.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.4.1" class="ltx_text ltx_font_bold">74.44 <span id="S5.T1.3.1.8.6.4.1.1" class="ltx_text" style="color:#006B3D;">(+6.7)</span></span></td>
<td id="S5.T1.3.1.8.6.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr"><span id="S5.T1.3.1.8.6.5.1" class="ltx_text ltx_font_bold">78.17 <span id="S5.T1.3.1.8.6.5.1.1" class="ltx_text" style="color:#006B3D;">(+12.3)</span></span></td>
<td id="S5.T1.3.1.8.6.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.6.1" class="ltx_text ltx_font_bold">86.70 <span id="S5.T1.3.1.8.6.6.1.1" class="ltx_text" style="color:#006B3D;">(+11.0)</span></span></td>
<td id="S5.T1.3.1.8.6.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.7.1" class="ltx_text ltx_font_bold">90.00 <span id="S5.T1.3.1.8.6.7.1.1" class="ltx_text" style="color:#006B3D;">(+3.8)</span></span></td>
<td id="S5.T1.3.1.8.6.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.8.1" class="ltx_text ltx_font_bold">82.22 <span id="S5.T1.3.1.8.6.8.1.1" class="ltx_text" style="color:#006B3D;">(+5.0)</span></span></td>
<td id="S5.T1.3.1.8.6.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.3.1.8.6.9.1" class="ltx_text ltx_font_bold">83.33 <span id="S5.T1.3.1.8.6.9.1.1" class="ltx_text" style="color:#006B3D;">(+14.3)</span></span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.SS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p3.1.1">Evaluation. </span> LLM이 지침을 얼마나 잘 따르는지 평가하는 것은 복잡한데, 지침이 다양한 유효한 응답을 가지고 있다는 사실과 인간 평가를 복제하는 도전에서 비롯된다. <cite class="ltx_cite ltx_citemacro_citep">(Dubois et al., <a class="ltx_ref" href="#bib.bib12" title="">2023</a>; Zheng et al., <a class="ltx_ref" href="#bib.bib54" title="">2023</a>)</cite>에 이어 수업에 대한 자동 평가의 최근 발전은 LLM 기반 평가자가 확장 가능하고 설명 가능하며 인간 평가와 일치함을 보여준다. 따라서 우리는 ChatGPT를 기반으로 널리 사용되는 Vicuna 쌍별 평가자 <cite class="ltx_cite ltx_citemacro_citep">(Chiang et al., <a class="ltx_ref" href="#bib.bib9" title="">2023</a>)</cite>를 채택하여 가격과 효율성 측면에서 접근성에 대한 두 LLM의 응답 품질을 비교한다. 평가 프롬프트 템플릿은 그림<a class="ltx_ref" href="#A1.F12" title="Figure 12 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">12</span></a>, 부록<a class="ltx_ref" href="#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.9</span></a>에 있다. LPM 기반 평가자의 일관성을 입증하기 위해 부록 <a class="ltx_ref" href="#A1.SS6" title="A.6 Consistency between LLM-based Evaluators ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.6</span></a>에 GPT-4 기반 평가 결과를 포함한다. LLM 평가자가 가질 수 있는 위치 편향을 완화하기 위해 응답 명령을 교환하여 모든 평가를 두 번 수행한다. 반응이 두 번 승리할 때만 더 나은 것으로 간주된다. <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib8" title="">2023b</a>)</cite>에 이어 평가 랜덤성을 줄이기 위해 온도를 0.0으로 설정하고 다른 파라미터를 기본으로 두었다.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS3.p4.1">이전 작업 <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>; Zhao et al., <a class="ltx_ref" href="#bib.bib53" title="">2023</a>)</cite>와 유사하게, 우리는 목표 LLM이 강한 LLM으로부터 얼마나 많은 모델 용량을 회복하는지 나타내기 위해 강한 LLM에 대한 목표 LLM의 승과 동점의 총 비율을 계산한다. CRR은 모든 대상 LLM 간의 조합 쌍별 비교를 단순화한다. 메트릭 이름을 <em class="ltx_emph ltx_font_italic" id="S5.SS3.p4.1.1">Capacity Recovery Ratio</em> (CRR), 여기서 <math alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" class="ltx_Math" display="inline" id="S5.SS3.p4.1.m1.1"><semantics id="S5.SS3.p4.1.m1.1a"><mrow id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.2" xref="S5.SS3.p4.1.m1.1.1.2a.cmml">CRR</mtext><mo id="S5.SS3.p4.1.m1.1.1.1" xref="S5.SS3.p4.1.m1.1.1.1.cmml">=</mo><mfrac id="S5.SS3.p4.1.m1.1.1.3" xref="S5.SS3.p4.1.m1.1.1.3.cmml"><mrow id="S5.SS3.p4.1.m1.1.1.3.2" xref="S5.SS3.p4.1.m1.1.1.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.3.2.2" xref="S5.SS3.p4.1.m1.1.1.3.2.2a.cmml">wins</mtext><mo id="S5.SS3.p4.1.m1.1.1.3.2.1" xref="S5.SS3.p4.1.m1.1.1.3.2.1.cmml">+</mo><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.3.2.3" xref="S5.SS3.p4.1.m1.1.1.3.2.3a.cmml">ties</mtext></mrow><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.3.3" xref="S5.SS3.p4.1.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><apply id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1"><eq id="S5.SS3.p4.1.m1.1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1.1"></eq><ci id="S5.SS3.p4.1.m1.1.1.2a.cmml" xref="S5.SS3.p4.1.m1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.2.cmml" xref="S5.SS3.p4.1.m1.1.1.2">CRR</mtext></ci><apply id="S5.SS3.p4.1.m1.1.1.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3"><divide id="S5.SS3.p4.1.m1.1.1.3.1.cmml" xref="S5.SS3.p4.1.m1.1.1.3"></divide><apply id="S5.SS3.p4.1.m1.1.1.3.2.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2"><plus id="S5.SS3.p4.1.m1.1.1.3.2.1.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.1"></plus><ci id="S5.SS3.p4.1.m1.1.1.3.2.2a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.2"><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.3.2.2.cmml" mathsize="70%" xref="S5.SS3.p4.1.m1.1.1.3.2.2">wins</mtext></ci><ci id="S5.SS3.p4.1.m1.1.1.3.2.3a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.3"><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.3.2.3.cmml" mathsize="70%" xref="S5.SS3.p4.1.m1.1.1.3.2.3">ties</mtext></ci></apply><ci id="S5.SS3.p4.1.m1.1.1.3.3a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.3"><mtext class="ltx_mathvariant_monospace" id="S5.SS3.p4.1.m1.1.1.3.3.cmml" mathsize="70%" xref="S5.SS3.p4.1.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation></semantics></math>로 지정합니다. 실험에서 우리는 강한 LLM이 목표 모델보다 훨씬 능력이 있기 때문에 타이 수가 종종 승수를 지배한다는 것을 관찰한다. 그래서 우리는 계산에서 승리에 추가적인 가중치를 두지 않는다. CRR이 모델 성능을 충실하게 반영한다는 것을 입증하기 위해 Evol-Instruct의 부록 <a class="ltx_ref" href="#A1.SS5" title="A.5 Detailed Comparison Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.5</span></a>에서 승, 동 및 손실의 정확한 수를 보여준다. 절대값은 우리가 선택하는 특정 LLM 평가자를 기반으로 할 수 있기 때문에 절대값 대신 다른 방법 간의 CRR 격차에 초점을 맞추고 싶다.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Open-Domain Instruction Following</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p1.1.1">Results with LLaMA-based Target LLMs. </span> Table <a class="ltx_ref" href="#S5.T1" title="Table 1 ‣ 5.3 Experiment and Evaluation Details ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">1</span></a>는 명령어 튜닝을 위해 CodecLM과 2000개의 합성 데이터와의 비교 기준선의 성능을 요약한 것이다. 모든 방법은 LLaMA-7B 또는 -13B를 표적 LLM으로 훈련하고 데이터를 생성하는 강력한 LLM인 제미니-프로와 비교한다. 코덱LM은 크기가 다른 두 개의 목표 LLM으로 모든 벤치마크에서 일관되게 방법을 비교하는 것보다 우수하다. CodecLM의 일관성 있게 우수한 성능은 다른 다운스트림 명령어 분포 및 목표 LLM에 대한 일반화 가능성을 강조한다. Tree-Instruct와 WizardLM의 변형은 모두 명령어 복잡성의 중요성에 초점을 맞추지만, 그들의 성능이 단순한 명령어, 특히 더 큰 목표 LLM을 가진 Alpagasus보다 항상 나은 것은 아니다. 이 관찰은 데이터의 효과가 명령 복잡성에 의해서만 결정될 수 없음을 나타내며 자체 루브릭 및 대조적 필터링 설계의 동기를 검증한다. 또한, 위저드LM+의 위저드LM에 대한 승리는 명령어 메타데이터를 통한 명령어 분산 매칭의 유효성을 확인한다. 대상 LLM을 LLaMA-7B에서 -13B로 이동할 때 모든 방법은 상당한 성능 향상을 얻으며, 이는 모델 크기 스케일링에 대한 사전 발견과 일치한다.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p2.1.1">Results with PaLM-based Models. </span> Table <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.4 Open-Domain Instruction Following ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a>는 LLaMA 기반 실험에서 CodecLM과 가장 성능이 좋은 기준선의 결과를 요약한 것이다. 우리는 계산 예산으로 인해 1000개의 합성 데이터를 생성한다. 텍스트 들소(text-bison)는 명령어 튜닝을 포함한 다양한 기술과 정렬된 독점 모델이기 때문에 기본 접근법으로도 포함한다. 흥미롭게도, 텍스트 들소는 다양한 벤치마크에서 강력한 성능을 얻습니다. 알파가수스와 위저드LM+는 모두 텍스트 들소보다 성능이 낮으며, 이는 잘 조정된 LLM을 지속적으로 개선하는 것이 사소하지 않음을 시사한다. 반대로, 코덱LM은 목표 LLM을 개선하기 위해 고품질 데이터 쌍을 적응적으로 조정하는 핵심 설계 덕분에 대부분의 경우 텍스트 바이슨을 능가한다.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 2:</span>CRR Results on PaLM-based models. 각 방법은 텍스트-들소(text-bison)를 기반으로 대상 모델을 학습하고, 강한 모델인 텍스트-유니콘(text-unicorn)과 비교한다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>CRR Results on PaLM-based models. Each method trains a target model based on text-bison, and compares against the strong model, text-unicorn.
</figcaption>
<div id="S5.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:274.0pt;height:92.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.3pt,7.6pt) scale(0.86,0.86) ;">
<table id="S5.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2"><span id="S5.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="S5.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="4"><span id="S5.T2.1.1.1.1.2.1" class="ltx_text ltx_font_bold">text-bison vs. text-unicorn</span></th>
</tr>
<tr id="S5.T2.1.1.2.2" class="ltx_tr">
<th id="S5.T2.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.2.2.1.1" class="ltx_text ltx_font_bold">Evol-Ins.</span></th>
<th id="S5.T2.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.2.2.2.1" class="ltx_text ltx_font_bold">Vicuna</span></th>
<th id="S5.T2.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.2.2.3.1" class="ltx_text ltx_font_bold">Self-Ins.</span></th>
<th id="S5.T2.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.2.2.4.1" class="ltx_text ltx_font_bold">Koala</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.1.3.1" class="ltx_tr">
<th id="S5.T2.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">text-bison</th>
<td id="S5.T2.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">87.16</td>
<td id="S5.T2.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">81.25</td>
<td id="S5.T2.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.3.1.4.1" class="ltx_text ltx_font_bold">74.21</span></td>
<td id="S5.T2.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">77.47</td>
</tr>
<tr id="S5.T2.1.1.4.2" class="ltx_tr">
<th id="S5.T2.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" style="padding-left:3.0pt;padding-right:3.0pt;">Alpagasus</th>
<td id="S5.T2.1.1.4.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">82.11<span id="S5.T2.1.1.4.2.2.1" class="ltx_text" style="color:#FF0000;">(-5.1)</span>
</td>
<td id="S5.T2.1.1.4.2.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">81.25 <span id="S5.T2.1.1.4.2.3.1" class="ltx_text" style="color:#006B3D;">(+0.0)</span>
</td>
<td id="S5.T2.1.1.4.2.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">67.86 <span id="S5.T2.1.1.4.2.4.1" class="ltx_text" style="color:#FF0000;">(-6.4)</span>
</td>
<td id="S5.T2.1.1.4.2.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">73.33 <span id="S5.T2.1.1.4.2.5.1" class="ltx_text" style="color:#FF0000;">(-4.1)</span>
</td>
</tr>
<tr id="S5.T2.1.1.5.3" class="ltx_tr">
<th id="S5.T2.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" style="padding-left:3.0pt;padding-right:3.0pt;">WizardLM+</th>
<td id="S5.T2.1.1.5.3.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">84.40 <span id="S5.T2.1.1.5.3.2.1" class="ltx_text" style="color:#FF0000;">(-2.8)</span>
</td>
<td id="S5.T2.1.1.5.3.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">78.75 <span id="S5.T2.1.1.5.3.3.1" class="ltx_text" style="color:#FF0000;">(-2.5)</span>
</td>
<td id="S5.T2.1.1.5.3.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">69.44 <span id="S5.T2.1.1.5.3.4.1" class="ltx_text" style="color:#FF0000;">(-4.8)</span>
</td>
<td id="S5.T2.1.1.5.3.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">73.89 <span id="S5.T2.1.1.5.3.5.1" class="ltx_text" style="color:#FF0000;">(-3.6)</span>
</td>
</tr>
<tr id="S5.T2.1.1.6.4" class="ltx_tr">
<th id="S5.T2.1.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" style="padding-left:3.0pt;padding-right:3.0pt;">CodecLM (ours)</th>
<td id="S5.T2.1.1.6.4.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.6.4.2.1" class="ltx_text ltx_font_bold">88.53 <span id="S5.T2.1.1.6.4.2.1.1" class="ltx_text" style="color:#006B3D;">(+1.4)</span></span></td>
<td id="S5.T2.1.1.6.4.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.6.4.3.1" class="ltx_text ltx_font_bold">86.25 <span id="S5.T2.1.1.6.4.3.1.1" class="ltx_text" style="color:#006B3D;">(+5.0)</span></span></td>
<td id="S5.T2.1.1.6.4.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">72.22 <span id="S5.T2.1.1.6.4.4.1" class="ltx_text" style="color:#FF0000;">(-2.0)</span>
</td>
<td id="S5.T2.1.1.6.4.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.1.1.6.4.5.1" class="ltx_text ltx_font_bold">80.56 <span id="S5.T2.1.1.6.4.5.1.1" class="ltx_text" style="color:#006B3D;">(+3.1)</span></span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Ablation Study</h3>

<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3:</span>Ablation study of CodecLM’s core designs. 모든 구성 요소가 최종 성능에 기여합니다.</figcaption>
<div id="S5.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:224.0pt;height:76.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-19.8pt,6.8pt) scale(0.85,0.85) ;">
<table id="S5.T3.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.1.1.1.1" class="ltx_tr">
<td id="S5.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Metadata</span></td>
<td id="S5.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Self-Rubrics</span></td>
<td id="S5.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S5.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Contrastive Filtering</span></td>
<td id="S5.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.1.1.1.1.4.1" class="ltx_text ltx_font_bold">CRR</span></td>
</tr>
<tr id="S5.T3.1.1.2.2" class="ltx_tr">
<td id="S5.T3.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">✗</td>
<td id="S5.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">✗</td>
<td id="S5.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">✗</td>
<td id="S5.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">72.02</td>
</tr>
<tr id="S5.T3.1.1.3.3" class="ltx_tr">
<td id="S5.T3.1.1.3.3.1" class="ltx_td ltx_align_center">✓</td>
<td id="S5.T3.1.1.3.3.2" class="ltx_td ltx_align_center">✗</td>
<td id="S5.T3.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_rr">✗</td>
<td id="S5.T3.1.1.3.3.4" class="ltx_td ltx_align_center">75.23</td>
</tr>
<tr id="S5.T3.1.1.4.4" class="ltx_tr">
<td id="S5.T3.1.1.4.4.1" class="ltx_td ltx_align_center">✓</td>
<td id="S5.T3.1.1.4.4.2" class="ltx_td ltx_align_center">✓</td>
<td id="S5.T3.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_rr">✗</td>
<td id="S5.T3.1.1.4.4.4" class="ltx_td ltx_align_center">77.52</td>
</tr>
<tr id="S5.T3.1.1.5.5" class="ltx_tr">
<td id="S5.T3.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td id="S5.T3.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td id="S5.T3.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr">✓</td>
<td id="S5.T3.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_bb">79.82</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.SS5.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS5.p1.1">이 절에서는 CodecLM의 효과를 경험적으로 탐구하기 위해 포괄적인 절제 연구를 수행한다. 우리는 주로 LLaMA-7B 모델을 표적 LLM으로, 제미니-프로를 강력한 LLM으로 사용하여 실험을 수행하고 Evol-Instruct 벤치마크에 CRR을 보고한다.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p2.1.1">Effectiveness of Core Designs. </span> 우리는 표<a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">3</span></a>의 프레임워크에서 컴포넌트별 기여도를 보여준다. 첫 번째 행은 Self-Instruct의 결과를 베이스라인으로 가지며, 두 번째 행은 명령어 메타데이터의 기본 명령어와 LLM만 정렬하고, 세 번째 행과 네 번째 행에 각각 Self-Rubrics와 Contrastive Filtering을 점진적으로 추가한다. 우리는 모든 구성 요소가 최종 성능에 기여한다는 것을 분명히 관찰합니다. 흥미롭게도 메타데이터에서 기본 명령어를 사용하는 성능은 표 <a class="ltx_ref" href="#S5.T1" title="Table 1 ‣ 5.3 Experiment and Evaluation Details ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">1</span></a>의 WizardLM+와 동등하다. 이 관찰은 지침을 복잡하게 만들기 위한 인간이 만든 전략이 다른 유형의 지침에 맞지 않을 수 있음을 나타낸다. 반대로, Self-Rubrics는 상이한 메타데이터에 기초하여 명령어 개선 액션들을 적응적으로 생성하고, 그 결과 타겟 LLM에 대한 더 나은 맞춤화된 명령어들을 생성한다. 대비 필터링의 추가 개선 사항은 선택된 데이터가 정렬에 실제로 더 효과적임을 보여준다.</p>
</div>
<div id="S5.SS5.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS5.p3.2"><span class="ltx_text ltx_font_bold" id="S5.SS5.p3.2.1">Effect of Number of Iterations. </span> 그림 <a class="ltx_ref" href="#S5.F3" title="Figure 3 ‣ 5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">3</span></a>에서 CodecLM 반복 횟수의 영향을 보여준다. 특히, 우리는 모든 합성 데이터 <math alttext="\mathcal{D}_{g}" class="ltx_Math" display="inline" id="S5.SS5.p3.1.m1.1"><semantics id="S5.SS5.p3.1.m1.1a"><msub id="S5.SS5.p3.1.m1.1.1" xref="S5.SS5.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p3.1.m1.1.1.2" xref="S5.SS5.p3.1.m1.1.1.2.cmml">𝒟</mi><mi id="S5.SS5.p3.1.m1.1.1.3" xref="S5.SS5.p3.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.1.m1.1b"><apply id="S5.SS5.p3.1.m1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS5.p3.1.m1.1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1">subscript</csymbol><ci id="S5.SS5.p3.1.m1.1.1.2.cmml" xref="S5.SS5.p3.1.m1.1.1.2">𝒟</ci><ci id="S5.SS5.p3.1.m1.1.1.3.cmml" xref="S5.SS5.p3.1.m1.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.1.m1.1c">\mathcal{D}_{g}</annotation></semantics></math>에서 각 반복의 데이터 비율을 세어 왼쪽 y축이 있는 파란색 막대 차트에 보여준다. 또한 합성 데이터에 대한 학습 후 CRR에서 목표 모델 성능을 y축이 오른쪽인 노란색 선 차트에서 현재 반복할 때까지 그리도록 한다. 데이터 비율 막대 차트로부터 데이터의 <math alttext="70\%" class="ltx_Math" display="inline" id="S5.SS5.p3.2.m2.1"><semantics id="S5.SS5.p3.2.m2.1a"><mrow id="S5.SS5.p3.2.m2.1.1" xref="S5.SS5.p3.2.m2.1.1.cmml"><mn id="S5.SS5.p3.2.m2.1.1.2" xref="S5.SS5.p3.2.m2.1.1.2.cmml">70</mn><mo id="S5.SS5.p3.2.m2.1.1.1" xref="S5.SS5.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.2.m2.1b"><apply id="S5.SS5.p3.2.m2.1.1.cmml" xref="S5.SS5.p3.2.m2.1.1"><csymbol cd="latexml" id="S5.SS5.p3.2.m2.1.1.1.cmml" xref="S5.SS5.p3.2.m2.1.1.1">percent</csymbol><cn id="S5.SS5.p3.2.m2.1.1.2.cmml" type="integer" xref="S5.SS5.p3.2.m2.1.1.2">70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.2.m2.1c">70\%</annotation></semantics></math> 이상이 첫 번째 반복에서 나온다는 것을 관찰한다. 이는 대조적 필터링이 덜 복잡하지만 도전적인 명령어를 성공적으로 수집한다는 것을 나타내며, 이는 목표 LLM의 명령어 추종 능력을 구축하는 데 중요하다. 두 번째 반복부터 데이터 비율이 점점 작아집니다. 그러나 <em class="ltx_emph ltx_font_italic" id="S5.SS5.p3.2.2">less is more for alignment</em> observation <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="#bib.bib55" title="">2023a</a>)</cite> 고품질의 더 복잡한 명령어는 양이 적음에도 불구하고 실제로 최종 성능에 기여한다.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2404.05875/assets/x3.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="205" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 3:</span>Data proportion from each iteration and the corresponding CRR performance at each iteration.</figcaption>
</figure>
<figure id="S5.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2404.05875/assets/x4.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="133" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 4:</span>Metadata matching proportion vs. CRR</figcaption>
</figure>
<div id="S5.SS5.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS5.p4.4"><span class="ltx_text ltx_font_bold" id="S5.SS5.p4.4.1">Exploration on Distribution Matching. </span> 이전 결과에서 볼 수 있듯이 다운스트림 명령 배포에서 추출한 메타데이터를 생성하는 것이 실제로 도움이 됩니다. 그러나, 실제로, 추출되거나 사람이 작성한 메타데이터는 명령어 분포를 정확하게 특성화할 수 없을 수 있다. 따라서 명령어 메타데이터로 표현되는 분포가 테스트 분포와 완전히 일치하지 않을 때 CodecLM의 성능을 탐색할 필요가 있다. 실제 테스트 분포가 복잡하고 사전으로 알려져 있지 않기 때문에 메타데이터 <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.SS5.p4.1.m1.1"><semantics id="S5.SS5.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p4.1.m1.1.1" xref="S5.SS5.p4.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.1.m1.1b"><ci id="S5.SS5.p4.1.m1.1.1.cmml" xref="S5.SS5.p4.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.1.m1.1c">\mathcal{M}</annotation></semantics></math> 세트로부터 랜덤 서브샘플링에 의해 다양한 분포 매칭 정도를 근사화한다. 데이터 양의 영향을 통제하기 위해 각 경우에 대해 명령-응답 쌍의 총 수를 동일하게 유지한다. 예를 들어, <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.SS5.p4.3.m3.1"><semantics id="S5.SS5.p4.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p4.3.m3.1.1" xref="S5.SS5.p4.3.m3.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.3.m3.1b"><ci id="S5.SS5.p4.3.m3.1.1.cmml" xref="S5.SS5.p4.3.m3.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.3.m3.1c">\mathcal{M}</annotation></semantics></math>의 <math alttext="20\%" class="ltx_Math" display="inline" id="S5.SS5.p4.2.m2.1"><semantics id="S5.SS5.p4.2.m2.1a"><mrow id="S5.SS5.p4.2.m2.1.1" xref="S5.SS5.p4.2.m2.1.1.cmml"><mn id="S5.SS5.p4.2.m2.1.1.2" xref="S5.SS5.p4.2.m2.1.1.2.cmml">20</mn><mo id="S5.SS5.p4.2.m2.1.1.1" xref="S5.SS5.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.2.m2.1b"><apply id="S5.SS5.p4.2.m2.1.1.cmml" xref="S5.SS5.p4.2.m2.1.1"><csymbol cd="latexml" id="S5.SS5.p4.2.m2.1.1.1.cmml" xref="S5.SS5.p4.2.m2.1.1.1">percent</csymbol><cn id="S5.SS5.p4.2.m2.1.1.2.cmml" type="integer" xref="S5.SS5.p4.2.m2.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.2.m2.1c">20\%</annotation></semantics></math>를 서브 샘플링할 때, 이에 따라 각 메타데이터에 대해 5배 이상의 인스트럭션을 생성하도록 강한 LLM을 프롬프트한다. 결과는 그림 <a class="ltx_ref" href="#S5.F4" title="Figure 4 ‣ 5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4</span></a>의 상단에 나와 있으며, 우리는 더 나은 명령어 메타데이터가 기본 분포를 포착할수록 목표 LLM이 더 나은 성능을 달성할 수 있다는 추세를 관찰했다. 또한, 메타데이터 매칭 비율이 <math alttext="60\%" class="ltx_Math" display="inline" id="S5.SS5.p4.4.m4.1"><semantics id="S5.SS5.p4.4.m4.1a"><mrow id="S5.SS5.p4.4.m4.1.1" xref="S5.SS5.p4.4.m4.1.1.cmml"><mn id="S5.SS5.p4.4.m4.1.1.2" xref="S5.SS5.p4.4.m4.1.1.2.cmml">60</mn><mo id="S5.SS5.p4.4.m4.1.1.1" xref="S5.SS5.p4.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.4.m4.1b"><apply id="S5.SS5.p4.4.m4.1.1.cmml" xref="S5.SS5.p4.4.m4.1.1"><csymbol cd="latexml" id="S5.SS5.p4.4.m4.1.1.1.cmml" xref="S5.SS5.p4.4.m4.1.1.1">percent</csymbol><cn id="S5.SS5.p4.4.m4.1.1.2.cmml" type="integer" xref="S5.SS5.p4.4.m4.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.4.m4.1c">60\%</annotation></semantics></math> 이상인 경우, 완전 매칭된 결과로서 근접 성능을 얻을 수 있다. 이 관찰은 잠재적인 명령어 메타데이터 불일치 하에서 CodecLM의 견고성을 강조한다.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2404.05875/assets/x5.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="297" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5:</span>Scaling with model size and data quantity.</figcaption>
</figure>
<div id="S5.SS5.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS5.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p5.1.1">Scaling with Model Size and Data Quantity. </span> 합성 데이터 양과 모델 크기가 다른 방법을 탐색하기 위해 가장 경쟁적인 기준선인 WizardLM+와 CodecLM을 비교하여 실험을 수행한다. LLaMA-7B 및 -13B를 타겟 LLM으로 하는 Evol-Instruct에 대한 실험 결과는 그림 <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">5</span></a>에 나와 있다. 두 방법 모두 더 많은 합성 데이터와 더 큰 목표 모델로 점점 더 나은 성능을 보인다. CodecLM은 모든 경우에서 WizardLM+를 일관되게 능가하여 데이터 효율성과 확장성이 뛰어납니다. 우리는 목표 모델과 강한 LLM 사이의 고유한 능력 차이로 인해 8k 이상의 합성 데이터를 생성한 후 이득이 점차 감소할 것으로 예상한다.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p" id="S6.p1.1">본 논문에서는 LLM 정렬을 위한 합성 데이터를 서로 다른 타겟 명령어 분포와 LLM으로 맞춤화하는 CodecLM을 제안한다. CodecLM은 명령어 메타 데이터를 통해 효과적으로 명령어 분포를 캡처하고, Self-Rubrics와 Contrastive Filtering을 통해 가장 효과적인 명령어-응답 쌍을 조정함을 보인다. 코덱LM은 인간 주석의 필요 없이 맞춤형 사용을 위해 LLM을 적용하는 데 강력한 솔루션을 제공한다. 우리는 CodecLM이 더 풍부한 메타데이터 정의, 더 나은 신속한 설계 및 더 신뢰할 수 있는 LLM 기반 점수 작성자와 같은 프레임워크 내에서 여러 유망한 연구 방향의 문을 여는 표적 LLM 정렬을 위한 일반적인 프레임워크 역할을 한다고 믿는다. CodecLM은 직교 연구 분야에서도 이익을 얻을 수 있으며 윤리적 고려 및 한계 섹션에서 논의를 계속한다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethical Considerations</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.p1.1">코덱LM이 LLM 정렬을 위한 효과적인 데이터 합성 프레임워크 역할을 하지만 작업의 윤리적 영향도 반영해야 한다. 제안하는 방법은 LLMs을 활용하여 명령어-응답 쌍을 생성한다. 데이터 주석 과정에서 무의식적인 실수를 할 수 있는 인간 주석자와 유사하게 LLM은 때때로 비윤리적, 독성 또는 오판의 소지가 있는 명령 및 응답 <cite class="ltx_cite ltx_citemacro_citep">(Bender et al., <a class="ltx_ref" href="#bib.bib4" title="">2021</a>)</cite>를 생성한다. 또한, 생성된 데이터를 사용하여 목표 LLM을 훈련함에 따라 결과적인 명령어 조정 LLM은 원래 모델에서 편향 및 공정성 문제 <cite class="ltx_cite ltx_citemacro_citep">(Gallegos et al., <a class="ltx_ref" href="#bib.bib15" title="">2023</a>)</cite>를 전달할 수 있다. 부록 <a class="ltx_ref" href="#A1.SS3" title="A.3 Additional Implementation Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.3</span></a>에 명시된 대로 수동 검사를 수행했지만 실제로는 CodecLM에서 사용되는 LLMs의 무독화 및 편향을 완화하기 위해 기존 기술  <cite class="ltx_cite ltx_citemacro_citep">(Hanu and Unitary team, <a class="ltx_ref" href="#bib.bib17" title="">2020</a>; Thakur et al., <a class="ltx_ref" href="#bib.bib43" title="">2023</a>)</cite>를 채택하고 생성된 데이터를 정리하기 위해 보다 엄격한 검사 및 필터링 규칙을 설계해야 한다. 프레임워크의 유연성으로 인해 편향 및 공정성 문제를 줄이는 영역에서 향후 진전이 CodecLM에 보완적일 수 있다고 상상한다.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx2.p1" class="ltx_para">
<p class="ltx_p" id="Sx2.p1.1">LLM 정렬 분야에서 향후 연구 기회를 고취하기 위해 다음과 같은 측면에서 CodecLM의 한계를 인정한다.</p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p class="ltx_p" id="Sx2.p2.1">우선, 윤리적 고려사항에서 논의된 바와 같이, 우리의 방법은 데이터를 생성하기 위해 강한 LLM을 요구하므로, 우리의 방법의 성능은 LLM의 품질에 의존하며, 그것으로부터 편향 및 공정성 문제를 물려받을 수 있다. 반면에, CodecLM은 진보된 편향 감소 및 공정성 향상 접근법으로 개선된 더 강한 LLM으로부터 이익을 얻을 수 있다.</p>
</div>
<div id="Sx2.p3" class="ltx_para">
<p class="ltx_p" id="Sx2.p3.1">둘째, 직교 방향으로서, 본 방법은 즉각적인 주입 <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib31" title="">2023</a>)</cite> 및 탈옥 <cite class="ltx_cite ltx_citemacro_citep">(Zou et al., <a class="ltx_ref" href="#bib.bib57" title="">2023</a>)</cite>와 같은 적대적 공격에 대한 명령어 조정 모델의 견고성을 탐색하지 않았다. 실제적으로, 우리는 우리의 방법에서 명령 조정된 LLM에 따라 적대적 방어 기술 <cite class="ltx_cite ltx_citemacro_citep">(Jain et al., <a class="ltx_ref" href="#bib.bib22" title="">2023</a>)</cite>를 적용해야 한다.</p>
</div>
<div id="Sx2.p4" class="ltx_para">
<p class="ltx_p" id="Sx2.p4.1">또한, 정렬을 위한 데이터 합성에서 최근 연구에 따른 LLM 기반 자동 평가 방법을 주로 사용한다. 최근 연구 <cite class="ltx_cite ltx_citemacro_citep">(Chiang et al., <a class="ltx_ref" href="#bib.bib9" title="">2023</a>; Dubois et al., <a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>는 LLM 기반 평가가 인간 평가와 대체로 일치하지만, LLM 기반 평가자의 확장성과 신뢰성은 여전히 개선의 여지가 있다. LLM 기반 평가 결과를 보완하기 위해 부록 <a class="ltx_ref" href="#A1.SS7" title="A.7 Additional Benchmark Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.7</span></a>에 표준 벤치마크 결과를 포함하지만, LLM을 더 잘 평가하는 진전은 여전히 우리 방법의 효율성을 더 신뢰할 수 있는 입증으로 이어질 수 있다고 믿는다.</p>
</div>
<div id="Sx2.p5" class="ltx_para">
<p class="ltx_p" id="Sx2.p5.1">마지막으로, 섹션 <a class="ltx_ref" href="#S5.SS5" title="5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">5.5</span></a>에 도시된 바와 같이, CodecLM은 중간 분포 불일치에 강인하지만, 그 성능은 여전히 메타데이터가 기본 명령어 분포를 얼마나 잘 캡처하는지에 의존한다. 실제로 수집된 종자 지침은 실제 테스트 지침과 다를 수 있다. 또는 사용자 명세에서 직접 메타데이터를 생성하는 경우, 사용자는 테스트 시간에 자신의 생각을 변경하여 원본 메타데이터를 넘어 모델 분산 해제 지침을 보낼 수 있다. 결과적으로, CodecLM은 분배 불일치 하에서 성능 저하를 겪을 수 있다. 이를 해결하기 위해 CodecLM에서 생성된 데이터를 갱신하기 위해 사용자 명령 트래픽이나 사용자 피드백을 지속적으로 수집하고, 목표 LLM을 지속적으로 갱신할 수 있다.</p>
</div>
<div id="Sx2.p6" class="ltx_para">
<p class="ltx_p" id="Sx2.p6.1">향후 연구가 LLM 정렬을 위한 유연한 데이터 합성 프레임워크로 CodecLM을 활용할 수 있어 현 분야의 발전이 CodecLM에 통합되어 현재의 한계를 줄일 수 있기를 바란다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rohan Anil, Andrew&nbsp;M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,
Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen,
et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Palm 2 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.10403</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aribandi et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Vamsi Aribandi, Yi&nbsp;Tay, Tal Schuster, Jinfeng Rao, Huaixiu&nbsp;Steven Zheng,
Sanket&nbsp;Vaibhav Mehta, Honglei Zhuang, Vinh&nbsp;Q Tran, Dara Bahri, Jianmo Ni,
et&nbsp;al. 2021.

</span>
<span class="ltx_bibblock">Ext5: Towards extreme multi-task scaling for transfer learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.10952</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Training a helpful and harmless assistant with reinforcement learning
from human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.05862</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Emily&nbsp;M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
Shmitchell. 2021.

</span>
<span class="ltx_bibblock">On the dangers of stochastic parrots: Can language models be too big?

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 ACM conference on fairness,
accountability, and transparency</em>, pages 610–623.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beyer et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Lucas Beyer, Xiaohua Zhai, Amélie Royer, Larisa Markeeva, Rohan Anil, and
Alexander Kolesnikov. 2022.

</span>
<span class="ltx_bibblock">Knowledge distillation: A good teacher is patient and consistent.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pages 10925–10934.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
33:1877–1901.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Derek Chen, Celine Lee, Yunan Lu, Domenic Rosati, and Zhou Yu.
2023a.

</span>
<span class="ltx_bibblock">Mixture of soft prompts for controllable data generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.01580</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav,
Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et&nbsp;al.
2023b.

</span>
<span class="ltx_bibblock">Alpagasus: Training a better alpaca with fewer data.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.08701</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Zhuohan Li, Zi&nbsp;Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph&nbsp;E. Gonzalez, Ion Stoica, and
Eric&nbsp;P. Xing. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://lmsys.org/blog/2023-03-30-vicuna/" title="" class="ltx_ref ltx_href">Vicuna: An
open-source chatbot impressing gpt-4 with 90%* chatgpt quality</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus,
Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11416</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yi&nbsp;Dong, Zhilin Wang, Makesh&nbsp;Narsimhan Sreedhar, Xianchao Wu, and Oleksii
Kuchaiev. 2023.

</span>
<span class="ltx_bibblock">Steerlm: Attribute conditioned sft as an (user-steerable) alternative
to rlhf.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.05344</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubois et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba,
Carlos Guestrin, Percy Liang, and Tatsunori&nbsp;B Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Alpacafarm: A simulation framework for methods that learn from human
feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14387</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Efrat and Levy (2020)</span>
<span class="ltx_bibblock">
Avia Efrat and Omer Levy. 2020.

</span>
<span class="ltx_bibblock">The turking test: Can language models understand instructions?

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11982</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernando et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim
Rocktäschel. 2023.

</span>
<span class="ltx_bibblock">Promptbreeder: Self-referential self-improvement via prompt
evolution.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.16797</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gallegos et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Isabel&nbsp;O Gallegos, Ryan&nbsp;A Rossi, Joe Barrow, Md&nbsp;Mehrab Tanjim, Sungchul Kim,
Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen&nbsp;K Ahmed. 2023.

</span>
<span class="ltx_bibblock">Bias and fairness in large language models: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.00770</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wallace, Pieter Abbeel, Sergey
Levine, and Dawn Song. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://bair.berkeley.edu/blog/2023/04/03/koala/" title="" class="ltx_ref ltx_href">Koala: A
dialogue model for academic research</a>.

</span>
<span class="ltx_bibblock">Blog post.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanu and Unitary team (2020)</span>
<span class="ltx_bibblock">
Laura Hanu and Unitary team. 2020.

</span>
<span class="ltx_bibblock">Detoxify.

</span>
<span class="ltx_bibblock">Github. https://github.com/unitaryai/detoxify.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn
Song, and Jacob Steinhardt. 2020.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.03300</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et&nbsp;al. (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1503.02531</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Or&nbsp;Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022.

</span>
<span class="ltx_bibblock">Unnatural instructions: Tuning language models with (almost) no human
labor.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.09689</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsieh et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii,
Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023.

</span>
<span class="ltx_bibblock">Distilling step-by-step! outperforming larger language models with
less training data and smaller model sizes.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.02301</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer,
Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, and Tom
Goldstein. 2023.

</span>
<span class="ltx_bibblock">Baseline defenses for adversarial attacks against aligned language
models.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.00614</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Welling (2013)</span>
<span class="ltx_bibblock">
Diederik&nbsp;P Kingma and Max Welling. 2013.

</span>
<span class="ltx_bibblock">Auto-encoding variational bayes.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6114</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Köpf et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis,
Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen&nbsp;Minh Duc, Oliver
Stanley, Richárd Nagyfi, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Openassistant conversations–democratizing large language model
alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.07327</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kramer (1991)</span>
<span class="ltx_bibblock">
Mark&nbsp;A Kramer. 1991.

</span>
<span class="ltx_bibblock">Nonlinear principal component analysis using autoassociative neural
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">AIChE journal</em>, 37(2):233–243.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Gyeong-Geon Lee, Ehsan Latif, Xuansheng Wu, Ninghao Liu, and Xiaoming Zhai.
2023.

</span>
<span class="ltx_bibblock">Applying large language models and chain-of-thought for automatic
scoring.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.03748</em>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy,
Jason Weston, and Mike Lewis. 2023.

</span>
<span class="ltx_bibblock">Self-alignment with instruction backtranslation.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.06259</em>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Xiang&nbsp;Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori
Hashimoto, Luke Zettlemoyer, and Mike Lewis. 2022.

</span>
<span class="ltx_bibblock">Contrastive decoding: Open-ended text generation as optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.15097</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chen Liang, Simiao Zuo, Qingru Zhang, Pengcheng He, Weizhu Chen, and Tuo Zhao.
2023.

</span>
<span class="ltx_bibblock">Less is more: Task-aware layer-wise distillation for language model
compression.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
20852–20867. PMLR.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Alisa Liu, Swabha Swayamdipta, Noah&nbsp;A Smith, and Yejin Choi. 2022.

</span>
<span class="ltx_bibblock">Wanli: Worker and ai collaboration for natural language inference
dataset creation.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.05955</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yi&nbsp;Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu
Wang, Yan Zheng, and Yang Liu. 2023.

</span>
<span class="ltx_bibblock">Prompt injection attack against llm-integrated applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.05499</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaan et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah
Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et&nbsp;al.
2023.

</span>
<span class="ltx_bibblock">Self-refine: Iterative refinement with self-feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.17651</em>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yu&nbsp;Meng, Martin Michalski, Jiaxin Huang, Yu&nbsp;Zhang, Tarek Abdelzaher, and Jiawei
Han. 2023.

</span>
<span class="ltx_bibblock">Tuning language models as training data generators for
augmentation-enhanced few-shot learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
24457–24477. PMLR.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023a)</span>
<span class="ltx_bibblock">
OpenAI. 2023a.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2303.08774.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023b)</span>
<span class="ltx_bibblock">
OpenAI. 2023b.

</span>
<span class="ltx_bibblock">Introducing gpts.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openai.com/blog/introducing-gpts" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/blog/introducing-gpts</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
35:27730–27744.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023.

</span>
<span class="ltx_bibblock">Instruction tuning with gpt-4.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.03277</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">The Journal of Machine Learning Research</em>, 21(1):5485–5551.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick and Schütze (2021)</span>
<span class="ltx_bibblock">
Timo Schick and Hinrich Schütze. 2021.

</span>
<span class="ltx_bibblock">Generating datasets with pretrained language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.07540</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suzgun et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi&nbsp;Tay,
Hyung&nbsp;Won Chung, Aakanksha Chowdhery, Quoc&nbsp;V Le, Ed&nbsp;H Chi, Denny Zhou, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock">Challenging big-bench tasks and whether chain-of-thought can solve
them.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.09261</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac,
Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew&nbsp;M Dai, Anja Hauth, et&nbsp;al.
2023.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.11805</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thakur et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, Paul&nbsp;Pu Liang, and
Louis-Philippe Morency. 2023.

</span>
<span class="ltx_bibblock">Language models get a gender makeover: Mitigating gender bias with
few-shot data interventions.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.04597</em>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Victor et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Sanh Victor, Webson Albert, Raffel Colin, Bach Stephen, Sutawika Lintang,
Alyafeai Zaid, Chaffin Antoine, Stiegler Arnaud, Raja Arun, Dey Manan, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock">Multitask prompted training enables zero-shot task generalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot,
Khyathi&nbsp;Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah&nbsp;A Smith,
Iz&nbsp;Beltagy, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">How far can camels go? exploring the state of instruction tuning on
open resources.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.04751</em>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A Smith, Daniel
Khashabi, and Hannaneh Hajishirzi. 2022.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language model with self generated
instructions.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.10560</em>.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent&nbsp;Y Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian
Lester, Nan Du, Andrew&nbsp;M Dai, and Quoc&nbsp;V Le. 2021.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.01652</em>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed&nbsp;Chi, Quoc&nbsp;V
Le, Denny Zhou, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
35:24824–24837.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu&nbsp;Zhao, Jiazhan Feng, Chongyang
Tao, and Daxin Jiang. 2023.

</span>
<span class="ltx_bibblock">Wizardlm: Empowering large language models to follow complex
instructions.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.12244</em>.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc&nbsp;V Le, Denny Zhou, and
Xinyun Chen. 2023.

</span>
<span class="ltx_bibblock">Large language models as optimizers.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.03409</em>.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu&nbsp;Meng, Alexander Ratner, Ranjay Krishna,
Jiaming Shen, and Chao Zhang. 2023.

</span>
<span class="ltx_bibblock">Large language model as attributed training data generator: A tale of
diversity and bias.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.15895</em>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yingxiu Zhao, Bowen Yu, Binyuan Hui, Haiyang Yu, Fei Huang, Yongbin Li, and
Nevin&nbsp;L Zhang. 2023.

</span>
<span class="ltx_bibblock">A preliminary study of the intrinsic relationship between complexity
and alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.05696</em>.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao
Zhuang, Zi&nbsp;Lin, Zhuohan Li, Dacheng Li, Eric Xing, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.05685</em>.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe
Ma, Avia Efrat, Ping Yu, Lili Yu, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.11206</em>.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu,
Yi&nbsp;Luan, Denny Zhou, and Le&nbsp;Hou. 2023b.

</span>
<span class="ltx_bibblock">Instruction-following evaluation for large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.07911</em>.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Andy Zou, Zifan Wang, J.&nbsp;Zico Kolter, and Matt Fredrikson. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2307.15043" title="" class="ltx_ref ltx_href">Universal and transferable
adversarial attacks on aligned language models</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Benchmark Details</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS1.p1.1">다음 벤치마크에 따른 공개 수업의 세부 사항은 다음과 같습니다.</p>
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="A1.I1.i1.p1.1">Evol-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>는 온라인 오픈 소스 프로젝트, 플랫폼 및 포럼과 같은 다양한 소스의 218개의 실제 인간 지침을 포함한다.</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="A1.I1.i2.p1.1">Vicuna<cite class="ltx_cite ltx_citemacro_citep">(Chiang et al., <a class="ltx_ref" href="#bib.bib9" title="">2023</a>)</cite>는 GPT-4가 프롬프트 엔지니어링을 통해 생성한 80개의 다양한 명령어를 포함한다.</p>
</div>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="A1.I1.i3.p1.1">Self-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib47" title="">2022</a>)</cite>는 사용자 지향 애플리케이션에 의해 동기화된 252개의 전문가 작성 명령어를 포함한다.</p>
</div>
</li>
<li id="A1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="A1.I1.i4.p1.1">Koala<cite class="ltx_cite ltx_citemacro_citep">(Geng et al., <a class="ltx_ref" href="#bib.bib16" title="">2023</a>)</cite>는 온라인에 게시된 180개의 대화 스타일의 실제 사용자 지침을 포함한다.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A1.SS1.p1.2">이 모든 벤치마크는 여러 범주 또는 작업의 영어 지침으로 구성됩니다. 그러나 일반적인 지식 QA 및 코딩과 같은 몇 가지 일반적인 사용 사례를 공유하지만 다른 벤치마크에서 명령어의 적용 범위는 실제로 다르다. 예를 들어 <cite class="ltx_cite ltx_citemacro_citet">Xu et al. (<a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>는 Evol-Instruct가 명령어 분포에서 Vicuna와 어떻게 다른지 자세히 논의한다. 명령어 분포의 차이는 다운스트림 태스크가 다른 실제 시나리오를 효과적으로 모방한다.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para">
<p class="ltx_p" id="A1.SS1.p2.1">추가 표준 NLP 벤치마크의 세부사항은 다음과 같다:</p>
<ul id="A1.I2" class="ltx_itemize">
<li id="A1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="A1.I2.i1.p1.1">MMLU<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="#bib.bib18" title="">2020</a>)</cite>, Massive Multitask Language Understanding은 언어 모델의 능력을 측정하기 위해 고안된 벤치마크이다. STEM, 인문학, 사회과학 등 다양한 분야에 걸쳐 57개 과목을 다루고 있다. 테스트 결과 보고에는 테스트 분할만 사용하고 모든 작업에서 평균 점수를 보고합니다.</p>
</div>
</li>
<li id="A1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="A1.I2.i2.p1.1">BBH<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et al., <a class="ltx_ref" href="#bib.bib40" title="">2022</a>)</cite>, BIG-Bench-Hard에는 이전 언어 모델이 평균 인간 평가자를 능가하지 못한 23개의 도전적인 BIG-Bench 작업이 포함된다.</p>
</div>
</li>
</ul>
</div>
<div id="A1.SS1.p3" class="ltx_para">
<p class="ltx_p" id="A1.SS1.p3.1">모든 벤치마크는 비상업적 연구 목적으로 공개적으로 사용할 수 있으며 이 연구 작업에서 사용을 엄격하게 제한한다. 또한 이러한 데이터 세트를 주의 깊게 확인하고 개인 정보가 포함되지 않았는지 확인합니다.</p>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Baseline Details</h3>

<div id="A1.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p1.1.1">Self-Instruct</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib47" title="">2022</a>)</cite>는 기존의 시드 명령어를 적은 샷 시연으로 LLM을 프롬프트하여 명령어를 생성한다. 여기서는 시드 명령어로 Alpaca <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="#bib.bib41" title="">2023</a>)</cite> 데이터 세트를 무작위로 하위 샘플링한다. 알파카 자체는 Self-Instruct를 기반으로 하기 때문에 하위 집합을 시드로 사용하는 것은 Self-Instruct 방법의 자연스러운 연속이다.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p2.1.1">Alpagasus</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib8" title="">2023b</a>)</cite> ChatGPT 기반 응답 품질 평가기를 사용하여 데이터를 선택적으로 필터링합니다. 원래 접근 방식을 거의 따라 자체 지침에 의해 생성된 명령-응답 쌍에 전략을 채택한다.</p>
</div>
<div id="A1.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p3.1.1">Tree-Instruct</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a class="ltx_ref" href="#bib.bib53" title="">2023</a>)</cite>는 LLM이 의미 트리를 통해 명령어를 암묵적으로 복잡하게 만들도록 프롬프트함으로써 명령어 품질을 향상시킨다. 원본 논문에 이어 서브샘플링된 알파카 데이터 세트를 시드 데이터로 사용한다. 최상의 성능을 위해 트리 노드의 수를 10개로 설정하였다.</p>
</div>
<div id="A1.SS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p4.1.1">WizardLM</span> <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>iteratively complicates instructions by prompting the LLM with set of pre-defined evolution operations. 위저드 LM의 인기와 효과를 고려하여 Alpaca를 시드 데이터로 사용하는 원본 버전과 CodecLM에서 생성된 동일한 기본 명령어 세트를 시드 데이터로 사용하는 향상된 버전의 두 가지 변형을 사용하여 실험한다. 이후의 변형을 프레임워크의 구성 요소에 의해 강화된 것으로 <span class="ltx_text ltx_font_bold" id="A1.SS2.p4.1.2">WizardLM+</span>으로 명명한다.</p>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Additional Implementation Details</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS3.p1.2">다양한 지침의 사용 사례와 기술을 믹스 앤 매칭하여 메타데이터를 200으로 늘립니다. <math alttext="\{u_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="A1.SS3.p1.1.m1.1"><semantics id="A1.SS3.p1.1.m1.1a"><msubsup id="A1.SS3.p1.1.m1.1.1" xref="A1.SS3.p1.1.m1.1.1.cmml"><mrow id="A1.SS3.p1.1.m1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.1.1.1.1.2.cmml"><mo id="A1.SS3.p1.1.m1.1.1.1.1.1.2" stretchy="false" xref="A1.SS3.p1.1.m1.1.1.1.1.2.cmml">{</mo><msub id="A1.SS3.p1.1.m1.1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.cmml"><mi id="A1.SS3.p1.1.m1.1.1.1.1.1.1.2" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.2.cmml">u</mi><mi id="A1.SS3.p1.1.m1.1.1.1.1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.SS3.p1.1.m1.1.1.1.1.1.3" stretchy="false" xref="A1.SS3.p1.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="A1.SS3.p1.1.m1.1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.1.3.cmml"><mi id="A1.SS3.p1.1.m1.1.1.1.3.2" xref="A1.SS3.p1.1.m1.1.1.1.3.2.cmml">i</mi><mo id="A1.SS3.p1.1.m1.1.1.1.3.1" xref="A1.SS3.p1.1.m1.1.1.1.3.1.cmml">=</mo><mn id="A1.SS3.p1.1.m1.1.1.1.3.3" xref="A1.SS3.p1.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="A1.SS3.p1.1.m1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.3.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.1.m1.1b"><apply id="A1.SS3.p1.1.m1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1">superscript</csymbol><apply id="A1.SS3.p1.1.m1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1">subscript</csymbol><set id="A1.SS3.p1.1.m1.1.1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1"><apply id="A1.SS3.p1.1.m1.1.1.1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="A1.SS3.p1.1.m1.1.1.1.1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.2">𝑢</ci><ci id="A1.SS3.p1.1.m1.1.1.1.1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="A1.SS3.p1.1.m1.1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3"><eq id="A1.SS3.p1.1.m1.1.1.1.3.1.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3.1"></eq><ci id="A1.SS3.p1.1.m1.1.1.1.3.2.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3.2">𝑖</ci><cn id="A1.SS3.p1.1.m1.1.1.1.3.3.cmml" type="integer" xref="A1.SS3.p1.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="A1.SS3.p1.1.m1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.1.m1.1c">\{u_{i}\}_{i=1}^{n}</annotation></semantics></math>로부터 하나의 유스 케이스를 랜덤 샘플링하고, <math alttext="\bigcup_{i=1}^{n}{\bm{s}}_{i}" class="ltx_Math" display="inline" id="A1.SS3.p1.2.m2.1"><semantics id="A1.SS3.p1.2.m2.1a"><mrow id="A1.SS3.p1.2.m2.1.1" xref="A1.SS3.p1.2.m2.1.1.cmml"><msubsup id="A1.SS3.p1.2.m2.1.1.1" xref="A1.SS3.p1.2.m2.1.1.1.cmml"><mo id="A1.SS3.p1.2.m2.1.1.1.2.2" xref="A1.SS3.p1.2.m2.1.1.1.2.2.cmml">⋃</mo><mrow id="A1.SS3.p1.2.m2.1.1.1.2.3" xref="A1.SS3.p1.2.m2.1.1.1.2.3.cmml"><mi id="A1.SS3.p1.2.m2.1.1.1.2.3.2" xref="A1.SS3.p1.2.m2.1.1.1.2.3.2.cmml">i</mi><mo id="A1.SS3.p1.2.m2.1.1.1.2.3.1" xref="A1.SS3.p1.2.m2.1.1.1.2.3.1.cmml">=</mo><mn id="A1.SS3.p1.2.m2.1.1.1.2.3.3" xref="A1.SS3.p1.2.m2.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="A1.SS3.p1.2.m2.1.1.1.3" xref="A1.SS3.p1.2.m2.1.1.1.3.cmml">n</mi></msubsup><msub id="A1.SS3.p1.2.m2.1.1.2" xref="A1.SS3.p1.2.m2.1.1.2.cmml"><mi id="A1.SS3.p1.2.m2.1.1.2.2" xref="A1.SS3.p1.2.m2.1.1.2.2.cmml">𝒔</mi><mi id="A1.SS3.p1.2.m2.1.1.2.3" xref="A1.SS3.p1.2.m2.1.1.2.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.2.m2.1b"><apply id="A1.SS3.p1.2.m2.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1"><apply id="A1.SS3.p1.2.m2.1.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1">superscript</csymbol><apply id="A1.SS3.p1.2.m2.1.1.1.2.cmml" xref="A1.SS3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.1.2.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1">subscript</csymbol><union id="A1.SS3.p1.2.m2.1.1.1.2.2.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.2"></union><apply id="A1.SS3.p1.2.m2.1.1.1.2.3.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3"><eq id="A1.SS3.p1.2.m2.1.1.1.2.3.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3.1"></eq><ci id="A1.SS3.p1.2.m2.1.1.1.2.3.2.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3.2">𝑖</ci><cn id="A1.SS3.p1.2.m2.1.1.1.2.3.3.cmml" type="integer" xref="A1.SS3.p1.2.m2.1.1.1.2.3.3">1</cn></apply></apply><ci id="A1.SS3.p1.2.m2.1.1.1.3.cmml" xref="A1.SS3.p1.2.m2.1.1.1.3">𝑛</ci></apply><apply id="A1.SS3.p1.2.m2.1.1.2.cmml" xref="A1.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.2.1.cmml" xref="A1.SS3.p1.2.m2.1.1.2">subscript</csymbol><ci id="A1.SS3.p1.2.m2.1.1.2.2.cmml" xref="A1.SS3.p1.2.m2.1.1.2.2">𝒔</ci><ci id="A1.SS3.p1.2.m2.1.1.2.3.cmml" xref="A1.SS3.p1.2.m2.1.1.2.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.2.m2.1c">\bigcup_{i=1}^{n}{\bm{s}}_{i}</annotation></semantics></math>로부터 교체 없이 샘플링된 하나 이상의 스킬과 페어링한다. 대부분의 기술은 사용 사례 간에 일반화할 수 있지만 불합리한 사용 사례와 기술 쌍을 제외하기 위해 여전히 수동 건전성 검사를 수행한다. 사전 작업 <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023</a>)</cite>와 Self-Rubrics를 통해 반복적으로 명령어를 개선하기 위한 하이퍼파라미터를 정렬한다. 우리는 4개의 루브릭과 그에 대응하는 액션을 생성하고, 각 반복에서 명령어 개선을 위한 1개의 액션을 랜덤하게 선택한다. 위저드LM과의 공정한 비교를 위해, 또한 각 명령어에 대해 최대 4번의 개선 반복을 사용한다(기본 프롬프트 생성을 첫 번째 반복으로 카운트한다). 대비 필터링의 경우, 우리는 항상 강한 LLM 자체를 득점자로 사용한다. 모든 실험에 대해 점수 척도를 10으로, 필터링 임계값을 3으로 설정했다. AlpacaEval <cite class="ltx_cite ltx_citemacro_citep">(Dubois et al., <a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite> 데이터 세트를 사용하여 임계값을 얻습니다. 그리고 우리는 이 임계값이 일반적으로 다른 설정에서 잘 작동한다는 것을 발견한다. 또한, LLaMA 기반 모델의 경우, 대조적 필터링에서 응답 생성을 위한 목표 LLM으로 그들의 Alpaca<cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="#bib.bib41" title="">2023</a>)</cite> 대응물을 사용하는 것이 명령 튜닝되지 않은 원래 모델보다 더 잘 작동한다. 메타데이터 추출, 기본 명령어 생성 및 Self-Rubrics는 추론 온도 0.7을 사용한다. LLaMA 기반 모델의 경우 최대 생성 토큰 수를 2048개, PaLM 기반 모델의 경우 API 제약으로 인해 1024개로 설정한다. 또한, 메타데이터 추출을 위해 20%의 검증 집합을 따로 두었지만, 여전히 본 논문에서 전체 테스트 집합에 대한 성능을 보고하고 있는데, 그 이유는 다음과 같다. (1) 전체 테스트 벤치마크에서 검증 집합을 제거해도 우리의 방법의 상대적 우월한 성능은 변하지 않으며, 우리의 방법과 기준선 사이의 성능 차이는 거의 그대로 유지된다. 따라서 더 나은 재현성을 위해 보관합니다. (2) 생성된 명령어들을 주의 깊게 확인함으로써, 생성된 명령어들 중 어느 것도 원래의 검증 명령어들과 중복되지 않음을 주목하고, 따라서 데이터 생성 프로세스 동안 데이터 누설이 발생하지 않는다.</p>
</div>
<div id="A1.SS3.p2" class="ltx_para">
<p class="ltx_p" id="A1.SS3.p2.1">생성된 데이터에 대해 수동 검사를 수행하여 개인 정보나 불쾌한 내용이 생성되지 않도록 합니다.</p>
</div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Training Details</h3>

<div id="A1.SS4.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS4.p1.3">LLaMA 기반 모델의 경우 이전 작업 <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="#bib.bib55" title="">2023a</a>; Chen et al., <a class="ltx_ref" href="#bib.bib8" title="">2023b</a>)</cite>에서 명령어 튜닝의 관행을 따릅니다. 더 작은 데이터 크기를 위해 <cite class="ltx_cite ltx_citemacro_citet">Zhou et al. (<a class="ltx_ref" href="#bib.bib55" title="">2023a</a>)</cite>에서 제안한 바와 같이 15개의 epoch에 대한 목표 모델을 미세 조정하기 위해 <math alttext="\beta_{1}=0.9,\beta_{2}=0.95" class="ltx_Math" display="inline" id="A1.SS4.p1.1.m1.2"><semantics id="A1.SS4.p1.1.m1.2a"><mrow id="A1.SS4.p1.1.m1.2.2.2" xref="A1.SS4.p1.1.m1.2.2.3.cmml"><mrow id="A1.SS4.p1.1.m1.1.1.1.1" xref="A1.SS4.p1.1.m1.1.1.1.1.cmml"><msub id="A1.SS4.p1.1.m1.1.1.1.1.2" xref="A1.SS4.p1.1.m1.1.1.1.1.2.cmml"><mi id="A1.SS4.p1.1.m1.1.1.1.1.2.2" xref="A1.SS4.p1.1.m1.1.1.1.1.2.2.cmml">β</mi><mn id="A1.SS4.p1.1.m1.1.1.1.1.2.3" xref="A1.SS4.p1.1.m1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="A1.SS4.p1.1.m1.1.1.1.1.1" xref="A1.SS4.p1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="A1.SS4.p1.1.m1.1.1.1.1.3" xref="A1.SS4.p1.1.m1.1.1.1.1.3.cmml">0.9</mn></mrow><mo id="A1.SS4.p1.1.m1.2.2.2.3" xref="A1.SS4.p1.1.m1.2.2.3a.cmml">,</mo><mrow id="A1.SS4.p1.1.m1.2.2.2.2" xref="A1.SS4.p1.1.m1.2.2.2.2.cmml"><msub id="A1.SS4.p1.1.m1.2.2.2.2.2" xref="A1.SS4.p1.1.m1.2.2.2.2.2.cmml"><mi id="A1.SS4.p1.1.m1.2.2.2.2.2.2" xref="A1.SS4.p1.1.m1.2.2.2.2.2.2.cmml">β</mi><mn id="A1.SS4.p1.1.m1.2.2.2.2.2.3" xref="A1.SS4.p1.1.m1.2.2.2.2.2.3.cmml">2</mn></msub><mo id="A1.SS4.p1.1.m1.2.2.2.2.1" xref="A1.SS4.p1.1.m1.2.2.2.2.1.cmml">=</mo><mn id="A1.SS4.p1.1.m1.2.2.2.2.3" xref="A1.SS4.p1.1.m1.2.2.2.2.3.cmml">0.95</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.1.m1.2b"><apply id="A1.SS4.p1.1.m1.2.2.3.cmml" xref="A1.SS4.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.2.2.3a.cmml" xref="A1.SS4.p1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="A1.SS4.p1.1.m1.1.1.1.1.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1"><eq id="A1.SS4.p1.1.m1.1.1.1.1.1.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.1"></eq><apply id="A1.SS4.p1.1.m1.1.1.1.1.2.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.1.1.1.1.2.1.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2">subscript</csymbol><ci id="A1.SS4.p1.1.m1.1.1.1.1.2.2.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2.2">𝛽</ci><cn id="A1.SS4.p1.1.m1.1.1.1.1.2.3.cmml" type="integer" xref="A1.SS4.p1.1.m1.1.1.1.1.2.3">1</cn></apply><cn id="A1.SS4.p1.1.m1.1.1.1.1.3.cmml" type="float" xref="A1.SS4.p1.1.m1.1.1.1.1.3">0.9</cn></apply><apply id="A1.SS4.p1.1.m1.2.2.2.2.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2"><eq id="A1.SS4.p1.1.m1.2.2.2.2.1.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.1"></eq><apply id="A1.SS4.p1.1.m1.2.2.2.2.2.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.2.2.2.2.2.1.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="A1.SS4.p1.1.m1.2.2.2.2.2.2.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2.2">𝛽</ci><cn id="A1.SS4.p1.1.m1.2.2.2.2.2.3.cmml" type="integer" xref="A1.SS4.p1.1.m1.2.2.2.2.2.3">2</cn></apply><cn id="A1.SS4.p1.1.m1.2.2.2.2.3.cmml" type="float" xref="A1.SS4.p1.1.m1.2.2.2.2.3">0.95</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.1.m1.2c">\beta_{1}=0.9,\beta_{2}=0.95</annotation></semantics></math>와 함께 AdamW 최적화기를 사용한다. 초기 학습률을 <math alttext="1\times 10^{-5}" class="ltx_Math" display="inline" id="A1.SS4.p1.2.m2.1"><semantics id="A1.SS4.p1.2.m2.1a"><mrow id="A1.SS4.p1.2.m2.1.1" xref="A1.SS4.p1.2.m2.1.1.cmml"><mn id="A1.SS4.p1.2.m2.1.1.2" xref="A1.SS4.p1.2.m2.1.1.2.cmml">1</mn><mo id="A1.SS4.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS4.p1.2.m2.1.1.1.cmml">×</mo><msup id="A1.SS4.p1.2.m2.1.1.3" xref="A1.SS4.p1.2.m2.1.1.3.cmml"><mn id="A1.SS4.p1.2.m2.1.1.3.2" xref="A1.SS4.p1.2.m2.1.1.3.2.cmml">10</mn><mrow id="A1.SS4.p1.2.m2.1.1.3.3" xref="A1.SS4.p1.2.m2.1.1.3.3.cmml"><mo id="A1.SS4.p1.2.m2.1.1.3.3a" xref="A1.SS4.p1.2.m2.1.1.3.3.cmml">−</mo><mn id="A1.SS4.p1.2.m2.1.1.3.3.2" xref="A1.SS4.p1.2.m2.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.2.m2.1b"><apply id="A1.SS4.p1.2.m2.1.1.cmml" xref="A1.SS4.p1.2.m2.1.1"><times id="A1.SS4.p1.2.m2.1.1.1.cmml" xref="A1.SS4.p1.2.m2.1.1.1"></times><cn id="A1.SS4.p1.2.m2.1.1.2.cmml" type="integer" xref="A1.SS4.p1.2.m2.1.1.2">1</cn><apply id="A1.SS4.p1.2.m2.1.1.3.cmml" xref="A1.SS4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="A1.SS4.p1.2.m2.1.1.3.1.cmml" xref="A1.SS4.p1.2.m2.1.1.3">superscript</csymbol><cn id="A1.SS4.p1.2.m2.1.1.3.2.cmml" type="integer" xref="A1.SS4.p1.2.m2.1.1.3.2">10</cn><apply id="A1.SS4.p1.2.m2.1.1.3.3.cmml" xref="A1.SS4.p1.2.m2.1.1.3.3"><minus id="A1.SS4.p1.2.m2.1.1.3.3.1.cmml" xref="A1.SS4.p1.2.m2.1.1.3.3"></minus><cn id="A1.SS4.p1.2.m2.1.1.3.3.2.cmml" type="integer" xref="A1.SS4.p1.2.m2.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.2.m2.1c">1\times 10^{-5}</annotation></semantics></math>로 설정하고, 학습이 끝날 때까지 선형적으로 <math alttext="1\times 10^{-6}" class="ltx_Math" display="inline" id="A1.SS4.p1.3.m3.1"><semantics id="A1.SS4.p1.3.m3.1a"><mrow id="A1.SS4.p1.3.m3.1.1" xref="A1.SS4.p1.3.m3.1.1.cmml"><mn id="A1.SS4.p1.3.m3.1.1.2" xref="A1.SS4.p1.3.m3.1.1.2.cmml">1</mn><mo id="A1.SS4.p1.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS4.p1.3.m3.1.1.1.cmml">×</mo><msup id="A1.SS4.p1.3.m3.1.1.3" xref="A1.SS4.p1.3.m3.1.1.3.cmml"><mn id="A1.SS4.p1.3.m3.1.1.3.2" xref="A1.SS4.p1.3.m3.1.1.3.2.cmml">10</mn><mrow id="A1.SS4.p1.3.m3.1.1.3.3" xref="A1.SS4.p1.3.m3.1.1.3.3.cmml"><mo id="A1.SS4.p1.3.m3.1.1.3.3a" xref="A1.SS4.p1.3.m3.1.1.3.3.cmml">−</mo><mn id="A1.SS4.p1.3.m3.1.1.3.3.2" xref="A1.SS4.p1.3.m3.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.3.m3.1b"><apply id="A1.SS4.p1.3.m3.1.1.cmml" xref="A1.SS4.p1.3.m3.1.1"><times id="A1.SS4.p1.3.m3.1.1.1.cmml" xref="A1.SS4.p1.3.m3.1.1.1"></times><cn id="A1.SS4.p1.3.m3.1.1.2.cmml" type="integer" xref="A1.SS4.p1.3.m3.1.1.2">1</cn><apply id="A1.SS4.p1.3.m3.1.1.3.cmml" xref="A1.SS4.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A1.SS4.p1.3.m3.1.1.3.1.cmml" xref="A1.SS4.p1.3.m3.1.1.3">superscript</csymbol><cn id="A1.SS4.p1.3.m3.1.1.3.2.cmml" type="integer" xref="A1.SS4.p1.3.m3.1.1.3.2">10</cn><apply id="A1.SS4.p1.3.m3.1.1.3.3.cmml" xref="A1.SS4.p1.3.m3.1.1.3.3"><minus id="A1.SS4.p1.3.m3.1.1.3.3.1.cmml" xref="A1.SS4.p1.3.m3.1.1.3.3"></minus><cn id="A1.SS4.p1.3.m3.1.1.3.3.2.cmml" type="integer" xref="A1.SS4.p1.3.m3.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.3.m3.1c">1\times 10^{-6}</annotation></semantics></math>로 하강시킨다. 우리는 훈련에 8개의 A100 GPU를 사용하기 때문에 GPU 배치 크기당 8개로 설정했는데, 이는 총 배치 크기 64에 해당한다. 최대 토큰 길이는 2048로 설정됩니다.</p>
</div>
<div id="A1.SS4.p2" class="ltx_para">
<p class="ltx_p" id="A1.SS4.p2.1">PaLM 기반 모델의 경우 Google Cloud의 LLM 튜닝 웹 UI에서 기본 명령어 튜닝 설정을 따릅니다. 튜닝 스텝 수를 2000, 학습률 승수를 1로 설정하고 TPU 트레이닝 옵션을 사용한다.</p>
</div>
<figure id="A1.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 4:</span>표준 벤치마크에 대한 추가 결과.</figcaption>
<div id="A1.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:212.4pt;height:88.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.2pt,0.9pt) scale(0.98,0.98) ;">
<table id="A1.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T4.1.1.1.1" class="ltx_tr">
<th id="A1.T4.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt"><span id="A1.T4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="A1.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.1.1.1.1.2.1" class="ltx_text ltx_font_bold">BBH</span></th>
<th id="A1.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.1.1.1.1.3.1" class="ltx_text ltx_font_bold">MMLU</span></th>
<th id="A1.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Average</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T4.1.1.2.1" class="ltx_tr">
<th id="A1.T4.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t">LLaMA-7B</th>
<td id="A1.T4.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">30.93</td>
<td id="A1.T4.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">35.17</td>
<td id="A1.T4.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">33.05</td>
</tr>
<tr id="A1.T4.1.1.3.2" class="ltx_tr">
<th id="A1.T4.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr">Alpagasus</th>
<td id="A1.T4.1.1.3.2.2" class="ltx_td ltx_align_center">31.55</td>
<td id="A1.T4.1.1.3.2.3" class="ltx_td ltx_align_center">36.46</td>
<td id="A1.T4.1.1.3.2.4" class="ltx_td ltx_align_center">34.01</td>
</tr>
<tr id="A1.T4.1.1.4.3" class="ltx_tr">
<th id="A1.T4.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr">WizardLM+</th>
<td id="A1.T4.1.1.4.3.2" class="ltx_td ltx_align_center">31.72</td>
<td id="A1.T4.1.1.4.3.3" class="ltx_td ltx_align_center">37.89</td>
<td id="A1.T4.1.1.4.3.4" class="ltx_td ltx_align_center">34.81</td>
</tr>
<tr id="A1.T4.1.1.5.4" class="ltx_tr">
<th id="A1.T4.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_rr">CodecLM (ours)</th>
<td id="A1.T4.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T4.1.1.5.4.2.1" class="ltx_text ltx_font_bold">32.60</span></td>
<td id="A1.T4.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T4.1.1.5.4.3.1" class="ltx_text ltx_font_bold">42.67</span></td>
<td id="A1.T4.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T4.1.1.5.4.4.1" class="ltx_text ltx_font_bold">37.64</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Detailed Comparison Results</h3>

<div id="A1.SS5.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS5.p1.1">우리는 CRR이 다른 방법으로 훈련된 대상 LLM의 능력을 얼마나 충실하게 반영하는지 입증하기 위해 LLaMA 기반 모델을 사용한 Evol-Instruct 벤치마크에 대한 쌍별 비교의 세부 사항을 보여준다. <a class="ltx_ref" href="#A1.T5" title="Table 5 ‣ A.5 Detailed Comparison Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">5</span></a>에서 우리는 넥타이의 수가 결과를 지배하고 승수의 수가 부족하다는 것을 관찰한다. 우리는 목표 모델이 본질적으로 강한 모델에서 지식을 증류하고 있다는 사실에 기인한다. 그 결과 대부분의 경우 LLM 기반 평가자의 렌즈를 통해서만 지도 조정 대상 모델이 강한 모델만큼 잘 대응할 수 있다.</p>
</div>
<figure id="A1.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 5:</span>Evol-Instruct 벤치마크 상의 LLaMA 기반 모델과의 상세한 비교 결과. 각 방법은 LLaMA-7B 또는 -13B를 기반으로 목표 모델을 학습하고 강력한 모델인 제미니-프로와 비교한다. 용량 회복 비율(%) <math alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" class="ltx_Math" display="inline" id="A1.T5.2.m1.1"><semantics id="A1.T5.2.m1.1b"><mrow id="A1.T5.2.m1.1.1" xref="A1.T5.2.m1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.2" xref="A1.T5.2.m1.1.1.2a.cmml">CRR</mtext><mo id="A1.T5.2.m1.1.1.1" xref="A1.T5.2.m1.1.1.1.cmml">=</mo><mfrac id="A1.T5.2.m1.1.1.3" xref="A1.T5.2.m1.1.1.3.cmml"><mrow id="A1.T5.2.m1.1.1.3.2" xref="A1.T5.2.m1.1.1.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.2.2" xref="A1.T5.2.m1.1.1.3.2.2a.cmml">wins</mtext><mo id="A1.T5.2.m1.1.1.3.2.1" xref="A1.T5.2.m1.1.1.3.2.1.cmml">+</mo><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.2.3" xref="A1.T5.2.m1.1.1.3.2.3a.cmml">ties</mtext></mrow><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.3" xref="A1.T5.2.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.2.m1.1c"><apply id="A1.T5.2.m1.1.1.cmml" xref="A1.T5.2.m1.1.1"><eq id="A1.T5.2.m1.1.1.1.cmml" xref="A1.T5.2.m1.1.1.1"></eq><ci id="A1.T5.2.m1.1.1.2a.cmml" xref="A1.T5.2.m1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.2.cmml" xref="A1.T5.2.m1.1.1.2">CRR</mtext></ci><apply id="A1.T5.2.m1.1.1.3.cmml" xref="A1.T5.2.m1.1.1.3"><divide id="A1.T5.2.m1.1.1.3.1.cmml" xref="A1.T5.2.m1.1.1.3"></divide><apply id="A1.T5.2.m1.1.1.3.2.cmml" xref="A1.T5.2.m1.1.1.3.2"><plus id="A1.T5.2.m1.1.1.3.2.1.cmml" xref="A1.T5.2.m1.1.1.3.2.1"></plus><ci id="A1.T5.2.m1.1.1.3.2.2a.cmml" xref="A1.T5.2.m1.1.1.3.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.2.2.cmml" mathsize="70%" xref="A1.T5.2.m1.1.1.3.2.2">wins</mtext></ci><ci id="A1.T5.2.m1.1.1.3.2.3a.cmml" xref="A1.T5.2.m1.1.1.3.2.3"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.2.3.cmml" mathsize="70%" xref="A1.T5.2.m1.1.1.3.2.3">ties</mtext></ci></apply><ci id="A1.T5.2.m1.1.1.3.3a.cmml" xref="A1.T5.2.m1.1.1.3.3"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.3.cmml" mathsize="70%" xref="A1.T5.2.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.2.m1.1d">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation></semantics></math></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Detailed comparison results with LLaMA-based models on Evol-Instruct benchmark. Each method trains a target model based on LLaMA-7B or -13B, and compares against the strong model, Gemini-Pro. Capacity Recovery Ratio (%), <math id="A1.T5.2.m1.1" class="ltx_Math" alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" display="inline"><semantics id="A1.T5.2.m1.1b"><mrow id="A1.T5.2.m1.1.1" xref="A1.T5.2.m1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.2" xref="A1.T5.2.m1.1.1.2a.cmml">CRR</mtext><mo id="A1.T5.2.m1.1.1.1" xref="A1.T5.2.m1.1.1.1.cmml">=</mo><mfrac id="A1.T5.2.m1.1.1.3" xref="A1.T5.2.m1.1.1.3.cmml"><mrow id="A1.T5.2.m1.1.1.3.2" xref="A1.T5.2.m1.1.1.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.2.2" xref="A1.T5.2.m1.1.1.3.2.2a.cmml">wins</mtext><mo id="A1.T5.2.m1.1.1.3.2.1" xref="A1.T5.2.m1.1.1.3.2.1.cmml">+</mo><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.2.3" xref="A1.T5.2.m1.1.1.3.2.3a.cmml">ties</mtext></mrow><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.3.3" xref="A1.T5.2.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.2.m1.1c"><apply id="A1.T5.2.m1.1.1.cmml" xref="A1.T5.2.m1.1.1"><eq id="A1.T5.2.m1.1.1.1.cmml" xref="A1.T5.2.m1.1.1.1"></eq><ci id="A1.T5.2.m1.1.1.2a.cmml" xref="A1.T5.2.m1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="A1.T5.2.m1.1.1.2.cmml" xref="A1.T5.2.m1.1.1.2">CRR</mtext></ci><apply id="A1.T5.2.m1.1.1.3.cmml" xref="A1.T5.2.m1.1.1.3"><divide id="A1.T5.2.m1.1.1.3.1.cmml" xref="A1.T5.2.m1.1.1.3"></divide><apply id="A1.T5.2.m1.1.1.3.2.cmml" xref="A1.T5.2.m1.1.1.3.2"><plus id="A1.T5.2.m1.1.1.3.2.1.cmml" xref="A1.T5.2.m1.1.1.3.2.1"></plus><ci id="A1.T5.2.m1.1.1.3.2.2a.cmml" xref="A1.T5.2.m1.1.1.3.2.2"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="A1.T5.2.m1.1.1.3.2.2.cmml" xref="A1.T5.2.m1.1.1.3.2.2">wins</mtext></ci><ci id="A1.T5.2.m1.1.1.3.2.3a.cmml" xref="A1.T5.2.m1.1.1.3.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="A1.T5.2.m1.1.1.3.2.3.cmml" xref="A1.T5.2.m1.1.1.3.2.3">ties</mtext></ci></apply><ci id="A1.T5.2.m1.1.1.3.3a.cmml" xref="A1.T5.2.m1.1.1.3.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="A1.T5.2.m1.1.1.3.3.cmml" xref="A1.T5.2.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.2.m1.1d">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation></semantics></math>.
</figcaption>
<div id="A1.T5.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:336.5pt;height:132.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.6pt,5.8pt) scale(0.92,0.92) ;">
<table id="A1.T5.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T5.3.1.1.1" class="ltx_tr">
<th id="A1.T5.3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt" rowspan="2"><span id="A1.T5.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<td id="A1.T5.3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="4"><span id="A1.T5.3.1.1.1.2.1" class="ltx_text ltx_font_bold">LLaMA-7B vs. Gemini-Pro</span></td>
<td id="A1.T5.3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="A1.T5.3.1.1.1.3.1" class="ltx_text ltx_font_bold">LLaMA-13B vs. Gemini-Pro</span></td>
</tr>
<tr id="A1.T5.3.1.2.2" class="ltx_tr">
<td id="A1.T5.3.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.1.1" class="ltx_text ltx_font_bold">Wins</span></td>
<td id="A1.T5.3.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.2.1" class="ltx_text ltx_font_bold">Ties</span></td>
<td id="A1.T5.3.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.3.1" class="ltx_text ltx_font_bold">Losses</span></td>
<td id="A1.T5.3.1.2.2.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="A1.T5.3.1.2.2.4.1" class="ltx_text ltx_font_bold">CRR</span></td>
<td id="A1.T5.3.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.5.1" class="ltx_text ltx_font_bold">Wins</span></td>
<td id="A1.T5.3.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.6.1" class="ltx_text ltx_font_bold">Ties</span></td>
<td id="A1.T5.3.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.7.1" class="ltx_text ltx_font_bold">Losses</span></td>
<td id="A1.T5.3.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T5.3.1.2.2.8.1" class="ltx_text ltx_font_bold">CRR</span></td>
</tr>
<tr id="A1.T5.3.1.3.3" class="ltx_tr">
<th id="A1.T5.3.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t">Self-Instruct</th>
<td id="A1.T5.3.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">17</td>
<td id="A1.T5.3.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">140</td>
<td id="A1.T5.3.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">61</td>
<td id="A1.T5.3.1.3.3.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">72.02</td>
<td id="A1.T5.3.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">29</td>
<td id="A1.T5.3.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">136</td>
<td id="A1.T5.3.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">53</td>
<td id="A1.T5.3.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t">75.69</td>
</tr>
<tr id="A1.T5.3.1.4.4" class="ltx_tr">
<th id="A1.T5.3.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Alpagasus</th>
<td id="A1.T5.3.1.4.4.2" class="ltx_td ltx_align_center">17</td>
<td id="A1.T5.3.1.4.4.3" class="ltx_td ltx_align_center">147</td>
<td id="A1.T5.3.1.4.4.4" class="ltx_td ltx_align_center">54</td>
<td id="A1.T5.3.1.4.4.5" class="ltx_td ltx_align_center ltx_border_rr">75.23</td>
<td id="A1.T5.3.1.4.4.6" class="ltx_td ltx_align_center">26</td>
<td id="A1.T5.3.1.4.4.7" class="ltx_td ltx_align_center">148</td>
<td id="A1.T5.3.1.4.4.8" class="ltx_td ltx_align_center">44</td>
<td id="A1.T5.3.1.4.4.9" class="ltx_td ltx_align_center">79.82</td>
</tr>
<tr id="A1.T5.3.1.5.5" class="ltx_tr">
<th id="A1.T5.3.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Tree-Instruct</th>
<td id="A1.T5.3.1.5.5.2" class="ltx_td ltx_align_center">23</td>
<td id="A1.T5.3.1.5.5.3" class="ltx_td ltx_align_center">141</td>
<td id="A1.T5.3.1.5.5.4" class="ltx_td ltx_align_center">54</td>
<td id="A1.T5.3.1.5.5.5" class="ltx_td ltx_align_center ltx_border_rr">75.23</td>
<td id="A1.T5.3.1.5.5.6" class="ltx_td ltx_align_center">26</td>
<td id="A1.T5.3.1.5.5.7" class="ltx_td ltx_align_center">154</td>
<td id="A1.T5.3.1.5.5.8" class="ltx_td ltx_align_center">38</td>
<td id="A1.T5.3.1.5.5.9" class="ltx_td ltx_align_center">82.57</td>
</tr>
<tr id="A1.T5.3.1.6.6" class="ltx_tr">
<th id="A1.T5.3.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM</th>
<td id="A1.T5.3.1.6.6.2" class="ltx_td ltx_align_center">19</td>
<td id="A1.T5.3.1.6.6.3" class="ltx_td ltx_align_center">143</td>
<td id="A1.T5.3.1.6.6.4" class="ltx_td ltx_align_center">56</td>
<td id="A1.T5.3.1.6.6.5" class="ltx_td ltx_align_center ltx_border_rr">74.31</td>
<td id="A1.T5.3.1.6.6.6" class="ltx_td ltx_align_center">30</td>
<td id="A1.T5.3.1.6.6.7" class="ltx_td ltx_align_center">149</td>
<td id="A1.T5.3.1.6.6.8" class="ltx_td ltx_align_center">39</td>
<td id="A1.T5.3.1.6.6.9" class="ltx_td ltx_align_center">82.11</td>
</tr>
<tr id="A1.T5.3.1.7.7" class="ltx_tr">
<th id="A1.T5.3.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM+</th>
<td id="A1.T5.3.1.7.7.2" class="ltx_td ltx_align_center">19</td>
<td id="A1.T5.3.1.7.7.3" class="ltx_td ltx_align_center">146</td>
<td id="A1.T5.3.1.7.7.4" class="ltx_td ltx_align_center">53</td>
<td id="A1.T5.3.1.7.7.5" class="ltx_td ltx_align_center ltx_border_rr">75.69</td>
<td id="A1.T5.3.1.7.7.6" class="ltx_td ltx_align_center">31</td>
<td id="A1.T5.3.1.7.7.7" class="ltx_td ltx_align_center">153</td>
<td id="A1.T5.3.1.7.7.8" class="ltx_td ltx_align_center">34</td>
<td id="A1.T5.3.1.7.7.9" class="ltx_td ltx_align_center">84.40</td>
</tr>
<tr id="A1.T5.3.1.8.8" class="ltx_tr">
<th id="A1.T5.3.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr">CodecLM (ours)</th>
<td id="A1.T5.3.1.8.8.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.2.1" class="ltx_text ltx_font_bold">29</span></td>
<td id="A1.T5.3.1.8.8.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.3.1" class="ltx_text ltx_font_bold">145</span></td>
<td id="A1.T5.3.1.8.8.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.4.1" class="ltx_text ltx_font_bold">44</span></td>
<td id="A1.T5.3.1.8.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr"><span id="A1.T5.3.1.8.8.5.1" class="ltx_text ltx_font_bold">79.82</span></td>
<td id="A1.T5.3.1.8.8.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.6.1" class="ltx_text ltx_font_bold">35</span></td>
<td id="A1.T5.3.1.8.8.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.7.1" class="ltx_text ltx_font_bold">154</span></td>
<td id="A1.T5.3.1.8.8.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.8.1" class="ltx_text ltx_font_bold">29</span></td>
<td id="A1.T5.3.1.8.8.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T5.3.1.8.8.9.1" class="ltx_text ltx_font_bold">86.70</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="A1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Consistency between LLM-based Evaluators</h3>

<figure id="A1.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 6:</span>Performance gap to Self-Instruct in CRR on Evol-Instruct, evaluated by ChatGPT and GPT4 respectively. 각 방법은 LLaMA-7B 또는 -13B를 기반으로 목표 모델을 학습하고 강력한 모델인 제미니-프로와 비교한다. 우리는 두 개의 LLM 기반 자동 평가자가 일관된 결과를 산출하는 것을 관찰한다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance gap to Self-Instruct in terms of CRR on Evol-Instruct, evaluated by ChatGPT and GPT4, respectively. Each method trains a target model based on LLaMA-7B or -13B, and compares against the strong model, Gemini-Pro. We observe two LLM-based automatic evaluators yields consistent results.
</figcaption>
<div id="A1.T6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:254.0pt;height:132.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.0pt,5.8pt) scale(0.92,0.92) ;">
<table id="A1.T6.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T6.1.1.1.1" class="ltx_tr">
<th id="A1.T6.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" rowspan="2"><span id="A1.T6.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="A1.T6.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_tt" colspan="2"><span id="A1.T6.1.1.1.1.2.1" class="ltx_text ltx_font_bold">LLaMA-7B vs. Gemini-Pro</span></th>
<th id="A1.T6.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="A1.T6.1.1.1.1.3.1" class="ltx_text ltx_font_bold">LLaMA-13B vs. Gemini-Pro</span></th>
</tr>
<tr id="A1.T6.1.1.2.2" class="ltx_tr">
<th id="A1.T6.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T6.1.1.2.2.1.1" class="ltx_text ltx_font_bold">ChatGPT</span></th>
<th id="A1.T6.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t"><span id="A1.T6.1.1.2.2.2.1" class="ltx_text ltx_font_bold">GPT4</span></th>
<th id="A1.T6.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T6.1.1.2.2.3.1" class="ltx_text ltx_font_bold">ChatGPT</span></th>
<th id="A1.T6.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T6.1.1.2.2.4.1" class="ltx_text ltx_font_bold">GPT4</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T6.1.1.3.1" class="ltx_tr">
<th id="A1.T6.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t">Self-Instruct</th>
<td id="A1.T6.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="A1.T6.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.00</td>
<td id="A1.T6.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="A1.T6.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
</tr>
<tr id="A1.T6.1.1.4.2" class="ltx_tr">
<th id="A1.T6.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Alpagasus</th>
<td id="A1.T6.1.1.4.2.2" class="ltx_td ltx_align_center">+3.21</td>
<td id="A1.T6.1.1.4.2.3" class="ltx_td ltx_align_center ltx_border_rr">+1.38</td>
<td id="A1.T6.1.1.4.2.4" class="ltx_td ltx_align_center">+4.13</td>
<td id="A1.T6.1.1.4.2.5" class="ltx_td ltx_align_center">+1.83</td>
</tr>
<tr id="A1.T6.1.1.5.3" class="ltx_tr">
<th id="A1.T6.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">Tree-Instruct</th>
<td id="A1.T6.1.1.5.3.2" class="ltx_td ltx_align_center">+3.21</td>
<td id="A1.T6.1.1.5.3.3" class="ltx_td ltx_align_center ltx_border_rr">+2.29</td>
<td id="A1.T6.1.1.5.3.4" class="ltx_td ltx_align_center">+6.88</td>
<td id="A1.T6.1.1.5.3.5" class="ltx_td ltx_align_center">+4.59</td>
</tr>
<tr id="A1.T6.1.1.6.4" class="ltx_tr">
<th id="A1.T6.1.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM</th>
<td id="A1.T6.1.1.6.4.2" class="ltx_td ltx_align_center">+2.29</td>
<td id="A1.T6.1.1.6.4.3" class="ltx_td ltx_align_center ltx_border_rr">+0.46</td>
<td id="A1.T6.1.1.6.4.4" class="ltx_td ltx_align_center">+6.42</td>
<td id="A1.T6.1.1.6.4.5" class="ltx_td ltx_align_center">+3.21</td>
</tr>
<tr id="A1.T6.1.1.7.5" class="ltx_tr">
<th id="A1.T6.1.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr">WizardLM+</th>
<td id="A1.T6.1.1.7.5.2" class="ltx_td ltx_align_center">+3.67</td>
<td id="A1.T6.1.1.7.5.3" class="ltx_td ltx_align_center ltx_border_rr">+2.29</td>
<td id="A1.T6.1.1.7.5.4" class="ltx_td ltx_align_center">+8.72</td>
<td id="A1.T6.1.1.7.5.5" class="ltx_td ltx_align_center">+5.50</td>
</tr>
<tr id="A1.T6.1.1.8.6" class="ltx_tr">
<th id="A1.T6.1.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr">CodecLM (ours)</th>
<td id="A1.T6.1.1.8.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T6.1.1.8.6.2.1" class="ltx_text ltx_font_bold">+7.80</span></td>
<td id="A1.T6.1.1.8.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr"><span id="A1.T6.1.1.8.6.3.1" class="ltx_text ltx_font_bold">+8.26</span></td>
<td id="A1.T6.1.1.8.6.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T6.1.1.8.6.4.1" class="ltx_text ltx_font_bold">+11.01</span></td>
<td id="A1.T6.1.1.8.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T6.1.1.8.6.5.1" class="ltx_text ltx_font_bold">+8.72</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="A1.SS6.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS6.p1.1">본 논문에서는 ChatGPT를 LLM 심사위원으로 사용하여 최종 평가, 커뮤니티가 결과를 재현할 수 있는 효율성, 가격 및 접근성을 제공한다. <cite class="ltx_cite ltx_citemacro_citep">(Chiang et al., <a class="ltx_ref" href="#bib.bib9" title="">2023</a>)</cite>에서 지적한 바와 같이 LLMs 평가자는 인간의 선호도와 대체로 일치하지만 고유한 편향을 가질 수 있다. 따라서 본 논문의 실험 결과가 확실한지 확인하기 위해 GPT-4를 판정자로 사용하고 서로 다른 기준선과 Self-Instruct 방법 간의 CRR 성능 차이를 비교한다. <a class="ltx_ref" href="#A1.T6" title="Table 6 ‣ A.6 Consistency between LLM-based Evaluators ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">6</span></a>의 비교 결과는 두 LLM 기반 판사의 일치를 보여주며 비교 방법에 비해 CodecLM의 우수한 성능을 확인한다.</p>
</div>
</section>
<section id="A1.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.7 </span>Additional Benchmark Results</h3>

<div id="A1.SS7.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS7.p1.1">LLM 기반 자동 평가기를 사용하여 성능 결과를 보완하기 위해 표준 NLP 벤치마크, MMLU <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="#bib.bib18" title="">2020</a>)</cite> 및 BBH <cite class="ltx_cite ltx_citemacro_citep">(Suzgun et al., <a class="ltx_ref" href="#bib.bib40" title="">2022</a>)</cite>에서 섹션 <a class="ltx_ref" href="#S5.SS4" title="5.4 Open-Domain Instruction Following ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">5.4</span></a>에 제시된 상위 방법으로 조정된 LLM을 평가한다. 우리는 LLaMA-7B를 기반으로 대상 모델을 평가하기 위해 시연 없이 <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib46" title="">2023</a>)</cite> 또는 CoT <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="#bib.bib49" title="">2022</a>)</cite> 프롬프트에 도입된 동일한 설정을 따른다. 제안한 방법의 경우 Evol-Instruction 벤치마크 평가와 동일한 설정을 따른다. 평가 결과를 표 <a class="ltx_ref" href="#A1.T4" title="Table 4 ‣ A.4 Training Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4</span></a>에 제시하고 바닐라 LLaMA-7B의 성능을 기준으로 한다. 우리는 LLM 기반 자동 평가기를 사용하는 표 <a class="ltx_ref" href="#S5.T1" title="Table 1 ‣ 5.3 Experiment and Evaluation Details ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">1</span></a>에서와 동일한 모든 방법의 성능 순위를 관찰한다. 서로 다른 두 평가 방법 간의 일관성은 경쟁 방법의 상대적 성능을 입증하는 측면에서 LLM 기반 평가자의 신뢰성을 나타낸다.</p>
</div>
<figure id="A1.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2404.05875/assets/x6.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="358" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 6:</span>CodecLM의 명령어 개선 과정에 대한 사례 연구. 공간을 절약하기 위해 반복적인 지침은 생략됩니다.</figcaption>
</figure>
</section>
<section id="A1.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.8 </span>Case Study</h3>

<div id="A1.SS8.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS8.p1.1">그림 <a class="ltx_ref" href="#A1.F6" title="Figure 6 ‣ A.7 Additional Benchmark Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">6</span></a>에서 명령어 메타데이터에서 최종 고품질 프롬프트까지의 반복적인 테일러링 프로세스를 보여주는 사례 연구를 제시한다. 실제로, 반복은 대비 필터링 프로세스에 의해 더 일찍 종료될 수 있다. 본 논문에서는 Self-Rubrics가 주어진 메타데이터에 따라 루브릭과 액션을 맞춤화할 수 있음을 보인다. 흥미롭게도 LLM에 의해 생성된 작용은 매우 도메인 특이적으로 보인다. 예를 들어, 마지막 액션에서 <em class="ltx_emph ltx_font_italic" id="A1.SS8.p1.1.1">SWOT analysis</em>은 심지어 비전문가 인간 주석자가 고안하기 어려울 수 있다. 또한 지시문에 나타난 색채 텍스트는 LLM이 지시문을 정교하게 다듬기 위해 행동을 매우 정확하게 따를 수 있음을 보여준다.</p>
</div>
</section>
<section id="A1.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.9 </span>Prompt Templates for CodecLM</h3>

<div id="A1.SS9.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS9.p1.1">우리는 더 나은 재현성을 위해 여기 부록에 모든 신속한 템플릿을 제시한다. 특히, 빠른 참조를 위해 프롬프트 템플릿과 그 사용법 사이의 대응 관계를 다음과 같이 나열한다:</p>
<ul id="A1.I3" class="ltx_itemize">
<li id="A1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i1.p1" class="ltx_para">
<p class="ltx_p" id="A1.I3.i1.p1.1">[그림 <a class="ltx_ref" href="#A1.F7" title="Figure 7 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">7</span></a>: 사용 사례 및 전송 가능한 기술을 포함하여 명령어를 메타데이터로 인코딩합니다.</p>
</div>
</li>
<li id="A1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i2.p1" class="ltx_para">
<p class="ltx_p" id="A1.I3.i2.p1.1"><a class="ltx_ref" href="#A1.F8" title="Figure 8 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">8</span></a>: 명령어 메타데이터를 구조가 비교적 간단한 기본 명령어들로 디코딩하는 것.</p>
</div>
</li>
<li id="A1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i3.p1" class="ltx_para">
<p class="ltx_p" id="A1.I3.i3.p1.1">[Figure <a class="ltx_ref" href="#A1.F9" title="Figure 9 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">9</span></a>: 명령어가 얼마나 도전적인지 판단하기 위한 루브릭을 생성하고, 주어진 메타데이터를 기반으로 명령어를 개선하기 위한 액션.</p>
</div>
</li>
<li id="A1.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i4.p1" class="ltx_para">
<p class="ltx_p" id="A1.I3.i4.p1.1"><a class="ltx_ref" href="#A1.F10" title="Figure 10 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">10</span></a>: 생성된 액션 중 하나를 추종하여 입력 명령어를 개선하는 단계.</p>
</div>
</li>
<li id="A1.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i5.p1" class="ltx_para">
<p class="ltx_p" id="A1.I3.i5.p1.1"><a class="ltx_ref" href="#A1.F11" title="Figure 11 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">11</span></a>: 타겟과 강한 LLM으로부터의 응답 품질을 비교한다. 설명 부분을 제거하여 비쿠나 스타일 쌍별 비교 프롬프트에서 조정되었습니다.</p>
</div>
</li>
<li id="A1.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i6.p1" class="ltx_para">
<p class="ltx_p" id="A1.I3.i6.p1.1">그림 <a class="ltx_ref" href="#A1.F12" title="Figure 12 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">12</span></a>: LLM(<span class="ltx_text ltx_font_italic" id="A1.I3.i6.p1.1.1">e.g.</span>, ChatGPT, GPT-4)을 심사위원으로 사용하는 자동 평가. <cite class="ltx_cite ltx_citemacro_citep">(Chiang et al., <a class="ltx_ref" href="#bib.bib9" title="">2023</a>; Chen et al., <a class="ltx_ref" href="#bib.bib8" title="">2023b</a>)</cite>의 템플릿에 따라</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A1.SS9.p1.2">그림 <a class="ltx_ref" href="#A1.F7" title="Figure 7 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">7</span></a>의 첫 번째 인코딩 프롬프트를 제외하고 모든 프롬프트는 0-shot이며, 이는 작업과 기술의 대략적인 세분성을 LLM에 보여주기 위해 소수의 샷 데모를 활용한다. 또한 이러한 프롬프트는 실제로 매우 잘 작동하기 때문에 선택합니다. 그리고 우리는 최근의 신속한 최적화 기술 <cite class="ltx_cite ltx_citemacro_citep">(Fernando et al., <a class="ltx_ref" href="#bib.bib14" title="">2023</a>; Yang et al., <a class="ltx_ref" href="#bib.bib51" title="">2023</a>)</cite>가 우리의 프레임워크에 원활하게 통합될 수 있다고 믿고 향후 작업으로 남긴다.</p>
</div>
<figure id="A1.F7" class="ltx_figure">
<div id="A1.F7.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGFuIGluc3RydWN0aW9uIGFuYWx5emVyLgpHaXZlbiBhbiBpbnN0cnVjdGlvbiwgeW91IHNob3VsZCByZWNvZ25pemUgaXRzIHVzZSBjYXNlIGFuZCB0aGUgc2tpbGxzIChvciBrbm93bGVkZ2UpCnJlcXVpcmVkIGZvciBhIGxhcmdlIGxhbmd1YWdlIG1vZGVsIChMTE0pIHRvIGFuc3dlciB0aGUgcXVlc3Rpb24uCkdlbmVyYXRlIHRoZSB1c2UgY2FzZSBhbmQgc2tpbGxzIHJlcXVpcmVkIHdpdGhvdXQgYW55IGV4cGxhbmF0aW9uLgpMaXN0IGF0IG1vc3QgMyBza2lsbHMsIGVhY2ggc2tpbGwgc2hvdWxkIGJlIHRyYW5zZmVyYWJsZSwgc28gdGhhdCBMTE0gY2FuIGxldmVyYWdlIHRoZW0gdG8gYW5zd2VyCnNpbWlsYXIgcXVlc3Rpb25zLgpBdm9pZCB1c2luZyAic2tpbGwiLCAia25vd2xlZGdlIiB0byBkZXNjcmliZSBhIHNraWxsLCBhbmQgZWFjaCBza2lsbCBzaG91bGQgYmUgY29uY2lzZSAoMi0zIHdvcmRzKS4KRm9sbG93IHRoZSBleGFtcGxlcyBiZWxvdyB0byBhbmFseXplIHRoZSBnaXZlbiBpbnN0cnVjdGlvbi4KXHBhciNFeGFtcGxlIDEjCkFzIGEgc3BvcnRzIGNvbW1lbnRhdG9yLCBkZXNjcmliZSB0aGUgd2lubmluZyBwbGF5IGluIHRoZSBmaW5hbCBzZWNvbmRzIG9mIGEgY2hhbXBpb25zaGlwIGdhbWUuClVzZSBjYXNlOiBjcmVhdGl2ZSB3cml0aW5nClNraWxsczogcm9sZS1wbGF5LCBzcG9ydHMKXHBhciNFeGFtcGxlIDIjCkhvdyB0byByZWFkIGEgbGFyZ2UgZmlsZSAoPiAyVCkgdXNpbmcgcHl0aG9uPwpUYXNrOiBjb2RlIGdlbmVyYXRpb24KU2tpbGxzOiBweXRob24KXHBhciNFeGFtcGxlIDMjClRoZSBtZXRob2Qgc2VjdGlvbiBvZiB5b3VyIHBhcGVyIGlzIHRvbyBicmllZiBhbmQgZG9lcyBub3QgZXhwbGFpbiBob3cgeW91ciBwcm9wb3NlZCBtb2RlbCB3b3JrcwppbiBkZXRhaWwuIEhvdyBjYW4geW91IHByb3ZpZGUgbW9yZSBkZXRhaWxzIG9mIHRoZSBoaWVyYXJjaGljYWwgZW5jb2RlciBhbmQgdGhlIGNhc2NhZGVkIHNlbGVjdG9ycywKc3VjaCBhcyB0aGVpciBhcmNoaXRlY3R1cmVzLCBpbnB1dHMsIG91dHB1dHMsIGFuZCBwYXJhbWV0ZXJzPwpUYXNrOiBnZW5lcmFsIGtub3dsZWRnZSBxdWVzdGlvbiBhbnN3ZXJpbmcKU2tpbGxzOiBhY2FkZW1pYyB3cml0aW5nLCBtYWNoaW5lIGxlYXJuaW5nClxwYXI8aW5wdXQgaW5zdHJ1Y3Rpb24+CjxvdXRwdXQgbWV0YWRhdGE+Cg==" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_lst_identifier">I</span><span id="lstnumberx2.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.3" class="ltx_text ltx_lst_identifier">want</span><span id="lstnumberx2.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.5" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx2.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx2.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.9" class="ltx_text ltx_lst_identifier">act</span><span id="lstnumberx2.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.11" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx2.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.13" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx2.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx2.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx2.17" class="ltx_text ltx_lst_identifier">analyzer</span>.
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span id="lstnumberx3.1" class="ltx_text ltx_lst_identifier">Given</span><span id="lstnumberx3.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.3" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx3.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.5" class="ltx_text ltx_lst_identifier">instruction</span>,<span id="lstnumberx3.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.7" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx3.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.9" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx3.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.11" class="ltx_text ltx_lst_identifier">recognize</span><span id="lstnumberx3.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.13" class="ltx_text ltx_lst_identifier">its</span><span id="lstnumberx3.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.15" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx3.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.17" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx3.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.19" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx3.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.21" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx3.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.23" class="ltx_text ltx_lst_identifier">skills</span><span id="lstnumberx3.24" class="ltx_text ltx_lst_space"> </span>(<span id="lstnumberx3.25" class="ltx_text ltx_lst_identifier">or</span><span id="lstnumberx3.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.27" class="ltx_text ltx_lst_identifier">knowledge</span>)
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span id="lstnumberx4.1" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx4.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.3" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx4.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.5" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx4.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.7" class="ltx_text ltx_lst_identifier">large</span><span id="lstnumberx4.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.9" class="ltx_text ltx_lst_identifier">language</span><span id="lstnumberx4.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.11" class="ltx_text ltx_lst_identifier">model</span><span id="lstnumberx4.12" class="ltx_text ltx_lst_space"> </span>(<span id="lstnumberx4.13" class="ltx_text ltx_lst_identifier">LLM</span>)<span id="lstnumberx4.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.15" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx4.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.17" class="ltx_text ltx_lst_identifier">answer</span><span id="lstnumberx4.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx4.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx4.21" class="ltx_text ltx_lst_identifier">question</span>.
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_lst_identifier">Generate</span><span id="lstnumberx5.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.3" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx5.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.5" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx5.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.7" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx5.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.9" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx5.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.11" class="ltx_text ltx_lst_identifier">skills</span><span id="lstnumberx5.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.13" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx5.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.15" class="ltx_text ltx_lst_identifier">without</span><span id="lstnumberx5.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.17" class="ltx_text ltx_lst_identifier">any</span><span id="lstnumberx5.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.19" class="ltx_text ltx_lst_identifier">explanation</span>.
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span id="lstnumberx6.1" class="ltx_text ltx_lst_identifier">List</span><span id="lstnumberx6.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.3" class="ltx_text ltx_lst_identifier">at</span><span id="lstnumberx6.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.5" class="ltx_text ltx_lst_identifier">most</span><span id="lstnumberx6.6" class="ltx_text ltx_lst_space"> </span>3<span id="lstnumberx6.7" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.8" class="ltx_text ltx_lst_identifier">skills</span>,<span id="lstnumberx6.9" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.10" class="ltx_text ltx_lst_identifier">each</span><span id="lstnumberx6.11" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.12" class="ltx_text ltx_lst_identifier">skill</span><span id="lstnumberx6.13" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.14" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx6.15" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.16" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx6.17" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.18" class="ltx_text ltx_lst_identifier">transferable</span>,<span id="lstnumberx6.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.20" class="ltx_text ltx_lst_identifier">so</span><span id="lstnumberx6.21" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.22" class="ltx_text ltx_lst_identifier">that</span><span id="lstnumberx6.23" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.24" class="ltx_text ltx_lst_identifier">LLM</span><span id="lstnumberx6.25" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.26" class="ltx_text ltx_lst_identifier">can</span><span id="lstnumberx6.27" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.28" class="ltx_text ltx_lst_identifier">leverage</span><span id="lstnumberx6.29" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.30" class="ltx_text ltx_lst_identifier">them</span><span id="lstnumberx6.31" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.32" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx6.33" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx6.34" class="ltx_text ltx_lst_identifier">answer</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span id="lstnumberx7.1" class="ltx_text ltx_lst_identifier">similar</span><span id="lstnumberx7.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx7.3" class="ltx_text ltx_lst_identifier">questions</span>.
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span id="lstnumberx8.1" class="ltx_text ltx_lst_identifier">Avoid</span><span id="lstnumberx8.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.3" class="ltx_text ltx_lst_identifier">using</span><span id="lstnumberx8.4" class="ltx_text ltx_lst_space"> </span>"<span id="lstnumberx8.5" class="ltx_text ltx_lst_identifier">skill</span>",<span id="lstnumberx8.6" class="ltx_text ltx_lst_space"> </span>"<span id="lstnumberx8.7" class="ltx_text ltx_lst_identifier">knowledge</span>"<span id="lstnumberx8.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.9" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx8.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.11" class="ltx_text ltx_lst_identifier">describe</span><span id="lstnumberx8.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx8.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.15" class="ltx_text ltx_lst_identifier">skill</span>,<span id="lstnumberx8.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.17" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx8.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.19" class="ltx_text ltx_lst_identifier">each</span><span id="lstnumberx8.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.21" class="ltx_text ltx_lst_identifier">skill</span><span id="lstnumberx8.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.23" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx8.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.25" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx8.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.27" class="ltx_text ltx_lst_identifier">concise</span><span id="lstnumberx8.28" class="ltx_text ltx_lst_space"> </span>(2-3<span id="lstnumberx8.29" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx8.30" class="ltx_text ltx_lst_identifier">words</span>).
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span id="lstnumberx9.1" class="ltx_text ltx_lst_identifier">Follow</span><span id="lstnumberx9.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.3" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx9.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.5" class="ltx_text ltx_lst_identifier">examples</span><span id="lstnumberx9.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.7" class="ltx_text ltx_lst_identifier">below</span><span id="lstnumberx9.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.9" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx9.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.11" class="ltx_text ltx_lst_identifier">analyze</span><span id="lstnumberx9.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.13" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx9.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.15" class="ltx_text ltx_lst_identifier">given</span><span id="lstnumberx9.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx9.17" class="ltx_text ltx_lst_identifier">instruction</span>.
</div>
<div id="lstnumberx10" class="ltx_listingline">\<span id="lstnumberx10.1" class="ltx_text ltx_lst_identifier">par</span>#<span id="lstnumberx10.2" class="ltx_text ltx_lst_identifier">Example</span><span id="lstnumberx10.3" class="ltx_text ltx_lst_space"> </span>1#
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span id="lstnumberx11.1" class="ltx_text ltx_lst_identifier">As</span><span id="lstnumberx11.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.3" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx11.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.5" class="ltx_text ltx_lst_identifier">sports</span><span id="lstnumberx11.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.7" class="ltx_text ltx_lst_identifier">commentator</span>,<span id="lstnumberx11.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.9" class="ltx_text ltx_lst_identifier">describe</span><span id="lstnumberx11.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.11" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx11.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.13" class="ltx_text ltx_lst_identifier">winning</span><span id="lstnumberx11.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.15" class="ltx_text ltx_lst_identifier">play</span><span id="lstnumberx11.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.17" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx11.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx11.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.21" class="ltx_text ltx_lst_identifier">final</span><span id="lstnumberx11.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.23" class="ltx_text ltx_lst_identifier">seconds</span><span id="lstnumberx11.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.25" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx11.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.27" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx11.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.29" class="ltx_text ltx_lst_identifier">championship</span><span id="lstnumberx11.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx11.31" class="ltx_text ltx_lst_identifier">game</span>.
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span id="lstnumberx12.1" class="ltx_text ltx_lst_identifier">Use</span><span id="lstnumberx12.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx12.3" class="ltx_text ltx_lst_identifier">case</span>:<span id="lstnumberx12.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx12.5" class="ltx_text ltx_lst_identifier">creative</span><span id="lstnumberx12.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx12.7" class="ltx_text ltx_lst_identifier">writing</span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span id="lstnumberx13.1" class="ltx_text ltx_lst_identifier">Skills</span>:<span id="lstnumberx13.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx13.3" class="ltx_text ltx_lst_identifier">role</span>-<span id="lstnumberx13.4" class="ltx_text ltx_lst_identifier">play</span>,<span id="lstnumberx13.5" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx13.6" class="ltx_text ltx_lst_identifier">sports</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">\<span id="lstnumberx14.1" class="ltx_text ltx_lst_identifier">par</span>#<span id="lstnumberx14.2" class="ltx_text ltx_lst_identifier">Example</span><span id="lstnumberx14.3" class="ltx_text ltx_lst_space"> </span>2#
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span id="lstnumberx15.1" class="ltx_text ltx_lst_identifier">How</span><span id="lstnumberx15.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.3" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx15.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.5" class="ltx_text ltx_lst_identifier">read</span><span id="lstnumberx15.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.7" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx15.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.9" class="ltx_text ltx_lst_identifier">large</span><span id="lstnumberx15.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.11" class="ltx_text ltx_lst_identifier">file</span><span id="lstnumberx15.12" class="ltx_text ltx_lst_space"> </span>(&gt;<span id="lstnumberx15.13" class="ltx_text ltx_lst_space"> </span>2<span id="lstnumberx15.14" class="ltx_text ltx_lst_identifier">T</span>)<span id="lstnumberx15.15" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.16" class="ltx_text ltx_lst_identifier">using</span><span id="lstnumberx15.17" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx15.18" class="ltx_text ltx_lst_identifier">python</span>?
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span id="lstnumberx16.1" class="ltx_text ltx_lst_identifier">Task</span>:<span id="lstnumberx16.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx16.3" class="ltx_text ltx_lst_identifier">code</span><span id="lstnumberx16.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx16.5" class="ltx_text ltx_lst_identifier">generation</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span id="lstnumberx17.1" class="ltx_text ltx_lst_identifier">Skills</span>:<span id="lstnumberx17.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx17.3" class="ltx_text ltx_lst_identifier">python</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">\<span id="lstnumberx18.1" class="ltx_text ltx_lst_identifier">par</span>#<span id="lstnumberx18.2" class="ltx_text ltx_lst_identifier">Example</span><span id="lstnumberx18.3" class="ltx_text ltx_lst_space"> </span>3#
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span id="lstnumberx19.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx19.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.3" class="ltx_text ltx_lst_identifier">method</span><span id="lstnumberx19.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.5" class="ltx_text ltx_lst_identifier">section</span><span id="lstnumberx19.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.7" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx19.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.9" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx19.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.11" class="ltx_text ltx_lst_identifier">paper</span><span id="lstnumberx19.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.13" class="ltx_text ltx_lst_identifier">is</span><span id="lstnumberx19.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.15" class="ltx_text ltx_lst_identifier">too</span><span id="lstnumberx19.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.17" class="ltx_text ltx_lst_identifier">brief</span><span id="lstnumberx19.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.19" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx19.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.21" class="ltx_text ltx_lst_identifier">does</span><span id="lstnumberx19.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.23" class="ltx_text ltx_lst_identifier">not</span><span id="lstnumberx19.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.25" class="ltx_text ltx_lst_identifier">explain</span><span id="lstnumberx19.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.27" class="ltx_text ltx_lst_identifier">how</span><span id="lstnumberx19.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.29" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx19.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.31" class="ltx_text ltx_lst_identifier">proposed</span><span id="lstnumberx19.32" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.33" class="ltx_text ltx_lst_identifier">model</span><span id="lstnumberx19.34" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx19.35" class="ltx_text ltx_lst_identifier">works</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span id="lstnumberx20.1" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx20.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.3" class="ltx_text ltx_lst_identifier">detail</span>.<span id="lstnumberx20.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.5" class="ltx_text ltx_lst_identifier">How</span><span id="lstnumberx20.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.7" class="ltx_text ltx_lst_identifier">can</span><span id="lstnumberx20.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.9" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx20.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.11" class="ltx_text ltx_lst_identifier">provide</span><span id="lstnumberx20.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.13" class="ltx_text ltx_lst_identifier">more</span><span id="lstnumberx20.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.15" class="ltx_text ltx_lst_identifier">details</span><span id="lstnumberx20.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.17" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx20.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx20.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.21" class="ltx_text ltx_lst_identifier">hierarchical</span><span id="lstnumberx20.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.23" class="ltx_text ltx_lst_identifier">encoder</span><span id="lstnumberx20.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.25" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx20.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.27" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx20.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.29" class="ltx_text ltx_lst_identifier">cascaded</span><span id="lstnumberx20.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx20.31" class="ltx_text ltx_lst_identifier">selectors</span>,
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span id="lstnumberx21.1" class="ltx_text ltx_lst_identifier">such</span><span id="lstnumberx21.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.3" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx21.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.5" class="ltx_text ltx_lst_identifier">their</span><span id="lstnumberx21.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.7" class="ltx_text ltx_lst_identifier">architectures</span>,<span id="lstnumberx21.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.9" class="ltx_text ltx_lst_identifier">inputs</span>,<span id="lstnumberx21.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.11" class="ltx_text ltx_lst_identifier">outputs</span>,<span id="lstnumberx21.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.13" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx21.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx21.15" class="ltx_text ltx_lst_identifier">parameters</span>?
</div>
<div id="lstnumberx22" class="ltx_listingline">
<span id="lstnumberx22.1" class="ltx_text ltx_lst_identifier">Task</span>:<span id="lstnumberx22.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx22.3" class="ltx_text ltx_lst_identifier">general</span><span id="lstnumberx22.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx22.5" class="ltx_text ltx_lst_identifier">knowledge</span><span id="lstnumberx22.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx22.7" class="ltx_text ltx_lst_identifier">question</span><span id="lstnumberx22.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx22.9" class="ltx_text ltx_lst_identifier">answering</span>
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span id="lstnumberx23.1" class="ltx_text ltx_lst_identifier">Skills</span>:<span id="lstnumberx23.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx23.3" class="ltx_text ltx_lst_identifier">academic</span><span id="lstnumberx23.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx23.5" class="ltx_text ltx_lst_identifier">writing</span>,<span id="lstnumberx23.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx23.7" class="ltx_text ltx_lst_identifier">machine</span><span id="lstnumberx23.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx23.9" class="ltx_text ltx_lst_identifier">learning</span>
</div>
<div id="lstnumberx24" class="ltx_listingline">\<span id="lstnumberx24.1" class="ltx_text ltx_lst_identifier">par</span>&lt;<span id="lstnumberx24.2" class="ltx_text ltx_lst_identifier">input</span><span id="lstnumberx24.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx24.4" class="ltx_text ltx_lst_identifier">instruction</span>&gt;
</div>
<div id="lstnumberx25" class="ltx_listingline">&lt;<span id="lstnumberx25.1" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx25.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx25.3" class="ltx_text ltx_lst_identifier">metadata</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">그림 7:</span>Prompt template to encode the input into metadata, consisting of its use case and transferable skills.</figcaption>
</figure>
<figure id="A1.F8" class="ltx_figure">
<div id="A1.F8.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGFuIGluc3RydWN0aW9uIHdyaXRlci4KWW91ciBvYmplY3RpdmUgaXMgdG8gd3JpdGUgPG51bWJlciBvZiBpbnN0cnVjdGlvbnM+IGluc3RydWN0aW9ucyB0aGF0IG11c3QgYmUgcmVhc29uYWJsZQphbmQgbXVzdCBiZSB1bmRlcnN0b29kIGFuZCByZXNwb25kZWQgYnkgaHVtYW5zLgpUaGUgZ2VuZXJhdGVkIGluc3RydWN0aW9ucyBzaG91bGQgYmUgZGl2ZXJzZSBlbm91Z2ggd2hpbGUgZm9sbG93aW5nIHRoZSBjb25zdHJhaW50cyBiZWxvdzoKXHBhclVzZSBjYXNlIG9mIHRoZSBpbnN0cnVjdGlvbnM6IDx1c2UgY2FzZT4KU2tpbGxzIHJlcXVpcmVkIHRvIHJlc3BvbmQgdG8gdGhlIGluc3RydWN0aW9uczogPHNraWxscz4KXHBhckdlbmVyYXRlIHRoZSBpbnN0cnVjdGlvbnMgd2l0aG91dCBhbnN3ZXJpbmcgaW4gbnVtYmVyZWQgYnVsbGV0aW4gcG9pbnRzLgpccGFyPG91dHB1dCBpbnN0cnVjdGlvbnM+Cg==" download="">⬇</a></div>
<div id="lstnumberx26" class="ltx_listingline">
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span id="lstnumberx27.1" class="ltx_text ltx_lst_identifier">I</span><span id="lstnumberx27.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.3" class="ltx_text ltx_lst_identifier">want</span><span id="lstnumberx27.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.5" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx27.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx27.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.9" class="ltx_text ltx_lst_identifier">act</span><span id="lstnumberx27.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.11" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx27.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.13" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx27.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx27.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx27.17" class="ltx_text ltx_lst_identifier">writer</span>.
</div>
<div id="lstnumberx28" class="ltx_listingline">
<span id="lstnumberx28.1" class="ltx_text ltx_lst_identifier">Your</span><span id="lstnumberx28.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.3" class="ltx_text ltx_lst_identifier">objective</span><span id="lstnumberx28.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.5" class="ltx_text ltx_lst_identifier">is</span><span id="lstnumberx28.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx28.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.9" class="ltx_text ltx_lst_identifier">write</span><span id="lstnumberx28.10" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx28.11" class="ltx_text ltx_lst_identifier">number</span><span id="lstnumberx28.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.13" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx28.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.15" class="ltx_text ltx_lst_identifier">instructions</span>&gt;<span id="lstnumberx28.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.17" class="ltx_text ltx_lst_identifier">instructions</span><span id="lstnumberx28.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.19" class="ltx_text ltx_lst_identifier">that</span><span id="lstnumberx28.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.21" class="ltx_text ltx_lst_identifier">must</span><span id="lstnumberx28.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.23" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx28.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx28.25" class="ltx_text ltx_lst_identifier">reasonable</span>
</div>
<div id="lstnumberx29" class="ltx_listingline">
<span id="lstnumberx29.1" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx29.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.3" class="ltx_text ltx_lst_identifier">must</span><span id="lstnumberx29.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.5" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx29.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.7" class="ltx_text ltx_lst_identifier">understood</span><span id="lstnumberx29.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.9" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx29.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.11" class="ltx_text ltx_lst_identifier">responded</span><span id="lstnumberx29.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.13" class="ltx_text ltx_lst_identifier">by</span><span id="lstnumberx29.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx29.15" class="ltx_text ltx_lst_identifier">humans</span>.
</div>
<div id="lstnumberx30" class="ltx_listingline">
<span id="lstnumberx30.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx30.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.3" class="ltx_text ltx_lst_identifier">generated</span><span id="lstnumberx30.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.5" class="ltx_text ltx_lst_identifier">instructions</span><span id="lstnumberx30.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.7" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx30.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.9" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx30.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.11" class="ltx_text ltx_lst_identifier">diverse</span><span id="lstnumberx30.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.13" class="ltx_text ltx_lst_identifier">enough</span><span id="lstnumberx30.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.15" class="ltx_text ltx_lst_identifier">while</span><span id="lstnumberx30.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.17" class="ltx_text ltx_lst_identifier">following</span><span id="lstnumberx30.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx30.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.21" class="ltx_text ltx_lst_identifier">constraints</span><span id="lstnumberx30.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx30.23" class="ltx_text ltx_lst_identifier">below</span>:
</div>
<div id="lstnumberx31" class="ltx_listingline">\<span id="lstnumberx31.1" class="ltx_text ltx_lst_identifier">parUse</span><span id="lstnumberx31.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.3" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx31.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx31.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.7" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx31.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.9" class="ltx_text ltx_lst_identifier">instructions</span>:<span id="lstnumberx31.10" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx31.11" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx31.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx31.13" class="ltx_text ltx_lst_identifier">case</span>&gt;
</div>
<div id="lstnumberx32" class="ltx_listingline">
<span id="lstnumberx32.1" class="ltx_text ltx_lst_identifier">Skills</span><span id="lstnumberx32.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.3" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx32.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.5" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx32.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.7" class="ltx_text ltx_lst_identifier">respond</span><span id="lstnumberx32.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.9" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx32.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.11" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx32.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx32.13" class="ltx_text ltx_lst_identifier">instructions</span>:<span id="lstnumberx32.14" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx32.15" class="ltx_text ltx_lst_identifier">skills</span>&gt;
</div>
<div id="lstnumberx33" class="ltx_listingline">\<span id="lstnumberx33.1" class="ltx_text ltx_lst_identifier">parGenerate</span><span id="lstnumberx33.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.3" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx33.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.5" class="ltx_text ltx_lst_identifier">instructions</span><span id="lstnumberx33.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.7" class="ltx_text ltx_lst_identifier">without</span><span id="lstnumberx33.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.9" class="ltx_text ltx_lst_identifier">answering</span><span id="lstnumberx33.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.11" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx33.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.13" class="ltx_text ltx_lst_identifier">numbered</span><span id="lstnumberx33.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.15" class="ltx_text ltx_lst_identifier">bulletin</span><span id="lstnumberx33.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx33.17" class="ltx_text ltx_lst_identifier">points</span>.
</div>
<div id="lstnumberx34" class="ltx_listingline">\<span id="lstnumberx34.1" class="ltx_text ltx_lst_identifier">par</span>&lt;<span id="lstnumberx34.2" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx34.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx34.4" class="ltx_text ltx_lst_identifier">instructions</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8:</span>Prompt template to generate instructions from metadata.</figcaption>
</figure>
<figure id="A1.F9" class="ltx_figure">
<div id="A1.F9.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGEgaW5zdHJ1Y3Rpb24ganVkZ2Ugd2l0aCBkb21haW4gZXhwZXJ0aXNlLgpZb3VyIGpvYiBpcyB0byBnZW5lcmF0ZSA8bnVtYmVyX29mX3J1YnJpY3M+IGRvbWFpbiBzcGVjaWZpYyBydWJyaWNzIHRvIGFzc2VzcyB0aGUgZGlmZmljdWx0eSBhbmQKY29tcGxleGl0eSBiYXNlZCBvbiB0aGUgdXNlIGNhc2Ugb2YgdGhlIGluc3RydWN0aW9uLCBhbmQgc2tpbGxzIHJlcXVpcmVkIHRvIHJlc3BvbmQgdG8gaXQuClRoZSBnZW5lcmF0ZWQgcnVicmljcyBzaG91bGQgYmUgY2xlYXIsIGNvbmNpc2UgYW5kIHVuYW1iaWd1b3VzLgpCYXNlZCBvbiB0aGUgZ2VuZXJhdGVkIHJ1YnJpY3MsIGdlbmVyYXRlIGNvcnJlc3BvbmRpbmcgYWN0aW9ucyB0byBpbXByb3ZlIGFuIGluc3RydWN0aW9uIGJ5Cm1ha2luZyBpdCBtb3JlIGNoYWxsZW5naW5nLgpccGFyVGhlIHVzZSBjYXNlIG9mIHRoZSBpbnN0cnVjdGlvbjogPHVzZSBjYXNlPi4KVGhlIHNraWxscyByZXF1aXJlZCB0byBzb2x2ZSB0aGUgaW5zdHJ1Y3Rpb246IDxza2lsbHM+LgpccGFyR2VuZXJhdGUgdGhlIGRvbWFpbi1zcGVjaWZpYyBydWJyaWNzIGFuZCBhY3Rpb25zIHdpdGhvdXQgZXhwbGFuYXRpb24gaW4gbnVtYmVyZWQgYnVsbGV0aW4gcG9pbnRzOgpccGFyPG91dHB1dCBydWJyaWNzPgo8b3V0cHV0IGFjdGlvbnM+Cg==" download="">⬇</a></div>
<div id="lstnumberx35" class="ltx_listingline">
</div>
<div id="lstnumberx36" class="ltx_listingline">
<span id="lstnumberx36.1" class="ltx_text ltx_lst_identifier">I</span><span id="lstnumberx36.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.3" class="ltx_text ltx_lst_identifier">want</span><span id="lstnumberx36.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.5" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx36.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx36.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.9" class="ltx_text ltx_lst_identifier">act</span><span id="lstnumberx36.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.11" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx36.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx36.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx36.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.17" class="ltx_text ltx_lst_identifier">judge</span><span id="lstnumberx36.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.19" class="ltx_text ltx_lst_identifier">with</span><span id="lstnumberx36.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.21" class="ltx_text ltx_lst_identifier">domain</span><span id="lstnumberx36.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx36.23" class="ltx_text ltx_lst_identifier">expertise</span>.
</div>
<div id="lstnumberx37" class="ltx_listingline">
<span id="lstnumberx37.1" class="ltx_text ltx_lst_identifier">Your</span><span id="lstnumberx37.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.3" class="ltx_text ltx_lst_identifier">job</span><span id="lstnumberx37.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.5" class="ltx_text ltx_lst_identifier">is</span><span id="lstnumberx37.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx37.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.9" class="ltx_text ltx_lst_identifier">generate</span><span id="lstnumberx37.10" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx37.11" class="ltx_text ltx_lst_identifier">number_of_rubrics</span>&gt;<span id="lstnumberx37.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.13" class="ltx_text ltx_lst_identifier">domain</span><span id="lstnumberx37.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.15" class="ltx_text ltx_lst_identifier">specific</span><span id="lstnumberx37.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.17" class="ltx_text ltx_lst_identifier">rubrics</span><span id="lstnumberx37.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.19" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx37.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.21" class="ltx_text ltx_lst_identifier">assess</span><span id="lstnumberx37.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx37.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.25" class="ltx_text ltx_lst_identifier">difficulty</span><span id="lstnumberx37.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx37.27" class="ltx_text ltx_lst_identifier">and</span>
</div>
<div id="lstnumberx38" class="ltx_listingline">
<span id="lstnumberx38.1" class="ltx_text ltx_lst_identifier">complexity</span><span id="lstnumberx38.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.3" class="ltx_text ltx_lst_identifier">based</span><span id="lstnumberx38.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.5" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx38.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.7" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx38.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.9" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx38.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.11" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx38.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.13" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx38.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.15" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx38.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.17" class="ltx_text ltx_lst_identifier">instruction</span>,<span id="lstnumberx38.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.19" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx38.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.21" class="ltx_text ltx_lst_identifier">skills</span><span id="lstnumberx38.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.23" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx38.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.25" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx38.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.27" class="ltx_text ltx_lst_identifier">respond</span><span id="lstnumberx38.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.29" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx38.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx38.31" class="ltx_text ltx_lst_identifier">it</span>.
</div>
<div id="lstnumberx39" class="ltx_listingline">
<span id="lstnumberx39.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx39.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.3" class="ltx_text ltx_lst_identifier">generated</span><span id="lstnumberx39.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.5" class="ltx_text ltx_lst_identifier">rubrics</span><span id="lstnumberx39.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.7" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx39.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.9" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx39.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.11" class="ltx_text ltx_lst_identifier">clear</span>,<span id="lstnumberx39.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.13" class="ltx_text ltx_lst_identifier">concise</span><span id="lstnumberx39.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.15" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx39.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx39.17" class="ltx_text ltx_lst_identifier">unambiguous</span>.
</div>
<div id="lstnumberx40" class="ltx_listingline">
<span id="lstnumberx40.1" class="ltx_text ltx_lst_identifier">Based</span><span id="lstnumberx40.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.3" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx40.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.5" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx40.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.7" class="ltx_text ltx_lst_identifier">generated</span><span id="lstnumberx40.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.9" class="ltx_text ltx_lst_identifier">rubrics</span>,<span id="lstnumberx40.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.11" class="ltx_text ltx_lst_identifier">generate</span><span id="lstnumberx40.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.13" class="ltx_text ltx_lst_identifier">corresponding</span><span id="lstnumberx40.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.15" class="ltx_text ltx_lst_identifier">actions</span><span id="lstnumberx40.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.17" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx40.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.19" class="ltx_text ltx_lst_identifier">improve</span><span id="lstnumberx40.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.21" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx40.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.23" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx40.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx40.25" class="ltx_text ltx_lst_identifier">by</span>
</div>
<div id="lstnumberx41" class="ltx_listingline">
<span id="lstnumberx41.1" class="ltx_text ltx_lst_identifier">making</span><span id="lstnumberx41.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx41.3" class="ltx_text ltx_lst_identifier">it</span><span id="lstnumberx41.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx41.5" class="ltx_text ltx_lst_identifier">more</span><span id="lstnumberx41.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx41.7" class="ltx_text ltx_lst_identifier">challenging</span>.
</div>
<div id="lstnumberx42" class="ltx_listingline">\<span id="lstnumberx42.1" class="ltx_text ltx_lst_identifier">parThe</span><span id="lstnumberx42.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.3" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx42.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.5" class="ltx_text ltx_lst_identifier">case</span><span id="lstnumberx42.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.7" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx42.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.9" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx42.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.11" class="ltx_text ltx_lst_identifier">instruction</span>:<span id="lstnumberx42.12" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx42.13" class="ltx_text ltx_lst_identifier">use</span><span id="lstnumberx42.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx42.15" class="ltx_text ltx_lst_identifier">case</span>&gt;.
</div>
<div id="lstnumberx43" class="ltx_listingline">
<span id="lstnumberx43.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx43.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.3" class="ltx_text ltx_lst_identifier">skills</span><span id="lstnumberx43.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.5" class="ltx_text ltx_lst_identifier">required</span><span id="lstnumberx43.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx43.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.9" class="ltx_text ltx_lst_identifier">solve</span><span id="lstnumberx43.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.11" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx43.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx43.13" class="ltx_text ltx_lst_identifier">instruction</span>:<span id="lstnumberx43.14" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx43.15" class="ltx_text ltx_lst_identifier">skills</span>&gt;.
</div>
<div id="lstnumberx44" class="ltx_listingline">\<span id="lstnumberx44.1" class="ltx_text ltx_lst_identifier">parGenerate</span><span id="lstnumberx44.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.3" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx44.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.5" class="ltx_text ltx_lst_identifier">domain</span>-<span id="lstnumberx44.6" class="ltx_text ltx_lst_identifier">specific</span><span id="lstnumberx44.7" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.8" class="ltx_text ltx_lst_identifier">rubrics</span><span id="lstnumberx44.9" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.10" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx44.11" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.12" class="ltx_text ltx_lst_identifier">actions</span><span id="lstnumberx44.13" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.14" class="ltx_text ltx_lst_identifier">without</span><span id="lstnumberx44.15" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.16" class="ltx_text ltx_lst_identifier">explanation</span><span id="lstnumberx44.17" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.18" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx44.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.20" class="ltx_text ltx_lst_identifier">numbered</span><span id="lstnumberx44.21" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.22" class="ltx_text ltx_lst_identifier">bulletin</span><span id="lstnumberx44.23" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx44.24" class="ltx_text ltx_lst_identifier">points</span>:
</div>
<div id="lstnumberx45" class="ltx_listingline">\<span id="lstnumberx45.1" class="ltx_text ltx_lst_identifier">par</span>&lt;<span id="lstnumberx45.2" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx45.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx45.4" class="ltx_text ltx_lst_identifier">rubrics</span>&gt;
</div>
<div id="lstnumberx46" class="ltx_listingline">&lt;<span id="lstnumberx46.1" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx46.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx46.3" class="ltx_text ltx_lst_identifier">actions</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9:</span>Prompt template to generate actions to improve instructions based on instructions.</figcaption>
</figure>
<figure id="A1.F10" class="ltx_figure">
<div id="A1.F10.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGEgaW5zdHJ1Y3Rpb24gaW1wcm92ZXIgd2l0aCBkb21haW4gZXhwZXJ0aXNlLgpZb3VyIGpvYiBpcyB0byBtYWtlIHRoZSBnaXZlbiBpbnN0cnVjdGlvbiBtb3JlIGNoYWxsZW5naW5nIGZvbGxvd2luZyB0aGUgZ2l2ZW4gaW1wcm92aW5nIGFjdGlvbgppdGVtLCBhbmQgdGhlIGdlbmVyYXRlZCBpbnN0cnVjdGlvbiBzaG91bGQgYmUgcmVhc29uYWJsZSBhbmQgc2VsZi1jb25zaXN0ZW50LgpEbyBub3QgZGlyZWN0bHkgY29weSB3b3JkcyBvciBwaHJhc2VzIGluIHRoZSBhY3Rpb24uClxwYXJJbXByb3ZpbmcgYWN0aW9uOiA8YWN0aW9uPgpJbnB1dCBpbnN0cnVjdGlvbjogPGlucHV0IGluc3RydWN0aW9uPgpccGFySW1wcm92ZWQgaW5zdHJ1Y3Rpb246IDxvdXRwdXQgaW5zdHJ1Y3Rpb24+Cg==" download="">⬇</a></div>
<div id="lstnumberx47" class="ltx_listingline">
</div>
<div id="lstnumberx48" class="ltx_listingline">
<span id="lstnumberx48.1" class="ltx_text ltx_lst_identifier">I</span><span id="lstnumberx48.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.3" class="ltx_text ltx_lst_identifier">want</span><span id="lstnumberx48.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.5" class="ltx_text ltx_lst_identifier">you</span><span id="lstnumberx48.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx48.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.9" class="ltx_text ltx_lst_identifier">act</span><span id="lstnumberx48.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.11" class="ltx_text ltx_lst_identifier">as</span><span id="lstnumberx48.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx48.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx48.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.17" class="ltx_text ltx_lst_identifier">improver</span><span id="lstnumberx48.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.19" class="ltx_text ltx_lst_identifier">with</span><span id="lstnumberx48.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.21" class="ltx_text ltx_lst_identifier">domain</span><span id="lstnumberx48.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx48.23" class="ltx_text ltx_lst_identifier">expertise</span>.
</div>
<div id="lstnumberx49" class="ltx_listingline">
<span id="lstnumberx49.1" class="ltx_text ltx_lst_identifier">Your</span><span id="lstnumberx49.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.3" class="ltx_text ltx_lst_identifier">job</span><span id="lstnumberx49.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.5" class="ltx_text ltx_lst_identifier">is</span><span id="lstnumberx49.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx49.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.9" class="ltx_text ltx_lst_identifier">make</span><span id="lstnumberx49.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.11" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx49.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.13" class="ltx_text ltx_lst_identifier">given</span><span id="lstnumberx49.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.15" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx49.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.17" class="ltx_text ltx_lst_identifier">more</span><span id="lstnumberx49.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.19" class="ltx_text ltx_lst_identifier">challenging</span><span id="lstnumberx49.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.21" class="ltx_text ltx_lst_identifier">following</span><span id="lstnumberx49.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx49.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.25" class="ltx_text ltx_lst_identifier">given</span><span id="lstnumberx49.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.27" class="ltx_text ltx_lst_identifier">improving</span><span id="lstnumberx49.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx49.29" class="ltx_text ltx_lst_identifier">action</span>
</div>
<div id="lstnumberx50" class="ltx_listingline">
<span id="lstnumberx50.1" class="ltx_text ltx_lst_identifier">item</span>,<span id="lstnumberx50.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.3" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx50.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.5" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx50.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.7" class="ltx_text ltx_lst_identifier">generated</span><span id="lstnumberx50.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.9" class="ltx_text ltx_lst_identifier">instruction</span><span id="lstnumberx50.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.11" class="ltx_text ltx_lst_identifier">should</span><span id="lstnumberx50.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.13" class="ltx_text ltx_lst_identifier">be</span><span id="lstnumberx50.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.15" class="ltx_text ltx_lst_identifier">reasonable</span><span id="lstnumberx50.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.17" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx50.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx50.19" class="ltx_text ltx_lst_identifier">self</span>-<span id="lstnumberx50.20" class="ltx_text ltx_lst_identifier">consistent</span>.
</div>
<div id="lstnumberx51" class="ltx_listingline">
<span id="lstnumberx51.1" class="ltx_text ltx_lst_identifier">Do</span><span id="lstnumberx51.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.3" class="ltx_text ltx_lst_identifier">not</span><span id="lstnumberx51.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.5" class="ltx_text ltx_lst_identifier">directly</span><span id="lstnumberx51.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.7" class="ltx_text ltx_lst_identifier">copy</span><span id="lstnumberx51.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.9" class="ltx_text ltx_lst_identifier">words</span><span id="lstnumberx51.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.11" class="ltx_text ltx_lst_identifier">or</span><span id="lstnumberx51.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.13" class="ltx_text ltx_lst_identifier">phrases</span><span id="lstnumberx51.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.15" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx51.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.17" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx51.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx51.19" class="ltx_text ltx_lst_identifier">action</span>.
</div>
<div id="lstnumberx52" class="ltx_listingline">\<span id="lstnumberx52.1" class="ltx_text ltx_lst_identifier">parImproving</span><span id="lstnumberx52.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx52.3" class="ltx_text ltx_lst_identifier">action</span>:<span id="lstnumberx52.4" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx52.5" class="ltx_text ltx_lst_identifier">action</span>&gt;
</div>
<div id="lstnumberx53" class="ltx_listingline">
<span id="lstnumberx53.1" class="ltx_text ltx_lst_identifier">Input</span><span id="lstnumberx53.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx53.3" class="ltx_text ltx_lst_identifier">instruction</span>:<span id="lstnumberx53.4" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx53.5" class="ltx_text ltx_lst_identifier">input</span><span id="lstnumberx53.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx53.7" class="ltx_text ltx_lst_identifier">instruction</span>&gt;
</div>
<div id="lstnumberx54" class="ltx_listingline">\<span id="lstnumberx54.1" class="ltx_text ltx_lst_identifier">parImproved</span><span id="lstnumberx54.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx54.3" class="ltx_text ltx_lst_identifier">instruction</span>:<span id="lstnumberx54.4" class="ltx_text ltx_lst_space"> </span>&lt;<span id="lstnumberx54.5" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx54.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx54.7" class="ltx_text ltx_lst_identifier">instruction</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">그림 10:</span>Prompt template to improve instructions following generated actions.</figcaption>
</figure>
<figure id="A1.F11" class="ltx_figure">
<div id="A1.F11.3" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,CllvdSBhcmUgYSBoZWxwZnVsIGFuZCBwcmVjaXNlIGFzc2lzdGFudCBmb3IgY2hlY2tpbmcgdGhlIHF1YWxpdHkgb2YgdGhlIGFuc3dlci4KXHBhcjxRdWVzdGlvbj4KW1RoZSBTdGFydCBvZiBBc3Npc3RhbnQgMSdzIEFuc3dlcl0KPGFuc3dlcl8xPgpbVGhlIEVuZCBvZiBBc3Npc3RhbnQgMSdzIEFuc3dlcl0KW1RoZSBTdGFydCBvZiBBc3Npc3RhbnQgMidzIEFuc3dlcl0KPGFuc3dlcl8yPgpbVGhlIEVuZCBvZiBBc3Npc3RhbnQgMidzIEFuc3dlcl0KXHBhcldlIHdvdWxkIGxpa2UgdG8gcmVxdWVzdCB5b3VyIGZlZWRiYWNrIG9uIHRoZSBwZXJmb3JtYW5jZSBvZiB0d28gQUkgYXNzaXN0YW50cyBpbiByZXNwb25zZSB0bwp0aGUgdXNlciBxdWVzdGlvbiBkaXNwbGF5ZWQgYWJvdmUuClBsZWFzZSByYXRlIHRoZSBoZWxwZnVsbmVzcywgcmVsZXZhbmNlLCBhY2N1cmFjeSwgbGV2ZWwgb2YgZGV0YWlscyBvZiB0aGVpciByZXNwb25zZXMuIEVhY2gKYXNzaXN0YW50IHJlY2VpdmVzIGFuIG92ZXJhbGwgc2NvcmUgb24gYSBzY2FsZSBvZiAxIHRvIDEwLCB3aGVyZSBhIGhpZ2hlciBzY29yZSBpbmRpY2F0ZXMKYmV0dGVyIG92ZXJhbGwgcGVyZm9ybWFuY2UuClBsZWFzZSBvbmx5IG91dHB1dCBhIHNpbmdsZSBsaW5lIGNvbnRhaW5pbmcgb25seSB0d28gdmFsdWVzIGluZGljYXRpbmcgdGhlIHNjb3JlcyBmb3IgQXNzaXN0YW50IDEKYW5kIDIsIHJlc3BlY3RpdmVseS4gVGhlIHR3byBzY29yZXMgYXJlIHNlcGFyYXRlZCBieSBhIHNwYWNlLgpQbGVhc2UgYXZvaWRpbmcgYW55IHBvdGVudGlhbCBiaWFzIGFuZCBlbnN1cmluZyB0aGF0IHRoZSBvcmRlciBpbiB3aGljaCB0aGUgcmVzcG9uc2VzIHdlcmUKcHJlc2VudGVkIGRvZXMgbm90IGFmZmVjdCB5b3VyIGp1ZGdtZW50Lgo=" download="">⬇</a></div>
<div id="lstnumberx55" class="ltx_listingline">
</div>
<div id="lstnumberx56" class="ltx_listingline">
<span id="lstnumberx56.1" class="ltx_text ltx_lst_identifier">You</span><span id="lstnumberx56.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.3" class="ltx_text ltx_lst_identifier">are</span><span id="lstnumberx56.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.5" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx56.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.7" class="ltx_text ltx_lst_identifier">helpful</span><span id="lstnumberx56.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.9" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx56.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.11" class="ltx_text ltx_lst_identifier">precise</span><span id="lstnumberx56.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.13" class="ltx_text ltx_lst_identifier">assistant</span><span id="lstnumberx56.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.15" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx56.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.17" class="ltx_text ltx_lst_identifier">checking</span><span id="lstnumberx56.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx56.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.21" class="ltx_text ltx_lst_identifier">quality</span><span id="lstnumberx56.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.23" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx56.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.25" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx56.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx56.27" class="ltx_text ltx_lst_identifier">answer</span>.
</div>
<div id="lstnumberx57" class="ltx_listingline">\<span id="lstnumberx57.1" class="ltx_text ltx_lst_identifier">par</span>&lt;<span id="lstnumberx57.2" class="ltx_text ltx_lst_identifier">Question</span>&gt;
</div>
<div id="lstnumberx58" class="ltx_listingline">[<span id="lstnumberx58.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx58.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx58.3" class="ltx_text ltx_lst_identifier">Start</span><span id="lstnumberx58.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx58.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx58.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx58.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx58.8" class="ltx_text ltx_lst_space"> </span>1’<span id="lstnumberx58.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx58.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx58.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx59" class="ltx_listingline">&lt;<span id="lstnumberx59.1" class="ltx_text ltx_lst_identifier">answer_1</span>&gt;
</div>
<div id="lstnumberx60" class="ltx_listingline">[<span id="lstnumberx60.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx60.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx60.3" class="ltx_text ltx_lst_identifier">End</span><span id="lstnumberx60.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx60.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx60.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx60.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx60.8" class="ltx_text ltx_lst_space"> </span>1’<span id="lstnumberx60.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx60.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx60.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx61" class="ltx_listingline">[<span id="lstnumberx61.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx61.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx61.3" class="ltx_text ltx_lst_identifier">Start</span><span id="lstnumberx61.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx61.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx61.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx61.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx61.8" class="ltx_text ltx_lst_space"> </span>2’<span id="lstnumberx61.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx61.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx61.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx62" class="ltx_listingline">&lt;<span id="lstnumberx62.1" class="ltx_text ltx_lst_identifier">answer_2</span>&gt;
</div>
<div id="lstnumberx63" class="ltx_listingline">[<span id="lstnumberx63.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx63.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx63.3" class="ltx_text ltx_lst_identifier">End</span><span id="lstnumberx63.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx63.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx63.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx63.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx63.8" class="ltx_text ltx_lst_space"> </span>2’<span id="lstnumberx63.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx63.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx63.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx64" class="ltx_listingline">\<span id="lstnumberx64.1" class="ltx_text ltx_lst_identifier">parWe</span><span id="lstnumberx64.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.3" class="ltx_text ltx_lst_identifier">would</span><span id="lstnumberx64.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.5" class="ltx_text ltx_lst_identifier">like</span><span id="lstnumberx64.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx64.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.9" class="ltx_text ltx_lst_identifier">request</span><span id="lstnumberx64.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.11" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx64.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.13" class="ltx_text ltx_lst_identifier">feedback</span><span id="lstnumberx64.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.15" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx64.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.17" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx64.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.19" class="ltx_text ltx_lst_identifier">performance</span><span id="lstnumberx64.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.21" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx64.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.23" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx64.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.25" class="ltx_text ltx_lst_identifier">AI</span><span id="lstnumberx64.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.27" class="ltx_text ltx_lst_identifier">assistants</span><span id="lstnumberx64.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.29" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx64.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.31" class="ltx_text ltx_lst_identifier">response</span><span id="lstnumberx64.32" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx64.33" class="ltx_text ltx_lst_identifier">to</span>
</div>
<div id="lstnumberx65" class="ltx_listingline">
<span id="lstnumberx65.1" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx65.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx65.3" class="ltx_text ltx_lst_identifier">user</span><span id="lstnumberx65.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx65.5" class="ltx_text ltx_lst_identifier">question</span><span id="lstnumberx65.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx65.7" class="ltx_text ltx_lst_identifier">displayed</span><span id="lstnumberx65.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx65.9" class="ltx_text ltx_lst_identifier">above</span>.
</div>
<div id="lstnumberx66" class="ltx_listingline">
<span id="lstnumberx66.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx66.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.3" class="ltx_text ltx_lst_identifier">rate</span><span id="lstnumberx66.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.5" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx66.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.7" class="ltx_text ltx_lst_identifier">helpfulness</span>,<span id="lstnumberx66.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.9" class="ltx_text ltx_lst_identifier">relevance</span>,<span id="lstnumberx66.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.11" class="ltx_text ltx_lst_identifier">accuracy</span>,<span id="lstnumberx66.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.13" class="ltx_text ltx_lst_identifier">level</span><span id="lstnumberx66.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.15" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx66.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.17" class="ltx_text ltx_lst_identifier">details</span><span id="lstnumberx66.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.19" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx66.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.21" class="ltx_text ltx_lst_identifier">their</span><span id="lstnumberx66.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.23" class="ltx_text ltx_lst_identifier">responses</span>.<span id="lstnumberx66.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx66.25" class="ltx_text ltx_lst_identifier">Each</span>
</div>
<div id="lstnumberx67" class="ltx_listingline">
<span id="lstnumberx67.1" class="ltx_text ltx_lst_identifier">assistant</span><span id="lstnumberx67.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.3" class="ltx_text ltx_lst_identifier">receives</span><span id="lstnumberx67.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.5" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx67.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.7" class="ltx_text ltx_lst_identifier">overall</span><span id="lstnumberx67.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.9" class="ltx_text ltx_lst_identifier">score</span><span id="lstnumberx67.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.11" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx67.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx67.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.15" class="ltx_text ltx_lst_identifier">scale</span><span id="lstnumberx67.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.17" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx67.18" class="ltx_text ltx_lst_space"> </span>1<span id="lstnumberx67.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.20" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx67.21" class="ltx_text ltx_lst_space"> </span>10,<span id="lstnumberx67.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.23" class="ltx_text ltx_lst_identifier">where</span><span id="lstnumberx67.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.25" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx67.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.27" class="ltx_text ltx_lst_identifier">higher</span><span id="lstnumberx67.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.29" class="ltx_text ltx_lst_identifier">score</span><span id="lstnumberx67.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx67.31" class="ltx_text ltx_lst_identifier">indicates</span>
</div>
<div id="lstnumberx68" class="ltx_listingline">
<span id="lstnumberx68.1" class="ltx_text ltx_lst_identifier">better</span><span id="lstnumberx68.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx68.3" class="ltx_text ltx_lst_identifier">overall</span><span id="lstnumberx68.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx68.5" class="ltx_text ltx_lst_identifier">performance</span>.
</div>
<div id="lstnumberx69" class="ltx_listingline">
<span id="lstnumberx69.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx69.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.3" class="ltx_text ltx_lst_identifier">only</span><span id="lstnumberx69.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.5" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx69.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.7" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx69.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.9" class="ltx_text ltx_lst_identifier">single</span><span id="lstnumberx69.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.11" class="ltx_text ltx_lst_identifier">line</span><span id="lstnumberx69.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.13" class="ltx_text ltx_lst_identifier">containing</span><span id="lstnumberx69.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.15" class="ltx_text ltx_lst_identifier">only</span><span id="lstnumberx69.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.17" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx69.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.19" class="ltx_text ltx_lst_identifier">values</span><span id="lstnumberx69.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.21" class="ltx_text ltx_lst_identifier">indicating</span><span id="lstnumberx69.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx69.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.25" class="ltx_text ltx_lst_identifier">scores</span><span id="lstnumberx69.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.27" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx69.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx69.29" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx69.30" class="ltx_text ltx_lst_space"> </span>1
</div>
<div id="lstnumberx70" class="ltx_listingline">
<span id="lstnumberx70.1" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx70.2" class="ltx_text ltx_lst_space"> </span>2,<span id="lstnumberx70.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.4" class="ltx_text ltx_lst_identifier">respectively</span>.<span id="lstnumberx70.5" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.6" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx70.7" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.8" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx70.9" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.10" class="ltx_text ltx_lst_identifier">scores</span><span id="lstnumberx70.11" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.12" class="ltx_text ltx_lst_identifier">are</span><span id="lstnumberx70.13" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.14" class="ltx_text ltx_lst_identifier">separated</span><span id="lstnumberx70.15" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.16" class="ltx_text ltx_lst_identifier">by</span><span id="lstnumberx70.17" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.18" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx70.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx70.20" class="ltx_text ltx_lst_identifier">space</span>.
</div>
<div id="lstnumberx71" class="ltx_listingline">
<span id="lstnumberx71.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx71.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.3" class="ltx_text ltx_lst_identifier">avoiding</span><span id="lstnumberx71.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.5" class="ltx_text ltx_lst_identifier">any</span><span id="lstnumberx71.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.7" class="ltx_text ltx_lst_identifier">potential</span><span id="lstnumberx71.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.9" class="ltx_text ltx_lst_identifier">bias</span><span id="lstnumberx71.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.11" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx71.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.13" class="ltx_text ltx_lst_identifier">ensuring</span><span id="lstnumberx71.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.15" class="ltx_text ltx_lst_identifier">that</span><span id="lstnumberx71.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.17" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx71.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.19" class="ltx_text ltx_lst_identifier">order</span><span id="lstnumberx71.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.21" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx71.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.23" class="ltx_text ltx_lst_identifier">which</span><span id="lstnumberx71.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.25" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx71.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.27" class="ltx_text ltx_lst_identifier">responses</span><span id="lstnumberx71.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx71.29" class="ltx_text ltx_lst_identifier">were</span>
</div>
<div id="lstnumberx72" class="ltx_listingline">
<span id="lstnumberx72.1" class="ltx_text ltx_lst_identifier">presented</span><span id="lstnumberx72.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.3" class="ltx_text ltx_lst_identifier">does</span><span id="lstnumberx72.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.5" class="ltx_text ltx_lst_identifier">not</span><span id="lstnumberx72.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.7" class="ltx_text ltx_lst_identifier">affect</span><span id="lstnumberx72.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.9" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx72.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx72.11" class="ltx_text ltx_lst_identifier">judgment</span>.
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 11:</span>Prompt template used in Contrastive Filtering to compare the responses of the strong and the target LLMs. 이 템플릿을 스코어러 <math alttext="S" class="ltx_Math" display="inline" id="A1.F11.2.m1.1"><semantics id="A1.F11.2.m1.1b"><mi id="A1.F11.2.m1.1.1" xref="A1.F11.2.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="A1.F11.2.m1.1c"><ci id="A1.F11.2.m1.1.1.cmml" xref="A1.F11.2.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F11.2.m1.1d">S</annotation></semantics></math>로 사용하여 강력한 LLM을 직접 사용하여 타사 LLM을 호출하는 추가 비용을 방지합니다.</figcaption>
</figure>
<figure id="A1.F12" class="ltx_figure">
<div id="A1.F12.1" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ClN5c3RlbTogWW91IGFyZSBhIGhlbHBmdWwgYW5kIHByZWNpc2UgYXNzaXN0YW50IGZvciBjaGVja2luZyB0aGUgcXVhbGl0eSBvZiB0aGUgYW5zd2VyLgpccGFyVXNlcjoKPFF1ZXN0aW9uPgpbVGhlIFN0YXJ0IG9mIEFzc2lzdGFudCAxJ3MgQW5zd2VyXQo8YW5zd2VyXzE+CltUaGUgRW5kIG9mIEFzc2lzdGFudCAxJ3MgQW5zd2VyXQpbVGhlIFN0YXJ0IG9mIEFzc2lzdGFudCAyJ3MgQW5zd2VyXQo8YW5zd2VyXzI+CltUaGUgRW5kIG9mIEFzc2lzdGFudCAyJ3MgQW5zd2VyXQpccGFyV2Ugd291bGQgbGlrZSB0byByZXF1ZXN0IHlvdXIgZmVlZGJhY2sgb24gdGhlIHBlcmZvcm1hbmNlIG9mIHR3byBBSSBhc3Npc3RhbnRzIGluIHJlc3BvbnNlIHRvCnRoZSB1c2VyIHF1ZXN0aW9uIGRpc3BsYXllZCBhYm92ZS4KUGxlYXNlIHJhdGUgdGhlIGhlbHBmdWxuZXNzLCByZWxldmFuY2UsIGFjY3VyYWN5LCBsZXZlbCBvZiBkZXRhaWxzIG9mIHRoZWlyIHJlc3BvbnNlcy4gRWFjaAphc3Npc3RhbnQgcmVjZWl2ZXMgYW4gb3ZlcmFsbCBzY29yZSBvbiBhIHNjYWxlIG9mIDEgdG8gMTAsIHdoZXJlIGEgaGlnaGVyIHNjb3JlIGluZGljYXRlcwpiZXR0ZXIgb3ZlcmFsbCBwZXJmb3JtYW5jZS4KUGxlYXNlIGZpcnN0IG91dHB1dCBhIHNpbmdsZSBsaW5lIGNvbnRhaW5pbmcgb25seSB0d28gdmFsdWVzIGluZGljYXRpbmcgdGhlIHNjb3JlcyBmb3IgQXNzaXN0YW50IDEKYW5kIDIsIHJlc3BlY3RpdmVseS4KVGhlIHR3byBzY29yZXMgYXJlIHNlcGFyYXRlZCBieSBhIHNwYWNlLiBJbiB0aGUgc3Vic2VxdWVudCBsaW5lLCBwbGVhc2UgcHJvdmlkZSBhIGNvbXByZWhlbnNpdmUKZXhwbGFuYXRpb24gb2YgeW91ciBldmFsdWF0aW9uLCBhdm9pZGluZyBhbnkgcG90ZW50aWFsIGJpYXMgYW5kIGVuc3VyaW5nIHRoYXQgdGhlIG9yZGVyIGluIHdoaWNoCnRoZSByZXNwb25zZXMgd2VyZSBwcmVzZW50ZWQgZG9lcyBub3QgYWZmZWN0IHlvdXIganVkZ21lbnQuCg==" download="">⬇</a></div>
<div id="lstnumberx73" class="ltx_listingline">
</div>
<div id="lstnumberx74" class="ltx_listingline">
<span id="lstnumberx74.1" class="ltx_text ltx_lst_identifier">System</span>:<span id="lstnumberx74.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.3" class="ltx_text ltx_lst_identifier">You</span><span id="lstnumberx74.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.5" class="ltx_text ltx_lst_identifier">are</span><span id="lstnumberx74.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.7" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx74.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.9" class="ltx_text ltx_lst_identifier">helpful</span><span id="lstnumberx74.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.11" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx74.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.13" class="ltx_text ltx_lst_identifier">precise</span><span id="lstnumberx74.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.15" class="ltx_text ltx_lst_identifier">assistant</span><span id="lstnumberx74.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.17" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx74.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.19" class="ltx_text ltx_lst_identifier">checking</span><span id="lstnumberx74.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.21" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx74.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.23" class="ltx_text ltx_lst_identifier">quality</span><span id="lstnumberx74.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.25" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx74.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.27" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx74.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx74.29" class="ltx_text ltx_lst_identifier">answer</span>.
</div>
<div id="lstnumberx75" class="ltx_listingline">\<span id="lstnumberx75.1" class="ltx_text ltx_lst_identifier">parUser</span>:
</div>
<div id="lstnumberx76" class="ltx_listingline">&lt;<span id="lstnumberx76.1" class="ltx_text ltx_lst_identifier">Question</span>&gt;
</div>
<div id="lstnumberx77" class="ltx_listingline">[<span id="lstnumberx77.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx77.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx77.3" class="ltx_text ltx_lst_identifier">Start</span><span id="lstnumberx77.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx77.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx77.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx77.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx77.8" class="ltx_text ltx_lst_space"> </span>1’<span id="lstnumberx77.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx77.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx77.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx78" class="ltx_listingline">&lt;<span id="lstnumberx78.1" class="ltx_text ltx_lst_identifier">answer_1</span>&gt;
</div>
<div id="lstnumberx79" class="ltx_listingline">[<span id="lstnumberx79.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx79.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx79.3" class="ltx_text ltx_lst_identifier">End</span><span id="lstnumberx79.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx79.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx79.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx79.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx79.8" class="ltx_text ltx_lst_space"> </span>1’<span id="lstnumberx79.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx79.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx79.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx80" class="ltx_listingline">[<span id="lstnumberx80.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx80.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx80.3" class="ltx_text ltx_lst_identifier">Start</span><span id="lstnumberx80.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx80.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx80.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx80.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx80.8" class="ltx_text ltx_lst_space"> </span>2’<span id="lstnumberx80.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx80.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx80.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx81" class="ltx_listingline">&lt;<span id="lstnumberx81.1" class="ltx_text ltx_lst_identifier">answer_2</span>&gt;
</div>
<div id="lstnumberx82" class="ltx_listingline">[<span id="lstnumberx82.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx82.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx82.3" class="ltx_text ltx_lst_identifier">End</span><span id="lstnumberx82.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx82.5" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx82.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx82.7" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx82.8" class="ltx_text ltx_lst_space"> </span>2’<span id="lstnumberx82.9" class="ltx_text ltx_lst_identifier">s</span><span id="lstnumberx82.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx82.11" class="ltx_text ltx_lst_identifier">Answer</span>]
</div>
<div id="lstnumberx83" class="ltx_listingline">\<span id="lstnumberx83.1" class="ltx_text ltx_lst_identifier">parWe</span><span id="lstnumberx83.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.3" class="ltx_text ltx_lst_identifier">would</span><span id="lstnumberx83.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.5" class="ltx_text ltx_lst_identifier">like</span><span id="lstnumberx83.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.7" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx83.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.9" class="ltx_text ltx_lst_identifier">request</span><span id="lstnumberx83.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.11" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx83.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.13" class="ltx_text ltx_lst_identifier">feedback</span><span id="lstnumberx83.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.15" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx83.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.17" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx83.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.19" class="ltx_text ltx_lst_identifier">performance</span><span id="lstnumberx83.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.21" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx83.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.23" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx83.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.25" class="ltx_text ltx_lst_identifier">AI</span><span id="lstnumberx83.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.27" class="ltx_text ltx_lst_identifier">assistants</span><span id="lstnumberx83.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.29" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx83.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.31" class="ltx_text ltx_lst_identifier">response</span><span id="lstnumberx83.32" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx83.33" class="ltx_text ltx_lst_identifier">to</span>
</div>
<div id="lstnumberx84" class="ltx_listingline">
<span id="lstnumberx84.1" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx84.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx84.3" class="ltx_text ltx_lst_identifier">user</span><span id="lstnumberx84.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx84.5" class="ltx_text ltx_lst_identifier">question</span><span id="lstnumberx84.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx84.7" class="ltx_text ltx_lst_identifier">displayed</span><span id="lstnumberx84.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx84.9" class="ltx_text ltx_lst_identifier">above</span>.
</div>
<div id="lstnumberx85" class="ltx_listingline">
<span id="lstnumberx85.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx85.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.3" class="ltx_text ltx_lst_identifier">rate</span><span id="lstnumberx85.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.5" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx85.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.7" class="ltx_text ltx_lst_identifier">helpfulness</span>,<span id="lstnumberx85.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.9" class="ltx_text ltx_lst_identifier">relevance</span>,<span id="lstnumberx85.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.11" class="ltx_text ltx_lst_identifier">accuracy</span>,<span id="lstnumberx85.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.13" class="ltx_text ltx_lst_identifier">level</span><span id="lstnumberx85.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.15" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx85.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.17" class="ltx_text ltx_lst_identifier">details</span><span id="lstnumberx85.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.19" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx85.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.21" class="ltx_text ltx_lst_identifier">their</span><span id="lstnumberx85.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.23" class="ltx_text ltx_lst_identifier">responses</span>.<span id="lstnumberx85.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx85.25" class="ltx_text ltx_lst_identifier">Each</span>
</div>
<div id="lstnumberx86" class="ltx_listingline">
<span id="lstnumberx86.1" class="ltx_text ltx_lst_identifier">assistant</span><span id="lstnumberx86.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.3" class="ltx_text ltx_lst_identifier">receives</span><span id="lstnumberx86.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.5" class="ltx_text ltx_lst_identifier">an</span><span id="lstnumberx86.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.7" class="ltx_text ltx_lst_identifier">overall</span><span id="lstnumberx86.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.9" class="ltx_text ltx_lst_identifier">score</span><span id="lstnumberx86.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.11" class="ltx_text ltx_lst_identifier">on</span><span id="lstnumberx86.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx86.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.15" class="ltx_text ltx_lst_identifier">scale</span><span id="lstnumberx86.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.17" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx86.18" class="ltx_text ltx_lst_space"> </span>1<span id="lstnumberx86.19" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.20" class="ltx_text ltx_lst_identifier">to</span><span id="lstnumberx86.21" class="ltx_text ltx_lst_space"> </span>10,<span id="lstnumberx86.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.23" class="ltx_text ltx_lst_identifier">where</span><span id="lstnumberx86.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.25" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx86.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.27" class="ltx_text ltx_lst_identifier">higher</span><span id="lstnumberx86.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.29" class="ltx_text ltx_lst_identifier">score</span><span id="lstnumberx86.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx86.31" class="ltx_text ltx_lst_identifier">indicates</span>
</div>
<div id="lstnumberx87" class="ltx_listingline">
<span id="lstnumberx87.1" class="ltx_text ltx_lst_identifier">better</span><span id="lstnumberx87.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx87.3" class="ltx_text ltx_lst_identifier">overall</span><span id="lstnumberx87.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx87.5" class="ltx_text ltx_lst_identifier">performance</span>.
</div>
<div id="lstnumberx88" class="ltx_listingline">
<span id="lstnumberx88.1" class="ltx_text ltx_lst_identifier">Please</span><span id="lstnumberx88.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.3" class="ltx_text ltx_lst_identifier">first</span><span id="lstnumberx88.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.5" class="ltx_text ltx_lst_identifier">output</span><span id="lstnumberx88.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.7" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx88.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.9" class="ltx_text ltx_lst_identifier">single</span><span id="lstnumberx88.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.11" class="ltx_text ltx_lst_identifier">line</span><span id="lstnumberx88.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.13" class="ltx_text ltx_lst_identifier">containing</span><span id="lstnumberx88.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.15" class="ltx_text ltx_lst_identifier">only</span><span id="lstnumberx88.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.17" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx88.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.19" class="ltx_text ltx_lst_identifier">values</span><span id="lstnumberx88.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.21" class="ltx_text ltx_lst_identifier">indicating</span><span id="lstnumberx88.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx88.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.25" class="ltx_text ltx_lst_identifier">scores</span><span id="lstnumberx88.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.27" class="ltx_text ltx_lst_identifier">for</span><span id="lstnumberx88.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx88.29" class="ltx_text ltx_lst_identifier">Assistant</span><span id="lstnumberx88.30" class="ltx_text ltx_lst_space"> </span>1
</div>
<div id="lstnumberx89" class="ltx_listingline">
<span id="lstnumberx89.1" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx89.2" class="ltx_text ltx_lst_space"> </span>2,<span id="lstnumberx89.3" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx89.4" class="ltx_text ltx_lst_identifier">respectively</span>.
</div>
<div id="lstnumberx90" class="ltx_listingline">
<span id="lstnumberx90.1" class="ltx_text ltx_lst_identifier">The</span><span id="lstnumberx90.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.3" class="ltx_text ltx_lst_identifier">two</span><span id="lstnumberx90.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.5" class="ltx_text ltx_lst_identifier">scores</span><span id="lstnumberx90.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.7" class="ltx_text ltx_lst_identifier">are</span><span id="lstnumberx90.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.9" class="ltx_text ltx_lst_identifier">separated</span><span id="lstnumberx90.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.11" class="ltx_text ltx_lst_identifier">by</span><span id="lstnumberx90.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.13" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx90.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.15" class="ltx_text ltx_lst_identifier">space</span>.<span id="lstnumberx90.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.17" class="ltx_text ltx_lst_identifier">In</span><span id="lstnumberx90.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.19" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx90.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.21" class="ltx_text ltx_lst_identifier">subsequent</span><span id="lstnumberx90.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.23" class="ltx_text ltx_lst_identifier">line</span>,<span id="lstnumberx90.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.25" class="ltx_text ltx_lst_identifier">please</span><span id="lstnumberx90.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.27" class="ltx_text ltx_lst_identifier">provide</span><span id="lstnumberx90.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.29" class="ltx_text ltx_lst_identifier">a</span><span id="lstnumberx90.30" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx90.31" class="ltx_text ltx_lst_identifier">comprehensive</span>
</div>
<div id="lstnumberx91" class="ltx_listingline">
<span id="lstnumberx91.1" class="ltx_text ltx_lst_identifier">explanation</span><span id="lstnumberx91.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.3" class="ltx_text ltx_lst_identifier">of</span><span id="lstnumberx91.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.5" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx91.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.7" class="ltx_text ltx_lst_identifier">evaluation</span>,<span id="lstnumberx91.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.9" class="ltx_text ltx_lst_identifier">avoiding</span><span id="lstnumberx91.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.11" class="ltx_text ltx_lst_identifier">any</span><span id="lstnumberx91.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.13" class="ltx_text ltx_lst_identifier">potential</span><span id="lstnumberx91.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.15" class="ltx_text ltx_lst_identifier">bias</span><span id="lstnumberx91.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.17" class="ltx_text ltx_lst_identifier">and</span><span id="lstnumberx91.18" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.19" class="ltx_text ltx_lst_identifier">ensuring</span><span id="lstnumberx91.20" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.21" class="ltx_text ltx_lst_identifier">that</span><span id="lstnumberx91.22" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.23" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx91.24" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.25" class="ltx_text ltx_lst_identifier">order</span><span id="lstnumberx91.26" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.27" class="ltx_text ltx_lst_identifier">in</span><span id="lstnumberx91.28" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx91.29" class="ltx_text ltx_lst_identifier">which</span>
</div>
<div id="lstnumberx92" class="ltx_listingline">
<span id="lstnumberx92.1" class="ltx_text ltx_lst_identifier">the</span><span id="lstnumberx92.2" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.3" class="ltx_text ltx_lst_identifier">responses</span><span id="lstnumberx92.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.5" class="ltx_text ltx_lst_identifier">were</span><span id="lstnumberx92.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.7" class="ltx_text ltx_lst_identifier">presented</span><span id="lstnumberx92.8" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.9" class="ltx_text ltx_lst_identifier">does</span><span id="lstnumberx92.10" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.11" class="ltx_text ltx_lst_identifier">not</span><span id="lstnumberx92.12" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.13" class="ltx_text ltx_lst_identifier">affect</span><span id="lstnumberx92.14" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.15" class="ltx_text ltx_lst_identifier">your</span><span id="lstnumberx92.16" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx92.17" class="ltx_text ltx_lst_identifier">judgment</span>.
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">그림 12:</span>Prompt template for automatic evaluation using LLM (<span class="ltx_text ltx_font_italic" id="A1.F12.3.1">e.g.</span>, ChatGPT, GPT-4) as the judge.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2404.05874" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2404.05875" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2404.05875">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.05875" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2404.05876" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 16:42:54 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>