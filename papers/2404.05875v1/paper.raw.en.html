<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>CodecLM: Aligning Language Models with Tailored Synthetic Data</title>
<!--Generated on Mon Apr  8 21:14:10 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2404.05875v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2404.05875v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2404.05875v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2404.05875v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S1" title="1 Introduction ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S2" title="2 Related Work ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S3" title="3 Problem Statement ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Problem Statement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S4" title="4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>CodecLM</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S4.SS1" title="4.1 LLM as Codec for Instructions ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>LLM as Codec for Instructions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S4.SS2" title="4.2 Instruction Tailoring via Self-Rubrics ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Instruction Tailoring via Self-Rubrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S4.SS3" title="4.3 Instruction Selection via Contrastive Filtering ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Instruction Selection via Contrastive Filtering</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5" title="5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.SS1" title="5.1 Evaluation Benchmarks ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Evaluation Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.SS2" title="5.2 Baseline Methods ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Baseline Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.SS3" title="5.3 Experiment and Evaluation Details ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Experiment and Evaluation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.SS4" title="5.4 Open-Domain Instruction Following ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Open-Domain Instruction Following</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.SS5" title="5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Ablation Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S6" title="6 Conclusion ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1" title="Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS1" title="A.1 Benchmark Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Benchmark Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS2" title="A.2 Baseline Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Baseline Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS3" title="A.3 Additional Implementation Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Additional Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS4" title="A.4 Training Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Training Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS5" title="A.5 Detailed Comparison Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.5 </span>Detailed Comparison Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS6" title="A.6 Consistency between LLM-based Evaluators ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.6 </span>Consistency between LLM-based Evaluators</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS7" title="A.7 Additional Benchmark Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.7 </span>Additional Benchmark Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS8" title="A.8 Case Study ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.8 </span>Case Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.9 </span>Prompt Templates for CodecLM</span></a></li>
</ol>
</li>
</ol></nav>

<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewBox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: inconsolata</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><div class="section" id="target-section"><div id="license-tr">License: arXiv.org perpetual non-exclusive license</div><div id="watermark-tr">arXiv:2404.05875v1 [cs.CL] 08 Apr 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">CodecLM: Aligning Language Models with Tailored Synthetic Data</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zifeng Wang<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><msup id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1a" xref="id1.1.m1.1.1.cmml"></mi><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><ci id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1">†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>, Chun-Liang Li<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><msup id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mi id="id2.2.m2.1.1a" xref="id2.2.m2.1.1.cmml"></mi><mo id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><ci id="id2.2.m2.1.1.1.cmml" xref="id2.2.m2.1.1.1">†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>, Vincent Perot<math alttext="{}^{*}" class="ltx_Math" display="inline" id="id3.3.m3.1"><semantics id="id3.3.m3.1a"><msup id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml"><mi id="id3.3.m3.1.1a" xref="id3.3.m3.1.1.cmml"></mi><mo id="id3.3.m3.1.1.1" xref="id3.3.m3.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><apply id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"><times id="id3.3.m3.1.1.1.cmml" xref="id3.3.m3.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>, Long T. Le<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="id4.4.m4.1"><semantics id="id4.4.m4.1a"><msup id="id4.4.m4.1.1" xref="id4.4.m4.1.1.cmml"><mi id="id4.4.m4.1.1a" xref="id4.4.m4.1.1.cmml"></mi><mo id="id4.4.m4.1.1.1" xref="id4.4.m4.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="id4.4.m4.1b"><apply id="id4.4.m4.1.1.cmml" xref="id4.4.m4.1.1"><ci id="id4.4.m4.1.1.1.cmml" xref="id4.4.m4.1.1.1">†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.4.m4.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="id4.4.m4.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>, 
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="id11.11.7">Jin Miao<math alttext="{}^{\ddagger}" class="ltx_Math" display="inline" id="id5.5.1.m1.1"><semantics id="id5.5.1.m1.1a"><msup id="id5.5.1.m1.1.1" xref="id5.5.1.m1.1.1.cmml"><mi id="id5.5.1.m1.1.1a" xref="id5.5.1.m1.1.1.cmml"></mi><mo id="id5.5.1.m1.1.1.1" mathvariant="normal" xref="id5.5.1.m1.1.1.1.cmml">‡</mo></msup><annotation-xml encoding="MathML-Content" id="id5.5.1.m1.1b"><apply id="id5.5.1.m1.1.1.cmml" xref="id5.5.1.m1.1.1"><ci id="id5.5.1.m1.1.1.1.cmml" xref="id5.5.1.m1.1.1.1">normal-‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id5.5.1.m1.1c">{}^{\ddagger}</annotation><annotation encoding="application/x-llamapun" id="id5.5.1.m1.1d">start_FLOATSUPERSCRIPT ‡ end_FLOATSUPERSCRIPT</annotation></semantics></math>, Zizhao Zhang<math alttext="{}^{\ddagger}" class="ltx_Math" display="inline" id="id6.6.2.m2.1"><semantics id="id6.6.2.m2.1a"><msup id="id6.6.2.m2.1.1" xref="id6.6.2.m2.1.1.cmml"><mi id="id6.6.2.m2.1.1a" xref="id6.6.2.m2.1.1.cmml"></mi><mo id="id6.6.2.m2.1.1.1" mathvariant="normal" xref="id6.6.2.m2.1.1.1.cmml">‡</mo></msup><annotation-xml encoding="MathML-Content" id="id6.6.2.m2.1b"><apply id="id6.6.2.m2.1.1.cmml" xref="id6.6.2.m2.1.1"><ci id="id6.6.2.m2.1.1.1.cmml" xref="id6.6.2.m2.1.1.1">normal-‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.6.2.m2.1c">{}^{\ddagger}</annotation><annotation encoding="application/x-llamapun" id="id6.6.2.m2.1d">start_FLOATSUPERSCRIPT ‡ end_FLOATSUPERSCRIPT</annotation></semantics></math>, Chen-Yu Lee<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="id7.7.3.m3.1"><semantics id="id7.7.3.m3.1a"><msup id="id7.7.3.m3.1.1" xref="id7.7.3.m3.1.1.cmml"><mi id="id7.7.3.m3.1.1a" xref="id7.7.3.m3.1.1.cmml"></mi><mo id="id7.7.3.m3.1.1.1" mathvariant="normal" xref="id7.7.3.m3.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="id7.7.3.m3.1b"><apply id="id7.7.3.m3.1.1.cmml" xref="id7.7.3.m3.1.1"><ci id="id7.7.3.m3.1.1.1.cmml" xref="id7.7.3.m3.1.1.1">normal-†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id7.7.3.m3.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="id7.7.3.m3.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>, Tomas Pfister<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="id8.8.4.m4.1"><semantics id="id8.8.4.m4.1a"><msup id="id8.8.4.m4.1.1" xref="id8.8.4.m4.1.1.cmml"><mi id="id8.8.4.m4.1.1a" xref="id8.8.4.m4.1.1.cmml"></mi><mo id="id8.8.4.m4.1.1.1" mathvariant="normal" xref="id8.8.4.m4.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="id8.8.4.m4.1b"><apply id="id8.8.4.m4.1.1.cmml" xref="id8.8.4.m4.1.1"><ci id="id8.8.4.m4.1.1.1.cmml" xref="id8.8.4.m4.1.1.1">normal-†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id8.8.4.m4.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="id8.8.4.m4.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break"><math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="id9.9.5.m5.1"><semantics id="id9.9.5.m5.1a"><msup id="id9.9.5.m5.1.1" xref="id9.9.5.m5.1.1.cmml"><mi id="id9.9.5.m5.1.1a" xref="id9.9.5.m5.1.1.cmml"></mi><mo id="id9.9.5.m5.1.1.1" mathvariant="normal" xref="id9.9.5.m5.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="id9.9.5.m5.1b"><apply id="id9.9.5.m5.1.1.cmml" xref="id9.9.5.m5.1.1"><ci id="id9.9.5.m5.1.1.1.cmml" xref="id9.9.5.m5.1.1.1">normal-†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.9.5.m5.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="id9.9.5.m5.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>Google Cloud AI Research, <math alttext="{}^{\ddagger}" class="ltx_Math" display="inline" id="id10.10.6.m6.1"><semantics id="id10.10.6.m6.1a"><msup id="id10.10.6.m6.1.1" xref="id10.10.6.m6.1.1.cmml"><mi id="id10.10.6.m6.1.1a" xref="id10.10.6.m6.1.1.cmml"></mi><mo id="id10.10.6.m6.1.1.1" mathvariant="normal" xref="id10.10.6.m6.1.1.1.cmml">‡</mo></msup><annotation-xml encoding="MathML-Content" id="id10.10.6.m6.1b"><apply id="id10.10.6.m6.1.1.cmml" xref="id10.10.6.m6.1.1"><ci id="id10.10.6.m6.1.1.1.cmml" xref="id10.10.6.m6.1.1.1">normal-‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id10.10.6.m6.1c">{}^{\ddagger}</annotation><annotation encoding="application/x-llamapun" id="id10.10.6.m6.1d">start_FLOATSUPERSCRIPT ‡ end_FLOATSUPERSCRIPT</annotation></semantics></math>Google Cloud AI, <math alttext="{}^{*}" class="ltx_Math" display="inline" id="id11.11.7.m7.1"><semantics id="id11.11.7.m7.1a"><msup id="id11.11.7.m7.1.1" xref="id11.11.7.m7.1.1.cmml"><mi id="id11.11.7.m7.1.1a" xref="id11.11.7.m7.1.1.cmml"></mi><mo id="id11.11.7.m7.1.1.1" mathvariant="normal" xref="id11.11.7.m7.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="id11.11.7.m7.1b"><apply id="id11.11.7.m7.1.1.cmml" xref="id11.11.7.m7.1.1"><times id="id11.11.7.m7.1.1.1.cmml" xref="id11.11.7.m7.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="id11.11.7.m7.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="id11.11.7.m7.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>Google Research
<br class="ltx_break"></span><span class="ltx_text ltx_font_typewriter" id="id12.12.id1">{zifengw, chunliang, vperot, longtle,</span><span class="ltx_text ltx_font_bold" id="id13.13.id2">
<br class="ltx_break"></span><span class="ltx_text ltx_font_typewriter" id="id14.14.id3">jinmiao, zizhaoz, chenyulee, tpfister}@google.com</span><span class="ltx_text ltx_font_bold" id="id15.15.id4">
</span>
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id16.id1">Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next-token prediction objective and users’ actual goals. To reduce the labor and time cost to collect or annotate data by humans, researchers start to explore the use of LLMs to generate instruction-aligned synthetic data.
Recent works focus on generating diverse instructions and applying LLM to increase instruction complexity, often neglecting downstream use cases. It remains unclear how to <em class="ltx_emph ltx_font_italic" id="id16.id1.1">tailor</em> high-quality data to elicit better instruction-following abilities in different target instruction distributions and LLMs. To this end, we introduce <span class="ltx_text ltx_font_bold" id="id16.id1.2">CodecLM</span>, a general framework for adaptively generating high-quality synthetic data for LLM alignment with different downstream instruction distributions and LLMs. Drawing on the Encode-Decode principles, we use LLMs as codecs to guide the data generation process.
We first <em class="ltx_emph ltx_font_italic" id="id16.id1.3">encode</em> seed instructions into metadata, which are concise keywords generated on-the-fly to capture the target instruction distribution, and then <em class="ltx_emph ltx_font_italic" id="id16.id1.4">decode</em> metadata to create tailored instructions. We also introduce Self-Rubrics and Contrastive Filtering during decoding to tailor data-efficient samples. Extensive experiments on four open-domain instruction following benchmarks validate the effectiveness of CodecLM over the current state-of-the-arts.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p ltx_align_center ltx_align_bottom" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1">CodecLM: Aligning Language Models with Tailored Synthetic Data</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="p2">
<br class="ltx_break">
<p class="ltx_p" id="p2.11"><span class="ltx_text" id="p2.11.11" style="width:433.6pt;"><span class="ltx_text" id="p2.11.11.11" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p2.11.11.11.11">
<span class="ltx_tbody">
<span class="ltx_tr" id="p2.4.4.4.4.4">
<span class="ltx_td ltx_align_center" id="p2.4.4.4.4.4.4"><span class="ltx_text ltx_font_bold" id="p2.4.4.4.4.4.4.4">Zifeng Wang<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="p2.1.1.1.1.1.1.1.m1.1"><semantics id="p2.1.1.1.1.1.1.1.m1.1a"><msup id="p2.1.1.1.1.1.1.1.m1.1.1" xref="p2.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="p2.1.1.1.1.1.1.1.m1.1.1a" xref="p2.1.1.1.1.1.1.1.m1.1.1.cmml"></mi><mo id="p2.1.1.1.1.1.1.1.m1.1.1.1" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="p2.1.1.1.1.1.1.1.m1.1b"><apply id="p2.1.1.1.1.1.1.1.m1.1.1.cmml" xref="p2.1.1.1.1.1.1.1.m1.1.1"><ci id="p2.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="p2.1.1.1.1.1.1.1.m1.1.1.1">normal-†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.1.1.1.1.1.1.1.m1.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="p2.1.1.1.1.1.1.1.m1.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>, Chun-Liang Li<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="p2.2.2.2.2.2.2.2.m2.1"><semantics id="p2.2.2.2.2.2.2.2.m2.1a"><msup id="p2.2.2.2.2.2.2.2.m2.1.1" xref="p2.2.2.2.2.2.2.2.m2.1.1.cmml"><mi id="p2.2.2.2.2.2.2.2.m2.1.1a" xref="p2.2.2.2.2.2.2.2.m2.1.1.cmml"></mi><mo id="p2.2.2.2.2.2.2.2.m2.1.1.1" mathvariant="normal" xref="p2.2.2.2.2.2.2.2.m2.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="p2.2.2.2.2.2.2.2.m2.1b"><apply id="p2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="p2.2.2.2.2.2.2.2.m2.1.1"><ci id="p2.2.2.2.2.2.2.2.m2.1.1.1.cmml" xref="p2.2.2.2.2.2.2.2.m2.1.1.1">normal-†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.2.2.2.2.2.2.2.m2.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="p2.2.2.2.2.2.2.2.m2.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>, Vincent Perot<math alttext="{}^{*}" class="ltx_Math" display="inline" id="p2.3.3.3.3.3.3.3.m3.1"><semantics id="p2.3.3.3.3.3.3.3.m3.1a"><msup id="p2.3.3.3.3.3.3.3.m3.1.1" xref="p2.3.3.3.3.3.3.3.m3.1.1.cmml"><mi id="p2.3.3.3.3.3.3.3.m3.1.1a" xref="p2.3.3.3.3.3.3.3.m3.1.1.cmml"></mi><mo id="p2.3.3.3.3.3.3.3.m3.1.1.1" mathvariant="normal" xref="p2.3.3.3.3.3.3.3.m3.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="p2.3.3.3.3.3.3.3.m3.1b"><apply id="p2.3.3.3.3.3.3.3.m3.1.1.cmml" xref="p2.3.3.3.3.3.3.3.m3.1.1"><times id="p2.3.3.3.3.3.3.3.m3.1.1.1.cmml" xref="p2.3.3.3.3.3.3.3.m3.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.3.3.3.3.3.3.3.m3.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="p2.3.3.3.3.3.3.3.m3.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>, Long T. Le<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="p2.4.4.4.4.4.4.4.m4.1"><semantics id="p2.4.4.4.4.4.4.4.m4.1a"><msup id="p2.4.4.4.4.4.4.4.m4.1.1" xref="p2.4.4.4.4.4.4.4.m4.1.1.cmml"><mi id="p2.4.4.4.4.4.4.4.m4.1.1a" xref="p2.4.4.4.4.4.4.4.m4.1.1.cmml"></mi><mo id="p2.4.4.4.4.4.4.4.m4.1.1.1" mathvariant="normal" xref="p2.4.4.4.4.4.4.4.m4.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="p2.4.4.4.4.4.4.4.m4.1b"><apply id="p2.4.4.4.4.4.4.4.m4.1.1.cmml" xref="p2.4.4.4.4.4.4.4.m4.1.1"><ci id="p2.4.4.4.4.4.4.4.m4.1.1.1.cmml" xref="p2.4.4.4.4.4.4.4.m4.1.1.1">normal-†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.4.4.4.4.4.4.4.m4.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="p2.4.4.4.4.4.4.4.m4.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>,</span></span></span>
<span class="ltx_tr" id="p2.8.8.8.8.8">
<span class="ltx_td ltx_align_center" id="p2.8.8.8.8.8.4"><span class="ltx_text ltx_font_bold" id="p2.8.8.8.8.8.4.4">Jin Miao<math alttext="{}^{\ddagger}" class="ltx_Math" display="inline" id="p2.5.5.5.5.5.1.1.m1.1"><semantics id="p2.5.5.5.5.5.1.1.m1.1a"><msup id="p2.5.5.5.5.5.1.1.m1.1.1" xref="p2.5.5.5.5.5.1.1.m1.1.1.cmml"><mi id="p2.5.5.5.5.5.1.1.m1.1.1a" xref="p2.5.5.5.5.5.1.1.m1.1.1.cmml"></mi><mo id="p2.5.5.5.5.5.1.1.m1.1.1.1" mathvariant="normal" xref="p2.5.5.5.5.5.1.1.m1.1.1.1.cmml">‡</mo></msup><annotation-xml encoding="MathML-Content" id="p2.5.5.5.5.5.1.1.m1.1b"><apply id="p2.5.5.5.5.5.1.1.m1.1.1.cmml" xref="p2.5.5.5.5.5.1.1.m1.1.1"><ci id="p2.5.5.5.5.5.1.1.m1.1.1.1.cmml" xref="p2.5.5.5.5.5.1.1.m1.1.1.1">normal-‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.5.5.5.5.5.1.1.m1.1c">{}^{\ddagger}</annotation><annotation encoding="application/x-llamapun" id="p2.5.5.5.5.5.1.1.m1.1d">start_FLOATSUPERSCRIPT ‡ end_FLOATSUPERSCRIPT</annotation></semantics></math>, Zizhao Zhang<math alttext="{}^{\ddagger}" class="ltx_Math" display="inline" id="p2.6.6.6.6.6.2.2.m2.1"><semantics id="p2.6.6.6.6.6.2.2.m2.1a"><msup id="p2.6.6.6.6.6.2.2.m2.1.1" xref="p2.6.6.6.6.6.2.2.m2.1.1.cmml"><mi id="p2.6.6.6.6.6.2.2.m2.1.1a" xref="p2.6.6.6.6.6.2.2.m2.1.1.cmml"></mi><mo id="p2.6.6.6.6.6.2.2.m2.1.1.1" mathvariant="normal" xref="p2.6.6.6.6.6.2.2.m2.1.1.1.cmml">‡</mo></msup><annotation-xml encoding="MathML-Content" id="p2.6.6.6.6.6.2.2.m2.1b"><apply id="p2.6.6.6.6.6.2.2.m2.1.1.cmml" xref="p2.6.6.6.6.6.2.2.m2.1.1"><ci id="p2.6.6.6.6.6.2.2.m2.1.1.1.cmml" xref="p2.6.6.6.6.6.2.2.m2.1.1.1">normal-‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.6.6.6.6.6.2.2.m2.1c">{}^{\ddagger}</annotation><annotation encoding="application/x-llamapun" id="p2.6.6.6.6.6.2.2.m2.1d">start_FLOATSUPERSCRIPT ‡ end_FLOATSUPERSCRIPT</annotation></semantics></math>, Chen-Yu Lee<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="p2.7.7.7.7.7.3.3.m3.1"><semantics id="p2.7.7.7.7.7.3.3.m3.1a"><msup id="p2.7.7.7.7.7.3.3.m3.1.1" xref="p2.7.7.7.7.7.3.3.m3.1.1.cmml"><mi id="p2.7.7.7.7.7.3.3.m3.1.1a" xref="p2.7.7.7.7.7.3.3.m3.1.1.cmml"></mi><mo id="p2.7.7.7.7.7.3.3.m3.1.1.1" mathvariant="normal" xref="p2.7.7.7.7.7.3.3.m3.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="p2.7.7.7.7.7.3.3.m3.1b"><apply id="p2.7.7.7.7.7.3.3.m3.1.1.cmml" xref="p2.7.7.7.7.7.3.3.m3.1.1"><ci id="p2.7.7.7.7.7.3.3.m3.1.1.1.cmml" xref="p2.7.7.7.7.7.3.3.m3.1.1.1">normal-†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.7.7.7.7.7.3.3.m3.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="p2.7.7.7.7.7.3.3.m3.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>, Tomas Pfister<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="p2.8.8.8.8.8.4.4.m4.1"><semantics id="p2.8.8.8.8.8.4.4.m4.1a"><msup id="p2.8.8.8.8.8.4.4.m4.1.1" xref="p2.8.8.8.8.8.4.4.m4.1.1.cmml"><mi id="p2.8.8.8.8.8.4.4.m4.1.1a" xref="p2.8.8.8.8.8.4.4.m4.1.1.cmml"></mi><mo id="p2.8.8.8.8.8.4.4.m4.1.1.1" mathvariant="normal" xref="p2.8.8.8.8.8.4.4.m4.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="p2.8.8.8.8.8.4.4.m4.1b"><apply id="p2.8.8.8.8.8.4.4.m4.1.1.cmml" xref="p2.8.8.8.8.8.4.4.m4.1.1"><ci id="p2.8.8.8.8.8.4.4.m4.1.1.1.cmml" xref="p2.8.8.8.8.8.4.4.m4.1.1.1">normal-†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.8.8.8.8.8.4.4.m4.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="p2.8.8.8.8.8.4.4.m4.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span></span>
<span class="ltx_tr" id="p2.11.11.11.11.11">
<span class="ltx_td ltx_align_center" id="p2.11.11.11.11.11.3"><math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="p2.9.9.9.9.9.1.m1.1"><semantics id="p2.9.9.9.9.9.1.m1.1a"><msup id="p2.9.9.9.9.9.1.m1.1.1" xref="p2.9.9.9.9.9.1.m1.1.1.cmml"><mi id="p2.9.9.9.9.9.1.m1.1.1a" xref="p2.9.9.9.9.9.1.m1.1.1.cmml"></mi><mo id="p2.9.9.9.9.9.1.m1.1.1.1" xref="p2.9.9.9.9.9.1.m1.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="p2.9.9.9.9.9.1.m1.1b"><apply id="p2.9.9.9.9.9.1.m1.1.1.cmml" xref="p2.9.9.9.9.9.1.m1.1.1"><ci id="p2.9.9.9.9.9.1.m1.1.1.1.cmml" xref="p2.9.9.9.9.9.1.m1.1.1.1">†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.9.9.9.9.9.1.m1.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="p2.9.9.9.9.9.1.m1.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>Google Cloud AI Research, <math alttext="{}^{\ddagger}" class="ltx_Math" display="inline" id="p2.10.10.10.10.10.2.m2.1"><semantics id="p2.10.10.10.10.10.2.m2.1a"><msup id="p2.10.10.10.10.10.2.m2.1.1" xref="p2.10.10.10.10.10.2.m2.1.1.cmml"><mi id="p2.10.10.10.10.10.2.m2.1.1a" xref="p2.10.10.10.10.10.2.m2.1.1.cmml"></mi><mo id="p2.10.10.10.10.10.2.m2.1.1.1" xref="p2.10.10.10.10.10.2.m2.1.1.1.cmml">‡</mo></msup><annotation-xml encoding="MathML-Content" id="p2.10.10.10.10.10.2.m2.1b"><apply id="p2.10.10.10.10.10.2.m2.1.1.cmml" xref="p2.10.10.10.10.10.2.m2.1.1"><ci id="p2.10.10.10.10.10.2.m2.1.1.1.cmml" xref="p2.10.10.10.10.10.2.m2.1.1.1">‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.10.10.10.10.10.2.m2.1c">{}^{\ddagger}</annotation><annotation encoding="application/x-llamapun" id="p2.10.10.10.10.10.2.m2.1d">start_FLOATSUPERSCRIPT ‡ end_FLOATSUPERSCRIPT</annotation></semantics></math>Google Cloud AI, <math alttext="{}^{*}" class="ltx_Math" display="inline" id="p2.11.11.11.11.11.3.m3.1"><semantics id="p2.11.11.11.11.11.3.m3.1a"><msup id="p2.11.11.11.11.11.3.m3.1.1" xref="p2.11.11.11.11.11.3.m3.1.1.cmml"><mi id="p2.11.11.11.11.11.3.m3.1.1a" xref="p2.11.11.11.11.11.3.m3.1.1.cmml"></mi><mo id="p2.11.11.11.11.11.3.m3.1.1.1" xref="p2.11.11.11.11.11.3.m3.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="p2.11.11.11.11.11.3.m3.1b"><apply id="p2.11.11.11.11.11.3.m3.1.1.cmml" xref="p2.11.11.11.11.11.3.m3.1.1"><times id="p2.11.11.11.11.11.3.m3.1.1.1.cmml" xref="p2.11.11.11.11.11.3.m3.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.11.11.11.11.11.3.m3.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="p2.11.11.11.11.11.3.m3.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>Google Research</span></span>
<span class="ltx_tr" id="p2.11.11.11.11.12.1">
<span class="ltx_td ltx_align_center" id="p2.11.11.11.11.12.1.1"><span class="ltx_text ltx_font_typewriter" id="p2.11.11.11.11.12.1.1.1">{zifengw, chunliang, vperot, longtle,</span></span></span>
<span class="ltx_tr" id="p2.11.11.11.11.13.2">
<span class="ltx_td ltx_align_center" id="p2.11.11.11.11.13.2.1"><span class="ltx_text ltx_font_typewriter" id="p2.11.11.11.11.13.2.1.1">jinmiao, zizhaoz, chenyulee, tpfister}@google.com</span></span></span>
</span>
</span></span> </span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="705" id="S1.F1.g1" src="x1.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of CodecLM. We first <span class="ltx_text ltx_font_bold" id="S1.F1.3.1">encode</span> seed instructions into metadata to capture the underlying distribution of instructions. This metadata is then <span class="ltx_text ltx_font_bold" id="S1.F1.4.2">decoded</span> through Self-Rubrics and Contrastive Filtering to tailor high-quality synthetic instructions that are aligned with the target instruction distribution. Intermediate instructions and responses are omitted in the figure for clarity.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) have exhibited remarkable capabilities across a wide array of natural language processing (NLP) tasks <cite class="ltx_cite ltx_citemacro_citep">(Brown et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib6" title="">2020</a>; Ouyang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib36" title="">2022</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib34" title="">2023a</a>; Anil et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib1" title="">2023</a>)</cite>. In particular, LLMs can be trained for improved instruction-following through various methods, including fine-tuning on human-annotated data&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib44" title="">2023</a>; Bai et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib3" title="">2022</a>)</cite> or extracted knowledge from stronger LLMs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>; Taori et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib41" title="">2023</a>; Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>; Peng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib37" title="">2023</a>)</cite>. Recent progress in this area highlights the critical role of high-quality data in enhancing LLMs’ instruction-following capabilities&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib55" title="">2023a</a>; Köpf et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib24" title="">2023</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib8" title="">2023b</a>)</cite>. However, acquiring such data through human annotation remains cost-prohibitive and difficult to scale, hindering further progress.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">As an alternative solution to human annotation, recent work explores generating instruction-response pairs for LLM alignment by prompting them with example data or prompts and iteratively refining the results&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Honovich et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib20" title="">2022</a>; Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>; Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib27" title="">2023</a>; Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>. While these methods are effective at generating diverse and complex instructions for LLM alignment broadly, real-world applications often prioritize tailoring the LLM to specific downstream tasks such as individual enterprise applications or personal assistant agents&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib35" title="">2023b</a>)</cite>, which often involve different instruction distributions. This desideratum for task-specific alignment brings us to a core question for data synthesis: <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">how can we tailor synthetic data to align LLMs for different instruction-following tasks?</em></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Specifically, current data synthesis approaches fall short of providing effective solutions for task-specific LLM alignment. While prior works by
<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite> emphasize diversity and complexity as hallmarks of high-quality data, these approaches stumble when facing different downstream tasks that may involve specific instruction distributions. A diverse dataset for one task might not effectively cover the instruction distribution for another. Furthermore, the definition of “complex” instructions can be subjective and vary across tasks. To complicate matters further, an LLM might excel at some seemingly complex instructions while struggling with others that appear simple according to human-crafted criteria. These limitations underscore the need for a unified data synthesis framework that can generate tailored data to align LLMs on specific downstream tasks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this work, we present a novel framework, <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">CodecLM</span>, which systematically generates tailored high-quality data to align LLMs for different downstream tasks. A high-level overview of CodecLM is shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">1</span></a>. Inspired by the principles of Encode-Decode process&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kramer, <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib25" title="">1991</a>; Kingma and Welling, <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib23" title="">2013</a>)</cite>, we leverage a strong LLM as a codec to “encode” seed instructions from our target task into instruction <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">metadata</em> and then “decode” the metadata into tailored synthetic instructions.
The metadata serves as a word-level abstraction of the input instruction distribution, including the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.3">use case</em> and <em class="ltx_emph ltx_font_italic" id="S1.p4.1.4">skills</em> for effective instruction following. It can be automatically generated by encoding seed instructions, or directly provided by users with a high-level anticipation of the downstream task.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Once the metadata is extracted, we then “decode” them to generate tailored instructions. We begin by prompting a LLM with the metadata as constraints, creating basic instructions. To elevate the instruction quality, we introduce <em class="ltx_emph ltx_font_italic" id="S1.p5.1.1">Self-Rubrics</em>. It samples appropriate actions from strong LLMs to make the basic instruction more complex or challenging based on the rubrics it generates for different metadata.
Intuitively, a general knowledge QA instruction about math would differ in complexity rubrics from one in creative writing about sports. With self-generated rubrics and actions based on metadata, the strong LLM crafts instructions that better align the target LLM with specific knowledge required for the downstream task. We can run Self-Rubrics iteratively to control the instruction complexity, similar to &nbsp;<cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>, and finally generate the corresponding responses.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">We also introduce <em class="ltx_emph ltx_font_italic" id="S1.p6.1.1">Contrastive Filtering</em> during decoding to further identify the most effective instruction-response pairs by leveraging the quality discrepancy between the target and a stronger LLM. This strategy identifies two key instruction sets: (a) those the target LLM struggles with, pushing it to improve in its weak areas for more significant gains, and (b) those the target LLM excels at, feeding them back into the Self-Rubrics process for improved data efficiency.
Contrastive Filtering serves as a response-level analogy of contrastive decoding&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib28" title="">2022</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">CodecLM sets a new state-of-the-art on four open-domain instruction-following benchmarks with various LLM choices, demonstrating its effectiveness in LLM alignment for diverse instruction distributions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Instruction Tuning for LLM Alignment.</span> Tuning LLM to faithfully follow instructions and align with diverse human preferences remains a significant challenge&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Efrat and Levy, <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib13" title="">2020</a>)</cite>. Early research primarily focused on cross-task generalization, where models were fine-tuned on various public NLP datasets to improve performance on diverse tasks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib38" title="">2020</a>; Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib48" title="">2021</a>; Aribandi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib2" title="">2021</a>; Victor et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib45" title="">2022</a>; Chung et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib10" title="">2022</a>)</cite>.
More recently, researchers have extended instruction tuning to open-domains, characterized by a wider range of formats and task types. This shift has been driven by crowdsourcing human-generated instruction-response pairs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ouyang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib36" title="">2022</a>; Köpf et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib24" title="">2023</a>; Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib55" title="">2023a</a>)</cite> and LLM-generated data&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib41" title="">2023</a>; Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>)</cite>.
Unlike prior work, CodecLM presents a unique approach for tailoring synthetic data to specific downstream tasks without human annotation, utilizing the concept of instruction metadata.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Data Generation for Instruction Tuning.</span> To address the high cost of human annotation for high-quality instruction-response pairs, several studies advocate for automating the data generation process&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Schick and Schütze, <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib39" title="">2021</a>; Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib30" title="">2022</a>; Meng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib33" title="">2023</a>)</cite>. Leveraging the in-context learning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Brown et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib6" title="">2020</a>)</cite> ability of LLMs, &nbsp;<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>); Honovich et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib20" title="">2022</a>)</cite> prompt LLMs with seed instructions to generate synthetic ones. These are then fed to stronger LLMs, <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">e.g.</span>, ChatGPT, to generate responses for training the target (often smaller) LLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib41" title="">2023</a>)</cite>. As a representative work, WizardLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>, designs a fixed set of human-crafted operations to increase complexity of instructions and control difficulty of generated data. <cite class="ltx_cite ltx_citemacro_citet">Zhao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib53" title="">2023</a>); Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib55" title="">2023a</a>)</cite> further confirm the importance of instruction complexity for LLM alignment through empirical studies. Different from these works that rely on pre-defined rules without considering the downstream tasks, CodecLM enables automatically tailoring instructions for different downstream tasks and target LLMs. We also introduce Self-Rubrics and Contrastive Filtering to further identify the most effective instruction-response pairs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Distillation.</span> Alternatively, tuning the target LLM with responses generated from another LLM can be viewed as knowledge distillation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hinton et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib19" title="">2015</a>; Beyer et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib5" title="">2022</a>)</cite>. However, our focus remains on instruction generation, while still being flexible to readily integrate with existing distillation techniques&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hsieh et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib21" title="">2023</a>; Liang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib29" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Finally, we discuss some of the most relevant recent work. AttrPrompt&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib52" title="">2023</a>)</cite> leverages LLM as attributed data generator by extracting attributes within instructions. However, it focuses solely on classification tasks and requires human intervention for attribute selection. In contrast, our work focuses on the broader context of aligning LLMs to follow open-domain instructions, eliminating the need for human efforts. MSP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib7" title="">2023a</a>)</cite> utilizes trainable soft prompts to control generation, but requires gradient access to the LLM. Our method, on the other hand, is readily compatible with black-box LLMs that only offer API access for high-quality data generation. SteerLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dong et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib11" title="">2023</a>)</cite> analyzes quality-related aspects of responses, instead of the instructions, to capture human preference. Therefore, SteerLM can be used alongside CodecLM as a parallel approach for enhancing response quality.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="339" id="S2.F2.g1" src="x2.png" width="822">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of the proposed CodecLM. First, the strong LLM <math alttext="f_{s}" class="ltx_Math" display="inline" id="S2.F2.7.m1.1"><semantics id="S2.F2.7.m1.1b"><msub id="S2.F2.7.m1.1.1" xref="S2.F2.7.m1.1.1.cmml"><mi id="S2.F2.7.m1.1.1.2" xref="S2.F2.7.m1.1.1.2.cmml">f</mi><mi id="S2.F2.7.m1.1.1.3" xref="S2.F2.7.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.7.m1.1c"><apply id="S2.F2.7.m1.1.1.cmml" xref="S2.F2.7.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.7.m1.1.1.1.cmml" xref="S2.F2.7.m1.1.1">subscript</csymbol><ci id="S2.F2.7.m1.1.1.2.cmml" xref="S2.F2.7.m1.1.1.2">𝑓</ci><ci id="S2.F2.7.m1.1.1.3.cmml" xref="S2.F2.7.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.7.m1.1d">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.7.m1.1e">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> encodes the seed instruction into instruction metadata, specifying its use case and skills required for responses. Next, <math alttext="f_{s}" class="ltx_Math" display="inline" id="S2.F2.8.m2.1"><semantics id="S2.F2.8.m2.1b"><msub id="S2.F2.8.m2.1.1" xref="S2.F2.8.m2.1.1.cmml"><mi id="S2.F2.8.m2.1.1.2" xref="S2.F2.8.m2.1.1.2.cmml">f</mi><mi id="S2.F2.8.m2.1.1.3" xref="S2.F2.8.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.8.m2.1c"><apply id="S2.F2.8.m2.1.1.cmml" xref="S2.F2.8.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.8.m2.1.1.1.cmml" xref="S2.F2.8.m2.1.1">subscript</csymbol><ci id="S2.F2.8.m2.1.1.2.cmml" xref="S2.F2.8.m2.1.1.2">𝑓</ci><ci id="S2.F2.8.m2.1.1.3.cmml" xref="S2.F2.8.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.8.m2.1d">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.8.m2.1e">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> decodes metadata into basic instructions. Meanwhile, Self-Rubrics leverages <math alttext="f_{s}" class="ltx_Math" display="inline" id="S2.F2.9.m3.1"><semantics id="S2.F2.9.m3.1b"><msub id="S2.F2.9.m3.1.1" xref="S2.F2.9.m3.1.1.cmml"><mi id="S2.F2.9.m3.1.1.2" xref="S2.F2.9.m3.1.1.2.cmml">f</mi><mi id="S2.F2.9.m3.1.1.3" xref="S2.F2.9.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.9.m3.1c"><apply id="S2.F2.9.m3.1.1.cmml" xref="S2.F2.9.m3.1.1"><csymbol cd="ambiguous" id="S2.F2.9.m3.1.1.1.cmml" xref="S2.F2.9.m3.1.1">subscript</csymbol><ci id="S2.F2.9.m3.1.1.2.cmml" xref="S2.F2.9.m3.1.1.2">𝑓</ci><ci id="S2.F2.9.m3.1.1.3.cmml" xref="S2.F2.9.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.9.m3.1d">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.9.m3.1e">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> to generate rubrics and actions to improve the basic instruction, tailoring them for the downstream task. Finally, Contrastive Filtering uses a scoring function <math alttext="S" class="ltx_Math" display="inline" id="S2.F2.10.m4.1"><semantics id="S2.F2.10.m4.1b"><mi id="S2.F2.10.m4.1.1" xref="S2.F2.10.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.F2.10.m4.1c"><ci id="S2.F2.10.m4.1.1.cmml" xref="S2.F2.10.m4.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.10.m4.1d">S</annotation><annotation encoding="application/x-llamapun" id="S2.F2.10.m4.1e">italic_S</annotation></semantics></math> to compares <math alttext="f_{s}" class="ltx_Math" display="inline" id="S2.F2.11.m5.1"><semantics id="S2.F2.11.m5.1b"><msub id="S2.F2.11.m5.1.1" xref="S2.F2.11.m5.1.1.cmml"><mi id="S2.F2.11.m5.1.1.2" xref="S2.F2.11.m5.1.1.2.cmml">f</mi><mi id="S2.F2.11.m5.1.1.3" xref="S2.F2.11.m5.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.11.m5.1c"><apply id="S2.F2.11.m5.1.1.cmml" xref="S2.F2.11.m5.1.1"><csymbol cd="ambiguous" id="S2.F2.11.m5.1.1.1.cmml" xref="S2.F2.11.m5.1.1">subscript</csymbol><ci id="S2.F2.11.m5.1.1.2.cmml" xref="S2.F2.11.m5.1.1.2">𝑓</ci><ci id="S2.F2.11.m5.1.1.3.cmml" xref="S2.F2.11.m5.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.11.m5.1d">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.11.m5.1e">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="f_{t}" class="ltx_Math" display="inline" id="S2.F2.12.m6.1"><semantics id="S2.F2.12.m6.1b"><msub id="S2.F2.12.m6.1.1" xref="S2.F2.12.m6.1.1.cmml"><mi id="S2.F2.12.m6.1.1.2" xref="S2.F2.12.m6.1.1.2.cmml">f</mi><mi id="S2.F2.12.m6.1.1.3" xref="S2.F2.12.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.12.m6.1c"><apply id="S2.F2.12.m6.1.1.cmml" xref="S2.F2.12.m6.1.1"><csymbol cd="ambiguous" id="S2.F2.12.m6.1.1.1.cmml" xref="S2.F2.12.m6.1.1">subscript</csymbol><ci id="S2.F2.12.m6.1.1.2.cmml" xref="S2.F2.12.m6.1.1.2">𝑓</ci><ci id="S2.F2.12.m6.1.1.3.cmml" xref="S2.F2.12.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.12.m6.1d">f_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.12.m6.1e">italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>’s responses. The most effective pairs are selected for aligning the LLM, while less effective instructions are sent for further improvement. In this figure, the strong LLM’s response is winning against the target one’s, so we select the corresponding pair for instruction tuning the target LLM.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Problem Statement</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.4">We study the open-domain instruction following problem&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>; Taori et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib41" title="">2023</a>; Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>, where instructions vary in input format and tasks. Specifically, we consider two practical scenarios: (1) Starting with a given set of <math alttext="n" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">italic_n</annotation></semantics></math> seed instructions <math alttext="\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><msub id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.2.m2.1.1.3.2" xref="S3.p1.2.m2.1.1.3.2.cmml">𝒟</mi><mi id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml">s</mi></msub><mo id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">=</mo><msubsup id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml"><mrow id="S3.p1.2.m2.1.1.1.1.1.1" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml"><mo id="S3.p1.2.m2.1.1.1.1.1.1.2" stretchy="false" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml">{</mo><msub id="S3.p1.2.m2.1.1.1.1.1.1.1" xref="S3.p1.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S3.p1.2.m2.1.1.1.1.1.1.1.2" xref="S3.p1.2.m2.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S3.p1.2.m2.1.1.1.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.p1.2.m2.1.1.1.1.1.1.3" stretchy="false" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p1.2.m2.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.3.cmml"><mi id="S3.p1.2.m2.1.1.1.1.3.2" xref="S3.p1.2.m2.1.1.1.1.3.2.cmml">i</mi><mo id="S3.p1.2.m2.1.1.1.1.3.1" xref="S3.p1.2.m2.1.1.1.1.3.1.cmml">=</mo><mn id="S3.p1.2.m2.1.1.1.1.3.3" xref="S3.p1.2.m2.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p1.2.m2.1.1.1.3" xref="S3.p1.2.m2.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><eq id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2"></eq><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.p1.2.m2.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.3.2">𝒟</ci><ci id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3">𝑠</ci></apply><apply id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1">superscript</csymbol><apply id="S3.p1.2.m2.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1">subscript</csymbol><set id="S3.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1"><apply id="S3.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1.2">𝐼</ci><ci id="S3.p1.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S3.p1.2.m2.1.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.1.3"><eq id="S3.p1.2.m2.1.1.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.1.1.3.1"></eq><ci id="S3.p1.2.m2.1.1.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.1.1.3.2">𝑖</ci><cn id="S3.p1.2.m2.1.1.1.1.3.3.cmml" type="integer" xref="S3.p1.2.m2.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p1.2.m2.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = { italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math>, each drawn from some underlying distribution <math alttext="P_{I}" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><msub id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">P</mi><mi id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">𝑃</ci><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">P_{I}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">italic_P start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math>. For our experiments, we create a set of seed instructions using a held-out validation set. Practically, such instructions can be collected from the usage traffic of users. (2) In the absence of seed instructions, but with prior knowledge of downstream tasks, we directly start with a given set of instruction metadata <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S3.p1.4.m4.1"><semantics id="S3.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.4.m4.1d">caligraphic_M</annotation></semantics></math> (see Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S4.SS1" title="4.1 LLM as Codec for Instructions ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4.1</span></a> for definition). The latter scenario is especially useful for end users who lack existing instruction data but wish to jumpstart LLM tailored to specific applications, similar to the concept of GPTs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib35" title="">2023b</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.6">We focus on the first scenario for clarity, though the second can be derived similarly by leveraging an LLM as the encoder (Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S4.SS1" title="4.1 LLM as Codec for Instructions ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4.1</span></a>). Our goal is to generate a set of high-quality instruction-response pairs <math alttext="\mathcal{D}_{g}=\{(I^{{}^{\prime}}_{j},R^{{}^{\prime}}_{j})\}_{j=1}^{m}" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><mrow id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><msub id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.1.m1.1.1.3.2" xref="S3.p2.1.m1.1.1.3.2.cmml">𝒟</mi><mi id="S3.p2.1.m1.1.1.3.3" xref="S3.p2.1.m1.1.1.3.3.cmml">g</mi></msub><mo id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">=</mo><msubsup id="S3.p2.1.m1.1.1.1" xref="S3.p2.1.m1.1.1.1.cmml"><mrow id="S3.p2.1.m1.1.1.1.1.1.1" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml"><mo id="S3.p2.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml">{</mo><mrow id="S3.p2.1.m1.1.1.1.1.1.1.1.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml"><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.2.3" stretchy="false" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml">(</mo><msubsup id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">I</mi><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi><msup id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3a" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"></mi><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">′</mo></msup></msubsup><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.2.4" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml">,</mo><msubsup id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml">R</mi><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3.cmml">j</mi><msup id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3a" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml"></mi><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1.cmml">′</mo></msup></msubsup><mo id="S3.p2.1.m1.1.1.1.1.1.1.1.2.5" stretchy="false" xref="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S3.p2.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p2.1.m1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.3.cmml"><mi id="S3.p2.1.m1.1.1.1.1.3.2" xref="S3.p2.1.m1.1.1.1.1.3.2.cmml">j</mi><mo id="S3.p2.1.m1.1.1.1.1.3.1" xref="S3.p2.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S3.p2.1.m1.1.1.1.1.3.3" xref="S3.p2.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p2.1.m1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.3.cmml">m</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><eq id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2"></eq><apply id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.3.1.cmml" xref="S3.p2.1.m1.1.1.3">subscript</csymbol><ci id="S3.p2.1.m1.1.1.3.2.cmml" xref="S3.p2.1.m1.1.1.3.2">𝒟</ci><ci id="S3.p2.1.m1.1.1.3.3.cmml" xref="S3.p2.1.m1.1.1.3.3">𝑔</ci></apply><apply id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1">superscript</csymbol><apply id="S3.p2.1.m1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1">subscript</csymbol><set id="S3.p2.1.m1.1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1"><interval closure="open" id="S3.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2"><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.2">𝐼</ci><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3"><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.2.3.1">′</ci></apply></apply><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.1.1.3">𝑗</ci></apply><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2">subscript</csymbol><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.2">𝑅</ci><apply id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3"><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.2.3.1">′</ci></apply></apply><ci id="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.1.1.2.2.3">𝑗</ci></apply></interval></set><apply id="S3.p2.1.m1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.3"><eq id="S3.p2.1.m1.1.1.1.1.3.1.cmml" xref="S3.p2.1.m1.1.1.1.1.3.1"></eq><ci id="S3.p2.1.m1.1.1.1.1.3.2.cmml" xref="S3.p2.1.m1.1.1.1.1.3.2">𝑗</ci><cn id="S3.p2.1.m1.1.1.1.1.3.3.cmml" type="integer" xref="S3.p2.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p2.1.m1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.3">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\mathcal{D}_{g}=\{(I^{{}^{\prime}}_{j},R^{{}^{\prime}}_{j})\}_{j=1}^{m}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT = { ( italic_I start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_R start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT</annotation></semantics></math>, using a strong LLM <math alttext="f_{s}" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">f</mi><mi id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">𝑓</ci><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and then use <math alttext="\mathcal{D}_{g}" class="ltx_Math" display="inline" id="S3.p2.3.m3.1"><semantics id="S3.p2.3.m3.1a"><msub id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.3.m3.1.1.2" xref="S3.p2.3.m3.1.1.2.cmml">𝒟</mi><mi id="S3.p2.3.m3.1.1.3" xref="S3.p2.3.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><apply id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p2.3.m3.1.1.1.cmml" xref="S3.p2.3.m3.1.1">subscript</csymbol><ci id="S3.p2.3.m3.1.1.2.cmml" xref="S3.p2.3.m3.1.1.2">𝒟</ci><ci id="S3.p2.3.m3.1.1.3.cmml" xref="S3.p2.3.m3.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">\mathcal{D}_{g}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.3.m3.1d">caligraphic_D start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT</annotation></semantics></math> to fine-tune the target LLM <math alttext="f_{t}" class="ltx_Math" display="inline" id="S3.p2.4.m4.1"><semantics id="S3.p2.4.m4.1a"><msub id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml"><mi id="S3.p2.4.m4.1.1.2" xref="S3.p2.4.m4.1.1.2.cmml">f</mi><mi id="S3.p2.4.m4.1.1.3" xref="S3.p2.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p2.4.m4.1.1.1.cmml" xref="S3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.p2.4.m4.1.1.2.cmml" xref="S3.p2.4.m4.1.1.2">𝑓</ci><ci id="S3.p2.4.m4.1.1.3.cmml" xref="S3.p2.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">f_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.4.m4.1d">italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. We evaluate the performance of the fine-tuned LLM <math alttext="f_{t}" class="ltx_Math" display="inline" id="S3.p2.5.m5.1"><semantics id="S3.p2.5.m5.1a"><msub id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml"><mi id="S3.p2.5.m5.1.1.2" xref="S3.p2.5.m5.1.1.2.cmml">f</mi><mi id="S3.p2.5.m5.1.1.3" xref="S3.p2.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><apply id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.1.cmml" xref="S3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.p2.5.m5.1.1.2.cmml" xref="S3.p2.5.m5.1.1.2">𝑓</ci><ci id="S3.p2.5.m5.1.1.3.cmml" xref="S3.p2.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">f_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.5.m5.1d">italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> on test instructions from the target distribution <math alttext="P_{I}" class="ltx_Math" display="inline" id="S3.p2.6.m6.1"><semantics id="S3.p2.6.m6.1a"><msub id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml"><mi id="S3.p2.6.m6.1.1.2" xref="S3.p2.6.m6.1.1.2.cmml">P</mi><mi id="S3.p2.6.m6.1.1.3" xref="S3.p2.6.m6.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1b"><apply id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p2.6.m6.1.1.1.cmml" xref="S3.p2.6.m6.1.1">subscript</csymbol><ci id="S3.p2.6.m6.1.1.2.cmml" xref="S3.p2.6.m6.1.1.2">𝑃</ci><ci id="S3.p2.6.m6.1.1.3.cmml" xref="S3.p2.6.m6.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1c">P_{I}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.6.m6.1d">italic_P start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math>, to which we are aligning.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>CodecLM</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We propose CodecLM, a general framework for generating high-quality instruction-response pairs tailored to different downstream tasks and LLMs, eliminating the need for human annotation. See Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a> for method overview.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>LLM as Codec for Instructions</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">In this section, we introduce the concept of using a strong LLM as a codec, <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">i.e.</span>, both encoder and decoder, for instruction generation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.3"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.3.1">LLM as Encoder with Instruction Metadata.</span>
We begin by encoding the given seed instructions <math alttext="\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><msub id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.1.m1.1.1.3.2" xref="S4.SS1.p2.1.m1.1.1.3.2.cmml">𝒟</mi><mi id="S4.SS1.p2.1.m1.1.1.3.3" xref="S4.SS1.p2.1.m1.1.1.3.3.cmml">s</mi></msub><mo id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">=</mo><msubsup id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml"><mrow id="S4.SS1.p2.1.m1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml"><mo id="S4.SS1.p2.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS1.p2.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS1.p2.1.m1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.3.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.3.2" xref="S4.SS1.p2.1.m1.1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS1.p2.1.m1.1.1.1.1.3.1" xref="S4.SS1.p2.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS1.p2.1.m1.1.1.1.1.3.3" xref="S4.SS1.p2.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS1.p2.1.m1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><eq id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2"></eq><apply id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2">𝒟</ci><ci id="S4.SS1.p2.1.m1.1.1.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3">𝑠</ci></apply><apply id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1">superscript</csymbol><apply id="S4.SS1.p2.1.m1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1">subscript</csymbol><set id="S4.SS1.p2.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1"><apply id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.2">𝐼</ci><ci id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S4.SS1.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3"><eq id="S4.SS1.p2.1.m1.1.1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3.1"></eq><ci id="S4.SS1.p2.1.m1.1.1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3.2">𝑖</ci><cn id="S4.SS1.p2.1.m1.1.1.1.1.3.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS1.p2.1.m1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\mathcal{D}_{s}=\{I_{i}\}_{i=1}^{n}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = { italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math> into instruction <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.3.2">metadata</em> <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">caligraphic_M</annotation></semantics></math>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.3.3">i.e.</span>, keywords that capture the underlying target instruction distribution. Inspired by the task pool by&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>)</cite> and the post-hoc analysis on skill distribution by&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>, we define the metadata as encompassing two key aspects: <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.3.4">use case</em> and <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.3.5">skills</em>. Use case describes the intended task (<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.3.6">e.g.</span>, question answering or creative writing), while Skills are the knowledge the LLM required to have to successfully respond to the given instruction (<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.3.7">e.g.</span>, algorithms or communication). Skills are often generalizable to different use cases. Therefore, each instruction has a single use case and may involve multiple skills.
To extract this metadata, we leverage the strong LLM <math alttext="f_{s}" class="ltx_Math" display="inline" id="S4.SS1.p2.3.m3.1"><semantics id="S4.SS1.p2.3.m3.1a"><msub id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">f</mi><mi id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝑓</ci><ci id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.3.m3.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> following the prompt template in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F7" title="Figure 7 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">7</span></a>, Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.9</span></a>. While richer definitions are possible based on finer-grained instruction-following metrics&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib56" title="">2023b</a>)</cite>, we prioritize use case and skills for their broad applicability across diverse instruction distributions. Future work can explore extending this metadata further.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.6">For each instruction <math alttext="I_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><msub id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mi id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">I</mi><mi id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">𝐼</ci><ci id="S4.SS1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">I_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, we extract the corresponding use case <math alttext="u_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><msub id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mi id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">u</mi><mi id="S4.SS1.p3.2.m2.1.1.3" xref="S4.SS1.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">𝑢</ci><ci id="S4.SS1.p3.2.m2.1.1.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">u_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and set of skills <math alttext="{\bm{s}}_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><msub id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">𝒔</mi><mi id="S4.SS1.p3.3.m3.1.1.3" xref="S4.SS1.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">𝒔</ci><ci id="S4.SS1.p3.3.m3.1.1.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">{\bm{s}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">bold_italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. We then have the set of metadata as <math alttext="\mathcal{M}=\{(u_{i},{\bm{s}}_{i})\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S4.SS1.p3.4.m4.1"><semantics id="S4.SS1.p3.4.m4.1a"><mrow id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p3.4.m4.1.1.3" xref="S4.SS1.p3.4.m4.1.1.3.cmml">ℳ</mi><mo id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml">=</mo><msubsup id="S4.SS1.p3.4.m4.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.cmml"><mrow id="S4.SS1.p3.4.m4.1.1.1.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml"><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml">{</mo><mrow id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml"><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.3" stretchy="false" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2.cmml">u</mi><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.4" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml">,</mo><msub id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2.cmml">𝒔</mi><mi id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.5" stretchy="false" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S4.SS1.p3.4.m4.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS1.p3.4.m4.1.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.1.3.cmml"><mi id="S4.SS1.p3.4.m4.1.1.1.1.3.2" xref="S4.SS1.p3.4.m4.1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS1.p3.4.m4.1.1.1.1.3.1" xref="S4.SS1.p3.4.m4.1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS1.p3.4.m4.1.1.1.1.3.3" xref="S4.SS1.p3.4.m4.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS1.p3.4.m4.1.1.1.3" xref="S4.SS1.p3.4.m4.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><eq id="S4.SS1.p3.4.m4.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2"></eq><ci id="S4.SS1.p3.4.m4.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.3">ℳ</ci><apply id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1">superscript</csymbol><apply id="S4.SS1.p3.4.m4.1.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1">subscript</csymbol><set id="S4.SS1.p3.4.m4.1.1.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1"><interval closure="open" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2"><apply id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.2">𝑢</ci><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.2">𝒔</ci><ci id="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply></interval></set><apply id="S4.SS1.p3.4.m4.1.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3"><eq id="S4.SS1.p3.4.m4.1.1.1.1.3.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3.1"></eq><ci id="S4.SS1.p3.4.m4.1.1.1.1.3.2.cmml" xref="S4.SS1.p3.4.m4.1.1.1.1.3.2">𝑖</ci><cn id="S4.SS1.p3.4.m4.1.1.1.1.3.3.cmml" type="integer" xref="S4.SS1.p3.4.m4.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS1.p3.4.m4.1.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">\mathcal{M}=\{(u_{i},{\bm{s}}_{i})\}_{i=1}^{n}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.4.m4.1d">caligraphic_M = { ( italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math>. Instructions may share or partially overlap in their <math alttext="u_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.5.m5.1"><semantics id="S4.SS1.p3.5.m5.1a"><msub id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml"><mi id="S4.SS1.p3.5.m5.1.1.2" xref="S4.SS1.p3.5.m5.1.1.2.cmml">u</mi><mi id="S4.SS1.p3.5.m5.1.1.3" xref="S4.SS1.p3.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><apply id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.5.m5.1.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.p3.5.m5.1.1.2.cmml" xref="S4.SS1.p3.5.m5.1.1.2">𝑢</ci><ci id="S4.SS1.p3.5.m5.1.1.3.cmml" xref="S4.SS1.p3.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">u_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.5.m5.1d">italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>’s and <math alttext="{\bm{s}}_{i}" class="ltx_Math" display="inline" id="S4.SS1.p3.6.m6.1"><semantics id="S4.SS1.p3.6.m6.1a"><msub id="S4.SS1.p3.6.m6.1.1" xref="S4.SS1.p3.6.m6.1.1.cmml"><mi id="S4.SS1.p3.6.m6.1.1.2" xref="S4.SS1.p3.6.m6.1.1.2.cmml">𝒔</mi><mi id="S4.SS1.p3.6.m6.1.1.3" xref="S4.SS1.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m6.1b"><apply id="S4.SS1.p3.6.m6.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.6.m6.1.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p3.6.m6.1.1.2.cmml" xref="S4.SS1.p3.6.m6.1.1.2">𝒔</ci><ci id="S4.SS1.p3.6.m6.1.1.3.cmml" xref="S4.SS1.p3.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m6.1c">{\bm{s}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.6.m6.1d">bold_italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, reflecting the distribution of tasks and capabilities within the seed instructions.
Use cases and skills are generated on-the-fly, not limited to some predefined sets, enabling broader applicability. However, we can always provide such constraints with our prior knowledge, or even directly write out metadata without any seed instructions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.3"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.3.1">LLM as Decoder for Instruction Generation.</span> Given the metadata <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">caligraphic_M</annotation></semantics></math>, we decode metadata into synthetic instructions, following a generation and tailoring paradigm. For each use case and skills pair in <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S4.SS1.p4.2.m2.1"><semantics id="S4.SS1.p4.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><ci id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.2.m2.1d">caligraphic_M</annotation></semantics></math>, we list them as constraints to prompt the strong LLM <math alttext="f_{s}" class="ltx_Math" display="inline" id="S4.SS1.p4.3.m3.1"><semantics id="S4.SS1.p4.3.m3.1a"><msub id="S4.SS1.p4.3.m3.1.1" xref="S4.SS1.p4.3.m3.1.1.cmml"><mi id="S4.SS1.p4.3.m3.1.1.2" xref="S4.SS1.p4.3.m3.1.1.2.cmml">f</mi><mi id="S4.SS1.p4.3.m3.1.1.3" xref="S4.SS1.p4.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><apply id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.3.m3.1.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p4.3.m3.1.1.2.cmml" xref="S4.SS1.p4.3.m3.1.1.2">𝑓</ci><ci id="S4.SS1.p4.3.m3.1.1.3.cmml" xref="S4.SS1.p4.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.3.m3.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> to generate multiple instructions. Therefore, the generated instructions are for the given use case, and require the given skills to be responded.
Moreover, to prevent the LLM from generating repetitive instructions, we encourage its generation to be diverse in the prompt, and do not provide any demonstrations that the LLM might copy from. The example prompt template for generating basic instructions is in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F8" title="Figure 8 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">8</span></a>, Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.9</span></a>. Continuing the decoding process, we then tailor the basic instructions for more effective alignment through Self-Rubrics (Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S4.SS2" title="4.2 Instruction Tailoring via Self-Rubrics ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4.2</span></a>) and Contrastive Filtering (Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S4.SS3" title="4.3 Instruction Selection via Contrastive Filtering ‣ 4 CodecLM ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4.3</span></a>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Instruction Tailoring via Self-Rubrics</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Metadata-conditioned instructions lay the groundwork for aligning the target LLM to desired tasks. Studies suggest that more complex instructions can improve alignment performance&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>; Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib53" title="">2023</a>)</cite>. A common practice is to involve human experts crafting general guidance to complicate instructions, such as adding reasoning steps or constraints. However, this one-size-fits-all strategy falls short for diverse instructions. Tailoring guidance to different tasks, like solving calculus problems versus writing news articles, requires distinct approaches.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.2">Therefore, we introduce Self-Rubrics, which leverages the strong LLM to tailor instructions by adjusting their complexity according to the extracted metadata.
Self-Rubrics first guides the LLM to generate metadata-specific rubrics for assessing instruction complexity. Then, informed by these rubrics, the LLM generates a corresponding set of actions to enhance the instruction’s complexity.
For metadata <math alttext="(u_{i},{\bm{s}}_{i})" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.2"><semantics id="S4.SS2.p2.1.m1.2a"><mrow id="S4.SS2.p2.1.m1.2.2.2" xref="S4.SS2.p2.1.m1.2.2.3.cmml"><mo id="S4.SS2.p2.1.m1.2.2.2.3" stretchy="false" xref="S4.SS2.p2.1.m1.2.2.3.cmml">(</mo><msub id="S4.SS2.p2.1.m1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.1.1.2.cmml">u</mi><mi id="S4.SS2.p2.1.m1.1.1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS2.p2.1.m1.2.2.2.4" xref="S4.SS2.p2.1.m1.2.2.3.cmml">,</mo><msub id="S4.SS2.p2.1.m1.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.cmml"><mi id="S4.SS2.p2.1.m1.2.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.2.cmml">𝒔</mi><mi id="S4.SS2.p2.1.m1.2.2.2.2.3" xref="S4.SS2.p2.1.m1.2.2.2.2.3.cmml">i</mi></msub><mo id="S4.SS2.p2.1.m1.2.2.2.5" stretchy="false" xref="S4.SS2.p2.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.2b"><interval closure="open" id="S4.SS2.p2.1.m1.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2"><apply id="S4.SS2.p2.1.m1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2">𝑢</ci><ci id="S4.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.SS2.p2.1.m1.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.2.2.2.2.1.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2">𝒔</ci><ci id="S4.SS2.p2.1.m1.2.2.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.2c">(u_{i},{\bm{s}}_{i})</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.2d">( italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, the corresponding set of generated actions is <math alttext="{\bm{a}}_{i}" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1"><semantics id="S4.SS2.p2.2.m2.1a"><msub id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">𝒂</mi><mi id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">𝒂</ci><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">{\bm{a}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m2.1d">bold_italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. Our generated actions are more domain-specific, and unambiguous than generic rules crafted by human, making the complicated instructions better tailored towards the target distribution captured by the metadata. For example, for the use case of “business plan development” and skills of “market research and planning”, generic rules like “add reasoning steps” is vague and inappropriate. On the contrary, Self-Rubrics is able to generate actions like “add SWOT analyisis” and “include comparison with market competitors” (see Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS8" title="A.8 Case Study ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.8</span></a> for the full details) to complicate the instruction.
The prompt template to generate rubrics and actions for instruction improvement is shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F9" title="Figure 9 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">9</span></a>, Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.9</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.3">With the obtained actions <math alttext="\{{\bm{a}}_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><msubsup id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mrow id="S4.SS2.p3.1.m1.1.1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.1.2.cmml"><mo id="S4.SS2.p3.1.m1.1.1.1.1.1.2" stretchy="false" xref="S4.SS2.p3.1.m1.1.1.1.1.2.cmml">{</mo><msub id="S4.SS2.p3.1.m1.1.1.1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1.1.1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.2.cmml">𝒂</mi><mi id="S4.SS2.p3.1.m1.1.1.1.1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS2.p3.1.m1.1.1.1.1.1.3" stretchy="false" xref="S4.SS2.p3.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS2.p3.1.m1.1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.1.3.cmml"><mi id="S4.SS2.p3.1.m1.1.1.1.3.2" xref="S4.SS2.p3.1.m1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS2.p3.1.m1.1.1.1.3.1" xref="S4.SS2.p3.1.m1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS2.p3.1.m1.1.1.1.3.3" xref="S4.SS2.p3.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1">superscript</csymbol><apply id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1">subscript</csymbol><set id="S4.SS2.p3.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1"><apply id="S4.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.2">𝒂</ci><ci id="S4.SS2.p3.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S4.SS2.p3.1.m1.1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3"><eq id="S4.SS2.p3.1.m1.1.1.1.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3.1"></eq><ci id="S4.SS2.p3.1.m1.1.1.1.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.1.3.2">𝑖</ci><cn id="S4.SS2.p3.1.m1.1.1.1.3.3.cmml" type="integer" xref="S4.SS2.p3.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\{{\bm{a}}_{i}\}_{i=1}^{n}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">{ bold_italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math>, we can iteratively prompt <math alttext="f_{s}" class="ltx_Math" display="inline" id="S4.SS2.p3.2.m2.1"><semantics id="S4.SS2.p3.2.m2.1a"><msub id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">f</mi><mi id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">𝑓</ci><ci id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.2.m2.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> to complicate the basic instructions, following the prompt template in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F10" title="Figure 10 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">10</span></a>. We randomly sample an action <math alttext="{\bm{a}}_{i}" class="ltx_Math" display="inline" id="S4.SS2.p3.3.m3.1"><semantics id="S4.SS2.p3.3.m3.1a"><msub id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml"><mi id="S4.SS2.p3.3.m3.1.1.2" xref="S4.SS2.p3.3.m3.1.1.2.cmml">𝒂</mi><mi id="S4.SS2.p3.3.m3.1.1.3" xref="S4.SS2.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><apply id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.1.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p3.3.m3.1.1.2.cmml" xref="S4.SS2.p3.3.m3.1.1.2">𝒂</ci><ci id="S4.SS2.p3.3.m3.1.1.3.cmml" xref="S4.SS2.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">{\bm{a}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.3.m3.1d">bold_italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> from the multiple actions generated for a pair of use case and skills. This design choice not only enables controlled complexity&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>, but also prevents potential confusion between different actions for the LLM. </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Instruction Selection via Contrastive Filtering</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">While Self-Rubrics tailors complex instructions based on instruction metadata, not all instructions are equally effective for instruction tuning, regardless of their complexity&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib8" title="">2023b</a>; Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib55" title="">2023a</a>)</cite>. Intuitively, exposing the target LLM to instructions it finds challenging can effectively identify its areas for improvement. Therefore, it is crucial to select the most impactful instructions for aligning the target LLM.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.13">We therefore introduce Contrastive Filtering, a method to select the instructions that can effectively enhance the target LLM <math alttext="f_{t}" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><msub id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">f</mi><mi id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">𝑓</ci><ci id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">f_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. For clarity, we define the space of all natural language sequences as <math alttext="\mathcal{N}" class="ltx_Math" display="inline" id="S4.SS3.p2.2.m2.1"><semantics id="S4.SS3.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">\mathcal{N}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.2.m2.1d">caligraphic_N</annotation></semantics></math>. We have the strong LLM <math alttext="f_{s}:\mathcal{N}\to\mathcal{N}" class="ltx_Math" display="inline" id="S4.SS3.p2.3.m3.1"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><msub id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2.2" xref="S4.SS3.p2.3.m3.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.3.m3.1.1.2.3" xref="S4.SS3.p2.3.m3.1.1.2.3.cmml">s</mi></msub><mo id="S4.SS3.p2.3.m3.1.1.1" lspace="0.278em" rspace="0.278em" xref="S4.SS3.p2.3.m3.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.3.m3.1.1.3.2" xref="S4.SS3.p2.3.m3.1.1.3.2.cmml">𝒩</mi><mo id="S4.SS3.p2.3.m3.1.1.3.1" stretchy="false" xref="S4.SS3.p2.3.m3.1.1.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.3.m3.1.1.3.3" xref="S4.SS3.p2.3.m3.1.1.3.3.cmml">𝒩</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><ci id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1">:</ci><apply id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.2.1.cmml" xref="S4.SS3.p2.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.2.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2.2">𝑓</ci><ci id="S4.SS3.p2.3.m3.1.1.2.3.cmml" xref="S4.SS3.p2.3.m3.1.1.2.3">𝑠</ci></apply><apply id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3"><ci id="S4.SS3.p2.3.m3.1.1.3.1.cmml" xref="S4.SS3.p2.3.m3.1.1.3.1">→</ci><ci id="S4.SS3.p2.3.m3.1.1.3.2.cmml" xref="S4.SS3.p2.3.m3.1.1.3.2">𝒩</ci><ci id="S4.SS3.p2.3.m3.1.1.3.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3">𝒩</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">f_{s}:\mathcal{N}\to\mathcal{N}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.3.m3.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT : caligraphic_N → caligraphic_N</annotation></semantics></math>, the target LLM <math alttext="f_{t}:\mathcal{N}\to\mathcal{N}" class="ltx_Math" display="inline" id="S4.SS3.p2.4.m4.1"><semantics id="S4.SS3.p2.4.m4.1a"><mrow id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><msub id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2.2" xref="S4.SS3.p2.4.m4.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.4.m4.1.1.2.3" xref="S4.SS3.p2.4.m4.1.1.2.3.cmml">t</mi></msub><mo id="S4.SS3.p2.4.m4.1.1.1" lspace="0.278em" rspace="0.278em" xref="S4.SS3.p2.4.m4.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.4.m4.1.1.3.2" xref="S4.SS3.p2.4.m4.1.1.3.2.cmml">𝒩</mi><mo id="S4.SS3.p2.4.m4.1.1.3.1" stretchy="false" xref="S4.SS3.p2.4.m4.1.1.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.4.m4.1.1.3.3" xref="S4.SS3.p2.4.m4.1.1.3.3.cmml">𝒩</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><ci id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1.1">:</ci><apply id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.1.1.2.1.cmml" xref="S4.SS3.p2.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.4.m4.1.1.2.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2.2">𝑓</ci><ci id="S4.SS3.p2.4.m4.1.1.2.3.cmml" xref="S4.SS3.p2.4.m4.1.1.2.3">𝑡</ci></apply><apply id="S4.SS3.p2.4.m4.1.1.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3"><ci id="S4.SS3.p2.4.m4.1.1.3.1.cmml" xref="S4.SS3.p2.4.m4.1.1.3.1">→</ci><ci id="S4.SS3.p2.4.m4.1.1.3.2.cmml" xref="S4.SS3.p2.4.m4.1.1.3.2">𝒩</ci><ci id="S4.SS3.p2.4.m4.1.1.3.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3.3">𝒩</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">f_{t}:\mathcal{N}\to\mathcal{N}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.4.m4.1d">italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT : caligraphic_N → caligraphic_N</annotation></semantics></math>, and a scoring function <math alttext="S:\mathcal{N}\to\mathbb{R}" class="ltx_Math" display="inline" id="S4.SS3.p2.5.m5.1"><semantics id="S4.SS3.p2.5.m5.1a"><mrow id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml"><mi id="S4.SS3.p2.5.m5.1.1.2" xref="S4.SS3.p2.5.m5.1.1.2.cmml">S</mi><mo id="S4.SS3.p2.5.m5.1.1.1" lspace="0.278em" rspace="0.278em" xref="S4.SS3.p2.5.m5.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.5.m5.1.1.3" xref="S4.SS3.p2.5.m5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.5.m5.1.1.3.2" xref="S4.SS3.p2.5.m5.1.1.3.2.cmml">𝒩</mi><mo id="S4.SS3.p2.5.m5.1.1.3.1" stretchy="false" xref="S4.SS3.p2.5.m5.1.1.3.1.cmml">→</mo><mi id="S4.SS3.p2.5.m5.1.1.3.3" xref="S4.SS3.p2.5.m5.1.1.3.3.cmml">ℝ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"><ci id="S4.SS3.p2.5.m5.1.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1.1">:</ci><ci id="S4.SS3.p2.5.m5.1.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.2">𝑆</ci><apply id="S4.SS3.p2.5.m5.1.1.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3"><ci id="S4.SS3.p2.5.m5.1.1.3.1.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1">→</ci><ci id="S4.SS3.p2.5.m5.1.1.3.2.cmml" xref="S4.SS3.p2.5.m5.1.1.3.2">𝒩</ci><ci id="S4.SS3.p2.5.m5.1.1.3.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3.3">ℝ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">S:\mathcal{N}\to\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.5.m5.1d">italic_S : caligraphic_N → blackboard_R</annotation></semantics></math> to evaluate response quality.
In practice, <math alttext="S" class="ltx_Math" display="inline" id="S4.SS3.p2.6.m6.1"><semantics id="S4.SS3.p2.6.m6.1a"><mi id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><ci id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">S</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.6.m6.1d">italic_S</annotation></semantics></math> is obtained by reusing the strong LLM <math alttext="f_{s}" class="ltx_Math" display="inline" id="S4.SS3.p2.7.m7.1"><semantics id="S4.SS3.p2.7.m7.1a"><msub id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml"><mi id="S4.SS3.p2.7.m7.1.1.2" xref="S4.SS3.p2.7.m7.1.1.2.cmml">f</mi><mi id="S4.SS3.p2.7.m7.1.1.3" xref="S4.SS3.p2.7.m7.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><apply id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.7.m7.1.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1">subscript</csymbol><ci id="S4.SS3.p2.7.m7.1.1.2.cmml" xref="S4.SS3.p2.7.m7.1.1.2">𝑓</ci><ci id="S4.SS3.p2.7.m7.1.1.3.cmml" xref="S4.SS3.p2.7.m7.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.7.m7.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> with a prompt template (Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F11" title="Figure 11 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">11</span></a>, Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.9</span></a>) adapted from the Vicuna pairwise evaluation template&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib41" title="">2023</a>; Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>)</cite>.
To mitigate potential position bias, we average the scores obtained by exchanging the positions of two responses&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>)</cite>.
We observe using <math alttext="f_{s}" class="ltx_Math" display="inline" id="S4.SS3.p2.8.m8.1"><semantics id="S4.SS3.p2.8.m8.1a"><msub id="S4.SS3.p2.8.m8.1.1" xref="S4.SS3.p2.8.m8.1.1.cmml"><mi id="S4.SS3.p2.8.m8.1.1.2" xref="S4.SS3.p2.8.m8.1.1.2.cmml">f</mi><mi id="S4.SS3.p2.8.m8.1.1.3" xref="S4.SS3.p2.8.m8.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.8.m8.1b"><apply id="S4.SS3.p2.8.m8.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.8.m8.1.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1">subscript</csymbol><ci id="S4.SS3.p2.8.m8.1.1.2.cmml" xref="S4.SS3.p2.8.m8.1.1.2">𝑓</ci><ci id="S4.SS3.p2.8.m8.1.1.3.cmml" xref="S4.SS3.p2.8.m8.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.8.m8.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.8.m8.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> for scoring works quite well in practice, so we prioritize this option for simplicity.
Given an input instruction <math alttext="I\in\mathcal{N}" class="ltx_Math" display="inline" id="S4.SS3.p2.9.m9.1"><semantics id="S4.SS3.p2.9.m9.1a"><mrow id="S4.SS3.p2.9.m9.1.1" xref="S4.SS3.p2.9.m9.1.1.cmml"><mi id="S4.SS3.p2.9.m9.1.1.2" xref="S4.SS3.p2.9.m9.1.1.2.cmml">I</mi><mo id="S4.SS3.p2.9.m9.1.1.1" xref="S4.SS3.p2.9.m9.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.9.m9.1.1.3" xref="S4.SS3.p2.9.m9.1.1.3.cmml">𝒩</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.9.m9.1b"><apply id="S4.SS3.p2.9.m9.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1"><in id="S4.SS3.p2.9.m9.1.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1.1"></in><ci id="S4.SS3.p2.9.m9.1.1.2.cmml" xref="S4.SS3.p2.9.m9.1.1.2">𝐼</ci><ci id="S4.SS3.p2.9.m9.1.1.3.cmml" xref="S4.SS3.p2.9.m9.1.1.3">𝒩</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.9.m9.1c">I\in\mathcal{N}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.9.m9.1d">italic_I ∈ caligraphic_N</annotation></semantics></math>, we obtain responses from both LLMs as <math alttext="f_{s}(I)" class="ltx_Math" display="inline" id="S4.SS3.p2.10.m10.1"><semantics id="S4.SS3.p2.10.m10.1a"><mrow id="S4.SS3.p2.10.m10.1.2" xref="S4.SS3.p2.10.m10.1.2.cmml"><msub id="S4.SS3.p2.10.m10.1.2.2" xref="S4.SS3.p2.10.m10.1.2.2.cmml"><mi id="S4.SS3.p2.10.m10.1.2.2.2" xref="S4.SS3.p2.10.m10.1.2.2.2.cmml">f</mi><mi id="S4.SS3.p2.10.m10.1.2.2.3" xref="S4.SS3.p2.10.m10.1.2.2.3.cmml">s</mi></msub><mo id="S4.SS3.p2.10.m10.1.2.1" xref="S4.SS3.p2.10.m10.1.2.1.cmml">⁢</mo><mrow id="S4.SS3.p2.10.m10.1.2.3.2" xref="S4.SS3.p2.10.m10.1.2.cmml"><mo id="S4.SS3.p2.10.m10.1.2.3.2.1" stretchy="false" xref="S4.SS3.p2.10.m10.1.2.cmml">(</mo><mi id="S4.SS3.p2.10.m10.1.1" xref="S4.SS3.p2.10.m10.1.1.cmml">I</mi><mo id="S4.SS3.p2.10.m10.1.2.3.2.2" stretchy="false" xref="S4.SS3.p2.10.m10.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.10.m10.1b"><apply id="S4.SS3.p2.10.m10.1.2.cmml" xref="S4.SS3.p2.10.m10.1.2"><times id="S4.SS3.p2.10.m10.1.2.1.cmml" xref="S4.SS3.p2.10.m10.1.2.1"></times><apply id="S4.SS3.p2.10.m10.1.2.2.cmml" xref="S4.SS3.p2.10.m10.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.10.m10.1.2.2.1.cmml" xref="S4.SS3.p2.10.m10.1.2.2">subscript</csymbol><ci id="S4.SS3.p2.10.m10.1.2.2.2.cmml" xref="S4.SS3.p2.10.m10.1.2.2.2">𝑓</ci><ci id="S4.SS3.p2.10.m10.1.2.2.3.cmml" xref="S4.SS3.p2.10.m10.1.2.2.3">𝑠</ci></apply><ci id="S4.SS3.p2.10.m10.1.1.cmml" xref="S4.SS3.p2.10.m10.1.1">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.10.m10.1c">f_{s}(I)</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.10.m10.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_I )</annotation></semantics></math> and <math alttext="f_{t}(I)" class="ltx_Math" display="inline" id="S4.SS3.p2.11.m11.1"><semantics id="S4.SS3.p2.11.m11.1a"><mrow id="S4.SS3.p2.11.m11.1.2" xref="S4.SS3.p2.11.m11.1.2.cmml"><msub id="S4.SS3.p2.11.m11.1.2.2" xref="S4.SS3.p2.11.m11.1.2.2.cmml"><mi id="S4.SS3.p2.11.m11.1.2.2.2" xref="S4.SS3.p2.11.m11.1.2.2.2.cmml">f</mi><mi id="S4.SS3.p2.11.m11.1.2.2.3" xref="S4.SS3.p2.11.m11.1.2.2.3.cmml">t</mi></msub><mo id="S4.SS3.p2.11.m11.1.2.1" xref="S4.SS3.p2.11.m11.1.2.1.cmml">⁢</mo><mrow id="S4.SS3.p2.11.m11.1.2.3.2" xref="S4.SS3.p2.11.m11.1.2.cmml"><mo id="S4.SS3.p2.11.m11.1.2.3.2.1" stretchy="false" xref="S4.SS3.p2.11.m11.1.2.cmml">(</mo><mi id="S4.SS3.p2.11.m11.1.1" xref="S4.SS3.p2.11.m11.1.1.cmml">I</mi><mo id="S4.SS3.p2.11.m11.1.2.3.2.2" stretchy="false" xref="S4.SS3.p2.11.m11.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.11.m11.1b"><apply id="S4.SS3.p2.11.m11.1.2.cmml" xref="S4.SS3.p2.11.m11.1.2"><times id="S4.SS3.p2.11.m11.1.2.1.cmml" xref="S4.SS3.p2.11.m11.1.2.1"></times><apply id="S4.SS3.p2.11.m11.1.2.2.cmml" xref="S4.SS3.p2.11.m11.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.11.m11.1.2.2.1.cmml" xref="S4.SS3.p2.11.m11.1.2.2">subscript</csymbol><ci id="S4.SS3.p2.11.m11.1.2.2.2.cmml" xref="S4.SS3.p2.11.m11.1.2.2.2">𝑓</ci><ci id="S4.SS3.p2.11.m11.1.2.2.3.cmml" xref="S4.SS3.p2.11.m11.1.2.2.3">𝑡</ci></apply><ci id="S4.SS3.p2.11.m11.1.1.cmml" xref="S4.SS3.p2.11.m11.1.1">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.11.m11.1c">f_{t}(I)</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.11.m11.1d">italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_I )</annotation></semantics></math>, respectively. We then define the <em class="ltx_emph ltx_font_italic" id="S4.SS3.p2.13.1">quality gap</em> <math alttext="G:\mathcal{N}\to\mathbb{R}" class="ltx_Math" display="inline" id="S4.SS3.p2.12.m12.1"><semantics id="S4.SS3.p2.12.m12.1a"><mrow id="S4.SS3.p2.12.m12.1.1" xref="S4.SS3.p2.12.m12.1.1.cmml"><mi id="S4.SS3.p2.12.m12.1.1.2" xref="S4.SS3.p2.12.m12.1.1.2.cmml">G</mi><mo id="S4.SS3.p2.12.m12.1.1.1" lspace="0.278em" rspace="0.278em" xref="S4.SS3.p2.12.m12.1.1.1.cmml">:</mo><mrow id="S4.SS3.p2.12.m12.1.1.3" xref="S4.SS3.p2.12.m12.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p2.12.m12.1.1.3.2" xref="S4.SS3.p2.12.m12.1.1.3.2.cmml">𝒩</mi><mo id="S4.SS3.p2.12.m12.1.1.3.1" stretchy="false" xref="S4.SS3.p2.12.m12.1.1.3.1.cmml">→</mo><mi id="S4.SS3.p2.12.m12.1.1.3.3" xref="S4.SS3.p2.12.m12.1.1.3.3.cmml">ℝ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.12.m12.1b"><apply id="S4.SS3.p2.12.m12.1.1.cmml" xref="S4.SS3.p2.12.m12.1.1"><ci id="S4.SS3.p2.12.m12.1.1.1.cmml" xref="S4.SS3.p2.12.m12.1.1.1">:</ci><ci id="S4.SS3.p2.12.m12.1.1.2.cmml" xref="S4.SS3.p2.12.m12.1.1.2">𝐺</ci><apply id="S4.SS3.p2.12.m12.1.1.3.cmml" xref="S4.SS3.p2.12.m12.1.1.3"><ci id="S4.SS3.p2.12.m12.1.1.3.1.cmml" xref="S4.SS3.p2.12.m12.1.1.3.1">→</ci><ci id="S4.SS3.p2.12.m12.1.1.3.2.cmml" xref="S4.SS3.p2.12.m12.1.1.3.2">𝒩</ci><ci id="S4.SS3.p2.12.m12.1.1.3.3.cmml" xref="S4.SS3.p2.12.m12.1.1.3.3">ℝ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.12.m12.1c">G:\mathcal{N}\to\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.12.m12.1d">italic_G : caligraphic_N → blackboard_R</annotation></semantics></math> between these responses to estimate the <em class="ltx_emph ltx_font_italic" id="S4.SS3.p2.13.2">effectiveness</em> of the instruction: <math alttext="G(I)=S(f_{s}(I))-S(f_{t}(I))" class="ltx_Math" display="inline" id="S4.SS3.p2.13.m13.5"><semantics id="S4.SS3.p2.13.m13.5a"><mrow id="S4.SS3.p2.13.m13.5.5" xref="S4.SS3.p2.13.m13.5.5.cmml"><mrow id="S4.SS3.p2.13.m13.5.5.4" xref="S4.SS3.p2.13.m13.5.5.4.cmml"><mi id="S4.SS3.p2.13.m13.5.5.4.2" xref="S4.SS3.p2.13.m13.5.5.4.2.cmml">G</mi><mo id="S4.SS3.p2.13.m13.5.5.4.1" xref="S4.SS3.p2.13.m13.5.5.4.1.cmml">⁢</mo><mrow id="S4.SS3.p2.13.m13.5.5.4.3.2" xref="S4.SS3.p2.13.m13.5.5.4.cmml"><mo id="S4.SS3.p2.13.m13.5.5.4.3.2.1" stretchy="false" xref="S4.SS3.p2.13.m13.5.5.4.cmml">(</mo><mi id="S4.SS3.p2.13.m13.1.1" xref="S4.SS3.p2.13.m13.1.1.cmml">I</mi><mo id="S4.SS3.p2.13.m13.5.5.4.3.2.2" stretchy="false" xref="S4.SS3.p2.13.m13.5.5.4.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p2.13.m13.5.5.3" xref="S4.SS3.p2.13.m13.5.5.3.cmml">=</mo><mrow id="S4.SS3.p2.13.m13.5.5.2" xref="S4.SS3.p2.13.m13.5.5.2.cmml"><mrow id="S4.SS3.p2.13.m13.4.4.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.cmml"><mi id="S4.SS3.p2.13.m13.4.4.1.1.3" xref="S4.SS3.p2.13.m13.4.4.1.1.3.cmml">S</mi><mo id="S4.SS3.p2.13.m13.4.4.1.1.2" xref="S4.SS3.p2.13.m13.4.4.1.1.2.cmml">⁢</mo><mrow id="S4.SS3.p2.13.m13.4.4.1.1.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml"><mo id="S4.SS3.p2.13.m13.4.4.1.1.1.1.2" stretchy="false" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml"><msub id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.cmml"><mi id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3.cmml">s</mi></msub><mo id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.3.2" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml"><mo id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.3.2.1" stretchy="false" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">(</mo><mi id="S4.SS3.p2.13.m13.2.2" xref="S4.SS3.p2.13.m13.2.2.cmml">I</mi><mo id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.3.2.2" stretchy="false" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p2.13.m13.4.4.1.1.1.1.3" stretchy="false" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p2.13.m13.5.5.2.3" xref="S4.SS3.p2.13.m13.5.5.2.3.cmml">−</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.cmml"><mi id="S4.SS3.p2.13.m13.5.5.2.2.3" xref="S4.SS3.p2.13.m13.5.5.2.2.3.cmml">S</mi><mo id="S4.SS3.p2.13.m13.5.5.2.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.2.cmml">⁢</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2.1.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml"><mo id="S4.SS3.p2.13.m13.5.5.2.2.1.1.2" stretchy="false" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">(</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml"><msub id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.cmml"><mi id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3.cmml">t</mi></msub><mo id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1.cmml">⁢</mo><mrow id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.3.2" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml"><mo id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.3.2.1" stretchy="false" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">(</mo><mi id="S4.SS3.p2.13.m13.3.3" xref="S4.SS3.p2.13.m13.3.3.cmml">I</mi><mo id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.3.2.2" stretchy="false" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p2.13.m13.5.5.2.2.1.1.3" stretchy="false" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.13.m13.5b"><apply id="S4.SS3.p2.13.m13.5.5.cmml" xref="S4.SS3.p2.13.m13.5.5"><eq id="S4.SS3.p2.13.m13.5.5.3.cmml" xref="S4.SS3.p2.13.m13.5.5.3"></eq><apply id="S4.SS3.p2.13.m13.5.5.4.cmml" xref="S4.SS3.p2.13.m13.5.5.4"><times id="S4.SS3.p2.13.m13.5.5.4.1.cmml" xref="S4.SS3.p2.13.m13.5.5.4.1"></times><ci id="S4.SS3.p2.13.m13.5.5.4.2.cmml" xref="S4.SS3.p2.13.m13.5.5.4.2">𝐺</ci><ci id="S4.SS3.p2.13.m13.1.1.cmml" xref="S4.SS3.p2.13.m13.1.1">𝐼</ci></apply><apply id="S4.SS3.p2.13.m13.5.5.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2"><minus id="S4.SS3.p2.13.m13.5.5.2.3.cmml" xref="S4.SS3.p2.13.m13.5.5.2.3"></minus><apply id="S4.SS3.p2.13.m13.4.4.1.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1"><times id="S4.SS3.p2.13.m13.4.4.1.1.2.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.2"></times><ci id="S4.SS3.p2.13.m13.4.4.1.1.3.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.3">𝑆</ci><apply id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1"><times id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.1"></times><apply id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.1.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.2">𝑓</ci><ci id="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3.cmml" xref="S4.SS3.p2.13.m13.4.4.1.1.1.1.1.2.3">𝑠</ci></apply><ci id="S4.SS3.p2.13.m13.2.2.cmml" xref="S4.SS3.p2.13.m13.2.2">𝐼</ci></apply></apply><apply id="S4.SS3.p2.13.m13.5.5.2.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2"><times id="S4.SS3.p2.13.m13.5.5.2.2.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.2"></times><ci id="S4.SS3.p2.13.m13.5.5.2.2.3.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.3">𝑆</ci><apply id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1"><times id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.1"></times><apply id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.1.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2">subscript</csymbol><ci id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.2">𝑓</ci><ci id="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3.cmml" xref="S4.SS3.p2.13.m13.5.5.2.2.1.1.1.2.3">𝑡</ci></apply><ci id="S4.SS3.p2.13.m13.3.3.cmml" xref="S4.SS3.p2.13.m13.3.3">𝐼</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.13.m13.5c">G(I)=S(f_{s}(I))-S(f_{t}(I))</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.13.m13.5d">italic_G ( italic_I ) = italic_S ( italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_I ) ) - italic_S ( italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_I ) )</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.11">The quality gap metric <math alttext="G" class="ltx_Math" display="inline" id="S4.SS3.p3.1.m1.1"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">G</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.1.m1.1d">italic_G</annotation></semantics></math> reflects how much the target LLM benefits from the strong LLM for each instruction <math alttext="I" class="ltx_Math" display="inline" id="S4.SS3.p3.2.m2.1"><semantics id="S4.SS3.p3.2.m2.1a"><mi id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><ci id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">I</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.2.m2.1d">italic_I</annotation></semantics></math>.
As demonstrated in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a>, here are two possible cases: (1) <math alttext="|G(I)|>\theta" class="ltx_Math" display="inline" id="S4.SS3.p3.3.m3.2"><semantics id="S4.SS3.p3.3.m3.2a"><mrow id="S4.SS3.p3.3.m3.2.2" xref="S4.SS3.p3.3.m3.2.2.cmml"><mrow id="S4.SS3.p3.3.m3.2.2.1.1" xref="S4.SS3.p3.3.m3.2.2.1.2.cmml"><mo id="S4.SS3.p3.3.m3.2.2.1.1.2" stretchy="false" xref="S4.SS3.p3.3.m3.2.2.1.2.1.cmml">|</mo><mrow id="S4.SS3.p3.3.m3.2.2.1.1.1" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml"><mi id="S4.SS3.p3.3.m3.2.2.1.1.1.2" xref="S4.SS3.p3.3.m3.2.2.1.1.1.2.cmml">G</mi><mo id="S4.SS3.p3.3.m3.2.2.1.1.1.1" xref="S4.SS3.p3.3.m3.2.2.1.1.1.1.cmml">⁢</mo><mrow id="S4.SS3.p3.3.m3.2.2.1.1.1.3.2" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml"><mo id="S4.SS3.p3.3.m3.2.2.1.1.1.3.2.1" stretchy="false" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml">(</mo><mi id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">I</mi><mo id="S4.SS3.p3.3.m3.2.2.1.1.1.3.2.2" stretchy="false" xref="S4.SS3.p3.3.m3.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p3.3.m3.2.2.1.1.3" stretchy="false" xref="S4.SS3.p3.3.m3.2.2.1.2.1.cmml">|</mo></mrow><mo id="S4.SS3.p3.3.m3.2.2.2" xref="S4.SS3.p3.3.m3.2.2.2.cmml">&gt;</mo><mi id="S4.SS3.p3.3.m3.2.2.3" xref="S4.SS3.p3.3.m3.2.2.3.cmml">θ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.2b"><apply id="S4.SS3.p3.3.m3.2.2.cmml" xref="S4.SS3.p3.3.m3.2.2"><gt id="S4.SS3.p3.3.m3.2.2.2.cmml" xref="S4.SS3.p3.3.m3.2.2.2"></gt><apply id="S4.SS3.p3.3.m3.2.2.1.2.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1"><abs id="S4.SS3.p3.3.m3.2.2.1.2.1.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.2"></abs><apply id="S4.SS3.p3.3.m3.2.2.1.1.1.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.1"><times id="S4.SS3.p3.3.m3.2.2.1.1.1.1.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.1.1"></times><ci id="S4.SS3.p3.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS3.p3.3.m3.2.2.1.1.1.2">𝐺</ci><ci id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">𝐼</ci></apply></apply><ci id="S4.SS3.p3.3.m3.2.2.3.cmml" xref="S4.SS3.p3.3.m3.2.2.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.2c">|G(I)|&gt;\theta</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.3.m3.2d">| italic_G ( italic_I ) | &gt; italic_θ</annotation></semantics></math>, where <math alttext="\theta\in\mathbb{R}" class="ltx_Math" display="inline" id="S4.SS3.p3.4.m4.1"><semantics id="S4.SS3.p3.4.m4.1a"><mrow id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml"><mi id="S4.SS3.p3.4.m4.1.1.2" xref="S4.SS3.p3.4.m4.1.1.2.cmml">θ</mi><mo id="S4.SS3.p3.4.m4.1.1.1" xref="S4.SS3.p3.4.m4.1.1.1.cmml">∈</mo><mi id="S4.SS3.p3.4.m4.1.1.3" xref="S4.SS3.p3.4.m4.1.1.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><apply id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1"><in id="S4.SS3.p3.4.m4.1.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1.1"></in><ci id="S4.SS3.p3.4.m4.1.1.2.cmml" xref="S4.SS3.p3.4.m4.1.1.2">𝜃</ci><ci id="S4.SS3.p3.4.m4.1.1.3.cmml" xref="S4.SS3.p3.4.m4.1.1.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">\theta\in\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.4.m4.1d">italic_θ ∈ blackboard_R</annotation></semantics></math> is a certain threshold. This indicates that: Either the strong LLM has a much better response than the target LLM, we add <math alttext="(I,f_{s}(I))" class="ltx_Math" display="inline" id="S4.SS3.p3.5.m5.3"><semantics id="S4.SS3.p3.5.m5.3a"><mrow id="S4.SS3.p3.5.m5.3.3.1" xref="S4.SS3.p3.5.m5.3.3.2.cmml"><mo id="S4.SS3.p3.5.m5.3.3.1.2" stretchy="false" xref="S4.SS3.p3.5.m5.3.3.2.cmml">(</mo><mi id="S4.SS3.p3.5.m5.2.2" xref="S4.SS3.p3.5.m5.2.2.cmml">I</mi><mo id="S4.SS3.p3.5.m5.3.3.1.3" xref="S4.SS3.p3.5.m5.3.3.2.cmml">,</mo><mrow id="S4.SS3.p3.5.m5.3.3.1.1" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml"><msub id="S4.SS3.p3.5.m5.3.3.1.1.2" xref="S4.SS3.p3.5.m5.3.3.1.1.2.cmml"><mi id="S4.SS3.p3.5.m5.3.3.1.1.2.2" xref="S4.SS3.p3.5.m5.3.3.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p3.5.m5.3.3.1.1.2.3" xref="S4.SS3.p3.5.m5.3.3.1.1.2.3.cmml">s</mi></msub><mo id="S4.SS3.p3.5.m5.3.3.1.1.1" xref="S4.SS3.p3.5.m5.3.3.1.1.1.cmml">⁢</mo><mrow id="S4.SS3.p3.5.m5.3.3.1.1.3.2" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml"><mo id="S4.SS3.p3.5.m5.3.3.1.1.3.2.1" stretchy="false" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml">(</mo><mi id="S4.SS3.p3.5.m5.1.1" xref="S4.SS3.p3.5.m5.1.1.cmml">I</mi><mo id="S4.SS3.p3.5.m5.3.3.1.1.3.2.2" stretchy="false" xref="S4.SS3.p3.5.m5.3.3.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p3.5.m5.3.3.1.4" stretchy="false" xref="S4.SS3.p3.5.m5.3.3.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.3b"><interval closure="open" id="S4.SS3.p3.5.m5.3.3.2.cmml" xref="S4.SS3.p3.5.m5.3.3.1"><ci id="S4.SS3.p3.5.m5.2.2.cmml" xref="S4.SS3.p3.5.m5.2.2">𝐼</ci><apply id="S4.SS3.p3.5.m5.3.3.1.1.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1"><times id="S4.SS3.p3.5.m5.3.3.1.1.1.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.1"></times><apply id="S4.SS3.p3.5.m5.3.3.1.1.2.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p3.5.m5.3.3.1.1.2.1.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2">subscript</csymbol><ci id="S4.SS3.p3.5.m5.3.3.1.1.2.2.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2.2">𝑓</ci><ci id="S4.SS3.p3.5.m5.3.3.1.1.2.3.cmml" xref="S4.SS3.p3.5.m5.3.3.1.1.2.3">𝑠</ci></apply><ci id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1">𝐼</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.3c">(I,f_{s}(I))</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.5.m5.3d">( italic_I , italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_I ) )</annotation></semantics></math> to our high-quality instruction-response pool <math alttext="\mathcal{D}_{g}" class="ltx_Math" display="inline" id="S4.SS3.p3.6.m6.1"><semantics id="S4.SS3.p3.6.m6.1a"><msub id="S4.SS3.p3.6.m6.1.1" xref="S4.SS3.p3.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p3.6.m6.1.1.2" xref="S4.SS3.p3.6.m6.1.1.2.cmml">𝒟</mi><mi id="S4.SS3.p3.6.m6.1.1.3" xref="S4.SS3.p3.6.m6.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.6.m6.1b"><apply id="S4.SS3.p3.6.m6.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.6.m6.1.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1">subscript</csymbol><ci id="S4.SS3.p3.6.m6.1.1.2.cmml" xref="S4.SS3.p3.6.m6.1.1.2">𝒟</ci><ci id="S4.SS3.p3.6.m6.1.1.3.cmml" xref="S4.SS3.p3.6.m6.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.6.m6.1c">\mathcal{D}_{g}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.6.m6.1d">caligraphic_D start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT</annotation></semantics></math> to fill the gap; Or rarely, the target LLM gives much better response than the strong LLM, we add <math alttext="(I,f_{t}(I))" class="ltx_Math" display="inline" id="S4.SS3.p3.7.m7.3"><semantics id="S4.SS3.p3.7.m7.3a"><mrow id="S4.SS3.p3.7.m7.3.3.1" xref="S4.SS3.p3.7.m7.3.3.2.cmml"><mo id="S4.SS3.p3.7.m7.3.3.1.2" stretchy="false" xref="S4.SS3.p3.7.m7.3.3.2.cmml">(</mo><mi id="S4.SS3.p3.7.m7.2.2" xref="S4.SS3.p3.7.m7.2.2.cmml">I</mi><mo id="S4.SS3.p3.7.m7.3.3.1.3" xref="S4.SS3.p3.7.m7.3.3.2.cmml">,</mo><mrow id="S4.SS3.p3.7.m7.3.3.1.1" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml"><msub id="S4.SS3.p3.7.m7.3.3.1.1.2" xref="S4.SS3.p3.7.m7.3.3.1.1.2.cmml"><mi id="S4.SS3.p3.7.m7.3.3.1.1.2.2" xref="S4.SS3.p3.7.m7.3.3.1.1.2.2.cmml">f</mi><mi id="S4.SS3.p3.7.m7.3.3.1.1.2.3" xref="S4.SS3.p3.7.m7.3.3.1.1.2.3.cmml">t</mi></msub><mo id="S4.SS3.p3.7.m7.3.3.1.1.1" xref="S4.SS3.p3.7.m7.3.3.1.1.1.cmml">⁢</mo><mrow id="S4.SS3.p3.7.m7.3.3.1.1.3.2" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml"><mo id="S4.SS3.p3.7.m7.3.3.1.1.3.2.1" stretchy="false" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml">(</mo><mi id="S4.SS3.p3.7.m7.1.1" xref="S4.SS3.p3.7.m7.1.1.cmml">I</mi><mo id="S4.SS3.p3.7.m7.3.3.1.1.3.2.2" stretchy="false" xref="S4.SS3.p3.7.m7.3.3.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p3.7.m7.3.3.1.4" stretchy="false" xref="S4.SS3.p3.7.m7.3.3.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.7.m7.3b"><interval closure="open" id="S4.SS3.p3.7.m7.3.3.2.cmml" xref="S4.SS3.p3.7.m7.3.3.1"><ci id="S4.SS3.p3.7.m7.2.2.cmml" xref="S4.SS3.p3.7.m7.2.2">𝐼</ci><apply id="S4.SS3.p3.7.m7.3.3.1.1.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1"><times id="S4.SS3.p3.7.m7.3.3.1.1.1.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.1"></times><apply id="S4.SS3.p3.7.m7.3.3.1.1.2.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p3.7.m7.3.3.1.1.2.1.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2">subscript</csymbol><ci id="S4.SS3.p3.7.m7.3.3.1.1.2.2.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2.2">𝑓</ci><ci id="S4.SS3.p3.7.m7.3.3.1.1.2.3.cmml" xref="S4.SS3.p3.7.m7.3.3.1.1.2.3">𝑡</ci></apply><ci id="S4.SS3.p3.7.m7.1.1.cmml" xref="S4.SS3.p3.7.m7.1.1">𝐼</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.7.m7.3c">(I,f_{t}(I))</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.7.m7.3d">( italic_I , italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_I ) )</annotation></semantics></math> to <math alttext="\mathcal{D}_{g}" class="ltx_Math" display="inline" id="S4.SS3.p3.8.m8.1"><semantics id="S4.SS3.p3.8.m8.1a"><msub id="S4.SS3.p3.8.m8.1.1" xref="S4.SS3.p3.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p3.8.m8.1.1.2" xref="S4.SS3.p3.8.m8.1.1.2.cmml">𝒟</mi><mi id="S4.SS3.p3.8.m8.1.1.3" xref="S4.SS3.p3.8.m8.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.8.m8.1b"><apply id="S4.SS3.p3.8.m8.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.8.m8.1.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1">subscript</csymbol><ci id="S4.SS3.p3.8.m8.1.1.2.cmml" xref="S4.SS3.p3.8.m8.1.1.2">𝒟</ci><ci id="S4.SS3.p3.8.m8.1.1.3.cmml" xref="S4.SS3.p3.8.m8.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.8.m8.1c">\mathcal{D}_{g}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.8.m8.1d">caligraphic_D start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT</annotation></semantics></math> as as an implicit regularization to keep the target LLM’s desirable behavior to certain instructions. (2) <math alttext="|G(I)|\leq\theta" class="ltx_Math" display="inline" id="S4.SS3.p3.9.m9.2"><semantics id="S4.SS3.p3.9.m9.2a"><mrow id="S4.SS3.p3.9.m9.2.2" xref="S4.SS3.p3.9.m9.2.2.cmml"><mrow id="S4.SS3.p3.9.m9.2.2.1.1" xref="S4.SS3.p3.9.m9.2.2.1.2.cmml"><mo id="S4.SS3.p3.9.m9.2.2.1.1.2" stretchy="false" xref="S4.SS3.p3.9.m9.2.2.1.2.1.cmml">|</mo><mrow id="S4.SS3.p3.9.m9.2.2.1.1.1" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml"><mi id="S4.SS3.p3.9.m9.2.2.1.1.1.2" xref="S4.SS3.p3.9.m9.2.2.1.1.1.2.cmml">G</mi><mo id="S4.SS3.p3.9.m9.2.2.1.1.1.1" xref="S4.SS3.p3.9.m9.2.2.1.1.1.1.cmml">⁢</mo><mrow id="S4.SS3.p3.9.m9.2.2.1.1.1.3.2" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml"><mo id="S4.SS3.p3.9.m9.2.2.1.1.1.3.2.1" stretchy="false" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml">(</mo><mi id="S4.SS3.p3.9.m9.1.1" xref="S4.SS3.p3.9.m9.1.1.cmml">I</mi><mo id="S4.SS3.p3.9.m9.2.2.1.1.1.3.2.2" stretchy="false" xref="S4.SS3.p3.9.m9.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p3.9.m9.2.2.1.1.3" stretchy="false" xref="S4.SS3.p3.9.m9.2.2.1.2.1.cmml">|</mo></mrow><mo id="S4.SS3.p3.9.m9.2.2.2" xref="S4.SS3.p3.9.m9.2.2.2.cmml">≤</mo><mi id="S4.SS3.p3.9.m9.2.2.3" xref="S4.SS3.p3.9.m9.2.2.3.cmml">θ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.9.m9.2b"><apply id="S4.SS3.p3.9.m9.2.2.cmml" xref="S4.SS3.p3.9.m9.2.2"><leq id="S4.SS3.p3.9.m9.2.2.2.cmml" xref="S4.SS3.p3.9.m9.2.2.2"></leq><apply id="S4.SS3.p3.9.m9.2.2.1.2.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1"><abs id="S4.SS3.p3.9.m9.2.2.1.2.1.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.2"></abs><apply id="S4.SS3.p3.9.m9.2.2.1.1.1.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.1"><times id="S4.SS3.p3.9.m9.2.2.1.1.1.1.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.1.1"></times><ci id="S4.SS3.p3.9.m9.2.2.1.1.1.2.cmml" xref="S4.SS3.p3.9.m9.2.2.1.1.1.2">𝐺</ci><ci id="S4.SS3.p3.9.m9.1.1.cmml" xref="S4.SS3.p3.9.m9.1.1">𝐼</ci></apply></apply><ci id="S4.SS3.p3.9.m9.2.2.3.cmml" xref="S4.SS3.p3.9.m9.2.2.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.9.m9.2c">|G(I)|\leq\theta</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.9.m9.2d">| italic_G ( italic_I ) | ≤ italic_θ</annotation></semantics></math>, where the quality of responses from both LLMs is similar, so learning from <math alttext="I" class="ltx_Math" display="inline" id="S4.SS3.p3.10.m10.1"><semantics id="S4.SS3.p3.10.m10.1a"><mi id="S4.SS3.p3.10.m10.1.1" xref="S4.SS3.p3.10.m10.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.10.m10.1b"><ci id="S4.SS3.p3.10.m10.1.1.cmml" xref="S4.SS3.p3.10.m10.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.10.m10.1c">I</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.10.m10.1d">italic_I</annotation></semantics></math> does not lead to much gain. We then send <math alttext="I" class="ltx_Math" display="inline" id="S4.SS3.p3.11.m11.1"><semantics id="S4.SS3.p3.11.m11.1a"><mi id="S4.SS3.p3.11.m11.1.1" xref="S4.SS3.p3.11.m11.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.11.m11.1b"><ci id="S4.SS3.p3.11.m11.1.1.cmml" xref="S4.SS3.p3.11.m11.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.11.m11.1c">I</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.11.m11.1d">italic_I</annotation></semantics></math> to the next Self-Rubrics iteration for further improvement.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">Contrastive Filtering complements Self-Rubrics to select effective instruction-response pairs by calibrating the target LLM’s instruction-following capability with the strong LLM’s. Analogous to Constrastive Decoding&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib28" title="">2022</a>)</cite> at response-level, Contrastive Filtering can also be regarded as LLM-feedback&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Madaan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib32" title="">2023</a>)</cite> with the interaction of two LLMs. While we adopt the strong LLM as scoring function to measure the quality gap, our framework can be compatible with and potentially benefit from the advances in more reliable and comprehensive scoring and feedback systems&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lee et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib26" title="">2023</a>)</cite>, and we leave it as promising future work.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We conduct comprehensive experiments to evaluate CodecLM using different LLMs on multiple representative benchmarks, closely following well-established evaluation settings for open-domain instruction following in prior work&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib8" title="">2023b</a>)</cite>.
We also conduct a case study in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS8" title="A.8 Case Study ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.8</span></a> to illustrate how CodecLM tailors an instruction step by step.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation Benchmarks</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We evaluate CodecLM on four widely-used open-domain instruction-following benchmarks with diverse instruction distributions to reduce evaluation bias. Our test benchmarks include Evol-Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>, Vicuna&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>)</cite>, Self-Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>)</cite> and Koala&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Geng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib16" title="">2023</a>)</cite>.
To complement the evaluation, we also evaluate on two standard NLP benchmarks MMLU&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib18" title="">2020</a>)</cite> and BBH&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib40" title="">2022</a>)</cite> in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS7" title="A.7 Additional Benchmark Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.7</span></a>.
Please refer to Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS1" title="A.1 Benchmark Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.1</span></a> for benchmark details.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Baseline Methods</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We compare our method against state-of-the-art data generation approaches for instruction tuning. For fair comparison, we provide all methods the same LLM backbones when possible. Moreover, we control the number of instruction-response pairs the same for all methods to ablate the effect of data quantity.
Baseline methods include <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">Self-Instruct</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>)</cite>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.2">Alpagasus</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib8" title="">2023b</a>)</cite>, &nbsp;<span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.3">Tree-Instruct</span>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.4">WizardLM</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>, and <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.5">WizardLM+</span>, an enhanced version of WizardLM using the same basic instructions generated from CodecLM as seed instructions. Baseline details are presented in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS2" title="A.2 Baseline Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Experiment and Evaluation Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.1">LLM Backbones.</span> We adopt LLaMA-based&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib44" title="">2023</a>)</cite> and PaLM-based&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Anil et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib1" title="">2023</a>)</cite> LLMs as our target LLMs in our experiments. For LLaMA-based target LLMs, we use Gemini-Pro&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Team et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib42" title="">2023</a>)</cite> as the strong LLM, and LLaMA-7B, -13B as the target LLMs. For PaLM-based target LLMs, we use text-unicorn as the strong LLM, and text-bison as the target LLM. PaLM-based models and Gemini-Pro are accessible through Google Cloud API<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cloud.google.com/vertex-ai" title="">https://cloud.google.com/vertex-ai</a></span></span></span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p2.1.1">Implementation Details of CodecLM.</span> We split all benchmarks into 20% validation set and 80% evaluation set. We extract the instruction metadata from the validation set, see Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS3" title="A.3 Additional Implementation Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.3</span></a> for more details. Depending on the specified total data size, we prompt the strong LLM to generate equal number of base instruction per metadata. We generate 500-8000 synthetic data throughout the experiments. We generate 4 rubrics and corresponding actions. At each iteration, we randomly choose 1 action for improving instruction. We run Self-Rubrics at most 4 iterations. For Contrastive Filtering, We set the scoring scale to 10 and the filtering threshold to 3 for all experiments. We align these configurations with&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>
and leave more detailed rationales of these configurations, additional hyperparameter settings, and training details in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS3" title="A.3 Additional Implementation Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.3</span></a>-<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS4" title="A.4 Training Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.4</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results with LLaMA-based target models on four open-domain instruction following benchmarks. Each method trains a target model based on LLaMA-7B or -13B, and compares against the strong model, Gemini-Pro. The reported metric Capacity Recovery Ratio (%), <math alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" class="ltx_Math" display="inline" id="S5.T1.2.m1.1"><semantics id="S5.T1.2.m1.1b"><mrow id="S5.T1.2.m1.1.1" xref="S5.T1.2.m1.1.1.cmml"><mtext id="S5.T1.2.m1.1.1.2" xref="S5.T1.2.m1.1.1.2a.cmml">𝙲𝚁𝚁</mtext><mo id="S5.T1.2.m1.1.1.1" xref="S5.T1.2.m1.1.1.1.cmml">=</mo><mfrac id="S5.T1.2.m1.1.1.3" xref="S5.T1.2.m1.1.1.3.cmml"><mrow id="S5.T1.2.m1.1.1.3.2" xref="S5.T1.2.m1.1.1.3.2.cmml"><mtext id="S5.T1.2.m1.1.1.3.2.2" xref="S5.T1.2.m1.1.1.3.2.2a.cmml">𝚠𝚒𝚗𝚜</mtext><mo id="S5.T1.2.m1.1.1.3.2.1" xref="S5.T1.2.m1.1.1.3.2.1.cmml">+</mo><mtext id="S5.T1.2.m1.1.1.3.2.3" xref="S5.T1.2.m1.1.1.3.2.3a.cmml">𝚝𝚒𝚎𝚜</mtext></mrow><mtext id="S5.T1.2.m1.1.1.3.3" mathvariant="monospace" xref="S5.T1.2.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.m1.1c"><apply id="S5.T1.2.m1.1.1.cmml" xref="S5.T1.2.m1.1.1"><eq id="S5.T1.2.m1.1.1.1.cmml" xref="S5.T1.2.m1.1.1.1"></eq><ci id="S5.T1.2.m1.1.1.2a.cmml" xref="S5.T1.2.m1.1.1.2"><mtext id="S5.T1.2.m1.1.1.2.cmml" xref="S5.T1.2.m1.1.1.2">𝙲𝚁𝚁</mtext></ci><apply id="S5.T1.2.m1.1.1.3.cmml" xref="S5.T1.2.m1.1.1.3"><divide id="S5.T1.2.m1.1.1.3.1.cmml" xref="S5.T1.2.m1.1.1.3"></divide><apply id="S5.T1.2.m1.1.1.3.2.cmml" xref="S5.T1.2.m1.1.1.3.2"><plus id="S5.T1.2.m1.1.1.3.2.1.cmml" xref="S5.T1.2.m1.1.1.3.2.1"></plus><ci id="S5.T1.2.m1.1.1.3.2.2a.cmml" xref="S5.T1.2.m1.1.1.3.2.2"><mtext id="S5.T1.2.m1.1.1.3.2.2.cmml" mathsize="70%" xref="S5.T1.2.m1.1.1.3.2.2">𝚠𝚒𝚗𝚜</mtext></ci><ci id="S5.T1.2.m1.1.1.3.2.3a.cmml" xref="S5.T1.2.m1.1.1.3.2.3"><mtext id="S5.T1.2.m1.1.1.3.2.3.cmml" mathsize="70%" xref="S5.T1.2.m1.1.1.3.2.3">𝚝𝚒𝚎𝚜</mtext></ci></apply><ci id="S5.T1.2.m1.1.1.3.3a.cmml" xref="S5.T1.2.m1.1.1.3.3"><mtext id="S5.T1.2.m1.1.1.3.3.cmml" mathsize="70%" mathvariant="monospace" xref="S5.T1.2.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.m1.1d">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.2.m1.1e">CRR = divide start_ARG wins + ties end_ARG start_ARG total comparisons end_ARG</annotation></semantics></math>. Larger CRR means better performance.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.3" style="width:462.7pt;height:126.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-31.5pt,8.6pt) scale(0.88,0.88) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T1.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" id="S5.T1.3.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_tt" colspan="4" id="S5.T1.3.1.1.1.2">
<span class="ltx_text ltx_font_bold" id="S5.T1.3.1.1.1.2.1">LLaMA-7B vs. Gemini-Pro</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S5.T1.3.1.1.1.3">
<span class="ltx_text ltx_font_bold" id="S5.T1.3.1.1.1.3.1">LLaMA-13B vs. Gemini-Pro</span></th>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T1.3.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.2.2.1.1">Evol-Ins.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T1.3.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.2.2.2.1">Vicuna</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T1.3.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.2.2.3.1">Koala</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" id="S5.T1.3.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.2.2.4.1">Self-Ins.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T1.3.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.2.2.5.1">Evol-Ins.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T1.3.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.2.2.6.1">Vicuna</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T1.3.1.2.2.7"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.2.2.7.1">Koala</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T1.3.1.2.2.8"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.2.2.8.1">Self-Ins.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.3.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T1.3.1.3.1.1">Self-Instruct</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.3.1.2">72.02</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.3.1.3">81.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.3.1.4">67.78</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S5.T1.3.1.3.1.5">65.87</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.3.1.6">75.69</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.3.1.7">86.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.3.1.8">77.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.3.1.9">69.05</td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T1.3.1.4.2.1">Alpagasus</th>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.2.2">75.23 <span class="ltx_text" id="S5.T1.3.1.4.2.2.1" style="color:#006B3D;">(+3.2)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.2.3">81.25 <span class="ltx_text" id="S5.T1.3.1.4.2.3.1" style="color:#006B3D;">(+0.0)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.2.4">71.11 <span class="ltx_text" id="S5.T1.3.1.4.2.4.1" style="color:#006B3D;">(+3.3)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S5.T1.3.1.4.2.5">70.24 <span class="ltx_text" id="S5.T1.3.1.4.2.5.1" style="color:#006B3D;">(+4.4)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.2.6">79.82 <span class="ltx_text" id="S5.T1.3.1.4.2.6.1" style="color:#006B3D;">(+4.1)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.2.7">87.50 <span class="ltx_text" id="S5.T1.3.1.4.2.7.1" style="color:#006B3D;">(+1.3)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.2.8">77.78 <span class="ltx_text" id="S5.T1.3.1.4.2.8.1" style="color:#006B3D;">(+0.6)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.2.9">71.03 <span class="ltx_text" id="S5.T1.3.1.4.2.9.1" style="color:#006B3D;">(+2.0)</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T1.3.1.5.3.1">Tree-Instruct</th>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.3.2">75.23 <span class="ltx_text" id="S5.T1.3.1.5.3.2.1" style="color:#006B3D;">(+3.2)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.3.3">81.25 <span class="ltx_text" id="S5.T1.3.1.5.3.3.1" style="color:#006B3D;">(+0.0)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.3.4">72.78 <span class="ltx_text" id="S5.T1.3.1.5.3.4.1" style="color:#006B3D;">(+5.0)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S5.T1.3.1.5.3.5">68.65 <span class="ltx_text" id="S5.T1.3.1.5.3.5.1" style="color:#006B3D;">(+2.8)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.3.6">82.57 <span class="ltx_text" id="S5.T1.3.1.5.3.6.1" style="color:#006B3D;">(+6.9)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.3.7">87.50 <span class="ltx_text" id="S5.T1.3.1.5.3.7.1" style="color:#006B3D;">(+1.3)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.3.8">80.56 <span class="ltx_text" id="S5.T1.3.1.5.3.8.1" style="color:#006B3D;">(+3.3)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.3.9">79.37 <span class="ltx_text" id="S5.T1.3.1.5.3.9.1" style="color:#006B3D;">(+10.3)</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T1.3.1.6.4.1">WizardLM</th>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.4.2">74.31 <span class="ltx_text" id="S5.T1.3.1.6.4.2.1" style="color:#006B3D;">(+2.3)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.4.3">76.25 <span class="ltx_text" id="S5.T1.3.1.6.4.3.1" style="color:#FF0000;">(-5.0)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.4.4">65.56 <span class="ltx_text" id="S5.T1.3.1.6.4.4.1" style="color:#FF0000;">(-2.2)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S5.T1.3.1.6.4.5">71.43 <span class="ltx_text" id="S5.T1.3.1.6.4.5.1" style="color:#006B3D;">(+5.6)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.4.6">82.11 <span class="ltx_text" id="S5.T1.3.1.6.4.6.1" style="color:#006B3D;">(+6.4)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.4.7">86.25 <span class="ltx_text" id="S5.T1.3.1.6.4.7.1" style="color:#006B3D;">(+0.0)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.4.8">78.89 <span class="ltx_text" id="S5.T1.3.1.6.4.8.1" style="color:#006B3D;">(+1.7)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.4.9">76.19 <span class="ltx_text" id="S5.T1.3.1.6.4.9.1" style="color:#006B3D;">(+7.1)</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T1.3.1.7.5.1">WizardLM+</th>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.5.2">75.69 <span class="ltx_text" id="S5.T1.3.1.7.5.2.1" style="color:#006B3D;">(+3.7)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.5.3">83.75 <span class="ltx_text" id="S5.T1.3.1.7.5.3.1" style="color:#006B3D;">(+2.5)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.5.4">68.33 <span class="ltx_text" id="S5.T1.3.1.7.5.4.1" style="color:#006B3D;">(+0.6)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S5.T1.3.1.7.5.5">72.22 <span class="ltx_text" id="S5.T1.3.1.7.5.5.1" style="color:#006B3D;">(+6.4)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.5.6">84.40 <span class="ltx_text" id="S5.T1.3.1.7.5.6.1" style="color:#006B3D;">(+8.7)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.5.7">88.75 <span class="ltx_text" id="S5.T1.3.1.7.5.7.1" style="color:#006B3D;">(+2.5)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.5.8">81.11 <span class="ltx_text" id="S5.T1.3.1.7.5.8.1" style="color:#006B3D;">(+3.9)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.5.9">79.76 <span class="ltx_text" id="S5.T1.3.1.7.5.9.1" style="color:#006B3D;">(+10.7)</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="S5.T1.3.1.8.6.1">CodecLM (ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.8.6.2"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.8.6.2.1">79.82 <span class="ltx_text" id="S5.T1.3.1.8.6.2.1.1" style="color:#006B3D;">(+7.8)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.8.6.3"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.8.6.3.1">88.75 <span class="ltx_text" id="S5.T1.3.1.8.6.3.1.1" style="color:#006B3D;">(+7.5)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.8.6.4"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.8.6.4.1">74.44 <span class="ltx_text" id="S5.T1.3.1.8.6.4.1.1" style="color:#006B3D;">(+6.7)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr" id="S5.T1.3.1.8.6.5"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.8.6.5.1">78.17 <span class="ltx_text" id="S5.T1.3.1.8.6.5.1.1" style="color:#006B3D;">(+12.3)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.8.6.6"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.8.6.6.1">86.70 <span class="ltx_text" id="S5.T1.3.1.8.6.6.1.1" style="color:#006B3D;">(+11.0)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.8.6.7"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.8.6.7.1">90.00 <span class="ltx_text" id="S5.T1.3.1.8.6.7.1.1" style="color:#006B3D;">(+3.8)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.8.6.8"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.8.6.8.1">82.22 <span class="ltx_text" id="S5.T1.3.1.8.6.8.1.1" style="color:#006B3D;">(+5.0)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.8.6.9"><span class="ltx_text ltx_font_bold" id="S5.T1.3.1.8.6.9.1">83.33 <span class="ltx_text" id="S5.T1.3.1.8.6.9.1.1" style="color:#006B3D;">(+14.3)</span></span></td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p3.1.1">Evaluation.</span>
Assessing how well LLMs follow instructions is complex, arising from the fact that an instruction has various valid responses, and the challenge of replicating human evaluation. Recent advances in automatic evaluation on instruction following&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dubois et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib12" title="">2023</a>; Zheng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib54" title="">2023</a>)</cite> demonstrate that LLM-based evaluators are scalable, explainable, and consistent with human evaluations. Therefore, we adopt widely-used Vicuna pairwise evaluator&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>)</cite> based on ChatGPT to compare the response quality from two LLMs for its accessibility in price and efficiency. The evaluation prompt template is in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F12" title="Figure 12 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">12</span></a>, Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS9" title="A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.9</span></a>. We include GPT-4 based evaluation results in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS6" title="A.6 Consistency between LLM-based Evaluators ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.6</span></a> to demonstrate the consistency of LLM-based evaluators. To mitigate position bias that the LLM evaluator may have, we conduct every evaluation twice by exchanging response orders. A response is considered better only if it wins twice. Following&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib8" title="">2023b</a>)</cite>, we set the temperature to 0.0 to reduce evaluation randomness, and left other parameters as default.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1">Similar to prior work&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>; Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib53" title="">2023</a>)</cite>, we compute the total ratio of wins and ties of a target LLM against the strong LLM, to indicate how much model capacity the target LLM recovers from the strong LLM (often treated as the upper bound performer). CRR simplifies the combinatorial pairwise comparisons between all target LLMs. We name the metric as <em class="ltx_emph ltx_font_italic" id="S5.SS3.p4.1.1">Capacity Recovery Ratio</em> (CRR), where <math alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" class="ltx_Math" display="inline" id="S5.SS3.p4.1.m1.1"><semantics id="S5.SS3.p4.1.m1.1a"><mrow id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml"><mtext id="S5.SS3.p4.1.m1.1.1.2" xref="S5.SS3.p4.1.m1.1.1.2a.cmml">𝙲𝚁𝚁</mtext><mo id="S5.SS3.p4.1.m1.1.1.1" xref="S5.SS3.p4.1.m1.1.1.1.cmml">=</mo><mfrac id="S5.SS3.p4.1.m1.1.1.3" xref="S5.SS3.p4.1.m1.1.1.3.cmml"><mrow id="S5.SS3.p4.1.m1.1.1.3.2" xref="S5.SS3.p4.1.m1.1.1.3.2.cmml"><mtext id="S5.SS3.p4.1.m1.1.1.3.2.2" xref="S5.SS3.p4.1.m1.1.1.3.2.2a.cmml">𝚠𝚒𝚗𝚜</mtext><mo id="S5.SS3.p4.1.m1.1.1.3.2.1" xref="S5.SS3.p4.1.m1.1.1.3.2.1.cmml">+</mo><mtext id="S5.SS3.p4.1.m1.1.1.3.2.3" xref="S5.SS3.p4.1.m1.1.1.3.2.3a.cmml">𝚝𝚒𝚎𝚜</mtext></mrow><mtext id="S5.SS3.p4.1.m1.1.1.3.3" mathvariant="monospace" xref="S5.SS3.p4.1.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><apply id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1"><eq id="S5.SS3.p4.1.m1.1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1.1"></eq><ci id="S5.SS3.p4.1.m1.1.1.2a.cmml" xref="S5.SS3.p4.1.m1.1.1.2"><mtext id="S5.SS3.p4.1.m1.1.1.2.cmml" xref="S5.SS3.p4.1.m1.1.1.2">𝙲𝚁𝚁</mtext></ci><apply id="S5.SS3.p4.1.m1.1.1.3.cmml" xref="S5.SS3.p4.1.m1.1.1.3"><divide id="S5.SS3.p4.1.m1.1.1.3.1.cmml" xref="S5.SS3.p4.1.m1.1.1.3"></divide><apply id="S5.SS3.p4.1.m1.1.1.3.2.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2"><plus id="S5.SS3.p4.1.m1.1.1.3.2.1.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.1"></plus><ci id="S5.SS3.p4.1.m1.1.1.3.2.2a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.2"><mtext id="S5.SS3.p4.1.m1.1.1.3.2.2.cmml" mathsize="70%" xref="S5.SS3.p4.1.m1.1.1.3.2.2">𝚠𝚒𝚗𝚜</mtext></ci><ci id="S5.SS3.p4.1.m1.1.1.3.2.3a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.2.3"><mtext id="S5.SS3.p4.1.m1.1.1.3.2.3.cmml" mathsize="70%" xref="S5.SS3.p4.1.m1.1.1.3.2.3">𝚝𝚒𝚎𝚜</mtext></ci></apply><ci id="S5.SS3.p4.1.m1.1.1.3.3a.cmml" xref="S5.SS3.p4.1.m1.1.1.3.3"><mtext id="S5.SS3.p4.1.m1.1.1.3.3.cmml" mathsize="70%" mathvariant="monospace" xref="S5.SS3.p4.1.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.1.m1.1d">CRR = divide start_ARG wins + ties end_ARG start_ARG total comparisons end_ARG</annotation></semantics></math>. In experiments, we observe that the number of ties often dominates the number of wins, since the strong LLM is much capable than the target model. So we do not put additional weights on wins in the calculation. To demonstrate CRR faithfully reflects model performance, we show the exact number of wins, ties and losses in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS5" title="A.5 Detailed Comparison Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.5</span></a> on Evol-Instruct. We would like to emphasize our focus on the gap in CRR between different methods instead of the absolute value, since the absolute value may based on the specific LLM evaluator we choose.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Open-Domain Instruction Following</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p1.1.1">Results with LLaMA-based Target LLMs.</span> Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.T1" title="Table 1 ‣ 5.3 Experiment and Evaluation Details ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the performance of CodecLM and the comparing baselines with 2000 synthetic data for instruction tuning. All methods are trained on LLaMA-7B or -13B as the target LLM and compared against Gemini-Pro, the strong LLM that generates the data. CodecLM outperforms comparing methods consistently on all benchmarks, with two target LLMs of different sizes. The consistently superior performance of CodecLM highlights its generalizability to different downstream instruction distributions and target LLMs. Both Tree-Instruct and variants of WizardLM focus on the importance of instruction complexity, however, their performances are not always better than Alpagasus with simple instructions, especially with larger target LLM. This observation indicates that the effectiveness of data cannot be solely determined by instruction complexity, and validates the motivation of our design of Self-Rubrics and Contrastive Filtering. Moreover, the win of WizardLM+ over WizardLM confirms the efficacy of instruction distribution matching via instruction metadata. When shifting the target LLM from LLaMA-7B to -13B, all methods get a significant performance boost, which accords with prior discoveries on scaling model size&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib48" title="">2021</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p2.1.1">Results with PaLM-based Models.</span> Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.T2" title="Table 2 ‣ 5.4 Open-Domain Instruction Following ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes the results of CodecLM and the best performing baselines in LLaMA-based experiments. We generate 1000 synthetic data due to computation budget. Since text-bison is a proprietary model that has been aligned with various techniques including instruction tuning, we also include it as a baseline approach. Interestingly, text-bison obtains strong performance across different benchmarks. Both Alpagasus and WizardLM+ underperform text-bison, suggesting it is non-trivial to improve upon a well-tuned LLM continually. CodecLM, on the contrary, outperforms text-bison in most cases, thanks to our core designs that adaptively tailor high quality data pairs to improve the target LLM.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>CRR Results on PaLM-based models. Each method trains a target model based on text-bison, and compares against the strong model, text-unicorn.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:248.2pt;height:92.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-20.2pt,7.6pt) scale(0.86,0.86) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" id="S5.T2.1.1.1.1.1" rowspan="2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S5.T2.1.1.1.1.2" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.2.1">text-bison vs. text-unicorn</span></th>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.2.2.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.2.2.1.1">Evol-Ins.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.2.2.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.2.2.2.1">Vicuna</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.2.2.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.2.2.3.1">Self-Ins.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.1.1.2.2.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.2.2.4.1">Koala</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T2.1.1.3.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">text-bison</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.1.2" style="padding-left:3.0pt;padding-right:3.0pt;">87.16</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.1.3" style="padding-left:3.0pt;padding-right:3.0pt;">81.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.1.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.3.1.4.1">74.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.1.5" style="padding-left:3.0pt;padding-right:3.0pt;">77.47</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T2.1.1.4.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">Alpagasus</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2.2" style="padding-left:3.0pt;padding-right:3.0pt;">82.11<span class="ltx_text" id="S5.T2.1.1.4.2.2.1" style="color:#FF0000;">(-5.1)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2.3" style="padding-left:3.0pt;padding-right:3.0pt;">81.25 <span class="ltx_text" id="S5.T2.1.1.4.2.3.1" style="color:#006B3D;">(+0.0)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2.4" style="padding-left:3.0pt;padding-right:3.0pt;">67.86 <span class="ltx_text" id="S5.T2.1.1.4.2.4.1" style="color:#FF0000;">(-6.4)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.2.5" style="padding-left:3.0pt;padding-right:3.0pt;">73.33 <span class="ltx_text" id="S5.T2.1.1.4.2.5.1" style="color:#FF0000;">(-4.1)</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T2.1.1.5.3.1" style="padding-left:3.0pt;padding-right:3.0pt;">WizardLM+</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.3.2" style="padding-left:3.0pt;padding-right:3.0pt;">84.40 <span class="ltx_text" id="S5.T2.1.1.5.3.2.1" style="color:#FF0000;">(-2.8)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.3.3" style="padding-left:3.0pt;padding-right:3.0pt;">78.75 <span class="ltx_text" id="S5.T2.1.1.5.3.3.1" style="color:#FF0000;">(-2.5)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.3.4" style="padding-left:3.0pt;padding-right:3.0pt;">69.44 <span class="ltx_text" id="S5.T2.1.1.5.3.4.1" style="color:#FF0000;">(-4.8)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.3.5" style="padding-left:3.0pt;padding-right:3.0pt;">73.89 <span class="ltx_text" id="S5.T2.1.1.5.3.5.1" style="color:#FF0000;">(-3.6)</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="S5.T2.1.1.6.4.1" style="padding-left:3.0pt;padding-right:3.0pt;">CodecLM (ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.1.6.4.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.6.4.2.1">88.53 <span class="ltx_text" id="S5.T2.1.1.6.4.2.1.1" style="color:#006B3D;">(+1.4)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.1.6.4.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.6.4.3.1">86.25 <span class="ltx_text" id="S5.T2.1.1.6.4.3.1.1" style="color:#006B3D;">(+5.0)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.1.6.4.4" style="padding-left:3.0pt;padding-right:3.0pt;">72.22 <span class="ltx_text" id="S5.T2.1.1.6.4.4.1" style="color:#FF0000;">(-2.0)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.1.6.4.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.6.4.5.1">80.56 <span class="ltx_text" id="S5.T2.1.1.6.4.5.1.1" style="color:#006B3D;">(+3.1)</span></span></td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Ablation Study</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation study of CodecLM’s core designs. All components contribute to the final performance.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.1" style="width:183.2pt;height:76.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.2pt,6.8pt) scale(0.85,0.85) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T3.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.1.1">Metadata</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.2.1">Self-Rubrics</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" id="S5.T3.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.3.1">Contrastive Filtering</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.4.1">CRR</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.2.2.1">✗</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.2.2.2">✗</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S5.T3.1.1.2.2.3">✗</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.2.2.4">72.02</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.3.3">
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.1">✓</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.2">✗</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S5.T3.1.1.3.3.3">✗</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.3.4">75.23</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.4.4">
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.1">✓</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.2">✓</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S5.T3.1.1.4.4.3">✗</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.4.4">77.52</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.5.5.1">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.5.5.2">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr" id="S5.T3.1.1.5.5.3">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.5.5.4">79.82</td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">In this section, we conduct comprehensive ablation studies to empirically explore the effectiveness of CodecLM. We mainly conduct experiments with LLaMA-7B model as the target LLM, Gemini-Pro as the strong LLM, and report the CRR on the Evol-Instruct benchmark.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p2">
<p class="ltx_p" id="S5.SS5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p2.1.1">Effectiveness of Core Designs.</span>
We show component-wise contributions in our framework in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.T3" title="Table 3 ‣ 5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">3</span></a>. The 1st row has the result from Self-Instruct as a baseline; In the 2nd row, we only align the LLM with basic instructions from instruction metadata; We gradually add Self-Rubrics and Contrastive Filtering in the 3rd and 4th rows, respectively. We clearly observe that every component contributes to the final performance. Interesting, the performance of using basic instructions from metadata is even on par with that of WizardLM+ in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.T1" title="Table 1 ‣ 5.3 Experiment and Evaluation Details ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">1</span></a>. This observation indicates that human-crafted strategies for complicating instructions may not fit different types of instructions. On the contrary, Self-Rubrics adaptively generates instruction improving actions based on different metadata, resulting in better tailored instructions for the target LLM. Further improvements from Contrastive Filtering demonstrate that selected data are indeed more effective for alignment.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p3">
<p class="ltx_p" id="S5.SS5.p3.2"><span class="ltx_text ltx_font_bold" id="S5.SS5.p3.2.1">Effect of Number of Iterations.</span> We demonstrate the effect of number of CodecLM iterations in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.F3" title="Figure 3 ‣ 5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">3</span></a>. In particular, we count the proportion of data from each iteration in all synthesized data <math alttext="\mathcal{D}_{g}" class="ltx_Math" display="inline" id="S5.SS5.p3.1.m1.1"><semantics id="S5.SS5.p3.1.m1.1a"><msub id="S5.SS5.p3.1.m1.1.1" xref="S5.SS5.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p3.1.m1.1.1.2" xref="S5.SS5.p3.1.m1.1.1.2.cmml">𝒟</mi><mi id="S5.SS5.p3.1.m1.1.1.3" xref="S5.SS5.p3.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.1.m1.1b"><apply id="S5.SS5.p3.1.m1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS5.p3.1.m1.1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1">subscript</csymbol><ci id="S5.SS5.p3.1.m1.1.1.2.cmml" xref="S5.SS5.p3.1.m1.1.1.2">𝒟</ci><ci id="S5.SS5.p3.1.m1.1.1.3.cmml" xref="S5.SS5.p3.1.m1.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.1.m1.1c">\mathcal{D}_{g}</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p3.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT</annotation></semantics></math> and show it in the blue bar chart with left y-axis. We also draw the target model performance in CRR after training on the synthetic data up until the current iteration in the yellow line chart with right y-axis. From the data proportion bar chart, we observe that more than <math alttext="70\%" class="ltx_Math" display="inline" id="S5.SS5.p3.2.m2.1"><semantics id="S5.SS5.p3.2.m2.1a"><mrow id="S5.SS5.p3.2.m2.1.1" xref="S5.SS5.p3.2.m2.1.1.cmml"><mn id="S5.SS5.p3.2.m2.1.1.2" xref="S5.SS5.p3.2.m2.1.1.2.cmml">70</mn><mo id="S5.SS5.p3.2.m2.1.1.1" xref="S5.SS5.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.2.m2.1b"><apply id="S5.SS5.p3.2.m2.1.1.cmml" xref="S5.SS5.p3.2.m2.1.1"><csymbol cd="latexml" id="S5.SS5.p3.2.m2.1.1.1.cmml" xref="S5.SS5.p3.2.m2.1.1.1">percent</csymbol><cn id="S5.SS5.p3.2.m2.1.1.2.cmml" type="integer" xref="S5.SS5.p3.2.m2.1.1.2">70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.2.m2.1c">70\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p3.2.m2.1d">70 %</annotation></semantics></math> of the data comes from the first iteration. This indicates Contrastive Filtering successfully collects less complex yet challenging instructions, which are critical for building up the instruction-following ability of the target LLM. Starting from the second iteration, the data proportion gets increasingly small. However, similar to the <em class="ltx_emph ltx_font_italic" id="S5.SS5.p3.2.2">less is more for alignment</em> observation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib55" title="">2023a</a>)</cite>, high-quality and more complex instructions indeed contribute to the final performance despite less in quantity.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="369" id="S5.F3.g1" src="x3.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Data proportion from each iteration and the corresponding CRR performance at each iteration.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="240" id="S5.F4.g1" src="x4.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Metadata matching proportion vs. CRR.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS5.p4">
<p class="ltx_p" id="S5.SS5.p4.4"><span class="ltx_text ltx_font_bold" id="S5.SS5.p4.4.1">Exploration on Distribution Matching.</span> As shown by previous results, generating metadata extracted from the downstream instruction distribution indeed helps. However, in practice, the extracted or human-written metadata may not be able to precisely characterize the instruction distribution. Therefore, it is necessary to explore the performance of CodecLM when the distribution represented by instruction metadata does not fully match the test distribution. As the true test distribution is complicated and not known as a prior, we approximate various extent of distribution matching by random subsampling from the set of metadata <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.SS5.p4.1.m1.1"><semantics id="S5.SS5.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p4.1.m1.1.1" xref="S5.SS5.p4.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.1.m1.1b"><ci id="S5.SS5.p4.1.m1.1.1.cmml" xref="S5.SS5.p4.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.1.m1.1d">caligraphic_M</annotation></semantics></math>.
To control the effect of data quantity, we keep the total number of instruction-response pairs the same for each case. For example, when subsampling <math alttext="20\%" class="ltx_Math" display="inline" id="S5.SS5.p4.2.m2.1"><semantics id="S5.SS5.p4.2.m2.1a"><mrow id="S5.SS5.p4.2.m2.1.1" xref="S5.SS5.p4.2.m2.1.1.cmml"><mn id="S5.SS5.p4.2.m2.1.1.2" xref="S5.SS5.p4.2.m2.1.1.2.cmml">20</mn><mo id="S5.SS5.p4.2.m2.1.1.1" xref="S5.SS5.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.2.m2.1b"><apply id="S5.SS5.p4.2.m2.1.1.cmml" xref="S5.SS5.p4.2.m2.1.1"><csymbol cd="latexml" id="S5.SS5.p4.2.m2.1.1.1.cmml" xref="S5.SS5.p4.2.m2.1.1.1">percent</csymbol><cn id="S5.SS5.p4.2.m2.1.1.2.cmml" type="integer" xref="S5.SS5.p4.2.m2.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.2.m2.1c">20\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.2.m2.1d">20 %</annotation></semantics></math> of <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.SS5.p4.3.m3.1"><semantics id="S5.SS5.p4.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p4.3.m3.1.1" xref="S5.SS5.p4.3.m3.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.3.m3.1b"><ci id="S5.SS5.p4.3.m3.1.1.cmml" xref="S5.SS5.p4.3.m3.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.3.m3.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.3.m3.1d">caligraphic_M</annotation></semantics></math>, we prompt the strong LLM to generate 5 times more instructions for each metadata accordingly. The result is shown in the upper part of Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.F4" title="Figure 4 ‣ 5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4</span></a>, and we did observe the trend that the better instruction metadata captures the underlying distribution, the better performance the target LLM can achieve. Moreover, when the metadata matching proportion is equal or greater than <math alttext="60\%" class="ltx_Math" display="inline" id="S5.SS5.p4.4.m4.1"><semantics id="S5.SS5.p4.4.m4.1a"><mrow id="S5.SS5.p4.4.m4.1.1" xref="S5.SS5.p4.4.m4.1.1.cmml"><mn id="S5.SS5.p4.4.m4.1.1.2" xref="S5.SS5.p4.4.m4.1.1.2.cmml">60</mn><mo id="S5.SS5.p4.4.m4.1.1.1" xref="S5.SS5.p4.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.4.m4.1b"><apply id="S5.SS5.p4.4.m4.1.1.cmml" xref="S5.SS5.p4.4.m4.1.1"><csymbol cd="latexml" id="S5.SS5.p4.4.m4.1.1.1.cmml" xref="S5.SS5.p4.4.m4.1.1.1">percent</csymbol><cn id="S5.SS5.p4.4.m4.1.1.2.cmml" type="integer" xref="S5.SS5.p4.4.m4.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.4.m4.1c">60\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.4.m4.1d">60 %</annotation></semantics></math>, we obtain close performance as the fully-matched result. This observation highlights CodecLM’s robustness under potential instruction metadata mismatch.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="536" id="S5.F5.g1" src="x5.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Scaling with model size and data quantity.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS5.p5">
<p class="ltx_p" id="S5.SS5.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p5.1.1">Scaling with Model Size and Data Quantity.</span> To explore how our method scales with different synthetic data quantities and model sizes, we conduct experiments by comparing CodecLM with WizardLM+, the most competitive baseline. The experiment results on Evol-Instruct with LLaMA-7B and -13B as the target LLM are presented in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.F5" title="Figure 5 ‣ 5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">5</span></a>. Both methods get increasingly better performance with more synthetic data and larger target models. CodecLM consistently outperforms WizardLM+ under all cases, demonstrating its great data efficiency and scalability. We expect the gain will gradually diminish after we generate more than 8k synthetic data, due to the intrinsic ability gap between the target models and the strong LLM.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this work, we propose CodecLM to tailor synthetic data for LLM alignment with different target instruction distributions and LLMs. We show that CodecLM effectively captures the underlying instruction distribution via instruction metadata, and further tailor the most effective instruction-response pairs through Self-Rubrics and Contrastive Filtering. CodecLM provides a potent solution towards adapting LLMs for customized uses, without the necessity of human annotation. We believe CodecLM serves as a general framework for targeted LLM alignment, which opens the door to multiple promising research directions within the framework, such as richer metadata definition, better prompt design, and more reliable LLM-based scorer. CodecLM can also benefit from orthogonal research fields, and we continue the discussion in Ethical Considerations and Limitations sections.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Ethical Considerations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Although CodecLM serves as an effective data synthesis framework for LLM alignment, we should also reflect on the ethical impact of our work. Our method leverages LLMs to generate instruction-response pairs. Similar to human annotators who might make unconscious mistakes during the data annotation process, LLMs also sometimes generate unethical, toxic or misleading instructions and responses&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Bender et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib4" title="">2021</a>)</cite>. Moreover, as we train a target LLM using the generated data, the resulting instruction-tuned LLM might also carry the bias and fairness issues&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gallegos et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib15" title="">2023</a>)</cite> from the original model. Although we conducted manual inspection as specified in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS3" title="A.3 Additional Implementation Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.3</span></a>, in practice, we should adopt existing techniques &nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hanu and Unitary team, <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib17" title="">2020</a>; Thakur et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib43" title="">2023</a>)</cite> to detoxify and mitigate bias from LLMs used in CodecLM, and design more strict inspection and filtering rules to clean up the generated data. Due to the flexibility of our framework, we envision future progress in the domain of reducing bias and fairness issues can be complementary to CodecLM.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Limitations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">We acknowledge the limitations of CodecLM from the following aspects to inspire future research opportunities in the field of LLM alignment.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="Sx2.p2">
<p class="ltx_p" id="Sx2.p2.1">First of all, as discussed in the Ethical Considerations, our method requires a strong LLM to generate the data, so the performance of our method depends on the quality of the LLM and may inherit bias and fairness issues from it. On the other hand, CodecLM can benefit from stronger LLMs improved with advanced bias-reducing and fairness-enhancing approaches.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="Sx2.p3">
<p class="ltx_p" id="Sx2.p3.1">Secondly, as an orthogonal direction, our method did not explore robustness of the instruction-tuned model towards adversarial attacks such as prompt injection&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib31" title="">2023</a>)</cite> and jailbreaking&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib57" title="">2023</a>)</cite>. In practice, we should apply adversarial defense techniques&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Jain et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib22" title="">2023</a>)</cite> accordingly to the instruction-tuned LLM from our method.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="Sx2.p4">
<p class="ltx_p" id="Sx2.p4.1">Moreover, we mainly use LLM-based automatic evaluation methods following recent works in data synthesis for alignment. Although recent studies&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>; Dubois et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib12" title="">2023</a>)</cite> demonstrate LLM-based evaluation is largely consistent with human evaluation, the scalability and reliability of LLM-based evaluators still have room for improvements. Although we include some standard benchmark results in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.SS7" title="A.7 Additional Benchmark Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">A.7</span></a> to complement LLM-based evaluation results, we still believe the progress in better evaluating LLMs can lead to a more reliable demonstration of the effectiveness of our method.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="Sx2.p5">
<p class="ltx_p" id="Sx2.p5.1">Finally, as shown in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.SS5" title="5.5 Ablation Study ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">5.5</span></a>, although CodecLM is robust to moderate distribution mismatch, its performance still depends on how well the metadata captures the underlying instruction distribution. In practice, our collected seed instruction might differ from the actual test instructions. Or in the case that we directly create metadata from user specification, the users might change their mind at test time to send the model out-of-distribution instructions beyond the original metadata. As a consequence, CodecLM may suffer performance degradation under distribution mismatch. As a remedy, we can constantly collect user instruction traffic or user feedback to update the generated data from CodecLM, and continuously update the target LLM.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="Sx2.p6">
<p class="ltx_p" id="Sx2.p6.1">We hope future work can leverage CodecLM as a flexible data synthesis framework for LLM alignment, so that advances in the field can be integrated into CodecLM to reduce its current limitations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rohan Anil, Andrew&nbsp;M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,
Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen,
et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Palm 2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2305.10403</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aribandi et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Vamsi Aribandi, Yi&nbsp;Tay, Tal Schuster, Jinfeng Rao, Huaixiu&nbsp;Steven Zheng,
Sanket&nbsp;Vaibhav Mehta, Honglei Zhuang, Vinh&nbsp;Q Tran, Dara Bahri, Jianmo Ni,
et&nbsp;al. 2021.

</span>
<span class="ltx_bibblock">Ext5: Towards extreme multi-task scaling for transfer learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2111.10952</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Training a helpful and harmless assistant with reinforcement learning
from human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2204.05862</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Emily&nbsp;M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
Shmitchell. 2021.

</span>
<span class="ltx_bibblock">On the dangers of stochastic parrots: Can language models be too big?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 2021 ACM conference on fairness,
accountability, and transparency</em>, pages 610–623.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beyer et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lucas Beyer, Xiaohua Zhai, Amélie Royer, Larisa Markeeva, Rohan Anil, and
Alexander Kolesnikov. 2022.

</span>
<span class="ltx_bibblock">Knowledge distillation: A good teacher is patient and consistent.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pages 10925–10934.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Advances in neural information processing systems</em>,
33:1877–1901.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Derek Chen, Celine Lee, Yunan Lu, Domenic Rosati, and Zhou Yu.
2023a.

</span>
<span class="ltx_bibblock">Mixture of soft prompts for controllable data generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2303.01580</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav,
Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et&nbsp;al.
2023b.

</span>
<span class="ltx_bibblock">Alpagasus: Training a better alpaca with fewer data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2307.08701</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Zhuohan Li, Zi&nbsp;Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph&nbsp;E. Gonzalez, Ion Stoica, and
Eric&nbsp;P. Xing. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://lmsys.org/blog/2023-03-30-vicuna/" title="">Vicuna: An
open-source chatbot impressing gpt-4 with 90%* chatgpt quality</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus,
Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2210.11416</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Dong, Zhilin Wang, Makesh&nbsp;Narsimhan Sreedhar, Xianchao Wu, and Oleksii
Kuchaiev. 2023.

</span>
<span class="ltx_bibblock">Steerlm: Attribute conditioned sft as an (user-steerable) alternative
to rlhf.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2310.05344</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubois et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba,
Carlos Guestrin, Percy Liang, and Tatsunori&nbsp;B Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Alpacafarm: A simulation framework for methods that learn from human
feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2305.14387</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Efrat and Levy (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Avia Efrat and Omer Levy. 2020.

</span>
<span class="ltx_bibblock">The turking test: Can language models understand instructions?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2010.11982</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernando et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim
Rocktäschel. 2023.

</span>
<span class="ltx_bibblock">Promptbreeder: Self-referential self-improvement via prompt
evolution.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2309.16797</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gallegos et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Isabel&nbsp;O Gallegos, Ryan&nbsp;A Rossi, Joe Barrow, Md&nbsp;Mehrab Tanjim, Sungchul Kim,
Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen&nbsp;K Ahmed. 2023.

</span>
<span class="ltx_bibblock">Bias and fairness in large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2309.00770</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wallace, Pieter Abbeel, Sergey
Levine, and Dawn Song. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://bair.berkeley.edu/blog/2023/04/03/koala/" title="">Koala: A
dialogue model for academic research</a>.

</span>
<span class="ltx_bibblock">Blog post.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanu and Unitary team (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Laura Hanu and Unitary team. 2020.

</span>
<span class="ltx_bibblock">Detoxify.

</span>
<span class="ltx_bibblock">Github. https://github.com/unitaryai/detoxify.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn
Song, and Jacob Steinhardt. 2020.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2009.03300</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et&nbsp;al. (2015)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:1503.02531</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Or&nbsp;Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022.

</span>
<span class="ltx_bibblock">Unnatural instructions: Tuning language models with (almost) no human
labor.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2212.09689</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsieh et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii,
Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023.

</span>
<span class="ltx_bibblock">Distilling step-by-step! outperforming larger language models with
less training data and smaller model sizes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2305.02301</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer,
Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, and Tom
Goldstein. 2023.

</span>
<span class="ltx_bibblock">Baseline defenses for adversarial attacks against aligned language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2309.00614</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Welling (2013)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Diederik&nbsp;P Kingma and Max Welling. 2013.

</span>
<span class="ltx_bibblock">Auto-encoding variational bayes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:1312.6114</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Köpf et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis,
Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen&nbsp;Minh Duc, Oliver
Stanley, Richárd Nagyfi, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Openassistant conversations–democratizing large language model
alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2304.07327</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kramer (1991)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mark&nbsp;A Kramer. 1991.

</span>
<span class="ltx_bibblock">Nonlinear principal component analysis using autoassociative neural
networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">AIChE journal</em>, 37(2):233–243.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gyeong-Geon Lee, Ehsan Latif, Xuansheng Wu, Ninghao Liu, and Xiaoming Zhai.
2023.

</span>
<span class="ltx_bibblock">Applying large language models and chain-of-thought for automatic
scoring.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2312.03748</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy,
Jason Weston, and Mike Lewis. 2023.

</span>
<span class="ltx_bibblock">Self-alignment with instruction backtranslation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2308.06259</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiang&nbsp;Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori
Hashimoto, Luke Zettlemoyer, and Mike Lewis. 2022.

</span>
<span class="ltx_bibblock">Contrastive decoding: Open-ended text generation as optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2210.15097</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chen Liang, Simiao Zuo, Qingru Zhang, Pengcheng He, Weizhu Chen, and Tuo Zhao.
2023.

</span>
<span class="ltx_bibblock">Less is more: Task-aware layer-wise distillation for language model
compression.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">International Conference on Machine Learning</em>, pages
20852–20867. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alisa Liu, Swabha Swayamdipta, Noah&nbsp;A Smith, and Yejin Choi. 2022.

</span>
<span class="ltx_bibblock">Wanli: Worker and ai collaboration for natural language inference
dataset creation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2201.05955</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu
Wang, Yan Zheng, and Yang Liu. 2023.

</span>
<span class="ltx_bibblock">Prompt injection attack against llm-integrated applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2306.05499</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaan et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah
Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et&nbsp;al.
2023.

</span>
<span class="ltx_bibblock">Self-refine: Iterative refinement with self-feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2303.17651</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yu&nbsp;Meng, Martin Michalski, Jiaxin Huang, Yu&nbsp;Zhang, Tarek Abdelzaher, and Jiawei
Han. 2023.

</span>
<span class="ltx_bibblock">Tuning language models as training data generators for
augmentation-enhanced few-shot learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">International Conference on Machine Learning</em>, pages
24457–24477. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI. 2023a.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">ArXiv</em>, abs/2303.08774.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI. 2023b.

</span>
<span class="ltx_bibblock">Introducing gpts.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/blog/introducing-gpts" title="">https://openai.com/blog/introducing-gpts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Advances in Neural Information Processing Systems</em>,
35:27730–27744.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023.

</span>
<span class="ltx_bibblock">Instruction tuning with gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2304.03277</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">The Journal of Machine Learning Research</em>, 21(1):5485–5551.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick and Schütze (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Timo Schick and Hinrich Schütze. 2021.

</span>
<span class="ltx_bibblock">Generating datasets with pretrained language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2104.07540</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suzgun et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi&nbsp;Tay,
Hyung&nbsp;Won Chung, Aakanksha Chowdhery, Quoc&nbsp;V Le, Ed&nbsp;H Chi, Denny Zhou, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock">Challenging big-bench tasks and whether chain-of-thought can solve
them.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2210.09261</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" title="">https://github.com/tatsu-lab/stanford_alpaca</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac,
Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew&nbsp;M Dai, Anja Hauth, et&nbsp;al.
2023.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2312.11805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thakur et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, Paul&nbsp;Pu Liang, and
Louis-Philippe Morency. 2023.

</span>
<span class="ltx_bibblock">Language models get a gender makeover: Mitigating gender bias with
few-shot data interventions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2306.04597</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Victor et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sanh Victor, Webson Albert, Raffel Colin, Bach Stephen, Sutawika Lintang,
Alyafeai Zaid, Chaffin Antoine, Stiegler Arnaud, Raja Arun, Dey Manan, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock">Multitask prompted training enables zero-shot task generalization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot,
Khyathi&nbsp;Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah&nbsp;A Smith,
Iz&nbsp;Beltagy, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">How far can camels go? exploring the state of instruction tuning on
open resources.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2306.04751</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A Smith, Daniel
Khashabi, and Hannaneh Hajishirzi. 2022.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language model with self generated
instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2212.10560</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent&nbsp;Y Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian
Lester, Nan Du, Andrew&nbsp;M Dai, and Quoc&nbsp;V Le. 2021.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2109.01652</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed&nbsp;Chi, Quoc&nbsp;V
Le, Denny Zhou, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Advances in Neural Information Processing Systems</em>,
35:24824–24837.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu&nbsp;Zhao, Jiazhan Feng, Chongyang
Tao, and Daxin Jiang. 2023.

</span>
<span class="ltx_bibblock">Wizardlm: Empowering large language models to follow complex
instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:2304.12244</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc&nbsp;V Le, Denny Zhou, and
Xinyun Chen. 2023.

</span>
<span class="ltx_bibblock">Large language models as optimizers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2309.03409</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu&nbsp;Meng, Alexander Ratner, Ranjay Krishna,
Jiaming Shen, and Chao Zhang. 2023.

</span>
<span class="ltx_bibblock">Large language model as attributed training data generator: A tale of
diversity and bias.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv preprint arXiv:2306.15895</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yingxiu Zhao, Bowen Yu, Binyuan Hui, Haiyang Yu, Fei Huang, Yongbin Li, and
Nevin&nbsp;L Zhang. 2023.

</span>
<span class="ltx_bibblock">A preliminary study of the intrinsic relationship between complexity
and alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:2308.05696</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao
Zhuang, Zi&nbsp;Lin, Zhuohan Li, Dacheng Li, Eric Xing, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">arXiv preprint arXiv:2306.05685</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe
Ma, Avia Efrat, Ping Yu, Lili Yu, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">arXiv preprint arXiv:2305.11206</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu,
Yi&nbsp;Luan, Denny Zhou, and Le&nbsp;Hou. 2023b.

</span>
<span class="ltx_bibblock">Instruction-following evaluation for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:2311.07911</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andy Zou, Zifan Wang, J.&nbsp;Zico Kolter, and Matt Fredrikson. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2307.15043" title="">Universal and transferable
adversarial attacks on aligned language models</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Benchmark Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">The details of the open-instruction following benchmarks are included below:
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1">Evol-Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite> includes 218 real-world human instructions from diverse sources such as online open-source projects, platforms, and forums.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1">Vicuna&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>)</cite> includes 80 diverse instructions generated by GPT-4 through prompt engineering.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1">Self-Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>)</cite> includes 252 expert-written instructions motivated by user-oriented applications.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p" id="A1.I1.i4.p1.1">Koala&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Geng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib16" title="">2023</a>)</cite> includes 180 conversation-style real user instructions that were posted online.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
<p class="ltx_p" id="A1.SS1.p1.2">All these benchmarks consist of English instructions from multiple categories or tasks. However, though sharing some common use cases such as general knowledge QA and coding, the coverage of the instructions in different benchmarks are indeed different. For example, &nbsp;<cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite> discuss in detail how Evol-Instruct is different from Vicuna in instruction distribution. The difference between instruction distributions effectively mimic the practical scenario where we have different downstream tasks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1">The details of the additional standard NLP benchmarks are included below:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A1.I2">
<li class="ltx_item" id="A1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i1.p1">
<p class="ltx_p" id="A1.I2.i1.p1.1">MMLU&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib18" title="">2020</a>)</cite>, Massive Multitask Language Understanding, is a benchmark designed to measure capability of language models. It covers 57 subjects across STEM, the humanities, the social sciences, and more areas. We only use the test split for reporting the test results, and report the average score across all tasks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i2.p1">
<p class="ltx_p" id="A1.I2.i2.p1.1">BBH&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib40" title="">2022</a>)</cite>, BIG-Bench-Hard, includes 23 challenging BIG-Bench tasks that prior language models did not outperform average human-raters.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A1.SS1.p3">
<p class="ltx_p" id="A1.SS1.p3.1">All benchmarks are publicly available for non-commercial research purposes, and we strictly limit their usage in this research work. We also carefully check these datasets and make sure that no personal information is involved.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Baseline Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p1.1.1">Self-Instruct</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib47" title="">2022</a>)</cite> generates instructions by prompting LLM with existing seed instructions as few-shot demonstrations. Here we randomly subsample the Alpaca&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib41" title="">2023</a>)</cite> dataset as seed instructions. Since Alpaca itself is based on Self-Instruct, using its subset as seed is a natural continuation of the Self-Instruct method.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS2.p2">
<p class="ltx_p" id="A1.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p2.1.1">Alpagasus</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib8" title="">2023b</a>)</cite> selectively filters data using ChatGPT-based response quality evaluator. Closely following the original approach, we adopt the strategy upon instruction-response pairs generated by Self-Instruct.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS2.p3">
<p class="ltx_p" id="A1.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p3.1.1">Tree-Instruct</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib53" title="">2023</a>)</cite> improves instruction quality by prompting the LLM to implicitly complicate instruction through its semantic tree. Following the original paper, we use the subsampled Alpaca dataset as seed data. We set the number of tree nodes to 10 for best possible performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS2.p4">
<p class="ltx_p" id="A1.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p4.1.1">WizardLM</span> <cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite> iteratively complicates instructions by prompting the LLM with a set of pre-defined evolution operations. Given the popularity and effectiveness of WizardLM, we experiment it with two variants: the original version using Alpaca as seed data, and the enhanced version uses the same set of basic instructions generated from CodecLM as seed data. We name the later variant as <span class="ltx_text ltx_font_bold" id="A1.SS2.p4.1.2">WizardLM+</span> as its enhanced by components of our framework.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Additional Implementation Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.2">We augment the metadata to 200 by mix-and-matching use cases and skills from different instructions. We randomly sample one use case from <math alttext="\{u_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="A1.SS3.p1.1.m1.1"><semantics id="A1.SS3.p1.1.m1.1a"><msubsup id="A1.SS3.p1.1.m1.1.1" xref="A1.SS3.p1.1.m1.1.1.cmml"><mrow id="A1.SS3.p1.1.m1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.1.1.1.1.2.cmml"><mo id="A1.SS3.p1.1.m1.1.1.1.1.1.2" stretchy="false" xref="A1.SS3.p1.1.m1.1.1.1.1.2.cmml">{</mo><msub id="A1.SS3.p1.1.m1.1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.cmml"><mi id="A1.SS3.p1.1.m1.1.1.1.1.1.1.2" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.2.cmml">u</mi><mi id="A1.SS3.p1.1.m1.1.1.1.1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.SS3.p1.1.m1.1.1.1.1.1.3" stretchy="false" xref="A1.SS3.p1.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="A1.SS3.p1.1.m1.1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.1.3.cmml"><mi id="A1.SS3.p1.1.m1.1.1.1.3.2" xref="A1.SS3.p1.1.m1.1.1.1.3.2.cmml">i</mi><mo id="A1.SS3.p1.1.m1.1.1.1.3.1" xref="A1.SS3.p1.1.m1.1.1.1.3.1.cmml">=</mo><mn id="A1.SS3.p1.1.m1.1.1.1.3.3" xref="A1.SS3.p1.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="A1.SS3.p1.1.m1.1.1.3" xref="A1.SS3.p1.1.m1.1.1.3.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.1.m1.1b"><apply id="A1.SS3.p1.1.m1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1">superscript</csymbol><apply id="A1.SS3.p1.1.m1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1">subscript</csymbol><set id="A1.SS3.p1.1.m1.1.1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1"><apply id="A1.SS3.p1.1.m1.1.1.1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="A1.SS3.p1.1.m1.1.1.1.1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.2">𝑢</ci><ci id="A1.SS3.p1.1.m1.1.1.1.1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="A1.SS3.p1.1.m1.1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3"><eq id="A1.SS3.p1.1.m1.1.1.1.3.1.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3.1"></eq><ci id="A1.SS3.p1.1.m1.1.1.1.3.2.cmml" xref="A1.SS3.p1.1.m1.1.1.1.3.2">𝑖</ci><cn id="A1.SS3.p1.1.m1.1.1.1.3.3.cmml" type="integer" xref="A1.SS3.p1.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="A1.SS3.p1.1.m1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.1.m1.1c">\{u_{i}\}_{i=1}^{n}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.p1.1.m1.1d">{ italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math>, and pair it with one or more skills sampled without replacement from <math alttext="\bigcup_{i=1}^{n}{\bm{s}}_{i}" class="ltx_Math" display="inline" id="A1.SS3.p1.2.m2.1"><semantics id="A1.SS3.p1.2.m2.1a"><mrow id="A1.SS3.p1.2.m2.1.1" xref="A1.SS3.p1.2.m2.1.1.cmml"><msubsup id="A1.SS3.p1.2.m2.1.1.1" xref="A1.SS3.p1.2.m2.1.1.1.cmml"><mo id="A1.SS3.p1.2.m2.1.1.1.2.2" xref="A1.SS3.p1.2.m2.1.1.1.2.2.cmml">⋃</mo><mrow id="A1.SS3.p1.2.m2.1.1.1.2.3" xref="A1.SS3.p1.2.m2.1.1.1.2.3.cmml"><mi id="A1.SS3.p1.2.m2.1.1.1.2.3.2" xref="A1.SS3.p1.2.m2.1.1.1.2.3.2.cmml">i</mi><mo id="A1.SS3.p1.2.m2.1.1.1.2.3.1" xref="A1.SS3.p1.2.m2.1.1.1.2.3.1.cmml">=</mo><mn id="A1.SS3.p1.2.m2.1.1.1.2.3.3" xref="A1.SS3.p1.2.m2.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="A1.SS3.p1.2.m2.1.1.1.3" xref="A1.SS3.p1.2.m2.1.1.1.3.cmml">n</mi></msubsup><msub id="A1.SS3.p1.2.m2.1.1.2" xref="A1.SS3.p1.2.m2.1.1.2.cmml"><mi id="A1.SS3.p1.2.m2.1.1.2.2" xref="A1.SS3.p1.2.m2.1.1.2.2.cmml">𝒔</mi><mi id="A1.SS3.p1.2.m2.1.1.2.3" xref="A1.SS3.p1.2.m2.1.1.2.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.2.m2.1b"><apply id="A1.SS3.p1.2.m2.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1"><apply id="A1.SS3.p1.2.m2.1.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1">superscript</csymbol><apply id="A1.SS3.p1.2.m2.1.1.1.2.cmml" xref="A1.SS3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.1.2.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1">subscript</csymbol><union id="A1.SS3.p1.2.m2.1.1.1.2.2.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.2"></union><apply id="A1.SS3.p1.2.m2.1.1.1.2.3.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3"><eq id="A1.SS3.p1.2.m2.1.1.1.2.3.1.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3.1"></eq><ci id="A1.SS3.p1.2.m2.1.1.1.2.3.2.cmml" xref="A1.SS3.p1.2.m2.1.1.1.2.3.2">𝑖</ci><cn id="A1.SS3.p1.2.m2.1.1.1.2.3.3.cmml" type="integer" xref="A1.SS3.p1.2.m2.1.1.1.2.3.3">1</cn></apply></apply><ci id="A1.SS3.p1.2.m2.1.1.1.3.cmml" xref="A1.SS3.p1.2.m2.1.1.1.3">𝑛</ci></apply><apply id="A1.SS3.p1.2.m2.1.1.2.cmml" xref="A1.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.2.1.cmml" xref="A1.SS3.p1.2.m2.1.1.2">subscript</csymbol><ci id="A1.SS3.p1.2.m2.1.1.2.2.cmml" xref="A1.SS3.p1.2.m2.1.1.2.2">𝒔</ci><ci id="A1.SS3.p1.2.m2.1.1.2.3.cmml" xref="A1.SS3.p1.2.m2.1.1.2.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.2.m2.1c">\bigcup_{i=1}^{n}{\bm{s}}_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.p1.2.m2.1d">⋃ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. Although most skills are generalizable between use cases, we still conduct manual sanity check to exclude unreasonable use case and skills pairs.
We align our hyperparameters for iteratively improving instructions via Self-Rubrics with prior work&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib50" title="">2023</a>)</cite>: We generate 4 rubrics and corresponding actions, and at each iteration, we randomly choose 1 action for improving instruction. For fair comparison with WizardLM, we also use at most 4 improve iterations for each instruction (we count basic prompt generation as the first iteration). For Contrastive Filtering, we always use the strong LLM itself as the scorer. We set the scoring scale to 10 and the filtering threshold to 3 for all experiments. We obtain the threshold by developing on the AlpacaEval&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dubois et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib12" title="">2023</a>)</cite> dataset. And we find this threshold works generally well across different settings. Moreover, for LLaMA-based models, using their Alpaca&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib41" title="">2023</a>)</cite> counterparts as the target LLM for response generation in Contrastive Filtering works better than the original model that is not instruction tuned. For metadata extraction, base instruction generation and Self-Rubrics, we use a inference temperature of 0.7. We set the maximum number of tokens for generation to 2048 for LLaMA-based models, and 1024 for PaLM-based models due to API constraints. Moreover, although we set aside 20% validation set for metadata extraction, we still report the performance on the full test set in the main paper, the reasons are as follows: (1) We observe removing the validation set from the full test benchmark will not change the relative superior performance of our method, the performance gap between our method and baselines remains almost the same. Therefore, we keep them in for better reproducibility. (2) By carefully checking the generated instructions, we notice that none of the generated instructions overlap with the original validation instructions, so no data leaking happens during the data generation process.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.p2">
<p class="ltx_p" id="A1.SS3.p2.1">We conduct manual inspection on the generated data to make sure no personal information or offensive contents are generated.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Training Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS4.p1">
<p class="ltx_p" id="A1.SS4.p1.3">For LLaMA-based models, we follow the practices in instruction tuning in prior works&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib55" title="">2023a</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib8" title="">2023b</a>)</cite>. We use AdamW optimizer with <math alttext="\beta_{1}=0.9,\beta_{2}=0.95" class="ltx_Math" display="inline" id="A1.SS4.p1.1.m1.2"><semantics id="A1.SS4.p1.1.m1.2a"><mrow id="A1.SS4.p1.1.m1.2.2.2" xref="A1.SS4.p1.1.m1.2.2.3.cmml"><mrow id="A1.SS4.p1.1.m1.1.1.1.1" xref="A1.SS4.p1.1.m1.1.1.1.1.cmml"><msub id="A1.SS4.p1.1.m1.1.1.1.1.2" xref="A1.SS4.p1.1.m1.1.1.1.1.2.cmml"><mi id="A1.SS4.p1.1.m1.1.1.1.1.2.2" xref="A1.SS4.p1.1.m1.1.1.1.1.2.2.cmml">β</mi><mn id="A1.SS4.p1.1.m1.1.1.1.1.2.3" xref="A1.SS4.p1.1.m1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="A1.SS4.p1.1.m1.1.1.1.1.1" xref="A1.SS4.p1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="A1.SS4.p1.1.m1.1.1.1.1.3" xref="A1.SS4.p1.1.m1.1.1.1.1.3.cmml">0.9</mn></mrow><mo id="A1.SS4.p1.1.m1.2.2.2.3" xref="A1.SS4.p1.1.m1.2.2.3a.cmml">,</mo><mrow id="A1.SS4.p1.1.m1.2.2.2.2" xref="A1.SS4.p1.1.m1.2.2.2.2.cmml"><msub id="A1.SS4.p1.1.m1.2.2.2.2.2" xref="A1.SS4.p1.1.m1.2.2.2.2.2.cmml"><mi id="A1.SS4.p1.1.m1.2.2.2.2.2.2" xref="A1.SS4.p1.1.m1.2.2.2.2.2.2.cmml">β</mi><mn id="A1.SS4.p1.1.m1.2.2.2.2.2.3" xref="A1.SS4.p1.1.m1.2.2.2.2.2.3.cmml">2</mn></msub><mo id="A1.SS4.p1.1.m1.2.2.2.2.1" xref="A1.SS4.p1.1.m1.2.2.2.2.1.cmml">=</mo><mn id="A1.SS4.p1.1.m1.2.2.2.2.3" xref="A1.SS4.p1.1.m1.2.2.2.2.3.cmml">0.95</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.1.m1.2b"><apply id="A1.SS4.p1.1.m1.2.2.3.cmml" xref="A1.SS4.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.2.2.3a.cmml" xref="A1.SS4.p1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="A1.SS4.p1.1.m1.1.1.1.1.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1"><eq id="A1.SS4.p1.1.m1.1.1.1.1.1.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.1"></eq><apply id="A1.SS4.p1.1.m1.1.1.1.1.2.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.1.1.1.1.2.1.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2">subscript</csymbol><ci id="A1.SS4.p1.1.m1.1.1.1.1.2.2.cmml" xref="A1.SS4.p1.1.m1.1.1.1.1.2.2">𝛽</ci><cn id="A1.SS4.p1.1.m1.1.1.1.1.2.3.cmml" type="integer" xref="A1.SS4.p1.1.m1.1.1.1.1.2.3">1</cn></apply><cn id="A1.SS4.p1.1.m1.1.1.1.1.3.cmml" type="float" xref="A1.SS4.p1.1.m1.1.1.1.1.3">0.9</cn></apply><apply id="A1.SS4.p1.1.m1.2.2.2.2.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2"><eq id="A1.SS4.p1.1.m1.2.2.2.2.1.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.1"></eq><apply id="A1.SS4.p1.1.m1.2.2.2.2.2.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.2.2.2.2.2.1.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="A1.SS4.p1.1.m1.2.2.2.2.2.2.cmml" xref="A1.SS4.p1.1.m1.2.2.2.2.2.2">𝛽</ci><cn id="A1.SS4.p1.1.m1.2.2.2.2.2.3.cmml" type="integer" xref="A1.SS4.p1.1.m1.2.2.2.2.2.3">2</cn></apply><cn id="A1.SS4.p1.1.m1.2.2.2.2.3.cmml" type="float" xref="A1.SS4.p1.1.m1.2.2.2.2.3">0.95</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.1.m1.2c">\beta_{1}=0.9,\beta_{2}=0.95</annotation><annotation encoding="application/x-llamapun" id="A1.SS4.p1.1.m1.2d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9 , italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.95</annotation></semantics></math> to finetune the target model for 15 epochs, as suggested by <cite class="ltx_cite ltx_citemacro_citet">Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib55" title="">2023a</a>)</cite> for smaller data size.
We set the initial learning rate to <math alttext="1\times 10^{-5}" class="ltx_Math" display="inline" id="A1.SS4.p1.2.m2.1"><semantics id="A1.SS4.p1.2.m2.1a"><mrow id="A1.SS4.p1.2.m2.1.1" xref="A1.SS4.p1.2.m2.1.1.cmml"><mn id="A1.SS4.p1.2.m2.1.1.2" xref="A1.SS4.p1.2.m2.1.1.2.cmml">1</mn><mo id="A1.SS4.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS4.p1.2.m2.1.1.1.cmml">×</mo><msup id="A1.SS4.p1.2.m2.1.1.3" xref="A1.SS4.p1.2.m2.1.1.3.cmml"><mn id="A1.SS4.p1.2.m2.1.1.3.2" xref="A1.SS4.p1.2.m2.1.1.3.2.cmml">10</mn><mrow id="A1.SS4.p1.2.m2.1.1.3.3" xref="A1.SS4.p1.2.m2.1.1.3.3.cmml"><mo id="A1.SS4.p1.2.m2.1.1.3.3a" xref="A1.SS4.p1.2.m2.1.1.3.3.cmml">−</mo><mn id="A1.SS4.p1.2.m2.1.1.3.3.2" xref="A1.SS4.p1.2.m2.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.2.m2.1b"><apply id="A1.SS4.p1.2.m2.1.1.cmml" xref="A1.SS4.p1.2.m2.1.1"><times id="A1.SS4.p1.2.m2.1.1.1.cmml" xref="A1.SS4.p1.2.m2.1.1.1"></times><cn id="A1.SS4.p1.2.m2.1.1.2.cmml" type="integer" xref="A1.SS4.p1.2.m2.1.1.2">1</cn><apply id="A1.SS4.p1.2.m2.1.1.3.cmml" xref="A1.SS4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="A1.SS4.p1.2.m2.1.1.3.1.cmml" xref="A1.SS4.p1.2.m2.1.1.3">superscript</csymbol><cn id="A1.SS4.p1.2.m2.1.1.3.2.cmml" type="integer" xref="A1.SS4.p1.2.m2.1.1.3.2">10</cn><apply id="A1.SS4.p1.2.m2.1.1.3.3.cmml" xref="A1.SS4.p1.2.m2.1.1.3.3"><minus id="A1.SS4.p1.2.m2.1.1.3.3.1.cmml" xref="A1.SS4.p1.2.m2.1.1.3.3"></minus><cn id="A1.SS4.p1.2.m2.1.1.3.3.2.cmml" type="integer" xref="A1.SS4.p1.2.m2.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.2.m2.1c">1\times 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="A1.SS4.p1.2.m2.1d">1 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math> and linearly decaying to <math alttext="1\times 10^{-6}" class="ltx_Math" display="inline" id="A1.SS4.p1.3.m3.1"><semantics id="A1.SS4.p1.3.m3.1a"><mrow id="A1.SS4.p1.3.m3.1.1" xref="A1.SS4.p1.3.m3.1.1.cmml"><mn id="A1.SS4.p1.3.m3.1.1.2" xref="A1.SS4.p1.3.m3.1.1.2.cmml">1</mn><mo id="A1.SS4.p1.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS4.p1.3.m3.1.1.1.cmml">×</mo><msup id="A1.SS4.p1.3.m3.1.1.3" xref="A1.SS4.p1.3.m3.1.1.3.cmml"><mn id="A1.SS4.p1.3.m3.1.1.3.2" xref="A1.SS4.p1.3.m3.1.1.3.2.cmml">10</mn><mrow id="A1.SS4.p1.3.m3.1.1.3.3" xref="A1.SS4.p1.3.m3.1.1.3.3.cmml"><mo id="A1.SS4.p1.3.m3.1.1.3.3a" xref="A1.SS4.p1.3.m3.1.1.3.3.cmml">−</mo><mn id="A1.SS4.p1.3.m3.1.1.3.3.2" xref="A1.SS4.p1.3.m3.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.3.m3.1b"><apply id="A1.SS4.p1.3.m3.1.1.cmml" xref="A1.SS4.p1.3.m3.1.1"><times id="A1.SS4.p1.3.m3.1.1.1.cmml" xref="A1.SS4.p1.3.m3.1.1.1"></times><cn id="A1.SS4.p1.3.m3.1.1.2.cmml" type="integer" xref="A1.SS4.p1.3.m3.1.1.2">1</cn><apply id="A1.SS4.p1.3.m3.1.1.3.cmml" xref="A1.SS4.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A1.SS4.p1.3.m3.1.1.3.1.cmml" xref="A1.SS4.p1.3.m3.1.1.3">superscript</csymbol><cn id="A1.SS4.p1.3.m3.1.1.3.2.cmml" type="integer" xref="A1.SS4.p1.3.m3.1.1.3.2">10</cn><apply id="A1.SS4.p1.3.m3.1.1.3.3.cmml" xref="A1.SS4.p1.3.m3.1.1.3.3"><minus id="A1.SS4.p1.3.m3.1.1.3.3.1.cmml" xref="A1.SS4.p1.3.m3.1.1.3.3"></minus><cn id="A1.SS4.p1.3.m3.1.1.3.3.2.cmml" type="integer" xref="A1.SS4.p1.3.m3.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.3.m3.1c">1\times 10^{-6}</annotation><annotation encoding="application/x-llamapun" id="A1.SS4.p1.3.m3.1d">1 × 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT</annotation></semantics></math> by the end of training. We set per GPU batch size to 8, which is equivalent to a total batch size of 64,
as we use 8 A100 GPUs for training. The maximum token length is set to 2048.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS4.p2">
<p class="ltx_p" id="A1.SS4.p2.1">For PaLM-based models, we follow the default instruction tuning setting on Google Cloud’s LLM tuning web UI. We set the number of tuning steps to 2000, the learning rate multiplier to 1, and use the TPU training option.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Additional results on standard benchmarks.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T4.1" style="width:165.3pt;height:88.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-1.7pt,0.9pt) scale(0.98,0.98) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T4.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T4.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" id="A1.T4.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T4.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.1.2.1">BBH</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T4.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.1.3.1">MMLU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T4.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.1.4.1">Average</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T4.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="A1.T4.1.1.2.1.1">LLaMA-7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T4.1.1.2.1.2">30.93</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T4.1.1.2.1.3">35.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T4.1.1.2.1.4">33.05</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="A1.T4.1.1.3.2.1">Alpagasus</th>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.3.2.2">31.55</td>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.3.2.3">36.46</td>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.3.2.4">34.01</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="A1.T4.1.1.4.3.1">WizardLM+</th>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.4.3.2">31.72</td>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.4.3.3">37.89</td>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.4.3.4">34.81</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="A1.T4.1.1.5.4.1">CodecLM (ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T4.1.1.5.4.2"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.5.4.2.1">32.60</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T4.1.1.5.4.3"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.5.4.3.1">42.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T4.1.1.5.4.4"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.5.4.4.1">37.64</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A1.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Detailed Comparison Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS5.p1">
<p class="ltx_p" id="A1.SS5.p1.1">We show the details of pairwise comparison on Evol-Instruct benchmark with LLaMA-based models, as a demonstration of how CRR faithfully reflects the capability of the target LLMs trained by different methods. In Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.T5" title="Table 5 ‣ A.5 Detailed Comparison Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">5</span></a>, we observe that number of ties dominates the results and the number of wins are scarce. We attribute it to the fact that the target model is essentially distilling knowledge from the strong model. As a result, most of the time, the instruction-tuned target model is only able to respond as good as the strong model, through the lens of the LLM-based evaluator.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Detailed comparison results with LLaMA-based models on Evol-Instruct benchmark. Each method trains a target model based on LLaMA-7B or -13B, and compares against the strong model, Gemini-Pro. Capacity Recovery Ratio (%), <math alttext="\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}" class="ltx_Math" display="inline" id="A1.T5.2.m1.1"><semantics id="A1.T5.2.m1.1b"><mrow id="A1.T5.2.m1.1.1" xref="A1.T5.2.m1.1.1.cmml"><mtext id="A1.T5.2.m1.1.1.2" xref="A1.T5.2.m1.1.1.2a.cmml">𝙲𝚁𝚁</mtext><mo id="A1.T5.2.m1.1.1.1" xref="A1.T5.2.m1.1.1.1.cmml">=</mo><mfrac id="A1.T5.2.m1.1.1.3" xref="A1.T5.2.m1.1.1.3.cmml"><mrow id="A1.T5.2.m1.1.1.3.2" xref="A1.T5.2.m1.1.1.3.2.cmml"><mtext id="A1.T5.2.m1.1.1.3.2.2" xref="A1.T5.2.m1.1.1.3.2.2a.cmml">𝚠𝚒𝚗𝚜</mtext><mo id="A1.T5.2.m1.1.1.3.2.1" xref="A1.T5.2.m1.1.1.3.2.1.cmml">+</mo><mtext id="A1.T5.2.m1.1.1.3.2.3" xref="A1.T5.2.m1.1.1.3.2.3a.cmml">𝚝𝚒𝚎𝚜</mtext></mrow><mtext id="A1.T5.2.m1.1.1.3.3" mathvariant="monospace" xref="A1.T5.2.m1.1.1.3.3a.cmml">total comparisons</mtext></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.2.m1.1c"><apply id="A1.T5.2.m1.1.1.cmml" xref="A1.T5.2.m1.1.1"><eq id="A1.T5.2.m1.1.1.1.cmml" xref="A1.T5.2.m1.1.1.1"></eq><ci id="A1.T5.2.m1.1.1.2a.cmml" xref="A1.T5.2.m1.1.1.2"><mtext id="A1.T5.2.m1.1.1.2.cmml" xref="A1.T5.2.m1.1.1.2">𝙲𝚁𝚁</mtext></ci><apply id="A1.T5.2.m1.1.1.3.cmml" xref="A1.T5.2.m1.1.1.3"><divide id="A1.T5.2.m1.1.1.3.1.cmml" xref="A1.T5.2.m1.1.1.3"></divide><apply id="A1.T5.2.m1.1.1.3.2.cmml" xref="A1.T5.2.m1.1.1.3.2"><plus id="A1.T5.2.m1.1.1.3.2.1.cmml" xref="A1.T5.2.m1.1.1.3.2.1"></plus><ci id="A1.T5.2.m1.1.1.3.2.2a.cmml" xref="A1.T5.2.m1.1.1.3.2.2"><mtext id="A1.T5.2.m1.1.1.3.2.2.cmml" mathsize="70%" xref="A1.T5.2.m1.1.1.3.2.2">𝚠𝚒𝚗𝚜</mtext></ci><ci id="A1.T5.2.m1.1.1.3.2.3a.cmml" xref="A1.T5.2.m1.1.1.3.2.3"><mtext id="A1.T5.2.m1.1.1.3.2.3.cmml" mathsize="70%" xref="A1.T5.2.m1.1.1.3.2.3">𝚝𝚒𝚎𝚜</mtext></ci></apply><ci id="A1.T5.2.m1.1.1.3.3a.cmml" xref="A1.T5.2.m1.1.1.3.3"><mtext id="A1.T5.2.m1.1.1.3.3.cmml" mathsize="70%" mathvariant="monospace" xref="A1.T5.2.m1.1.1.3.3">total comparisons</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.2.m1.1d">\texttt{CRR}=\frac{\texttt{wins}+\texttt{ties}}{\texttt{total comparisons}}</annotation><annotation encoding="application/x-llamapun" id="A1.T5.2.m1.1e">CRR = divide start_ARG wins + ties end_ARG start_ARG total comparisons end_ARG</annotation></semantics></math>.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T5.3" style="width:237.1pt;height:132.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.3pt,5.8pt) scale(0.92,0.92) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T5.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T5.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt" id="A1.T5.3.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.1.1.1.1">Methods</span></th>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="4" id="A1.T5.3.1.1.1.2">
<span class="ltx_text ltx_font_bold" id="A1.T5.3.1.1.1.2.1">LLaMA-7B vs. Gemini-Pro</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A1.T5.3.1.1.1.3">
<span class="ltx_text ltx_font_bold" id="A1.T5.3.1.1.1.3.1">LLaMA-13B vs. Gemini-Pro</span></td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.2.2.1"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.2.2.1.1">Wins</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.2.2.2"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.2.2.2.1">Ties</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.2.2.3"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.2.2.3.1">Losses</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="A1.T5.3.1.2.2.4"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.2.2.4.1">CRR</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.2.2.5"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.2.2.5.1">Wins</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.2.2.6"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.2.2.6.1">Ties</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.2.2.7"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.2.2.7.1">Losses</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.2.2.8"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.2.2.8.1">CRR</span></td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="A1.T5.3.1.3.3.1">Self-Instruct</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.3.3.2">17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.3.3.3">140</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.3.3.4">61</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="A1.T5.3.1.3.3.5">72.02</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.3.3.6">29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.3.3.7">136</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.3.3.8">53</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.3.1.3.3.9">75.69</td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="A1.T5.3.1.4.4.1">Alpagasus</th>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.4.4.2">17</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.4.4.3">147</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.4.4.4">54</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="A1.T5.3.1.4.4.5">75.23</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.4.4.6">26</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.4.4.7">148</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.4.4.8">44</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.4.4.9">79.82</td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="A1.T5.3.1.5.5.1">Tree-Instruct</th>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.5.5.2">23</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.5.5.3">141</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.5.5.4">54</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="A1.T5.3.1.5.5.5">75.23</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.5.5.6">26</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.5.5.7">154</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.5.5.8">38</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.5.5.9">82.57</td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="A1.T5.3.1.6.6.1">WizardLM</th>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.6.6.2">19</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.6.6.3">143</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.6.6.4">56</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="A1.T5.3.1.6.6.5">74.31</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.6.6.6">30</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.6.6.7">149</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.6.6.8">39</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.6.6.9">82.11</td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="A1.T5.3.1.7.7.1">WizardLM+</th>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.7.7.2">19</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.7.7.3">146</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.7.7.4">53</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="A1.T5.3.1.7.7.5">75.69</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.7.7.6">31</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.7.7.7">153</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.7.7.8">34</td>
<td class="ltx_td ltx_align_center" id="A1.T5.3.1.7.7.9">84.40</td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="A1.T5.3.1.8.8.1">CodecLM (ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.3.1.8.8.2"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.8.8.2.1">29</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.3.1.8.8.3"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.8.8.3.1">145</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.3.1.8.8.4"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.8.8.4.1">44</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr" id="A1.T5.3.1.8.8.5"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.8.8.5.1">79.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.3.1.8.8.6"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.8.8.6.1">35</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.3.1.8.8.7"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.8.8.7.1">154</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.3.1.8.8.8"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.8.8.8.1">29</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.3.1.8.8.9"><span class="ltx_text ltx_font_bold" id="A1.T5.3.1.8.8.9.1">86.70</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A1.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Consistency between LLM-based Evaluators</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A1.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance gap to Self-Instruct in terms of CRR on Evol-Instruct, evaluated by ChatGPT and GPT4, respectively. Each method trains a target model based on LLaMA-7B or -13B, and compares against the strong model, Gemini-Pro. We observe two LLM-based automatic evaluators yields consistent results.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T6.1" style="width:198.8pt;height:132.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-8.6pt,5.8pt) scale(0.92,0.92) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T6.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" id="A1.T6.1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A1.T6.1.1.1.1.1.1">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_tt" colspan="2" id="A1.T6.1.1.1.1.2">
<span class="ltx_text ltx_font_bold" id="A1.T6.1.1.1.1.2.1">LLaMA-7B vs. Gemini-Pro</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="A1.T6.1.1.1.1.3">
<span class="ltx_text ltx_font_bold" id="A1.T6.1.1.1.1.3.1">LLaMA-13B vs. Gemini-Pro</span></th>
</tr>
<tr class="ltx_tr" id="A1.T6.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T6.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="A1.T6.1.1.2.2.1.1">ChatGPT</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" id="A1.T6.1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="A1.T6.1.1.2.2.2.1">GPT4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T6.1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="A1.T6.1.1.2.2.3.1">ChatGPT</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T6.1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="A1.T6.1.1.2.2.4.1">GPT4</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T6.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="A1.T6.1.1.3.1.1">Self-Instruct</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.1.1.3.1.2">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="A1.T6.1.1.3.1.3">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.1.1.3.1.4">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.1.1.3.1.5">0.00</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="A1.T6.1.1.4.2.1">Alpagasus</th>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.4.2.2">+3.21</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="A1.T6.1.1.4.2.3">+1.38</td>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.4.2.4">+4.13</td>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.4.2.5">+1.83</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="A1.T6.1.1.5.3.1">Tree-Instruct</th>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.5.3.2">+3.21</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="A1.T6.1.1.5.3.3">+2.29</td>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.5.3.4">+6.88</td>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.5.3.5">+4.59</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="A1.T6.1.1.6.4.1">WizardLM</th>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.6.4.2">+2.29</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="A1.T6.1.1.6.4.3">+0.46</td>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.6.4.4">+6.42</td>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.6.4.5">+3.21</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="A1.T6.1.1.7.5.1">WizardLM+</th>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.7.5.2">+3.67</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="A1.T6.1.1.7.5.3">+2.29</td>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.7.5.4">+8.72</td>
<td class="ltx_td ltx_align_center" id="A1.T6.1.1.7.5.5">+5.50</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="A1.T6.1.1.8.6.1">CodecLM (ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T6.1.1.8.6.2"><span class="ltx_text ltx_font_bold" id="A1.T6.1.1.8.6.2.1">+7.80</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr" id="A1.T6.1.1.8.6.3"><span class="ltx_text ltx_font_bold" id="A1.T6.1.1.8.6.3.1">+8.26</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T6.1.1.8.6.4"><span class="ltx_text ltx_font_bold" id="A1.T6.1.1.8.6.4.1">+11.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T6.1.1.8.6.5"><span class="ltx_text ltx_font_bold" id="A1.T6.1.1.8.6.5.1">+8.72</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS6.p1">
<p class="ltx_p" id="A1.SS6.p1.1">In the main paper, we use ChatGPT as the LLM judge for final evaluation, for its efficiency, price and accessibility for the community to reproduce our results. As pointed out in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>)</cite>, LLMs evaluators, although largely consistent with human preferences, may have their own biases. Therefore, to make sure our experimental results are solid, we also use GPT-4 as the judge and compare against the performance gap in CRR between different baselines and the Self-Instruct method. The comparison results in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.T6" title="Table 6 ‣ A.6 Consistency between LLM-based Evaluators ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">6</span></a> demonstrates the agreement of two LLM-based judges and confirms the superior performance of CodecLM against comparing methods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.7 </span>Additional Benchmark Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS7.p1">
<p class="ltx_p" id="A1.SS7.p1.1">To complement the performance result using LLM-based automatic evaluator, we also evaluate LLMs tuned with the top methods presented in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.SS4" title="5.4 Open-Domain Instruction Following ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">5.4</span></a> on standard NLP benchmarks, MMLU&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib18" title="">2020</a>)</cite> and BBH&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib40" title="">2022</a>)</cite>. We follow the same settings introduced in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib46" title="">2023</a>)</cite> without demonstrations or CoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib49" title="">2022</a>)</cite> prompt for evaluating the target models based on LLaMA-7B. For our method, we follow the same setting as in Evol-Instruction benchmark evaluation. We present the evaluation results in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.T4" title="Table 4 ‣ A.4 Training Details ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">4</span></a> and use the performance of vanilla LLaMA-7B as a reference. We observe the same performance ranking of all methods as that in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#S5.T1" title="Table 1 ‣ 5.3 Experiment and Evaluation Details ‣ 5 Experiments ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">1</span></a> where we use LLM-based automatic evaluator. The consistency between two different evaluation approaches indicates the reliability of LLM-based evaluator in terms of demonstrating relative performance of competing methods.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A1.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="645" id="A1.F6.g1" src="x6.png" width="813">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Case study on the instruction improvement process of CodecLM. Repetitive instructions are omitted to save space.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A1.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.8 </span>Case Study</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS8.p1">
<p class="ltx_p" id="A1.SS8.p1.1">We present a case study in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F6" title="Figure 6 ‣ A.7 Additional Benchmark Results ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">6</span></a> to show an iterative tailoring process from instruction metadata to the final high-quality prompt. In practice, the iteration may terminate earlier by the Contrastive Filtering process. We observe that Self-Rubrics is able to tailor rubrics and actions according to the given metadata. Interestingly, the actions generated by LLM seems very domain-specific. For example, the <em class="ltx_emph ltx_font_italic" id="A1.SS8.p1.1.1">SWOT analysis</em> in the last action may even be hard for non-expert human annotators to come up with. Moreover, the colored texts in instructions demonstrate that LLM is able to follow the actions quite precisely to refine the instructions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS9">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.9 </span>Prompt Templates for CodecLM</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS9.p1">
<p class="ltx_p" id="A1.SS9.p1.1">We present all prompt templates here in the appendix for better reproducibility. In particular, we list the correspondence between prompt templates and their usages as follows for quick reference:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A1.I3">
<li class="ltx_item" id="A1.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i1.p1">
<p class="ltx_p" id="A1.I3.i1.p1.1">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F7" title="Figure 7 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">7</span></a>: Encoding instructions into metadata, including use case and transferable skills.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i2.p1">
<p class="ltx_p" id="A1.I3.i2.p1.1">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F8" title="Figure 8 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">8</span></a>: Decoding instruction metadata into basic instructions that are relatively simple in structure.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i3.p1">
<p class="ltx_p" id="A1.I3.i3.p1.1">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F9" title="Figure 9 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">9</span></a>: Generating rubrics to judge how challenging an instruction is, and actions to improve the instruction based on the given metadata.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i4.p1">
<p class="ltx_p" id="A1.I3.i4.p1.1">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F10" title="Figure 10 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">10</span></a>: Improving the input instruction by following one of the generated actions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I3.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i5.p1">
<p class="ltx_p" id="A1.I3.i5.p1.1">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F11" title="Figure 11 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">11</span></a>: Comparing the responses quality from the target and strong LLMs. Adapted from the Vicuna-style pairwise comparison prompt by removing the explanation part.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A1.I3.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i6.p1">
<p class="ltx_p" id="A1.I3.i6.p1.1">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F12" title="Figure 12 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">12</span></a>: Automatic evaluation using LLM (<span class="ltx_text ltx_font_italic" id="A1.I3.i6.p1.1.1">e.g.</span>, ChatGPT, GPT-4) as the judge. Following the templates in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib9" title="">2023</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib8" title="">2023b</a>)</cite></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
<p class="ltx_p" id="A1.SS9.p1.2">All prompts are zero-shot except for the first encoding prompt in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#A1.F7" title="Figure 7 ‣ A.9 Prompt Templates for CodecLM ‣ Appendix A Appendix ‣ CodecLM: Aligning Language Models with Tailored Synthetic Data"><span class="ltx_text ltx_ref_tag">7</span></a>, which utilizes few-shot demonstrations to showcase the LLM a rough granularity of the task and skills. Also, we choose these prompts as they work quite well in practice. And we believe recent prompt optimization techniques&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Fernando et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib14" title="">2023</a>; Yang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.05875v1#bib.bib51" title="">2023</a>)</cite> can be incorporated seamlessly into our framework, and we leave them as future work.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A1.F7">
<div class="ltx_listing ltx_lstlisting ltx_listing" id="A1.F7.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGFuIGluc3RydWN0aW9uIGFuYWx5emVyLgpHaXZlbiBhbiBpbnN0cnVjdGlvbiwgeW91IHNob3VsZCByZWNvZ25pemUgaXRzIHVzZSBjYXNlIGFuZCB0aGUgc2tpbGxzIChvciBrbm93bGVkZ2UpCiUqKioqIGNhbWVyYV9yZWFkeS50ZXggTGluZSAxNDAwICoqKipyZXF1aXJlZCBmb3IgYSBsYXJnZSBsYW5ndWFnZSBtb2RlbCAoTExNKSB0byBhbnN3ZXIgdGhlIHF1ZXN0aW9uLgpHZW5lcmF0ZSB0aGUgdXNlIGNhc2UgYW5kIHNraWxscyByZXF1aXJlZCB3aXRob3V0IGFueSBleHBsYW5hdGlvbi4KTGlzdCBhdCBtb3N0IDMgc2tpbGxzLCBlYWNoIHNraWxsIHNob3VsZCBiZSB0cmFuc2ZlcmFibGUsIHNvIHRoYXQgTExNIGNhbiBsZXZlcmFnZSB0aGVtIHRvIGFuc3dlcgpzaW1pbGFyIHF1ZXN0aW9ucy4KQXZvaWQgdXNpbmcgInNraWxsIiwgImtub3dsZWRnZSIgdG8gZGVzY3JpYmUgYSBza2lsbCwgYW5kIGVhY2ggc2tpbGwgc2hvdWxkIGJlIGNvbmNpc2UgKDItMyB3b3JkcykuCkZvbGxvdyB0aGUgZXhhbXBsZXMgYmVsb3cgdG8gYW5hbHl6ZSB0aGUgZ2l2ZW4gaW5zdHJ1Y3Rpb24uClxwYXIjRXhhbXBsZSAxIwpBcyBhIHNwb3J0cyBjb21tZW50YXRvciwgZGVzY3JpYmUgdGhlIHdpbm5pbmcgcGxheSBpbiB0aGUgZmluYWwgc2Vjb25kcyBvZiBhIGNoYW1waW9uc2hpcCBnYW1lLgpVc2UgY2FzZTogY3JlYXRpdmUgd3JpdGluZwpTa2lsbHM6IHJvbGUtcGxheSwgc3BvcnRzClxwYXIjRXhhbXBsZSAyIwpIb3cgdG8gcmVhZCBhIGxhcmdlIGZpbGUgKD4gMlQpIHVzaW5nIHB5dGhvbj8KVGFzazogY29kZSBnZW5lcmF0aW9uClNraWxsczogcHl0aG9uClxwYXIjRXhhbXBsZSAzIwpUaGUgbWV0aG9kIHNlY3Rpb24gb2YgeW91ciBwYXBlciBpcyB0b28gYnJpZWYgYW5kIGRvZXMgbm90IGV4cGxhaW4gaG93IHlvdXIgcHJvcG9zZWQgbW9kZWwgd29ya3MKaW4gZGV0YWlsLiBIb3cgY2FuIHlvdSBwcm92aWRlIG1vcmUgZGV0YWlscyBvZiB0aGUgaGllcmFyY2hpY2FsIGVuY29kZXIgYW5kIHRoZSBjYXNjYWRlZCBzZWxlY3RvcnMsCnN1Y2ggYXMgdGhlaXIgYXJjaGl0ZWN0dXJlcywgaW5wdXRzLCBvdXRwdXRzLCBhbmQgcGFyYW1ldGVycz8KVGFzazogZ2VuZXJhbCBrbm93bGVkZ2UgcXVlc3Rpb24gYW5zd2VyaW5nClNraWxsczogYWNhZGVtaWMgd3JpdGluZywgbWFjaGluZSBsZWFybmluZwpccGFyPGlucHV0IGluc3RydWN0aW9uPgolKioqKiBjYW1lcmFfcmVhZHkudGV4IExpbmUgMTQyNSAqKioqPG91dHB1dCBtZXRhZGF0YT4K">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx2.1">I</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.3">want</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.5">you</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.9">act</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.11">as</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.13">an</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.15">instruction</span><span class="ltx_text ltx_lst_space" id="lstnumberx2.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx2.17">analyzer</span>.
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx3.1">Given</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.3">an</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.5">instruction</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx3.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.7">you</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.9">should</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.11">recognize</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.13">its</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.15">use</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.17">case</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.19">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.21">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.23">skills</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.24">&nbsp;</span>(<span class="ltx_text ltx_lst_identifier" id="lstnumberx3.25">or</span><span class="ltx_text ltx_lst_space" id="lstnumberx3.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx3.27">knowledge</span>)
</div>
<div class="ltx_listingline" id="lstnumberx4">%****<span class="ltx_text ltx_lst_space" id="lstnumberx4.1">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.2">camera_ready</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx4.3">tex</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.5">Line</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.6">&nbsp;</span>1400<span class="ltx_text ltx_lst_space" id="lstnumberx4.7">&nbsp;</span>****<span class="ltx_text ltx_lst_identifier" id="lstnumberx4.8">required</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.10">for</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.11">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.12">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.13">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.14">large</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.15">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.16">language</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.17">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.18">model</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.19">&nbsp;</span>(<span class="ltx_text ltx_lst_identifier" id="lstnumberx4.20">LLM</span>)<span class="ltx_text ltx_lst_space" id="lstnumberx4.21">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.22">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.23">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.24">answer</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.25">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.26">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx4.27">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx4.28">question</span>.
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx5.1">Generate</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.3">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.5">use</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.7">case</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.9">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.11">skills</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.13">required</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.15">without</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.17">any</span><span class="ltx_text ltx_lst_space" id="lstnumberx5.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx5.19">explanation</span>.
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx6.1">List</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.3">at</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.5">most</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.6">&nbsp;</span>3<span class="ltx_text ltx_lst_space" id="lstnumberx6.7">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.8">skills</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx6.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.10">each</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.11">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.12">skill</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.13">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.14">should</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.15">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.16">be</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.17">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.18">transferable</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx6.19">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.20">so</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.21">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.22">that</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.23">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.24">LLM</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.25">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.26">can</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.27">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.28">leverage</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.29">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.30">them</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.31">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.32">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx6.33">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx6.34">answer</span>
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx7.1">similar</span><span class="ltx_text ltx_lst_space" id="lstnumberx7.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx7.3">questions</span>.
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx8.1">Avoid</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.3">using</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.4">&nbsp;</span>"<span class="ltx_text ltx_lst_identifier" id="lstnumberx8.5">skill</span>",<span class="ltx_text ltx_lst_space" id="lstnumberx8.6">&nbsp;</span>"<span class="ltx_text ltx_lst_identifier" id="lstnumberx8.7">knowledge</span>"<span class="ltx_text ltx_lst_space" id="lstnumberx8.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.9">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.11">describe</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.13">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.15">skill</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx8.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.17">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.19">each</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.21">skill</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.23">should</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.25">be</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.27">concise</span><span class="ltx_text ltx_lst_space" id="lstnumberx8.28">&nbsp;</span>(2-3<span class="ltx_text ltx_lst_space" id="lstnumberx8.29">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx8.30">words</span>).
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx9.1">Follow</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.3">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.5">examples</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.7">below</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.9">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.11">analyze</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.13">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.15">given</span><span class="ltx_text ltx_lst_space" id="lstnumberx9.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx9.17">instruction</span>.
</div>
<div class="ltx_listingline" id="lstnumberx10">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx10.1">par</span>#<span class="ltx_text ltx_lst_identifier" id="lstnumberx10.2">Example</span><span class="ltx_text ltx_lst_space" id="lstnumberx10.3">&nbsp;</span>1#
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx11.1">As</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.3">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.5">sports</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.7">commentator</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx11.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.9">describe</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.11">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.13">winning</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.15">play</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.17">in</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.19">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.21">final</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.23">seconds</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.25">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.27">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.29">championship</span><span class="ltx_text ltx_lst_space" id="lstnumberx11.30">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx11.31">game</span>.
</div>
<div class="ltx_listingline" id="lstnumberx12">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx12.1">Use</span><span class="ltx_text ltx_lst_space" id="lstnumberx12.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx12.3">case</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx12.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx12.5">creative</span><span class="ltx_text ltx_lst_space" id="lstnumberx12.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx12.7">writing</span>
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx13.1">Skills</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx13.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx13.3">role</span>-<span class="ltx_text ltx_lst_identifier" id="lstnumberx13.4">play</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx13.5">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx13.6">sports</span>
</div>
<div class="ltx_listingline" id="lstnumberx14">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx14.1">par</span>#<span class="ltx_text ltx_lst_identifier" id="lstnumberx14.2">Example</span><span class="ltx_text ltx_lst_space" id="lstnumberx14.3">&nbsp;</span>2#
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx15.1">How</span><span class="ltx_text ltx_lst_space" id="lstnumberx15.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx15.3">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx15.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx15.5">read</span><span class="ltx_text ltx_lst_space" id="lstnumberx15.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx15.7">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx15.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx15.9">large</span><span class="ltx_text ltx_lst_space" id="lstnumberx15.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx15.11">file</span><span class="ltx_text ltx_lst_space" id="lstnumberx15.12">&nbsp;</span>(&gt;<span class="ltx_text ltx_lst_space" id="lstnumberx15.13">&nbsp;</span>2<span class="ltx_text ltx_lst_identifier" id="lstnumberx15.14">T</span>)<span class="ltx_text ltx_lst_space" id="lstnumberx15.15">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx15.16">using</span><span class="ltx_text ltx_lst_space" id="lstnumberx15.17">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx15.18">python</span>?
</div>
<div class="ltx_listingline" id="lstnumberx16">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx16.1">Task</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx16.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx16.3">code</span><span class="ltx_text ltx_lst_space" id="lstnumberx16.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx16.5">generation</span>
</div>
<div class="ltx_listingline" id="lstnumberx17">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx17.1">Skills</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx17.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx17.3">python</span>
</div>
<div class="ltx_listingline" id="lstnumberx18">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx18.1">par</span>#<span class="ltx_text ltx_lst_identifier" id="lstnumberx18.2">Example</span><span class="ltx_text ltx_lst_space" id="lstnumberx18.3">&nbsp;</span>3#
</div>
<div class="ltx_listingline" id="lstnumberx19">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx19.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.3">method</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.5">section</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.7">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.9">your</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.11">paper</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.13">is</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.15">too</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.17">brief</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.19">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.21">does</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.23">not</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.25">explain</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.27">how</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.29">your</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.30">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.31">proposed</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.32">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.33">model</span><span class="ltx_text ltx_lst_space" id="lstnumberx19.34">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx19.35">works</span>
</div>
<div class="ltx_listingline" id="lstnumberx20">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx20.1">in</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.3">detail</span>.<span class="ltx_text ltx_lst_space" id="lstnumberx20.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.5">How</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.7">can</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.9">you</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.11">provide</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.13">more</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.15">details</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.17">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.19">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.21">hierarchical</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.23">encoder</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.25">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.27">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.29">cascaded</span><span class="ltx_text ltx_lst_space" id="lstnumberx20.30">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx20.31">selectors</span>,
</div>
<div class="ltx_listingline" id="lstnumberx21">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx21.1">such</span><span class="ltx_text ltx_lst_space" id="lstnumberx21.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx21.3">as</span><span class="ltx_text ltx_lst_space" id="lstnumberx21.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx21.5">their</span><span class="ltx_text ltx_lst_space" id="lstnumberx21.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx21.7">architectures</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx21.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx21.9">inputs</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx21.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx21.11">outputs</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx21.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx21.13">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx21.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx21.15">parameters</span>?
</div>
<div class="ltx_listingline" id="lstnumberx22">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx22.1">Task</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx22.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx22.3">general</span><span class="ltx_text ltx_lst_space" id="lstnumberx22.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx22.5">knowledge</span><span class="ltx_text ltx_lst_space" id="lstnumberx22.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx22.7">question</span><span class="ltx_text ltx_lst_space" id="lstnumberx22.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx22.9">answering</span>
</div>
<div class="ltx_listingline" id="lstnumberx23">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx23.1">Skills</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx23.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx23.3">academic</span><span class="ltx_text ltx_lst_space" id="lstnumberx23.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx23.5">writing</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx23.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx23.7">machine</span><span class="ltx_text ltx_lst_space" id="lstnumberx23.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx23.9">learning</span>
</div>
<div class="ltx_listingline" id="lstnumberx24">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx24.1">par</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx24.2">input</span><span class="ltx_text ltx_lst_space" id="lstnumberx24.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx24.4">instruction</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx25">%****<span class="ltx_text ltx_lst_space" id="lstnumberx25.1">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx25.2">camera_ready</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx25.3">tex</span><span class="ltx_text ltx_lst_space" id="lstnumberx25.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx25.5">Line</span><span class="ltx_text ltx_lst_space" id="lstnumberx25.6">&nbsp;</span>1425<span class="ltx_text ltx_lst_space" id="lstnumberx25.7">&nbsp;</span>****&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx25.8">output</span><span class="ltx_text ltx_lst_space" id="lstnumberx25.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx25.10">metadata</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Prompt template to encode the input into metadata, consisting of its use case and transferable skills.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A1.F8">
<div class="ltx_listing ltx_lstlisting ltx_listing" id="A1.F8.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGFuIGluc3RydWN0aW9uIHdyaXRlci4KWW91ciBvYmplY3RpdmUgaXMgdG8gd3JpdGUgPG51bWJlciBvZiBpbnN0cnVjdGlvbnM+IGluc3RydWN0aW9ucyB0aGF0IG11c3QgYmUgcmVhc29uYWJsZQphbmQgbXVzdCBiZSB1bmRlcnN0b29kIGFuZCByZXNwb25kZWQgYnkgaHVtYW5zLgpUaGUgZ2VuZXJhdGVkIGluc3RydWN0aW9ucyBzaG91bGQgYmUgZGl2ZXJzZSBlbm91Z2ggd2hpbGUgZm9sbG93aW5nIHRoZSBjb25zdHJhaW50cyBiZWxvdzoKXHBhclVzZSBjYXNlIG9mIHRoZSBpbnN0cnVjdGlvbnM6IDx1c2UgY2FzZT4KU2tpbGxzIHJlcXVpcmVkIHRvIHJlc3BvbmQgdG8gdGhlIGluc3RydWN0aW9uczogPHNraWxscz4KXHBhckdlbmVyYXRlIHRoZSBpbnN0cnVjdGlvbnMgd2l0aG91dCBhbnN3ZXJpbmcgaW4gbnVtYmVyZWQgYnVsbGV0aW4gcG9pbnRzLgpccGFyPG91dHB1dCBpbnN0cnVjdGlvbnM+Cg==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx26">
</div>
<div class="ltx_listingline" id="lstnumberx27">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx27.1">I</span><span class="ltx_text ltx_lst_space" id="lstnumberx27.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx27.3">want</span><span class="ltx_text ltx_lst_space" id="lstnumberx27.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx27.5">you</span><span class="ltx_text ltx_lst_space" id="lstnumberx27.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx27.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx27.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx27.9">act</span><span class="ltx_text ltx_lst_space" id="lstnumberx27.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx27.11">as</span><span class="ltx_text ltx_lst_space" id="lstnumberx27.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx27.13">an</span><span class="ltx_text ltx_lst_space" id="lstnumberx27.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx27.15">instruction</span><span class="ltx_text ltx_lst_space" id="lstnumberx27.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx27.17">writer</span>.
</div>
<div class="ltx_listingline" id="lstnumberx28">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx28.1">Your</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.3">objective</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.5">is</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.9">write</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.10">&nbsp;</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx28.11">number</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.13">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.15">instructions</span>&gt;<span class="ltx_text ltx_lst_space" id="lstnumberx28.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.17">instructions</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.19">that</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.21">must</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.23">be</span><span class="ltx_text ltx_lst_space" id="lstnumberx28.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx28.25">reasonable</span>
</div>
<div class="ltx_listingline" id="lstnumberx29">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx29.1">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx29.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx29.3">must</span><span class="ltx_text ltx_lst_space" id="lstnumberx29.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx29.5">be</span><span class="ltx_text ltx_lst_space" id="lstnumberx29.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx29.7">understood</span><span class="ltx_text ltx_lst_space" id="lstnumberx29.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx29.9">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx29.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx29.11">responded</span><span class="ltx_text ltx_lst_space" id="lstnumberx29.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx29.13">by</span><span class="ltx_text ltx_lst_space" id="lstnumberx29.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx29.15">humans</span>.
</div>
<div class="ltx_listingline" id="lstnumberx30">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx30.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.3">generated</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.5">instructions</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.7">should</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.9">be</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.11">diverse</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.13">enough</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.15">while</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.17">following</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.19">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.21">constraints</span><span class="ltx_text ltx_lst_space" id="lstnumberx30.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx30.23">below</span>:
</div>
<div class="ltx_listingline" id="lstnumberx31">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx31.1">parUse</span><span class="ltx_text ltx_lst_space" id="lstnumberx31.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx31.3">case</span><span class="ltx_text ltx_lst_space" id="lstnumberx31.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx31.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx31.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx31.7">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx31.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx31.9">instructions</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx31.10">&nbsp;</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx31.11">use</span><span class="ltx_text ltx_lst_space" id="lstnumberx31.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx31.13">case</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx32">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx32.1">Skills</span><span class="ltx_text ltx_lst_space" id="lstnumberx32.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx32.3">required</span><span class="ltx_text ltx_lst_space" id="lstnumberx32.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx32.5">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx32.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx32.7">respond</span><span class="ltx_text ltx_lst_space" id="lstnumberx32.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx32.9">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx32.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx32.11">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx32.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx32.13">instructions</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx32.14">&nbsp;</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx32.15">skills</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx33">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx33.1">parGenerate</span><span class="ltx_text ltx_lst_space" id="lstnumberx33.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx33.3">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx33.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx33.5">instructions</span><span class="ltx_text ltx_lst_space" id="lstnumberx33.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx33.7">without</span><span class="ltx_text ltx_lst_space" id="lstnumberx33.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx33.9">answering</span><span class="ltx_text ltx_lst_space" id="lstnumberx33.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx33.11">in</span><span class="ltx_text ltx_lst_space" id="lstnumberx33.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx33.13">numbered</span><span class="ltx_text ltx_lst_space" id="lstnumberx33.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx33.15">bulletin</span><span class="ltx_text ltx_lst_space" id="lstnumberx33.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx33.17">points</span>.
</div>
<div class="ltx_listingline" id="lstnumberx34">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx34.1">par</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx34.2">output</span><span class="ltx_text ltx_lst_space" id="lstnumberx34.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx34.4">instructions</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Prompt template to generate instructions from metadata.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A1.F9">
<div class="ltx_listing ltx_lstlisting ltx_listing" id="A1.F9.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGEgaW5zdHJ1Y3Rpb24ganVkZ2Ugd2l0aCBkb21haW4gZXhwZXJ0aXNlLgpZb3VyIGpvYiBpcyB0byBnZW5lcmF0ZSA8bnVtYmVyX29mX3J1YnJpY3M+IGRvbWFpbiBzcGVjaWZpYyBydWJyaWNzIHRvIGFzc2VzcyB0aGUgZGlmZmljdWx0eSBhbmQKY29tcGxleGl0eSBiYXNlZCBvbiB0aGUgdXNlIGNhc2Ugb2YgdGhlIGluc3RydWN0aW9uLCBhbmQgc2tpbGxzIHJlcXVpcmVkIHRvIHJlc3BvbmQgdG8gaXQuClRoZSBnZW5lcmF0ZWQgcnVicmljcyBzaG91bGQgYmUgY2xlYXIsIGNvbmNpc2UgYW5kIHVuYW1iaWd1b3VzLgpCYXNlZCBvbiB0aGUgZ2VuZXJhdGVkIHJ1YnJpY3MsIGdlbmVyYXRlIGNvcnJlc3BvbmRpbmcgYWN0aW9ucyB0byBpbXByb3ZlIGFuIGluc3RydWN0aW9uIGJ5Cm1ha2luZyBpdCBtb3JlIGNoYWxsZW5naW5nLgpccGFyVGhlIHVzZSBjYXNlIG9mIHRoZSBpbnN0cnVjdGlvbjogPHVzZSBjYXNlPi4KVGhlIHNraWxscyByZXF1aXJlZCB0byBzb2x2ZSB0aGUgaW5zdHJ1Y3Rpb246IDxza2lsbHM+LgpccGFyR2VuZXJhdGUgdGhlIGRvbWFpbi1zcGVjaWZpYyBydWJyaWNzIGFuZCBhY3Rpb25zIHdpdGhvdXQgZXhwbGFuYXRpb24gaW4gbnVtYmVyZWQgYnVsbGV0aW4gcG9pbnRzOgpccGFyPG91dHB1dCBydWJyaWNzPgo8b3V0cHV0IGFjdGlvbnM+Cg==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx35">
</div>
<div class="ltx_listingline" id="lstnumberx36">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx36.1">I</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.3">want</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.5">you</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.9">act</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.11">as</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.13">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.15">instruction</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.17">judge</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.19">with</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.21">domain</span><span class="ltx_text ltx_lst_space" id="lstnumberx36.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx36.23">expertise</span>.
</div>
<div class="ltx_listingline" id="lstnumberx37">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx37.1">Your</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.3">job</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.5">is</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.9">generate</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.10">&nbsp;</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx37.11">number_of_rubrics</span>&gt;<span class="ltx_text ltx_lst_space" id="lstnumberx37.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.13">domain</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.15">specific</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.17">rubrics</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.19">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.21">assess</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.23">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.25">difficulty</span><span class="ltx_text ltx_lst_space" id="lstnumberx37.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx37.27">and</span>
</div>
<div class="ltx_listingline" id="lstnumberx38">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx38.1">complexity</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.3">based</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.5">on</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.7">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.9">use</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.11">case</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.13">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.15">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.17">instruction</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx38.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.19">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.21">skills</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.23">required</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.25">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.27">respond</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.29">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx38.30">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx38.31">it</span>.
</div>
<div class="ltx_listingline" id="lstnumberx39">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx39.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx39.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx39.3">generated</span><span class="ltx_text ltx_lst_space" id="lstnumberx39.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx39.5">rubrics</span><span class="ltx_text ltx_lst_space" id="lstnumberx39.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx39.7">should</span><span class="ltx_text ltx_lst_space" id="lstnumberx39.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx39.9">be</span><span class="ltx_text ltx_lst_space" id="lstnumberx39.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx39.11">clear</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx39.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx39.13">concise</span><span class="ltx_text ltx_lst_space" id="lstnumberx39.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx39.15">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx39.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx39.17">unambiguous</span>.
</div>
<div class="ltx_listingline" id="lstnumberx40">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx40.1">Based</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.3">on</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.5">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.7">generated</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.9">rubrics</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx40.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.11">generate</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.13">corresponding</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.15">actions</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.17">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.19">improve</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.21">an</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.23">instruction</span><span class="ltx_text ltx_lst_space" id="lstnumberx40.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx40.25">by</span>
</div>
<div class="ltx_listingline" id="lstnumberx41">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx41.1">making</span><span class="ltx_text ltx_lst_space" id="lstnumberx41.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx41.3">it</span><span class="ltx_text ltx_lst_space" id="lstnumberx41.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx41.5">more</span><span class="ltx_text ltx_lst_space" id="lstnumberx41.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx41.7">challenging</span>.
</div>
<div class="ltx_listingline" id="lstnumberx42">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx42.1">parThe</span><span class="ltx_text ltx_lst_space" id="lstnumberx42.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx42.3">use</span><span class="ltx_text ltx_lst_space" id="lstnumberx42.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx42.5">case</span><span class="ltx_text ltx_lst_space" id="lstnumberx42.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx42.7">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx42.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx42.9">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx42.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx42.11">instruction</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx42.12">&nbsp;</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx42.13">use</span><span class="ltx_text ltx_lst_space" id="lstnumberx42.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx42.15">case</span>&gt;.
</div>
<div class="ltx_listingline" id="lstnumberx43">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx43.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx43.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx43.3">skills</span><span class="ltx_text ltx_lst_space" id="lstnumberx43.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx43.5">required</span><span class="ltx_text ltx_lst_space" id="lstnumberx43.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx43.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx43.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx43.9">solve</span><span class="ltx_text ltx_lst_space" id="lstnumberx43.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx43.11">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx43.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx43.13">instruction</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx43.14">&nbsp;</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx43.15">skills</span>&gt;.
</div>
<div class="ltx_listingline" id="lstnumberx44">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx44.1">parGenerate</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.3">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.5">domain</span>-<span class="ltx_text ltx_lst_identifier" id="lstnumberx44.6">specific</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.7">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.8">rubrics</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.10">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.11">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.12">actions</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.13">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.14">without</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.15">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.16">explanation</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.17">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.18">in</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.19">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.20">numbered</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.21">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.22">bulletin</span><span class="ltx_text ltx_lst_space" id="lstnumberx44.23">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx44.24">points</span>:
</div>
<div class="ltx_listingline" id="lstnumberx45">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx45.1">par</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx45.2">output</span><span class="ltx_text ltx_lst_space" id="lstnumberx45.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx45.4">rubrics</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx46">&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx46.1">output</span><span class="ltx_text ltx_lst_space" id="lstnumberx46.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx46.3">actions</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Prompt template to generate actions to improve instructions based on instruction metadata.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A1.F10">
<div class="ltx_listing ltx_lstlisting ltx_listing" id="A1.F10.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,Ckkgd2FudCB5b3UgdG8gYWN0IGFzIGEgaW5zdHJ1Y3Rpb24gaW1wcm92ZXIgd2l0aCBkb21haW4gZXhwZXJ0aXNlLgpZb3VyIGpvYiBpcyB0byBtYWtlIHRoZSBnaXZlbiBpbnN0cnVjdGlvbiBtb3JlIGNoYWxsZW5naW5nIGZvbGxvd2luZyB0aGUgZ2l2ZW4gaW1wcm92aW5nIGFjdGlvbgppdGVtLCBhbmQgdGhlIGdlbmVyYXRlZCBpbnN0cnVjdGlvbiBzaG91bGQgYmUgcmVhc29uYWJsZSBhbmQgc2VsZi1jb25zaXN0ZW50LgpEbyBub3QgZGlyZWN0bHkgY29weSB3b3JkcyBvciBwaHJhc2VzIGluIHRoZSBhY3Rpb24uClxwYXJJbXByb3ZpbmcgYWN0aW9uOiA8YWN0aW9uPgpJbnB1dCBpbnN0cnVjdGlvbjogPGlucHV0IGluc3RydWN0aW9uPgpccGFySW1wcm92ZWQgaW5zdHJ1Y3Rpb246IDxvdXRwdXQgaW5zdHJ1Y3Rpb24+Cg==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx47">
</div>
<div class="ltx_listingline" id="lstnumberx48">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx48.1">I</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.3">want</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.5">you</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.9">act</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.11">as</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.13">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.15">instruction</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.17">improver</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.19">with</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.21">domain</span><span class="ltx_text ltx_lst_space" id="lstnumberx48.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx48.23">expertise</span>.
</div>
<div class="ltx_listingline" id="lstnumberx49">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx49.1">Your</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.3">job</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.5">is</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.9">make</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.11">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.13">given</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.15">instruction</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.17">more</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.19">challenging</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.21">following</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.23">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.25">given</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.27">improving</span><span class="ltx_text ltx_lst_space" id="lstnumberx49.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx49.29">action</span>
</div>
<div class="ltx_listingline" id="lstnumberx50">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx50.1">item</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx50.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx50.3">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx50.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx50.5">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx50.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx50.7">generated</span><span class="ltx_text ltx_lst_space" id="lstnumberx50.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx50.9">instruction</span><span class="ltx_text ltx_lst_space" id="lstnumberx50.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx50.11">should</span><span class="ltx_text ltx_lst_space" id="lstnumberx50.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx50.13">be</span><span class="ltx_text ltx_lst_space" id="lstnumberx50.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx50.15">reasonable</span><span class="ltx_text ltx_lst_space" id="lstnumberx50.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx50.17">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx50.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx50.19">self</span>-<span class="ltx_text ltx_lst_identifier" id="lstnumberx50.20">consistent</span>.
</div>
<div class="ltx_listingline" id="lstnumberx51">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx51.1">Do</span><span class="ltx_text ltx_lst_space" id="lstnumberx51.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx51.3">not</span><span class="ltx_text ltx_lst_space" id="lstnumberx51.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx51.5">directly</span><span class="ltx_text ltx_lst_space" id="lstnumberx51.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx51.7">copy</span><span class="ltx_text ltx_lst_space" id="lstnumberx51.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx51.9">words</span><span class="ltx_text ltx_lst_space" id="lstnumberx51.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx51.11">or</span><span class="ltx_text ltx_lst_space" id="lstnumberx51.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx51.13">phrases</span><span class="ltx_text ltx_lst_space" id="lstnumberx51.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx51.15">in</span><span class="ltx_text ltx_lst_space" id="lstnumberx51.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx51.17">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx51.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx51.19">action</span>.
</div>
<div class="ltx_listingline" id="lstnumberx52">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx52.1">parImproving</span><span class="ltx_text ltx_lst_space" id="lstnumberx52.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx52.3">action</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx52.4">&nbsp;</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx52.5">action</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx53">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx53.1">Input</span><span class="ltx_text ltx_lst_space" id="lstnumberx53.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx53.3">instruction</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx53.4">&nbsp;</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx53.5">input</span><span class="ltx_text ltx_lst_space" id="lstnumberx53.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx53.7">instruction</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx54">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx54.1">parImproved</span><span class="ltx_text ltx_lst_space" id="lstnumberx54.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx54.3">instruction</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx54.4">&nbsp;</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx54.5">output</span><span class="ltx_text ltx_lst_space" id="lstnumberx54.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx54.7">instruction</span>&gt;
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Prompt template to improve instructions following generated actions.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A1.F11">
<div class="ltx_listing ltx_lstlisting ltx_listing" id="A1.F11.3">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,CllvdSBhcmUgYSBoZWxwZnVsIGFuZCBwcmVjaXNlIGFzc2lzdGFudCBmb3IgY2hlY2tpbmcgdGhlIHF1YWxpdHkgb2YgdGhlIGFuc3dlci4KXHBhcjxRdWVzdGlvbj4KW1RoZSBTdGFydCBvZiBBc3Npc3RhbnQgMSdzIEFuc3dlcl0KJSoqKiogY2FtZXJhX3JlYWR5LnRleCBMaW5lIDE1MDAgKioqKjxhbnN3ZXJfMT4KW1RoZSBFbmQgb2YgQXNzaXN0YW50IDEncyBBbnN3ZXJdCltUaGUgU3RhcnQgb2YgQXNzaXN0YW50IDIncyBBbnN3ZXJdCjxhbnN3ZXJfMj4KW1RoZSBFbmQgb2YgQXNzaXN0YW50IDIncyBBbnN3ZXJdClxwYXJXZSB3b3VsZCBsaWtlIHRvIHJlcXVlc3QgeW91ciBmZWVkYmFjayBvbiB0aGUgcGVyZm9ybWFuY2Ugb2YgdHdvIEFJIGFzc2lzdGFudHMgaW4gcmVzcG9uc2UgdG8KdGhlIHVzZXIgcXVlc3Rpb24gZGlzcGxheWVkIGFib3ZlLgpQbGVhc2UgcmF0ZSB0aGUgaGVscGZ1bG5lc3MsIHJlbGV2YW5jZSwgYWNjdXJhY3ksIGxldmVsIG9mIGRldGFpbHMgb2YgdGhlaXIgcmVzcG9uc2VzLiBFYWNoCmFzc2lzdGFudCByZWNlaXZlcyBhbiBvdmVyYWxsIHNjb3JlIG9uIGEgc2NhbGUgb2YgMSB0byAxMCwgd2hlcmUgYSBoaWdoZXIgc2NvcmUgaW5kaWNhdGVzCmJldHRlciBvdmVyYWxsIHBlcmZvcm1hbmNlLgpQbGVhc2Ugb25seSBvdXRwdXQgYSBzaW5nbGUgbGluZSBjb250YWluaW5nIG9ubHkgdHdvIHZhbHVlcyBpbmRpY2F0aW5nIHRoZSBzY29yZXMgZm9yIEFzc2lzdGFudCAxCmFuZCAyLCByZXNwZWN0aXZlbHkuIFRoZSB0d28gc2NvcmVzIGFyZSBzZXBhcmF0ZWQgYnkgYSBzcGFjZS4KUGxlYXNlIGF2b2lkaW5nIGFueSBwb3RlbnRpYWwgYmlhcyBhbmQgZW5zdXJpbmcgdGhhdCB0aGUgb3JkZXIgaW4gd2hpY2ggdGhlIHJlc3BvbnNlcyB3ZXJlCnByZXNlbnRlZCBkb2VzIG5vdCBhZmZlY3QgeW91ciBqdWRnbWVudC4K">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx55">
</div>
<div class="ltx_listingline" id="lstnumberx56">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx56.1">You</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.3">are</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.5">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.7">helpful</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.9">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.11">precise</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.13">assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.15">for</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.17">checking</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.19">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.21">quality</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.23">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.25">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx56.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx56.27">answer</span>.
</div>
<div class="ltx_listingline" id="lstnumberx57">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx57.1">par</span>&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx57.2">Question</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx58">[<span class="ltx_text ltx_lst_identifier" id="lstnumberx58.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx58.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx58.3">Start</span><span class="ltx_text ltx_lst_space" id="lstnumberx58.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx58.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx58.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx58.7">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx58.8">&nbsp;</span>1’<span class="ltx_text ltx_lst_identifier" id="lstnumberx58.9">s</span><span class="ltx_text ltx_lst_space" id="lstnumberx58.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx58.11">Answer</span>]
</div>
<div class="ltx_listingline" id="lstnumberx59">%****<span class="ltx_text ltx_lst_space" id="lstnumberx59.1">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx59.2">camera_ready</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx59.3">tex</span><span class="ltx_text ltx_lst_space" id="lstnumberx59.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx59.5">Line</span><span class="ltx_text ltx_lst_space" id="lstnumberx59.6">&nbsp;</span>1500<span class="ltx_text ltx_lst_space" id="lstnumberx59.7">&nbsp;</span>****&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx59.8">answer_1</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx60">[<span class="ltx_text ltx_lst_identifier" id="lstnumberx60.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx60.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx60.3">End</span><span class="ltx_text ltx_lst_space" id="lstnumberx60.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx60.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx60.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx60.7">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx60.8">&nbsp;</span>1’<span class="ltx_text ltx_lst_identifier" id="lstnumberx60.9">s</span><span class="ltx_text ltx_lst_space" id="lstnumberx60.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx60.11">Answer</span>]
</div>
<div class="ltx_listingline" id="lstnumberx61">[<span class="ltx_text ltx_lst_identifier" id="lstnumberx61.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx61.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx61.3">Start</span><span class="ltx_text ltx_lst_space" id="lstnumberx61.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx61.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx61.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx61.7">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx61.8">&nbsp;</span>2’<span class="ltx_text ltx_lst_identifier" id="lstnumberx61.9">s</span><span class="ltx_text ltx_lst_space" id="lstnumberx61.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx61.11">Answer</span>]
</div>
<div class="ltx_listingline" id="lstnumberx62">&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx62.1">answer_2</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx63">[<span class="ltx_text ltx_lst_identifier" id="lstnumberx63.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx63.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx63.3">End</span><span class="ltx_text ltx_lst_space" id="lstnumberx63.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx63.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx63.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx63.7">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx63.8">&nbsp;</span>2’<span class="ltx_text ltx_lst_identifier" id="lstnumberx63.9">s</span><span class="ltx_text ltx_lst_space" id="lstnumberx63.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx63.11">Answer</span>]
</div>
<div class="ltx_listingline" id="lstnumberx64">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx64.1">parWe</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.3">would</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.5">like</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.9">request</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.11">your</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.13">feedback</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.15">on</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.17">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.19">performance</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.21">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.23">two</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.25">AI</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.27">assistants</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.29">in</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.30">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.31">response</span><span class="ltx_text ltx_lst_space" id="lstnumberx64.32">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx64.33">to</span>
</div>
<div class="ltx_listingline" id="lstnumberx65">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx65.1">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx65.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx65.3">user</span><span class="ltx_text ltx_lst_space" id="lstnumberx65.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx65.5">question</span><span class="ltx_text ltx_lst_space" id="lstnumberx65.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx65.7">displayed</span><span class="ltx_text ltx_lst_space" id="lstnumberx65.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx65.9">above</span>.
</div>
<div class="ltx_listingline" id="lstnumberx66">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx66.1">Please</span><span class="ltx_text ltx_lst_space" id="lstnumberx66.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.3">rate</span><span class="ltx_text ltx_lst_space" id="lstnumberx66.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.5">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx66.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.7">helpfulness</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx66.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.9">relevance</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx66.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.11">accuracy</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx66.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.13">level</span><span class="ltx_text ltx_lst_space" id="lstnumberx66.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.15">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx66.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.17">details</span><span class="ltx_text ltx_lst_space" id="lstnumberx66.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.19">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx66.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.21">their</span><span class="ltx_text ltx_lst_space" id="lstnumberx66.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.23">responses</span>.<span class="ltx_text ltx_lst_space" id="lstnumberx66.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx66.25">Each</span>
</div>
<div class="ltx_listingline" id="lstnumberx67">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx67.1">assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.3">receives</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.5">an</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.7">overall</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.9">score</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.11">on</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.13">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.15">scale</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.17">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.18">&nbsp;</span>1<span class="ltx_text ltx_lst_space" id="lstnumberx67.19">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.20">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.21">&nbsp;</span>10,<span class="ltx_text ltx_lst_space" id="lstnumberx67.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.23">where</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.25">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.27">higher</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.29">score</span><span class="ltx_text ltx_lst_space" id="lstnumberx67.30">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx67.31">indicates</span>
</div>
<div class="ltx_listingline" id="lstnumberx68">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx68.1">better</span><span class="ltx_text ltx_lst_space" id="lstnumberx68.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx68.3">overall</span><span class="ltx_text ltx_lst_space" id="lstnumberx68.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx68.5">performance</span>.
</div>
<div class="ltx_listingline" id="lstnumberx69">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx69.1">Please</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.3">only</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.5">output</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.7">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.9">single</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.11">line</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.13">containing</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.15">only</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.17">two</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.19">values</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.21">indicating</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.23">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.25">scores</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.27">for</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx69.29">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx69.30">&nbsp;</span>1
</div>
<div class="ltx_listingline" id="lstnumberx70">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx70.1">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx70.2">&nbsp;</span>2,<span class="ltx_text ltx_lst_space" id="lstnumberx70.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx70.4">respectively</span>.<span class="ltx_text ltx_lst_space" id="lstnumberx70.5">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx70.6">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx70.7">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx70.8">two</span><span class="ltx_text ltx_lst_space" id="lstnumberx70.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx70.10">scores</span><span class="ltx_text ltx_lst_space" id="lstnumberx70.11">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx70.12">are</span><span class="ltx_text ltx_lst_space" id="lstnumberx70.13">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx70.14">separated</span><span class="ltx_text ltx_lst_space" id="lstnumberx70.15">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx70.16">by</span><span class="ltx_text ltx_lst_space" id="lstnumberx70.17">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx70.18">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx70.19">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx70.20">space</span>.
</div>
<div class="ltx_listingline" id="lstnumberx71">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx71.1">Please</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.3">avoiding</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.5">any</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.7">potential</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.9">bias</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.11">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.13">ensuring</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.15">that</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.17">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.19">order</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.21">in</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.23">which</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.25">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.27">responses</span><span class="ltx_text ltx_lst_space" id="lstnumberx71.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx71.29">were</span>
</div>
<div class="ltx_listingline" id="lstnumberx72">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx72.1">presented</span><span class="ltx_text ltx_lst_space" id="lstnumberx72.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx72.3">does</span><span class="ltx_text ltx_lst_space" id="lstnumberx72.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx72.5">not</span><span class="ltx_text ltx_lst_space" id="lstnumberx72.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx72.7">affect</span><span class="ltx_text ltx_lst_space" id="lstnumberx72.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx72.9">your</span><span class="ltx_text ltx_lst_space" id="lstnumberx72.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx72.11">judgment</span>.
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Prompt template used in Contrastive Filtering to compare the responses of the strong and the target LLMs. We directly use the strong LLM with this template as the scorer <math alttext="S" class="ltx_Math" display="inline" id="A1.F11.2.m1.1"><semantics id="A1.F11.2.m1.1b"><mi id="A1.F11.2.m1.1.1" xref="A1.F11.2.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="A1.F11.2.m1.1c"><ci id="A1.F11.2.m1.1.1.cmml" xref="A1.F11.2.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F11.2.m1.1d">S</annotation><annotation encoding="application/x-llamapun" id="A1.F11.2.m1.1e">italic_S</annotation></semantics></math> to avoid additional costs from calling a third-party LLM.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A1.F12">
<div class="ltx_listing ltx_lstlisting ltx_listing" id="A1.F12.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ClN5c3RlbTogWW91IGFyZSBhIGhlbHBmdWwgYW5kIHByZWNpc2UgYXNzaXN0YW50IGZvciBjaGVja2luZyB0aGUgcXVhbGl0eSBvZiB0aGUgYW5zd2VyLgolKioqKiBjYW1lcmFfcmVhZHkudGV4IExpbmUgMTUyNSAqKioqXHBhclVzZXI6CjxRdWVzdGlvbj4KW1RoZSBTdGFydCBvZiBBc3Npc3RhbnQgMSdzIEFuc3dlcl0KPGFuc3dlcl8xPgpbVGhlIEVuZCBvZiBBc3Npc3RhbnQgMSdzIEFuc3dlcl0KW1RoZSBTdGFydCBvZiBBc3Npc3RhbnQgMidzIEFuc3dlcl0KPGFuc3dlcl8yPgpbVGhlIEVuZCBvZiBBc3Npc3RhbnQgMidzIEFuc3dlcl0KXHBhcldlIHdvdWxkIGxpa2UgdG8gcmVxdWVzdCB5b3VyIGZlZWRiYWNrIG9uIHRoZSBwZXJmb3JtYW5jZSBvZiB0d28gQUkgYXNzaXN0YW50cyBpbiByZXNwb25zZSB0bwp0aGUgdXNlciBxdWVzdGlvbiBkaXNwbGF5ZWQgYWJvdmUuClBsZWFzZSByYXRlIHRoZSBoZWxwZnVsbmVzcywgcmVsZXZhbmNlLCBhY2N1cmFjeSwgbGV2ZWwgb2YgZGV0YWlscyBvZiB0aGVpciByZXNwb25zZXMuIEVhY2gKYXNzaXN0YW50IHJlY2VpdmVzIGFuIG92ZXJhbGwgc2NvcmUgb24gYSBzY2FsZSBvZiAxIHRvIDEwLCB3aGVyZSBhIGhpZ2hlciBzY29yZSBpbmRpY2F0ZXMKYmV0dGVyIG92ZXJhbGwgcGVyZm9ybWFuY2UuClBsZWFzZSBmaXJzdCBvdXRwdXQgYSBzaW5nbGUgbGluZSBjb250YWluaW5nIG9ubHkgdHdvIHZhbHVlcyBpbmRpY2F0aW5nIHRoZSBzY29yZXMgZm9yIEFzc2lzdGFudCAxCmFuZCAyLCByZXNwZWN0aXZlbHkuClRoZSB0d28gc2NvcmVzIGFyZSBzZXBhcmF0ZWQgYnkgYSBzcGFjZS4gSW4gdGhlIHN1YnNlcXVlbnQgbGluZSwgcGxlYXNlIHByb3ZpZGUgYSBjb21wcmVoZW5zaXZlCmV4cGxhbmF0aW9uIG9mIHlvdXIgZXZhbHVhdGlvbiwgYXZvaWRpbmcgYW55IHBvdGVudGlhbCBiaWFzIGFuZCBlbnN1cmluZyB0aGF0IHRoZSBvcmRlciBpbiB3aGljaAp0aGUgcmVzcG9uc2VzIHdlcmUgcHJlc2VudGVkIGRvZXMgbm90IGFmZmVjdCB5b3VyIGp1ZGdtZW50Lgo=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx73">
</div>
<div class="ltx_listingline" id="lstnumberx74">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx74.1">System</span>:<span class="ltx_text ltx_lst_space" id="lstnumberx74.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.3">You</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.5">are</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.7">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.9">helpful</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.11">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.13">precise</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.15">assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.17">for</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.19">checking</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.21">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.23">quality</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.25">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.27">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx74.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx74.29">answer</span>.
</div>
<div class="ltx_listingline" id="lstnumberx75">%****<span class="ltx_text ltx_lst_space" id="lstnumberx75.1">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx75.2">camera_ready</span>.<span class="ltx_text ltx_lst_identifier" id="lstnumberx75.3">tex</span><span class="ltx_text ltx_lst_space" id="lstnumberx75.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx75.5">Line</span><span class="ltx_text ltx_lst_space" id="lstnumberx75.6">&nbsp;</span>1525<span class="ltx_text ltx_lst_space" id="lstnumberx75.7">&nbsp;</span>****\<span class="ltx_text ltx_lst_identifier" id="lstnumberx75.8">parUser</span>:
</div>
<div class="ltx_listingline" id="lstnumberx76">&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx76.1">Question</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx77">[<span class="ltx_text ltx_lst_identifier" id="lstnumberx77.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx77.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx77.3">Start</span><span class="ltx_text ltx_lst_space" id="lstnumberx77.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx77.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx77.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx77.7">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx77.8">&nbsp;</span>1’<span class="ltx_text ltx_lst_identifier" id="lstnumberx77.9">s</span><span class="ltx_text ltx_lst_space" id="lstnumberx77.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx77.11">Answer</span>]
</div>
<div class="ltx_listingline" id="lstnumberx78">&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx78.1">answer_1</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx79">[<span class="ltx_text ltx_lst_identifier" id="lstnumberx79.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx79.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx79.3">End</span><span class="ltx_text ltx_lst_space" id="lstnumberx79.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx79.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx79.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx79.7">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx79.8">&nbsp;</span>1’<span class="ltx_text ltx_lst_identifier" id="lstnumberx79.9">s</span><span class="ltx_text ltx_lst_space" id="lstnumberx79.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx79.11">Answer</span>]
</div>
<div class="ltx_listingline" id="lstnumberx80">[<span class="ltx_text ltx_lst_identifier" id="lstnumberx80.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx80.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx80.3">Start</span><span class="ltx_text ltx_lst_space" id="lstnumberx80.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx80.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx80.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx80.7">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx80.8">&nbsp;</span>2’<span class="ltx_text ltx_lst_identifier" id="lstnumberx80.9">s</span><span class="ltx_text ltx_lst_space" id="lstnumberx80.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx80.11">Answer</span>]
</div>
<div class="ltx_listingline" id="lstnumberx81">&lt;<span class="ltx_text ltx_lst_identifier" id="lstnumberx81.1">answer_2</span>&gt;
</div>
<div class="ltx_listingline" id="lstnumberx82">[<span class="ltx_text ltx_lst_identifier" id="lstnumberx82.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx82.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx82.3">End</span><span class="ltx_text ltx_lst_space" id="lstnumberx82.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx82.5">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx82.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx82.7">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx82.8">&nbsp;</span>2’<span class="ltx_text ltx_lst_identifier" id="lstnumberx82.9">s</span><span class="ltx_text ltx_lst_space" id="lstnumberx82.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx82.11">Answer</span>]
</div>
<div class="ltx_listingline" id="lstnumberx83">\<span class="ltx_text ltx_lst_identifier" id="lstnumberx83.1">parWe</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.3">would</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.5">like</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.7">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.9">request</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.11">your</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.13">feedback</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.15">on</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.17">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.19">performance</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.21">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.23">two</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.25">AI</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.27">assistants</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.29">in</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.30">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.31">response</span><span class="ltx_text ltx_lst_space" id="lstnumberx83.32">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx83.33">to</span>
</div>
<div class="ltx_listingline" id="lstnumberx84">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx84.1">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx84.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx84.3">user</span><span class="ltx_text ltx_lst_space" id="lstnumberx84.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx84.5">question</span><span class="ltx_text ltx_lst_space" id="lstnumberx84.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx84.7">displayed</span><span class="ltx_text ltx_lst_space" id="lstnumberx84.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx84.9">above</span>.
</div>
<div class="ltx_listingline" id="lstnumberx85">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx85.1">Please</span><span class="ltx_text ltx_lst_space" id="lstnumberx85.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.3">rate</span><span class="ltx_text ltx_lst_space" id="lstnumberx85.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.5">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx85.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.7">helpfulness</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx85.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.9">relevance</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx85.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.11">accuracy</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx85.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.13">level</span><span class="ltx_text ltx_lst_space" id="lstnumberx85.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.15">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx85.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.17">details</span><span class="ltx_text ltx_lst_space" id="lstnumberx85.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.19">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx85.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.21">their</span><span class="ltx_text ltx_lst_space" id="lstnumberx85.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.23">responses</span>.<span class="ltx_text ltx_lst_space" id="lstnumberx85.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx85.25">Each</span>
</div>
<div class="ltx_listingline" id="lstnumberx86">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx86.1">assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.3">receives</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.5">an</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.7">overall</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.9">score</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.11">on</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.13">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.15">scale</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.17">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.18">&nbsp;</span>1<span class="ltx_text ltx_lst_space" id="lstnumberx86.19">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.20">to</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.21">&nbsp;</span>10,<span class="ltx_text ltx_lst_space" id="lstnumberx86.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.23">where</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.25">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.27">higher</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.29">score</span><span class="ltx_text ltx_lst_space" id="lstnumberx86.30">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx86.31">indicates</span>
</div>
<div class="ltx_listingline" id="lstnumberx87">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx87.1">better</span><span class="ltx_text ltx_lst_space" id="lstnumberx87.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx87.3">overall</span><span class="ltx_text ltx_lst_space" id="lstnumberx87.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx87.5">performance</span>.
</div>
<div class="ltx_listingline" id="lstnumberx88">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx88.1">Please</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.3">first</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.5">output</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.7">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.9">single</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.11">line</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.13">containing</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.15">only</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.17">two</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.19">values</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.21">indicating</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.23">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.25">scores</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.27">for</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx88.29">Assistant</span><span class="ltx_text ltx_lst_space" id="lstnumberx88.30">&nbsp;</span>1
</div>
<div class="ltx_listingline" id="lstnumberx89">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx89.1">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx89.2">&nbsp;</span>2,<span class="ltx_text ltx_lst_space" id="lstnumberx89.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx89.4">respectively</span>.
</div>
<div class="ltx_listingline" id="lstnumberx90">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx90.1">The</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.3">two</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.5">scores</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.7">are</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.9">separated</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.11">by</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.13">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.15">space</span>.<span class="ltx_text ltx_lst_space" id="lstnumberx90.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.17">In</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.19">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.21">subsequent</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.23">line</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx90.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.25">please</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.27">provide</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.29">a</span><span class="ltx_text ltx_lst_space" id="lstnumberx90.30">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx90.31">comprehensive</span>
</div>
<div class="ltx_listingline" id="lstnumberx91">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx91.1">explanation</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.3">of</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.5">your</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.7">evaluation</span>,<span class="ltx_text ltx_lst_space" id="lstnumberx91.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.9">avoiding</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.11">any</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.13">potential</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.15">bias</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.17">and</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.19">ensuring</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.21">that</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.22">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.23">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.25">order</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.26">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.27">in</span><span class="ltx_text ltx_lst_space" id="lstnumberx91.28">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx91.29">which</span>
</div>
<div class="ltx_listingline" id="lstnumberx92">
<span class="ltx_text ltx_lst_identifier" id="lstnumberx92.1">the</span><span class="ltx_text ltx_lst_space" id="lstnumberx92.2">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx92.3">responses</span><span class="ltx_text ltx_lst_space" id="lstnumberx92.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx92.5">were</span><span class="ltx_text ltx_lst_space" id="lstnumberx92.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx92.7">presented</span><span class="ltx_text ltx_lst_space" id="lstnumberx92.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx92.9">does</span><span class="ltx_text ltx_lst_space" id="lstnumberx92.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx92.11">not</span><span class="ltx_text ltx_lst_space" id="lstnumberx92.12">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx92.13">affect</span><span class="ltx_text ltx_lst_space" id="lstnumberx92.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx92.15">your</span><span class="ltx_text ltx_lst_space" id="lstnumberx92.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier" id="lstnumberx92.17">judgment</span>.
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Prompt template for automatic evaluation using LLM (<span class="ltx_text ltx_font_italic" id="A1.F12.3.1">e.g.</span>, ChatGPT, GPT-4) as the judge.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>