<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.01432] Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge</title><meta property="og:description" content="Large language models (LLMs) memorize a vast amount of factual knowledge, exhibiting strong performance across diverse tasks and domains. However, it has been observed that the performance diminishes when dealing with ‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.01432">

<!--Generated on Fri Apr  5 16:22:13 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Heydar Soudani 
<br class="ltx_break">Radboud University 
<br class="ltx_break">Nijmegen 
<br class="ltx_break">The Netherlands 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">heydar.soudani@ru.nl</span> 
<br class="ltx_break">&amp;Evangelos Kanoulas 
<br class="ltx_break">University of Amsterdam 
<br class="ltx_break">Amsterdam 
<br class="ltx_break">The Netherlands 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">e.kanoulas@uva.nl</span> 
<br class="ltx_break">&amp;Faegheh Hasibi 
<br class="ltx_break">Radboud University 
<br class="ltx_break">Nijmegen 
<br class="ltx_break">The Netherlands 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">faegheh.hasibi@ru.nl</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Large language models (LLMs) memorize a vast amount of factual knowledge, exhibiting strong performance across diverse tasks and domains. However, it has been observed that the performance diminishes when dealing with less-popular or low-frequency concepts and entities, for example in domain specific applications.
The two prominent approaches to enhance the performance of LLMs on low-frequent topics are: Retrieval Augmented Generation (RAG) and fine-tuning (FT) over synthetic data.
This paper explores and evaluates the impact of RAG and FT on customizing LLMs in handling low-frequency entities on question answering task.
Our findings indicate that FT significantly boosts the performance across entities of varying popularity, especially in the most and least popular groups, while RAG surpasses other methods.
Additionally, the success of both RAG and FT approaches is amplified by advancements in retrieval and data augmentation techniques.
The code and data is available at <a target="_blank" href="https://github.com/informagi/RAGvsFT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/informagi/RAGvsFT</a>.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.1" class="ltx_block ltx_align_bottom">
<p id="p1.1.1" class="ltx_p"><span id="p1.1.1.1" class="ltx_text ltx_font_bold">Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.1.2" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.1.2.1" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.1.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.2.1.1.1.1" class="ltx_tr">
<span id="p1.1.2.1.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Heydar Soudani</span></span></span>
<span id="p1.1.2.1.1.2.2" class="ltx_tr">
<span id="p1.1.2.1.1.2.2.1" class="ltx_td ltx_align_center">Radboud University</span></span>
<span id="p1.1.2.1.1.3.3" class="ltx_tr">
<span id="p1.1.2.1.1.3.3.1" class="ltx_td ltx_align_center">Nijmegen</span></span>
<span id="p1.1.2.1.1.4.4" class="ltx_tr">
<span id="p1.1.2.1.1.4.4.1" class="ltx_td ltx_align_center">The Netherlands</span></span>
<span id="p1.1.2.1.1.5.5" class="ltx_tr">
<span id="p1.1.2.1.1.5.5.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.5.5.1.1" class="ltx_text ltx_font_typewriter">heydar.soudani@ru.nl</span></span></span>
</span>
</span></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span id="p1.1.2.2" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.2.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.2.2.1.1.1" class="ltx_tr">
<span id="p1.1.2.2.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Evangelos Kanoulas</span></span></span>
<span id="p1.1.2.2.1.2.2" class="ltx_tr">
<span id="p1.1.2.2.1.2.2.1" class="ltx_td ltx_align_center">University of Amsterdam</span></span>
<span id="p1.1.2.2.1.3.3" class="ltx_tr">
<span id="p1.1.2.2.1.3.3.1" class="ltx_td ltx_align_center">Amsterdam</span></span>
<span id="p1.1.2.2.1.4.4" class="ltx_tr">
<span id="p1.1.2.2.1.4.4.1" class="ltx_td ltx_align_center">The Netherlands</span></span>
<span id="p1.1.2.2.1.5.5" class="ltx_tr">
<span id="p1.1.2.2.1.5.5.1" class="ltx_td ltx_align_center"><span id="p1.1.2.2.1.5.5.1.1" class="ltx_text ltx_font_typewriter">e.kanoulas@uva.nl</span></span></span>
</span>
</span></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span id="p1.1.2.3" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.3.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.2.3.1.1.1" class="ltx_tr">
<span id="p1.1.2.3.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Faegheh Hasibi</span></span></span>
<span id="p1.1.2.3.1.2.2" class="ltx_tr">
<span id="p1.1.2.3.1.2.2.1" class="ltx_td ltx_align_center">Radboud University</span></span>
<span id="p1.1.2.3.1.3.3" class="ltx_tr">
<span id="p1.1.2.3.1.3.3.1" class="ltx_td ltx_align_center">Nijmegen</span></span>
<span id="p1.1.2.3.1.4.4" class="ltx_tr">
<span id="p1.1.2.3.1.4.4.1" class="ltx_td ltx_align_center">The Netherlands</span></span>
<span id="p1.1.2.3.1.5.5" class="ltx_tr">
<span id="p1.1.2.3.1.5.5.1" class="ltx_td ltx_align_center"><span id="p1.1.2.3.1.5.5.1.1" class="ltx_text ltx_font_typewriter">faegheh.hasibi@ru.nl</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Large Language Models (LLMs) exhibit outstanding capabilities in executing tasks that demand extensive memorization of factual data&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chowdhery et&nbsp;al., <a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite>. However, their memorization capabilities are constrained when dealing with less frequent entities&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Mallen et&nbsp;al. (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>); Kandpal et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>); Sun et&nbsp;al. (<a href="#bib.bib34" title="" class="ltx_ref">2023</a>)</cite>, and even the largest models may encounter the well-known "hallucination" problem&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Shuster et&nbsp;al. (<a href="#bib.bib32" title="" class="ltx_ref">2021</a>)</cite> and temporal degradation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Kasai et&nbsp;al. (<a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite>.
Consequently, when LLMs are intended for deployment in less resourced domains, customization becomes imperative to ensure optimal performance. A common example is within the industrial setup, where chatbots or Question Answering (QA) systems need to accurately answer users‚Äô questions about a proprietary knowledge graph or intra-company terminology with limited textual description.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Retrieval-Augmented Generation (RAG) and Fine-Tuning (FT) stand out as two prominent approaches for adapting LLMs to specific domains. RAG retrieves relevant information from a document corpus and enhances LLM‚Äôs response generation through the implementation of in-context learning (ICL). Conversely, the fine-tuning approach updates model weights to become adept at recalling specific information and enhance its memorization capabilities during inference.
In the context of less popular knowledge, where limited data is available, data augmentation methods are utilized to generate synthetic training data, serving as an initial step towards fine tuning.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2403.01432/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="216" height="131" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Correlation between subject entity popularity in a question and the effects of RAG and FT on FlanT5-small performance in open-domain question answering. FT markedly improves accuracy in the initial and final buckets relative to others (indicated by the pink line).</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we aim to understand which approach and under what conditions is more effective for industry-specific models. Specifically, we seek to answer the following research questions:

<br class="ltx_break"><span id="S1.p3.1.1" class="ltx_text ltx_font_bold">(RQ1)</span> What is the effectiveness of RAG and fine-tuning with synthetic data on QA for low-frequency factual knowledge?

<br class="ltx_break"><span id="S1.p3.1.2" class="ltx_text ltx_font_bold">(RQ2)</span> Which parameters, including the quality of synthetic samples, the method to be fine-tuned, the model size, and the performance of retrieval models affect the downstream performance?</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To address our RQs, we performed a comprehensive comparison of RAG and fine tuning methods, with specific attention to less popular knowledge.
Our evaluation setup explores various factors, including model size, retrieval models, the quality of synthetic data generation, and the fine-tuning method (PEFT vs. full fine tuning).</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Our findings indicate that FT consistently enhances performance for entities, both popular and less popular, with the most substantial improvements observed in the most and least popular categories. Furthermore, RAG consistently outperforms fine tuning methods, particularly when combined with FT in smaller models, a benefit that diminishes in base models and is non-existent in larger models. Lastly, the effectiveness of both RAG and FT strategies increases with improvements in the performance of the retrieval and data augmentation models.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Data Augmentation (DA).</span>
Data availability is crucial for fine-tuning in specialized domains.
DA addresses data scarcity problem by generating task- and domain-relevant samples from existing unlabeled texts.
A common DA approach for the QA task is generating question-answer pairs through a four-step <em id="S2.p1.1.2" class="ltx_emph ltx_font_italic">Pipeline</em>, consisting of: passage selection, answer extraction, question generation, and consistency filtering&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Alberti et&nbsp;al., <a href="#bib.bib1" title="" class="ltx_ref">2019</a>; Lewis et&nbsp;al., <a href="#bib.bib19" title="" class="ltx_ref">2019</a>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>; Ushio et&nbsp;al., <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Ushio et&nbsp;al. (<a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite> conducted an empirical study comparing three question answer generation approaches: Pipeline, Multitask, and End-to-End (E2E) and showed the E2E approach outperforms others in downstream tasks.
Recently, the utilization of LLMs to generate data is shown effective in information retrieval, QA, and dialogue creation tasks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Soudani et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2023</a>; Askari et&nbsp;al., <a href="#bib.bib4" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Retrieval Augmented Generation.</span>
RAG enhances LLMs by integrating external knowledge sources with input queries, enriching the model with additional context for knowledge-intensive tasks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>. It utilizes an information retrieval system to find relevant documents and adds them to the input prompt to enhance response generation of an LLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Asai et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2023a</a>, <a href="#bib.bib3" title="" class="ltx_ref">b</a>)</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Less popular Knowledge.</span>
An entity‚Äôs popularity in an LLM is gauged by its frequency in the model‚Äôs pre-training data&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Godbole and Jia, <a href="#bib.bib12" title="" class="ltx_ref">2023</a>; Min et&nbsp;al., <a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>, often assessed through the entity‚Äôs occurrence in a large corpus&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kandpal et&nbsp;al., <a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite>. Due to the practical challenges of direct counting, approximations like traffic metrics and content density are used&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Sun et&nbsp;al., <a href="#bib.bib34" title="" class="ltx_ref">2023</a>)</cite>. Wikipedia pageviews are among the most prevalent methods for measuring the popularity of entities&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Mallen et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2023</a>; Sciavolino et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2021</a>; Chen et&nbsp;al., <a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Comparing FT vs. RAG</span>.
As interest grows in refining pre-trained language models for particular tasks, the comparison of FT and RAG strategies under equitable conditions is becoming increasingly important.
<cite class="ltx_cite ltx_citemacro_citet">Mosbach et&nbsp;al. (<a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite> explored the effectiveness of few-shot FT versus In-context Learning for classification tasks in general domains. <cite class="ltx_cite ltx_citemacro_citet">de&nbsp;Luis&nbsp;Balaguer et&nbsp;al. (<a href="#bib.bib10" title="" class="ltx_ref">2024</a>)</cite> compared FT and RAG in answering long, agriculture, and geography-specific questions. <cite class="ltx_cite ltx_citemacro_citet">Ovadia et&nbsp;al. (<a href="#bib.bib28" title="" class="ltx_ref">2023</a>)</cite> assessed the performance on multiple-choice questions in specialized areas like Anatomy, Astronomy, College Biology, and Prehistory. In contrast to these studies, we directly address the integration of less popular factual knowledge into LLMs, comparing various retrieval, data augmentation, and fine tuning methods.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Evaluation Setup</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We evaluate LLMs on the closed-book QA task, focusing on the <span id="S3.p1.1.1" class="ltx_text ltx_font_smallcaps">PopQA</span> dataset&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Mallen et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite> characterized by questions that covers a long-tail entity distribution.
It also includes unique Wikipedia titles, facilitating the calculation of pageviews and identification of relevant Wikipedia pages. We acquire the relevant Wikipedia page for each subject entity in the <span id="S3.p1.1.2" class="ltx_text ltx_font_smallcaps">PopQA</span> dataset and divide the entities into five buckets based on their popularity levels (Figure&nbsp;<a href="#S3.F2" title="Figure 2 ‚Ä£ 3 Evaluation Setup ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2403.01432/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="161" height="101" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distribution of sample counts across buckets, defined by <math id="S3.F2.4.m1.1" class="ltx_Math" alttext="log_{10}(\text{pageviews})" display="inline"><semantics id="S3.F2.4.m1.1b"><mrow id="S3.F2.4.m1.1.2" xref="S3.F2.4.m1.1.2.cmml"><mi id="S3.F2.4.m1.1.2.2" xref="S3.F2.4.m1.1.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.F2.4.m1.1.2.1" xref="S3.F2.4.m1.1.2.1.cmml">‚Äã</mo><mi id="S3.F2.4.m1.1.2.3" xref="S3.F2.4.m1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.F2.4.m1.1.2.1b" xref="S3.F2.4.m1.1.2.1.cmml">‚Äã</mo><msub id="S3.F2.4.m1.1.2.4" xref="S3.F2.4.m1.1.2.4.cmml"><mi id="S3.F2.4.m1.1.2.4.2" xref="S3.F2.4.m1.1.2.4.2.cmml">g</mi><mn id="S3.F2.4.m1.1.2.4.3" xref="S3.F2.4.m1.1.2.4.3.cmml">10</mn></msub><mo lspace="0em" rspace="0em" id="S3.F2.4.m1.1.2.1c" xref="S3.F2.4.m1.1.2.1.cmml">‚Äã</mo><mrow id="S3.F2.4.m1.1.2.5.2" xref="S3.F2.4.m1.1.1a.cmml"><mo stretchy="false" id="S3.F2.4.m1.1.2.5.2.1" xref="S3.F2.4.m1.1.1a.cmml">(</mo><mtext id="S3.F2.4.m1.1.1" xref="S3.F2.4.m1.1.1.cmml">pageviews</mtext><mo stretchy="false" id="S3.F2.4.m1.1.2.5.2.2" xref="S3.F2.4.m1.1.1a.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.4.m1.1c"><apply id="S3.F2.4.m1.1.2.cmml" xref="S3.F2.4.m1.1.2"><times id="S3.F2.4.m1.1.2.1.cmml" xref="S3.F2.4.m1.1.2.1"></times><ci id="S3.F2.4.m1.1.2.2.cmml" xref="S3.F2.4.m1.1.2.2">ùëô</ci><ci id="S3.F2.4.m1.1.2.3.cmml" xref="S3.F2.4.m1.1.2.3">ùëú</ci><apply id="S3.F2.4.m1.1.2.4.cmml" xref="S3.F2.4.m1.1.2.4"><csymbol cd="ambiguous" id="S3.F2.4.m1.1.2.4.1.cmml" xref="S3.F2.4.m1.1.2.4">subscript</csymbol><ci id="S3.F2.4.m1.1.2.4.2.cmml" xref="S3.F2.4.m1.1.2.4.2">ùëî</ci><cn type="integer" id="S3.F2.4.m1.1.2.4.3.cmml" xref="S3.F2.4.m1.1.2.4.3">10</cn></apply><ci id="S3.F2.4.m1.1.1a.cmml" xref="S3.F2.4.m1.1.2.5.2"><mtext id="S3.F2.4.m1.1.1.cmml" xref="S3.F2.4.m1.1.1">pageviews</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.4.m1.1d">log_{10}(\text{pageviews})</annotation></semantics></math>. The leftmost bin includes entities with fewer than <math id="S3.F2.5.m2.1" class="ltx_Math" alttext="10^{2}" display="inline"><semantics id="S3.F2.5.m2.1b"><msup id="S3.F2.5.m2.1.1" xref="S3.F2.5.m2.1.1.cmml"><mn id="S3.F2.5.m2.1.1.2" xref="S3.F2.5.m2.1.1.2.cmml">10</mn><mn id="S3.F2.5.m2.1.1.3" xref="S3.F2.5.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.F2.5.m2.1c"><apply id="S3.F2.5.m2.1.1.cmml" xref="S3.F2.5.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.5.m2.1.1.1.cmml" xref="S3.F2.5.m2.1.1">superscript</csymbol><cn type="integer" id="S3.F2.5.m2.1.1.2.cmml" xref="S3.F2.5.m2.1.1.2">10</cn><cn type="integer" id="S3.F2.5.m2.1.1.3.cmml" xref="S3.F2.5.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.5.m2.1d">10^{2}</annotation></semantics></math> pageviews, while the rightmost bin encompasses entities with over <math id="S3.F2.6.m3.1" class="ltx_Math" alttext="10^{5}" display="inline"><semantics id="S3.F2.6.m3.1b"><msup id="S3.F2.6.m3.1.1" xref="S3.F2.6.m3.1.1.cmml"><mn id="S3.F2.6.m3.1.1.2" xref="S3.F2.6.m3.1.1.2.cmml">10</mn><mn id="S3.F2.6.m3.1.1.3" xref="S3.F2.6.m3.1.1.3.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="S3.F2.6.m3.1c"><apply id="S3.F2.6.m3.1.1.cmml" xref="S3.F2.6.m3.1.1"><csymbol cd="ambiguous" id="S3.F2.6.m3.1.1.1.cmml" xref="S3.F2.6.m3.1.1">superscript</csymbol><cn type="integer" id="S3.F2.6.m3.1.1.2.cmml" xref="S3.F2.6.m3.1.1.2">10</cn><cn type="integer" id="S3.F2.6.m3.1.1.3.cmml" xref="S3.F2.6.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.m3.1d">10^{5}</annotation></semantics></math> pageviews.</figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">To ensure a fair comparison between DA and RAG methods, we limit our focus to Wikipedia pages whose corresponding entities appear in the PopQA dataset. This setup also mirrors real-world industry practices, where entities and their corresponding textual descriptions are related to companies‚Äô specific internal concepts.
</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>RAG Approach</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We utilize a variety of retrieval models to retrieve relevant passages for the RAG approach: BM25&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Robertson and Zaragoza, <a href="#bib.bib30" title="" class="ltx_ref">2009</a>)</cite>, Contriever&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Izacard et&nbsp;al., <a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite>, DPR&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et&nbsp;al., <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>, and a two-stages re-ranker that combines BM25 with DPR, all implemented according to the BEIR benchmark&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Thakur et&nbsp;al., <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite>. Moreover, we utilize an ideal retrieval setup, where the summary paragraph of the Wikipedia page for the mentioned entity in the question is considered. We adopt this method because the true evidence for annotating passages is not available, yet the summary section assumably contains the answer to the question. The efficacy of this approach is evidenced in Figure&nbsp;<a href="#A4.F5" title="Figure 5 ‚Ä£ Appendix D Detailed Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> in Appendix&nbsp;<a href="#A4" title="Appendix D Detailed Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>, which shows QA performance with the the ideal retriever achieves the highest results.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">After retrieving the most relevant passage for a question, we apply zero-shot prompting for generative prediction using a straightforward template:
<code id="S3.SS1.p2.1.1" class="ltx_verbatim ltx_font_typewriter">"Context: &lt;context&gt;. Based on the provided </code>
<br class="ltx_break"><code id="S3.SS1.p2.1.2" class="ltx_verbatim ltx_font_typewriter"> context, answer the question: &lt;question&gt;"</code>.
We experiment with three sizes of the FlanT5 model&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chung et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite>‚Äîsmall, base, and large‚Äîto examine the impact of model scale on performance. Following <cite class="ltx_cite ltx_citemacro_citet">Mallen et&nbsp;al. (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite>, we report on the Accuracy metric, where a prediction is considered accurate if it contains a substring that exactly matches any of the provided gold answers.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Fine-Tuning Approach</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We generate training data for the fine tuning approach using two distinct data augmentation methods.
The first one is the End-to-End approach&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ushio et&nbsp;al., <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite>, utilizing a model specifically trained for paragraph-level QA generation, using the T5 model&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al., <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite>, referred to as <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold">E2E</span> in our paper. Additionally, we explore the generation of synthetic training data by prompting an LLM, utilizing Zephyr&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Tunstall et&nbsp;al., <a href="#bib.bib36" title="" class="ltx_ref">2023</a>)</cite> for QA generation. This method is referred to as the <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_bold">Prompt</span> method in our discussion.
We generate QAs exclusively using the summary section of Wikipedia pages to ensures a fair comparison between FT and RAG with ideal retriever.
Further details on the QA generation process, including the prompt, input and output examples, and statistics of the generated QAs, are provided in the Appendix&nbsp;<a href="#A2" title="Appendix B QA Generation ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">After generating QA pairs, we proceeded to fine-tune the FlanT5 models using two approaches: full parameter tuning (<span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Full</span>) and Parameter Efficient Fine-Tuning (<span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_bold">PEFT</span>). Within the range of PEFT techniques&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zaken et&nbsp;al., <a href="#bib.bib38" title="" class="ltx_ref">2022</a>; Liu et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2022</a>; Ma et&nbsp;al., <a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite>, we utilize QLoRA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dettmers et&nbsp;al., <a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite>, chosen for its broad acceptance in the field&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kaddour et&nbsp;al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>; Naveed et&nbsp;al., <a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite> and efficient use of computational resources we had at our disposal. More information about FT approaches and hyper parameters are detailed in Appendix&nbsp;<a href="#A3" title="Appendix C Fine-Tuning Setup ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments and Results</h2>

<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S4.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Rec@1</span></th>
<th id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">Rec@3</span></th>
<th id="S4.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.1.1.1.4.1" class="ltx_text ltx_font_bold">Rec@5</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">BM25</th>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">36.14</td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">73.76</td>
<td id="S4.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">81.68</td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Contriever</th>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_align_center">72.77</td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_align_center">91.58</td>
<td id="S4.T1.1.3.2.4" class="ltx_td ltx_align_center">96.04</td>
</tr>
<tr id="S4.T1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">BM25+DPR</th>
<td id="S4.T1.1.4.3.2" class="ltx_td ltx_align_center"><span id="S4.T1.1.4.3.2.1" class="ltx_text ltx_font_bold">79.21</span></td>
<td id="S4.T1.1.4.3.3" class="ltx_td ltx_align_center">91.58</td>
<td id="S4.T1.1.4.3.4" class="ltx_td ltx_align_center">92.57</td>
</tr>
<tr id="S4.T1.1.5.4" class="ltx_tr">
<th id="S4.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b">DPR</th>
<td id="S4.T1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b">78.21</td>
<td id="S4.T1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T1.1.5.4.3.1" class="ltx_text ltx_font_bold">92.57</span></td>
<td id="S4.T1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T1.1.5.4.4.1" class="ltx_text ltx_font_bold">93.64</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span> Performance comparison of retrieval models on our corpus, with DPR models outperforming the rest. The relevant passage for every question is assumed to be the first paragraph of the Wikipedia page.</figcaption>
</figure>
<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text ltx_font_bold">Retrieval performance.</span>
Figure&nbsp;<a href="#S4.F3" title="Figure 3 ‚Ä£ 4 Experiments and Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> compares the performance of retrieval models against ideal retriever (assumed to be the ground truth here) across popularity buckets. Since only the highest-ranked passage is included in the input prompt, our analysis is focused on Recall@1. The results indicate that retrieval effectiveness is higher in low popular entities compare to popular entities. This is probably due to limited occurrences of noisy passages for low popular entities. Table&nbsp;<a href="#S4.T1" title="Table 1 ‚Ä£ 4 Experiments and Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides the overall retrieval scores for all methods.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p"><span id="S4.p2.1.1" class="ltx_text ltx_font_bold">FT and RAG comparison.</span>
We assess the impact of RAG and FT in four distinct configurations:
(i) Neither FT nor RAG used <span id="S4.p2.1.2" class="ltx_text ltx_font_italic">(-FT-RAG)</span>,
(ii) RAG used without FT <span id="S4.p2.1.3" class="ltx_text ltx_font_italic">(-FT+RAG)</span>,
(iii) FT applied without RAG <span id="S4.p2.1.4" class="ltx_text ltx_font_italic">(+FT-RAG)</span>, and
(iv)) both FT and RAG employed <span id="S4.p2.1.5" class="ltx_text ltx_font_italic">(+FT+RAG)</span>.
The findings are detailed in Table&nbsp;<a href="#S4.T2" title="Table 2 ‚Ä£ 4 Experiments and Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Generally, FT improves accuracy of the base model, but does not reach the effectiveness of RAG on the base model. The optimal performance is achieved by integrating both FT and RAG.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"></th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_nopad_l ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"></th>
<td id="S4.T2.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">-FT/</span></td>
<td id="S4.T2.1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">-FT/</span></td>
<td id="S4.T2.1.1.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.1.1.5.1" class="ltx_text ltx_font_bold">+FT/</span></td>
<td id="S4.T2.1.1.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.1.1.6.1" class="ltx_text ltx_font_bold">+FT/</span></td>
</tr>
<tr id="S4.T2.1.2.2" class="ltx_tr">
<th id="S4.T2.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.2.2.1.1" class="ltx_text ltx_font_bold">FT</span></th>
<th id="S4.T2.1.2.2.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.2.2.2.1" class="ltx_text ltx_font_bold">QA</span></th>
<td id="S4.T2.1.2.2.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.2.2.3.1" class="ltx_text ltx_font_bold">-RAG</span></td>
<td id="S4.T2.1.2.2.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.2.2.4.1" class="ltx_text ltx_font_bold">+RAG</span></td>
<td id="S4.T2.1.2.2.5" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.2.2.5.1" class="ltx_text ltx_font_bold">-RAG</span></td>
<td id="S4.T2.1.2.2.6" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.2.2.6.1" class="ltx_text ltx_font_bold">+RAG</span></td>
</tr>
<tr id="S4.T2.1.3.3" class="ltx_tr">
<th id="S4.T2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="6"><span id="S4.T2.1.3.3.1.1" class="ltx_text ltx_font_bold">FlanT5-small</span></th>
</tr>
<tr id="S4.T2.1.4.4" class="ltx_tr">
<th id="S4.T2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T2.1.4.4.1.1" class="ltx_text">PEFT</span></th>
<th id="S4.T2.1.4.4.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T2.1.4.4.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="4"><span id="S4.T2.1.4.4.3.1" class="ltx_text">3.05</span></td>
<td id="S4.T2.1.4.4.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="4"><span id="S4.T2.1.4.4.4.1" class="ltx_text">26.13</span></td>
<td id="S4.T2.1.4.4.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">5.53</td>
<td id="S4.T2.1.4.4.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">22.91</td>
</tr>
<tr id="S4.T2.1.5.5" class="ltx_tr">
<th id="S4.T2.1.5.5.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T2.1.5.5.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">7.01</td>
<td id="S4.T2.1.5.5.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">49.85</td>
</tr>
<tr id="S4.T2.1.6.6" class="ltx_tr">
<th id="S4.T2.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T2.1.6.6.1.1" class="ltx_text">Full</span></th>
<th id="S4.T2.1.6.6.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T2.1.6.6.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">6.35</td>
<td id="S4.T2.1.6.6.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">10.21</td>
</tr>
<tr id="S4.T2.1.7.7" class="ltx_tr">
<th id="S4.T2.1.7.7.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T2.1.7.7.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.7.7.2.1" class="ltx_text ltx_font_bold">8.52</span></td>
<td id="S4.T2.1.7.7.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.7.7.3.1" class="ltx_text ltx_font_bold">49.88</span></td>
</tr>
<tr id="S4.T2.1.8.8" class="ltx_tr">
<th id="S4.T2.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="6"><span id="S4.T2.1.8.8.1.1" class="ltx_text ltx_font_bold">FlanT5-base</span></th>
</tr>
<tr id="S4.T2.1.9.9" class="ltx_tr">
<th id="S4.T2.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T2.1.9.9.1.1" class="ltx_text">PEFT</span></th>
<th id="S4.T2.1.9.9.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T2.1.9.9.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="4"><span id="S4.T2.1.9.9.3.1" class="ltx_text">6.72</span></td>
<td id="S4.T2.1.9.9.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="4"><span id="S4.T2.1.9.9.4.1" class="ltx_text">63.13</span></td>
<td id="S4.T2.1.9.9.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">6.94</td>
<td id="S4.T2.1.9.9.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">51.61</td>
</tr>
<tr id="S4.T2.1.10.10" class="ltx_tr">
<th id="S4.T2.1.10.10.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T2.1.10.10.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">9.92</td>
<td id="S4.T2.1.10.10.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.10.10.3.1" class="ltx_text ltx_font_bold">63.29</span></td>
</tr>
<tr id="S4.T2.1.11.11" class="ltx_tr">
<th id="S4.T2.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T2.1.11.11.1.1" class="ltx_text">Full</span></th>
<th id="S4.T2.1.11.11.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T2.1.11.11.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">8.63</td>
<td id="S4.T2.1.11.11.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">24.17</td>
</tr>
<tr id="S4.T2.1.12.12" class="ltx_tr">
<th id="S4.T2.1.12.12.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T2.1.12.12.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.12.12.2.1" class="ltx_text ltx_font_bold">11.41</span></td>
<td id="S4.T2.1.12.12.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">60.26</td>
</tr>
<tr id="S4.T2.1.13.13" class="ltx_tr">
<th id="S4.T2.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="6"><span id="S4.T2.1.13.13.1.1" class="ltx_text ltx_font_bold">FlanT5-large</span></th>
</tr>
<tr id="S4.T2.1.14.14" class="ltx_tr">
<th id="S4.T2.1.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T2.1.14.14.1.1" class="ltx_text">PEFT</span></th>
<th id="S4.T2.1.14.14.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T2.1.14.14.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="4"><span id="S4.T2.1.14.14.3.1" class="ltx_text">8.41</span></td>
<td id="S4.T2.1.14.14.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="4"><span id="S4.T2.1.14.14.4.1" class="ltx_text">58.12</span></td>
<td id="S4.T2.1.14.14.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">8.22</td>
<td id="S4.T2.1.14.14.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">55.26</td>
</tr>
<tr id="S4.T2.1.15.15" class="ltx_tr">
<th id="S4.T2.1.15.15.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T2.1.15.15.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">12.15</td>
<td id="S4.T2.1.15.15.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.15.15.3.1" class="ltx_text ltx_font_bold">61.71</span></td>
</tr>
<tr id="S4.T2.1.16.16" class="ltx_tr">
<th id="S4.T2.1.16.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T2.1.16.16.1.1" class="ltx_text">Full</span></th>
<th id="S4.T2.1.16.16.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T2.1.16.16.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.16.16.3.1" class="ltx_text ltx_font_bold">16.23</span></td>
<td id="S4.T2.1.16.16.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">13.31</td>
</tr>
<tr id="S4.T2.1.17.17" class="ltx_tr">
<th id="S4.T2.1.17.17.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T2.1.17.17.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">13.91</td>
<td id="S4.T2.1.17.17.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">58.60</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span> Accuracy of base and fine-tuned models, both with and without RAG. The RAG results presented are based on ideal retrieval.</figcaption>
</figure>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2403.01432/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="170" height="108" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span> Recall@1 for four retrieval models across different popularity levels. The results indicate that retrieval models perform more effectively with less popular knowledge compared to more popular ones.</figcaption>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Figure&nbsp;<a href="#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrates that fine-tuning enhances QA accuracy across all popularity levels for the FlanT5-small model, with the greatest improvements in the most and least popular buckets. While fine-tuning boosts performance for less popular categories in smaller models, this advantage decreases in base models and disappears in larger models; see Figure&nbsp;<a href="#A4.F4" title="Figure 4 ‚Ä£ Appendix D Detailed Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> for more details. This is likely due to the improved memorization of larger models.</p>
</div>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p id="S4.p4.1" class="ltx_p"><span id="S4.p4.1.1" class="ltx_text ltx_font_bold">Effect of external parameters on RAG and FT.</span>
We delve into additional factors that influence model specialization in processing less popular knowledge. A key aspect under review is the effect of full tuning versus PEFT. Table&nbsp;<a href="#S4.T2" title="Table 2 ‚Ä£ 4 Experiments and Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows PEFT leads to smaller gains in the <span id="S4.p4.1.2" class="ltx_text ltx_font_italic">+FT-RAG</span> compared to full FT, yet it significantly improves accuracy in the <span id="S4.p4.1.3" class="ltx_text ltx_font_italic">+FT+RAG</span> setup. This suggests that PEFT enables the LLM to maintain its reasoning abilities based on the provided prompts.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">Our investigation also covers two QA generation techniques. The E2E method generates over 12 times more QA than the prompting method (cf. Table&nbsp;<a href="#A2.T4" title="Table 4 ‚Ä£ B.2 E2E Method ‚Ä£ Appendix B QA Generation ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> in Appendix&nbsp;<a href="#A3" title="Appendix C Fine-Tuning Setup ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>), while prompt-based method generates more quality QAs. The results in Table&nbsp;<a href="#S4.T2" title="Table 2 ‚Ä£ 4 Experiments and Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show that fine-tuned models trained on prompt-generated data outperform E2E-generated ones. This highlights the significance of synthetic data quality over quantity.</p>
</div>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.1" class="ltx_p">The performance of the retrieval model is another important consideration. Table&nbsp;<a href="#S4.T3" title="Table 3 ‚Ä£ 4 Experiments and Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> presents the QA system‚Äôs accuracy utilizing various retrieval strategies within the RAG framework. The findings demonstrate a direct correlation between the retrieval model performance and the overall QA accuracy, underscoring the retrieval model‚Äôs impact on the downstream task‚Äôs effectiveness.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">FT</span></th>
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">QA</span></th>
<th id="S4.T3.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<div id="S4.T3.1.1.1.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.8pt;height:26.2pt;vertical-align:-9.7pt;"><span class="ltx_transformed_inner" style="width:26.3pt;transform:translate(-9.71pt,0pt) rotate(-90deg) ;">
<p id="S4.T3.1.1.1.3.1.1" class="ltx_p"><span id="S4.T3.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">BM25</span></p>
</span></div>
</th>
<th id="S4.T3.1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<div id="S4.T3.1.1.1.4.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.8pt;height:45.9pt;vertical-align:-19.5pt;"><span class="ltx_transformed_inner" style="width:45.9pt;transform:translate(-19.53pt,0pt) rotate(-90deg) ;">
<p id="S4.T3.1.1.1.4.1.1" class="ltx_p"><span id="S4.T3.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Contriever</span></p>
</span></div>
</th>
<th id="S4.T3.1.1.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<div id="S4.T3.1.1.1.5.1" class="ltx_inline-block ltx_transformed_outer" style="width:7.7pt;height:55.8pt;vertical-align:-24.9pt;"><span class="ltx_transformed_inner" style="width:55.8pt;transform:translate(-24.08pt,1.25pt) rotate(-90deg) ;">
<p id="S4.T3.1.1.1.5.1.1" class="ltx_p"><span id="S4.T3.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold">BM25+DPR</span></p>
</span></div>
</th>
<th id="S4.T3.1.1.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<div id="S4.T3.1.1.1.6.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.8pt;height:21.8pt;vertical-align:-7.5pt;"><span class="ltx_transformed_inner" style="width:21.8pt;transform:translate(-7.49pt,0pt) rotate(-90deg) ;">
<p id="S4.T3.1.1.1.6.1.1" class="ltx_p"><span id="S4.T3.1.1.1.6.1.1.1" class="ltx_text ltx_font_bold">DPR</span></p>
</span></div>
</th>
<th id="S4.T3.1.1.1.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<div id="S4.T3.1.1.1.7.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:21.4pt;vertical-align:-7.2pt;"><span class="ltx_transformed_inner" style="width:21.4pt;transform:translate(-7.22pt,0pt) rotate(-90deg) ;">
<p id="S4.T3.1.1.1.7.1.1" class="ltx_p"><span id="S4.T3.1.1.1.7.1.1.1" class="ltx_text ltx_font_bold">Ideal</span></p>
</span></div>
</th>
</tr>
<tr id="S4.T3.1.2.2" class="ltx_tr">
<th id="S4.T3.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="2"><span id="S4.T3.1.2.2.1.1" class="ltx_text ltx_font_bold">FlanT5-small</span></th>
<th id="S4.T3.1.2.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">9.76</th>
<th id="S4.T3.1.2.2.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">17.22</th>
<th id="S4.T3.1.2.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">20.80</th>
<th id="S4.T3.1.2.2.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">21.41</th>
<th id="S4.T3.1.2.2.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">26.13</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.3.1" class="ltx_tr">
<th id="S4.T3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T3.1.3.1.1.1" class="ltx_text">PEFT</span></th>
<th id="S4.T3.1.3.1.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T3.1.3.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">13.13</td>
<td id="S4.T3.1.3.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">17.30</td>
<td id="S4.T3.1.3.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">19.74</td>
<td id="S4.T3.1.3.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">19.81</td>
<td id="S4.T3.1.3.1.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">22.91</td>
</tr>
<tr id="S4.T3.1.4.2" class="ltx_tr">
<th id="S4.T3.1.4.2.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T3.1.4.2.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">20.82</td>
<td id="S4.T3.1.4.2.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">34.87</td>
<td id="S4.T3.1.4.2.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">40.45</td>
<td id="S4.T3.1.4.2.5" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">41.25</td>
<td id="S4.T3.1.4.2.6" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">49.85</td>
</tr>
<tr id="S4.T3.1.5.3" class="ltx_tr">
<th id="S4.T3.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T3.1.5.3.1.1" class="ltx_text">Full</span></th>
<th id="S4.T3.1.5.3.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T3.1.5.3.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">6.48</td>
<td id="S4.T3.1.5.3.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">9.11</td>
<td id="S4.T3.1.5.3.5" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">9.31</td>
<td id="S4.T3.1.5.3.6" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">9.48</td>
<td id="S4.T3.1.5.3.7" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">10.21</td>
</tr>
<tr id="S4.T3.1.6.4" class="ltx_tr">
<th id="S4.T3.1.6.4.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T3.1.6.4.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.6.4.2.1" class="ltx_text ltx_font_bold">20.95</span></td>
<td id="S4.T3.1.6.4.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.6.4.3.1" class="ltx_text ltx_font_bold">35.09</span></td>
<td id="S4.T3.1.6.4.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.6.4.4.1" class="ltx_text ltx_font_bold">40.52</span></td>
<td id="S4.T3.1.6.4.5" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.6.4.5.1" class="ltx_text ltx_font_bold">41.53</span></td>
<td id="S4.T3.1.6.4.6" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.6.4.6.1" class="ltx_text ltx_font_bold">49.88</span></td>
</tr>
<tr id="S4.T3.1.7.5" class="ltx_tr">
<th id="S4.T3.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="2"><span id="S4.T3.1.7.5.1.1" class="ltx_text ltx_font_bold">FlanT5-base</span></th>
<td id="S4.T3.1.7.5.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">26.56</td>
<td id="S4.T3.1.7.5.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">43.42</td>
<td id="S4.T3.1.7.5.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">50.41</td>
<td id="S4.T3.1.7.5.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">51.35</td>
<td id="S4.T3.1.7.5.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">63.13</td>
</tr>
<tr id="S4.T3.1.8.6" class="ltx_tr">
<th id="S4.T3.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T3.1.8.6.1.1" class="ltx_text">PEFT</span></th>
<th id="S4.T3.1.8.6.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T3.1.8.6.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">22.72</td>
<td id="S4.T3.1.8.6.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">35.80</td>
<td id="S4.T3.1.8.6.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">42.05</td>
<td id="S4.T3.1.8.6.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">42.84</td>
<td id="S4.T3.1.8.6.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">51.61</td>
</tr>
<tr id="S4.T3.1.9.7" class="ltx_tr">
<th id="S4.T3.1.9.7.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T3.1.9.7.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.9.7.2.1" class="ltx_text ltx_font_bold">26.83</span></td>
<td id="S4.T3.1.9.7.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.9.7.3.1" class="ltx_text ltx_font_bold">43.20</span></td>
<td id="S4.T3.1.9.7.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.9.7.4.1" class="ltx_text ltx_font_bold">50.59</span></td>
<td id="S4.T3.1.9.7.5" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.9.7.5.1" class="ltx_text ltx_font_bold">51.43</span></td>
<td id="S4.T3.1.9.7.6" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.9.7.6.1" class="ltx_text ltx_font_bold">63.29</span></td>
</tr>
<tr id="S4.T3.1.10.8" class="ltx_tr">
<th id="S4.T3.1.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T3.1.10.8.1.1" class="ltx_text">Full</span></th>
<th id="S4.T3.1.10.8.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T3.1.10.8.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">11.78</td>
<td id="S4.T3.1.10.8.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">18.53</td>
<td id="S4.T3.1.10.8.5" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">20.59</td>
<td id="S4.T3.1.10.8.6" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">21.15</td>
<td id="S4.T3.1.10.8.7" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">24.17</td>
</tr>
<tr id="S4.T3.1.11.9" class="ltx_tr">
<th id="S4.T3.1.11.9.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T3.1.11.9.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">25.77</td>
<td id="S4.T3.1.11.9.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">41.78</td>
<td id="S4.T3.1.11.9.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">48.52</td>
<td id="S4.T3.1.11.9.5" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">49.39</td>
<td id="S4.T3.1.11.9.6" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">60.26</td>
</tr>
<tr id="S4.T3.1.12.10" class="ltx_tr">
<th id="S4.T3.1.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="2"><span id="S4.T3.1.12.10.1.1" class="ltx_text ltx_font_bold">FlanT5-large</span></th>
<td id="S4.T3.1.12.10.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">26.74</td>
<td id="S4.T3.1.12.10.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">40.53</td>
<td id="S4.T3.1.12.10.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">46.86</td>
<td id="S4.T3.1.12.10.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">47.57</td>
<td id="S4.T3.1.12.10.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">58.12</td>
</tr>
<tr id="S4.T3.1.13.11" class="ltx_tr">
<th id="S4.T3.1.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T3.1.13.11.1.1" class="ltx_text">PEFT</span></th>
<th id="S4.T3.1.13.11.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T3.1.13.11.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">25.72</td>
<td id="S4.T3.1.13.11.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">39.25</td>
<td id="S4.T3.1.13.11.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">45.34</td>
<td id="S4.T3.1.13.11.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">45.90</td>
<td id="S4.T3.1.13.11.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">55.26</td>
</tr>
<tr id="S4.T3.1.14.12" class="ltx_tr">
<th id="S4.T3.1.14.12.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T3.1.14.12.2" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.14.12.2.1" class="ltx_text ltx_font_bold">28.60</span></td>
<td id="S4.T3.1.14.12.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.14.12.3.1" class="ltx_text ltx_font_bold">43.45</span></td>
<td id="S4.T3.1.14.12.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.14.12.4.1" class="ltx_text ltx_font_bold">50.15</span></td>
<td id="S4.T3.1.14.12.5" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.14.12.5.1" class="ltx_text ltx_font_bold">50.91</span></td>
<td id="S4.T3.1.14.12.6" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T3.1.14.12.6.1" class="ltx_text ltx_font_bold">61.71</span></td>
</tr>
<tr id="S4.T3.1.15.13" class="ltx_tr">
<th id="S4.T3.1.15.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T3.1.15.13.1.1" class="ltx_text">Full</span></th>
<th id="S4.T3.1.15.13.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</th>
<td id="S4.T3.1.15.13.3" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">7.67</td>
<td id="S4.T3.1.15.13.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">12.29</td>
<td id="S4.T3.1.15.13.5" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">12.01</td>
<td id="S4.T3.1.15.13.6" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">12.44</td>
<td id="S4.T3.1.15.13.7" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">13.31</td>
</tr>
<tr id="S4.T3.1.16.14" class="ltx_tr">
<th id="S4.T3.1.16.14.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</th>
<td id="S4.T3.1.16.14.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">25.54</td>
<td id="S4.T3.1.16.14.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">40.88</td>
<td id="S4.T3.1.16.14.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">46.82</td>
<td id="S4.T3.1.16.14.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">47.87</td>
<td id="S4.T3.1.16.14.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">58.60</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span> Accuracy of RAG for base and fine-tuned LLMs using different retrieval models.</figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this study, we performed a comparative analysis to evaluate the effectiveness of RAG versus FT, with a focus on less popular knowledge. Our results reveal that FT leads to consistent performance improvements for all entities,
with the most notable gains seen in the most and least popular categories. We found that RAG stands out as a more effective strategy, especially when used in combination with fine-tuning. This advantage decreases however in larger models. Additionally, we observed that the success of both RAG and FT strategies improves with the enhancement of the retrieval and data augmentation models‚Äô performance. Understanding the critical importance of synthetic data quality, future work will focus on developing an effective method for data creation.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Our study primarily addressed a template-based QA task, suggesting future research could tackle more complex QA challenges, such as multi-hop QA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ho et&nbsp;al., <a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite> or Conversational QA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Christmann et&nbsp;al., <a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite>.
Furthermore, we noted that our use of Zephyr for synthetic data generation has limitations in following Chain of Thought (CoT), highlighting the potential benefits of advanced data generation techniques to enhance data quality and reduce fine-tuning cost.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This publication is part of the project LESSEN with project number NWA.1389.20.183 of the research program NWA ORC 2020/21 which is (partly) financed by the Dutch Research Council (NWO).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alberti et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin, and Michael Collins. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/P19-1620" title="" class="ltx_ref ltx_href">Synthetic QA corpora generation with roundtrip consistency</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers</em>, pages 6168‚Äì6173. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Akari Asai, Sewon Min, Zexuan Zhong, and Danqi Chen. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2023.ACL-TUTORIALS.6" title="" class="ltx_ref ltx_href">Retrieval-based language models and applications</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts, ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 41‚Äì46. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.11511" title="" class="ltx_ref ltx_href">Self-rag: Learning to retrieve, generate, and critique through self-reflection</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.11511.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Askari et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Arian Askari, Mohammad Aliannejadi, Chuan Meng, Evangelos Kanoulas, and Suzan Verberne. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.emnlp-main.623" title="" class="ltx_ref ltx_href">Expand, highlight, generate: Rl-driven document generation for passage reranking</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 10087‚Äì10099. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Anthony Chen, Pallavi Gudipati, Shayne Longpre, Xiao Ling, and Sameer Singh. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2021.ACL-LONG.345" title="" class="ltx_ref ltx_href">Evaluating entity disambiguation and the role of popularity in retrieval-based NLP</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021</em>, pages 4472‚Äì4485. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung&nbsp;Won Chung, Charles Sutton, Sebastian Gehrmann, and et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://jmlr.org/papers/v24/22-1144.html" title="" class="ltx_ref ltx_href">Palm: Scaling language modeling with pathways</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, 24:240:1‚Äì240:113.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Christmann et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Philipp Christmann, Rishiraj&nbsp;Saha Roy, and Gerhard Weikum. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3477495.3531815" title="" class="ltx_ref ltx_href">Conversational question answering on heterogeneous sources</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">SIGIR ‚Äô22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022</em>, pages 144‚Äì154. ACM.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Christmann et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Philipp Christmann, Rishiraj&nbsp;Saha Roy, and Gerhard Weikum. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2306.12235" title="" class="ltx_ref ltx_href">Compmix: A benchmark for heterogeneous question answering</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.12235.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang&nbsp;Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent&nbsp;Y. Zhao, Yanping Huang, Andrew&nbsp;M. Dai, Hongkun Yu, Slav Petrov, Ed&nbsp;H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc&nbsp;V. Le, and Jason Wei. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2210.11416" title="" class="ltx_ref ltx_href">Scaling instruction-finetuned language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2210.11416.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de&nbsp;Luis&nbsp;Balaguer et&nbsp;al. (2024)</span>
<span class="ltx_bibblock">
Maria&nbsp;Angels de&nbsp;Luis&nbsp;Balaguer, Vinamra Benara, Renato&nbsp;Luiz de&nbsp;Freitas&nbsp;Cunha, Roberto de&nbsp;M.&nbsp;Estev√£o&nbsp;Filho, Todd Hendry, Daniel Holstein, Jennifer Marsman, Nick Mecklenburg, Sara Malvar, Leonardo&nbsp;O. Nunes, Rafael Padilha, Morris Sharp, Bruno Silva, Swati Sharma, Vijay Aski, and Ranveer Chandra. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2401.08406" title="" class="ltx_ref ltx_href">RAG vs fine-tuning: Pipelines, tradeoffs, and a case study on agriculture</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2401.08406.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2305.14314" title="" class="ltx_ref ltx_href">Qlora: Efficient finetuning of quantized llms</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.14314.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Godbole and Jia (2023)</span>
<span class="ltx_bibblock">
Ameya Godbole and Robin Jia. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2023.FINDINGS-EACL.71" title="" class="ltx_ref ltx_href">Benchmarking long-tail generalization with likelihood splits</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EACL 2023, Dubrovnik, Croatia, May 2-6, 2023</em>, pages 933‚Äì953. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Xanh Ho, Anh-Khoa Duong&nbsp;Nguyen, Saku Sugawara, and Akiko Aizawa. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.coling-main.580" title="" class="ltx_ref ltx_href">Constructing a multi-hop QA dataset for comprehensive evaluation of reasoning steps</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on Computational Linguistics</em>, pages 6609‚Äì6625, Barcelona, Spain (Online). International Committee on Computational Linguistics.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=jKN1pXi7b0" title="" class="ltx_ref ltx_href">Unsupervised dense information retrieval with contrastive learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Trans. Mach. Learn. Res.</em>, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaddour et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2307.10169" title="" class="ltx_ref ltx_href">Challenges and applications of large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.10169.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.mlr.press/v202/kandpal23a.html" title="" class="ltx_ref ltx_href">Large language models struggle to learn long-tail knowledge</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning, ICML</em>, volume 202 of <em id="bib.bib16.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 15696‚Äì15707. PMLR.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick S.&nbsp;H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2020.EMNLP-MAIN.550" title="" class="ltx_ref ltx_href">Dense passage retrieval for open-domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020</em>, pages 6769‚Äì6781. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kasai et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jungo Kasai, Keisuke Sakaguchi, Yoichi Takahashi, Ronan&nbsp;Le Bras, Akari Asai, Xinyan Yu, Dragomir&nbsp;R. Radev, Noah&nbsp;A. Smith, Yejin Choi, and Kentaro Inui. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2207.13332" title="" class="ltx_ref ltx_href">Realtime QA: what‚Äôs the answer right now?</a>

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2207.13332.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Patrick S.&nbsp;H. Lewis, Ludovic Denoyer, and Sebastian Riedel. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/P19-1484" title="" class="ltx_ref ltx_href">Unsupervised question answering by cloze translation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers</em>, pages 4896‚Äì4910. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Patrick S.&nbsp;H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, Sebastian Riedel, and Douwe Kiela. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html" title="" class="ltx_ref ltx_href">Retrieval-augmented generation for knowledge-intensive NLP tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Patrick S.&nbsp;H. Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich K√ºttler, Aleksandra Piktus, Pontus Stenetorp, and Sebastian Riedel. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/TACL_A_00415" title="" class="ltx_ref ltx_href">PAQ: 65 million probably-asked questions and what you can do with them</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, 9:1098‚Äì1115.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin Raffel. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2022/hash/0cde695b83bd186c1fd456302888454c-Abstract-Conference.html" title="" class="ltx_ref ltx_href">Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xueguang Ma, Liang Wang, Nan Yang, Furu Wei, and Jimmy Lin. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.08319" title="" class="ltx_ref ltx_href">Fine-tuning llama for multi-stage text retrieval</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.08319.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mallen et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2023.ACL-LONG.546" title="" class="ltx_ref ltx_href">When not to trust language models: Investigating effectiveness of parametric and non-parametric memories</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</em>, pages 9802‚Äì9822. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Sewon Min, Weijia Shi, Mike Lewis, Xilun Chen, Wen-tau Yih, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2023.FINDINGS-ACL.132" title="" class="ltx_ref ltx_href">Nonparametric masked language modeling</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 2097‚Äì2118. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mosbach et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Dietrich Klakow, and Yanai Elazar. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2023.FINDINGS-ACL.779" title="" class="ltx_ref ltx_href">Few-shot fine-tuning vs. in-context learning: A fair comparison and evaluation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 12284‚Äì12314. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naveed et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Humza Naveed, Asad&nbsp;Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Nick Barnes, and Ajmal Mian. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2307.06435" title="" class="ltx_ref ltx_href">A comprehensive overview of large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.06435.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ovadia et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Oded Ovadia, Menachem Brief, Moshik Mishaeli, and Oren Elisha. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2312.05934" title="" class="ltx_ref ltx_href">Fine-tuning or retrieval? comparing knowledge injection in llms</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.05934.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J. Liu. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://jmlr.org/papers/v21/20-074.html" title="" class="ltx_ref ltx_href">Exploring the limits of transfer learning with a unified text-to-text transformer</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, 21:140:1‚Äì140:67.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson and Zaragoza (2009)</span>
<span class="ltx_bibblock">
Stephen&nbsp;E. Robertson and Hugo Zaragoza. 2009.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1561/1500000019" title="" class="ltx_ref ltx_href">The probabilistic relevance framework: BM25 and beyond</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Found. Trends Inf. Retr.</em>, 3(4):333‚Äì389.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sciavolino et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Christopher Sciavolino, Zexuan Zhong, Jinhyuk Lee, and Danqi Chen. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2021.EMNLP-MAIN.496" title="" class="ltx_ref ltx_href">Simple entity-centric questions challenge dense retrievers</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021</em>, pages 6138‚Äì6148. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shuster et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2021.FINDINGS-EMNLP.320" title="" class="ltx_ref ltx_href">Retrieval augmentation reduces hallucination in conversation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021</em>, pages 3784‚Äì3803. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soudani et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Heydar Soudani, Evangelos Kanoulas, and Faegheh Hasibi. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3583780.3615291" title="" class="ltx_ref ltx_href">Data augmentation for conversational AI</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, CIKM 2023, Birmingham, United Kingdom, October 21-25, 2023</em>, pages 5220‚Äì5223. ACM.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Kai Sun, Yifan&nbsp;Ethan Xu, Hanwen Zha, Yue Liu, and Xin&nbsp;Luna Dong. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2308.10168" title="" class="ltx_ref ltx_href">Head-to-tail: How knowledgeable are large language models (llm)? A.K.A. will llms replace knowledge graphs?</a>

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.10168.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thakur et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Nandan Thakur, Nils Reimers, Andreas R√ºckl√©, Abhishek Srivastava, and Iryna Gurevych. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/65b9eea6e1cc6bb9f0cd2a47751a186f-Abstract-round2.html" title="" class="ltx_ref ltx_href">BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tunstall et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Cl√©mentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sanseviero, Alexander&nbsp;M. Rush, and Thomas Wolf. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.16944" title="" class="ltx_ref ltx_href">Zephyr: Direct distillation of LM alignment</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.16944.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ushio et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Asahi Ushio, Fernando Alva-Manchego, and Jose Camacho-Collados. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-acl.899" title="" class="ltx_ref ltx_href">An empirical comparison of LM-based question and answer generation methods</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 14262‚Äì14272, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zaken et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Elad&nbsp;Ben Zaken, Yoav Goldberg, and Shauli Ravfogel. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2022.ACL-SHORT.1" title="" class="ltx_ref ltx_href">Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, pages 1‚Äì9. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_font_bold ltx_title_appendix">Appendix</h2>

</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Data Preprocessing</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Among the various datasets offering factual QA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Christmann et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023</a>; Sciavolino et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>, we selected one of the most recent ones, named <span id="A1.p1.1.1" class="ltx_text ltx_font_smallcaps">PopQA</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Mallen et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite>. <span id="A1.p1.1.2" class="ltx_text ltx_font_smallcaps">PopQA</span> dataset comprises approximately 14,000 templated questions aimed at eliciting single-entity answers, based on 16 types of relationships extracted from Wikipedia.
To assess the popularity of each entity, we followed the previous studies&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Mallen et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2023</a>; Sciavolino et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2021</a>; Chen et&nbsp;al., <a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>, using Wikipedia pageviews as a metric for popularity. We accumulated the pageviews for each entity from the start to the end of 2023.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p">Furthermore, we acquired the relevant Wikipedia page for each entity. Our corpus was then constructed by segmenting each Wikipedia page into a summary paragraph and subsequent additional paragraphs.
For this purpose, we utilized the Wikipedia dump from March 2022, available in the HuggingFace dataset repository at <a target="_blank" href="https://huggingface.co/datasets/wikipedia" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/wikipedia</a>.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>QA Generation</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Prompt Method</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.1" class="ltx_p">For generating synthetic QAs based on a given context, we used the following prompt:

<span id="A2.SS1.p1.1.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="A2.SS1.p1.1.1.1" class="ltx_p"><span id="A2.SS1.p1.1.1.1.1" class="ltx_text ltx_font_italic">You are a question-answer generator. Your goal is to generate question-answer pairs given the Context.</span> 
<br class="ltx_break"></span>
<span id="A2.SS1.p1.1.1.2" class="ltx_p"><span id="A2.SS1.p1.1.1.2.1" class="ltx_text ltx_font_bold ltx_font_italic">Example output:</span> {‚Äôquestion‚Äô: ‚Äù, ‚Äôanswer‚Äô: ‚Äù} 
<br class="ltx_break"></span>
<span id="A2.SS1.p1.1.1.3" class="ltx_p"><span id="A2.SS1.p1.1.1.3.1" class="ltx_text ltx_font_bold ltx_font_italic">Context:</span> $CONTEXT 
<br class="ltx_break"></span>
<span id="A2.SS1.p1.1.1.4" class="ltx_p"><span id="A2.SS1.p1.1.1.4.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 1:<span id="A2.SS1.p1.1.1.4.1.1" class="ltx_text ltx_font_medium"> Identify spans that are likely to be answers to questions, identify as many as possible.</span></span></span>
<span id="A2.SS1.p1.1.1.5" class="ltx_p"><span id="A2.SS1.p1.1.1.5.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 2:<span id="A2.SS1.p1.1.1.5.1.1" class="ltx_text ltx_font_medium"> For each identified span, generate a question.</span></span></span>
<span id="A2.SS1.p1.1.1.6" class="ltx_p"><span id="A2.SS1.p1.1.1.6.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 3:<span id="A2.SS1.p1.1.1.6.1.1" class="ltx_text ltx_font_medium"> Respond to the question in only a few tokens concisely.</span></span></span>
<span id="A2.SS1.p1.1.1.7" class="ltx_p"><span id="A2.SS1.p1.1.1.7.1" class="ltx_text ltx_font_bold ltx_font_italic">Step 4:<span id="A2.SS1.p1.1.1.7.1.1" class="ltx_text ltx_font_medium"> Output in JSON format following [‚Ä¶]</span></span> 
<br class="ltx_break"></span>
<span id="A2.SS1.p1.1.1.8" class="ltx_p"><span id="A2.SS1.p1.1.1.8.1" class="ltx_text ltx_font_italic">Ensure that you distinctly label and delineate Steps 1, 2, 3, and 4. Let‚Äôs think step by step:</span></span>
</span></p>
</div>
<div id="A2.SS1.p2" class="ltx_para">
<p id="A2.SS1.p2.1" class="ltx_p">Our test set comprises template-based QAs that feature single-entity answers. To generate QAs similar to those in the test set, we instructed the LLM to utilize a Chain of Thought (CoT) approach. However, we observed that not all the generated QAs adhered to our instructions. Below are some examples of QAs generated using this prompt-based approach:
</p>
</div>
<div id="A2.SS1.p3" class="ltx_para">
<span id="A2.SS1.p3.1" class="ltx_inline-block ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<span id="A2.SS1.p3.1.1" class="ltx_p"><span id="A2.SS1.p3.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Entity:</span> John Mayne 
<br class="ltx_break"></span>
<span id="A2.SS1.p3.1.2" class="ltx_p"><span id="A2.SS1.p3.1.2.1" class="ltx_text ltx_font_bold ltx_font_italic">Context:</span>
John Mayne was a Scottish printer, journalist and poet born in Dumfries. In 1780, his poem The Siller Gun appeared in its original form in Ruddiman‚Äôs Magazine, published by Walter Ruddiman in Edinburgh. It is a humorous work on an ancient custom in Dumfries of shooting for the SÃàiller Gun.·∏¶e also wrote a poem on Hallowe‚Äôen in 1780 which influenced Robert Burns‚Äôs 1785 poem Halloween. Mayne also wrote a version of the ballad Helen of Kirkconnel. His verses were admired by Walter Scott. 
<br class="ltx_break"></span>
<span id="A2.SS1.p3.1.3" class="ltx_p"><span id="A2.SS1.p3.1.3.1" class="ltx_text ltx_font_bold ltx_font_italic">Synthetic QAs:</span></span>
<span id="A2.SS1.p3.1.4" class="ltx_p"><span id="A2.SS1.p3.1.4.1" class="ltx_text ltx_font_italic">question 1:</span> "Who was John Mayne?"</span>
<span id="A2.SS1.p3.1.5" class="ltx_p"><span id="A2.SS1.p3.1.5.1" class="ltx_text ltx_font_italic">answer 1:</span> "John Mayne was a Scottish printer, journalist, and poet from Dumfries. (1780 poem: The Siller Gun)" 
<br class="ltx_break"></span>
<span id="A2.SS1.p3.1.6" class="ltx_p"><span id="A2.SS1.p3.1.6.1" class="ltx_text ltx_font_italic">question 2:</span> "What poem did John Mayne write in 1780 called Hallowe‚Äôen?",</span>
<span id="A2.SS1.p3.1.7" class="ltx_p"><span id="A2.SS1.p3.1.7.1" class="ltx_text ltx_font_italic">answer 2:</span> "Hallowe‚Äôen is a poem by John Mayne (1780)"</span>
</span>
</div>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>E2E Method</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p">We employed models trained for the Question Answer Generation (QAG) task, specifically using the T5-large model optimized for the End-to-End (E2E) approach, which was reported to deliver superior performance on the QA as the downstream task&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ushio et&nbsp;al., <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite>. However, a notable drawback of the E2E method is its limited control over the quality and quantity of generated samples. Additionally, due to the T5 model‚Äôs input token limitation, the input text must be restricted to 512 tokens. To ensure a fair comparison, we applied the same token limit to the inputs used with the prompt-based approach. Table&nbsp;<a href="#A2.T4" title="Table 4 ‚Ä£ B.2 E2E Method ‚Ä£ Appendix B QA Generation ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents statistics for the QAs generated by both the prompt and E2E methods, using the same corpus.</p>
</div>
<figure id="A2.T4" class="ltx_table">
<table id="A2.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A2.T4.1.1.1" class="ltx_tr">
<th id="A2.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="A2.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Relationship</span></th>
<th id="A2.T4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="A2.T4.1.1.1.2.1" class="ltx_text ltx_font_bold">#Ent.</span></th>
<td id="A2.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="2"><span id="A2.T4.1.1.1.3.1" class="ltx_text ltx_font_bold">Train-set</span></td>
<td id="A2.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="2"><span id="A2.T4.1.1.1.4.1" class="ltx_text ltx_font_bold">Dev-set</span></td>
</tr>
<tr id="A2.T4.1.2.2" class="ltx_tr">
<td id="A2.T4.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</td>
<td id="A2.T4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</td>
<td id="A2.T4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">E2E</td>
<td id="A2.T4.1.2.2.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Prompt</td>
</tr>
<tr id="A2.T4.1.3.3" class="ltx_tr">
<th id="A2.T4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">occupation</th>
<th id="A2.T4.1.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">532</th>
<td id="A2.T4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">16398</td>
<td id="A2.T4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">1872</td>
<td id="A2.T4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">1822</td>
<td id="A2.T4.1.3.3.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">207</td>
</tr>
<tr id="A2.T4.1.4.4" class="ltx_tr">
<th id="A2.T4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">place of birth</th>
<th id="A2.T4.1.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">584</th>
<td id="A2.T4.1.4.4.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">19993</td>
<td id="A2.T4.1.4.4.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">2043</td>
<td id="A2.T4.1.4.4.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">2221</td>
<td id="A2.T4.1.4.4.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">227</td>
</tr>
<tr id="A2.T4.1.5.5" class="ltx_tr">
<th id="A2.T4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">genre</th>
<th id="A2.T4.1.5.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">1619</th>
<td id="A2.T4.1.5.5.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">56101</td>
<td id="A2.T4.1.5.5.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">5338</td>
<td id="A2.T4.1.5.5.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">6233</td>
<td id="A2.T4.1.5.5.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">593</td>
</tr>
<tr id="A2.T4.1.6.6" class="ltx_tr">
<th id="A2.T4.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">father</th>
<th id="A2.T4.1.6.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">570</th>
<td id="A2.T4.1.6.6.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">37676</td>
<td id="A2.T4.1.6.6.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">2092</td>
<td id="A2.T4.1.6.6.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">4186</td>
<td id="A2.T4.1.6.6.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">406</td>
</tr>
<tr id="A2.T4.1.7.7" class="ltx_tr">
<th id="A2.T4.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">country</th>
<th id="A2.T4.1.7.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">838</th>
<td id="A2.T4.1.7.7.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">19362</td>
<td id="A2.T4.1.7.7.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">2769</td>
<td id="A2.T4.1.7.7.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">2151</td>
<td id="A2.T4.1.7.7.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">307</td>
</tr>
<tr id="A2.T4.1.8.8" class="ltx_tr">
<th id="A2.T4.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">producer</th>
<th id="A2.T4.1.8.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">1520</th>
<td id="A2.T4.1.8.8.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">41992</td>
<td id="A2.T4.1.8.8.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">4235</td>
<td id="A2.T4.1.8.8.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">4665</td>
<td id="A2.T4.1.8.8.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">470</td>
</tr>
<tr id="A2.T4.1.9.9" class="ltx_tr">
<th id="A2.T4.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">director</th>
<th id="A2.T4.1.9.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">1999</th>
<td id="A2.T4.1.9.9.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">27578</td>
<td id="A2.T4.1.9.9.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">4644</td>
<td id="A2.T4.1.9.9.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">3064</td>
<td id="A2.T4.1.9.9.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">515</td>
</tr>
<tr id="A2.T4.1.10.10" class="ltx_tr">
<th id="A2.T4.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">capital of</th>
<th id="A2.T4.1.10.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">363</th>
<td id="A2.T4.1.10.10.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">109141</td>
<td id="A2.T4.1.10.10.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">3388</td>
<td id="A2.T4.1.10.10.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">12126</td>
<td id="A2.T4.1.10.10.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">376</td>
</tr>
<tr id="A2.T4.1.11.11" class="ltx_tr">
<th id="A2.T4.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">screenwriter</th>
<th id="A2.T4.1.11.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">1999</th>
<td id="A2.T4.1.11.11.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">59680</td>
<td id="A2.T4.1.11.11.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">6932</td>
<td id="A2.T4.1.11.11.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">6631</td>
<td id="A2.T4.1.11.11.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">770</td>
</tr>
<tr id="A2.T4.1.12.12" class="ltx_tr">
<th id="A2.T4.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">composer</th>
<th id="A2.T4.1.12.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">978</th>
<td id="A2.T4.1.12.12.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">46574</td>
<td id="A2.T4.1.12.12.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">4064</td>
<td id="A2.T4.1.12.12.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">5174</td>
<td id="A2.T4.1.12.12.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">451</td>
</tr>
<tr id="A2.T4.1.13.13" class="ltx_tr">
<th id="A2.T4.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">color</th>
<th id="A2.T4.1.13.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">34</th>
<td id="A2.T4.1.13.13.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">4396</td>
<td id="A2.T4.1.13.13.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">160</td>
<td id="A2.T4.1.13.13.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">488</td>
<td id="A2.T4.1.13.13.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">17</td>
</tr>
<tr id="A2.T4.1.14.14" class="ltx_tr">
<th id="A2.T4.1.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">religion</th>
<th id="A2.T4.1.14.14.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">338</th>
<td id="A2.T4.1.14.14.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">18776</td>
<td id="A2.T4.1.14.14.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">1449</td>
<td id="A2.T4.1.14.14.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">2086</td>
<td id="A2.T4.1.14.14.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">161</td>
</tr>
<tr id="A2.T4.1.15.15" class="ltx_tr">
<th id="A2.T4.1.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">sport</th>
<th id="A2.T4.1.15.15.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">547</th>
<td id="A2.T4.1.15.15.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">14760</td>
<td id="A2.T4.1.15.15.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">1710</td>
<td id="A2.T4.1.15.15.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">1629</td>
<td id="A2.T4.1.15.15.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">189</td>
</tr>
<tr id="A2.T4.1.16.16" class="ltx_tr">
<th id="A2.T4.1.16.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">author</th>
<th id="A2.T4.1.16.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">1514</th>
<td id="A2.T4.1.16.16.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">46399</td>
<td id="A2.T4.1.16.16.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">5319</td>
<td id="A2.T4.1.16.16.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">5155</td>
<td id="A2.T4.1.16.16.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">590</td>
</tr>
<tr id="A2.T4.1.17.17" class="ltx_tr">
<th id="A2.T4.1.17.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">mother</th>
<th id="A2.T4.1.17.17.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">187</th>
<td id="A2.T4.1.17.17.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">7592</td>
<td id="A2.T4.1.17.17.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">477</td>
<td id="A2.T4.1.17.17.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">843</td>
<td id="A2.T4.1.17.17.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">52</td>
</tr>
<tr id="A2.T4.1.18.18" class="ltx_tr">
<th id="A2.T4.1.18.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">capital</th>
<th id="A2.T4.1.18.18.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">645</th>
<td id="A2.T4.1.18.18.3" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">28467</td>
<td id="A2.T4.1.18.18.4" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">1322</td>
<td id="A2.T4.1.18.18.5" class="ltx_td ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">3162</td>
<td id="A2.T4.1.18.18.6" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1.25pt;padding-bottom:1.25pt;">146</td>
</tr>
<tr id="A2.T4.1.19.19" class="ltx_tr">
<th id="A2.T4.1.19.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">All</th>
<th id="A2.T4.1.19.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">14,267</th>
<td id="A2.T4.1.19.19.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">491,525</td>
<td id="A2.T4.1.19.19.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">38,114</td>
<td id="A2.T4.1.19.19.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">56,803</td>
<td id="A2.T4.1.19.19.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">5,949</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span> Statistics for generated QA pairs using two methods. The E2E approach, utilizing T5-large, generates over 12 times more QAs compared to the prompt method.</figcaption>
</figure>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Fine-Tuning Setup</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">We fine-tuned three versions of FlanT5 (small, base, and large)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chung et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite> model. Our fine-tuning experiments encompassed both full parameter tuning and PEFT. Our focus was particularly on the QLoRA method&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dettmers et&nbsp;al., <a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite>, which is widely recognized for its approach of keeping the pre-trained model parameters fixed while incorporating trainable rank decomposition matrices into each layer of the Transformer architecture. Despite experimenting with various numbers of training epochs, we observed that the results plateaued after a certain point. Table&nbsp;<a href="#A3.T5" title="Table 5 ‚Ä£ Appendix C Fine-Tuning Setup ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> included presents our finalized hyperparameters for fine-tuning.</p>
</div>
<figure id="A3.T5" class="ltx_table">
<table id="A3.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T5.1.1.1" class="ltx_tr">
<th id="A3.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="A3.T5.1.1.1.1.1" class="ltx_text ltx_font_bold">Hyperparameter</span></th>
<th id="A3.T5.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="A3.T5.1.1.1.2.1" class="ltx_text ltx_font_bold">Value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T5.1.2.1" class="ltx_tr">
<th id="A3.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Epochs</th>
<td id="A3.T5.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">10</td>
</tr>
<tr id="A3.T5.1.3.2" class="ltx_tr">
<th id="A3.T5.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Batch size</th>
<td id="A3.T5.1.3.2.2" class="ltx_td ltx_align_right" style="padding-top:1.25pt;padding-bottom:1.25pt;">128</td>
</tr>
<tr id="A3.T5.1.4.3" class="ltx_tr">
<th id="A3.T5.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">Learing rate</th>
<td id="A3.T5.1.4.3.2" class="ltx_td ltx_align_right" style="padding-top:1.25pt;padding-bottom:1.25pt;">2e-4</td>
</tr>
<tr id="A3.T5.1.5.4" class="ltx_tr">
<th id="A3.T5.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">PEFT, alpha</th>
<td id="A3.T5.1.5.4.2" class="ltx_td ltx_align_right" style="padding-top:1.25pt;padding-bottom:1.25pt;">16</td>
</tr>
<tr id="A3.T5.1.6.5" class="ltx_tr">
<th id="A3.T5.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1.25pt;padding-bottom:1.25pt;">PEFT, rank</th>
<td id="A3.T5.1.6.5.2" class="ltx_td ltx_align_right" style="padding-top:1.25pt;padding-bottom:1.25pt;">32</td>
</tr>
<tr id="A3.T5.1.7.6" class="ltx_tr">
<th id="A3.T5.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">PEFT, dropout</th>
<td id="A3.T5.1.7.6.2" class="ltx_td ltx_align_right ltx_border_b" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.05</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span> Hyperparameters for Fine-Tuning: Following a thorough hyperparameter search, we standardized the hyperparameters across all versions of the model.</figcaption>
</figure>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Detailed Results</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">In this section, we provide additional results that corroborate our primary findings. Figure&nbsp;<a href="#A4.F4" title="Figure 4 ‚Ä£ Appendix D Detailed Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the impact of fine-tuning versus non-fine-tuning, both with and without RAG, on the FlanT5-base and FlanT5-large models. It further demonstrates that fine-tuning enhances accuracy across both the least-popular and popular buckets.
It should be noted that for the base model, the improvement in accuracy for the least-popular bucket is less significant compared to that of the small and large models.</p>
</div>
<figure id="A4.F4" class="ltx_figure"><img src="/html/2403.01432/assets/x4.png" id="A4.F4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="221" height="277" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Correlation between the popularity of the subject entity in a question and the impact of RAG and FT on the performance of FlanT5-base and FlanT5-large in QA.</figcaption>
</figure>
<div id="A4.p2" class="ltx_para">
<p id="A4.p2.1" class="ltx_p">Figure&nbsp;<a href="#A4.F5" title="Figure 5 ‚Ä£ Appendix D Detailed Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> displays the accuracy of the RAG approach before fine-tuning across various retrieval models. The Ideal retriever, which retrieves the summary section of the corresponding Wikipedia page, yields the highest accuracy.</p>
</div>
<figure id="A4.F5" class="ltx_figure"><img src="/html/2403.01432/assets/x5.png" id="A4.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="341" height="328" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span> The accuracy of the RAG approach before fine-tuning across all relationships in <span id="A4.F5.2.1" class="ltx_text ltx_font_smallcaps">PopQA</span> dataset.</figcaption>
</figure>
<div id="A4.p3" class="ltx_para">
<p id="A4.p3.1" class="ltx_p">Figure&nbsp;<a href="#A4.F6" title="Figure 6 ‚Ä£ Appendix D Detailed Results ‚Ä£ Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> compares the performance before and after fine-tuning, both with and without RAG, across all relationships. It also demonstrates that fine-tuning alone does not achieve the same level of accuracy as the RAG method for most of relationships.</p>
</div>
<figure id="A4.F6" class="ltx_figure"><img src="/html/2403.01432/assets/x6.png" id="A4.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="341" height="328" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span> The accuracy of the RAG approach before and after fine-tuning across all relationships in <span id="A4.F6.2.1" class="ltx_text ltx_font_smallcaps">PopQA</span> dataset.</figcaption>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.01431" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.01432" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2403.01432">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.01432" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.01433" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 16:22:13 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>