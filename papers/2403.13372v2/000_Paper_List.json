{
    "2403.13372v2": {
        "paper_id": "2403.13372v2",
        "abs_url": "https://arxiv.org/abs/2403.13372v2",
        "pdf_url": "https://arxiv.org/pdf/2403.13372v2.pdf",
        "supp_url": null,
        "src_website": "ArXiv",
        "download_name": "2403.13372v2_LlamaFactory_Unified_Efficient_Fine-Tuning_of_100+_Language_Models.pdf",
        "title": "LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models",
        "year": null,
        "paper_venue": null,
        "authors": [
            "Yaowei Zheng",
            "Richong Zhang",
            "Junhao Zhang",
            "Yanhan Ye",
            "Zheyan Luo",
            "Yongqiang Ma"
        ],
        "abstract": "and already received over 13,000 stars and 1,600 forks.",
        "comments": "12 pages, preprint",
        "official_code_urls": [
            "https://github.com/hiyouga/llama-factory"
        ],
        "pwc_page_url": "https://paperswithcode.com/paper/llamafactory-unified-efficient-fine-tuning-of",
        "bibtex": "@misc{zheng2024llamafactory,\n      title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models}, \n      author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Yongqiang Ma},\n      year={2024},\n      eprint={2403.13372},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}"
    }
}