<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.18223] A Survey of Large Language Models</title><meta property="og:description" content="Ever since the Turing Test was proposed in the 1950s, humans have explored the mastering of language intelligence by machine.
Language is essentially a complex, intricate system of human expressions governed by grammat…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey of Large Language Models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Survey of Large Language Models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.18223">

<!--Generated on Thu Feb 29 17:19:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Large Language Models; Emergent Abilities; Adaptation Tuning;
Utilization; Alignment; Capacity Evaluation
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Survey of Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wayne Xin Zhao, Kun Zhou*, Junyi Li*, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie and Ji-Rong Wen
</span><span class="ltx_author_notes">
Version: v13 (major update on November 23, 2023).
GitHub link: <a target="_blank" href="https://github.com/RUCAIBox/LLMSurvey" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/RUCAIBox/LLMSurvey</a>
Chinese version link: <a target="_blank" href="https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese.pdf</a>
* K. Zhou and J. Li contribute equally to this work.
The authors are mainly with Gaoling School of Artificial Intelligence and School of Information, Renmin University of China, Beijing, China; Jian-Yun Nie is with DIRO, Université de Montréal, Canada. 
<br class="ltx_break">Contact e-mail: batmanfly@gmail.com
<span id="id1.1.id1" class="ltx_text" style="color:#FF0000;">The authors of this survey paper reserve all the copyrights of the figures/tables, and any use of these materials for publication purpose must be officially granted by the survey authors.</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">1950년대에 튜링 테스트가 제안된 이후로 인간은 기계에 의한 언어 지능의 숙달을 탐구해 왔다. 언어는 본질적으로 문법적 규칙에 의해 지배되는 인간 표현의 복잡하고 복잡한 시스템이다. 언어를 이해하고 이해하기 위한 능력 있는 인공지능(AI) 알고리즘을 개발하는 것은 상당한 도전을 제기한다. 주요 접근법으로 <em class="ltx_emph ltx_font_italic" id="id2.id1.1">language modeling</em>은 지난 20년 동안 언어 이해와 생성을 위해 널리 연구되어 통계 언어 모델에서 신경 언어 모델로 진화했다. 최근 대규모 말뭉치를 대상으로 트랜스포머 모델을 사전 학습하여 다양한 자연어 처리(Natural Language Processing, NLP) 작업을 해결하는 데 강한 능력을 보이는 사전 학습 언어 모델(PLM)이 제안되고 있다. 연구진은 모델 스케일링이 개선된 모델 용량으로 이어질 수 있음을 발견했기 때문에 매개변수 스케일을 훨씬 더 큰 크기로 증가시켜 스케일링 효과를 추가로 조사한다. 흥미롭게도, 파라미터 스케일이 특정 레벨을 초과하는 경우, 이들 확대된 언어 모델들은 상당한 성능 향상을 달성할 뿐만 아니라, 소규모 언어 모델들에 존재하지 않는 일부 특수 능력들(<em class="ltx_emph ltx_font_italic" id="id2.id1.2">e.g.,</em> in-context learning)을 나타낸다(<em class="ltx_emph ltx_font_italic" id="id2.id1.3">e.g.,</em> BERT). 다양한 파라미터 스케일에서 언어 모델을 구별하기 위해, 연구 커뮤니티는 상당한 크기의 PLM에 대한 용어 <em class="ltx_emph ltx_font_italic" id="id2.id1.4">large language models(/LLM)</em>을 만들었다(<em class="ltx_emph ltx_font_italic" id="id2.id1.5">e.g.,</em>은 수백억 또는 수천억 개의 파라미터를 포함한다). 최근 LLMs에 대한 연구는 학계와 산업계 모두에서 크게 발전해 왔으며, 주목할 만한 진전은 LLMs을 기반으로 개발된 강력한 AI 챗봇인 ChatGPT(ChatGPT)의 출시로 사회적으로 많은 관심을 받고 있다. LLM의 기술적 진화는 AI 커뮤니티 전체에 중요한 영향을 미치고 있으며, 이는 AI 알고리즘을 개발하고 사용하는 방식에 혁명을 일으킬 것이다. 이러한 급속한 기술적 진보를 고려하여, 본 조사에서는 배경, 주요 발견 및 주류 기술을 도입하여 LLM의 최근 발전을 검토한다. 특히 LLM의 4가지 주요 측면, 즉 사전 훈련, 적응 조정, 활용 및 용량 평가에 중점을 둔다. 또한 LLM 개발을 위한 가용 자원을 요약하고 향후 방향을 위한 나머지 문제에 대해 논의한다. 이 조사는 LLM에 대한 문헌에 대한 최신 검토를 제공하며, 이는 연구자와 엔지니어 모두에게 유용한 자원이 될 수 있다.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Large Language Models; Emergent Abilities; Adaptation Tuning;
Utilization; Alignment; Capacity Evaluation

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span id="S1.2.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.1" class="ltx_logical-block">
<div id="S1.1.p1" class="ltx_para">
<p id="S1.1.p1.1" class="ltx_p ltx_align_right"><span id="S1.1.p1.1.1" class="ltx_text ltx_font_italic">“The limits of my language mean the limits of my world.”</span></p>
<p id="S1.1.p1.2" class="ltx_p ltx_align_right">—<em id="S1.1.p1.2.1" class="ltx_emph ltx_font_italic">Ludwig Wittgenstein</em></p>
</div>
</div>
<figure id="S1.F1" class="ltx_figure">
<div id="S1.F1.5" class="ltx_block">
<figure id="S1.F1.2.fig1" class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_middle" style="width:195.1pt;"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="461" height="266" alt="Refer to caption">
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption">(a) Query="Language Model"</figcaption>
</figure>
<figure id="S1.F1.4.fig1" class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_middle" style="width:195.1pt;"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x2.png" id="S1.F1.3.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="461" height="269" alt="Refer to caption">
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption">(b) Query="Large Language Model"</figcaption>
</figure>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 1:</span>Keyphases "<em class="ltx_emph ltx_font_italic" id="S1.F1.9.1">language model</em>"(2018년 6월 이후) 및 "<em class="ltx_emph ltx_font_italic" id="S1.F1.10.2">large language model</em>"(2019년 10월 이후)를 포함하는 arXiv 논문의 누적 수 추세는 각각 다음과 같다. 통계량은 제목 또는 초록의 키프레이즈를 월별로 조회하여 정확한 일치를 사용하여 계산됩니다. 우리는 두 키프레이즈에 대해 서로 다른 x축 범위를 설정했는데, 이는 "언어 모델"이 이전 시간에 탐색되었기 때문이다. 우리는 LLM의 연구 진행 과정에서 중요한 랜드마크에 해당하는 지점에 레이블을 붙인다. ChatGPT의 출시 후 급격한 증가가 발생한다: 제목 또는 초록에 "<em class="ltx_emph ltx_font_italic" id="S1.F1.11.3">large language model</em>"을 포함하는 출판된 arXiv 논문의 평균 수는 하루에 0.40개에서 8.58개로 증가한다(그림 <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>(b)).</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x3.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="148" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 2:</span> 과제 해결 능력의 관점에서 4세대 언어 모델(LM)의 진화 과정. 각 단계에 대한 시점은 매우 정확하지 않을 수 있으며, 각 단계에서 가장 대표적인 연구의 발표일에 따라 주로 시간을 설정한다. 신경 언어 모델의 경우 NPLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite> (“<em class="ltx_emph ltx_font_italic" id="S1.F2.3.1">A neural probabilistic language model</em>”) 및 NLPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite> (“<em class="ltx_emph ltx_font_italic" id="S1.F2.4.2">Natural language processing (almost) from scratch</em>”) 두 가지 접근법을 명명하기 위해 두 대표적인 연구의 논문 제목을 축약한다. 공간 제한으로 인해 우리는 이 그림에서 모든 대표적인 연구를 나열하지 않는다.</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">언어는 인간의 표현 능력과 의사소통 능력이 두드러지며, 유아기에 발달하여 평생에 걸쳐 진화한다.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib3" title="">3</a>, <a class="ltx_ref" href="#bib.bib4" title="">4</a>]</cite> 그러나 기계는 강력한 인공지능(AI) 알고리즘이 탑재되지 않는 한 인간의 언어 형태로 이해하고 소통하는 능력을 자연스럽게 파악할 수 없다. 이 목표를 달성하기 위해 기계가 인간 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite>와 같이 읽고 쓰고 통신할 수 있도록 하는 것은 오랜 연구 과제였다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">기술적으로 <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">language modeling (LM)</em>은 기계의 언어 지능을 발전시키는 주요 접근법 중 하나이다. 일반적으로 LM은 미래의 (또는 누락된) 토큰의 확률을 예측하기 위해 단어 시퀀스의 생성 가능성을 모델링하는 것을 목표로 한다. LM에 대한 연구는 문헌에서 광범위하게 주목을 받았으며, 이는 크게 네 가지 개발 단계로 나눌 수 있다.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.3"><math alttext="\bullet" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mo id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S1.p3.3.1">Statistical language models (SLM)</em>. SLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib6" title="">6</a>, <a class="ltx_ref" href="#bib.bib7" title="">7</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite>는 1990년대에 상승했던 <em class="ltx_emph ltx_font_italic" id="S1.p3.3.2">statistical learning</em> 메소드를 기반으로 개발되었다. 기본 아이디어는 마르코프 가정, <em class="ltx_emph ltx_font_italic" id="S1.p3.3.3">e.g.,</em> 가장 최근의 컨텍스트를 기반으로 다음 단어를 예측하는 것을 기반으로 단어 예측 모델을 구축하는 것이다. 고정 컨텍스트 길이 <math alttext="n" class="ltx_Math" display="inline" id="S1.p3.2.m2.1"><semantics id="S1.p3.2.m2.1a"><mi id="S1.p3.2.m2.1.1" xref="S1.p3.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><ci id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">n</annotation></semantics></math>를 갖는 SLM은 <math alttext="n" class="ltx_Math" display="inline" id="S1.p3.3.m3.1"><semantics id="S1.p3.3.m3.1a"><mi id="S1.p3.3.m3.1.1" xref="S1.p3.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S1.p3.3.m3.1b"><ci id="S1.p3.3.m3.1.1.cmml" xref="S1.p3.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.3.m3.1c">n</annotation></semantics></math>-gram 언어 모델, <em class="ltx_emph ltx_font_italic" id="S1.p3.3.4">e.g.,</em> bigram 및 trigram 언어 모델이라고도 한다. SLM은 정보 검색(IR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>, <a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite>와 자연어 처리(NLP) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib13" title="">13</a>, <a class="ltx_ref" href="#bib.bib14" title="">14</a>]</cite>에서 작업 성능을 향상시키기 위해 널리 적용되어 왔다. 그러나 이들은 차원이라는 저주에 시달리는 경우가 많다. 즉, 기하급수적인 수의 전이 확률을 추정해야 하기 때문에 고차 언어 모델을 정확하게 추정하는 것은 어렵다. 따라서 데이터 희소성 문제를 완화하기 위해 백오프 추정<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib15" title="">15</a>]</cite> 및 Good-Turing 추정<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite>와 같은 특별히 설계된 스무딩 전략이 도입되었다.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S1.p4.1.m1.1"><semantics id="S1.p4.1.m1.1a"><mo id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><ci id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">Neural language models (NLM)</em>. NLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib17" title="">17</a>, <a class="ltx_ref" href="#bib.bib18" title="">18</a>]</cite> neural networks, <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">e.g.,</em> multi-layer perceptron (MLP) and recurrent neural networks (RNNs). 주목할 만한 공헌으로 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite>에서 <em class="ltx_emph ltx_font_italic" id="S1.p4.1.3">distributed representation</em>의 개념을 도입하여 집계된 컨텍스트 특징에 조건화된 단어 예측 함수를 구축했다(<em class="ltx_emph ltx_font_italic" id="S1.p4.1.4">i.e.,</em> the distributed word vectors). 텍스트 데이터에 대한 효과적인 특징을 학습한다는 개념을 확장하여 다양한 NLP 작업에 대한 통일된 종단 간 솔루션을 구축하기 위해 일반적인 신경망 접근법이 개발되었다. 또한, 워드2vec<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib19" title="">19</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>는 분산 단어 표현을 학습하기 위한 단순화된 얕은 신경망을 구축하기 위해 제안되었으며, 이는 다양한 NLP 태스크에 걸쳐 매우 효과적인 것으로 입증되었다. 이러한 연구는 표상 학습을 위한 언어 모델의 사용을 시작했으며(단어 시퀀스 모델링 외에도), NLP 분야에 중요한 영향을 미쳤다.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p" id="S1.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S1.p5.1.m1.1"><semantics id="S1.p5.1.m1.1a"><mo id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><ci id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S1.p5.1.1">Pre-trained language models (PLM)</em>. 초기 시도로서, ELMo<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib21" title="">21</a>]</cite>는 양방향 LSTM(biLSTM) 네트워크(고정 단어 표현을 학습하는 대신)를 먼저 사전 학습한 다음 특정 다운스트림 태스크에 따라 biLSTM 네트워크를 미세 조정함으로써 상황 인식 단어 표현을 캡처하기 위해 제안되었다. 또한, 병렬성이 높은 트랜스포머 구조 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>를 기반으로, BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite>는 대규모 언라벨 코퍼라에서 특별히 설계된 사전 훈련 태스크를 사용하여 양방향 언어 모델을 사전 훈련함으로써 제안되었다. 이러한 사전 훈련된 문맥 인식 단어 표현은 범용 의미 자질로서 매우 효과적이며, 이는 NLP 태스크의 성능 바를 크게 상승시켰다. 이 연구는 "<em class="ltx_emph ltx_font_italic" id="S1.p5.1.2">pre-training</em> 및 <em class="ltx_emph ltx_font_italic" id="S1.p5.1.3">fine-tuning</em>" 학습 패러다임을 설정하는 많은 후속 작업에 영감을 주었다. 이 패러다임에 따라 PLM에 대한 많은 연구가 개발되었으며, 다른 아키텍처인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>, <a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite> (<em class="ltx_emph ltx_font_italic" id="S1.p5.1.4">e.g.,</em> GPT-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite> and BART <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite>) 또는 개선된 사전 훈련 전략인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>, <a class="ltx_ref" href="#bib.bib29" title="">29</a>]</cite>를 도입했다. 이 패러다임에서는 다양한 다운스트림 작업에 적응하기 위해 PLM을 미세 조정해야 하는 경우가 많다.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p" id="S1.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S1.p6.1.m1.1"><semantics id="S1.p6.1.m1.1a"><mo id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><ci id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S1.p6.1.1">Large language models (LLM)</em>. 연구자들은 스케일링 PLM (<em class="ltx_emph ltx_font_italic" id="S1.p6.1.2">e.g.,</em> scaling model size or data size)이 다운스트림 태스크에서 모델 용량을 향상 시키는 경우가 많다는 것을 발견했다 (<em class="ltx_emph ltx_font_italic" id="S1.p6.1.3">i.e.,</em> following the scaling law <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>). 많은 연구에서 더 큰 PLM을 훈련하여 성능 한계를 탐구했다(<em class="ltx_emph ltx_font_italic" id="S1.p6.1.4">e.g.,</em> 175B 매개 변수 GPT-3 및 540B 매개 변수 PaLM). 스케일링은 주로 모델 크기(유사한 아키텍처 및 사전 훈련 작업 포함)에서 수행되지만, 이러한 큰 크기의 PLM은 일련의 복잡한 작업을 해결하는 데 있어 더 작은 PLM(<em class="ltx_emph ltx_font_italic" id="S1.p6.1.5">e.g.,</em> 330M-parameter BERT 및 1.5B-parameter GPT-2)과 다른 동작을 표시하고 놀라운 능력(<em class="ltx_emph ltx_font_italic" id="S1.p6.1.6">emergent 능력</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>라고 함)을 보여준다. 예를 들어 GPT-3는 <em class="ltx_emph ltx_font_italic" id="S1.p6.1.7">in-context learning</em>을 통해 적은 샷 작업을 해결할 수 있지만 GPT-2는 잘 할 수 없습니다. 따라서, 연구 커뮤니티는 증가하는 연구 관심을 끄는 "<em class="ltx_emph ltx_font_italic" id="S1.p6.1.8">large language models (LLM)</em>”<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Note that a LLM is not necessarily more capable than a small PLM, and emergent abilities may not occur in some LLMs. </span></span></span> for these large-sized PLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib32" title="">32</a>, <a class="ltx_ref" href="#bib.bib33" title="">33</a>, <a class="ltx_ref" href="#bib.bib34" title="">34</a>, <a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite>를 인용한다(도<a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> 참조). LLM의 놀라운 응용은 인간과 놀라운 대화 능력을 제시하는 GPT 시리즈의 LLM을 대화용으로 적응시키는 <em class="ltx_emph ltx_font_italic" id="S1.p6.1.9">ChatGPT</em><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://openai.com/blog/chatgpt/</span></span></span>이다. <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>에서 ChatGPT의 출시 이후 LLM과 관련된 arXiv 논문의 급격한 증가를 관찰할 수 있다.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p class="ltx_p" id="S1.p7.1">앞서 논의한 바와 같이 언어 모델은 LLM을 특별히 위한 새로운 기술적 개념이 아니라 수십 년에 걸쳐 인공지능의 발전과 함께 진화해 왔다. 초기 언어 모델은 주로 텍스트 데이터를 모델링하고 생성하는 것을 목표로 하는 반면, 최신 언어 모델(<em class="ltx_emph ltx_font_italic" id="S1.p7.1.1">e.g.,</em> GPT-4)은 복잡한 과제 해결에 중점을 둔다. <em class="ltx_emph ltx_font_italic" id="S1.p7.1.2">language modeling</em>에서 <em class="ltx_emph ltx_font_italic" id="S1.p7.1.3">task solving</em>은 과학적 사고의 중요한 도약이며, 이는 연구사에서 언어 모델의 발전을 이해하는 열쇠이다. 과제 해결의 관점에서 4세대 언어 모델은 서로 다른 수준의 모델 역량을 보여주었다. <a class="ltx_ref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에서는 언어 모델의 진화 과정을 과제 해결 능력 측면에서 설명한다. 먼저, 통계적 언어 모델들은 주로 몇몇 특정 태스크들(<em class="ltx_emph ltx_font_italic" id="S1.p7.1.4">e.g.,</em> retrieval or speech tasks)에서 지원되었는데, 여기서 예측되거나 추정된 확률들은 태스크-특정 접근법들의 성능을 향상시킬 수 있다. 그 후, 신경망 언어 모델들은 인간 특징 엔지니어링에 대한 노력을 줄이는 것을 목표로 하는 학습 태스크-불가지론 표현(<em class="ltx_emph ltx_font_italic" id="S1.p7.1.5">e.g.,</em> features)에 초점을 맞추었다. 나아가 사전 학습된 언어 모델들은 다운스트림 태스크에 따라 최적화될 수 있는 상황 인지 표현을 학습하였다. 최신 언어 모델의 생성을 위해 범용 태스크 해결 수단으로 간주될 수 있는 모델 용량에 대한 스케일링 효과를 탐색하여 LLMs을 향상시킨다. 요약하자면, 진화 과정에서 언어 모델이 해결할 수 있는 작업 범위가 크게 확장되었고, 언어 모델이 달성한 작업 성능이 크게 향상되었다.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p class="ltx_p" id="S1.p8.1">기존 문헌에서 PLM은 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib36" title="">36</a>, <a class="ltx_ref" href="#bib.bib37" title="">37</a>, <a class="ltx_ref" href="#bib.bib38" title="">38</a>, <a class="ltx_ref" href="#bib.bib39" title="">39</a>]</cite>에 대해 널리 논의되고 조사되었지만 LLM은 체계적인 방식으로 거의 검토되지 않았다. 설문 조사에 동기를 부여하기 위해 먼저 LLM과 PLM 간의 세 가지 주요 차이점을 강조한다. 첫째, LLM은 이전의 더 작은 PLM에서 관찰되지 않을 수 있는 몇 가지 놀라운 출현 능력을 보여준다. 이러한 능력은 복잡한 작업에 대한 언어 모델의 성능에 핵심이며, AI 알고리즘을 예기치 않게 강력하고 효과적으로 만든다. 둘째, LLM은 인간이 AI 알고리즘을 개발하고 사용하는 방식에 혁명을 일으킬 것이다. 작은 PLM과 달리 LLM에 액세스하는 주요 접근법은 프롬프트 인터페이스(<em class="ltx_emph ltx_font_italic" id="S1.p8.1.1">e.g.,</em> GPT-4 API)를 통한 것입니다. 인간은 LLM이 어떻게 작동하는지 이해하고 LLM이 따를 수 있는 방식으로 작업을 포맷해야 한다. 셋째, LLM의 개발은 더 이상 연구와 공학의 명확한 구별을 이끌어내지 못한다. LLM의 학습은 대규모 데이터 처리 및 분산 병렬 학습에서 광범위한 실제 경험을 필요로 한다. 유능한 LLM을 개발하기 위해 연구자들은 엔지니어와 함께 작업하거나 엔지니어가 되는 복잡한 엔지니어링 문제를 해결해야 한다.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p class="ltx_p" id="S1.p9.1">오늘날 LLM은 AI 커뮤니티에 큰 영향을 미치고 있으며, ChatGPT와 GPT-4의 등장은 인공지능(AGI)의 가능성을 다시 생각하게 한다. OpenAI는 "<em class="ltx_emph ltx_font_italic" id="S1.p9.1.1">Planning for AGI and beyond</em>"이라는 제목의 기술 기사를 발표했으며, 이는 AGI에 접근하기 위한 단기 및 장기 계획을 논의합니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib40" title="">40</a>]</cite>, 보다 최근의 논문은 GPT-4가 AGI 시스템 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib41" title="">41</a>]</cite>의 초기 버전으로 간주될 수 있다고 주장했습니다. 인공지능의 연구 분야는 LLM이 빠르게 발전함에 따라 혁명을 일으키고 있다. NLP 분야에서 LLMs은 (어느 정도) 범용 언어 과제 해결자의 역할을 할 수 있으며, 연구 패러다임은 LLMs의 활용으로 전환되고 있다. IR 분야에서 기존 검색 엔진은 AI 챗봇을 통해 새로운 정보 탐색 방식으로 도전받고 있다(<em class="ltx_emph ltx_font_italic" id="S1.p9.1.2">i.e.,</em> ChatGPT), 그리고 <em class="ltx_emph ltx_font_italic" id="S1.p9.1.3">New Bing</em><span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://www.bing.com/new</span></span></span>은 LLMs 기반 검색 결과를 향상시키는 초기 시도를 제시한다. CV 분야에서 연구자들은 멀티모달 다이얼로그 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib42" title="">42</a>, <a class="ltx_ref" href="#bib.bib43" title="">43</a>, <a class="ltx_ref" href="#bib.bib44" title="">44</a>, <a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>, GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>를 더 잘 제공할 수 있는 ChatGPT 유사 비전 언어 모델을 개발하려고 시도했으며, 시각 정보를 통합하여 멀티모달 입력을 지원했다. 이 새로운 기술의 물결은 잠재적으로 LLM을 기반으로 하는 실제 응용 프로그램의 번영한 생태계로 이어질 것이다. 예를 들어 Microsoft 365는 사무 업무를 자동화 하기 위해 LLM (<em class="ltx_emph ltx_font_italic" id="S1.p9.1.4">i.e.,</em> Copilot)에서 권한을 부여 받고 있으며 OpenAI는 특수 기능을 구현 하기 위해 ChatGPT에서 플러그 인 사용을 지원 합니다.</p>
</div>
<div id="S1.p10" class="ltx_para">
<p class="ltx_p" id="S1.p10.1">진행과 영향에도 불구하고 LLM의 기본 원칙은 여전히 잘 탐구되지 않는다. 첫째, 왜 작은 PLM 대신 LLM에서 창발 능력이 발생하는지 불가사의하다. 보다 일반적인 문제로서 LLM의 우수한 능력에 기여하는 핵심 요인에 대한 깊고 상세한 조사가 부족하다. LLM이 언제 어떻게 그러한 능력을 얻을 수 있는지 연구하는 것이 중요하다. 이 문제에 대해 몇 가지 의미 있는 논의가 있지만, LLM의 "<em class="ltx_emph ltx_font_italic" id="S1.p10.1.1">secrets</em>"을 밝히기 위해서는 더 원칙적인 조사가 필요하다. 둘째, 연구 커뮤니티가 능력 있는 LLM을 훈련하는 것은 어렵다. 연산 자원의 엄청난 수요로 인해 LLM을 훈련하기 위한 다양한 전략의 효과를 조사하기 위한 반복적인 연구를 수행하는 것은 매우 비용이 많이 든다. 실제로 LLM은 주로 산업별로 훈련되며, 여기서 많은 중요한 훈련 세부 정보(<em class="ltx_emph ltx_font_italic" id="S1.p10.1.2">e.g.,</em> 데이터 수집 및 청소)는 대중에게 공개되지 않는다. 셋째, LLM을 인간의 가치나 선호도와 맞추는 것은 어렵다. 용량에도 불구하고 LLM은 독성, 가상 또는 유해한 내용물을 생성할 가능성이 있다. LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite> 사용의 잠재적 위험을 제거하기 위해서는 효과적이고 효율적인 제어 접근법이 필요하다.</p>
</div>
<div id="S1.p11" class="ltx_para">
<p class="ltx_p" id="S1.p11.1">기회와 도전 모두에 직면한 LLM의 연구 및 개발에 대한 더 많은 관심이 필요하다. LLMs에 대한 기본적인 이해를 제공하기 위해, 이 조사는 <em class="ltx_emph ltx_font_italic" id="S1.p11.1.1">pre-training</em> (how to pre-training a capable LLM), <em class="ltx_emph ltx_font_italic" id="S1.p11.1.2">adaptation</em> (how to effectively adapt pre-trained LLMs for better use), <em class="ltx_emph ltx_font_italic" id="S1.p11.1.3">utilization</em> (how to use LLMs for solving various downstream tasks) 및 <em class="ltx_emph ltx_font_italic" id="S1.p11.1.4">capability evaluation</em> (how to evaluate the abilities of LLMs and existing empirical findings). 우리는 문헌을 철저히 조사하고 LLM의 주요 발견, 기술 및 방법을 요약한다. 이 조사를 위해 링크 <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/RUCAIBox/LLMSurvey" target="_blank" title="">https://github.com/RUCAIBox/LLMSurvey</a>에서 LLMs에 대한 지원 리소스를 수집하여 GitHub 프로젝트 웹 사이트를 만듭니다. PLM 또는 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib38" title="">38</a>, <a class="ltx_ref" href="#bib.bib39" title="">39</a>, <a class="ltx_ref" href="#bib.bib48" title="">48</a>, <a class="ltx_ref" href="#bib.bib36" title="">36</a>, <a class="ltx_ref" href="#bib.bib49" title="">49</a>, <a class="ltx_ref" href="#bib.bib50" title="">50</a>, <a class="ltx_ref" href="#bib.bib32" title="">32</a>, <a class="ltx_ref" href="#bib.bib51" title="">51</a>, <a class="ltx_ref" href="#bib.bib52" title="">52</a>, <a class="ltx_ref" href="#bib.bib43" title="">43</a>, <a class="ltx_ref" href="#bib.bib53" title="">53</a>, <a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>에 대한 몇 가지 관련 리뷰 기사도 알고 있다. 이러한 논문은 PLM 또는 LLM의 일부 특정(또는 일반적인) 측면에 대해 논의한다. 이와 비교하여 LLM을 개발하고 사용하는 기술과 방법에 초점을 맞추고 LLM의 중요한 측면에 대한 비교적 포괄적인 참조를 제공한다.</p>
</div>
<div id="S1.p12" class="ltx_para">
<p class="ltx_p" id="S1.p12.1">이 조사의 나머지 부분은 다음과 같이 구성된다. 2절에서는 LLM에 대한 배경과 GPT 시리즈 모델의 진화를 소개하고, 3절에서는 LLM 개발을 위한 가용 자원을 요약한다. 4절, 5절, 6절 및 7절에서는 사전 훈련, 적응, 활용 및 용량 평가의 네 가지 측면에서 최근 진행 상황을 각각 검토하고 요약한다. 그런 다음 섹션 8에서는 신속한 설계를 위한 실용적인 가이드에 대해 논의하고 섹션 9에서는 여러 대표적인 도메인에서 LLM의 적용을 검토한다. 마지막으로 주요 연구 결과를 요약하여 섹션 10의 조사를 마무리하고 향후 작업을 위한 나머지 문제에 대해 논의한다.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Overview</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.1">이 섹션에서는 LLM의 배경에 대한 개요를 제시한 다음 GPT 시리즈 모델의 기술적 진화를 요약한다.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><span id="S2.SS1.1.1" class="ltx_text ltx_font_italic">Background for LLMs</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p1.1">전형적으로, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.1">large language models</em> (LLMs)는 GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>, PaLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>, Galactica <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite>, LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>와 같이 방대한 텍스트 데이터에 대해 훈련된 파라미터 <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>In existing literature, there is no formal consensus on the minimum parameter scale for LLMs, since the model capacity is also related to data size and total compute. In this survey, we take a slightly loose definition of LLMs, and mainly focus on discussing language models with a model size larger than 10B. </span></span></span>을 포함하는 Transformer 언어 모델을 의미한다. LLM은 (텍스트 생성을 통해) 자연어를 이해하고 복잡한 작업을 해결하는 강력한 능력을 나타낸다. LLM이 어떻게 작동하는지 빠르게 이해하기 위해 이 부분은 스케일링 법칙, 새로운 능력 및 핵심 기술을 포함한 LLM에 대한 기본 배경을 소개한다.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1">Formulation of Scaling Laws for LLMs</span>. 현재 LLM은 주로 트랜스포머 아키텍처 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>를 기반으로 하며, 여기서 멀티 헤드 어텐션 레이어는 매우 깊은 신경망에 적층된다. 기존의 LLM은 유사한 Transformer 아키텍처 및 사전 훈련 목적(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p2.1.2">e.g.,</em> 언어 모델링)을 작은 언어 모델로 채택한다. 그러나 LLM은 모델 크기, 데이터 크기 및 총 계산(확대 순서)을 크게 확장합니다. 광범위한 연구에 따르면 스케일링은 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>, <a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>의 모델 용량을 크게 향상시킬 수 있다. 따라서, 스케일링 효과를 특성화하기 위한 정량적 접근법을 확립하는 것이 유용하다. 다음으로 Transformer 언어 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>, <a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>에 대한 두 가지 대표적인 스케일링 법칙을 소개한다.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p3.5"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p3.1.m1.1"><semantics id="S2.SS1.p3.1.m1.1a"><mo id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.5.1">KM scaling law</em><span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Since there was not a model trained following this law in the original paper, we took the last names of the two co-first authors to name this scaling law. </span></span></span>. 2020년에 Kaplan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite> (the OpenAI team)은 신경 언어 모델에 대해 모델 크기(<math alttext="N" class="ltx_Math" display="inline" id="S2.SS1.p3.2.m2.1"><semantics id="S2.SS1.p3.2.m2.1a"><mi id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">N</annotation></semantics></math>), 데이터 세트 크기(<math alttext="D" class="ltx_Math" display="inline" id="S2.SS1.p3.3.m3.1"><semantics id="S2.SS1.p3.3.m3.1a"><mi id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><ci id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">D</annotation></semantics></math>) 및 훈련 계산량(<math alttext="C" class="ltx_Math" display="inline" id="S2.SS1.p3.4.m4.1"><semantics id="S2.SS1.p3.4.m4.1a"><mi id="S2.SS1.p3.4.m4.1.1" xref="S2.SS1.p3.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m4.1b"><ci id="S2.SS1.p3.4.m4.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m4.1c">C</annotation></semantics></math>)의 세 가지 주요 요인으로 모델 성능의 멱함수 관계를 모델링하기 위해 처음으로 제안했다. 계산 예산 <math alttext="c" class="ltx_Math" display="inline" id="S2.SS1.p3.5.m5.1"><semantics id="S2.SS1.p3.5.m5.1a"><mi id="S2.SS1.p3.5.m5.1.1" xref="S2.SS1.p3.5.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m5.1b"><ci id="S2.SS1.p3.5.m5.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m5.1c">c</annotation></semantics></math>가 주어지면, 그들은 스케일링 법칙<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content">6</sup><span class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>여기서, <math alttext="N_{c}" class="ltx_Math" display="inline" id="footnote6.m1.1"><semantics id="footnote6.m1.1b"><msub id="footnote6.m1.1.1" xref="footnote6.m1.1.1.cmml"><mi id="footnote6.m1.1.1.2" xref="footnote6.m1.1.1.2.cmml">N</mi><mi id="footnote6.m1.1.1.3" xref="footnote6.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="footnote6.m1.1c"><apply id="footnote6.m1.1.1.cmml" xref="footnote6.m1.1.1"><csymbol cd="ambiguous" id="footnote6.m1.1.1.1.cmml" xref="footnote6.m1.1.1">subscript</csymbol><ci id="footnote6.m1.1.1.2.cmml" xref="footnote6.m1.1.1.2">𝑁</ci><ci id="footnote6.m1.1.1.3.cmml" xref="footnote6.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote6.m1.1d">N_{c}</annotation></semantics></math>, <math alttext="D_{c}" class="ltx_Math" display="inline" id="footnote6.m2.1"><semantics id="footnote6.m2.1b"><msub id="footnote6.m2.1.1" xref="footnote6.m2.1.1.cmml"><mi id="footnote6.m2.1.1.2" xref="footnote6.m2.1.1.2.cmml">D</mi><mi id="footnote6.m2.1.1.3" xref="footnote6.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="footnote6.m2.1c"><apply id="footnote6.m2.1.1.cmml" xref="footnote6.m2.1.1"><csymbol cd="ambiguous" id="footnote6.m2.1.1.1.cmml" xref="footnote6.m2.1.1">subscript</csymbol><ci id="footnote6.m2.1.1.2.cmml" xref="footnote6.m2.1.1.2">𝐷</ci><ci id="footnote6.m2.1.1.3.cmml" xref="footnote6.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote6.m2.1d">D_{c}</annotation></semantics></math> 및 <math alttext="C_{c}" class="ltx_Math" display="inline" id="footnote6.m3.1"><semantics id="footnote6.m3.1b"><msub id="footnote6.m3.1.1" xref="footnote6.m3.1.1.cmml"><mi id="footnote6.m3.1.1.2" xref="footnote6.m3.1.1.2.cmml">C</mi><mi id="footnote6.m3.1.1.3" xref="footnote6.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="footnote6.m3.1c"><apply id="footnote6.m3.1.1.cmml" xref="footnote6.m3.1.1"><csymbol cd="ambiguous" id="footnote6.m3.1.1.1.cmml" xref="footnote6.m3.1.1">subscript</csymbol><ci id="footnote6.m3.1.1.2.cmml" xref="footnote6.m3.1.1.2">𝐶</ci><ci id="footnote6.m3.1.1.3.cmml" xref="footnote6.m3.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote6.m3.1d">C_{c}</annotation></semantics></math>는 각각 비 임베딩 파라미터 수, 트레이닝 토큰 수 및 FP-days 수에서 측정된다. 원본 논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>, <math alttext="C_{c}" class="ltx_Math" display="inline" id="footnote6.m4.1"><semantics id="footnote6.m4.1b"><msub id="footnote6.m4.1.1" xref="footnote6.m4.1.1.cmml"><mi id="footnote6.m4.1.1.2" xref="footnote6.m4.1.1.2.cmml">C</mi><mi id="footnote6.m4.1.1.3" xref="footnote6.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="footnote6.m4.1c"><apply id="footnote6.m4.1.1.cmml" xref="footnote6.m4.1.1"><csymbol cd="ambiguous" id="footnote6.m4.1.1.1.cmml" xref="footnote6.m4.1.1">subscript</csymbol><ci id="footnote6.m4.1.1.2.cmml" xref="footnote6.m4.1.1.2">𝐶</ci><ci id="footnote6.m4.1.1.3.cmml" xref="footnote6.m4.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote6.m4.1d">C_{c}</annotation></semantics></math> 및 <math alttext="C" class="ltx_Math" display="inline" id="footnote6.m5.1"><semantics id="footnote6.m5.1b"><mi id="footnote6.m5.1.1" xref="footnote6.m5.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="footnote6.m5.1c"><ci id="footnote6.m5.1.1.cmml" xref="footnote6.m5.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote6.m5.1d">C</annotation></semantics></math>는 컴퓨팅의 최적 사용에 해당하는 <math alttext="C_{c}^{min}" class="ltx_Math" display="inline" id="footnote6.m6.1"><semantics id="footnote6.m6.1b"><msubsup id="footnote6.m6.1.1" xref="footnote6.m6.1.1.cmml"><mi id="footnote6.m6.1.1.2.2" xref="footnote6.m6.1.1.2.2.cmml">C</mi><mi id="footnote6.m6.1.1.2.3" xref="footnote6.m6.1.1.2.3.cmml">c</mi><mrow id="footnote6.m6.1.1.3" xref="footnote6.m6.1.1.3.cmml"><mi id="footnote6.m6.1.1.3.2" xref="footnote6.m6.1.1.3.2.cmml">m</mi><mo id="footnote6.m6.1.1.3.1" lspace="0em" rspace="0em" xref="footnote6.m6.1.1.3.1.cmml">​</mo><mi id="footnote6.m6.1.1.3.3" xref="footnote6.m6.1.1.3.3.cmml">i</mi><mo id="footnote6.m6.1.1.3.1b" lspace="0em" rspace="0em" xref="footnote6.m6.1.1.3.1.cmml">​</mo><mi id="footnote6.m6.1.1.3.4" xref="footnote6.m6.1.1.3.4.cmml">n</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="footnote6.m6.1c"><apply id="footnote6.m6.1.1.cmml" xref="footnote6.m6.1.1"><csymbol cd="ambiguous" id="footnote6.m6.1.1.1.cmml" xref="footnote6.m6.1.1">superscript</csymbol><apply id="footnote6.m6.1.1.2.cmml" xref="footnote6.m6.1.1"><csymbol cd="ambiguous" id="footnote6.m6.1.1.2.1.cmml" xref="footnote6.m6.1.1">subscript</csymbol><ci id="footnote6.m6.1.1.2.2.cmml" xref="footnote6.m6.1.1.2.2">𝐶</ci><ci id="footnote6.m6.1.1.2.3.cmml" xref="footnote6.m6.1.1.2.3">𝑐</ci></apply><apply id="footnote6.m6.1.1.3.cmml" xref="footnote6.m6.1.1.3"><times id="footnote6.m6.1.1.3.1.cmml" xref="footnote6.m6.1.1.3.1"></times><ci id="footnote6.m6.1.1.3.2.cmml" xref="footnote6.m6.1.1.3.2">𝑚</ci><ci id="footnote6.m6.1.1.3.3.cmml" xref="footnote6.m6.1.1.3.3">𝑖</ci><ci id="footnote6.m6.1.1.3.4.cmml" xref="footnote6.m6.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote6.m6.1d">C_{c}^{min}</annotation></semantics></math> 및 <math alttext="C_{min}" class="ltx_Math" display="inline" id="footnote6.m7.1"><semantics id="footnote6.m7.1b"><msub id="footnote6.m7.1.1" xref="footnote6.m7.1.1.cmml"><mi id="footnote6.m7.1.1.2" xref="footnote6.m7.1.1.2.cmml">C</mi><mrow id="footnote6.m7.1.1.3" xref="footnote6.m7.1.1.3.cmml"><mi id="footnote6.m7.1.1.3.2" xref="footnote6.m7.1.1.3.2.cmml">m</mi><mo id="footnote6.m7.1.1.3.1" lspace="0em" rspace="0em" xref="footnote6.m7.1.1.3.1.cmml">​</mo><mi id="footnote6.m7.1.1.3.3" xref="footnote6.m7.1.1.3.3.cmml">i</mi><mo id="footnote6.m7.1.1.3.1b" lspace="0em" rspace="0em" xref="footnote6.m7.1.1.3.1.cmml">​</mo><mi id="footnote6.m7.1.1.3.4" xref="footnote6.m7.1.1.3.4.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="footnote6.m7.1c"><apply id="footnote6.m7.1.1.cmml" xref="footnote6.m7.1.1"><csymbol cd="ambiguous" id="footnote6.m7.1.1.1.cmml" xref="footnote6.m7.1.1">subscript</csymbol><ci id="footnote6.m7.1.1.2.cmml" xref="footnote6.m7.1.1.2">𝐶</ci><apply id="footnote6.m7.1.1.3.cmml" xref="footnote6.m7.1.1.3"><times id="footnote6.m7.1.1.3.1.cmml" xref="footnote6.m7.1.1.3.1"></times><ci id="footnote6.m7.1.1.3.2.cmml" xref="footnote6.m7.1.1.3.2">𝑚</ci><ci id="footnote6.m7.1.1.3.3.cmml" xref="footnote6.m7.1.1.3.3">𝑖</ci><ci id="footnote6.m7.1.1.3.4.cmml" xref="footnote6.m7.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote6.m7.1d">C_{min}</annotation></semantics></math>로 표기되어야 한다. 우리는 논의의 용이성을 위해 단순화된 표기법을 사용한다. </span></span></span></p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<table id="Sx2.EGx1" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\displaystyle L(N)" display="inline"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.2" xref="S2.E1.m1.1.2.cmml"><mi mathsize="90%" id="S2.E1.m1.1.2.2" xref="S2.E1.m1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.2.1" xref="S2.E1.m1.1.2.1.cmml">​</mo><mrow id="S2.E1.m1.1.2.3.2" xref="S2.E1.m1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E1.m1.1.2.3.2.1" xref="S2.E1.m1.1.2.cmml">(</mo><mi mathsize="90%" id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">N</mi><mo maxsize="90%" minsize="90%" id="S2.E1.m1.1.2.3.2.2" xref="S2.E1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.2.cmml" xref="S2.E1.m1.1.2"><times id="S2.E1.m1.1.2.1.cmml" xref="S2.E1.m1.1.2.1"></times><ci id="S2.E1.m1.1.2.2.cmml" xref="S2.E1.m1.1.2.2">𝐿</ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\displaystyle L(N)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_eqn_cell"><math id="S2.E1.m2.1" class="ltx_Math" alttext="\displaystyle=" display="inline"><semantics id="S2.E1.m2.1a"><mo mathsize="90%" id="S2.E1.m2.1.1" xref="S2.E1.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.E1.m2.1b"><eq id="S2.E1.m2.1.1.cmml" xref="S2.E1.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m2.1c">\displaystyle=</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E1.m3.3" class="ltx_Math" alttext="\displaystyle\bigg{(}\frac{N_{c}}{N}\bigg{)}^{\alpha_{N}},\text{~{}~{}~{}}\alpha_{N}\sim 0.076,N_{c}\sim 8.8\times 10^{13}" display="inline"><semantics id="S2.E1.m3.3a"><mrow id="S2.E1.m3.3.3.2" xref="S2.E1.m3.3.3.3.cmml"><mrow id="S2.E1.m3.2.2.1.1" xref="S2.E1.m3.2.2.1.1.cmml"><mrow id="S2.E1.m3.2.2.1.1.2.2" xref="S2.E1.m3.2.2.1.1.2.3.cmml"><msup id="S2.E1.m3.2.2.1.1.1.1.1" xref="S2.E1.m3.2.2.1.1.1.1.1.cmml"><mrow id="S2.E1.m3.2.2.1.1.1.1.1.2.2" xref="S2.E1.m3.1.1.cmml"><mo maxsize="210%" minsize="210%" id="S2.E1.m3.2.2.1.1.1.1.1.2.2.1" xref="S2.E1.m3.1.1.cmml">(</mo><mstyle displaystyle="true" id="S2.E1.m3.1.1" xref="S2.E1.m3.1.1.cmml"><mfrac id="S2.E1.m3.1.1a" xref="S2.E1.m3.1.1.cmml"><msub id="S2.E1.m3.1.1.2" xref="S2.E1.m3.1.1.2.cmml"><mi mathsize="90%" id="S2.E1.m3.1.1.2.2" xref="S2.E1.m3.1.1.2.2.cmml">N</mi><mi mathsize="90%" id="S2.E1.m3.1.1.2.3" xref="S2.E1.m3.1.1.2.3.cmml">c</mi></msub><mi mathsize="90%" id="S2.E1.m3.1.1.3" xref="S2.E1.m3.1.1.3.cmml">N</mi></mfrac></mstyle><mo maxsize="210%" minsize="210%" id="S2.E1.m3.2.2.1.1.1.1.1.2.2.2" xref="S2.E1.m3.1.1.cmml">)</mo></mrow><msub id="S2.E1.m3.2.2.1.1.1.1.1.3" xref="S2.E1.m3.2.2.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S2.E1.m3.2.2.1.1.1.1.1.3.2" xref="S2.E1.m3.2.2.1.1.1.1.1.3.2.cmml">α</mi><mi mathsize="90%" id="S2.E1.m3.2.2.1.1.1.1.1.3.3" xref="S2.E1.m3.2.2.1.1.1.1.1.3.3.cmml">N</mi></msub></msup><mo mathsize="90%" id="S2.E1.m3.2.2.1.1.2.2.3" xref="S2.E1.m3.2.2.1.1.2.3.cmml">,</mo><mrow id="S2.E1.m3.2.2.1.1.2.2.2" xref="S2.E1.m3.2.2.1.1.2.2.2.cmml"><mtext mathsize="90%" id="S2.E1.m3.2.2.1.1.2.2.2.2" xref="S2.E1.m3.2.2.1.1.2.2.2.2a.cmml">&nbsp;</mtext><mo lspace="0em" rspace="0em" id="S2.E1.m3.2.2.1.1.2.2.2.1" xref="S2.E1.m3.2.2.1.1.2.2.2.1.cmml">​</mo><msub id="S2.E1.m3.2.2.1.1.2.2.2.3" xref="S2.E1.m3.2.2.1.1.2.2.2.3.cmml"><mi mathsize="90%" id="S2.E1.m3.2.2.1.1.2.2.2.3.2" xref="S2.E1.m3.2.2.1.1.2.2.2.3.2.cmml">α</mi><mi mathsize="90%" id="S2.E1.m3.2.2.1.1.2.2.2.3.3" xref="S2.E1.m3.2.2.1.1.2.2.2.3.3.cmml">N</mi></msub></mrow></mrow><mo mathsize="90%" id="S2.E1.m3.2.2.1.1.3" xref="S2.E1.m3.2.2.1.1.3.cmml">∼</mo><mn mathsize="90%" id="S2.E1.m3.2.2.1.1.4" xref="S2.E1.m3.2.2.1.1.4.cmml">0.076</mn></mrow><mo mathsize="90%" id="S2.E1.m3.3.3.2.3" xref="S2.E1.m3.3.3.3a.cmml">,</mo><mrow id="S2.E1.m3.3.3.2.2" xref="S2.E1.m3.3.3.2.2.cmml"><msub id="S2.E1.m3.3.3.2.2.2" xref="S2.E1.m3.3.3.2.2.2.cmml"><mi mathsize="90%" id="S2.E1.m3.3.3.2.2.2.2" xref="S2.E1.m3.3.3.2.2.2.2.cmml">N</mi><mi mathsize="90%" id="S2.E1.m3.3.3.2.2.2.3" xref="S2.E1.m3.3.3.2.2.2.3.cmml">c</mi></msub><mo mathsize="90%" id="S2.E1.m3.3.3.2.2.1" xref="S2.E1.m3.3.3.2.2.1.cmml">∼</mo><mrow id="S2.E1.m3.3.3.2.2.3" xref="S2.E1.m3.3.3.2.2.3.cmml"><mn mathsize="90%" id="S2.E1.m3.3.3.2.2.3.2" xref="S2.E1.m3.3.3.2.2.3.2.cmml">8.8</mn><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S2.E1.m3.3.3.2.2.3.1" xref="S2.E1.m3.3.3.2.2.3.1.cmml">×</mo><msup id="S2.E1.m3.3.3.2.2.3.3" xref="S2.E1.m3.3.3.2.2.3.3.cmml"><mn mathsize="90%" id="S2.E1.m3.3.3.2.2.3.3.2" xref="S2.E1.m3.3.3.2.2.3.3.2.cmml">10</mn><mn mathsize="90%" id="S2.E1.m3.3.3.2.2.3.3.3" xref="S2.E1.m3.3.3.2.2.3.3.3.cmml">13</mn></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m3.3b"><apply id="S2.E1.m3.3.3.3.cmml" xref="S2.E1.m3.3.3.2"><csymbol cd="ambiguous" id="S2.E1.m3.3.3.3a.cmml" xref="S2.E1.m3.3.3.2.3">formulae-sequence</csymbol><apply id="S2.E1.m3.2.2.1.1.cmml" xref="S2.E1.m3.2.2.1.1"><csymbol cd="latexml" id="S2.E1.m3.2.2.1.1.3.cmml" xref="S2.E1.m3.2.2.1.1.3">similar-to</csymbol><list id="S2.E1.m3.2.2.1.1.2.3.cmml" xref="S2.E1.m3.2.2.1.1.2.2"><apply id="S2.E1.m3.2.2.1.1.1.1.1.cmml" xref="S2.E1.m3.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m3.2.2.1.1.1.1.1.1.cmml" xref="S2.E1.m3.2.2.1.1.1.1.1">superscript</csymbol><apply id="S2.E1.m3.1.1.cmml" xref="S2.E1.m3.2.2.1.1.1.1.1.2.2"><divide id="S2.E1.m3.1.1.1.cmml" xref="S2.E1.m3.2.2.1.1.1.1.1.2.2"></divide><apply id="S2.E1.m3.1.1.2.cmml" xref="S2.E1.m3.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m3.1.1.2.1.cmml" xref="S2.E1.m3.1.1.2">subscript</csymbol><ci id="S2.E1.m3.1.1.2.2.cmml" xref="S2.E1.m3.1.1.2.2">𝑁</ci><ci id="S2.E1.m3.1.1.2.3.cmml" xref="S2.E1.m3.1.1.2.3">𝑐</ci></apply><ci id="S2.E1.m3.1.1.3.cmml" xref="S2.E1.m3.1.1.3">𝑁</ci></apply><apply id="S2.E1.m3.2.2.1.1.1.1.1.3.cmml" xref="S2.E1.m3.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m3.2.2.1.1.1.1.1.3.1.cmml" xref="S2.E1.m3.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m3.2.2.1.1.1.1.1.3.2.cmml" xref="S2.E1.m3.2.2.1.1.1.1.1.3.2">𝛼</ci><ci id="S2.E1.m3.2.2.1.1.1.1.1.3.3.cmml" xref="S2.E1.m3.2.2.1.1.1.1.1.3.3">𝑁</ci></apply></apply><apply id="S2.E1.m3.2.2.1.1.2.2.2.cmml" xref="S2.E1.m3.2.2.1.1.2.2.2"><times id="S2.E1.m3.2.2.1.1.2.2.2.1.cmml" xref="S2.E1.m3.2.2.1.1.2.2.2.1"></times><ci id="S2.E1.m3.2.2.1.1.2.2.2.2a.cmml" xref="S2.E1.m3.2.2.1.1.2.2.2.2"><mtext mathsize="90%" id="S2.E1.m3.2.2.1.1.2.2.2.2.cmml" xref="S2.E1.m3.2.2.1.1.2.2.2.2">&nbsp;</mtext></ci><apply id="S2.E1.m3.2.2.1.1.2.2.2.3.cmml" xref="S2.E1.m3.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m3.2.2.1.1.2.2.2.3.1.cmml" xref="S2.E1.m3.2.2.1.1.2.2.2.3">subscript</csymbol><ci id="S2.E1.m3.2.2.1.1.2.2.2.3.2.cmml" xref="S2.E1.m3.2.2.1.1.2.2.2.3.2">𝛼</ci><ci id="S2.E1.m3.2.2.1.1.2.2.2.3.3.cmml" xref="S2.E1.m3.2.2.1.1.2.2.2.3.3">𝑁</ci></apply></apply></list><cn type="float" id="S2.E1.m3.2.2.1.1.4.cmml" xref="S2.E1.m3.2.2.1.1.4">0.076</cn></apply><apply id="S2.E1.m3.3.3.2.2.cmml" xref="S2.E1.m3.3.3.2.2"><csymbol cd="latexml" id="S2.E1.m3.3.3.2.2.1.cmml" xref="S2.E1.m3.3.3.2.2.1">similar-to</csymbol><apply id="S2.E1.m3.3.3.2.2.2.cmml" xref="S2.E1.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m3.3.3.2.2.2.1.cmml" xref="S2.E1.m3.3.3.2.2.2">subscript</csymbol><ci id="S2.E1.m3.3.3.2.2.2.2.cmml" xref="S2.E1.m3.3.3.2.2.2.2">𝑁</ci><ci id="S2.E1.m3.3.3.2.2.2.3.cmml" xref="S2.E1.m3.3.3.2.2.2.3">𝑐</ci></apply><apply id="S2.E1.m3.3.3.2.2.3.cmml" xref="S2.E1.m3.3.3.2.2.3"><times id="S2.E1.m3.3.3.2.2.3.1.cmml" xref="S2.E1.m3.3.3.2.2.3.1"></times><cn type="float" id="S2.E1.m3.3.3.2.2.3.2.cmml" xref="S2.E1.m3.3.3.2.2.3.2">8.8</cn><apply id="S2.E1.m3.3.3.2.2.3.3.cmml" xref="S2.E1.m3.3.3.2.2.3.3"><csymbol cd="ambiguous" id="S2.E1.m3.3.3.2.2.3.3.1.cmml" xref="S2.E1.m3.3.3.2.2.3.3">superscript</csymbol><cn type="integer" id="S2.E1.m3.3.3.2.2.3.3.2.cmml" xref="S2.E1.m3.3.3.2.2.3.3.2">10</cn><cn type="integer" id="S2.E1.m3.3.3.2.2.3.3.3.cmml" xref="S2.E1.m3.3.3.2.2.3.3.3">13</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m3.3c">\displaystyle\bigg{(}\frac{N_{c}}{N}\bigg{)}^{\alpha_{N}},\text{~{}~{}~{}}\alpha_{N}\sim 0.076,N_{c}\sim 8.8\times 10^{13}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S2.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex1.m1.1" class="ltx_Math" alttext="\displaystyle L(D)" display="inline"><semantics id="S2.Ex1.m1.1a"><mrow id="S2.Ex1.m1.1.2" xref="S2.Ex1.m1.1.2.cmml"><mi mathsize="90%" id="S2.Ex1.m1.1.2.2" xref="S2.Ex1.m1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.1.2.1" xref="S2.Ex1.m1.1.2.1.cmml">​</mo><mrow id="S2.Ex1.m1.1.2.3.2" xref="S2.Ex1.m1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.Ex1.m1.1.2.3.2.1" xref="S2.Ex1.m1.1.2.cmml">(</mo><mi mathsize="90%" id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml">D</mi><mo maxsize="90%" minsize="90%" id="S2.Ex1.m1.1.2.3.2.2" xref="S2.Ex1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.1b"><apply id="S2.Ex1.m1.1.2.cmml" xref="S2.Ex1.m1.1.2"><times id="S2.Ex1.m1.1.2.1.cmml" xref="S2.Ex1.m1.1.2.1"></times><ci id="S2.Ex1.m1.1.2.2.cmml" xref="S2.Ex1.m1.1.2.2">𝐿</ci><ci id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.1c">\displaystyle L(D)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_eqn_cell"><math id="S2.Ex1.m2.1" class="ltx_Math" alttext="\displaystyle=" display="inline"><semantics id="S2.Ex1.m2.1a"><mo mathsize="90%" id="S2.Ex1.m2.1.1" xref="S2.Ex1.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.Ex1.m2.1b"><eq id="S2.Ex1.m2.1.1.cmml" xref="S2.Ex1.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m2.1c">\displaystyle=</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex1.m3.3" class="ltx_Math" alttext="\displaystyle\bigg{(}\frac{D_{c}}{D}\bigg{)}^{\alpha_{D}},\text{~{}~{}~{}}\alpha_{D}\sim 0.095,D_{c}\sim 5.4\times 10^{13}" display="inline"><semantics id="S2.Ex1.m3.3a"><mrow id="S2.Ex1.m3.3.3.2" xref="S2.Ex1.m3.3.3.3.cmml"><mrow id="S2.Ex1.m3.2.2.1.1" xref="S2.Ex1.m3.2.2.1.1.cmml"><mrow id="S2.Ex1.m3.2.2.1.1.2.2" xref="S2.Ex1.m3.2.2.1.1.2.3.cmml"><msup id="S2.Ex1.m3.2.2.1.1.1.1.1" xref="S2.Ex1.m3.2.2.1.1.1.1.1.cmml"><mrow id="S2.Ex1.m3.2.2.1.1.1.1.1.2.2" xref="S2.Ex1.m3.1.1.cmml"><mo maxsize="210%" minsize="210%" id="S2.Ex1.m3.2.2.1.1.1.1.1.2.2.1" xref="S2.Ex1.m3.1.1.cmml">(</mo><mstyle displaystyle="true" id="S2.Ex1.m3.1.1" xref="S2.Ex1.m3.1.1.cmml"><mfrac id="S2.Ex1.m3.1.1a" xref="S2.Ex1.m3.1.1.cmml"><msub id="S2.Ex1.m3.1.1.2" xref="S2.Ex1.m3.1.1.2.cmml"><mi mathsize="90%" id="S2.Ex1.m3.1.1.2.2" xref="S2.Ex1.m3.1.1.2.2.cmml">D</mi><mi mathsize="90%" id="S2.Ex1.m3.1.1.2.3" xref="S2.Ex1.m3.1.1.2.3.cmml">c</mi></msub><mi mathsize="90%" id="S2.Ex1.m3.1.1.3" xref="S2.Ex1.m3.1.1.3.cmml">D</mi></mfrac></mstyle><mo maxsize="210%" minsize="210%" id="S2.Ex1.m3.2.2.1.1.1.1.1.2.2.2" xref="S2.Ex1.m3.1.1.cmml">)</mo></mrow><msub id="S2.Ex1.m3.2.2.1.1.1.1.1.3" xref="S2.Ex1.m3.2.2.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S2.Ex1.m3.2.2.1.1.1.1.1.3.2" xref="S2.Ex1.m3.2.2.1.1.1.1.1.3.2.cmml">α</mi><mi mathsize="90%" id="S2.Ex1.m3.2.2.1.1.1.1.1.3.3" xref="S2.Ex1.m3.2.2.1.1.1.1.1.3.3.cmml">D</mi></msub></msup><mo mathsize="90%" id="S2.Ex1.m3.2.2.1.1.2.2.3" xref="S2.Ex1.m3.2.2.1.1.2.3.cmml">,</mo><mrow id="S2.Ex1.m3.2.2.1.1.2.2.2" xref="S2.Ex1.m3.2.2.1.1.2.2.2.cmml"><mtext mathsize="90%" id="S2.Ex1.m3.2.2.1.1.2.2.2.2" xref="S2.Ex1.m3.2.2.1.1.2.2.2.2a.cmml">&nbsp;</mtext><mo lspace="0em" rspace="0em" id="S2.Ex1.m3.2.2.1.1.2.2.2.1" xref="S2.Ex1.m3.2.2.1.1.2.2.2.1.cmml">​</mo><msub id="S2.Ex1.m3.2.2.1.1.2.2.2.3" xref="S2.Ex1.m3.2.2.1.1.2.2.2.3.cmml"><mi mathsize="90%" id="S2.Ex1.m3.2.2.1.1.2.2.2.3.2" xref="S2.Ex1.m3.2.2.1.1.2.2.2.3.2.cmml">α</mi><mi mathsize="90%" id="S2.Ex1.m3.2.2.1.1.2.2.2.3.3" xref="S2.Ex1.m3.2.2.1.1.2.2.2.3.3.cmml">D</mi></msub></mrow></mrow><mo mathsize="90%" id="S2.Ex1.m3.2.2.1.1.3" xref="S2.Ex1.m3.2.2.1.1.3.cmml">∼</mo><mn mathsize="90%" id="S2.Ex1.m3.2.2.1.1.4" xref="S2.Ex1.m3.2.2.1.1.4.cmml">0.095</mn></mrow><mo mathsize="90%" id="S2.Ex1.m3.3.3.2.3" xref="S2.Ex1.m3.3.3.3a.cmml">,</mo><mrow id="S2.Ex1.m3.3.3.2.2" xref="S2.Ex1.m3.3.3.2.2.cmml"><msub id="S2.Ex1.m3.3.3.2.2.2" xref="S2.Ex1.m3.3.3.2.2.2.cmml"><mi mathsize="90%" id="S2.Ex1.m3.3.3.2.2.2.2" xref="S2.Ex1.m3.3.3.2.2.2.2.cmml">D</mi><mi mathsize="90%" id="S2.Ex1.m3.3.3.2.2.2.3" xref="S2.Ex1.m3.3.3.2.2.2.3.cmml">c</mi></msub><mo mathsize="90%" id="S2.Ex1.m3.3.3.2.2.1" xref="S2.Ex1.m3.3.3.2.2.1.cmml">∼</mo><mrow id="S2.Ex1.m3.3.3.2.2.3" xref="S2.Ex1.m3.3.3.2.2.3.cmml"><mn mathsize="90%" id="S2.Ex1.m3.3.3.2.2.3.2" xref="S2.Ex1.m3.3.3.2.2.3.2.cmml">5.4</mn><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S2.Ex1.m3.3.3.2.2.3.1" xref="S2.Ex1.m3.3.3.2.2.3.1.cmml">×</mo><msup id="S2.Ex1.m3.3.3.2.2.3.3" xref="S2.Ex1.m3.3.3.2.2.3.3.cmml"><mn mathsize="90%" id="S2.Ex1.m3.3.3.2.2.3.3.2" xref="S2.Ex1.m3.3.3.2.2.3.3.2.cmml">10</mn><mn mathsize="90%" id="S2.Ex1.m3.3.3.2.2.3.3.3" xref="S2.Ex1.m3.3.3.2.2.3.3.3.cmml">13</mn></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m3.3b"><apply id="S2.Ex1.m3.3.3.3.cmml" xref="S2.Ex1.m3.3.3.2"><csymbol cd="ambiguous" id="S2.Ex1.m3.3.3.3a.cmml" xref="S2.Ex1.m3.3.3.2.3">formulae-sequence</csymbol><apply id="S2.Ex1.m3.2.2.1.1.cmml" xref="S2.Ex1.m3.2.2.1.1"><csymbol cd="latexml" id="S2.Ex1.m3.2.2.1.1.3.cmml" xref="S2.Ex1.m3.2.2.1.1.3">similar-to</csymbol><list id="S2.Ex1.m3.2.2.1.1.2.3.cmml" xref="S2.Ex1.m3.2.2.1.1.2.2"><apply id="S2.Ex1.m3.2.2.1.1.1.1.1.cmml" xref="S2.Ex1.m3.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m3.2.2.1.1.1.1.1.1.cmml" xref="S2.Ex1.m3.2.2.1.1.1.1.1">superscript</csymbol><apply id="S2.Ex1.m3.1.1.cmml" xref="S2.Ex1.m3.2.2.1.1.1.1.1.2.2"><divide id="S2.Ex1.m3.1.1.1.cmml" xref="S2.Ex1.m3.2.2.1.1.1.1.1.2.2"></divide><apply id="S2.Ex1.m3.1.1.2.cmml" xref="S2.Ex1.m3.1.1.2"><csymbol cd="ambiguous" id="S2.Ex1.m3.1.1.2.1.cmml" xref="S2.Ex1.m3.1.1.2">subscript</csymbol><ci id="S2.Ex1.m3.1.1.2.2.cmml" xref="S2.Ex1.m3.1.1.2.2">𝐷</ci><ci id="S2.Ex1.m3.1.1.2.3.cmml" xref="S2.Ex1.m3.1.1.2.3">𝑐</ci></apply><ci id="S2.Ex1.m3.1.1.3.cmml" xref="S2.Ex1.m3.1.1.3">𝐷</ci></apply><apply id="S2.Ex1.m3.2.2.1.1.1.1.1.3.cmml" xref="S2.Ex1.m3.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m3.2.2.1.1.1.1.1.3.1.cmml" xref="S2.Ex1.m3.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex1.m3.2.2.1.1.1.1.1.3.2.cmml" xref="S2.Ex1.m3.2.2.1.1.1.1.1.3.2">𝛼</ci><ci id="S2.Ex1.m3.2.2.1.1.1.1.1.3.3.cmml" xref="S2.Ex1.m3.2.2.1.1.1.1.1.3.3">𝐷</ci></apply></apply><apply id="S2.Ex1.m3.2.2.1.1.2.2.2.cmml" xref="S2.Ex1.m3.2.2.1.1.2.2.2"><times id="S2.Ex1.m3.2.2.1.1.2.2.2.1.cmml" xref="S2.Ex1.m3.2.2.1.1.2.2.2.1"></times><ci id="S2.Ex1.m3.2.2.1.1.2.2.2.2a.cmml" xref="S2.Ex1.m3.2.2.1.1.2.2.2.2"><mtext mathsize="90%" id="S2.Ex1.m3.2.2.1.1.2.2.2.2.cmml" xref="S2.Ex1.m3.2.2.1.1.2.2.2.2">&nbsp;</mtext></ci><apply id="S2.Ex1.m3.2.2.1.1.2.2.2.3.cmml" xref="S2.Ex1.m3.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S2.Ex1.m3.2.2.1.1.2.2.2.3.1.cmml" xref="S2.Ex1.m3.2.2.1.1.2.2.2.3">subscript</csymbol><ci id="S2.Ex1.m3.2.2.1.1.2.2.2.3.2.cmml" xref="S2.Ex1.m3.2.2.1.1.2.2.2.3.2">𝛼</ci><ci id="S2.Ex1.m3.2.2.1.1.2.2.2.3.3.cmml" xref="S2.Ex1.m3.2.2.1.1.2.2.2.3.3">𝐷</ci></apply></apply></list><cn type="float" id="S2.Ex1.m3.2.2.1.1.4.cmml" xref="S2.Ex1.m3.2.2.1.1.4">0.095</cn></apply><apply id="S2.Ex1.m3.3.3.2.2.cmml" xref="S2.Ex1.m3.3.3.2.2"><csymbol cd="latexml" id="S2.Ex1.m3.3.3.2.2.1.cmml" xref="S2.Ex1.m3.3.3.2.2.1">similar-to</csymbol><apply id="S2.Ex1.m3.3.3.2.2.2.cmml" xref="S2.Ex1.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.Ex1.m3.3.3.2.2.2.1.cmml" xref="S2.Ex1.m3.3.3.2.2.2">subscript</csymbol><ci id="S2.Ex1.m3.3.3.2.2.2.2.cmml" xref="S2.Ex1.m3.3.3.2.2.2.2">𝐷</ci><ci id="S2.Ex1.m3.3.3.2.2.2.3.cmml" xref="S2.Ex1.m3.3.3.2.2.2.3">𝑐</ci></apply><apply id="S2.Ex1.m3.3.3.2.2.3.cmml" xref="S2.Ex1.m3.3.3.2.2.3"><times id="S2.Ex1.m3.3.3.2.2.3.1.cmml" xref="S2.Ex1.m3.3.3.2.2.3.1"></times><cn type="float" id="S2.Ex1.m3.3.3.2.2.3.2.cmml" xref="S2.Ex1.m3.3.3.2.2.3.2">5.4</cn><apply id="S2.Ex1.m3.3.3.2.2.3.3.cmml" xref="S2.Ex1.m3.3.3.2.2.3.3"><csymbol cd="ambiguous" id="S2.Ex1.m3.3.3.2.2.3.3.1.cmml" xref="S2.Ex1.m3.3.3.2.2.3.3">superscript</csymbol><cn type="integer" id="S2.Ex1.m3.3.3.2.2.3.3.2.cmml" xref="S2.Ex1.m3.3.3.2.2.3.3.2">10</cn><cn type="integer" id="S2.Ex1.m3.3.3.2.2.3.3.3.cmml" xref="S2.Ex1.m3.3.3.2.2.3.3.3">13</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m3.3c">\displaystyle\bigg{(}\frac{D_{c}}{D}\bigg{)}^{\alpha_{D}},\text{~{}~{}~{}}\alpha_{D}\sim 0.095,D_{c}\sim 5.4\times 10^{13}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex2.m1.1" class="ltx_Math" alttext="\displaystyle L(C)" display="inline"><semantics id="S2.Ex2.m1.1a"><mrow id="S2.Ex2.m1.1.2" xref="S2.Ex2.m1.1.2.cmml"><mi mathsize="90%" id="S2.Ex2.m1.1.2.2" xref="S2.Ex2.m1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.1.2.1" xref="S2.Ex2.m1.1.2.1.cmml">​</mo><mrow id="S2.Ex2.m1.1.2.3.2" xref="S2.Ex2.m1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.Ex2.m1.1.2.3.2.1" xref="S2.Ex2.m1.1.2.cmml">(</mo><mi mathsize="90%" id="S2.Ex2.m1.1.1" xref="S2.Ex2.m1.1.1.cmml">C</mi><mo maxsize="90%" minsize="90%" id="S2.Ex2.m1.1.2.3.2.2" xref="S2.Ex2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.1b"><apply id="S2.Ex2.m1.1.2.cmml" xref="S2.Ex2.m1.1.2"><times id="S2.Ex2.m1.1.2.1.cmml" xref="S2.Ex2.m1.1.2.1"></times><ci id="S2.Ex2.m1.1.2.2.cmml" xref="S2.Ex2.m1.1.2.2">𝐿</ci><ci id="S2.Ex2.m1.1.1.cmml" xref="S2.Ex2.m1.1.1">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.1c">\displaystyle L(C)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_eqn_cell"><math id="S2.Ex2.m2.1" class="ltx_Math" alttext="\displaystyle=" display="inline"><semantics id="S2.Ex2.m2.1a"><mo mathsize="90%" id="S2.Ex2.m2.1.1" xref="S2.Ex2.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.Ex2.m2.1b"><eq id="S2.Ex2.m2.1.1.cmml" xref="S2.Ex2.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m2.1c">\displaystyle=</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex2.m3.3" class="ltx_Math" alttext="\displaystyle\bigg{(}\frac{C_{c}}{C}\bigg{)}^{\alpha_{C}},\text{~{}~{}~{}}\alpha_{C}\sim 0.050,C_{c}\sim 3.1\times 10^{8}" display="inline"><semantics id="S2.Ex2.m3.3a"><mrow id="S2.Ex2.m3.3.3.2" xref="S2.Ex2.m3.3.3.3.cmml"><mrow id="S2.Ex2.m3.2.2.1.1" xref="S2.Ex2.m3.2.2.1.1.cmml"><mrow id="S2.Ex2.m3.2.2.1.1.2.2" xref="S2.Ex2.m3.2.2.1.1.2.3.cmml"><msup id="S2.Ex2.m3.2.2.1.1.1.1.1" xref="S2.Ex2.m3.2.2.1.1.1.1.1.cmml"><mrow id="S2.Ex2.m3.2.2.1.1.1.1.1.2.2" xref="S2.Ex2.m3.1.1.cmml"><mo maxsize="210%" minsize="210%" id="S2.Ex2.m3.2.2.1.1.1.1.1.2.2.1" xref="S2.Ex2.m3.1.1.cmml">(</mo><mstyle displaystyle="true" id="S2.Ex2.m3.1.1" xref="S2.Ex2.m3.1.1.cmml"><mfrac id="S2.Ex2.m3.1.1a" xref="S2.Ex2.m3.1.1.cmml"><msub id="S2.Ex2.m3.1.1.2" xref="S2.Ex2.m3.1.1.2.cmml"><mi mathsize="90%" id="S2.Ex2.m3.1.1.2.2" xref="S2.Ex2.m3.1.1.2.2.cmml">C</mi><mi mathsize="90%" id="S2.Ex2.m3.1.1.2.3" xref="S2.Ex2.m3.1.1.2.3.cmml">c</mi></msub><mi mathsize="90%" id="S2.Ex2.m3.1.1.3" xref="S2.Ex2.m3.1.1.3.cmml">C</mi></mfrac></mstyle><mo maxsize="210%" minsize="210%" id="S2.Ex2.m3.2.2.1.1.1.1.1.2.2.2" xref="S2.Ex2.m3.1.1.cmml">)</mo></mrow><msub id="S2.Ex2.m3.2.2.1.1.1.1.1.3" xref="S2.Ex2.m3.2.2.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S2.Ex2.m3.2.2.1.1.1.1.1.3.2" xref="S2.Ex2.m3.2.2.1.1.1.1.1.3.2.cmml">α</mi><mi mathsize="90%" id="S2.Ex2.m3.2.2.1.1.1.1.1.3.3" xref="S2.Ex2.m3.2.2.1.1.1.1.1.3.3.cmml">C</mi></msub></msup><mo mathsize="90%" id="S2.Ex2.m3.2.2.1.1.2.2.3" xref="S2.Ex2.m3.2.2.1.1.2.3.cmml">,</mo><mrow id="S2.Ex2.m3.2.2.1.1.2.2.2" xref="S2.Ex2.m3.2.2.1.1.2.2.2.cmml"><mtext mathsize="90%" id="S2.Ex2.m3.2.2.1.1.2.2.2.2" xref="S2.Ex2.m3.2.2.1.1.2.2.2.2a.cmml">&nbsp;</mtext><mo lspace="0em" rspace="0em" id="S2.Ex2.m3.2.2.1.1.2.2.2.1" xref="S2.Ex2.m3.2.2.1.1.2.2.2.1.cmml">​</mo><msub id="S2.Ex2.m3.2.2.1.1.2.2.2.3" xref="S2.Ex2.m3.2.2.1.1.2.2.2.3.cmml"><mi mathsize="90%" id="S2.Ex2.m3.2.2.1.1.2.2.2.3.2" xref="S2.Ex2.m3.2.2.1.1.2.2.2.3.2.cmml">α</mi><mi mathsize="90%" id="S2.Ex2.m3.2.2.1.1.2.2.2.3.3" xref="S2.Ex2.m3.2.2.1.1.2.2.2.3.3.cmml">C</mi></msub></mrow></mrow><mo mathsize="90%" id="S2.Ex2.m3.2.2.1.1.3" xref="S2.Ex2.m3.2.2.1.1.3.cmml">∼</mo><mn mathsize="90%" id="S2.Ex2.m3.2.2.1.1.4" xref="S2.Ex2.m3.2.2.1.1.4.cmml">0.050</mn></mrow><mo mathsize="90%" id="S2.Ex2.m3.3.3.2.3" xref="S2.Ex2.m3.3.3.3a.cmml">,</mo><mrow id="S2.Ex2.m3.3.3.2.2" xref="S2.Ex2.m3.3.3.2.2.cmml"><msub id="S2.Ex2.m3.3.3.2.2.2" xref="S2.Ex2.m3.3.3.2.2.2.cmml"><mi mathsize="90%" id="S2.Ex2.m3.3.3.2.2.2.2" xref="S2.Ex2.m3.3.3.2.2.2.2.cmml">C</mi><mi mathsize="90%" id="S2.Ex2.m3.3.3.2.2.2.3" xref="S2.Ex2.m3.3.3.2.2.2.3.cmml">c</mi></msub><mo mathsize="90%" id="S2.Ex2.m3.3.3.2.2.1" xref="S2.Ex2.m3.3.3.2.2.1.cmml">∼</mo><mrow id="S2.Ex2.m3.3.3.2.2.3" xref="S2.Ex2.m3.3.3.2.2.3.cmml"><mn mathsize="90%" id="S2.Ex2.m3.3.3.2.2.3.2" xref="S2.Ex2.m3.3.3.2.2.3.2.cmml">3.1</mn><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S2.Ex2.m3.3.3.2.2.3.1" xref="S2.Ex2.m3.3.3.2.2.3.1.cmml">×</mo><msup id="S2.Ex2.m3.3.3.2.2.3.3" xref="S2.Ex2.m3.3.3.2.2.3.3.cmml"><mn mathsize="90%" id="S2.Ex2.m3.3.3.2.2.3.3.2" xref="S2.Ex2.m3.3.3.2.2.3.3.2.cmml">10</mn><mn mathsize="90%" id="S2.Ex2.m3.3.3.2.2.3.3.3" xref="S2.Ex2.m3.3.3.2.2.3.3.3.cmml">8</mn></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m3.3b"><apply id="S2.Ex2.m3.3.3.3.cmml" xref="S2.Ex2.m3.3.3.2"><csymbol cd="ambiguous" id="S2.Ex2.m3.3.3.3a.cmml" xref="S2.Ex2.m3.3.3.2.3">formulae-sequence</csymbol><apply id="S2.Ex2.m3.2.2.1.1.cmml" xref="S2.Ex2.m3.2.2.1.1"><csymbol cd="latexml" id="S2.Ex2.m3.2.2.1.1.3.cmml" xref="S2.Ex2.m3.2.2.1.1.3">similar-to</csymbol><list id="S2.Ex2.m3.2.2.1.1.2.3.cmml" xref="S2.Ex2.m3.2.2.1.1.2.2"><apply id="S2.Ex2.m3.2.2.1.1.1.1.1.cmml" xref="S2.Ex2.m3.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m3.2.2.1.1.1.1.1.1.cmml" xref="S2.Ex2.m3.2.2.1.1.1.1.1">superscript</csymbol><apply id="S2.Ex2.m3.1.1.cmml" xref="S2.Ex2.m3.2.2.1.1.1.1.1.2.2"><divide id="S2.Ex2.m3.1.1.1.cmml" xref="S2.Ex2.m3.2.2.1.1.1.1.1.2.2"></divide><apply id="S2.Ex2.m3.1.1.2.cmml" xref="S2.Ex2.m3.1.1.2"><csymbol cd="ambiguous" id="S2.Ex2.m3.1.1.2.1.cmml" xref="S2.Ex2.m3.1.1.2">subscript</csymbol><ci id="S2.Ex2.m3.1.1.2.2.cmml" xref="S2.Ex2.m3.1.1.2.2">𝐶</ci><ci id="S2.Ex2.m3.1.1.2.3.cmml" xref="S2.Ex2.m3.1.1.2.3">𝑐</ci></apply><ci id="S2.Ex2.m3.1.1.3.cmml" xref="S2.Ex2.m3.1.1.3">𝐶</ci></apply><apply id="S2.Ex2.m3.2.2.1.1.1.1.1.3.cmml" xref="S2.Ex2.m3.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex2.m3.2.2.1.1.1.1.1.3.1.cmml" xref="S2.Ex2.m3.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex2.m3.2.2.1.1.1.1.1.3.2.cmml" xref="S2.Ex2.m3.2.2.1.1.1.1.1.3.2">𝛼</ci><ci id="S2.Ex2.m3.2.2.1.1.1.1.1.3.3.cmml" xref="S2.Ex2.m3.2.2.1.1.1.1.1.3.3">𝐶</ci></apply></apply><apply id="S2.Ex2.m3.2.2.1.1.2.2.2.cmml" xref="S2.Ex2.m3.2.2.1.1.2.2.2"><times id="S2.Ex2.m3.2.2.1.1.2.2.2.1.cmml" xref="S2.Ex2.m3.2.2.1.1.2.2.2.1"></times><ci id="S2.Ex2.m3.2.2.1.1.2.2.2.2a.cmml" xref="S2.Ex2.m3.2.2.1.1.2.2.2.2"><mtext mathsize="90%" id="S2.Ex2.m3.2.2.1.1.2.2.2.2.cmml" xref="S2.Ex2.m3.2.2.1.1.2.2.2.2">&nbsp;</mtext></ci><apply id="S2.Ex2.m3.2.2.1.1.2.2.2.3.cmml" xref="S2.Ex2.m3.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S2.Ex2.m3.2.2.1.1.2.2.2.3.1.cmml" xref="S2.Ex2.m3.2.2.1.1.2.2.2.3">subscript</csymbol><ci id="S2.Ex2.m3.2.2.1.1.2.2.2.3.2.cmml" xref="S2.Ex2.m3.2.2.1.1.2.2.2.3.2">𝛼</ci><ci id="S2.Ex2.m3.2.2.1.1.2.2.2.3.3.cmml" xref="S2.Ex2.m3.2.2.1.1.2.2.2.3.3">𝐶</ci></apply></apply></list><cn type="float" id="S2.Ex2.m3.2.2.1.1.4.cmml" xref="S2.Ex2.m3.2.2.1.1.4">0.050</cn></apply><apply id="S2.Ex2.m3.3.3.2.2.cmml" xref="S2.Ex2.m3.3.3.2.2"><csymbol cd="latexml" id="S2.Ex2.m3.3.3.2.2.1.cmml" xref="S2.Ex2.m3.3.3.2.2.1">similar-to</csymbol><apply id="S2.Ex2.m3.3.3.2.2.2.cmml" xref="S2.Ex2.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.Ex2.m3.3.3.2.2.2.1.cmml" xref="S2.Ex2.m3.3.3.2.2.2">subscript</csymbol><ci id="S2.Ex2.m3.3.3.2.2.2.2.cmml" xref="S2.Ex2.m3.3.3.2.2.2.2">𝐶</ci><ci id="S2.Ex2.m3.3.3.2.2.2.3.cmml" xref="S2.Ex2.m3.3.3.2.2.2.3">𝑐</ci></apply><apply id="S2.Ex2.m3.3.3.2.2.3.cmml" xref="S2.Ex2.m3.3.3.2.2.3"><times id="S2.Ex2.m3.3.3.2.2.3.1.cmml" xref="S2.Ex2.m3.3.3.2.2.3.1"></times><cn type="float" id="S2.Ex2.m3.3.3.2.2.3.2.cmml" xref="S2.Ex2.m3.3.3.2.2.3.2">3.1</cn><apply id="S2.Ex2.m3.3.3.2.2.3.3.cmml" xref="S2.Ex2.m3.3.3.2.2.3.3"><csymbol cd="ambiguous" id="S2.Ex2.m3.3.3.2.2.3.3.1.cmml" xref="S2.Ex2.m3.3.3.2.2.3.3">superscript</csymbol><cn type="integer" id="S2.Ex2.m3.3.3.2.2.3.3.2.cmml" xref="S2.Ex2.m3.3.3.2.2.3.3.2">10</cn><cn type="integer" id="S2.Ex2.m3.3.3.2.2.3.3.3.cmml" xref="S2.Ex2.m3.3.3.2.2.3.3.3">8</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m3.3c">\displaystyle\bigg{(}\frac{C_{c}}{C}\bigg{)}^{\alpha_{C}},\text{~{}~{}~{}}\alpha_{C}\sim 0.050,C_{c}\sim 3.1\times 10^{8}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.p5.1">여기서 <math alttext="L(\cdot)" class="ltx_Math" display="inline" id="S2.SS1.p5.1.m1.1"><semantics id="S2.SS1.p5.1.m1.1a"><mrow id="S2.SS1.p5.1.m1.1.2" xref="S2.SS1.p5.1.m1.1.2.cmml"><mi id="S2.SS1.p5.1.m1.1.2.2" xref="S2.SS1.p5.1.m1.1.2.2.cmml">L</mi><mo id="S2.SS1.p5.1.m1.1.2.1" lspace="0em" rspace="0em" xref="S2.SS1.p5.1.m1.1.2.1.cmml">​</mo><mrow id="S2.SS1.p5.1.m1.1.2.3.2" xref="S2.SS1.p5.1.m1.1.2.cmml"><mo id="S2.SS1.p5.1.m1.1.2.3.2.1" stretchy="false" xref="S2.SS1.p5.1.m1.1.2.cmml">(</mo><mo id="S2.SS1.p5.1.m1.1.1" lspace="0em" rspace="0em" xref="S2.SS1.p5.1.m1.1.1.cmml">⋅</mo><mo id="S2.SS1.p5.1.m1.1.2.3.2.2" stretchy="false" xref="S2.SS1.p5.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.1.m1.1b"><apply id="S2.SS1.p5.1.m1.1.2.cmml" xref="S2.SS1.p5.1.m1.1.2"><times id="S2.SS1.p5.1.m1.1.2.1.cmml" xref="S2.SS1.p5.1.m1.1.2.1"></times><ci id="S2.SS1.p5.1.m1.1.2.2.cmml" xref="S2.SS1.p5.1.m1.1.2.2">𝐿</ci><ci id="S2.SS1.p5.1.m1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.1.m1.1c">L(\cdot)</annotation></semantics></math>는 nats의 교차 엔트로피 손실을 나타내며, OpenAI의 후속 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib58" title="">58</a>]</cite>는 언어 모델링 손실이 두 부분으로 분해될 수 있음을 보여주었다. 즉 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p5.1.1">irreducible loss</em> (true data distribution의 entropy)와 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p5.1.2">reducible loss</em> (true와 모델 분포 사이의 KL 발산 추정치). 세 가지 법칙은 모델 성능을 다양한 데이터 크기(22M ~ 23B 토큰), 모델 크기(768M ~ 1.5B 비 임베딩 매개변수) 및 훈련 컴퓨팅에 피팅하여 도출되었으며, 일부 가정(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p5.1.3">e.g.,</em> 한 요인의 분석이 다른 두 요인에 의해 병목되지 않아야 한다. 그들은 모델 성능이 세 가지 요인에 강한 의존 관계를 가지고 있음을 보여주었다.</p>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p6.1.m1.1"><semantics id="S2.SS1.p6.1.m1.1a"><mo id="S2.SS1.p6.1.m1.1.1" xref="S2.SS1.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.1.m1.1b"><ci id="S2.SS1.p6.1.m1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p6.1.1">Chinchilla scaling law</em>. 또 다른 대표적인 연구로서, Hoffmann et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite> (the Google DeepMind team)은 LLMs에 대한 컴퓨팅-최적 트레이닝을 지시하기 위해 스케일링 법칙에 대한 대안적인 형태를 제안하였다. 그들은 더 큰 범위의 모델 크기(70M~16B) 및 데이터 크기(5B~500B 토큰)를 변경하여 엄격한 실험을 수행했으며 유사한 스케일링 법칙을 적용했지만 아래 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>와 같이 계수가 다르다.</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.3" class="ltx_Math" alttext="L(N,D)=E+\frac{A}{N^{\alpha}}+\frac{B}{D^{\beta}}," display="block"><semantics id="S2.E2.m1.3a"><mrow id="S2.E2.m1.3.3.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1.2" xref="S2.E2.m1.3.3.1.1.2.cmml"><mi id="S2.E2.m1.3.3.1.1.2.2" xref="S2.E2.m1.3.3.1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.1.1.2.1" xref="S2.E2.m1.3.3.1.1.2.1.cmml">​</mo><mrow id="S2.E2.m1.3.3.1.1.2.3.2" xref="S2.E2.m1.3.3.1.1.2.3.1.cmml"><mo stretchy="false" id="S2.E2.m1.3.3.1.1.2.3.2.1" xref="S2.E2.m1.3.3.1.1.2.3.1.cmml">(</mo><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">N</mi><mo id="S2.E2.m1.3.3.1.1.2.3.2.2" xref="S2.E2.m1.3.3.1.1.2.3.1.cmml">,</mo><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">D</mi><mo stretchy="false" id="S2.E2.m1.3.3.1.1.2.3.2.3" xref="S2.E2.m1.3.3.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.3.3.1.1.1" xref="S2.E2.m1.3.3.1.1.1.cmml">=</mo><mrow id="S2.E2.m1.3.3.1.1.3" xref="S2.E2.m1.3.3.1.1.3.cmml"><mi id="S2.E2.m1.3.3.1.1.3.2" xref="S2.E2.m1.3.3.1.1.3.2.cmml">E</mi><mo id="S2.E2.m1.3.3.1.1.3.1" xref="S2.E2.m1.3.3.1.1.3.1.cmml">+</mo><mfrac id="S2.E2.m1.3.3.1.1.3.3" xref="S2.E2.m1.3.3.1.1.3.3.cmml"><mi id="S2.E2.m1.3.3.1.1.3.3.2" xref="S2.E2.m1.3.3.1.1.3.3.2.cmml">A</mi><msup id="S2.E2.m1.3.3.1.1.3.3.3" xref="S2.E2.m1.3.3.1.1.3.3.3.cmml"><mi id="S2.E2.m1.3.3.1.1.3.3.3.2" xref="S2.E2.m1.3.3.1.1.3.3.3.2.cmml">N</mi><mi id="S2.E2.m1.3.3.1.1.3.3.3.3" xref="S2.E2.m1.3.3.1.1.3.3.3.3.cmml">α</mi></msup></mfrac><mo id="S2.E2.m1.3.3.1.1.3.1a" xref="S2.E2.m1.3.3.1.1.3.1.cmml">+</mo><mfrac id="S2.E2.m1.3.3.1.1.3.4" xref="S2.E2.m1.3.3.1.1.3.4.cmml"><mi id="S2.E2.m1.3.3.1.1.3.4.2" xref="S2.E2.m1.3.3.1.1.3.4.2.cmml">B</mi><msup id="S2.E2.m1.3.3.1.1.3.4.3" xref="S2.E2.m1.3.3.1.1.3.4.3.cmml"><mi id="S2.E2.m1.3.3.1.1.3.4.3.2" xref="S2.E2.m1.3.3.1.1.3.4.3.2.cmml">D</mi><mi id="S2.E2.m1.3.3.1.1.3.4.3.3" xref="S2.E2.m1.3.3.1.1.3.4.3.3.cmml">β</mi></msup></mfrac></mrow></mrow><mo id="S2.E2.m1.3.3.1.2" xref="S2.E2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.3b"><apply id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1"><eq id="S2.E2.m1.3.3.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1"></eq><apply id="S2.E2.m1.3.3.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2"><times id="S2.E2.m1.3.3.1.1.2.1.cmml" xref="S2.E2.m1.3.3.1.1.2.1"></times><ci id="S2.E2.m1.3.3.1.1.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2">𝐿</ci><interval closure="open" id="S2.E2.m1.3.3.1.1.2.3.1.cmml" xref="S2.E2.m1.3.3.1.1.2.3.2"><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">𝑁</ci><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">𝐷</ci></interval></apply><apply id="S2.E2.m1.3.3.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.3"><plus id="S2.E2.m1.3.3.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.3.1"></plus><ci id="S2.E2.m1.3.3.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.3.2">𝐸</ci><apply id="S2.E2.m1.3.3.1.1.3.3.cmml" xref="S2.E2.m1.3.3.1.1.3.3"><divide id="S2.E2.m1.3.3.1.1.3.3.1.cmml" xref="S2.E2.m1.3.3.1.1.3.3"></divide><ci id="S2.E2.m1.3.3.1.1.3.3.2.cmml" xref="S2.E2.m1.3.3.1.1.3.3.2">𝐴</ci><apply id="S2.E2.m1.3.3.1.1.3.3.3.cmml" xref="S2.E2.m1.3.3.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.3.3.3.1.cmml" xref="S2.E2.m1.3.3.1.1.3.3.3">superscript</csymbol><ci id="S2.E2.m1.3.3.1.1.3.3.3.2.cmml" xref="S2.E2.m1.3.3.1.1.3.3.3.2">𝑁</ci><ci id="S2.E2.m1.3.3.1.1.3.3.3.3.cmml" xref="S2.E2.m1.3.3.1.1.3.3.3.3">𝛼</ci></apply></apply><apply id="S2.E2.m1.3.3.1.1.3.4.cmml" xref="S2.E2.m1.3.3.1.1.3.4"><divide id="S2.E2.m1.3.3.1.1.3.4.1.cmml" xref="S2.E2.m1.3.3.1.1.3.4"></divide><ci id="S2.E2.m1.3.3.1.1.3.4.2.cmml" xref="S2.E2.m1.3.3.1.1.3.4.2">𝐵</ci><apply id="S2.E2.m1.3.3.1.1.3.4.3.cmml" xref="S2.E2.m1.3.3.1.1.3.4.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.3.4.3.1.cmml" xref="S2.E2.m1.3.3.1.1.3.4.3">superscript</csymbol><ci id="S2.E2.m1.3.3.1.1.3.4.3.2.cmml" xref="S2.E2.m1.3.3.1.1.3.4.3.2">𝐷</ci><ci id="S2.E2.m1.3.3.1.1.3.4.3.3.cmml" xref="S2.E2.m1.3.3.1.1.3.4.3.3">𝛽</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.3c">L(N,D)=E+\frac{A}{N^{\alpha}}+\frac{B}{D^{\beta}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p6.6" class="ltx_p">where <math id="S2.SS1.p6.2.m1.2" class="ltx_Math" alttext="E=1.69,A=406.4,B=410.7" display="inline"><semantics id="S2.SS1.p6.2.m1.2a"><mrow id="S2.SS1.p6.2.m1.2.2.2" xref="S2.SS1.p6.2.m1.2.2.3.cmml"><mrow id="S2.SS1.p6.2.m1.1.1.1.1" xref="S2.SS1.p6.2.m1.1.1.1.1.cmml"><mi id="S2.SS1.p6.2.m1.1.1.1.1.2" xref="S2.SS1.p6.2.m1.1.1.1.1.2.cmml">E</mi><mo id="S2.SS1.p6.2.m1.1.1.1.1.1" xref="S2.SS1.p6.2.m1.1.1.1.1.1.cmml">=</mo><mn id="S2.SS1.p6.2.m1.1.1.1.1.3" xref="S2.SS1.p6.2.m1.1.1.1.1.3.cmml">1.69</mn></mrow><mo id="S2.SS1.p6.2.m1.2.2.2.3" xref="S2.SS1.p6.2.m1.2.2.3a.cmml">,</mo><mrow id="S2.SS1.p6.2.m1.2.2.2.2.2" xref="S2.SS1.p6.2.m1.2.2.2.2.3.cmml"><mrow id="S2.SS1.p6.2.m1.2.2.2.2.1.1" xref="S2.SS1.p6.2.m1.2.2.2.2.1.1.cmml"><mi id="S2.SS1.p6.2.m1.2.2.2.2.1.1.2" xref="S2.SS1.p6.2.m1.2.2.2.2.1.1.2.cmml">A</mi><mo id="S2.SS1.p6.2.m1.2.2.2.2.1.1.1" xref="S2.SS1.p6.2.m1.2.2.2.2.1.1.1.cmml">=</mo><mn id="S2.SS1.p6.2.m1.2.2.2.2.1.1.3" xref="S2.SS1.p6.2.m1.2.2.2.2.1.1.3.cmml">406.4</mn></mrow><mo id="S2.SS1.p6.2.m1.2.2.2.2.2.3" xref="S2.SS1.p6.2.m1.2.2.2.2.3a.cmml">,</mo><mrow id="S2.SS1.p6.2.m1.2.2.2.2.2.2" xref="S2.SS1.p6.2.m1.2.2.2.2.2.2.cmml"><mi id="S2.SS1.p6.2.m1.2.2.2.2.2.2.2" xref="S2.SS1.p6.2.m1.2.2.2.2.2.2.2.cmml">B</mi><mo id="S2.SS1.p6.2.m1.2.2.2.2.2.2.1" xref="S2.SS1.p6.2.m1.2.2.2.2.2.2.1.cmml">=</mo><mn id="S2.SS1.p6.2.m1.2.2.2.2.2.2.3" xref="S2.SS1.p6.2.m1.2.2.2.2.2.2.3.cmml">410.7</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.2.m1.2b"><apply id="S2.SS1.p6.2.m1.2.2.3.cmml" xref="S2.SS1.p6.2.m1.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p6.2.m1.2.2.3a.cmml" xref="S2.SS1.p6.2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S2.SS1.p6.2.m1.1.1.1.1.cmml" xref="S2.SS1.p6.2.m1.1.1.1.1"><eq id="S2.SS1.p6.2.m1.1.1.1.1.1.cmml" xref="S2.SS1.p6.2.m1.1.1.1.1.1"></eq><ci id="S2.SS1.p6.2.m1.1.1.1.1.2.cmml" xref="S2.SS1.p6.2.m1.1.1.1.1.2">𝐸</ci><cn type="float" id="S2.SS1.p6.2.m1.1.1.1.1.3.cmml" xref="S2.SS1.p6.2.m1.1.1.1.1.3">1.69</cn></apply><apply id="S2.SS1.p6.2.m1.2.2.2.2.3.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p6.2.m1.2.2.2.2.3a.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S2.SS1.p6.2.m1.2.2.2.2.1.1.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.1.1"><eq id="S2.SS1.p6.2.m1.2.2.2.2.1.1.1.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.1.1.1"></eq><ci id="S2.SS1.p6.2.m1.2.2.2.2.1.1.2.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.1.1.2">𝐴</ci><cn type="float" id="S2.SS1.p6.2.m1.2.2.2.2.1.1.3.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.1.1.3">406.4</cn></apply><apply id="S2.SS1.p6.2.m1.2.2.2.2.2.2.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.2.2"><eq id="S2.SS1.p6.2.m1.2.2.2.2.2.2.1.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.2.2.1"></eq><ci id="S2.SS1.p6.2.m1.2.2.2.2.2.2.2.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.2.2.2">𝐵</ci><cn type="float" id="S2.SS1.p6.2.m1.2.2.2.2.2.2.3.cmml" xref="S2.SS1.p6.2.m1.2.2.2.2.2.2.3">410.7</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.2.m1.2c">E=1.69,A=406.4,B=410.7</annotation></semantics></math>, <math id="S2.SS1.p6.3.m2.1" class="ltx_Math" alttext="\alpha=0.34" display="inline"><semantics id="S2.SS1.p6.3.m2.1a"><mrow id="S2.SS1.p6.3.m2.1.1" xref="S2.SS1.p6.3.m2.1.1.cmml"><mi id="S2.SS1.p6.3.m2.1.1.2" xref="S2.SS1.p6.3.m2.1.1.2.cmml">α</mi><mo id="S2.SS1.p6.3.m2.1.1.1" xref="S2.SS1.p6.3.m2.1.1.1.cmml">=</mo><mn id="S2.SS1.p6.3.m2.1.1.3" xref="S2.SS1.p6.3.m2.1.1.3.cmml">0.34</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.3.m2.1b"><apply id="S2.SS1.p6.3.m2.1.1.cmml" xref="S2.SS1.p6.3.m2.1.1"><eq id="S2.SS1.p6.3.m2.1.1.1.cmml" xref="S2.SS1.p6.3.m2.1.1.1"></eq><ci id="S2.SS1.p6.3.m2.1.1.2.cmml" xref="S2.SS1.p6.3.m2.1.1.2">𝛼</ci><cn type="float" id="S2.SS1.p6.3.m2.1.1.3.cmml" xref="S2.SS1.p6.3.m2.1.1.3">0.34</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.3.m2.1c">\alpha=0.34</annotation></semantics></math> and <math id="S2.SS1.p6.4.m3.1" class="ltx_Math" alttext="\beta=0.28" display="inline"><semantics id="S2.SS1.p6.4.m3.1a"><mrow id="S2.SS1.p6.4.m3.1.1" xref="S2.SS1.p6.4.m3.1.1.cmml"><mi id="S2.SS1.p6.4.m3.1.1.2" xref="S2.SS1.p6.4.m3.1.1.2.cmml">β</mi><mo id="S2.SS1.p6.4.m3.1.1.1" xref="S2.SS1.p6.4.m3.1.1.1.cmml">=</mo><mn id="S2.SS1.p6.4.m3.1.1.3" xref="S2.SS1.p6.4.m3.1.1.3.cmml">0.28</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.4.m3.1b"><apply id="S2.SS1.p6.4.m3.1.1.cmml" xref="S2.SS1.p6.4.m3.1.1"><eq id="S2.SS1.p6.4.m3.1.1.1.cmml" xref="S2.SS1.p6.4.m3.1.1.1"></eq><ci id="S2.SS1.p6.4.m3.1.1.2.cmml" xref="S2.SS1.p6.4.m3.1.1.2">𝛽</ci><cn type="float" id="S2.SS1.p6.4.m3.1.1.3.cmml" xref="S2.SS1.p6.4.m3.1.1.3">0.28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.4.m3.1c">\beta=0.28</annotation></semantics></math>. By optimizing the loss <math id="S2.SS1.p6.5.m4.2" class="ltx_Math" alttext="L(N,D)" display="inline"><semantics id="S2.SS1.p6.5.m4.2a"><mrow id="S2.SS1.p6.5.m4.2.3" xref="S2.SS1.p6.5.m4.2.3.cmml"><mi id="S2.SS1.p6.5.m4.2.3.2" xref="S2.SS1.p6.5.m4.2.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p6.5.m4.2.3.1" xref="S2.SS1.p6.5.m4.2.3.1.cmml">​</mo><mrow id="S2.SS1.p6.5.m4.2.3.3.2" xref="S2.SS1.p6.5.m4.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS1.p6.5.m4.2.3.3.2.1" xref="S2.SS1.p6.5.m4.2.3.3.1.cmml">(</mo><mi id="S2.SS1.p6.5.m4.1.1" xref="S2.SS1.p6.5.m4.1.1.cmml">N</mi><mo id="S2.SS1.p6.5.m4.2.3.3.2.2" xref="S2.SS1.p6.5.m4.2.3.3.1.cmml">,</mo><mi id="S2.SS1.p6.5.m4.2.2" xref="S2.SS1.p6.5.m4.2.2.cmml">D</mi><mo stretchy="false" id="S2.SS1.p6.5.m4.2.3.3.2.3" xref="S2.SS1.p6.5.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.5.m4.2b"><apply id="S2.SS1.p6.5.m4.2.3.cmml" xref="S2.SS1.p6.5.m4.2.3"><times id="S2.SS1.p6.5.m4.2.3.1.cmml" xref="S2.SS1.p6.5.m4.2.3.1"></times><ci id="S2.SS1.p6.5.m4.2.3.2.cmml" xref="S2.SS1.p6.5.m4.2.3.2">𝐿</ci><interval closure="open" id="S2.SS1.p6.5.m4.2.3.3.1.cmml" xref="S2.SS1.p6.5.m4.2.3.3.2"><ci id="S2.SS1.p6.5.m4.1.1.cmml" xref="S2.SS1.p6.5.m4.1.1">𝑁</ci><ci id="S2.SS1.p6.5.m4.2.2.cmml" xref="S2.SS1.p6.5.m4.2.2">𝐷</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.5.m4.2c">L(N,D)</annotation></semantics></math> under the constraint <math id="S2.SS1.p6.6.m5.1" class="ltx_Math" alttext="C\approx 6ND" display="inline"><semantics id="S2.SS1.p6.6.m5.1a"><mrow id="S2.SS1.p6.6.m5.1.1" xref="S2.SS1.p6.6.m5.1.1.cmml"><mi id="S2.SS1.p6.6.m5.1.1.2" xref="S2.SS1.p6.6.m5.1.1.2.cmml">C</mi><mo id="S2.SS1.p6.6.m5.1.1.1" xref="S2.SS1.p6.6.m5.1.1.1.cmml">≈</mo><mrow id="S2.SS1.p6.6.m5.1.1.3" xref="S2.SS1.p6.6.m5.1.1.3.cmml"><mn id="S2.SS1.p6.6.m5.1.1.3.2" xref="S2.SS1.p6.6.m5.1.1.3.2.cmml">6</mn><mo lspace="0em" rspace="0em" id="S2.SS1.p6.6.m5.1.1.3.1" xref="S2.SS1.p6.6.m5.1.1.3.1.cmml">​</mo><mi id="S2.SS1.p6.6.m5.1.1.3.3" xref="S2.SS1.p6.6.m5.1.1.3.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p6.6.m5.1.1.3.1a" xref="S2.SS1.p6.6.m5.1.1.3.1.cmml">​</mo><mi id="S2.SS1.p6.6.m5.1.1.3.4" xref="S2.SS1.p6.6.m5.1.1.3.4.cmml">D</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.6.m5.1b"><apply id="S2.SS1.p6.6.m5.1.1.cmml" xref="S2.SS1.p6.6.m5.1.1"><approx id="S2.SS1.p6.6.m5.1.1.1.cmml" xref="S2.SS1.p6.6.m5.1.1.1"></approx><ci id="S2.SS1.p6.6.m5.1.1.2.cmml" xref="S2.SS1.p6.6.m5.1.1.2">𝐶</ci><apply id="S2.SS1.p6.6.m5.1.1.3.cmml" xref="S2.SS1.p6.6.m5.1.1.3"><times id="S2.SS1.p6.6.m5.1.1.3.1.cmml" xref="S2.SS1.p6.6.m5.1.1.3.1"></times><cn type="integer" id="S2.SS1.p6.6.m5.1.1.3.2.cmml" xref="S2.SS1.p6.6.m5.1.1.3.2">6</cn><ci id="S2.SS1.p6.6.m5.1.1.3.3.cmml" xref="S2.SS1.p6.6.m5.1.1.3.3">𝑁</ci><ci id="S2.SS1.p6.6.m5.1.1.3.4.cmml" xref="S2.SS1.p6.6.m5.1.1.3.4">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.6.m5.1c">C\approx 6ND</annotation></semantics></math>, they showed that the optimal allocation of compute budget to model size and data size can be derived as follows:</p>
</div>
<div id="S2.SS1.p7" class="ltx_para">
<table id="Sx2.EGx2" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E3.m1.5" class="ltx_Math" alttext="\displaystyle N_{opt}(C)=G\bigg{(}\frac{C}{6}\bigg{)}^{a},\text{~{}~{}~{}}D_{opt}(C)=G^{-1}\bigg{(}\frac{C}{6}\bigg{)}^{b}," display="inline"><semantics id="S2.E3.m1.5a"><mrow id="S2.E3.m1.5.5.1"><mrow id="S2.E3.m1.5.5.1.1.2" xref="S2.E3.m1.5.5.1.1.3.cmml"><mrow id="S2.E3.m1.5.5.1.1.1.1" xref="S2.E3.m1.5.5.1.1.1.1.cmml"><mrow id="S2.E3.m1.5.5.1.1.1.1.2" xref="S2.E3.m1.5.5.1.1.1.1.2.cmml"><msub id="S2.E3.m1.5.5.1.1.1.1.2.2" xref="S2.E3.m1.5.5.1.1.1.1.2.2.cmml"><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.1.1.2.2.2" xref="S2.E3.m1.5.5.1.1.1.1.2.2.2.cmml">N</mi><mrow id="S2.E3.m1.5.5.1.1.1.1.2.2.3" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.cmml"><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.1.1.2.2.3.2" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.1.1.2.2.3.1" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.1.cmml">​</mo><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.1.1.2.2.3.3" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.1.1.2.2.3.1a" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.1.cmml">​</mo><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.1.1.2.2.3.4" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.4.cmml">t</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.1.1.2.1" xref="S2.E3.m1.5.5.1.1.1.1.2.1.cmml">​</mo><mrow id="S2.E3.m1.5.5.1.1.1.1.2.3.2" xref="S2.E3.m1.5.5.1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.5.5.1.1.1.1.2.3.2.1" xref="S2.E3.m1.5.5.1.1.1.1.2.cmml">(</mo><mi mathsize="90%" id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml">C</mi><mo maxsize="90%" minsize="90%" id="S2.E3.m1.5.5.1.1.1.1.2.3.2.2" xref="S2.E3.m1.5.5.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S2.E3.m1.5.5.1.1.1.1.1" xref="S2.E3.m1.5.5.1.1.1.1.1.cmml">=</mo><mrow id="S2.E3.m1.5.5.1.1.1.1.3" xref="S2.E3.m1.5.5.1.1.1.1.3.cmml"><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.1.1.3.2" xref="S2.E3.m1.5.5.1.1.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.1.1.3.1" xref="S2.E3.m1.5.5.1.1.1.1.3.1.cmml">​</mo><msup id="S2.E3.m1.5.5.1.1.1.1.3.3" xref="S2.E3.m1.5.5.1.1.1.1.3.3.cmml"><mrow id="S2.E3.m1.5.5.1.1.1.1.3.3.2.2" xref="S2.E3.m1.2.2.cmml"><mo maxsize="210%" minsize="210%" id="S2.E3.m1.5.5.1.1.1.1.3.3.2.2.1" xref="S2.E3.m1.2.2.cmml">(</mo><mstyle displaystyle="true" id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml"><mfrac id="S2.E3.m1.2.2a" xref="S2.E3.m1.2.2.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2" xref="S2.E3.m1.2.2.2.cmml">C</mi><mn mathsize="90%" id="S2.E3.m1.2.2.3" xref="S2.E3.m1.2.2.3.cmml">6</mn></mfrac></mstyle><mo maxsize="210%" minsize="210%" id="S2.E3.m1.5.5.1.1.1.1.3.3.2.2.2" xref="S2.E3.m1.2.2.cmml">)</mo></mrow><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.1.1.3.3.3" xref="S2.E3.m1.5.5.1.1.1.1.3.3.3.cmml">a</mi></msup></mrow></mrow><mo mathsize="90%" id="S2.E3.m1.5.5.1.1.2.3" xref="S2.E3.m1.5.5.1.1.3a.cmml">,</mo><mrow id="S2.E3.m1.5.5.1.1.2.2" xref="S2.E3.m1.5.5.1.1.2.2.cmml"><mrow id="S2.E3.m1.5.5.1.1.2.2.2" xref="S2.E3.m1.5.5.1.1.2.2.2.cmml"><mtext mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.2.2" xref="S2.E3.m1.5.5.1.1.2.2.2.2a.cmml">&nbsp;</mtext><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.2.2.2.1" xref="S2.E3.m1.5.5.1.1.2.2.2.1.cmml">​</mo><msub id="S2.E3.m1.5.5.1.1.2.2.2.3" xref="S2.E3.m1.5.5.1.1.2.2.2.3.cmml"><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.2.3.2" xref="S2.E3.m1.5.5.1.1.2.2.2.3.2.cmml">D</mi><mrow id="S2.E3.m1.5.5.1.1.2.2.2.3.3" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.cmml"><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.2.3.3.2" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.2.2.2.3.3.1" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.1.cmml">​</mo><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.2.3.3.3" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.2.2.2.3.3.1a" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.1.cmml">​</mo><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.2.3.3.4" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.4.cmml">t</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.2.2.2.1a" xref="S2.E3.m1.5.5.1.1.2.2.2.1.cmml">​</mo><mrow id="S2.E3.m1.5.5.1.1.2.2.2.4.2" xref="S2.E3.m1.5.5.1.1.2.2.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.5.5.1.1.2.2.2.4.2.1" xref="S2.E3.m1.5.5.1.1.2.2.2.cmml">(</mo><mi mathsize="90%" id="S2.E3.m1.3.3" xref="S2.E3.m1.3.3.cmml">C</mi><mo maxsize="90%" minsize="90%" id="S2.E3.m1.5.5.1.1.2.2.2.4.2.2" xref="S2.E3.m1.5.5.1.1.2.2.2.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.1" xref="S2.E3.m1.5.5.1.1.2.2.1.cmml">=</mo><mrow id="S2.E3.m1.5.5.1.1.2.2.3" xref="S2.E3.m1.5.5.1.1.2.2.3.cmml"><msup id="S2.E3.m1.5.5.1.1.2.2.3.2" xref="S2.E3.m1.5.5.1.1.2.2.3.2.cmml"><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.3.2.2" xref="S2.E3.m1.5.5.1.1.2.2.3.2.2.cmml">G</mi><mrow id="S2.E3.m1.5.5.1.1.2.2.3.2.3" xref="S2.E3.m1.5.5.1.1.2.2.3.2.3.cmml"><mo mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.3.2.3a" xref="S2.E3.m1.5.5.1.1.2.2.3.2.3.cmml">−</mo><mn mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.3.2.3.2" xref="S2.E3.m1.5.5.1.1.2.2.3.2.3.2.cmml">1</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.2.2.3.1" xref="S2.E3.m1.5.5.1.1.2.2.3.1.cmml">​</mo><msup id="S2.E3.m1.5.5.1.1.2.2.3.3" xref="S2.E3.m1.5.5.1.1.2.2.3.3.cmml"><mrow id="S2.E3.m1.5.5.1.1.2.2.3.3.2.2" xref="S2.E3.m1.4.4.cmml"><mo maxsize="210%" minsize="210%" id="S2.E3.m1.5.5.1.1.2.2.3.3.2.2.1" xref="S2.E3.m1.4.4.cmml">(</mo><mstyle displaystyle="true" id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml"><mfrac id="S2.E3.m1.4.4a" xref="S2.E3.m1.4.4.cmml"><mi mathsize="90%" id="S2.E3.m1.4.4.2" xref="S2.E3.m1.4.4.2.cmml">C</mi><mn mathsize="90%" id="S2.E3.m1.4.4.3" xref="S2.E3.m1.4.4.3.cmml">6</mn></mfrac></mstyle><mo maxsize="210%" minsize="210%" id="S2.E3.m1.5.5.1.1.2.2.3.3.2.2.2" xref="S2.E3.m1.4.4.cmml">)</mo></mrow><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.3.3.3" xref="S2.E3.m1.5.5.1.1.2.2.3.3.3.cmml">b</mi></msup></mrow></mrow></mrow><mo mathsize="90%" id="S2.E3.m1.5.5.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.5b"><apply id="S2.E3.m1.5.5.1.1.3.cmml" xref="S2.E3.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.3a.cmml" xref="S2.E3.m1.5.5.1.1.2.3">formulae-sequence</csymbol><apply id="S2.E3.m1.5.5.1.1.1.1.cmml" xref="S2.E3.m1.5.5.1.1.1.1"><eq id="S2.E3.m1.5.5.1.1.1.1.1.cmml" xref="S2.E3.m1.5.5.1.1.1.1.1"></eq><apply id="S2.E3.m1.5.5.1.1.1.1.2.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2"><times id="S2.E3.m1.5.5.1.1.1.1.2.1.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2.1"></times><apply id="S2.E3.m1.5.5.1.1.1.1.2.2.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.1.1.2.2.1.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2.2">subscript</csymbol><ci id="S2.E3.m1.5.5.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2.2.2">𝑁</ci><apply id="S2.E3.m1.5.5.1.1.1.1.2.2.3.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3"><times id="S2.E3.m1.5.5.1.1.1.1.2.2.3.1.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.1"></times><ci id="S2.E3.m1.5.5.1.1.1.1.2.2.3.2.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.2">𝑜</ci><ci id="S2.E3.m1.5.5.1.1.1.1.2.2.3.3.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.3">𝑝</ci><ci id="S2.E3.m1.5.5.1.1.1.1.2.2.3.4.cmml" xref="S2.E3.m1.5.5.1.1.1.1.2.2.3.4">𝑡</ci></apply></apply><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">𝐶</ci></apply><apply id="S2.E3.m1.5.5.1.1.1.1.3.cmml" xref="S2.E3.m1.5.5.1.1.1.1.3"><times id="S2.E3.m1.5.5.1.1.1.1.3.1.cmml" xref="S2.E3.m1.5.5.1.1.1.1.3.1"></times><ci id="S2.E3.m1.5.5.1.1.1.1.3.2.cmml" xref="S2.E3.m1.5.5.1.1.1.1.3.2">𝐺</ci><apply id="S2.E3.m1.5.5.1.1.1.1.3.3.cmml" xref="S2.E3.m1.5.5.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.5.5.1.1.1.1.3.3">superscript</csymbol><apply id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.5.5.1.1.1.1.3.3.2.2"><divide id="S2.E3.m1.2.2.1.cmml" xref="S2.E3.m1.5.5.1.1.1.1.3.3.2.2"></divide><ci id="S2.E3.m1.2.2.2.cmml" xref="S2.E3.m1.2.2.2">𝐶</ci><cn type="integer" id="S2.E3.m1.2.2.3.cmml" xref="S2.E3.m1.2.2.3">6</cn></apply><ci id="S2.E3.m1.5.5.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.5.5.1.1.1.1.3.3.3">𝑎</ci></apply></apply></apply><apply id="S2.E3.m1.5.5.1.1.2.2.cmml" xref="S2.E3.m1.5.5.1.1.2.2"><eq id="S2.E3.m1.5.5.1.1.2.2.1.cmml" xref="S2.E3.m1.5.5.1.1.2.2.1"></eq><apply id="S2.E3.m1.5.5.1.1.2.2.2.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2"><times id="S2.E3.m1.5.5.1.1.2.2.2.1.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.1"></times><ci id="S2.E3.m1.5.5.1.1.2.2.2.2a.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.2"><mtext mathsize="90%" id="S2.E3.m1.5.5.1.1.2.2.2.2.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.2">&nbsp;</mtext></ci><apply id="S2.E3.m1.5.5.1.1.2.2.2.3.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.2.2.2.3.1.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.3">subscript</csymbol><ci id="S2.E3.m1.5.5.1.1.2.2.2.3.2.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.3.2">𝐷</ci><apply id="S2.E3.m1.5.5.1.1.2.2.2.3.3.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3"><times id="S2.E3.m1.5.5.1.1.2.2.2.3.3.1.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.1"></times><ci id="S2.E3.m1.5.5.1.1.2.2.2.3.3.2.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.2">𝑜</ci><ci id="S2.E3.m1.5.5.1.1.2.2.2.3.3.3.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.3">𝑝</ci><ci id="S2.E3.m1.5.5.1.1.2.2.2.3.3.4.cmml" xref="S2.E3.m1.5.5.1.1.2.2.2.3.3.4">𝑡</ci></apply></apply><ci id="S2.E3.m1.3.3.cmml" xref="S2.E3.m1.3.3">𝐶</ci></apply><apply id="S2.E3.m1.5.5.1.1.2.2.3.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3"><times id="S2.E3.m1.5.5.1.1.2.2.3.1.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.1"></times><apply id="S2.E3.m1.5.5.1.1.2.2.3.2.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.2"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.2.2.3.2.1.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.2">superscript</csymbol><ci id="S2.E3.m1.5.5.1.1.2.2.3.2.2.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.2.2">𝐺</ci><apply id="S2.E3.m1.5.5.1.1.2.2.3.2.3.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.2.3"><minus id="S2.E3.m1.5.5.1.1.2.2.3.2.3.1.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.2.3"></minus><cn type="integer" id="S2.E3.m1.5.5.1.1.2.2.3.2.3.2.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.2.3.2">1</cn></apply></apply><apply id="S2.E3.m1.5.5.1.1.2.2.3.3.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.2.2.3.3.1.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.3">superscript</csymbol><apply id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.3.2.2"><divide id="S2.E3.m1.4.4.1.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.3.2.2"></divide><ci id="S2.E3.m1.4.4.2.cmml" xref="S2.E3.m1.4.4.2">𝐶</ci><cn type="integer" id="S2.E3.m1.4.4.3.cmml" xref="S2.E3.m1.4.4.3">6</cn></apply><ci id="S2.E3.m1.5.5.1.1.2.2.3.3.3.cmml" xref="S2.E3.m1.5.5.1.1.2.2.3.3.3">𝑏</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.5c">\displaystyle N_{opt}(C)=G\bigg{(}\frac{C}{6}\bigg{)}^{a},\text{~{}~{}~{}}D_{opt}(C)=G^{-1}\bigg{(}\frac{C}{6}\bigg{)}^{b},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p8" class="ltx_para ltx_noindent">
<p id="S2.SS1.p8.9" class="ltx_p">where <math id="S2.SS1.p8.1.m1.1" class="ltx_Math" alttext="a=\frac{\alpha}{\alpha+\beta}" display="inline"><semantics id="S2.SS1.p8.1.m1.1a"><mrow id="S2.SS1.p8.1.m1.1.1" xref="S2.SS1.p8.1.m1.1.1.cmml"><mi id="S2.SS1.p8.1.m1.1.1.2" xref="S2.SS1.p8.1.m1.1.1.2.cmml">a</mi><mo id="S2.SS1.p8.1.m1.1.1.1" xref="S2.SS1.p8.1.m1.1.1.1.cmml">=</mo><mfrac id="S2.SS1.p8.1.m1.1.1.3" xref="S2.SS1.p8.1.m1.1.1.3.cmml"><mi id="S2.SS1.p8.1.m1.1.1.3.2" xref="S2.SS1.p8.1.m1.1.1.3.2.cmml">α</mi><mrow id="S2.SS1.p8.1.m1.1.1.3.3" xref="S2.SS1.p8.1.m1.1.1.3.3.cmml"><mi id="S2.SS1.p8.1.m1.1.1.3.3.2" xref="S2.SS1.p8.1.m1.1.1.3.3.2.cmml">α</mi><mo id="S2.SS1.p8.1.m1.1.1.3.3.1" xref="S2.SS1.p8.1.m1.1.1.3.3.1.cmml">+</mo><mi id="S2.SS1.p8.1.m1.1.1.3.3.3" xref="S2.SS1.p8.1.m1.1.1.3.3.3.cmml">β</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.1.m1.1b"><apply id="S2.SS1.p8.1.m1.1.1.cmml" xref="S2.SS1.p8.1.m1.1.1"><eq id="S2.SS1.p8.1.m1.1.1.1.cmml" xref="S2.SS1.p8.1.m1.1.1.1"></eq><ci id="S2.SS1.p8.1.m1.1.1.2.cmml" xref="S2.SS1.p8.1.m1.1.1.2">𝑎</ci><apply id="S2.SS1.p8.1.m1.1.1.3.cmml" xref="S2.SS1.p8.1.m1.1.1.3"><divide id="S2.SS1.p8.1.m1.1.1.3.1.cmml" xref="S2.SS1.p8.1.m1.1.1.3"></divide><ci id="S2.SS1.p8.1.m1.1.1.3.2.cmml" xref="S2.SS1.p8.1.m1.1.1.3.2">𝛼</ci><apply id="S2.SS1.p8.1.m1.1.1.3.3.cmml" xref="S2.SS1.p8.1.m1.1.1.3.3"><plus id="S2.SS1.p8.1.m1.1.1.3.3.1.cmml" xref="S2.SS1.p8.1.m1.1.1.3.3.1"></plus><ci id="S2.SS1.p8.1.m1.1.1.3.3.2.cmml" xref="S2.SS1.p8.1.m1.1.1.3.3.2">𝛼</ci><ci id="S2.SS1.p8.1.m1.1.1.3.3.3.cmml" xref="S2.SS1.p8.1.m1.1.1.3.3.3">𝛽</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.1.m1.1c">a=\frac{\alpha}{\alpha+\beta}</annotation></semantics></math>, <math id="S2.SS1.p8.2.m2.1" class="ltx_Math" alttext="b=\frac{\beta}{\alpha+\beta}" display="inline"><semantics id="S2.SS1.p8.2.m2.1a"><mrow id="S2.SS1.p8.2.m2.1.1" xref="S2.SS1.p8.2.m2.1.1.cmml"><mi id="S2.SS1.p8.2.m2.1.1.2" xref="S2.SS1.p8.2.m2.1.1.2.cmml">b</mi><mo id="S2.SS1.p8.2.m2.1.1.1" xref="S2.SS1.p8.2.m2.1.1.1.cmml">=</mo><mfrac id="S2.SS1.p8.2.m2.1.1.3" xref="S2.SS1.p8.2.m2.1.1.3.cmml"><mi id="S2.SS1.p8.2.m2.1.1.3.2" xref="S2.SS1.p8.2.m2.1.1.3.2.cmml">β</mi><mrow id="S2.SS1.p8.2.m2.1.1.3.3" xref="S2.SS1.p8.2.m2.1.1.3.3.cmml"><mi id="S2.SS1.p8.2.m2.1.1.3.3.2" xref="S2.SS1.p8.2.m2.1.1.3.3.2.cmml">α</mi><mo id="S2.SS1.p8.2.m2.1.1.3.3.1" xref="S2.SS1.p8.2.m2.1.1.3.3.1.cmml">+</mo><mi id="S2.SS1.p8.2.m2.1.1.3.3.3" xref="S2.SS1.p8.2.m2.1.1.3.3.3.cmml">β</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.2.m2.1b"><apply id="S2.SS1.p8.2.m2.1.1.cmml" xref="S2.SS1.p8.2.m2.1.1"><eq id="S2.SS1.p8.2.m2.1.1.1.cmml" xref="S2.SS1.p8.2.m2.1.1.1"></eq><ci id="S2.SS1.p8.2.m2.1.1.2.cmml" xref="S2.SS1.p8.2.m2.1.1.2">𝑏</ci><apply id="S2.SS1.p8.2.m2.1.1.3.cmml" xref="S2.SS1.p8.2.m2.1.1.3"><divide id="S2.SS1.p8.2.m2.1.1.3.1.cmml" xref="S2.SS1.p8.2.m2.1.1.3"></divide><ci id="S2.SS1.p8.2.m2.1.1.3.2.cmml" xref="S2.SS1.p8.2.m2.1.1.3.2">𝛽</ci><apply id="S2.SS1.p8.2.m2.1.1.3.3.cmml" xref="S2.SS1.p8.2.m2.1.1.3.3"><plus id="S2.SS1.p8.2.m2.1.1.3.3.1.cmml" xref="S2.SS1.p8.2.m2.1.1.3.3.1"></plus><ci id="S2.SS1.p8.2.m2.1.1.3.3.2.cmml" xref="S2.SS1.p8.2.m2.1.1.3.3.2">𝛼</ci><ci id="S2.SS1.p8.2.m2.1.1.3.3.3.cmml" xref="S2.SS1.p8.2.m2.1.1.3.3.3">𝛽</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.2.m2.1c">b=\frac{\beta}{\alpha+\beta}</annotation></semantics></math> and <math id="S2.SS1.p8.3.m3.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.SS1.p8.3.m3.1a"><mi id="S2.SS1.p8.3.m3.1.1" xref="S2.SS1.p8.3.m3.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.3.m3.1b"><ci id="S2.SS1.p8.3.m3.1.1.cmml" xref="S2.SS1.p8.3.m3.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.3.m3.1c">G</annotation></semantics></math> is a scaling coefficient that can be computed by <math id="S2.SS1.p8.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.SS1.p8.4.m4.1a"><mi id="S2.SS1.p8.4.m4.1.1" xref="S2.SS1.p8.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.4.m4.1b"><ci id="S2.SS1.p8.4.m4.1.1.cmml" xref="S2.SS1.p8.4.m4.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.4.m4.1c">A</annotation></semantics></math>, <math id="S2.SS1.p8.5.m5.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S2.SS1.p8.5.m5.1a"><mi id="S2.SS1.p8.5.m5.1.1" xref="S2.SS1.p8.5.m5.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.5.m5.1b"><ci id="S2.SS1.p8.5.m5.1.1.cmml" xref="S2.SS1.p8.5.m5.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.5.m5.1c">B</annotation></semantics></math>, <math id="S2.SS1.p8.6.m6.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS1.p8.6.m6.1a"><mi id="S2.SS1.p8.6.m6.1.1" xref="S2.SS1.p8.6.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.6.m6.1b"><ci id="S2.SS1.p8.6.m6.1.1.cmml" xref="S2.SS1.p8.6.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.6.m6.1c">\alpha</annotation></semantics></math> and <math id="S2.SS1.p8.7.m7.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S2.SS1.p8.7.m7.1a"><mi id="S2.SS1.p8.7.m7.1.1" xref="S2.SS1.p8.7.m7.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.7.m7.1b"><ci id="S2.SS1.p8.7.m7.1.1.cmml" xref="S2.SS1.p8.7.m7.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.7.m7.1c">\beta</annotation></semantics></math>. As analyzed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, given an increase in compute budget, the KM scaling law favors a larger budget allocation in model size than the data size, while the Chinchilla scaling law argues that the two sizes should be increased in equal scales, <em id="S2.SS1.p8.9.1" class="ltx_emph ltx_font_italic">i.e.,</em> having similar values for <math id="S2.SS1.p8.8.m8.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S2.SS1.p8.8.m8.1a"><mi id="S2.SS1.p8.8.m8.1.1" xref="S2.SS1.p8.8.m8.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.8.m8.1b"><ci id="S2.SS1.p8.8.m8.1.1.cmml" xref="S2.SS1.p8.8.m8.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.8.m8.1c">a</annotation></semantics></math> and <math id="S2.SS1.p8.9.m9.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S2.SS1.p8.9.m9.1a"><mi id="S2.SS1.p8.9.m9.1.1" xref="S2.SS1.p8.9.m9.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.9.m9.1b"><ci id="S2.SS1.p8.9.m9.1.1.cmml" xref="S2.SS1.p8.9.m9.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.9.m9.1c">b</annotation></semantics></math> in Equation&nbsp;(<a href="#S2.E3" title="In 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div id="S2.SS1.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.p9.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p9.1.1">Discussion on Scaling Laws</span>. 수식을 도입한 후, 우리는 스케일링 법칙에 대한 이해를 높이기 위해 다음 두 가지 측면에서 스케일링 법칙에 대해 계속 논의한다.</p>
</div>
<div id="S2.SS1.p10" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p10.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p10.1.m1.1"><semantics id="S2.SS1.p10.1.m1.1a"><mo id="S2.SS1.p10.1.m1.1.1" xref="S2.SS1.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p10.1.m1.1b"><ci id="S2.SS1.p10.1.m1.1.1.cmml" xref="S2.SS1.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p10.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p10.1.1">Predictable scaling</em>. 실제로, 스케일링 법칙은 LLM의 트레이닝을 지시하기 위해 사용될 수 있으며, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p10.1.2">predictable scaling</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>라고 불리는 더 작은 모델의 성능을 기반으로 더 큰 모델의 성능을 안정적으로 추정하는 것이 실현 가능한 것으로 입증되었다. LLM 훈련을 위한 예측 가능한 스케일링의 이점은 주로 두 가지이다. 첫째, 대형 모델의 경우 다양한 훈련 트릭이나 변형을 엄격하게 조사하는 것이 불가능하며, 소형 모델에서 얻은 경험이 대형 모델에도 적용될 수 있다면 매우 도움이 될 것이다. 예를 들어, 작은 프록시 모델은 큰 모델<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite>에 대한 데이터 혼합물의 최적 스케줄을 찾도록 훈련될 수 있다. 둘째, 대규모 모델의 훈련은 훈련 손실 스파이크와 같은 문제로 인해 시간이 오래 걸리고 스케일링 법칙을 사용하여 LLM의 훈련 상태를 모니터링할 수 있으며, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p10.1.3">e.g.,</em> 조기에 비정상 성능을 식별한다. 스케일링 법칙이 성능 증가(또는 손실 감소)의 부드러운 경향을 특성화함에도 불구하고, 또한 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p10.1.4">diminishing returns</em><span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://en.wikipedia.org/wiki/Diminishing_returns</span></span></span>이 모델 스케일링으로 발생할 수 있음을 나타낸다. OpenAI 팀의 경험적 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib58" title="">58</a>]</cite>는 수익 감소 지점에 접근하더라도 표현 품질 또는 의미 콘텐츠가 여전히 효과적으로 개선될 수 있음을 보여주었다 (<em class="ltx_emph ltx_font_italic" id="S2.SS1.p10.1.5">i.e.,</em> approaching the irreducible loss) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib58" title="">58</a>]</cite>. 이 결과는 대규모 모델을 훈련하는 것이 다운스트림 작업의 성능을 향상시키는 데 유망하다는 것을 시사한다. 스케일링 효과를 더 탐구하기 위해 잠재적인 문제는 LLM을 훈련하는 데 사용할 수 있는 데이터의 양이 실제로 제한된다는 것이다. 지속적으로 증가하는 모델 척도로, 공개 텍스트 데이터는 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib60" title="">60</a>]</cite>에 대해 곧 "소진"될 것이다. 따라서 데이터 반복 또는 증대가 데이터 부족을 완화하는데 유용할 수 있는 데이터 제한 체제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib61" title="">61</a>]</cite>에 스케일링 법칙이 어떻게 적용되는지 연구하는 것은 의미가 있을 것이다.</p>
</div>
<div id="S2.SS1.p11" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p11.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p11.1.m1.1"><semantics id="S2.SS1.p11.1.m1.1a"><mo id="S2.SS1.p11.1.m1.1.1" xref="S2.SS1.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p11.1.m1.1b"><ci id="S2.SS1.p11.1.m1.1.1.cmml" xref="S2.SS1.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p11.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p11.1.1">Task-level predictability</em>. 스케일링 법칙에 대한 기존 연구는 대부분 언어 모델링 손실(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p11.1.2">e.g.,</em> per-token cross-entropy loss in nats<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>) 측면에서 수행되지만 실제 작업에서 LLM의 성능에 더 관심이 있다. 따라서, 언어 모델링 손실의 감소가 작업 수행의 개선으로 어떻게 변환되는지가 기본적인 문제이다. 직관적으로, 언어 모델링 손실이 전체 모델 용량의 일반적인 척도로 간주될 수 있기 때문에, 언어 모델링 손실이 더 작은 모델은 다운스트림 태스크에서 더 나은 성능을 산출하는 경향이 있다. GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>는 일부 능력(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p11.1.3">e.g.,</em> 코딩 능력)이 스케일링 법칙을 통해 정확하게 예측될 수 있다고 보고했다. 그럼에도 불구하고 독자들은 언어 모델링 손실의 직접적인 감소가 항상 다운스트림 태스크에 대한 모델 성능의 개선을 나타내는 것은 아니라는 것을 알아야 한다. 특히, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p11.1.4">inverse scaling</em> 현상은 일부 태스크에 대해 발생하며, 여기서 태스크 성능은 언어 모델링 손실이 감소함에 따라 놀랍게도 악화됩니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib62" title="">62</a>]</cite>. 전반적으로, 태스크-레벨 스케일링 법칙은 태스크 관련 정보(태스크 메트릭, 태스크 난이도 등)에 종속적일 수 있기 때문에 탐색하고 특성화하는 것이 더 어렵다. 또한, 일부 용량(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p11.1.5">e.g.,</em> in-context learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>)은 스케일링 법칙에 따라 예측할 수 없으며, 이는 모델 크기가 특정 수준을 초과할 때만 관찰될 수 있다(아래에서 논의되는 바와 같이).</p>
</div>
<div id="S2.SS1.p12" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.p12.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p12.1.1">Emergent Abilities of LLMs</span>. 문헌 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>에서 LLM의 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p12.1.2">emergent abilities</em>은 LLM을 이전 PLM과 구별하는 가장 두드러진 특징 중 하나인 "작은 모델에는 존재하지 않지만 큰 모델에서 발생하는 능력"으로 형식적으로 정의된다. 또한 창발 능력이 발생할 때 주목할 만한 특성을 도입한다.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>: 척도가 일정 수준에 도달하면 성능이 무작위보다 크게 상승한다. 비유하자면, 이러한 출현 패턴은 물리학 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>, <a class="ltx_ref" href="#bib.bib63" title="">63</a>]</cite>에서 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p12.1.3">phase transition</em>의 현상과 밀접한 관련이 있다. 창발적 능력은 어떤 복잡한 과제<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>, <a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>와 관련하여 정의될 수 있는 것이 원칙이며, 우리는 다양한 과제를 해결하는 데 적용될 수 있는 일반적인 능력에 더 관심이 있다. 여기서는 LLM에 대한 세 가지 전형적인 출현 능력과 그러한 능력<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>It is difficult to accurately examine the critical size for emergent abilities of LLMs (<em class="ltx_emph ltx_font_italic" id="footnote8.1">i.e.,</em> the minimum size to possess an ability), since it might vary for different models or tasks. Also, existing studies often test emergent abilities on very limited model sizes for a specific LLM. For example, PaLM is often tested with three sizes of 8B, 62B and 540B. It is unclear about the model performance of the untested sizes.</span></span></span>을 가진 대표적인 모델을 간략하게 소개한다.</p>
</div>
<div id="S2.SS1.p13" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p13.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p13.1.m1.1"><semantics id="S2.SS1.p13.1.m1.1a"><mo id="S2.SS1.p13.1.m1.1.1" xref="S2.SS1.p13.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p13.1.m1.1b"><ci id="S2.SS1.p13.1.m1.1.1.cmml" xref="S2.SS1.p13.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p13.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p13.1.1">In-context learning. </em> in-context learning (ICL) 능력은 GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>에 의해 공식적으로 도입된다: 언어 모델이 자연어 명령 및/또는 여러 태스크 데모를 제공받았다고 가정하면, 추가 훈련 또는 그래디언트 업데이트<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>In a recent study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib65" title="">65</a>]</cite>, it also shows that in-context learning implicitly performs meta-optimization through the attention mechanism.</span></span></span>을 요구하지 않고, 입력 텍스트의 단어 시퀀스를 완료함으로써 테스트 인스턴스에 대한 예상 출력을 생성할 수 있다. GPT 시리즈 모델 중 175B GPT-3 모델은 일반적으로 강력한 ICL 능력을 나타냈지만 GPT-1 및 GPT-2 모델은 그렇지 않았다. 이러한 능력은 또한 특정 다운스트림 작업에 달려 있다. 예를 들어 ICL 능력은 13B GPT-3에 대한 산술 작업(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p13.1.2">e.g.,</em> the 3-digit 가감산)에서 나타날 수 있지만 175B GPT-3는 페르시안 QA 작업에서도 잘 작동할 수 없다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>.</p>
</div>
<div id="S2.SS1.p14" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p14.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p14.1.m1.1"><semantics id="S2.SS1.p14.1.m1.1a"><mo id="S2.SS1.p14.1.m1.1.1" xref="S2.SS1.p14.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p14.1.m1.1b"><ci id="S2.SS1.p14.1.m1.1.1.cmml" xref="S2.SS1.p14.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p14.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p14.1.1">Instruction following. </em> 자연어 설명을 통해 포맷된 다중 작업 데이터 세트의 혼합물로 미세 조정함으로써(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p14.1.2">instruction tuning</em>이라고 함), LLMs는 명령 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib67" title="">67</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>의 형태로도 기술되는 보이지 않는 작업에 대해 잘 수행하는 것으로 보여진다. 명령어 튜닝을 통해, LLM들은 명시적인 예들을 사용하지 않고 새로운 태스크들에 대한 태스크 명령들을 따르도록 인에이블되고, 따라서 향상된 일반화 능력을 갖는다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>의 실험에 따르면, 명령어 조정 LaMDA-PT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite>는 모델 크기가 68B에 도달했을 때 보이지 않는 태스크에서 조정되지 않은 태스크를 크게 능가하기 시작했지만 8B 이하의 모델 크기에서는 그렇지 않았다. 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>는 PaLM이 4개의 평가 벤치마크(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p14.1.3">i.e.,</em> MMLU, BBH, TyDiQA 및 MGSM)에서 다양한 작업에 대해 잘 수행하려면 62B의 모델 크기가 적어도 필요하다는 것을 발견했지만, 훨씬 작은 크기는 일부 특정 작업에 충분할 수 있다(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p14.1.4">e.g.,</em> MMLU).</p>
</div>
<div id="S2.SS1.p15" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p15.3"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p15.1.m1.1"><semantics id="S2.SS1.p15.1.m1.1a"><mo id="S2.SS1.p15.1.m1.1.1" xref="S2.SS1.p15.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p15.1.m1.1b"><ci id="S2.SS1.p15.1.m1.1.1.cmml" xref="S2.SS1.p15.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p15.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p15.3.1">Step-by-step reasoning. </em> 작은 언어 모델의 경우 일반적으로 여러 추론 단계를 포함하는 복잡한 작업, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p15.3.2">e.g.,</em> 수학적 단어 문제를 해결하는 것이 어렵다. 이와는 대조적으로, CoT 프롬프트 전략<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>에서 LLMs은 최종 답변을 도출하기 위한 중간 추론 단계를 수반하는 프롬프트 메커니즘을 활용하여 이러한 작업을 해결할 수 있다. 이 능력은 코드 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib47" title="">47</a>, <a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>에 대한 훈련에 의해 잠재적으로 획득될 것으로 추측된다. 실증 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>는 CoT 프롬프트가 모델 크기가 60B보다 큰 PaLM 및 LaMDA 변형에 적용될 때 성능 향상(산술 추론 벤치마크에서)을 가져올 수 있는 반면, 표준 프롬프트에 대한 이점은 모델 크기가 100B를 초과할 때 더 분명해진다. 또한, CoT 프롬핑에 의한 성능 향상은 다른 태스크들, 즉 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p15.3.3">e.g.,</em> GSM8K <math alttext="&gt;" class="ltx_Math" display="inline" id="S2.SS1.p15.2.m2.1"><semantics id="S2.SS1.p15.2.m2.1a"><mo id="S2.SS1.p15.2.m2.1.1" xref="S2.SS1.p15.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p15.2.m2.1b"><gt id="S2.SS1.p15.2.m2.1.1.cmml" xref="S2.SS1.p15.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p15.2.m2.1c">&gt;</annotation></semantics></math> MAWPS <math alttext="&gt;" class="ltx_Math" display="inline" id="S2.SS1.p15.3.m3.1"><semantics id="S2.SS1.p15.3.m3.1a"><mo id="S2.SS1.p15.3.m3.1.1" xref="S2.SS1.p15.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p15.3.m3.1b"><gt id="S2.SS1.p15.3.m3.1.1.cmml" xref="S2.SS1.p15.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p15.3.m3.1c">&gt;</annotation></semantics></math> SWAMP for PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>에 대해서도 달라지는 것으로 보인다.</p>
</div>
<div id="S2.SS1.p16" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.p16.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p16.1.1">How Emergent Abilities Relate to Scaling Laws</span>. 기존 문헌 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>, <a class="ltx_ref" href="#bib.bib34" title="">34</a>, <a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>에서 스케일링 법칙과 창발 능력은 소형 모델보다 대형 모델의 장점을 이해하는 두 가지 관점을 제공한다. 일반적으로 스케일링 법칙(종종 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p16.1.2">언어 모델링 손실</em>으로 측정됨)은 수익 체감의 잠재적 효과와 예측 가능한 성능 관계를 설명하는 반면, 창발 능력(종종 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p16.1.3">작업 성능</em>으로 측정됨)은 예측할 수 없지만 그러한 능력이 실제로 나타나면 매우 수익성이 높다. 두 관점은 서로 다른 성능 경향(연속 개선 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p16.1.4">v.s.</em> 급격한 성능 도약)을 반영하기 때문에 잘못된 결과 또는 관찰로 이어질 수 있습니다. 창발적 능력의 합리성에 대한 광범위한 논쟁도 있다. 대중적인 추측은 창발 능력이 특수 작업에 대한 평가 설정에 부분적으로 기인할 수 있다는 것이다(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p16.1.5">e.g.,</em> the discontinuous evaluation metrics)(<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib70" title="">70</a>, <a class="ltx_ref" href="#bib.bib71" title="">71</a>]</cite>: 평가 메트릭이 그에 따라 변경되면 창발 능력 곡선의 선명도가 사라질 것이다). 그러나 대부분의 태스크에서 LLM의 성능은 사용자가 불연속적인 방식으로 자연스럽게 인지한다. 예를 들어, 최종 사용자는 테스트 케이스를 성공적으로 통과할 수 있는 LLM에 의해 생성된 신뢰할 수 있는 코드를 선호하지만, 실패한 두 코드 사이의 오류가 적은 더 나은 코드를 선택하는 데 관심이 적다. 보다 최근에, 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib72" title="">72</a>]</cite>는 태스크 메트릭의 해상도를 확대하여 태스크 성능을 보다 예측할 수 있는 새로운 평가 설정을 제안한다. 이러한 노력에도 불구하고 LLM의 작동 메커니즘에 대한 보다 근본적인 연구(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p16.1.6">e.g.,</em> grokking<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Grokking refers that “a pattern in the data, improving generalization performance from random chance level to perfect generalization”, quoted from the original paper <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib73" title="">73</a>]</cite>.</span></span></span>)는 여전히 특정 능력의 출현을 이해할 필요가 있다. 스케일링 법칙과 창발 능력 사이의 미묘한 관계는 인간<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>This explanation is only for ease of understanding, and there is not direct evidence to connect the two points. </span></span></span>의 능력 획득과 유추하여 설명할 수 있다. 말하기 능력을 예로 들어보자. 아동에게 언어 발달(특히 유아)은 '출현 능력'이 발생하는 다단계 과정으로 간주될 수도 있다. 특히, 언어 능력은 시간 간격 내에서 비교적 안정적일 것이지만, 질적인 변화는 다른 능력 수준으로 진화할 때만 발생한다(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p16.1.7">e.g.,</em> 말하기 간단한 단어에서 말하기 간단한 문장으로). 이러한 학습 과정은 본질적으로 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p16.1.8">smooth</em> 및 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p16.1.9">stable</em>(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p16.1.10">i.e.,</em> 언어 능력은 시간이 지남에 따라 일정한 속도로 발달하지 않지만 실제로 아이가 매일 성장합니다. 어린 부모들이 그들의 아기들이 보여주는 말하기 능력의 예상치 못한 진보에 종종 놀랄 것이라는 것은 흥미롭다.</p>
</div>
<div id="S2.SS1.p17" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.p17.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p17.1.1">Key Techniques for LLMs</span>. LLM이 현재 상태로 진화하는 것은 오랜 시간이었다: <em class="ltx_emph ltx_font_italic" id="S2.SS1.p17.1.2">general</em> 및 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p17.1.3">capable</em> 학습자들. 개발 과정에서 LLM의 용량을 크게 향상시키는 중요한 기법들이 많이 제안되고 있다. 여기서는 (잠재적으로) LLM의 성공으로 이어지는 몇 가지 중요한 기술을 간략하게 나열하면 다음과 같다.</p>
</div>
<div id="S2.SS1.p18" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p18.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p18.1.m1.1"><semantics id="S2.SS1.p18.1.m1.1a"><mo id="S2.SS1.p18.1.m1.1.1" xref="S2.SS1.p18.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p18.1.m1.1b"><ci id="S2.SS1.p18.1.m1.1.1.cmml" xref="S2.SS1.p18.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p18.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p18.1.1">Scaling</em>. 이전 부분에서 논의된 바와 같이, Transformer 언어 모델에는 명백한 스케일링 효과가 존재한다: 더 큰 모델/데이터 크기 및 더 많은 트레이닝 컴퓨트는 일반적으로 개선된 모델 용량 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>, <a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>로 이어진다. 두 가지 대표적인 모델로 GPT-3와 PaLM은 모델 크기를 각각 175B와 540B로 증가시켜 스케일링 한계를 탐구했다. 컴퓨팅 예산은 일반적으로 제한적이기 때문에, 스케일링 법칙들은 컴퓨팅 리소스들의 보다 컴퓨팅-효율적인 할당을 수행하기 위해 추가로 채용될 수 있다. 예를 들어 Chinchilla (더 많은 훈련 토큰을 사용)는 동일한 컴퓨팅 예산 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>]으로 데이터 규모를 증가시킴으로써 상대 모델 Gopher (더 큰 모델 크기를 사용)보다 우수합니다. 또한 사전 훈련 데이터의 품질이 모델 용량에 중요한 역할을 하기 때문에 데이터 크기 조정은 세심한 세척 과정을 거쳐야 한다.</p>
</div>
<div id="S2.SS1.p19" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p19.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p19.1.m1.1"><semantics id="S2.SS1.p19.1.m1.1a"><mo id="S2.SS1.p19.1.m1.1.1" xref="S2.SS1.p19.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p19.1.m1.1b"><ci id="S2.SS1.p19.1.m1.1.1.cmml" xref="S2.SS1.p19.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p19.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p19.1.1">Training</em>. 대형 모델 크기 때문에, 유능한 LLM을 성공적으로 훈련시키는 것은 매우 어렵다. 다양한 병렬 전략들이 종종 공동으로 활용되는 LLM들의 네트워크 파라미터들을 학습하기 위해 분산 트레이닝 알고리즘들이 필요하다. 분산 학습을 지원하기 위해 DeepSpeed<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite> 및 Megatron-LM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>, <a class="ltx_ref" href="#bib.bib76" title="">76</a>, <a class="ltx_ref" href="#bib.bib77" title="">77</a>]</cite>와 같은 병렬 알고리즘의 구현 및 배포를 용이하게 하기 위한 여러 최적화 프레임워크가 출시되었다. 또한 최적화 트릭은 훈련 안정성 및 모델 성능에도 중요하며, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p19.1.2">e.g.,</em> restart to overcome training loss spike <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite> and mixed precision training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>. 보다 최근에 GPT-4<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>는 훨씬 작은 모델로 큰 모델의 성능을 안정적으로 예측하는 특수 인프라 및 최적화 방법을 개발할 것을 제안한다.</p>
</div>
<div id="S2.SS1.p20" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p20.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p20.1.m1.1"><semantics id="S2.SS1.p20.1.m1.1a"><mo id="S2.SS1.p20.1.m1.1.1" xref="S2.SS1.p20.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p20.1.m1.1b"><ci id="S2.SS1.p20.1.m1.1.1.cmml" xref="S2.SS1.p20.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p20.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p20.1.1">Ability eliciting</em>. 대규모 코퍼라에 대해 사전 훈련된 후 LLM은 범용 작업 해결사로서 잠재적인 능력을 부여받는다. 이러한 능력은 LLM이 일부 특정 작업을 수행할 때 명시적으로 표시되지 않을 수 있다. 기술적 접근으로는 그러한 능력을 이끌어내기 위해 적절한 과제 지시나 구체적인 맥락 내 학습 전략을 설계하는 것이 유용하다. 예를 들어, 연쇄적 사고 프롬프트는 중간 추론 단계를 포함함으로써 복잡한 추론 작업을 해결하는 데 유용한 것으로 나타났다. 또한 자연어로 표현된 태스크 설명으로 LLMs에 대한 명령어 튜닝을 수행하여 보이지 않는 태스크에 대한 LLMs의 일반화 가능성을 향상시킬 수 있다. 이러한 유도 기술은 주로 LLM의 출현 능력에 해당하며, 이는 작은 언어 모델에 동일한 효과를 나타내지 않을 수 있다.</p>
</div>
<div id="S2.SS1.p21" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p21.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p21.1.m1.1"><semantics id="S2.SS1.p21.1.m1.1a"><mo id="S2.SS1.p21.1.m1.1.1" xref="S2.SS1.p21.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p21.1.m1.1b"><ci id="S2.SS1.p21.1.m1.1.1.cmml" xref="S2.SS1.p21.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p21.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p21.1.1">Alignment tuning</em>. LLM은 사전 훈련된 말뭉치(고품질 및 저품질 데이터 모두 포함)의 데이터 특성을 캡처하도록 훈련되기 때문에 인간에게 독성, 편향 또는 심지어 유해한 콘텐츠를 생성할 가능성이 있다. LMs를 인간 값과 정렬할 필요가 있습니다. <em class="ltx_emph ltx_font_italic" id="S2.SS1.p21.1.2">e.g.,</em> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p21.1.3">helpful</em>, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p21.1.4">honest</em>, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p21.1.5">harmless</em>. 이를 위해 InstructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>는 LLMs가 예상된 명령을 따를 수 있도록 하는 효과적인 튜닝 접근법을 설계하며, 이는 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p21.1.6">reinforcement learning with human feedback</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>, <a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>의 기술을 활용한다. 그것은 정교하게 설계된 라벨링 전략과 함께 훈련 루프에 인간을 통합한다. ChatGPT는 실제로 고품질 무해한 응답을 생성하는 데 강력한 정렬 능력을 나타내는 InstructGPT와 유사한 기술에서 개발되었으며, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p21.1.7">예:</em> 모욕적인 질문에 답하기 위해 거부한다.</p>
</div>
<div id="S2.SS1.p22" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p22.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.p22.1.m1.1"><semantics id="S2.SS1.p22.1.m1.1a"><mo id="S2.SS1.p22.1.m1.1.1" xref="S2.SS1.p22.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p22.1.m1.1b"><ci id="S2.SS1.p22.1.m1.1.1.cmml" xref="S2.SS1.p22.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p22.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS1.p22.1.1">Tools manipulation</em>. 본질적으로, LLM들은 방대한 평문 말뭉치에 걸쳐 텍스트 생성기들로서 트레이닝되고, 따라서 텍스트의 형태로 가장 잘 표현되지 않는 태스크들에 대해 덜 잘 수행된다(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p22.1.2">e.g.,</em> 수치 계산). 또한, 이들의 용량은 또한 사전 트레이닝 데이터, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p22.1.3">e.g.,</em> 최신 정보를 캡처할 수 없는 것으로 제한된다. 이러한 문제를 해결하기 위해 최근에 제안된 기술은 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>, <a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>의 결함을 보완하기 위해 외부 도구를 사용하는 것이다. 예를 들어, LLMs는 정확한 계산을 위해 계산기 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>를 활용할 수 있고, 미지의 정보를 검색하기 위해 검색 엔진을 채용할 수 있다. 보다 최근에, ChatGPT는 LLM의 "<em class="ltx_emph ltx_font_italic" id="S2.SS1.p22.1.4">eyes and ears</em>"과 유추되는 외부 플러그인(기존 또는 새로 만든 앱) <span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>https://openai.com/blog/chatgpt-plugins</span></span></span>을 사용하는 메커니즘을 가능하게 했다. 이러한 메커니즘은 LLM에 대한 용량 범위를 광범위하게 확장할 수 있다.</p>
</div>
<div id="S2.SS1.p23" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p23.1">또한, 많은 다른 요인들(<em class="ltx_emph ltx_font_italic" id="S2.SS1.p23.1.1">e.g.,</em> the upgrade of hardware)도 LLMs의 성공에 기여한다. 현재, 우리는 논의를 LLM 개발을 위한 주요 기술적 접근법과 주요 발견으로 제한한다.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x4.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="215" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 3:</span>최근 몇 년 동안 기존 대형 언어 모델(10B보다 큰 크기를 가짐)의 타임라인. 타임라인은 모델에 대한 기술 논문의 릴리스 날짜(<em class="ltx_emph ltx_font_italic" id="S2.F3.2.1">e.g.,</em> the submission date to arXiv)에 따라 주로 설정되었다. 해당 논문이 없는 경우 모델의 날짜를 공개 또는 발표의 가장 빠른 시간으로 설정했습니다. LLM에 공개적으로 사용 가능한 모델 체크포인트를 노란색으로 표시합니다. 그림의 공간 한계로 인해 공개적으로 보고된 평가 결과가 있는 LLM만 포함한다.</figcaption>
</figure>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I:</span>용량 평가, 사전 훈련 데이터 규모(토큰 수 또는 스토리지 크기 중 하나) 및 하드웨어 리소스 비용을 포함하여 최근 몇 년 동안 대규모 언어 모델의 통계(이 조사에서 10B보다 큰 크기를 가짐)를 제공합니다. 이 표에서는 기술 세부 사항에 대한 공개 논문이 있는 LLM만 포함합니다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Statistics of large language models (having a size larger than 10B in this survey) in recent years, including the capacity evaluation, pre-training data scale (either in the number of tokens or storage size) and hardware resource costs. In this table, we only include LLMs with a public paper about the technical details.
Here, “Release Time” indicates the date when the corresponding paper was officially released. “Publicly Available” means that the model checkpoints can be publicly accessible while “Closed Source” means the opposite.
“Adaptation” indicates whether the model has been with subsequent fine-tuning: IT denotes instruction tuning and RLHF denotes reinforcement learning with human feedback.
“Evaluation” indicates whether the model has been evaluated with corresponding abilities in their original paper: ICL denotes in-context learning and CoT denotes chain-of-thought. “*” denotes the largest publicly available version.
</figcaption>
<table id="S2.T1.90" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S2.T1.90.91" class="ltx_tr">
<td id="S2.T1.90.91.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.91.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.91.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.91.4" class="ltx_td ltx_nopad_l ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.91.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.91.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;" colspan="2"><span id="S2.T1.90.91.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Adaptation</span></td>
<td id="S2.T1.90.91.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.91.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.91.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.91.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.91.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;" colspan="2"><span id="S2.T1.90.91.11.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Evaluation</span></td>
</tr>
<tr id="S2.T1.90.92" class="ltx_tr">
<td id="S2.T1.90.92.1" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.92.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></td>
<td id="S2.T1.90.92.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.3.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.90.92.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.90.92.3.1.1.1" class="ltx_tr">
<span id="S2.T1.90.92.3.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Release</span></span></span>
<span id="S2.T1.90.92.3.1.1.2" class="ltx_tr">
<span id="S2.T1.90.92.3.1.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.3.1.1.2.1.1" class="ltx_text ltx_font_bold">Time</span></span></span>
</span></span></td>
<td id="S2.T1.90.92.4" class="ltx_td ltx_nopad_l ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.4.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.90.92.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.90.92.4.1.1.1" class="ltx_tr">
<span id="S2.T1.90.92.4.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Size</span></span></span>
<span id="S2.T1.90.92.4.1.1.2" class="ltx_tr">
<span id="S2.T1.90.92.4.1.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.4.1.1.2.1.1" class="ltx_text ltx_font_bold">(B)</span></span></span>
</span></span></td>
<td id="S2.T1.90.92.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.5.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.90.92.5.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.90.92.5.1.1.1" class="ltx_tr">
<span id="S2.T1.90.92.5.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Base</span></span></span>
<span id="S2.T1.90.92.5.1.1.2" class="ltx_tr">
<span id="S2.T1.90.92.5.1.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.5.1.1.2.1.1" class="ltx_text ltx_font_bold">Model</span></span></span>
</span></span></td>
<td id="S2.T1.90.92.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">IT</span></td>
<td id="S2.T1.90.92.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RLHF</span></td>
<td id="S2.T1.90.92.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.8.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.90.92.8.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.90.92.8.1.1.1" class="ltx_tr">
<span id="S2.T1.90.92.8.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.8.1.1.1.1.1" class="ltx_text ltx_font_bold">Pre-train</span></span></span>
<span id="S2.T1.90.92.8.1.1.2" class="ltx_tr">
<span id="S2.T1.90.92.8.1.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.8.1.1.2.1.1" class="ltx_text ltx_font_bold">Data Scale</span></span></span>
</span></span></td>
<td id="S2.T1.90.92.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.9.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.90.92.9.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.90.92.9.1.1.1" class="ltx_tr">
<span id="S2.T1.90.92.9.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.9.1.1.1.1.1" class="ltx_text ltx_font_bold">Latest Data</span></span></span>
<span id="S2.T1.90.92.9.1.1.2" class="ltx_tr">
<span id="S2.T1.90.92.9.1.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.9.1.1.2.1.1" class="ltx_text ltx_font_bold">Timestamp</span></span></span>
</span></span></td>
<td id="S2.T1.90.92.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.10.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.90.92.10.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.90.92.10.1.1.1" class="ltx_tr">
<span id="S2.T1.90.92.10.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.10.1.1.1.1.1" class="ltx_text ltx_font_bold">Hardware</span></span></span>
<span id="S2.T1.90.92.10.1.1.2" class="ltx_tr">
<span id="S2.T1.90.92.10.1.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.10.1.1.2.1.1" class="ltx_text ltx_font_bold">(GPUs / TPUs)</span></span></span>
</span></span></td>
<td id="S2.T1.90.92.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.11.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.90.92.11.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.90.92.11.1.1.1" class="ltx_tr">
<span id="S2.T1.90.92.11.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.11.1.1.1.1.1" class="ltx_text ltx_font_bold">Training</span></span></span>
<span id="S2.T1.90.92.11.1.1.2" class="ltx_tr">
<span id="S2.T1.90.92.11.1.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.11.1.1.2.1.1" class="ltx_text ltx_font_bold">Time</span></span></span>
</span></span></td>
<td id="S2.T1.90.92.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.12.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ICL</span></td>
<td id="S2.T1.90.92.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.92.13.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CoT</span></td>
</tr>
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.1.1.3.1" class="ltx_text" style="font-size:80%;">T5&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.1.1.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib82" title="" class="ltx_ref">82</a><span id="S2.T1.1.1.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.4.1" class="ltx_text" style="font-size:80%;">Oct-2019</span></td>
<td id="S2.T1.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.5.1" class="ltx_text" style="font-size:80%;">11</span></td>
<td id="S2.T1.1.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.1.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.1.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.1.1.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.9.1" class="ltx_text" style="font-size:80%;">1T tokens</span></td>
<td id="S2.T1.1.1.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.10.1" class="ltx_text" style="font-size:80%;">Apr-2019</span></td>
<td id="S2.T1.1.1.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.11.1" class="ltx_text" style="font-size:80%;">1024 TPU v3</span></td>
<td id="S2.T1.1.1.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.1.1.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b"><ci id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.1.1.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.1.1.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.2.2" class="ltx_tr">
<td id="S2.T1.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.2.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.2.2.3.1" class="ltx_text" style="font-size:80%;">mT5&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.2.2.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib83" title="" class="ltx_ref">83</a><span id="S2.T1.2.2.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.2.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.4.1" class="ltx_text" style="font-size:80%;">Oct-2020</span></td>
<td id="S2.T1.2.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.5.1" class="ltx_text" style="font-size:80%;">13</span></td>
<td id="S2.T1.2.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.2.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.2.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.2.2.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.9.1" class="ltx_text" style="font-size:80%;">1T tokens</span></td>
<td id="S2.T1.2.2.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.2.2.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.2.2.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.2.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.2.2.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.2.2.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.2.2.1.m1.1.1" xref="S2.T1.2.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.1.m1.1b"><ci id="S2.T1.2.2.1.m1.1.1.cmml" xref="S2.T1.2.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.2.2.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.2.2.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr">
<td id="S2.T1.4.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.3.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.3.3.1.1" class="ltx_text" style="font-size:80%;">PanGu-</span><math id="S2.T1.3.3.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.T1.3.3.1.m1.1a"><mi mathsize="80%" id="S2.T1.3.3.1.m1.1.1" xref="S2.T1.3.3.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.1.m1.1b"><ci id="S2.T1.3.3.1.m1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.1.m1.1c">\alpha</annotation></semantics></math><span id="S2.T1.3.3.1.2" class="ltx_text" style="font-size:80%;">&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.3.3.1.3.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib84" title="" class="ltx_ref">84</a><span id="S2.T1.3.3.1.4.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.4.1" class="ltx_text" style="font-size:80%;">Apr-2021</span></td>
<td id="S2.T1.4.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.5.1" class="ltx_text" style="font-size:80%;">13*</span></td>
<td id="S2.T1.4.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.4.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.4.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.4.4.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.9.1" class="ltx_text" style="font-size:80%;">1.1TB</span></td>
<td id="S2.T1.4.4.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.4.4.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.11.1" class="ltx_text" style="font-size:80%;">2048 Ascend 910</span></td>
<td id="S2.T1.4.4.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.4.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.4.4.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.4.4.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.4.4.2.m1.1.1" xref="S2.T1.4.4.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.2.m1.1b"><ci id="S2.T1.4.4.2.m1.1.1.cmml" xref="S2.T1.4.4.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.4.4.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.4.4.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.90.93" class="ltx_tr">
<td id="S2.T1.90.93.1" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.93.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.90.93.2.1" class="ltx_text" style="font-size:80%;">CPM-2&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.90.93.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib85" title="" class="ltx_ref">85</a><span id="S2.T1.90.93.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.90.93.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.3.1" class="ltx_text" style="font-size:80%;">Jun-2021</span></td>
<td id="S2.T1.90.93.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.4.1" class="ltx_text" style="font-size:80%;">198</span></td>
<td id="S2.T1.90.93.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.93.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.93.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.93.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.8.1" class="ltx_text" style="font-size:80%;">2.6TB</span></td>
<td id="S2.T1.90.93.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.93.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.93.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.93.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.93.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.93.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.6.6" class="ltx_tr">
<td id="S2.T1.6.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.6.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.6.6.4.1" class="ltx_text" style="font-size:80%;">T0&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.6.6.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S2.T1.6.6.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.6.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.6.6.5.1" class="ltx_text" style="font-size:80%;">Oct-2021</span></td>
<td id="S2.T1.6.6.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.6.6.6.1" class="ltx_text" style="font-size:80%;">11</span></td>
<td id="S2.T1.6.6.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.6.6.7.1" class="ltx_text" style="font-size:80%;">T5</span></td>
<td id="S2.T1.5.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.5.5.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.5.5.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.5.5.1.m1.1.1" xref="S2.T1.5.5.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.1.m1.1b"><ci id="S2.T1.5.5.1.m1.1.1.cmml" xref="S2.T1.5.5.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.6.6.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.6.6.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.6.6.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.6.6.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.6.6.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.6.6.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.6.6.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.6.6.11.1" class="ltx_text" style="font-size:80%;">512 TPU v3</span></td>
<td id="S2.T1.6.6.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.6.6.12.1" class="ltx_text" style="font-size:80%;">27 h</span></td>
<td id="S2.T1.6.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.6.6.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.6.6.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.6.6.2.m1.1.1" xref="S2.T1.6.6.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.2.m1.1b"><ci id="S2.T1.6.6.2.m1.1.1.cmml" xref="S2.T1.6.6.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.6.6.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.6.6.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.7.7" class="ltx_tr">
<td id="S2.T1.7.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.7.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.7.7.3.1" class="ltx_text" style="font-size:80%;">CodeGen&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.7.7.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib86" title="" class="ltx_ref">86</a><span id="S2.T1.7.7.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.7.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.4.1" class="ltx_text" style="font-size:80%;">Mar-2022</span></td>
<td id="S2.T1.7.7.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.5.1" class="ltx_text" style="font-size:80%;">16</span></td>
<td id="S2.T1.7.7.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.7.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.7.7.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.7.7.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.9.1" class="ltx_text" style="font-size:80%;">577B tokens</span></td>
<td id="S2.T1.7.7.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.7.7.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.7.7.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.7.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.7.7.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.7.7.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.7.7.1.m1.1.1" xref="S2.T1.7.7.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.1.m1.1b"><ci id="S2.T1.7.7.1.m1.1.1.cmml" xref="S2.T1.7.7.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.7.7.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.7.7.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.8.8" class="ltx_tr">
<td id="S2.T1.8.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.8.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.8.8.3.1" class="ltx_text" style="font-size:80%;">GPT-NeoX-20B&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.8.8.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib87" title="" class="ltx_ref">87</a><span id="S2.T1.8.8.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.8.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.4.1" class="ltx_text" style="font-size:80%;">Apr-2022</span></td>
<td id="S2.T1.8.8.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.5.1" class="ltx_text" style="font-size:80%;">20</span></td>
<td id="S2.T1.8.8.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.8.8.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.8.8.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.8.8.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.9.1" class="ltx_text" style="font-size:80%;">825GB</span></td>
<td id="S2.T1.8.8.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.8.8.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.11.1" class="ltx_text" style="font-size:80%;">96 40G A100</span></td>
<td id="S2.T1.8.8.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.8.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.8.8.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.8.8.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.8.8.1.m1.1.1" xref="S2.T1.8.8.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.8.8.1.m1.1b"><ci id="S2.T1.8.8.1.m1.1.1.cmml" xref="S2.T1.8.8.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.8.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.8.8.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.8.8.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.10.10" class="ltx_tr">
<td id="S2.T1.10.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.10.10.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.10.10.4.1" class="ltx_text" style="font-size:80%;">Tk-Instruct&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.10.10.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib88" title="" class="ltx_ref">88</a><span id="S2.T1.10.10.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.10.10.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.10.10.5.1" class="ltx_text" style="font-size:80%;">Apr-2022</span></td>
<td id="S2.T1.10.10.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.10.10.6.1" class="ltx_text" style="font-size:80%;">11</span></td>
<td id="S2.T1.10.10.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.10.10.7.1" class="ltx_text" style="font-size:80%;">T5</span></td>
<td id="S2.T1.9.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.9.9.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.9.9.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.9.9.1.m1.1.1" xref="S2.T1.9.9.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.9.9.1.m1.1b"><ci id="S2.T1.9.9.1.m1.1.1.cmml" xref="S2.T1.9.9.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.9.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.10.10.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.10.10.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.10.10.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.10.10.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.10.10.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.10.10.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.10.10.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.10.10.11.1" class="ltx_text" style="font-size:80%;">256 TPU v3</span></td>
<td id="S2.T1.10.10.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.10.10.12.1" class="ltx_text" style="font-size:80%;">4 h</span></td>
<td id="S2.T1.10.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.10.10.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.10.10.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.10.10.2.m1.1.1" xref="S2.T1.10.10.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.10.10.2.m1.1b"><ci id="S2.T1.10.10.2.m1.1.1.cmml" xref="S2.T1.10.10.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.10.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.10.10.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.10.10.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.12.12" class="ltx_tr">
<td id="S2.T1.12.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.12.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.12.12.4.1" class="ltx_text" style="font-size:80%;">UL2&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.12.12.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib89" title="" class="ltx_ref">89</a><span id="S2.T1.12.12.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.12.12.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.12.12.5.1" class="ltx_text" style="font-size:80%;">May-2022</span></td>
<td id="S2.T1.12.12.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.12.12.6.1" class="ltx_text" style="font-size:80%;">20</span></td>
<td id="S2.T1.12.12.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.12.12.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.12.12.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.12.12.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.12.12.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.12.12.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.12.12.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.12.12.10.1" class="ltx_text" style="font-size:80%;">1T tokens</span></td>
<td id="S2.T1.12.12.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.12.12.11.1" class="ltx_text" style="font-size:80%;">Apr-2019</span></td>
<td id="S2.T1.12.12.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.12.12.12.1" class="ltx_text" style="font-size:80%;">512 TPU v4</span></td>
<td id="S2.T1.12.12.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.12.12.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.11.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.11.11.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.11.11.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.11.11.1.m1.1.1" xref="S2.T1.11.11.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.11.11.1.m1.1b"><ci id="S2.T1.11.11.1.m1.1.1.cmml" xref="S2.T1.11.11.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.11.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.12.12.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.12.12.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.12.12.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.12.12.2.m1.1.1" xref="S2.T1.12.12.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.12.12.2.m1.1b"><ci id="S2.T1.12.12.2.m1.1.1.cmml" xref="S2.T1.12.12.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.12.2.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.13.13" class="ltx_tr">
<td id="S2.T1.13.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.13.13.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.13.13.3.1" class="ltx_text" style="font-size:80%;">OPT&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.13.13.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib90" title="" class="ltx_ref">90</a><span id="S2.T1.13.13.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.13.13.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.4.1" class="ltx_text" style="font-size:80%;">May-2022</span></td>
<td id="S2.T1.13.13.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.5.1" class="ltx_text" style="font-size:80%;">175</span></td>
<td id="S2.T1.13.13.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.13.13.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.13.13.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.13.13.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.9.1" class="ltx_text" style="font-size:80%;">180B tokens</span></td>
<td id="S2.T1.13.13.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.13.13.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.11.1" class="ltx_text" style="font-size:80%;">992 80G A100</span></td>
<td id="S2.T1.13.13.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.13.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.13.13.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.13.13.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.13.13.1.m1.1.1" xref="S2.T1.13.13.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.13.13.1.m1.1b"><ci id="S2.T1.13.13.1.m1.1.1.cmml" xref="S2.T1.13.13.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.13.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.13.13.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.13.13.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.14.14" class="ltx_tr">
<td id="S2.T1.14.14.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.14.14.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.14.14.3.1" class="ltx_text" style="font-size:80%;">NLLB&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.14.14.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib91" title="" class="ltx_ref">91</a><span id="S2.T1.14.14.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.14.14.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.4.1" class="ltx_text" style="font-size:80%;">Jul-2022</span></td>
<td id="S2.T1.14.14.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.5.1" class="ltx_text" style="font-size:80%;">54.5</span></td>
<td id="S2.T1.14.14.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.14.14.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.14.14.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.14.14.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.14.14.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.14.14.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.14.14.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.14.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.14.14.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.14.14.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.14.14.1.m1.1.1" xref="S2.T1.14.14.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.14.14.1.m1.1b"><ci id="S2.T1.14.14.1.m1.1.1.cmml" xref="S2.T1.14.14.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.14.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.14.14.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.14.14.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.15.15" class="ltx_tr">
<td id="S2.T1.15.15.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.15.15.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.15.15.3.1" class="ltx_text" style="font-size:80%;">CodeGeeX&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.15.15.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib92" title="" class="ltx_ref">92</a><span id="S2.T1.15.15.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.15.15.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.4.1" class="ltx_text" style="font-size:80%;">Sep-2022</span></td>
<td id="S2.T1.15.15.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.5.1" class="ltx_text" style="font-size:80%;">13</span></td>
<td id="S2.T1.15.15.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.15.15.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.15.15.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.15.15.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.9.1" class="ltx_text" style="font-size:80%;">850B tokens</span></td>
<td id="S2.T1.15.15.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.15.15.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.11.1" class="ltx_text" style="font-size:80%;">1536 Ascend 910</span></td>
<td id="S2.T1.15.15.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.12.1" class="ltx_text" style="font-size:80%;">60 d</span></td>
<td id="S2.T1.15.15.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.15.15.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.15.15.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.15.15.1.m1.1.1" xref="S2.T1.15.15.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.15.15.1.m1.1b"><ci id="S2.T1.15.15.1.m1.1.1.cmml" xref="S2.T1.15.15.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.15.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.15.15.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.15.15.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.16.16" class="ltx_tr">
<td id="S2.T1.16.16.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.16.16.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.16.16.3.1" class="ltx_text" style="font-size:80%;">GLM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.16.16.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib93" title="" class="ltx_ref">93</a><span id="S2.T1.16.16.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.16.16.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.4.1" class="ltx_text" style="font-size:80%;">Oct-2022</span></td>
<td id="S2.T1.16.16.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.5.1" class="ltx_text" style="font-size:80%;">130</span></td>
<td id="S2.T1.16.16.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.16.16.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.16.16.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.16.16.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.9.1" class="ltx_text" style="font-size:80%;">400B tokens</span></td>
<td id="S2.T1.16.16.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.16.16.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.11.1" class="ltx_text" style="font-size:80%;">768 40G A100</span></td>
<td id="S2.T1.16.16.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.12.1" class="ltx_text" style="font-size:80%;">60 d</span></td>
<td id="S2.T1.16.16.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.16.16.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.16.16.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.16.16.1.m1.1.1" xref="S2.T1.16.16.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.16.16.1.m1.1b"><ci id="S2.T1.16.16.1.m1.1.1.cmml" xref="S2.T1.16.16.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.16.16.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.16.16.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.16.16.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.19.19" class="ltx_tr">
<td id="S2.T1.19.19.4" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.19.19.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.19.19.5.1" class="ltx_text" style="font-size:80%;">Flan-T5&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.19.19.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib69" title="" class="ltx_ref">69</a><span id="S2.T1.19.19.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.19.19.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.19.19.6.1" class="ltx_text" style="font-size:80%;">Oct-2022</span></td>
<td id="S2.T1.19.19.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.19.19.7.1" class="ltx_text" style="font-size:80%;">11</span></td>
<td id="S2.T1.19.19.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.19.19.8.1" class="ltx_text" style="font-size:80%;">T5</span></td>
<td id="S2.T1.17.17.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.17.17.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.17.17.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.17.17.1.m1.1.1" xref="S2.T1.17.17.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.17.17.1.m1.1b"><ci id="S2.T1.17.17.1.m1.1.1.cmml" xref="S2.T1.17.17.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.17.17.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.19.19.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.19.19.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.19.19.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.19.19.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.19.19.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.19.19.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.19.19.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.19.19.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.19.19.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.19.19.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.18.18.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.18.18.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.18.18.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.18.18.2.m1.1.1" xref="S2.T1.18.18.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.18.18.2.m1.1b"><ci id="S2.T1.18.18.2.m1.1.1.cmml" xref="S2.T1.18.18.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.18.18.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.19.19.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.19.19.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.19.19.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.19.19.3.m1.1.1" xref="S2.T1.19.19.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.19.19.3.m1.1b"><ci id="S2.T1.19.19.3.m1.1.1.cmml" xref="S2.T1.19.19.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.19.19.3.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.20.20" class="ltx_tr">
<td id="S2.T1.20.20.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.20.20.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.20.20.3.1" class="ltx_text" style="font-size:80%;">BLOOM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.20.20.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib78" title="" class="ltx_ref">78</a><span id="S2.T1.20.20.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.20.20.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.4.1" class="ltx_text" style="font-size:80%;">Nov-2022</span></td>
<td id="S2.T1.20.20.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.5.1" class="ltx_text" style="font-size:80%;">176</span></td>
<td id="S2.T1.20.20.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.20.20.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.20.20.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.20.20.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.9.1" class="ltx_text" style="font-size:80%;">366B tokens</span></td>
<td id="S2.T1.20.20.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.20.20.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.11.1" class="ltx_text" style="font-size:80%;">384 80G A100</span></td>
<td id="S2.T1.20.20.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.12.1" class="ltx_text" style="font-size:80%;">105 d</span></td>
<td id="S2.T1.20.20.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.20.20.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.20.20.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.20.20.1.m1.1.1" xref="S2.T1.20.20.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.20.20.1.m1.1b"><ci id="S2.T1.20.20.1.m1.1.1.cmml" xref="S2.T1.20.20.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.20.20.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.20.20.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.20.20.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.22.22" class="ltx_tr">
<td id="S2.T1.22.22.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.22.22.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.22.22.4.1" class="ltx_text" style="font-size:80%;">mT0&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.22.22.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib94" title="" class="ltx_ref">94</a><span id="S2.T1.22.22.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.22.22.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.22.22.5.1" class="ltx_text" style="font-size:80%;">Nov-2022</span></td>
<td id="S2.T1.22.22.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.22.22.6.1" class="ltx_text" style="font-size:80%;">13</span></td>
<td id="S2.T1.22.22.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.22.22.7.1" class="ltx_text" style="font-size:80%;">mT5</span></td>
<td id="S2.T1.21.21.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.21.21.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.21.21.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.21.21.1.m1.1.1" xref="S2.T1.21.21.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.21.21.1.m1.1b"><ci id="S2.T1.21.21.1.m1.1.1.cmml" xref="S2.T1.21.21.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.21.21.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.22.22.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.22.22.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.22.22.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.22.22.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.22.22.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.22.22.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.22.22.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.22.22.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.22.22.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.22.22.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.22.22.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.22.22.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.22.22.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.22.22.2.m1.1.1" xref="S2.T1.22.22.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.22.22.2.m1.1b"><ci id="S2.T1.22.22.2.m1.1.1.cmml" xref="S2.T1.22.22.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.22.22.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.22.22.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.22.22.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.24.24" class="ltx_tr">
<td id="S2.T1.24.24.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.24.24.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.24.24.4.1" class="ltx_text" style="font-size:80%;">Galactica&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.24.24.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib35" title="" class="ltx_ref">35</a><span id="S2.T1.24.24.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.24.24.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.24.24.5.1" class="ltx_text" style="font-size:80%;">Nov-2022</span></td>
<td id="S2.T1.24.24.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.24.24.6.1" class="ltx_text" style="font-size:80%;">120</span></td>
<td id="S2.T1.24.24.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.24.24.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.24.24.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.24.24.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.24.24.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.24.24.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.24.24.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.24.24.10.1" class="ltx_text" style="font-size:80%;">106B tokens</span></td>
<td id="S2.T1.24.24.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.24.24.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.24.24.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.24.24.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.24.24.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.24.24.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.23.23.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.23.23.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.23.23.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.23.23.1.m1.1.1" xref="S2.T1.23.23.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.23.23.1.m1.1b"><ci id="S2.T1.23.23.1.m1.1.1.cmml" xref="S2.T1.23.23.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.23.23.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.24.24.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.24.24.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.24.24.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.24.24.2.m1.1.1" xref="S2.T1.24.24.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.24.24.2.m1.1b"><ci id="S2.T1.24.24.2.m1.1.1.cmml" xref="S2.T1.24.24.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.24.24.2.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.26.26" class="ltx_tr">
<td id="S2.T1.26.26.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.26.26.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.26.26.4.1" class="ltx_text" style="font-size:80%;">BLOOMZ&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.26.26.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib94" title="" class="ltx_ref">94</a><span id="S2.T1.26.26.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.26.26.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.26.26.5.1" class="ltx_text" style="font-size:80%;">Nov-2022</span></td>
<td id="S2.T1.26.26.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.26.26.6.1" class="ltx_text" style="font-size:80%;">176</span></td>
<td id="S2.T1.26.26.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.26.26.7.1" class="ltx_text" style="font-size:80%;">BLOOM</span></td>
<td id="S2.T1.25.25.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.25.25.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.25.25.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.25.25.1.m1.1.1" xref="S2.T1.25.25.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.25.25.1.m1.1b"><ci id="S2.T1.25.25.1.m1.1.1.cmml" xref="S2.T1.25.25.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.25.25.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.26.26.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.26.26.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.26.26.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.26.26.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.26.26.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.26.26.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.26.26.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.26.26.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.26.26.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.26.26.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.26.26.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.26.26.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.26.26.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.26.26.2.m1.1.1" xref="S2.T1.26.26.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.26.26.2.m1.1b"><ci id="S2.T1.26.26.2.m1.1.1.cmml" xref="S2.T1.26.26.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.26.26.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.26.26.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.26.26.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.29.29" class="ltx_tr">
<td id="S2.T1.29.29.4" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.29.29.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.29.29.5.1" class="ltx_text" style="font-size:80%;">OPT-IML&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.29.29.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib95" title="" class="ltx_ref">95</a><span id="S2.T1.29.29.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.29.29.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.29.29.6.1" class="ltx_text" style="font-size:80%;">Dec-2022</span></td>
<td id="S2.T1.29.29.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.29.29.7.1" class="ltx_text" style="font-size:80%;">175</span></td>
<td id="S2.T1.29.29.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.29.29.8.1" class="ltx_text" style="font-size:80%;">OPT</span></td>
<td id="S2.T1.27.27.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.27.27.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.27.27.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.27.27.1.m1.1.1" xref="S2.T1.27.27.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.27.27.1.m1.1b"><ci id="S2.T1.27.27.1.m1.1.1.cmml" xref="S2.T1.27.27.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.27.27.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.29.29.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.29.29.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.29.29.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.29.29.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.29.29.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.29.29.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.29.29.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.29.29.12.1" class="ltx_text" style="font-size:80%;">128 40G A100</span></td>
<td id="S2.T1.29.29.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.29.29.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.28.28.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.28.28.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.28.28.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.28.28.2.m1.1.1" xref="S2.T1.28.28.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.28.28.2.m1.1b"><ci id="S2.T1.28.28.2.m1.1.1.cmml" xref="S2.T1.28.28.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.28.28.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.29.29.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.29.29.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.29.29.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.29.29.3.m1.1.1" xref="S2.T1.29.29.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.29.29.3.m1.1b"><ci id="S2.T1.29.29.3.m1.1.1.cmml" xref="S2.T1.29.29.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.29.29.3.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.30.30" class="ltx_tr">
<td id="S2.T1.30.30.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.30.30.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.30.30.3.1" class="ltx_text" style="font-size:80%;">LLaMA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.30.30.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib57" title="" class="ltx_ref">57</a><span id="S2.T1.30.30.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.30.30.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.4.1" class="ltx_text" style="font-size:80%;">Feb-2023</span></td>
<td id="S2.T1.30.30.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.5.1" class="ltx_text" style="font-size:80%;">65</span></td>
<td id="S2.T1.30.30.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.30.30.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.30.30.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.30.30.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.9.1" class="ltx_text" style="font-size:80%;">1.4T tokens</span></td>
<td id="S2.T1.30.30.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.30.30.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.11.1" class="ltx_text" style="font-size:80%;">2048 80G A100</span></td>
<td id="S2.T1.30.30.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.12.1" class="ltx_text" style="font-size:80%;">21 d</span></td>
<td id="S2.T1.30.30.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.30.30.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.30.30.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.30.30.1.m1.1.1" xref="S2.T1.30.30.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.30.30.1.m1.1b"><ci id="S2.T1.30.30.1.m1.1.1.cmml" xref="S2.T1.30.30.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.30.30.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.30.30.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.30.30.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.31.31" class="ltx_tr">
<td id="S2.T1.31.31.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.31.31.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.31.31.3.1" class="ltx_text" style="font-size:80%;">Pythia&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.31.31.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib96" title="" class="ltx_ref">96</a><span id="S2.T1.31.31.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.31.31.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.4.1" class="ltx_text" style="font-size:80%;">Apr-2023</span></td>
<td id="S2.T1.31.31.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.5.1" class="ltx_text" style="font-size:80%;">12</span></td>
<td id="S2.T1.31.31.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.31.31.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.31.31.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.31.31.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.9.1" class="ltx_text" style="font-size:80%;">300B tokens</span></td>
<td id="S2.T1.31.31.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.31.31.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.11.1" class="ltx_text" style="font-size:80%;">256 40G A100</span></td>
<td id="S2.T1.31.31.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.31.31.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.31.31.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.31.31.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.31.31.1.m1.1.1" xref="S2.T1.31.31.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.31.31.1.m1.1b"><ci id="S2.T1.31.31.1.m1.1.1.cmml" xref="S2.T1.31.31.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.31.31.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.31.31.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.31.31.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.32.32" class="ltx_tr">
<td id="S2.T1.32.32.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.32.32.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.32.32.3.1" class="ltx_text" style="font-size:80%;">CodeGen2&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.32.32.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib97" title="" class="ltx_ref">97</a><span id="S2.T1.32.32.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.32.32.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.4.1" class="ltx_text" style="font-size:80%;">May-2023</span></td>
<td id="S2.T1.32.32.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.5.1" class="ltx_text" style="font-size:80%;">16</span></td>
<td id="S2.T1.32.32.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.32.32.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.32.32.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.32.32.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.9.1" class="ltx_text" style="font-size:80%;">400B tokens</span></td>
<td id="S2.T1.32.32.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.32.32.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.32.32.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.32.32.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.32.32.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.32.32.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.32.32.1.m1.1.1" xref="S2.T1.32.32.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.32.32.1.m1.1b"><ci id="S2.T1.32.32.1.m1.1.1.cmml" xref="S2.T1.32.32.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.32.32.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.32.32.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.32.32.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.34.34" class="ltx_tr">
<td id="S2.T1.34.34.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.34.34.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.34.34.4.1" class="ltx_text" style="font-size:80%;">StarCoder&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.34.34.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib98" title="" class="ltx_ref">98</a><span id="S2.T1.34.34.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.34.34.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.34.34.5.1" class="ltx_text" style="font-size:80%;">May-2023</span></td>
<td id="S2.T1.34.34.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.34.34.6.1" class="ltx_text" style="font-size:80%;">15.5</span></td>
<td id="S2.T1.34.34.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.34.34.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.34.34.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.34.34.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.34.34.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.34.34.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.34.34.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.34.34.10.1" class="ltx_text" style="font-size:80%;">1T tokens</span></td>
<td id="S2.T1.34.34.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.34.34.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.34.34.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.34.34.12.1" class="ltx_text" style="font-size:80%;">512 40G A100</span></td>
<td id="S2.T1.34.34.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.34.34.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.33.33.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.33.33.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.33.33.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.33.33.1.m1.1.1" xref="S2.T1.33.33.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.33.33.1.m1.1b"><ci id="S2.T1.33.33.1.m1.1.1.cmml" xref="S2.T1.33.33.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.33.33.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.34.34.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.34.34.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.34.34.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.34.34.2.m1.1.1" xref="S2.T1.34.34.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.34.34.2.m1.1b"><ci id="S2.T1.34.34.2.m1.1.1.cmml" xref="S2.T1.34.34.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.34.34.2.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.37.37" class="ltx_tr">
<td id="S2.T1.37.37.4" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.37.37.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.37.37.5.1" class="ltx_text" style="font-size:80%;">LLaMA2&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.37.37.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib99" title="" class="ltx_ref">99</a><span id="S2.T1.37.37.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.37.37.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.37.37.6.1" class="ltx_text" style="font-size:80%;">Jul-2023</span></td>
<td id="S2.T1.37.37.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.37.37.7.1" class="ltx_text" style="font-size:80%;">70</span></td>
<td id="S2.T1.37.37.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.37.37.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.35.35.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.35.35.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.35.35.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.35.35.1.m1.1.1" xref="S2.T1.35.35.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.35.35.1.m1.1b"><ci id="S2.T1.35.35.1.m1.1.1.cmml" xref="S2.T1.35.35.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.35.35.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.36.36.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.36.36.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.36.36.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.36.36.2.m1.1.1" xref="S2.T1.36.36.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.36.36.2.m1.1b"><ci id="S2.T1.36.36.2.m1.1.1.cmml" xref="S2.T1.36.36.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.36.36.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.37.37.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.37.37.9.1" class="ltx_text" style="font-size:80%;">2T tokens</span></td>
<td id="S2.T1.37.37.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.37.37.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.37.37.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.37.37.11.1" class="ltx_text" style="font-size:80%;">2000 80G A100</span></td>
<td id="S2.T1.37.37.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.37.37.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.37.37.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.37.37.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.37.37.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.37.37.3.m1.1.1" xref="S2.T1.37.37.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.37.37.3.m1.1b"><ci id="S2.T1.37.37.3.m1.1.1.cmml" xref="S2.T1.37.37.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.37.37.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.37.37.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.37.37.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.40.40" class="ltx_tr">
<td id="S2.T1.40.40.4" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.40.40.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.40.40.5.1" class="ltx_text" style="font-size:80%;">Baichuan2&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.40.40.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib100" title="" class="ltx_ref">100</a><span id="S2.T1.40.40.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.40.40.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.40.40.6.1" class="ltx_text" style="font-size:80%;">Sep-2023</span></td>
<td id="S2.T1.40.40.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.40.40.7.1" class="ltx_text" style="font-size:80%;">13</span></td>
<td id="S2.T1.40.40.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.40.40.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.38.38.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.38.38.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.38.38.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.38.38.1.m1.1.1" xref="S2.T1.38.38.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.38.38.1.m1.1b"><ci id="S2.T1.38.38.1.m1.1.1.cmml" xref="S2.T1.38.38.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.38.38.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.39.39.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.39.39.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.39.39.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.39.39.2.m1.1.1" xref="S2.T1.39.39.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.39.39.2.m1.1b"><ci id="S2.T1.39.39.2.m1.1.1.cmml" xref="S2.T1.39.39.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.39.39.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.40.40.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.40.40.9.1" class="ltx_text" style="font-size:80%;">2.6T tokens</span></td>
<td id="S2.T1.40.40.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.40.40.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.40.40.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.40.40.11.1" class="ltx_text" style="font-size:80%;">1024 A800</span></td>
<td id="S2.T1.40.40.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.40.40.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.40.40.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.40.40.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.40.40.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.40.40.3.m1.1.1" xref="S2.T1.40.40.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.40.40.3.m1.1b"><ci id="S2.T1.40.40.3.m1.1.1.cmml" xref="S2.T1.40.40.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.40.40.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.40.40.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.40.40.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.43.43" class="ltx_tr">
<td id="S2.T1.43.43.4" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.43.43.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.43.43.5.1" class="ltx_text" style="font-size:80%;">QWEN&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.43.43.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib101" title="" class="ltx_ref">101</a><span id="S2.T1.43.43.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.43.43.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.43.43.6.1" class="ltx_text" style="font-size:80%;">Sep-2023</span></td>
<td id="S2.T1.43.43.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.43.43.7.1" class="ltx_text" style="font-size:80%;">14</span></td>
<td id="S2.T1.43.43.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.43.43.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.41.41.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.41.41.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.41.41.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.41.41.1.m1.1.1" xref="S2.T1.41.41.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.41.41.1.m1.1b"><ci id="S2.T1.41.41.1.m1.1.1.cmml" xref="S2.T1.41.41.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.41.41.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.42.42.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.42.42.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.42.42.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.42.42.2.m1.1.1" xref="S2.T1.42.42.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.42.42.2.m1.1b"><ci id="S2.T1.42.42.2.m1.1.1.cmml" xref="S2.T1.42.42.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.42.42.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.43.43.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.43.43.9.1" class="ltx_text" style="font-size:80%;">3T tokens</span></td>
<td id="S2.T1.43.43.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.43.43.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.43.43.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.43.43.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.43.43.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.43.43.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.43.43.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.43.43.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.43.43.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.43.43.3.m1.1.1" xref="S2.T1.43.43.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.43.43.3.m1.1b"><ci id="S2.T1.43.43.3.m1.1.1.cmml" xref="S2.T1.43.43.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.43.43.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.43.43.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.43.43.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.45.45" class="ltx_tr">
<td id="S2.T1.45.45.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.45.45.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.45.45.4.1" class="ltx_text" style="font-size:80%;">FLM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.45.45.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib102" title="" class="ltx_ref">102</a><span id="S2.T1.45.45.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.45.45.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.45.45.5.1" class="ltx_text" style="font-size:80%;">Sep-2023</span></td>
<td id="S2.T1.45.45.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.45.45.6.1" class="ltx_text" style="font-size:80%;">101</span></td>
<td id="S2.T1.45.45.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.45.45.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.44.44.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.44.44.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.44.44.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.44.44.1.m1.1.1" xref="S2.T1.44.44.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.44.44.1.m1.1b"><ci id="S2.T1.44.44.1.m1.1.1.cmml" xref="S2.T1.44.44.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.44.44.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.45.45.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.45.45.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.45.45.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.45.45.9.1" class="ltx_text" style="font-size:80%;">311B tokens</span></td>
<td id="S2.T1.45.45.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.45.45.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.45.45.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.45.45.11.1" class="ltx_text" style="font-size:80%;">192 A800</span></td>
<td id="S2.T1.45.45.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.45.45.12.1" class="ltx_text" style="font-size:80%;">22 d</span></td>
<td id="S2.T1.45.45.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.45.45.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.45.45.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.45.45.2.m1.1.1" xref="S2.T1.45.45.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.45.45.2.m1.1b"><ci id="S2.T1.45.45.2.m1.1.1.cmml" xref="S2.T1.45.45.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.45.45.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.45.45.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.45.45.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.46.46" class="ltx_tr">
<td id="S2.T1.46.46.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.2.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.46.46.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.46.46.2.1.1.1" class="ltx_tr">
<span id="S2.T1.46.46.2.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">Publicly</span></span>
<span id="S2.T1.46.46.2.1.1.2" class="ltx_tr">
<span id="S2.T1.46.46.2.1.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">Available</span></span>
</span></span></td>
<td id="S2.T1.46.46.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.46.46.3.1" class="ltx_text" style="font-size:80%;">Skywork&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.46.46.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib103" title="" class="ltx_ref">103</a><span id="S2.T1.46.46.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.46.46.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.4.1" class="ltx_text" style="font-size:80%;">Oct-2023</span></td>
<td id="S2.T1.46.46.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.5.1" class="ltx_text" style="font-size:80%;">13</span></td>
<td id="S2.T1.46.46.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.46.46.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.46.46.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.46.46.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.9.1" class="ltx_text" style="font-size:80%;">3.2T tokens</span></td>
<td id="S2.T1.46.46.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.46.46.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.11.1" class="ltx_text" style="font-size:80%;">512 80G A800</span></td>
<td id="S2.T1.46.46.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.46.46.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.46.46.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.46.46.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.46.46.1.m1.1.1" xref="S2.T1.46.46.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.46.46.1.m1.1b"><ci id="S2.T1.46.46.1.m1.1.1.cmml" xref="S2.T1.46.46.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.46.46.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.46.46.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.46.46.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.47.47" class="ltx_tr">
<td id="S2.T1.47.47.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.47.47.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.47.47.3.1" class="ltx_text" style="font-size:80%;">GPT-3&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.47.47.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib55" title="" class="ltx_ref">55</a><span id="S2.T1.47.47.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.47.47.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.4.1" class="ltx_text" style="font-size:80%;">May-2020</span></td>
<td id="S2.T1.47.47.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.5.1" class="ltx_text" style="font-size:80%;">175</span></td>
<td id="S2.T1.47.47.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.47.47.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.47.47.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.47.47.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.9.1" class="ltx_text" style="font-size:80%;">300B tokens</span></td>
<td id="S2.T1.47.47.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.47.47.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.47.47.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.47.47.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.47.47.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.47.47.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.47.47.1.m1.1.1" xref="S2.T1.47.47.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.47.47.1.m1.1b"><ci id="S2.T1.47.47.1.m1.1.1.cmml" xref="S2.T1.47.47.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.47.47.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.47.47.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.47.47.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.90.94" class="ltx_tr">
<td id="S2.T1.90.94.1" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.94.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.90.94.2.1" class="ltx_text" style="font-size:80%;">GShard&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.90.94.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib104" title="" class="ltx_ref">104</a><span id="S2.T1.90.94.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.90.94.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.3.1" class="ltx_text" style="font-size:80%;">Jun-2020</span></td>
<td id="S2.T1.90.94.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.4.1" class="ltx_text" style="font-size:80%;">600</span></td>
<td id="S2.T1.90.94.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.94.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.94.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.94.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.8.1" class="ltx_text" style="font-size:80%;">1T tokens</span></td>
<td id="S2.T1.90.94.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.94.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.10.1" class="ltx_text" style="font-size:80%;">2048 TPU v3</span></td>
<td id="S2.T1.90.94.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.11.1" class="ltx_text" style="font-size:80%;">4 d</span></td>
<td id="S2.T1.90.94.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.94.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.94.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.48.48" class="ltx_tr">
<td id="S2.T1.48.48.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.48.48.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.48.48.3.1" class="ltx_text" style="font-size:80%;">Codex&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.48.48.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib105" title="" class="ltx_ref">105</a><span id="S2.T1.48.48.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.48.48.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.4.1" class="ltx_text" style="font-size:80%;">Jul-2021</span></td>
<td id="S2.T1.48.48.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.5.1" class="ltx_text" style="font-size:80%;">12</span></td>
<td id="S2.T1.48.48.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.6.1" class="ltx_text" style="font-size:80%;">GPT-3</span></td>
<td id="S2.T1.48.48.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.48.48.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.48.48.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.9.1" class="ltx_text" style="font-size:80%;">100B tokens</span></td>
<td id="S2.T1.48.48.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.10.1" class="ltx_text" style="font-size:80%;">May-2020</span></td>
<td id="S2.T1.48.48.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.48.48.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.48.48.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.48.48.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.48.48.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.48.48.1.m1.1.1" xref="S2.T1.48.48.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.48.48.1.m1.1b"><ci id="S2.T1.48.48.1.m1.1.1.cmml" xref="S2.T1.48.48.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.48.48.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.48.48.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.48.48.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.49.49" class="ltx_tr">
<td id="S2.T1.49.49.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.49.49.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.49.49.3.1" class="ltx_text" style="font-size:80%;">ERNIE 3.0&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.49.49.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib106" title="" class="ltx_ref">106</a><span id="S2.T1.49.49.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.49.49.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.4.1" class="ltx_text" style="font-size:80%;">Jul-2021</span></td>
<td id="S2.T1.49.49.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.5.1" class="ltx_text" style="font-size:80%;">10</span></td>
<td id="S2.T1.49.49.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.49.49.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.49.49.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.49.49.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.9.1" class="ltx_text" style="font-size:80%;">375B tokens</span></td>
<td id="S2.T1.49.49.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.49.49.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.11.1" class="ltx_text" style="font-size:80%;">384 V100</span></td>
<td id="S2.T1.49.49.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.49.49.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.49.49.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.49.49.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.49.49.1.m1.1.1" xref="S2.T1.49.49.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.49.49.1.m1.1b"><ci id="S2.T1.49.49.1.m1.1.1.cmml" xref="S2.T1.49.49.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.49.49.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.49.49.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.49.49.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.50.50" class="ltx_tr">
<td id="S2.T1.50.50.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.50.50.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.50.50.3.1" class="ltx_text" style="font-size:80%;">Jurassic-1&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.50.50.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib107" title="" class="ltx_ref">107</a><span id="S2.T1.50.50.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.50.50.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.4.1" class="ltx_text" style="font-size:80%;">Aug-2021</span></td>
<td id="S2.T1.50.50.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.5.1" class="ltx_text" style="font-size:80%;">178</span></td>
<td id="S2.T1.50.50.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.50.50.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.50.50.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.50.50.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.9.1" class="ltx_text" style="font-size:80%;">300B tokens</span></td>
<td id="S2.T1.50.50.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.50.50.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.11.1" class="ltx_text" style="font-size:80%;">800 GPU</span></td>
<td id="S2.T1.50.50.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.50.50.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.50.50.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.50.50.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.50.50.1.m1.1.1" xref="S2.T1.50.50.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.50.50.1.m1.1b"><ci id="S2.T1.50.50.1.m1.1.1.cmml" xref="S2.T1.50.50.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.50.50.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.50.50.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.50.50.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.51.51" class="ltx_tr">
<td id="S2.T1.51.51.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.51.51.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.51.51.3.1" class="ltx_text" style="font-size:80%;">HyperCLOVA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.51.51.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib108" title="" class="ltx_ref">108</a><span id="S2.T1.51.51.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.51.51.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.4.1" class="ltx_text" style="font-size:80%;">Sep-2021</span></td>
<td id="S2.T1.51.51.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.5.1" class="ltx_text" style="font-size:80%;">82</span></td>
<td id="S2.T1.51.51.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.51.51.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.51.51.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.51.51.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.9.1" class="ltx_text" style="font-size:80%;">300B tokens</span></td>
<td id="S2.T1.51.51.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.51.51.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.11.1" class="ltx_text" style="font-size:80%;">1024 A100</span></td>
<td id="S2.T1.51.51.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.12.1" class="ltx_text" style="font-size:80%;">13.4 d</span></td>
<td id="S2.T1.51.51.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.51.51.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.51.51.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.51.51.1.m1.1.1" xref="S2.T1.51.51.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.51.51.1.m1.1b"><ci id="S2.T1.51.51.1.m1.1.1.cmml" xref="S2.T1.51.51.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.51.51.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.51.51.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.51.51.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.53.53" class="ltx_tr">
<td id="S2.T1.53.53.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.53.53.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.53.53.4.1" class="ltx_text" style="font-size:80%;">FLAN&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.53.53.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib67" title="" class="ltx_ref">67</a><span id="S2.T1.53.53.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.53.53.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.53.53.5.1" class="ltx_text" style="font-size:80%;">Sep-2021</span></td>
<td id="S2.T1.53.53.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.53.53.6.1" class="ltx_text" style="font-size:80%;">137</span></td>
<td id="S2.T1.53.53.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.53.53.7.1" class="ltx_text" style="font-size:80%;">LaMDA-PT</span></td>
<td id="S2.T1.52.52.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.52.52.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.52.52.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.52.52.1.m1.1.1" xref="S2.T1.52.52.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.52.52.1.m1.1b"><ci id="S2.T1.52.52.1.m1.1.1.cmml" xref="S2.T1.52.52.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.52.52.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.53.53.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.53.53.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.53.53.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.53.53.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.53.53.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.53.53.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.53.53.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.53.53.11.1" class="ltx_text" style="font-size:80%;">128 TPU v3</span></td>
<td id="S2.T1.53.53.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.53.53.12.1" class="ltx_text" style="font-size:80%;">60 h</span></td>
<td id="S2.T1.53.53.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.53.53.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.53.53.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.53.53.2.m1.1.1" xref="S2.T1.53.53.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.53.53.2.m1.1b"><ci id="S2.T1.53.53.2.m1.1.1.cmml" xref="S2.T1.53.53.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.53.53.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.53.53.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.53.53.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.54.54" class="ltx_tr">
<td id="S2.T1.54.54.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.54.54.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.54.54.3.1" class="ltx_text" style="font-size:80%;">Yuan 1.0&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.54.54.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib109" title="" class="ltx_ref">109</a><span id="S2.T1.54.54.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.54.54.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.4.1" class="ltx_text" style="font-size:80%;">Oct-2021</span></td>
<td id="S2.T1.54.54.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.5.1" class="ltx_text" style="font-size:80%;">245</span></td>
<td id="S2.T1.54.54.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.54.54.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.54.54.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.54.54.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.9.1" class="ltx_text" style="font-size:80%;">180B tokens</span></td>
<td id="S2.T1.54.54.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.54.54.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.11.1" class="ltx_text" style="font-size:80%;">2128 GPU</span></td>
<td id="S2.T1.54.54.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.54.54.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.54.54.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.54.54.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.54.54.1.m1.1.1" xref="S2.T1.54.54.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.54.54.1.m1.1b"><ci id="S2.T1.54.54.1.m1.1.1.cmml" xref="S2.T1.54.54.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.54.54.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.54.54.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.54.54.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.55.55" class="ltx_tr">
<td id="S2.T1.55.55.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.55.55.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.55.55.3.1" class="ltx_text" style="font-size:80%;">Anthropic&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.55.55.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib110" title="" class="ltx_ref">110</a><span id="S2.T1.55.55.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.55.55.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.4.1" class="ltx_text" style="font-size:80%;">Dec-2021</span></td>
<td id="S2.T1.55.55.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.5.1" class="ltx_text" style="font-size:80%;">52</span></td>
<td id="S2.T1.55.55.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.55.55.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.55.55.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.55.55.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.9.1" class="ltx_text" style="font-size:80%;">400B tokens</span></td>
<td id="S2.T1.55.55.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.55.55.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.55.55.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.55.55.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.55.55.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.55.55.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.55.55.1.m1.1.1" xref="S2.T1.55.55.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.55.55.1.m1.1b"><ci id="S2.T1.55.55.1.m1.1.1.cmml" xref="S2.T1.55.55.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.55.55.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.55.55.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.55.55.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.57.57" class="ltx_tr">
<td id="S2.T1.57.57.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.57.57.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.57.57.4.1" class="ltx_text" style="font-size:80%;">WebGPT&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.57.57.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib81" title="" class="ltx_ref">81</a><span id="S2.T1.57.57.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.57.57.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.57.57.5.1" class="ltx_text" style="font-size:80%;">Dec-2021</span></td>
<td id="S2.T1.57.57.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.57.57.6.1" class="ltx_text" style="font-size:80%;">175</span></td>
<td id="S2.T1.57.57.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.57.57.7.1" class="ltx_text" style="font-size:80%;">GPT-3</span></td>
<td id="S2.T1.57.57.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.57.57.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.56.56.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.56.56.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.56.56.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.56.56.1.m1.1.1" xref="S2.T1.56.56.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.56.56.1.m1.1b"><ci id="S2.T1.56.56.1.m1.1.1.cmml" xref="S2.T1.56.56.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.56.56.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.57.57.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.57.57.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.57.57.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.57.57.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.57.57.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.57.57.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.57.57.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.57.57.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.57.57.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.57.57.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.57.57.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.57.57.2.m1.1.1" xref="S2.T1.57.57.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.57.57.2.m1.1b"><ci id="S2.T1.57.57.2.m1.1.1.cmml" xref="S2.T1.57.57.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.57.57.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.57.57.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.57.57.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.58.58" class="ltx_tr">
<td id="S2.T1.58.58.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.58.58.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.58.58.3.1" class="ltx_text" style="font-size:80%;">Gopher&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.58.58.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S2.T1.58.58.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.58.58.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.4.1" class="ltx_text" style="font-size:80%;">Dec-2021</span></td>
<td id="S2.T1.58.58.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.5.1" class="ltx_text" style="font-size:80%;">280</span></td>
<td id="S2.T1.58.58.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.58.58.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.58.58.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.58.58.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.9.1" class="ltx_text" style="font-size:80%;">300B tokens</span></td>
<td id="S2.T1.58.58.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.58.58.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.11.1" class="ltx_text" style="font-size:80%;">4096 TPU v3</span></td>
<td id="S2.T1.58.58.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.12.1" class="ltx_text" style="font-size:80%;">920 h</span></td>
<td id="S2.T1.58.58.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.58.58.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.58.58.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.58.58.1.m1.1.1" xref="S2.T1.58.58.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.58.58.1.m1.1b"><ci id="S2.T1.58.58.1.m1.1.1.cmml" xref="S2.T1.58.58.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.58.58.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.58.58.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.58.58.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.59.59" class="ltx_tr">
<td id="S2.T1.59.59.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.59.59.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.59.59.3.1" class="ltx_text" style="font-size:80%;">ERNIE 3.0 Titan&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.59.59.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib111" title="" class="ltx_ref">111</a><span id="S2.T1.59.59.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.59.59.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.4.1" class="ltx_text" style="font-size:80%;">Dec-2021</span></td>
<td id="S2.T1.59.59.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.5.1" class="ltx_text" style="font-size:80%;">260</span></td>
<td id="S2.T1.59.59.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.59.59.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.59.59.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.59.59.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.59.59.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.59.59.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.59.59.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.59.59.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.59.59.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.59.59.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.59.59.1.m1.1.1" xref="S2.T1.59.59.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.59.59.1.m1.1b"><ci id="S2.T1.59.59.1.m1.1.1.cmml" xref="S2.T1.59.59.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.59.59.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.59.59.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.59.59.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.60.60" class="ltx_tr">
<td id="S2.T1.60.60.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.60.60.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.60.60.3.1" class="ltx_text" style="font-size:80%;">GLaM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.60.60.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib112" title="" class="ltx_ref">112</a><span id="S2.T1.60.60.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.60.60.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.4.1" class="ltx_text" style="font-size:80%;">Dec-2021</span></td>
<td id="S2.T1.60.60.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.5.1" class="ltx_text" style="font-size:80%;">1200</span></td>
<td id="S2.T1.60.60.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.60.60.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.60.60.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.60.60.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.9.1" class="ltx_text" style="font-size:80%;">280B tokens</span></td>
<td id="S2.T1.60.60.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.60.60.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.11.1" class="ltx_text" style="font-size:80%;">1024 TPU v4</span></td>
<td id="S2.T1.60.60.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.12.1" class="ltx_text" style="font-size:80%;">574 h</span></td>
<td id="S2.T1.60.60.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.60.60.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.60.60.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.60.60.1.m1.1.1" xref="S2.T1.60.60.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.60.60.1.m1.1b"><ci id="S2.T1.60.60.1.m1.1.1.cmml" xref="S2.T1.60.60.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.60.60.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.60.60.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.60.60.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.90.95" class="ltx_tr">
<td id="S2.T1.90.95.1" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.95.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.90.95.2.1" class="ltx_text" style="font-size:80%;">LaMDA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.90.95.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib68" title="" class="ltx_ref">68</a><span id="S2.T1.90.95.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.90.95.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.3.1" class="ltx_text" style="font-size:80%;">Jan-2022</span></td>
<td id="S2.T1.90.95.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.4.1" class="ltx_text" style="font-size:80%;">137</span></td>
<td id="S2.T1.90.95.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.95.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.95.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.95.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.8.1" class="ltx_text" style="font-size:80%;">768B tokens</span></td>
<td id="S2.T1.90.95.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.95.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.10.1" class="ltx_text" style="font-size:80%;">1024 TPU v3</span></td>
<td id="S2.T1.90.95.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.11.1" class="ltx_text" style="font-size:80%;">57.7 d</span></td>
<td id="S2.T1.90.95.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.95.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.95.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.61.61" class="ltx_tr">
<td id="S2.T1.61.61.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.61.61.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.61.61.3.1" class="ltx_text" style="font-size:80%;">MT-NLG&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.61.61.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib113" title="" class="ltx_ref">113</a><span id="S2.T1.61.61.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.61.61.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.4.1" class="ltx_text" style="font-size:80%;">Jan-2022</span></td>
<td id="S2.T1.61.61.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.5.1" class="ltx_text" style="font-size:80%;">530</span></td>
<td id="S2.T1.61.61.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.61.61.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.61.61.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.61.61.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.9.1" class="ltx_text" style="font-size:80%;">270B tokens</span></td>
<td id="S2.T1.61.61.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.61.61.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.11.1" class="ltx_text" style="font-size:80%;">4480 80G A100</span></td>
<td id="S2.T1.61.61.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.61.61.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.61.61.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.61.61.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.61.61.1.m1.1.1" xref="S2.T1.61.61.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.61.61.1.m1.1b"><ci id="S2.T1.61.61.1.m1.1.1.cmml" xref="S2.T1.61.61.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.61.61.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.61.61.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.61.61.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.90.96" class="ltx_tr">
<td id="S2.T1.90.96.1" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.90.96.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.90.96.2.1" class="ltx_text" style="font-size:80%;">AlphaCode&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.90.96.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib114" title="" class="ltx_ref">114</a><span id="S2.T1.90.96.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.90.96.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.3.1" class="ltx_text" style="font-size:80%;">Feb-2022</span></td>
<td id="S2.T1.90.96.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.4.1" class="ltx_text" style="font-size:80%;">41</span></td>
<td id="S2.T1.90.96.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.96.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.96.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.96.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.8.1" class="ltx_text" style="font-size:80%;">967B tokens</span></td>
<td id="S2.T1.90.96.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.9.1" class="ltx_text" style="font-size:80%;">Jul-2021</span></td>
<td id="S2.T1.90.96.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.96.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.96.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.96.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.96.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.64.64" class="ltx_tr">
<td id="S2.T1.64.64.4" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.64.64.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.64.64.5.1" class="ltx_text" style="font-size:80%;">InstructGPT&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.64.64.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib66" title="" class="ltx_ref">66</a><span id="S2.T1.64.64.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.64.64.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.64.64.6.1" class="ltx_text" style="font-size:80%;">Mar-2022</span></td>
<td id="S2.T1.64.64.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.64.64.7.1" class="ltx_text" style="font-size:80%;">175</span></td>
<td id="S2.T1.64.64.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.64.64.8.1" class="ltx_text" style="font-size:80%;">GPT-3</span></td>
<td id="S2.T1.62.62.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.62.62.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.62.62.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.62.62.1.m1.1.1" xref="S2.T1.62.62.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.62.62.1.m1.1b"><ci id="S2.T1.62.62.1.m1.1.1.cmml" xref="S2.T1.62.62.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.62.62.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.63.63.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.63.63.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.63.63.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.63.63.2.m1.1.1" xref="S2.T1.63.63.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.63.63.2.m1.1b"><ci id="S2.T1.63.63.2.m1.1.1.cmml" xref="S2.T1.63.63.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.63.63.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.64.64.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.64.64.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.64.64.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.64.64.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.64.64.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.64.64.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.64.64.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.64.64.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.64.64.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.64.64.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.64.64.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.64.64.3.m1.1.1" xref="S2.T1.64.64.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.64.64.3.m1.1b"><ci id="S2.T1.64.64.3.m1.1.1.cmml" xref="S2.T1.64.64.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.64.64.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.64.64.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.64.64.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.65.65" class="ltx_tr">
<td id="S2.T1.65.65.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.65.65.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.65.65.3.1" class="ltx_text" style="font-size:80%;">Chinchilla&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.65.65.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib34" title="" class="ltx_ref">34</a><span id="S2.T1.65.65.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.65.65.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.4.1" class="ltx_text" style="font-size:80%;">Mar-2022</span></td>
<td id="S2.T1.65.65.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.5.1" class="ltx_text" style="font-size:80%;">70</span></td>
<td id="S2.T1.65.65.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.65.65.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.65.65.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.65.65.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.9.1" class="ltx_text" style="font-size:80%;">1.4T tokens</span></td>
<td id="S2.T1.65.65.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.65.65.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.65.65.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.65.65.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.65.65.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.65.65.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.65.65.1.m1.1.1" xref="S2.T1.65.65.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.65.65.1.m1.1b"><ci id="S2.T1.65.65.1.m1.1.1.cmml" xref="S2.T1.65.65.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.65.65.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.65.65.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.65.65.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.67.67" class="ltx_tr">
<td id="S2.T1.67.67.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.67.67.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.67.67.4.1" class="ltx_text" style="font-size:80%;">PaLM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.67.67.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib56" title="" class="ltx_ref">56</a><span id="S2.T1.67.67.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.67.67.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.67.67.5.1" class="ltx_text" style="font-size:80%;">Apr-2022</span></td>
<td id="S2.T1.67.67.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.67.67.6.1" class="ltx_text" style="font-size:80%;">540</span></td>
<td id="S2.T1.67.67.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.67.67.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.67.67.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.67.67.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.67.67.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.67.67.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.67.67.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.67.67.10.1" class="ltx_text" style="font-size:80%;">780B tokens</span></td>
<td id="S2.T1.67.67.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.67.67.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.67.67.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.67.67.12.1" class="ltx_text" style="font-size:80%;">6144 TPU v4</span></td>
<td id="S2.T1.67.67.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.67.67.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.66.66.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.66.66.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.66.66.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.66.66.1.m1.1.1" xref="S2.T1.66.66.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.66.66.1.m1.1b"><ci id="S2.T1.66.66.1.m1.1.1.cmml" xref="S2.T1.66.66.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.66.66.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.67.67.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.67.67.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.67.67.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.67.67.2.m1.1.1" xref="S2.T1.67.67.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.67.67.2.m1.1b"><ci id="S2.T1.67.67.2.m1.1.1.cmml" xref="S2.T1.67.67.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.67.67.2.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.69.69" class="ltx_tr">
<td id="S2.T1.69.69.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.69.69.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.69.69.4.1" class="ltx_text" style="font-size:80%;">AlexaTM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.69.69.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib115" title="" class="ltx_ref">115</a><span id="S2.T1.69.69.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.69.69.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.69.69.5.1" class="ltx_text" style="font-size:80%;">Aug-2022</span></td>
<td id="S2.T1.69.69.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.69.69.6.1" class="ltx_text" style="font-size:80%;">20</span></td>
<td id="S2.T1.69.69.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.69.69.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.69.69.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.69.69.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.69.69.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.69.69.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.69.69.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.69.69.10.1" class="ltx_text" style="font-size:80%;">1.3T tokens</span></td>
<td id="S2.T1.69.69.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.69.69.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.69.69.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.69.69.12.1" class="ltx_text" style="font-size:80%;">128 A100</span></td>
<td id="S2.T1.69.69.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.69.69.13.1" class="ltx_text" style="font-size:80%;">120 d</span></td>
<td id="S2.T1.68.68.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.68.68.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.68.68.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.68.68.1.m1.1.1" xref="S2.T1.68.68.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.68.68.1.m1.1b"><ci id="S2.T1.68.68.1.m1.1.1.cmml" xref="S2.T1.68.68.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.68.68.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.69.69.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.69.69.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.69.69.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.69.69.2.m1.1.1" xref="S2.T1.69.69.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.69.69.2.m1.1b"><ci id="S2.T1.69.69.2.m1.1.1.cmml" xref="S2.T1.69.69.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.69.69.2.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.71.71" class="ltx_tr">
<td id="S2.T1.71.71.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.71.71.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.71.71.4.1" class="ltx_text" style="font-size:80%;">Sparrow&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.71.71.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib116" title="" class="ltx_ref">116</a><span id="S2.T1.71.71.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.71.71.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.71.71.5.1" class="ltx_text" style="font-size:80%;">Sep-2022</span></td>
<td id="S2.T1.71.71.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.71.71.6.1" class="ltx_text" style="font-size:80%;">70</span></td>
<td id="S2.T1.71.71.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.71.71.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.71.71.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.71.71.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.70.70.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.70.70.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.70.70.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.70.70.1.m1.1.1" xref="S2.T1.70.70.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.70.70.1.m1.1b"><ci id="S2.T1.70.70.1.m1.1.1.cmml" xref="S2.T1.70.70.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.70.70.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.71.71.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.71.71.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.71.71.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.71.71.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.71.71.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.71.71.11.1" class="ltx_text" style="font-size:80%;">64 TPU v3</span></td>
<td id="S2.T1.71.71.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.71.71.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.71.71.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.71.71.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.71.71.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.71.71.2.m1.1.1" xref="S2.T1.71.71.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.71.71.2.m1.1b"><ci id="S2.T1.71.71.2.m1.1.1.cmml" xref="S2.T1.71.71.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.71.71.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.71.71.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.71.71.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.72.72" class="ltx_tr">
<td id="S2.T1.72.72.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.72.72.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.72.72.3.1" class="ltx_text" style="font-size:80%;">WeLM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.72.72.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib117" title="" class="ltx_ref">117</a><span id="S2.T1.72.72.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.72.72.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.4.1" class="ltx_text" style="font-size:80%;">Sep-2022</span></td>
<td id="S2.T1.72.72.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.5.1" class="ltx_text" style="font-size:80%;">10</span></td>
<td id="S2.T1.72.72.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.72.72.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.72.72.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.72.72.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.9.1" class="ltx_text" style="font-size:80%;">300B tokens</span></td>
<td id="S2.T1.72.72.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.72.72.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.11.1" class="ltx_text" style="font-size:80%;">128 A100 40G</span></td>
<td id="S2.T1.72.72.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.12.1" class="ltx_text" style="font-size:80%;">24 d</span></td>
<td id="S2.T1.72.72.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.72.72.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.72.72.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.72.72.1.m1.1.1" xref="S2.T1.72.72.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.72.72.1.m1.1b"><ci id="S2.T1.72.72.1.m1.1.1.cmml" xref="S2.T1.72.72.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.72.72.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.72.72.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.72.72.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.74.74" class="ltx_tr">
<td id="S2.T1.74.74.3" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.74.74.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.74.74.4.1" class="ltx_text" style="font-size:80%;">U-PaLM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.74.74.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib118" title="" class="ltx_ref">118</a><span id="S2.T1.74.74.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.74.74.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.74.74.5.1" class="ltx_text" style="font-size:80%;">Oct-2022</span></td>
<td id="S2.T1.74.74.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.74.74.6.1" class="ltx_text" style="font-size:80%;">540</span></td>
<td id="S2.T1.74.74.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.74.74.7.1" class="ltx_text" style="font-size:80%;">PaLM</span></td>
<td id="S2.T1.74.74.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.74.74.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.74.74.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.74.74.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.74.74.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.74.74.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.74.74.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.74.74.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.74.74.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.74.74.12.1" class="ltx_text" style="font-size:80%;">512 TPU v4</span></td>
<td id="S2.T1.74.74.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.74.74.13.1" class="ltx_text" style="font-size:80%;">5 d</span></td>
<td id="S2.T1.73.73.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.73.73.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.73.73.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.73.73.1.m1.1.1" xref="S2.T1.73.73.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.73.73.1.m1.1b"><ci id="S2.T1.73.73.1.m1.1.1.cmml" xref="S2.T1.73.73.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.73.73.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.74.74.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.74.74.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.74.74.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.74.74.2.m1.1.1" xref="S2.T1.74.74.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.74.74.2.m1.1b"><ci id="S2.T1.74.74.2.m1.1.1.cmml" xref="S2.T1.74.74.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.74.74.2.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.77.77" class="ltx_tr">
<td id="S2.T1.77.77.4" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.77.77.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.77.77.5.1" class="ltx_text" style="font-size:80%;">Flan-PaLM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.77.77.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib69" title="" class="ltx_ref">69</a><span id="S2.T1.77.77.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.77.77.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.77.77.6.1" class="ltx_text" style="font-size:80%;">Oct-2022</span></td>
<td id="S2.T1.77.77.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.77.77.7.1" class="ltx_text" style="font-size:80%;">540</span></td>
<td id="S2.T1.77.77.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.77.77.8.1" class="ltx_text" style="font-size:80%;">PaLM</span></td>
<td id="S2.T1.75.75.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.75.75.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.75.75.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.75.75.1.m1.1.1" xref="S2.T1.75.75.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.75.75.1.m1.1b"><ci id="S2.T1.75.75.1.m1.1.1.cmml" xref="S2.T1.75.75.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.75.75.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.77.77.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.77.77.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.77.77.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.77.77.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.77.77.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.77.77.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.77.77.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.77.77.12.1" class="ltx_text" style="font-size:80%;">512 TPU v4</span></td>
<td id="S2.T1.77.77.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.77.77.13.1" class="ltx_text" style="font-size:80%;">37 h</span></td>
<td id="S2.T1.76.76.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.76.76.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.76.76.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.76.76.2.m1.1.1" xref="S2.T1.76.76.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.76.76.2.m1.1b"><ci id="S2.T1.76.76.2.m1.1.1.cmml" xref="S2.T1.76.76.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.76.76.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.77.77.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.77.77.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.77.77.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.77.77.3.m1.1.1" xref="S2.T1.77.77.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.77.77.3.m1.1b"><ci id="S2.T1.77.77.3.m1.1.1.cmml" xref="S2.T1.77.77.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.77.77.3.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.80.80" class="ltx_tr">
<td id="S2.T1.80.80.4" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.80.80.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.80.80.5.1" class="ltx_text" style="font-size:80%;">Flan-U-PaLM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.80.80.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib69" title="" class="ltx_ref">69</a><span id="S2.T1.80.80.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.80.80.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.80.80.6.1" class="ltx_text" style="font-size:80%;">Oct-2022</span></td>
<td id="S2.T1.80.80.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.80.80.7.1" class="ltx_text" style="font-size:80%;">540</span></td>
<td id="S2.T1.80.80.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.80.80.8.1" class="ltx_text" style="font-size:80%;">U-PaLM</span></td>
<td id="S2.T1.78.78.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.78.78.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.78.78.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.78.78.1.m1.1.1" xref="S2.T1.78.78.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.78.78.1.m1.1b"><ci id="S2.T1.78.78.1.m1.1.1.cmml" xref="S2.T1.78.78.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.78.78.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.80.80.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.80.80.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.80.80.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.80.80.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.80.80.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.80.80.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.80.80.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.80.80.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.80.80.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.80.80.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.79.79.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.79.79.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.79.79.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.79.79.2.m1.1.1" xref="S2.T1.79.79.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.79.79.2.m1.1b"><ci id="S2.T1.79.79.2.m1.1.1.cmml" xref="S2.T1.79.79.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.79.79.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.80.80.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.80.80.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.80.80.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.80.80.3.m1.1.1" xref="S2.T1.80.80.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.80.80.3.m1.1b"><ci id="S2.T1.80.80.3.m1.1.1.cmml" xref="S2.T1.80.80.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.80.80.3.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.84.84" class="ltx_tr">
<td id="S2.T1.84.84.5" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.84.84.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.84.84.6.1" class="ltx_text" style="font-size:80%;">GPT-4&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.84.84.6.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib46" title="" class="ltx_ref">46</a><span id="S2.T1.84.84.6.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.84.84.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.84.84.7.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
<td id="S2.T1.84.84.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.84.84.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.84.84.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.84.84.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.81.81.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.81.81.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.81.81.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.81.81.1.m1.1.1" xref="S2.T1.81.81.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.81.81.1.m1.1b"><ci id="S2.T1.81.81.1.m1.1.1.cmml" xref="S2.T1.81.81.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.81.81.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.82.82.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.82.82.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.82.82.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.82.82.2.m1.1.1" xref="S2.T1.82.82.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.82.82.2.m1.1b"><ci id="S2.T1.82.82.2.m1.1.1.cmml" xref="S2.T1.82.82.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.82.82.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.84.84.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.84.84.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.84.84.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.84.84.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.84.84.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.84.84.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.84.84.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.84.84.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.83.83.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.83.83.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.83.83.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.83.83.3.m1.1.1" xref="S2.T1.83.83.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.83.83.3.m1.1b"><ci id="S2.T1.83.83.3.m1.1.1.cmml" xref="S2.T1.83.83.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.83.83.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.84.84.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.84.84.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.84.84.4.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.84.84.4.m1.1.1" xref="S2.T1.84.84.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.84.84.4.m1.1b"><ci id="S2.T1.84.84.4.m1.1.1.cmml" xref="S2.T1.84.84.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.84.84.4.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.87.87" class="ltx_tr">
<td id="S2.T1.87.87.4" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S2.T1.85.85.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.85.85.1.1" class="ltx_text" style="font-size:80%;">PanGu-</span><math id="S2.T1.85.85.1.m1.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S2.T1.85.85.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.85.85.1.m1.1.1" xref="S2.T1.85.85.1.m1.1.1.cmml">Σ</mi><annotation-xml encoding="MathML-Content" id="S2.T1.85.85.1.m1.1b"><ci id="S2.T1.85.85.1.m1.1.1.cmml" xref="S2.T1.85.85.1.m1.1.1">Σ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.85.85.1.m1.1c">\Sigma</annotation></semantics></math><span id="S2.T1.85.85.1.2" class="ltx_text" style="font-size:80%;">&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.85.85.1.3.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib119" title="" class="ltx_ref">119</a><span id="S2.T1.85.85.1.4.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.87.87.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.87.87.5.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
<td id="S2.T1.87.87.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.87.87.6.1" class="ltx_text" style="font-size:80%;">1085</span></td>
<td id="S2.T1.86.86.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.86.86.2.1" class="ltx_text" style="font-size:80%;">PanGu-</span><math id="S2.T1.86.86.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.T1.86.86.2.m1.1a"><mi mathsize="80%" id="S2.T1.86.86.2.m1.1.1" xref="S2.T1.86.86.2.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.T1.86.86.2.m1.1b"><ci id="S2.T1.86.86.2.m1.1.1.cmml" xref="S2.T1.86.86.2.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.86.86.2.m1.1c">\alpha</annotation></semantics></math>
</td>
<td id="S2.T1.87.87.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.87.87.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.87.87.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.87.87.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.87.87.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.87.87.9.1" class="ltx_text" style="font-size:80%;">329B tokens</span></td>
<td id="S2.T1.87.87.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.87.87.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.87.87.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.87.87.11.1" class="ltx_text" style="font-size:80%;">512 Ascend 910</span></td>
<td id="S2.T1.87.87.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.87.87.12.1" class="ltx_text" style="font-size:80%;">100 d</span></td>
<td id="S2.T1.87.87.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.87.87.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.87.87.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.87.87.3.m1.1.1" xref="S2.T1.87.87.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.87.87.3.m1.1b"><ci id="S2.T1.87.87.3.m1.1.1.cmml" xref="S2.T1.87.87.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.87.87.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.87.87.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.87.87.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S2.T1.90.90" class="ltx_tr">
<td id="S2.T1.90.90.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.90.4.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.90.90.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.90.90.4.1.1.1" class="ltx_tr">
<span id="S2.T1.90.90.4.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">Closed</span></span>
<span id="S2.T1.90.90.4.1.1.2" class="ltx_tr">
<span id="S2.T1.90.90.4.1.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">Source</span></span>
</span></span></td>
<td id="S2.T1.90.90.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S2.T1.90.90.5.1" class="ltx_text" style="font-size:80%;">PaLM2&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.90.90.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib120" title="" class="ltx_ref">120</a><span id="S2.T1.90.90.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S2.T1.90.90.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.90.6.1" class="ltx_text" style="font-size:80%;">May-2023</span></td>
<td id="S2.T1.90.90.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.90.7.1" class="ltx_text" style="font-size:80%;">16</span></td>
<td id="S2.T1.90.90.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.90.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.88.88.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.88.88.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.88.88.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.88.88.1.m1.1.1" xref="S2.T1.88.88.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.88.88.1.m1.1b"><ci id="S2.T1.88.88.1.m1.1.1.cmml" xref="S2.T1.88.88.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.88.88.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.90.90.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.90.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.90.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.90.10.1" class="ltx_text" style="font-size:80%;">100B tokens</span></td>
<td id="S2.T1.90.90.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.90.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.90.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.90.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.90.90.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S2.T1.90.90.13.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S2.T1.89.89.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.89.89.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.89.89.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.89.89.2.m1.1.1" xref="S2.T1.89.89.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.89.89.2.m1.1b"><ci id="S2.T1.89.89.2.m1.1.1.cmml" xref="S2.T1.89.89.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.89.89.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T1.90.90.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><math id="S2.T1.90.90.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T1.90.90.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S2.T1.90.90.3.m1.1.1" xref="S2.T1.90.90.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S2.T1.90.90.3.m1.1b"><ci id="S2.T1.90.90.3.m1.1.1.cmml" xref="S2.T1.90.90.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.90.90.3.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
</tbody></table>
</figure>
<figure id="S2.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x5.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="107" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 4:</span>GPT 시리즈 모델의 기술 진화에 대한 간략한 그림. 우리는 주로 OpenAI의 논문, 블로그 기사 및 공식 API를 기반으로 이 수치를 플로팅한다. 여기서, <em class="ltx_emph ltx_font_italic" id="S2.F4.4.1">실선</em>은 두 모델 사이의 진화 경로 상에 명시적 증거(<em class="ltx_emph ltx_font_italic" id="S2.F4.5.2">e.g.,</em> the official statement that a new model is developed based on base model)가 존재함을 나타내는 반면, <em class="ltx_emph ltx_font_italic" id="S2.F4.6.3">dashed lines</em>은 상대적으로 약한 진화 관계를 나타낸다.</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span><span id="S2.SS2.1.1" class="ltx_text ltx_font_italic">Technical Evolution of GPT-series Models</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p1.1">ChatGPT는 인간과 소통하는 능력이 뛰어나 출시 이후 AI 커뮤니티의 흥분에 불을 붙였다. ChatGPT는 특히 최적화된 대화 용량을 가진 강력한 GPT 모델을 기반으로 개발됩니다. ChatGPT 및 GPT 모델에 대한 계속 증가하는 관심을 고려하여 GPT 시리즈 모델의 기술적 진화에 대한 특별한 논의를 추가하여 지난 몇 년 동안 어떻게 발전했는지 간략하게 요약한다. 한편, 그림 <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>에서 GPT 계열 모델의 기술적 진화를 묘사한 개략도를 그렸다. GPT 모델의 기본 원리는 언어 모델링에 의해 세계 지식을 디코더 전용 트랜스포머 모델로 압축하여 세계 지식의 의미를 복구(또는 암기)하고 범용 태스크 해결자 역할을 할 수 있도록 하는 것이다. 성공의 두 가지 핵심 포인트는 (I) 훈련 디코더 전용 트랜스포머 언어 모델로서 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p1.1.1">정확하게 다음 단어를 예측할 수 있는</em>과 (II) <em class="ltx_emph ltx_font_italic" id="S2.SS2.p1.1.2">언어 모델의 크기를 스케일링 업할 수 있는</em>이다. 전반적으로 LLMs에 대한 OpenAI의 연구는 크게 <span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>Note that the discussion of this part can be somewhat subjective. The overall viewpoints and summaries are made based on the understanding of the survey authors by reading the papers, blog articles, interview reports and APIs released by OpenAI. </span></span></span> 단계로 나눌 수 있다.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">Early Explorations</span>. Ilya Sutskever <span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hackernoon.com/an-interview-with-ilya-sutskever-co-founder-of-openai" target="_blank" title="">https://hackernoon.com/an-interview-with-ilya-sutskever-co-founder-of-openai</a></span></span></span>(OpenAI의 공동 설립자이자 수석 과학자)와의 한 인터뷰에 따르면, 언어 모델로 지능 시스템에 접근하는 아이디어는 OpenAI 초기 이미 탐구된 반면, 순환 신경망(RNN) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>로 시도되었다. Transformer의 등장으로 OpenAI는 두 개의 초기 GPT 모델, 즉 GPT-1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>]</cite>와 GPT-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>를 개발했는데, 이는 후속적으로 더 강력한 모델인 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p2.1.2">i.e.,</em> GPT-3 및 GPT-4의 토대가 될 수 있다.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><mo id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><ci id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS2.p3.1.1">GPT-1</em>. 2017년, 트랜스포머 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>는 구글에 의해 소개되었고, OpenAI 팀은 그들의 언어 모델링 작업을 이 새로운 신경망 아키텍처에 빠르게 적용했다. 그들은 2018년에 첫 번째 GPT 모델인 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p3.1.2">i.e.,</em> GPT-1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>]</cite>를 출시했으며, 모델 이름으로 약어 용어 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p3.1.3">GPT</em>을 만들었으며, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p3.1.4">Generative Pre-Training</em>에 해당한다. GPT-1은 생성형 디코더 전용 트랜스포머 구조를 기반으로 개발되었으며, 비감독 사전 훈련과 감독 미세 조정의 하이브리드 접근법을 채택했다. GPT-1은 GPT 시리즈 모델에 대한 핵심 아키텍처를 설정하고 자연어 텍스트인 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p3.1.5">i.e.,</em> 다음 단어를 예측하는 기본 원칙을 설정했다.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p4.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p4.1.m1.1"><semantics id="S2.SS2.p4.1.m1.1a"><mo id="S2.SS2.p4.1.m1.1.1" xref="S2.SS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.1.m1.1b"><ci id="S2.SS2.p4.1.m1.1.1.cmml" xref="S2.SS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS2.p4.2.1">GPT-2</em>. GPT-1의 유사한 아키텍처에 이어 GPT-2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>는 매개변수 규모를 1.5B로 증가시켰으며, 이는 대규모 웹 페이지 데이터 세트 WebText로 훈련되었다. GPT-2의 논문에서 주장한 바와 같이 라벨링된 데이터를 사용하여 명시적인 미세 조정 없이 비감독 언어 모델링을 통해 작업을 수행하려고 했다. 접근법의 동기를 부여하기 위해, 그들은 다중 태스크 해결을 위한 확률적 형태인 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p4.2.2">i.e.,</em> <math alttext="p(output|input,task)" class="ltx_Math" display="inline" id="S2.SS2.p4.2.m2.1"><semantics id="S2.SS2.p4.2.m2.1a"><mrow id="S2.SS2.p4.2.m2.1.1" xref="S2.SS2.p4.2.m2.1.1.cmml"><mi id="S2.SS2.p4.2.m2.1.1.3" xref="S2.SS2.p4.2.m2.1.1.3.cmml">p</mi><mo id="S2.SS2.p4.2.m2.1.1.2" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.2.cmml">​</mo><mrow id="S2.SS2.p4.2.m2.1.1.1.1" xref="S2.SS2.p4.2.m2.1.1.1.1.1.cmml"><mo id="S2.SS2.p4.2.m2.1.1.1.1.2" stretchy="false" xref="S2.SS2.p4.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p4.2.m2.1.1.1.1.1" xref="S2.SS2.p4.2.m2.1.1.1.1.1.cmml"><mrow id="S2.SS2.p4.2.m2.1.1.1.1.1.4" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.cmml"><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.4.2" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.2.cmml">o</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.4.1" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.4.3" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.3.cmml">u</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.4.1a" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.4.4" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.4.cmml">t</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.4.1b" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.4.5" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.5.cmml">p</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.4.1c" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.4.6" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.6.cmml">u</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.4.1d" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.4.7" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.7.cmml">t</mi></mrow><mo fence="false" id="S2.SS2.p4.2.m2.1.1.1.1.1.3" xref="S2.SS2.p4.2.m2.1.1.1.1.1.3.cmml">|</mo><mrow id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.3.cmml"><mrow id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.2" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.2.cmml">i</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.3" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.3.cmml">n</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1a" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.4" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.4.cmml">p</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1b" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.5" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.5.cmml">u</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1c" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.6" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.6.cmml">t</mi></mrow><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.3" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.3.cmml">,</mo><mrow id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.cmml"><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.2" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.2.cmml">t</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.1" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.3" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.3.cmml">a</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.1a" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.4" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.4.cmml">s</mi><mo id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.1b" lspace="0em" rspace="0em" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.1.cmml">​</mo><mi id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.5" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.5.cmml">k</mi></mrow></mrow></mrow><mo id="S2.SS2.p4.2.m2.1.1.1.1.3" stretchy="false" xref="S2.SS2.p4.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.2.m2.1b"><apply id="S2.SS2.p4.2.m2.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1"><times id="S2.SS2.p4.2.m2.1.1.2.cmml" xref="S2.SS2.p4.2.m2.1.1.2"></times><ci id="S2.SS2.p4.2.m2.1.1.3.cmml" xref="S2.SS2.p4.2.m2.1.1.3">𝑝</ci><apply id="S2.SS2.p4.2.m2.1.1.1.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p4.2.m2.1.1.1.1.1.3.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.3">conditional</csymbol><apply id="S2.SS2.p4.2.m2.1.1.1.1.1.4.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4"><times id="S2.SS2.p4.2.m2.1.1.1.1.1.4.1.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.1"></times><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.4.2.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.2">𝑜</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.4.3.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.3">𝑢</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.4.4.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.4">𝑡</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.4.5.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.5">𝑝</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.4.6.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.6">𝑢</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.4.7.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.4.7">𝑡</ci></apply><list id="S2.SS2.p4.2.m2.1.1.1.1.1.2.3.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2"><apply id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1"><times id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.1"></times><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.2">𝑖</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.3">𝑛</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.4.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.4">𝑝</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.5.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.5">𝑢</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.6.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.1.1.1.6">𝑡</ci></apply><apply id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2"><times id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.1.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.1"></times><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.2.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.2">𝑡</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.3.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.3">𝑎</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.4.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.4">𝑠</ci><ci id="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.5.cmml" xref="S2.SS2.p4.2.m2.1.1.1.1.1.2.2.2.5">𝑘</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.2.m2.1c">p(output|input,task)</annotation></semantics></math>(<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib123" title="">123</a>]</cite>에서 유사한 접근법이 채택됨)를 도입했는데, 이는 입력 및 태스크 정보에 대해 조건화된 출력을 예측한다. 이러한 조건부 확률을 모델링하기 위해, 언어 텍스트는 입력, 출력 및 태스크 정보를 포맷하는 통일된 방법으로 자연스럽게 채용될 수 있다. 이와 같이, 과제를 해결하는 과정을 풀이 텍스트를 생성하기 위한 단어 예측 문제로 캐스팅할 수 있다. 또한, 그들은 이 아이디어에 대해 보다 공식적인 주장을 도입했다: “(작업-특정) 감독된 목적은 감독되지 않은(언어 모델링) 목적과 동일하지만 시퀀스의 서브세트에 대해서만 평가되기 때문에, 감독되지 않은 목적의 전역 최소값은 또한 (다양한 작업에 대해) 감독된 목적의 전역 최소값” <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite><span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>To better understand this sentence, we put some explanation words in parentheses.</span></span></span>” 이 주장에 대한 기본적인 이해는 각각의 (NLP) 태스크가 월드 텍스트의 서브세트에 기초한 단어 예측 문제로서 고려될 수 있다는 것이다. 따라서 비감독 언어 모델링은 세계 텍스트를 복구하는 데 충분한 능력을 갖도록 훈련된다면 다양한 작업을 해결할 수 있다. GPT-2의 이 초기 논의는 옌센 황의 일리야 서츠키버 인터뷰에서 반향했다. “신경망이 학습한 것은 텍스트를 만들어낸 과정의 일부 표현이다. 이 텍스트는 사실 세계의 투영이다. 다음 단어를 예측하는 데 더 정확할수록, 충실도가 높을수록, 이 과정에서 더 많은 해상도를 얻는다.” <span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lifearchitect.ai/ilya/" target="_blank" title="">https://lifearchitect.ai/ilya/</a></span></span></span>.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p5.1.1">Capacity Leap</span>. GPT-2는 "감독되지 않은 멀티태스크 학습자"로 의도되지만, 전반적으로 감독된 미세 조정 최첨단 방법에 비해 열등한 성능을 갖는다. 모델 크기가 상대적으로 작기 때문에 다운스트림 작업, 특히 대화 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>, <a class="ltx_ref" href="#bib.bib125" title="">125</a>]</cite>에서 광범위하게 미세 조정되었습니다. GPT-2를 기반으로 GPT-3은 (거의 동일한) 생성 사전 훈련 아키텍처의 스케일링을 통해 주요 용량 도약을 보여준다.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p6.1.m1.1"><semantics id="S2.SS2.p6.1.m1.1a"><mo id="S2.SS2.p6.1.m1.1.1" xref="S2.SS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p6.1.m1.1b"><ci id="S2.SS2.p6.1.m1.1.1.cmml" xref="S2.SS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS2.p6.1.1">GPT-3</em>. GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>는 2020년에 출시되었으며 모델 매개변수를 175B의 훨씬 더 큰 크기로 조정했다. GPT-3의 논문에서는 LLMs을 수샷 또는 제로샷 방식으로 활용하는 인컨텍스트 학습(ICL)<span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span>GPT-2 essentially used ICL for unsupervised task learning, though it wasn’t called ICL at that time. </span></span></span>의 개념을 형식적으로 도입하였다. ICL은 LLMs에게 자연어 텍스트의 형태로 태스크를 이해하도록 지시(또는 지시)할 수 있다. ICL을 사용하여 LLM의 사전 훈련 및 활용은 동일한 언어 모델링 패러다임으로 수렴한다: 사전 훈련은 컨텍스트에 조건화된 다음 텍스트 시퀀스를 예측하는 반면 ICL은 태스크 설명 및 데모를 감안할 때 텍스트 시퀀스로도 포맷될 수 있는 올바른 태스크 솔루션을 예측한다. GPT-3는 다양한 NLP 작업에서 매우 우수한 성능을 보일 뿐만 아니라 추론이나 도메인 적응의 능력을 요구하는 특수하게 설계된 여러 작업에서도 매우 우수한 성능을 보인다. GPT-3의 논문은 LLM의 출현 능력에 대해 명시적으로 논의하지는 않지만 기본 스케일링 법칙 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p6.1.2">예를 들어,</em> 더 큰 모델은 훨씬 더 강한 ICL 능력을 가지고 있다(GPT-3의 논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>의 원래 그림 1.2에 예시됨). 전반적으로 GPT-3는 PLM에서 LLM으로 진화하는 여정에서 주목할 만한 랜드마크로 볼 수 있다. 신경망을 상당한 크기로 확장하면 모델 용량이 크게 증가할 수 있음을 경험적으로 입증했다.</p>
</div>
<div id="S2.SS2.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p7.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p7.1.1">Capacity Enhancement</span>. 강력한 용량으로 인해 GPT-3는 OpenAI를 위한 훨씬 더 능력 있는 LLM을 개발하는 기본 모델이었다. 전반적으로 OpenAI는 GPT-3 모델인 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p7.1.2">i.e.,</em> 코드 데이터에 대한 훈련 및 인간 선호도와의 정렬을 추가로 개선하기 위한 두 가지 주요 접근법을 탐구했으며, 이는 다음과 같다.</p>
</div>
<div id="S2.SS2.p8" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p8.1.m1.1"><semantics id="S2.SS2.p8.1.m1.1a"><mo id="S2.SS2.p8.1.m1.1.1" xref="S2.SS2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p8.1.m1.1b"><ci id="S2.SS2.p8.1.m1.1.1.cmml" xref="S2.SS2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p8.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS2.p8.1.1">Training on code data</em>. 원래 GPT-3 모델(일반 텍스트에서 사전 훈련됨)의 주요 한계는 복잡한 작업, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p8.1.2">e.g.,</em> 코드를 완성하고 수학 문제를 해결하는 데 있어 추론 능력이 부족하다는 것이다. 이러한 능력을 향상시키기 위해 2021년 7월 OpenAI에서 Codex<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite>를 도입했으며, 이는 GitHub 코드의 대규모 코퍼스에서 미세 조정된 GPT 모델이다. 이는 Codex가 매우 어려운 프로그래밍 문제를 해결할 수 있음을 보여주었고, 또한 수학 문제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib126" title="">126</a>]</cite>를 해결하는 데 있어 상당한 성능 향상을 가져왔다. 또한, 훈련 텍스트 및 코드 임베딩에 대한 대조적 접근 방식 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib127" title="">127</a>]</cite>가 2022년 1월에 보고되었으며, 이는 일련의 관련 작업(<em class="ltx_emph ltx_font_italic" id="S2.SS2.p8.1.3">i.e.,</em> linear-probe classification, text search 및 code search)을 개선하는 것으로 나타났다. 실제로 GPT-3.5 모델은 코드 기반 GPT 모델(<em class="ltx_emph ltx_font_italic" id="S2.SS2.p8.1.4">i.e.,</em> <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p8.1.5">code-davinci-002</span>)을 기반으로 개발되었으며, 이는 코드 데이터에 대한 훈련이 GPT 모델의 모델 용량, 특히 추론 능력을 향상시키는 데 매우 유용한 실습임을 나타낸다. 또한, 코드 데이터에 대한 교육이 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib47" title="">47</a>]</cite>의 연쇄적 사고 촉진 능력을 크게 증가시킬 수 있다는 추측도 있지만, 더 철저한 검증으로 더 조사할 가치가 있다.</p>
</div>
<div id="S2.SS2.p9" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p9.1.m1.1"><semantics id="S2.SS2.p9.1.m1.1a"><mo id="S2.SS2.p9.1.m1.1.1" xref="S2.SS2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p9.1.m1.1b"><ci id="S2.SS2.p9.1.m1.1.1.cmml" xref="S2.SS2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p9.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS2.p9.1.1">Human alignment</em>. 인간 정렬에 대한 관련 연구는 OpenAI에 대한 2017년(또는 이전)으로 거슬러 올라갈 수 있다: "learning from human preferences" <span class="ltx_note ltx_role_footnote" id="footnote18"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/research/learning-from-human-preferences" target="_blank" title="">https://openai.com/research/learning-from-human-preferences</a></span></span></span>이라는 제목의 블로그 기사는 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p9.1.2">preference comparisons</em> An annotated by human="cite idx=0></cite> (<em class="ltx_emph ltx_font_italic" id="S2.SS2.p9.1.3">reward training</em> step in the alignment algorithm in InstructGPT in Figure<a class="ltx_ref" href="#S5.F12" title="Figure 12 ‣ 5.2.3 Reinforcement Learning from Human Feedback ‣ 5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">12</span></a>). 이 RL 논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>]</cite>가 발표된 직후, 2017년 7월에 Proximal Policy Optimization(PPO) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib128" title="">128</a>]</cite>의 논문이 발표되었는데, 이는 현재 인간의 선호도로부터 학습을 위한 기초 RL 알고리즘인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>이다. 이후 2020년 1월 GPT-2는 앞서 언급한 RL 알고리즘 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>, <a class="ltx_ref" href="#bib.bib128" title="">128</a>]</cite>를 사용하여 미세 조정되었으며, 이는 NLP 작업에서 GPT-2의 용량을 개선하기 위해 인간의 선호도를 활용했다. 같은 해에, 다른 작품 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib129" title="">129</a>]</cite>는 인간의 선호도를 최적화하기 위한 요약 모델을 비슷한 방식으로 훈련시켰다. 이러한 선행 연구를 바탕으로 2022년 1월 인간 정렬을 위한 GPT-3 모델을 개선하기 위해 InstructGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>가 제안되었으며, 이는 3단계 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p9.1.4">reinforcement learning from human feedback(RLHF)</em> 알고리즘을 공식적으로 확립했다. "<em class="ltx_emph ltx_font_italic" id="S2.SS2.p9.1.5">instruction tuning</em>"의 문구는 OpenAI의 논문 및 문서에서 거의 사용되지 않은 것으로 보이며, 이는 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p9.1.6">supervised fine-tuning on human demonstrationations</em> (<em class="ltx_emph ltx_font_italic" id="S2.SS2.p9.1.7">i.e.,</em> the first step of the RLHF algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>)로 대체된다. 명령 후속 용량을 개선하는 것 외에도, RLHF 알고리즘은 LLMs에 대한 위해 또는 독성 콘텐츠를 생성하는 문제를 완화하는 데 특히 유용하며, 이는 실제로 LLMs의 안전한 배치에 핵심이다. OpenAI는 기술 논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib130" title="">130</a>]</cite>에서 정렬 연구에 대한 그들의 접근 방식을 설명하며, "인간 피드백을 사용하고 인간 평가를 돕고 정렬 연구를 수행하도록 AI 시스템을 훈련"하는 세 가지 유망한 방향을 요약했다.</p>
</div>
<div id="S2.SS2.p10" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p10.1">이러한 개선 기술들은 더 강한 용량들을 갖는 개선된 GPT-3 모델들로 이어지며, 이는 OpenAI에 의한 GPT-3.5 모델들로 불린다(섹션 <a class="ltx_ref" href="#S3.SS1" title="3.1 Publicly Available Model Checkpoints or APIs ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3.1</span></a>의 OpenAI API에 대한 논의를 참조).</p>
</div>
<div id="S2.SS2.p11" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p11.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p11.1.1">The Milestones of Language Models</span>. 모든 탐색 노력에 기초하여, 두 가지 주요 이정표는 OpenAI에 의해 달성되었으며, 즉 ChatGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib131" title="">131</a>]</cite>와 GPT-4<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>는 기존 AI 시스템의 용량 기준을 크게 높였다.</p>
</div>
<div id="S2.SS2.p12" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p12.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p12.1.m1.1"><semantics id="S2.SS2.p12.1.m1.1a"><mo id="S2.SS2.p12.1.m1.1.1" xref="S2.SS2.p12.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p12.1.m1.1b"><ci id="S2.SS2.p12.1.m1.1.1.cmml" xref="S2.SS2.p12.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p12.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS2.p12.1.1">ChatGPT</em>. 2022년 11월 OpenAI는 GPT 모델(GPT-3.5, GPT-4)을 기반으로 대화 모델 ChatGPT를 출시했다. 공식 블로그 기사에서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib131" title="">131</a>]</cite>를 소개하면서, ChatGPT는 InstructGPT(원래 게시물에서 InstructGPT에 대한 형제 모델이라고 함)와 유사한 방식으로 훈련되는 한편, 특히 대사에 최적화되었다. 그들은 데이터 수집 설정에서 ChatGPT와 InstructGPT의 훈련 간의 차이를 보고했다: 인간 생성 대화(사용자 및 AI의 역할 모두 수행)는 ChatGPT 훈련을 위한 대화 형식으로 InstructGPT 데이터 세트와 결합된다. ChatGPT는 방대한 지식의 저장, 수학적 문제에 대한 추론 능력, 멀티턴 대화에서 정확한 맥락 추적, 안전한 사용을 위해 인간의 가치와 잘 일치한다는 점에서 인간과 소통하는 데 탁월한 능력을 보였다. 이후, 플러그인 메커니즘은 ChatGPT에서 지원되었으며, 이는 기존 도구 또는 앱으로 ChatGPT의 용량을 더욱 확장한다. 지금까지 그것은 AI 역사상 가장 강력한 챗봇인 것 같다. ChatGPT의 출시는 향후 AI 연구에 큰 영향을 미치며, 이는 인간과 유사한 AI 시스템 탐구를 조명한다.</p>
</div>
<div id="S2.SS2.p13" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p13.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p13.1.m1.1"><semantics id="S2.SS2.p13.1.m1.1a"><mo id="S2.SS2.p13.1.m1.1.1" xref="S2.SS2.p13.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p13.1.m1.1b"><ci id="S2.SS2.p13.1.m1.1.1.cmml" xref="S2.SS2.p13.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p13.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS2.p13.1.1">GPT-4</em>. 또 다른 놀라운 진전으로, GPT-4<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>가 2023년 3월에 출시되었으며, 이는 텍스트 입력을 멀티모달 신호로 확장했다. 전반적으로 GPT-4는 GPT-3.5보다 복잡한 과제 해결 능력이 강해 많은 평가 과제에서 큰 성능 향상을 보였다. 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib41" title="">41</a>]</cite>는 다양한 난제 범위에 걸쳐 인간이 생성한 문제에 대한 정성적 테스트를 수행하여 GPT-4의 용량을 조사했으며 GPT-4가 ChatGPT와 같은 이전 GPT 모델보다 더 우수한 성능을 달성할 수 있음을 보여주었다. 또한, GPT-4는 6개월 반복 정렬(RLHF 훈련에서 추가 안전 보상 신호와 함께)로 인해 악의적이거나 자극적인 쿼리에 더 안전하게 응답한다. 기술 보고서에서 OpenAI는 GPT-4를 안전하게 개발하는 방법을 강조하고 환각, 개인 정보 보호 및 과잉 의존과 같은 LLM의 가능한 문제를 완화하기 위해 여러 개입 전략을 적용했다. 예를 들어, 그들은 위해 또는 독성 콘텐츠 생성을 줄이기 위해 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p13.1.2">red teaming</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib132" title="">132</a>]</cite>라는 메커니즘을 도입했다. 또 다른 중요한 측면으로서, GPT-4는 개선된 최적화 방법을 갖는 잘 확립된 딥 러닝 인프라 상에서 개발되었다. 그들은 모델 훈련 동안 적은 비율의 계산으로 최종 성능을 정확하게 예측할 수 있는 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p13.1.3">predictable scaling</em>이라는 새로운 메커니즘을 도입했다.</p>
</div>
<div id="S2.SS2.p14" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p14.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p14.1.m1.1"><semantics id="S2.SS2.p14.1.m1.1a"><mo id="S2.SS2.p14.1.m1.1.1" xref="S2.SS2.p14.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p14.1.m1.1b"><ci id="S2.SS2.p14.1.m1.1.1.cmml" xref="S2.SS2.p14.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p14.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S2.SS2.p14.1.1">GPT-4V, GPT-4 turbo, and beyond</em>. GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>에 대한 작업을 바탕으로 OpenAI는 2023년 9월에 GPT-4V를 추가로 출시하여 GPT-4의 비전 능력을 안전하게 배치하는 데 중점을 두었다. GPT-4V의 시스템 카드 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite>에서는 시각적으로 증강된 입력과 관련된 위험의 평가 및 완화에 대해 광범위하게 논의했다. 특히 GPT-4V는 다양한 응용 시나리오에서 강력한 비전 능력을 보여 강력한 멀티모달 학습 시스템으로서의 큰 잠재력을 보여주었다. 보다 최근에, OpenAI는 2023년 11월 DevDay에서 일련의 기술적 개선과 함께 <em class="ltx_emph ltx_font_italic" id="S2.SS2.p14.1.2">GPT-4 Turbo</em>이라는 이름의 업그레이드된 세대의 GPT-4 모델을 출시했다. GPT-4 Turbo는 개선된 모델 용량(GPT-4보다 더 가능), 확장된 지식 소스(최대 2023년 4월), 긴 컨텍스트 윈도우(최대 128k 토큰), 최적화된 모델 성능(저렴한 가격), 및 기타 유용한 기능 업데이트(기능 호출, 재현 가능한 출력 등)에 의해 특징지어지며, 동시에 에이전트 유사 어시스턴트의 신속한 개발을 용이하게 하기 위해 어시스턴트 API를 개시하였다. 이 API를 사용하면 개발자는 특정 명령, 추가 지식 및 도구 사용을 활용하여 애플리케이션 내에서 목표 지향 비서를 쉽게 만들 수 있습니다. 또한 GPT-4 Turbo with vision, DALL·E 3, Text-to-speech(TTS) 및 Listen to voice 샘플로 지원되는 이 새로운 릴리스에서 멀티모달 용량(참조, 듣기 및 말하기)도 향상되었습니다. 이러한 개선은 용량 범위를 크게 확장하고 GPT 모델의 작업 성능을 향상시켰다. 더 중요한 것은 개선된 모델, API 및 기능에서 기술 업그레이드로 애플리케이션 생태계가 크게 강화된다는 것입니다.</p>
</div>
<div id="S2.SS2.p15" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p15.1">엄청난 진보에도 불구하고, 이러한 우수한 LLMs, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p15.1.1">e.g.,</em> generate hallinations with factual errors or potentially risky response within some specific context <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>에는 여전히 한계가 있다. LLM의 더 많은 제한 사항 또는 문제는 섹션 <a class="ltx_ref" href="#S7" title="7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>에서 논의될 것이다. 그것은 더 유능하고 안전한 LLM을 개발하기 위해 오랜 연구 과제를 제기한다. 공학적인 관점에서 OpenAI는 5단계 개발 및 배포 라이프 사이클에 따라 모델 및 제품을 개발하기 위해 반복적인 배포 전략 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib134" title="">134</a>]</cite>를 채택했으며, 이는 모델 사용의 잠재적 위험을 효과적으로 줄이는 것을 목표로 한다. 아래에서는 어떻게 개발되었는지 구체적으로 이해하기 위해 기술 세부 사항에 대해 자세히 알아보겠습니다.</p>
</div>
<figure id="S2.F5" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x6.png" id="S2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="286" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 5:</span>LLaMA에 대해 수행된 연구 작업의 진화 그래프. 엄청난 숫자로 인해, 우리는 이 그림에 모든 LLaMA 변형을 포함할 수 없으며, 심지어 훨씬 우수한 작업도 포함할 수 없다. 증분 업데이트를 지원 하기 위해이 그림의 원본 파일을 공유 하 고 GitHub 페이지에 끌어오기 요청을 제출 하 여 독자가 원하는 모델을 포함 하는 것을 환영합니다.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Resources of LLMs</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p" id="S3.p1.1">어려운 기술적 문제와 막대한 계산 자원 수요를 고려할 때 LLM을 개발하거나 재현하는 것은 결코 쉬운 일이 아니다. 실행 가능한 방법은 기존 LLM에서 경험을 배우고 증분 개발 또는 실험 연구를 위해 공개적으로 사용 가능한 리소스를 재사용하는 것이다. 이 섹션에서는 모델 체크포인트(또는 API), 말뭉치 및 라이브러리를 포함하여 LLM 개발을 위해 공개적으로 사용할 수 있는 리소스를 간략하게 요약한다.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span id="S3.SS1.1.1" class="ltx_text ltx_font_italic">Publicly Available Model Checkpoints or APIs</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p1.1">모델 사전 훈련의 막대한 비용을 감안할 때 잘 훈련된 모델 체크포인트는 연구 커뮤니티를 위한 LLM의 연구 및 개발에 매우 중요하다. 매개 변수 척도는 LLM을 사용하기 위해 고려해야 할 핵심 요소이기 때문에 이러한 공개 모델을 두 가지 척도 수준(<em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.1">i.e.,</em> <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.2">수십억 개의 매개 변수</em> 및 <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.3">수백억 개의 매개 변수</em>)으로 분류한다. 또한 추론을 위해 모델을 로컬로 실행하지 않고 공용 API를 직접 사용하여 작업을 수행할 수 있습니다. 다음으로 공개적으로 사용 가능한 모델 체크포인트와 API를 소개합니다.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p2.3"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.3.1">Models with Tens of Billions of Parameters</span>. 이 범주의 대부분의 모델은 LLaMA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite> 및 LLaMA2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>(가장 큰 버전에서 70B 매개 변수 포함), NLLB<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib91" title="">91</a>]</cite>(가장 큰 버전에서 54.5B 매개 변수 포함), Falcon<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib135" title="">135</a>]</cite>(가장 큰 버전에서 40B 매개 변수 포함)를 제외하고 10B에서 20B 범위의 매개 변수 규모를 가지고 있다. 이 범위 내의 다른 모델로는 mT5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib83" title="">83</a>]</cite>, PanGu-<math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\alpha</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib84" title="">84</a>]</cite>, T0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>, GPT-NeoX-20B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib87" title="">87</a>]</cite>, CodeGen <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>, UL2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib89" title="">89</a>]</cite>, Flan-T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>, mT0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib94" title="">94</a>]</cite> 등이 있다. 그 중 Flan-T5(11B 버전)는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>의 세 가지 측면에서 명령어 튜닝을 탐구하기 때문에 명령어 튜닝을 위한 선행 모델 역할을 할 수 있다. 또한 코드 생성을 위해 설계된 자기회귀 언어 모델인 CodeGen(11B 버전)은 코드 생성 능력을 탐색하는데 좋은 후보로 고려될 수 있다. 또한 115개의 전문가 생성 문제로 구성된 멀티턴 프로그램 합성을 위한 새로운 벤치마크 MTPB <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>를 소개한다. 이러한 문제를 해결하기 위해서는 LLM이 충분한 프로그래밍 지식을 습득해야 한다(<em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.3.2">e.g.,</em> math, array operations and algorithms). 보다 최근에는 모델 아키텍처, 학습 알고리즘 및 데이터 분포의 선택이 모델에 미치는 영향을 조사하기 위해 CodeGen2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib97" title="">97</a>]</cite>가 출시되었다. 코딩 능력에 특화된 또 다른 LLM으로서, StarCoder<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib98" title="">98</a>]</cite>도 우수한 결과를 얻었다. 다국어 작업의 경우 mT0(13B 버전)이 좋은 후보 모델일 수 있으며, 이는 다국어 프롬프트를 사용하여 다국어 작업에 대해 미세 조정되었다. 또한 PanGu-<math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\alpha</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib84" title="">84</a>]</cite>는 딥러닝 프레임워크 MindSpore <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib136" title="">136</a>]</cite>를 기반으로 개발된 제로샷 또는 소샷 설정에서 중국어 다운스트림 태스크에서 좋은 성능을 보인다. PanGu-<math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\alpha</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib84" title="">84</a>]</cite>는 여러 버전의 모델(최대 200B 파라미터)을 보유하는 반면, 가장 큰 공개 버전은 13B 파라미터를 갖는다. LLM으로 널리 사용되는 LLaMA(65B version) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>는 다른 모델보다 약 5배 많은 파라미터를 포함하고 있으며, 명령어 수행과 관련된 태스크에서 우수한 성능을 보였다. LLaMA에 비해 LLaMA2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>는 인간 피드백(RLHF)으로부터 강화 학습에서 더 많은 탐색을 했고, 일반적으로 유용성과 안전 벤치마크 범위에 걸쳐 기존 오픈 소스 모델보다 우수한 <em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.3.3">LLaMA-chat</em>이라는 채팅 지향 버전을 개발했다. 개방성과 효과성으로 인해 LLaMA는 연구 커뮤니티에서 상당한 관심을 끌었고, 새로운 모델 또는 도구를 구현하기 위해 다양한 모델 버전을 미세 조정하거나 지속적으로 사전 훈련하는 데 많은 노력을 기울였다. 최근에는 또 다른 오픈 소스 LLM으로서 Falcon<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib135" title="">135</a>]</cite>도 오픈 벤치마크에서 매우 우수한 성능을 달성하였다. 사전 트레이닝 데이터를 준비하기 위해 보다 신중한 데이터 클리닝 프로세스가 특징이다(공개 공유 데이터 세트 <em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.3.4">RefinedWeb <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib141" title="">141</a>]</cite>). </em> 일반적으로 이러한 규모의 사전 훈련 모델은 수백 또는 수천 개의 GPU 또는 TPU를 필요로 합니다. 예를 들어 GPT-NeoX-20B는 각각 8개의 NVIDIA A100-SXM4-40GB GPU가 장착된 12개의 슈퍼마이크로 서버를 사용하는 반면 LLaMA는 원래 간행물에 보고된 대로 2,048개의 A100-80G GPU를 사용한다. 필요한 계산 리소스를 정확하게 추정하기 위해 <em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.3.5">FLOPS</em> (<em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.3.6">i.e.,</em> FLoating point number Operations Per Second) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>와 같은 관련 계산 수를 측정하는 메트릭을 사용하는 것이 좋습니다.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Models with Hundreds of Bills of Parameters</span>. 이 범주에 속하는 모델의 경우 소수의 모델만 공개적으로 출시되었다. 예를 들어, OPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite>, OPT-IML<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib95" title="">95</a>]</cite>, BLOOM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>, BLOOMZ<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib94" title="">94</a>]</cite>는 GPT-3(175B 버전)과 거의 동일한 수의 파라미터를 갖는 반면, GLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite> 및 Galactica<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite>는 각각 130B 및 120B의 파라미터를 갖는다. 그 중 OPT(175B version)는 명령어 조정 버전인 OPT-IML과 함께 오픈 셰어링에 특별한 동기를 부여하였으며, 이는 연구자들이 대규모로 재현 가능한 연구를 수행할 수 있도록 하는 것을 목표로 한다. 언어 간 일반화 연구를 위해 다국어 언어 모델링 작업의 능력으로 인해 BLOOM(176B 버전)과 BLOOMZ(176B 버전)를 기본 모델로 사용할 수 있다. 이중 언어 LLM으로서, GLM은 또한 인기 있는 작은 크기의 중국 채팅 모델 ChatGLM2-6B(ChatGLM-6B에 대한 업데이트된 버전)를 제공했는데, 이는 효율 및 용량에서 많은 개선을 특징으로 한다(<em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.2">예를 들어,</em> 양자화, 32K-길이 컨텍스트, 빠른 추론 속도). 이 규모의 모델은 일반적으로 수천 개의 GPU 또는 TPU를 훈련시켜야 합니다. 예를 들어 OPT(175B 버전)는 992개의 A100-80GB GPU를 사용했으며 GLM(130B 버전)은 96개의 NVIDIA DGX-A100(8x40G) GPU 노드의 클러스터를 사용했다.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">LLaMA Model Family</span>. LLaMA 모델 모음 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>는 2023년 2월 Meta AI에 의해 도입되었으며, 4가지 크기(7B, 13B, 30B 및 65B)로 구성되었다. 공개된 이후 LLaMA는 연구와 산업 커뮤니티 모두에서 광범위한 관심을 끌었다. LLaMA 모델은 지금까지 가장 인기 있는 개방형 언어 모델이 된 다양한 개방형 벤치마크에서 매우 우수한 성능을 달성했다. 많은 연구자들이 LLaMA 모델을 명령어 튜닝 또는 지속적인 사전 훈련으로 확장했다. 특히, 명령어 튜닝 LLaMA는 상대적으로 낮은 계산 비용으로 인해 맞춤형 또는 전문화된 모델을 개발하는 주요 접근법이 되었다. LLaMA 모델을 비영어권에서 효과적으로 적용하기 위해서는 원어휘(영어 코퍼스 위주로 학습)를 확장하거나 목표 언어의 명령어나 데이터로 미세 조정해야 하는 경우가 많다. 이러한 확장 모델 중 Stanford Alpaca<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>는 LLaMA(7B)를 기반으로 미세 조정된 최초의 개방형 명령 후속 모델이다. <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p4.1.2">text-davinci-003</span>을 사용하여 self-instruct <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>를 통해 생성된 52K instruction-following demonstration에 의해 훈련된다. <em class="ltx_emph ltx_font_italic" id="S3.SS1.p4.1.3">Alpaca-52K</em>로 명명된 명령어 데이터는 Alpaca-LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib144" title="">144</a>]</cite> (A reproduction of Stanford Alpaca using LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib145" title="">145</a>]</cite>), Koala <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib146" title="">146</a>]</cite> 및 BELLE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib147" title="">147</a>]</cite>와 같이 후속 작업에서 광범위하게 채택되었다. 또한, Vicuna<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>는 ShareGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>로부터 수집된 사용자 공유 대화 시 훈련된 또 다른 인기 있는 LLaMA 변형이다. LLaMA 모델 패밀리의 뛰어난 성능과 가용성으로 인해 많은 멀티모달 모델이 기본 언어 모델로 통합되어 강력한 언어 이해 및 생성 능력을 달성한다. 다른 변형과 비교하여 Vicuna는 멀티모달 언어 모델에서 더 선호되며, 이는 LLaVA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib149" title="">149</a>]</cite>, MiniGPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib150" title="">150</a>]</cite>, InstructBLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib151" title="">151</a>]</cite>, PandaGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib152" title="">152</a>]</cite> 등 다양한 인기 모델의 출현으로 이어졌다. LLaMA의 출시는 LLM의 연구 진전을 크게 발전시켰다. LLaMA에 대해 수행된 연구 작업을 요약하기 위해 그림 <a class="ltx_ref" href="#S2.F5" title="Figure 5 ‣ 2.2 Technical Evolution of GPT-series Models ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>에 간략한 진화 그래프를 제시한다.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">LLMs</span>의 Public API. 모델 복사본을 직접 사용하는 대신 API를 사용하면 모델을 로컬로 실행할 필요 없이 일반 사용자가 LLM을 사용할 수 있는 더 편리한 방법을 제공합니다. LLM을 사용하기 위한 대표적인 인터페이스로 GPT 시리즈 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib105" title="">105</a>, <a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>에 대한 API는 학계와 산업계 <span class="ltx_note ltx_role_footnote" id="footnote19"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note">19</span>https://platform.openai.com/docs/api-reference/introduction</span></span></span> 모두에 널리 사용되었다. OpenAI는 GPT-3 시리즈의 모델에 대한 7가지 주요 인터페이스를 제공했습니다. <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.2">ada</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.3">babbage</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.4">curie</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.4">davinci</span> (GPT-3 시리즈에서 가장 강력한 버전), <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.6">text-ada-001</span>, <span class="ltx_text ltx_font_type 이 중 처음 4개의 인터페이스는 OpenAI의 호스트 서버에서 더 미세 조정될 수 있다. 특히 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.9">babbage</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.10">curie</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.11">davinci</span>은 각각 GPT-3(1B), GPT-3(6.7B), GPT-3(175B) 모델에 해당한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>. 또한, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.12">code-cushman-001</span> (Power and multilingual version of the Codex (12B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite>) 및 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.13">code-davinci-002</span>이라고 불리는 Codex<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite>와 관련된 두 개의 API도 있다. 또한, GPT-3.5 시리즈는 하나의 기본 모델 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.14">code-davinci-002</span> 및 세 가지 향상된 버전, 즉 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.15">text-davinci-002</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.16">text-davinci-003</span> 및 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.17">gpt-3.5-turbo</span>을 포함한다. 보다 강력한 대안으로, 올해 OpenAI는 GPT-4 시리즈에 대한 모델 인터페이스를 출시했는데, 여기에는 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.18">gpt-4</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.19">gpt-4-32k</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.20">gpt-4-1106-preview</span> (<em class="ltx_emph ltx_font_italic" id="S3.SS1.p5.1.21">i.e.,</em> GPT-4 Turbo) 및 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.22">gpt-4-vision-preview</ OpenAI가 이러한 모델 인터페이스를 유지 및 업그레이드하고 있다는 점은 주목할 가치가 있습니다(<span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.24">gpt-3.5-turbo</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.25">gpt-4</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p5.1.26">gpt-4-32k</span>). 따라서 API 이름은 실제로 최신 버전을 가리킵니다. 현재 ChatGPT는 GPT-3.5 또는 GPT-4 모델로 구동될 수 있다. 전반적으로 특정 애플리케이션 시나리오 및 응답 요구 사항에 따라 적합한 모델 인터페이스를 선택합니다. 자세한 사용량은 프로젝트 웹사이트 <span class="ltx_note ltx_role_footnote" id="footnote20"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span>https://platform.openai.com/docs/models/overview</span></span></span>에서 확인할 수 있습니다.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II:</span>일반적으로 사용되는 데이터 소스의 통계.</figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T2.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Corpora</span></td>
<td id="S3.T2.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Size</span></td>
<td id="S3.T2.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Source</span></td>
<td id="S3.T2.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Latest Update Time</span></td>
</tr>
<tr id="S3.T2.1.2" class="ltx_tr">
<td id="S3.T2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.2.1.1" class="ltx_text" style="font-size:80%;">BookCorpus&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.2.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib153" title="" class="ltx_ref">153</a><span id="S3.T2.1.2.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.2.2.1" class="ltx_text" style="font-size:80%;">5GB</span></td>
<td id="S3.T2.1.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.2.3.1" class="ltx_text" style="font-size:80%;">Books</span></td>
<td id="S3.T2.1.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.2.4.1" class="ltx_text" style="font-size:80%;">Dec-2015</span></td>
</tr>
<tr id="S3.T2.1.3" class="ltx_tr">
<td id="S3.T2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.3.1.1" class="ltx_text" style="font-size:80%;">Gutenberg&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.3.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib154" title="" class="ltx_ref">154</a><span id="S3.T2.1.3.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.3.2.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S3.T2.1.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.3.3.1" class="ltx_text" style="font-size:80%;">Books</span></td>
<td id="S3.T2.1.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.3.4.1" class="ltx_text" style="font-size:80%;">Dec-2021</span></td>
</tr>
<tr id="S3.T2.1.4" class="ltx_tr">
<td id="S3.T2.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.4.1.1" class="ltx_text" style="font-size:80%;">C4&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib82" title="" class="ltx_ref">82</a><span id="S3.T2.1.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.4.2.1" class="ltx_text" style="font-size:80%;">800GB</span></td>
<td id="S3.T2.1.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.4.3.1" class="ltx_text" style="font-size:80%;">CommonCrawl</span></td>
<td id="S3.T2.1.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.4.4.1" class="ltx_text" style="font-size:80%;">Apr-2019</span></td>
</tr>
<tr id="S3.T2.1.5" class="ltx_tr">
<td id="S3.T2.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.5.1.1" class="ltx_text" style="font-size:80%;">CC-Stories-R&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.5.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib155" title="" class="ltx_ref">155</a><span id="S3.T2.1.5.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.5.2.1" class="ltx_text" style="font-size:80%;">31GB</span></td>
<td id="S3.T2.1.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.5.3.1" class="ltx_text" style="font-size:80%;">CommonCrawl</span></td>
<td id="S3.T2.1.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.5.4.1" class="ltx_text" style="font-size:80%;">Sep-2019</span></td>
</tr>
<tr id="S3.T2.1.6" class="ltx_tr">
<td id="S3.T2.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.6.1.1" class="ltx_text" style="font-size:80%;">CC-NEWS&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.6.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib27" title="" class="ltx_ref">27</a><span id="S3.T2.1.6.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.6.2.1" class="ltx_text" style="font-size:80%;">78GB</span></td>
<td id="S3.T2.1.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.6.3.1" class="ltx_text" style="font-size:80%;">CommonCrawl</span></td>
<td id="S3.T2.1.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.6.4.1" class="ltx_text" style="font-size:80%;">Feb-2019</span></td>
</tr>
<tr id="S3.T2.1.7" class="ltx_tr">
<td id="S3.T2.1.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.7.1.1" class="ltx_text" style="font-size:80%;">REALNEWs&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.7.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib156" title="" class="ltx_ref">156</a><span id="S3.T2.1.7.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.7.2.1" class="ltx_text" style="font-size:80%;">120GB</span></td>
<td id="S3.T2.1.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.7.3.1" class="ltx_text" style="font-size:80%;">CommonCrawl</span></td>
<td id="S3.T2.1.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.7.4.1" class="ltx_text" style="font-size:80%;">Apr-2019</span></td>
</tr>
<tr id="S3.T2.1.8" class="ltx_tr">
<td id="S3.T2.1.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.8.1.1" class="ltx_text" style="font-size:80%;">OpenWebText&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.8.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib157" title="" class="ltx_ref">157</a><span id="S3.T2.1.8.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.8.2.1" class="ltx_text" style="font-size:80%;">38GB</span></td>
<td id="S3.T2.1.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.8.3.1" class="ltx_text" style="font-size:80%;">Reddit links</span></td>
<td id="S3.T2.1.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.8.4.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
</tr>
<tr id="S3.T2.1.9" class="ltx_tr">
<td id="S3.T2.1.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.9.1.1" class="ltx_text" style="font-size:80%;">Pushift.io&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.9.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib158" title="" class="ltx_ref">158</a><span id="S3.T2.1.9.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.9.2.1" class="ltx_text" style="font-size:80%;">2TB</span></td>
<td id="S3.T2.1.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.9.3.1" class="ltx_text" style="font-size:80%;">Reddit links</span></td>
<td id="S3.T2.1.9.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.9.4.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
</tr>
<tr id="S3.T2.1.10" class="ltx_tr">
<td id="S3.T2.1.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.10.1.1" class="ltx_text" style="font-size:80%;">Wikipedia&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.10.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib159" title="" class="ltx_ref">159</a><span id="S3.T2.1.10.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.10.2.1" class="ltx_text" style="font-size:80%;">21GB</span></td>
<td id="S3.T2.1.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.10.3.1" class="ltx_text" style="font-size:80%;">Wikipedia</span></td>
<td id="S3.T2.1.10.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.10.4.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
</tr>
<tr id="S3.T2.1.11" class="ltx_tr">
<td id="S3.T2.1.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.11.1.1" class="ltx_text" style="font-size:80%;">BigQuery&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.11.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib160" title="" class="ltx_ref">160</a><span id="S3.T2.1.11.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.11.2.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S3.T2.1.11.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.11.3.1" class="ltx_text" style="font-size:80%;">Codes</span></td>
<td id="S3.T2.1.11.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.11.4.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
</tr>
<tr id="S3.T2.1.12" class="ltx_tr">
<td id="S3.T2.1.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.12.1.1" class="ltx_text" style="font-size:80%;">the Pile&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.12.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib161" title="" class="ltx_ref">161</a><span id="S3.T2.1.12.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.12.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.12.2.1" class="ltx_text" style="font-size:80%;">800GB</span></td>
<td id="S3.T2.1.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.12.3.1" class="ltx_text" style="font-size:80%;">Other</span></td>
<td id="S3.T2.1.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.12.4.1" class="ltx_text" style="font-size:80%;">Dec-2020</span></td>
</tr>
<tr id="S3.T2.1.13" class="ltx_tr">
<td id="S3.T2.1.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T2.1.13.1.1" class="ltx_text" style="font-size:80%;">ROOTS&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.13.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib162" title="" class="ltx_ref">162</a><span id="S3.T2.1.13.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T2.1.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.13.2.1" class="ltx_text" style="font-size:80%;">1.6TB</span></td>
<td id="S3.T2.1.13.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.13.3.1" class="ltx_text" style="font-size:80%;">Other</span></td>
<td id="S3.T2.1.13.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T2.1.13.4.1" class="ltx_text" style="font-size:80%;">Jun-2022</span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span id="S3.SS2.1.1" class="ltx_text ltx_font_italic">Commonly Used Corpora for Pre-training</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p1.1">이전 PLM과 달리 훨씬 더 많은 수의 매개변수로 구성된 LLM은 광범위한 콘텐츠를 다루는 더 많은 양의 훈련 데이터를 필요로 한다. 이러한 필요를 위해 연구를 위해 공개된 접근 가능한 훈련 데이터 세트가 점점 더 많아지고 있다. 이 섹션에서는 LLM을 훈련하기 위해 널리 사용되는 몇 가지 말뭉치를 간략하게 요약할 것이다. 콘텐츠 유형에 따라 이 말뭉치를 책, 커먼크롤, 레딧 링크, 위키피디아, 코드 및 기타의 6개 그룹으로 분류한다.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Books. </span> BookCorpus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib153" title="">153</a>]</cite>는 이전의 소규모 모델(<em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.1.2">e.g.,</em> GPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>]</cite> and GPT-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>)에서 일반적으로 사용되는 데이터 세트이며, 광범위한 주제 및 장르를 다루는 11,000권 이상의 책으로 구성된다(<em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.1.3">e.g.,</em> 소설 및 전기). 또 다른 대규모 서적 코퍼스는 프로젝트 구텐베르크<사이트 idx=3></사이트>로, 소설, 수필, 시, 드라마, 역사, 과학, 철학, 기타 유형의 공공 영역의 작품을 포함한 7만 권 이상의 문학 서적으로 구성되어 있다. 현재 MT-NLG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib113" title="">113</a>]</cite>와 LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>의 교육에 사용되는 가장 큰 오픈 소스 도서 컬렉션 중 하나이다. GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>에서 사용된 Books1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>와 Books2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>의 경우 BookCorpus보다 훨씬 크지만 지금까지 공개되지 않았다.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">CommonCrawl. </span> CommonCrawl <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib163" title="">163</a>]</cite>는 기존의 LLMs에 대한 학습 데이터로 널리 사용되어 온 페타바이트 규모의 데이터 볼륨을 포함하는 가장 큰 오픈 소스 웹 크롤링 데이터베이스 중 하나이다. 전체 데이터세트가 매우 크기 때문에 기존 연구들은 주로 특정 기간 내에 웹 페이지의 하위 집합을 추출한다. 그러나 웹 데이터에 잡음이 많고 품질이 낮은 정보가 널리 존재하기 때문에 사용 전에 데이터 전처리를 수행해야 한다. CommonCrawl을 기반으로 기존 작업에서 일반적으로 사용되는 필터링된 데이터셋은 C4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>, CC-Stories <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib155" title="">155</a>]</cite>, CC-News <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite>, RealNews <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib156" title="">156</a>]</cite> 네 가지이다. 거대 클린 크롤드 코퍼스(C4)는 en(806G), en.noclean(6T), realnewslike(36G), webtextlike(17G), 다국어(38T)의 5가지 변형(span idx=0></span>)을 포함한다. <em class="ltx_emph ltx_font_italic" id="S3.SS2.p3.1.2">en</em> 버전은 사전 훈련 T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>, LaMDA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite>, Gopher <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>, UL2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib89" title="">89</a>]</cite>에 활용되었다. mC4라고도 하는 다국어 C4는 mT5<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib83" title="">83</a>]</cite>에서 사용되었다. CC-Stories(31G)는 CommonCrawl 데이터의 부분집합으로 구성되어 있으며, 이 부분집합에서 내용들이 이야기와 같은 방식으로 만들어진다. CC-Stories의 원본 원본을 사용할 수 없기 때문에 표 <a class="ltx_ref" href="#S3.T2" title="TABLE II ‣ 3.1 Publicly Available Model Checkpoints or APIs ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">II</span></a>에서 재생 버전 <em class="ltx_emph ltx_font_italic" id="S3.SS2.p3.1.3">CC-Stories-R</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib164" title="">164</a>]</cite>를 포함합니다. 또한 CommonCrawl에서 추출된 두 개의 뉴스 코퍼라, <em class="ltx_emph ltx_font_italic" id="S3.SS2.p3.1.4">i.e.,</em> REALNEWS(120G) 및 CC-News(76G)도 사전 훈련 데이터로 일반적으로 사용된다.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Reddit Links. </span> Reddit은 사용자가 링크와 텍스트 게시물을 제출할 수 있는 소셜 미디어 플랫폼으로, "상표" 또는 "하표"를 통해 다른 사람이 투표할 수 있습니다. 높은 지지를 받은 게시물은 종종 유용한 것으로 간주되며 고품질 데이터 세트를 만드는 데 활용할 수 있다. WebText <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>는 Reddit의 높은 인용 링크로 구성된 잘 알려진 말뭉치이지만 공개적으로 사용할 수 있는 것은 아니다. 대리인으로는 OpenWebText<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib157" title="">157</a>]</cite>라는 쉽게 접근할 수 있는 오픈 소스 대안이 있다. Reddit에서 추출한 또 다른 말뭉치는 PushShift.io <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib158" title="">158</a>]</cite>로, 생성일 이후 Reddit의 과거 데이터로 구성된 실시간 업데이트 데이터셋이다. Pushshift는 월별 데이터 덤프뿐만 아니라 사용자가 전체 데이터 세트에 대한 검색, 요약 및 예비 조사를 수행할 수 있도록 지원하는 유용한 유틸리티 도구를 제공합니다. 이를 통해 사용자가 레딧 데이터를 쉽게 수집하고 처리할 수 있습니다.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.1">Wikipedia. </span>Wikipedia<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib159" title="">159</a>]</cite>는 다양한 주제의 고품질 기사를 대량으로 수록한 온라인 백과사전이다. 이 기사의 대부분은 광범위한 언어와 분야를 포괄하는 (지원 참조와 함께) 설명서 스타일의 글로 구성되어 있다. 전형적으로, Wikipedia의 영어 전용 필터링된 버전은 대부분의 LLMs에서 널리 사용된다(<em class="ltx_emph ltx_font_italic" id="S3.SS2.p5.1.2">e.g.,</em> GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>, LaMDA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite>, 및 LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>). 위키피디아는 여러 언어로 사용할 수 있으므로 다국어 설정에서 사용할 수 있습니다.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.1">Code. </span> 코드 데이터를 수집하기 위해 기존 작업은 주로 인터넷에서 오픈 소스 라이선스 코드를 크롤링합니다. 두 가지 주요 원본은 오픈 소스 라이선스 아래의 공개 코드 리포지토리(<em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.2">e.g.,</em> GitHub) 및 코드 관련 질문 응답 플랫폼(<em class="ltx_emph ltx_font_italic" id="S3.SS2.p6.1.3">e.g.,</em> StackOverflow)입니다. 구글은 빅쿼리 데이터셋 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib160" title="">160</a>]</cite>를 공개했는데, 대표적인 코드 데이터셋 역할을 하는 오픈소스 라이선스 코드 조각이 다양한 프로그래밍 언어로 상당수 포함되어 있다. CodeGen은 BigQuery 데이터셋의 하위 집합인 BIGQUERY <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>를 활용하여 CodeGen(CodeGen-Multi)의 다국어 버전을 학습시켰다.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p7.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p7.1.1">Others. <span> The Pile<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib161" title="">161</a>]</cite>는 책, 웹사이트, 코드, 과학 논문 및 소셜 미디어 플랫폼을 포함한 여러 소스의 800GB 이상의 데이터로 구성된 대규모, 다양하고 오픈 소스 텍스트 데이터 세트이다. 22개의 다양한 고품질 하위 집합으로 구성됩니다. Pile 데이터셋은 GPT-J(6B)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib165" title="">165</a>]</cite>, CodeGen(16B)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>, Megatron-Turing NLG(530B)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib113" title="">113</a>]</cite>와 같이 서로 다른 매개변수 척도를 가진 모델에 널리 사용된다. ROOTS<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib162" title="">162</a>]</cite>는 다양한 작은 데이터 세트(전체 1.61 TB의 텍스트)로 구성되며 59개의 다른 언어(자연어와 프로그래밍 언어를 포함)를 다루며 BLOOM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite> 학습에 사용되었다.</p>
</div>
<div id="S3.SS2.p8" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p8.1">실제로, 이는 일반적으로 단일 코퍼스 대신에 LLM들을 사전 트레이닝하기 위한 상이한 데이터 소스들의 혼합을 요구한다(도<a class="ltx_ref" href="#S3.F6" title="Figure 6 ‣ 3.4 Library Resource ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a> 참조). 따라서 기존 연구는 일반적으로 여러 기성 데이터 세트(<em class="ltx_emph ltx_font_italic" id="S3.SS2.p8.1.1">e.g.,</em> C4, OpenWebText, and the Pile)를 혼합한 다음 추가 처리를 수행하여 사전 훈련 코퍼스를 얻는다. 또한, 특정 응용 프로그램에 적응적인 LLM을 학습하기 위해서는 사전 학습 데이터에서 해당 정보를 풍부하게 하기 위해 관련 소스(<em class="ltx_emph ltx_font_italic" id="S3.SS2.p8.1.2">e.g.,</em> Wikipedia and BigQuery)에서 데이터를 추출하는 것도 중요하다. 기존 LLMs에서 사용되는 데이터 소스를 빠르게 참조하기 위해 세 가지 대표적인 LLMs의 사전 훈련 코퍼스를 제시한다:</p>
</div>
<div id="S3.SS2.p9" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS2.p9.1.m1.1"><semantics id="S3.SS2.p9.1.m1.1a"><mo id="S3.SS2.p9.1.m1.1.1" xref="S3.SS2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p9.1.m1.1b"><ci id="S3.SS2.p9.1.m1.1.1.cmml" xref="S3.SS2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p9.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS2.p9.1.1">GPT-3</em> (175B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>는 CommonCrawl <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib163" title="">163</a>]</cite>, WebText2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>, Books1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>, Books2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>, Wikipedia <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib159" title="">159</a>]</cite>를 포함한 300B 토큰의 혼합 데이터셋에 대해 학습하였다.</p>
</div>
<div id="S3.SS2.p10" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p10.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS2.p10.1.m1.1"><semantics id="S3.SS2.p10.1.m1.1a"><mo id="S3.SS2.p10.1.m1.1.1" xref="S3.SS2.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p10.1.m1.1b"><ci id="S3.SS2.p10.1.m1.1.1.cmml" xref="S3.SS2.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p10.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS2.p10.1.1">PaLM</em> (540B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>는 소셜 미디어 대화, 필터링된 웹 페이지, 책, Github, 다국어 Wikipedia 및 뉴스로부터 소싱되는 780B 토큰의 사전 트레이닝 데이터세트를 사용한다.</p>
</div>
<div id="S3.SS2.p11" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p11.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS2.p11.1.m1.1"><semantics id="S3.SS2.p11.1.m1.1a"><mo id="S3.SS2.p11.1.m1.1.1" xref="S3.SS2.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.1.m1.1b"><ci id="S3.SS2.p11.1.m1.1.1.cmml" xref="S3.SS2.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS2.p11.1.1">LLaMA</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>는 CommonCrawl, C4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>, Github, Wikipedia, books, ArXiv, StackExchange 등 다양한 소스에서 학습 데이터를 추출한다. LLaMA(6B) 및 LLaMA(13B)에 대한 트레이닝 데이터 크기는 1.0T 토큰이고, LLaMA(32B) 및 LLaMA(65B)에 대해 1.4T 토큰이 사용된다.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III:</span>A detailed list of available collections for instruction tuning.</figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T3.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Categories</span></td>
<td id="S3.T3.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Collections</span></td>
<td id="S3.T3.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Time</span></td>
<td id="S3.T3.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">#Examples</span></td>
</tr>
<tr id="S3.T3.1.2" class="ltx_tr">
<td id="S3.T3.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="7"><span id="S3.T3.1.2.1.1" class="ltx_text" style="font-size:80%;">Task</span></td>
<td id="S3.T3.1.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.2.2.1" class="ltx_text" style="font-size:80%;">Nat. Inst.&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib166" title="" class="ltx_ref">166</a><span id="S3.T3.1.2.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.2.3.1" class="ltx_text" style="font-size:80%;">Apr-2021</span></td>
<td id="S3.T3.1.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.2.4.1" class="ltx_text" style="font-size:80%;">193K</span></td>
</tr>
<tr id="S3.T3.1.3" class="ltx_tr">
<td id="S3.T3.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.3.1.1" class="ltx_text" style="font-size:80%;">FLAN&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.3.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib67" title="" class="ltx_ref">67</a><span id="S3.T3.1.3.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.3.2.1" class="ltx_text" style="font-size:80%;">Sep-2021</span></td>
<td id="S3.T3.1.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.3.3.1" class="ltx_text" style="font-size:80%;">4.4M</span></td>
</tr>
<tr id="S3.T3.1.4" class="ltx_tr">
<td id="S3.T3.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.4.1.1" class="ltx_text" style="font-size:80%;">P3&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib167" title="" class="ltx_ref">167</a><span id="S3.T3.1.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.4.2.1" class="ltx_text" style="font-size:80%;">Oct-2021</span></td>
<td id="S3.T3.1.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.4.3.1" class="ltx_text" style="font-size:80%;">12.1M</span></td>
</tr>
<tr id="S3.T3.1.5" class="ltx_tr">
<td id="S3.T3.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.5.1.1" class="ltx_text" style="font-size:80%;">Super Nat. Inst.&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.5.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib88" title="" class="ltx_ref">88</a><span id="S3.T3.1.5.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.5.2.1" class="ltx_text" style="font-size:80%;">Apr-2022</span></td>
<td id="S3.T3.1.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.5.3.1" class="ltx_text" style="font-size:80%;">5M</span></td>
</tr>
<tr id="S3.T3.1.6" class="ltx_tr">
<td id="S3.T3.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.6.1.1" class="ltx_text" style="font-size:80%;">MVPCorpus&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.6.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib168" title="" class="ltx_ref">168</a><span id="S3.T3.1.6.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.6.2.1" class="ltx_text" style="font-size:80%;">Jun-2022</span></td>
<td id="S3.T3.1.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.6.3.1" class="ltx_text" style="font-size:80%;">41M</span></td>
</tr>
<tr id="S3.T3.1.7" class="ltx_tr">
<td id="S3.T3.1.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.7.1.1" class="ltx_text" style="font-size:80%;">xP3&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.7.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib94" title="" class="ltx_ref">94</a><span id="S3.T3.1.7.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.7.2.1" class="ltx_text" style="font-size:80%;">Nov-2022</span></td>
<td id="S3.T3.1.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.7.3.1" class="ltx_text" style="font-size:80%;">81M</span></td>
</tr>
<tr id="S3.T3.1.8" class="ltx_tr">
<td id="S3.T3.1.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.8.1.1" class="ltx_text" style="font-size:80%;">OIG</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.8.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib169" title="" class="ltx_ref">169</a><span id="S3.T3.1.8.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.8.2.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
<td id="S3.T3.1.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.8.3.1" class="ltx_text" style="font-size:80%;">43M</span></td>
</tr>
<tr id="S3.T3.1.9" class="ltx_tr">
<td id="S3.T3.1.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="5"><span id="S3.T3.1.9.1.1" class="ltx_text" style="font-size:80%;">Chat</span></td>
<td id="S3.T3.1.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.9.2.1" class="ltx_text" style="font-size:80%;">HH-RLHF&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.9.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib170" title="" class="ltx_ref">170</a><span id="S3.T3.1.9.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.9.3.1" class="ltx_text" style="font-size:80%;">Apr-2022</span></td>
<td id="S3.T3.1.9.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.9.4.1" class="ltx_text" style="font-size:80%;">160K</span></td>
</tr>
<tr id="S3.T3.1.10" class="ltx_tr">
<td id="S3.T3.1.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.10.1.1" class="ltx_text" style="font-size:80%;">HC3&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.10.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib171" title="" class="ltx_ref">171</a><span id="S3.T3.1.10.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.10.2.1" class="ltx_text" style="font-size:80%;">Jan-2023</span></td>
<td id="S3.T3.1.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.10.3.1" class="ltx_text" style="font-size:80%;">87K</span></td>
</tr>
<tr id="S3.T3.1.11" class="ltx_tr">
<td id="S3.T3.1.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.11.1.1" class="ltx_text" style="font-size:80%;">ShareGPT&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.11.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib148" title="" class="ltx_ref">148</a><span id="S3.T3.1.11.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.11.2.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
<td id="S3.T3.1.11.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.11.3.1" class="ltx_text" style="font-size:80%;">90K</span></td>
</tr>
<tr id="S3.T3.1.12" class="ltx_tr">
<td id="S3.T3.1.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.12.1.1" class="ltx_text" style="font-size:80%;">Dolly&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.12.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib172" title="" class="ltx_ref">172</a><span id="S3.T3.1.12.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.12.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.12.2.1" class="ltx_text" style="font-size:80%;">Apr-2023</span></td>
<td id="S3.T3.1.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.12.3.1" class="ltx_text" style="font-size:80%;">15K</span></td>
</tr>
<tr id="S3.T3.1.13" class="ltx_tr">
<td id="S3.T3.1.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.13.1.1" class="ltx_text" style="font-size:80%;">OpenAssistant&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.13.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib173" title="" class="ltx_ref">173</a><span id="S3.T3.1.13.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.13.2.1" class="ltx_text" style="font-size:80%;">Apr-2023</span></td>
<td id="S3.T3.1.13.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.13.3.1" class="ltx_text" style="font-size:80%;">161K</span></td>
</tr>
<tr id="S3.T3.1.14" class="ltx_tr">
<td id="S3.T3.1.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="5"><span id="S3.T3.1.14.1.1" class="ltx_text" style="font-size:80%;">Synthetic</span></td>
<td id="S3.T3.1.14.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.14.2.1" class="ltx_text" style="font-size:80%;">Self-Instruct&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.14.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib143" title="" class="ltx_ref">143</a><span id="S3.T3.1.14.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.14.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.14.3.1" class="ltx_text" style="font-size:80%;">Dec-2022</span></td>
<td id="S3.T3.1.14.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.14.4.1" class="ltx_text" style="font-size:80%;">82K</span></td>
</tr>
<tr id="S3.T3.1.15" class="ltx_tr">
<td id="S3.T3.1.15.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.15.1.1" class="ltx_text" style="font-size:80%;">Alpaca&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.15.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib137" title="" class="ltx_ref">137</a><span id="S3.T3.1.15.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.15.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.15.2.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
<td id="S3.T3.1.15.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.15.3.1" class="ltx_text" style="font-size:80%;">52K</span></td>
</tr>
<tr id="S3.T3.1.16" class="ltx_tr">
<td id="S3.T3.1.16.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.16.1.1" class="ltx_text" style="font-size:80%;">Guanaco&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.16.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib174" title="" class="ltx_ref">174</a><span id="S3.T3.1.16.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.16.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.16.2.1" class="ltx_text" style="font-size:80%;">Mar-2023</span></td>
<td id="S3.T3.1.16.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.16.3.1" class="ltx_text" style="font-size:80%;">535K</span></td>
</tr>
<tr id="S3.T3.1.17" class="ltx_tr">
<td id="S3.T3.1.17.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.17.1.1" class="ltx_text" style="font-size:80%;">Baize&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.17.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib175" title="" class="ltx_ref">175</a><span id="S3.T3.1.17.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.17.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.17.2.1" class="ltx_text" style="font-size:80%;">Apr-2023</span></td>
<td id="S3.T3.1.17.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.17.3.1" class="ltx_text" style="font-size:80%;">158K</span></td>
</tr>
<tr id="S3.T3.1.18" class="ltx_tr">
<td id="S3.T3.1.18.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T3.1.18.1.1" class="ltx_text" style="font-size:80%;">BELLE&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.1.18.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib176" title="" class="ltx_ref">176</a><span id="S3.T3.1.18.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T3.1.18.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.18.2.1" class="ltx_text" style="font-size:80%;">Apr-2023</span></td>
<td id="S3.T3.1.18.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T3.1.18.3.1" class="ltx_text" style="font-size:80%;">1.5M</span></td>
</tr>
</tbody></table>
</figure>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV:</span>A list of available collections for alignment.</figcaption>
<table id="S3.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T4.1.1" class="ltx_tr">
<td id="S3.T4.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Dataset</span></td>
<td id="S3.T4.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Release Time</span></td>
<td id="S3.T4.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">#Examples</span></td>
</tr>
<tr id="S3.T4.1.2" class="ltx_tr">
<td id="S3.T4.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T4.1.2.1.1" class="ltx_text" style="font-size:80%;">Summarize from Feedback&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.1.2.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib129" title="" class="ltx_ref">129</a><span id="S3.T4.1.2.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T4.1.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.2.2.1" class="ltx_text" style="font-size:80%;">Sep-2020</span></td>
<td id="S3.T4.1.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.2.3.1" class="ltx_text" style="font-size:80%;">193K</span></td>
</tr>
<tr id="S3.T4.1.3" class="ltx_tr">
<td id="S3.T4.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T4.1.3.1.1" class="ltx_text" style="font-size:80%;">SHP&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.1.3.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib177" title="" class="ltx_ref">177</a><span id="S3.T4.1.3.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T4.1.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.3.2.1" class="ltx_text" style="font-size:80%;">Oct-2021</span></td>
<td id="S3.T4.1.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.3.3.1" class="ltx_text" style="font-size:80%;">385K</span></td>
</tr>
<tr id="S3.T4.1.4" class="ltx_tr">
<td id="S3.T4.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T4.1.4.1.1" class="ltx_text" style="font-size:80%;">WebGPT Comparisons&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.1.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib81" title="" class="ltx_ref">81</a><span id="S3.T4.1.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T4.1.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.4.2.1" class="ltx_text" style="font-size:80%;">Dec-2021</span></td>
<td id="S3.T4.1.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.4.3.1" class="ltx_text" style="font-size:80%;">19K</span></td>
</tr>
<tr id="S3.T4.1.5" class="ltx_tr">
<td id="S3.T4.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T4.1.5.1.1" class="ltx_text" style="font-size:80%;">Stack Exchange Preferences&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.1.5.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib178" title="" class="ltx_ref">178</a><span id="S3.T4.1.5.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T4.1.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.5.2.1" class="ltx_text" style="font-size:80%;">Dec-2021</span></td>
<td id="S3.T4.1.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.5.3.1" class="ltx_text" style="font-size:80%;">10M</span></td>
</tr>
<tr id="S3.T4.1.6" class="ltx_tr">
<td id="S3.T4.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T4.1.6.1.1" class="ltx_text" style="font-size:80%;">HH-RLHF&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.1.6.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib170" title="" class="ltx_ref">170</a><span id="S3.T4.1.6.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T4.1.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.6.2.1" class="ltx_text" style="font-size:80%;">Apr-2022</span></td>
<td id="S3.T4.1.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.6.3.1" class="ltx_text" style="font-size:80%;">169K</span></td>
</tr>
<tr id="S3.T4.1.7" class="ltx_tr">
<td id="S3.T4.1.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T4.1.7.1.1" class="ltx_text" style="font-size:80%;">Sandbox Alignment Data&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.1.7.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib179" title="" class="ltx_ref">179</a><span id="S3.T4.1.7.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T4.1.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.7.2.1" class="ltx_text" style="font-size:80%;">May-2023</span></td>
<td id="S3.T4.1.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.7.3.1" class="ltx_text" style="font-size:80%;">169K</span></td>
</tr>
<tr id="S3.T4.1.8" class="ltx_tr">
<td id="S3.T4.1.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T4.1.8.1.1" class="ltx_text" style="font-size:80%;">CValues&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.1.8.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib180" title="" class="ltx_ref">180</a><span id="S3.T4.1.8.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T4.1.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.8.2.1" class="ltx_text" style="font-size:80%;">Jul-2023</span></td>
<td id="S3.T4.1.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.8.3.1" class="ltx_text" style="font-size:80%;">145K</span></td>
</tr>
<tr id="S3.T4.1.9" class="ltx_tr">
<td id="S3.T4.1.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S3.T4.1.9.1.1" class="ltx_text" style="font-size:80%;">PKU-SafeRLHF&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.1.9.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib181" title="" class="ltx_ref">181</a><span id="S3.T4.1.9.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T4.1.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.9.2.1" class="ltx_text" style="font-size:80%;">Oct-2023</span></td>
<td id="S3.T4.1.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S3.T4.1.9.3.1" class="ltx_text" style="font-size:80%;">330K</span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span><span id="S3.SS3.1.1" class="ltx_text ltx_font_italic">Commonly Used Datasets for Fine-tuning</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.p1.1">사전 훈련 후 모델 용량을 향상시키기 위해 추가 미세 조정 LLM이 필요하며, 이는 종종 명령어 튜닝(지도 미세 조정) 및 정렬 튜닝의 두 가지 주요 단계를 포함한다. 이 섹션에서는 주로 두 가지 종류의 튜닝 접근법에 대한 관련 사용 가능한 데이터 세트에 대해 논의하는 데 중점을 두며, 더 많은 알고리즘 세부 사항은 섹션 <a class="ltx_ref" href="#S5" title="5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>에서 찾을 수 있다.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Instruction Tuning Datasets</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">사전 훈련 후 명령어 튜닝(<em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p1.1.1">a.k.a.,</em>supervised fine-tuning)은 LLMs의 특정 능력을 향상시키거나 해제하기 위한 중요한 방법이다(<em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p1.1.2">e.g.,</em> instruction following). 이 부분에서, 우리는 명령어 튜닝을 위해 널리 사용되는 몇 가지 데이터 세트를 소개하고, 포맷된 명령어 인스턴스의 구성 방법에 따라 NLP 태스크 데이터 세트, 일일 채팅 데이터 세트 및 합성 데이터 세트의 세 가지 주요 유형으로 분류한다. 우리는 표 <a class="ltx_ref" href="#S3.T3" title="TABLE III ‣ 3.2 Commonly Used Corpora for Pre-training ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">III</span></a>에서 그들의 세부사항을 보여준다.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS3.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.SSS1.p2.1.1">NLP Task Datasets. </span> 이러한 종류의 데이터 세트는 해당 자연어 작업 설명과 함께 수집된 NLP 작업 데이터 세트(<em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p2.1.2">e.g.,</em> 텍스트 분류 및 요약)를 기반으로 포맷된다. 이 범주에서 P3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib182" title="">182</a>]</cite>와 FLAN<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>, <a class="ltx_ref" href="#bib.bib183" title="">183</a>]</cite>는 명령어 튜닝을 위해 널리 사용되는 두 데이터 세트이다.</p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p3.1.m1.1"><semantics id="S3.SS3.SSS1.p3.1.m1.1a"><mo id="S3.SS3.SSS1.p3.1.m1.1.1" xref="S3.SS3.SSS1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.1.m1.1b"><ci id="S3.SS3.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p3.1.1">P3</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib182" title="">182</a>]</cite>는 170개의 영어 NLP 데이터셋과 2,052개의 영어 프롬프트 템플릿으로 구성되며, 여기서 각 데이터 예의 입력과 출력은 훈련 인스턴스를 구성하기 위한 특정 프롬프트 템플릿으로 포맷되었다.</p>
</div>
<div id="S3.SS3.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.1.m1.1"><semantics id="S3.SS3.SSS1.p4.1.m1.1a"><mo id="S3.SS3.SSS1.p4.1.m1.1.1" xref="S3.SS3.SSS1.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p4.1.m1.1b"><ci id="S3.SS3.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p4.1.1">FLAN</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>는 원래 버전에서 널리 사용되는 62개의 NLP 벤치마크로 구성된다. 최근에는 Muffin<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>, NIV2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib88" title="">88</a>]</cite>, T0-SF<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>, CoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>, <a class="ltx_ref" href="#bib.bib185" title="">185</a>, <a class="ltx_ref" href="#bib.bib186" title="">186</a>]</cite> 등의 추가 명령어 데이터셋을 혼합하여 FLAN을 확장하는 FLAN-v2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib183" title="">183</a>]</cite>도 제안한다. 머핀은 원래 FLAN에서 62개의 태스크와 대화 및 코드 합성 태스크를 포함하여 추가로 26개의 태스크를 포함한다. T0-SF는 Muffin과의 중복을 보장하면서 T0<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>로부터 추출된다. NIV2는 Natural-Instructions v2 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib88" title="">88</a>]</cite>, CoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>, <a class="ltx_ref" href="#bib.bib185" title="">185</a>, <a class="ltx_ref" href="#bib.bib186" title="">186</a>]</cite>는 9개의 추론 태스크와 해당 연쇄 사상 프롬프트 및 출력의 조합이다.</p>
</div>
<div id="S3.SS3.SSS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS3.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.SSS1.p5.1.1">Daily Chat Datasets. 이러한 종류의 데이터 세트는 쿼리가 인간에 의해 제기되고 응답이 주로 인간 라벨러 또는 LLMs에 의해 생성되는 실제 사용자 대화를 기반으로 구성된다(<em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p5.1.2">e.g.,</em> ChatGPT, GPT-4). 대화 유형에는 개방형 생성, 질문 응답, 브레인스토밍 및 채팅이 포함됩니다. 이 범주에서 ShareGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>, OpenAssistant <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib173" title="">173</a>]</cite> 및 Dolly <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib172" title="">172</a>]</cite>는 LLM 미세 조정을 위해 일반적으로 사용되는 세 가지 데이터 세트이다.</p>
</div>
<div id="S3.SS3.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p6.1.m1.1"><semantics id="S3.SS3.SSS1.p6.1.m1.1a"><mo id="S3.SS3.SSS1.p6.1.m1.1.1" xref="S3.SS3.SSS1.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p6.1.m1.1b"><ci id="S3.SS3.SSS1.p6.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p6.1.1">ShareGPT</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>는 사용자가 ShareGPT API를 통해 ChatGPT 또는 GPT-4와 자신의 대화를 업로드할 수 있는 데이터 수집 플랫폼에서 수집된다. 현재 이 데이터 세트는 인간의 실제 지시 또는 문의와 ChatGPT의 응답을 포함하여 약 90,000개의 대화로 구성된다.</p>
</div>
<div id="S3.SS3.SSS1.p7" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p7.1.m1.1"><semantics id="S3.SS3.SSS1.p7.1.m1.1a"><mo id="S3.SS3.SSS1.p7.1.m1.1.1" xref="S3.SS3.SSS1.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p7.1.m1.1b"><ci id="S3.SS3.SSS1.p7.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p7.1.1">OpenAssistant</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib173" title="">173</a>]</cite>는 인간과 AI 어시스턴트 사이의 66,497개의 실세계 대화 트리를 포함하는 다국어 코퍼스이다. 각 대화 트리는 여러 개의 노드로 구성되며, 각 노드는 대화에서 역할에 의해 생성된 정보를 나타낸다. 35개 언어에 걸쳐 있으며 461,292개의 수동으로 주석이 달린 응답 품질 등급이 포함되어 있습니다.</p>
</div>
<div id="S3.SS3.SSS1.p8" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p8.1.m1.1"><semantics id="S3.SS3.SSS1.p8.1.m1.1a"><mo id="S3.SS3.SSS1.p8.1.m1.1.1" xref="S3.SS3.SSS1.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p8.1.m1.1b"><ci id="S3.SS3.SSS1.p8.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p8.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p8.1.1">Dolly</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib172" title="">172</a>]</cite>는 Databricks로부터 15,000개의 인간 생성 데이터 인스턴스(prompt-response pairs)를 포함하는 영어 데이터셋이다. 이 데이터 세트는 브레인스토밍, 분류, 폐쇄형 도서 품질 보증, 생성, 정보 추출, 개방형 도서 품질 보증 및 요약을 포함하여 InstructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>에 요약된 7개 영역을 다룬다.</p>
</div>
<div id="S3.SS3.SSS1.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS3.SSS1.p9.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.SSS1.p9.1.1">Synthetic Datasets. </span> 이러한 종류의 데이터 세트는 일반적으로 미리 정의된 지침 규칙 또는 메서드를 기반으로 LLMs에 명령하여 구성됩니다. 이 범주에서 Self-Instruct-52K <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>, Alpaca <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite> 및 Baize <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib175" title="">175</a>]</cite>는 LLMs에 일반적으로 사용되는 세 가지 합성 데이터 세트이다.</p>
</div>
<div id="S3.SS3.SSS1.p10" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p10.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p10.1.m1.1"><semantics id="S3.SS3.SSS1.p10.1.m1.1a"><mo id="S3.SS3.SSS1.p10.1.m1.1.1" xref="S3.SS3.SSS1.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p10.1.m1.1b"><ci id="S3.SS3.SSS1.p10.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p10.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p10.1.1">Self-Instruct-52K</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>는 self-instruct <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite> 메소드를 통해 생성된 명령어 데이터셋으로 52,000개의 명령어를 가진 82,000개의 인스턴스로 구성된다. 구체적으로 175개의 시드 인스턴스를 구성한 후 LLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>를 반복적으로 프롬프트하여 무작위로 선택된 8개의 명령어를 기준으로 추가 명령어를 합성한다. 이어서, LLM은 합성 명령들에 기초하여 인스턴스 입력들 및 그들의 대응하는 출력들을 생성하도록 추가로 지시되고, 최종적으로 Self-Instruct-52K 데이터세트를 획득한다.</p>
</div>
<div id="S3.SS3.SSS1.p11" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p11.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p11.1.m1.1"><semantics id="S3.SS3.SSS1.p11.1.m1.1a"><mo id="S3.SS3.SSS1.p11.1.m1.1.1" xref="S3.SS3.SSS1.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p11.1.m1.1b"><ci id="S3.SS3.SSS1.p11.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p11.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p11.1.1">Alpaca</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite> 역시 self-instruct <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite> 메소드에 기반한 합성 데이터셋이다. Self-Instruct-52K의 175개 시드 데이터 세트에 대한 <span class="ltx_text ltx_font_typewriter" id="S3.SS3.SSS1.p11.1.2">text-davinci-003</span> 모델을 활용하여 52,000개의 새로운 명령어와 해당 입력 및 출력을 얻는다. 더욱이, 예시의 60%는 최종 데이터세트에서 입력 부분이 없는 순수한 명령어들이다.</p>
</div>
<div id="S3.SS3.SSS1.p12" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p12.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p12.1.m1.1"><semantics id="S3.SS3.SSS1.p12.1.m1.1a"><mo id="S3.SS3.SSS1.p12.1.m1.1.1" xref="S3.SS3.SSS1.p12.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p12.1.m1.1b"><ci id="S3.SS3.SSS1.p12.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p12.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p12.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS1.p12.1.1">Baize</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib175" title="">175</a>]</cite>는 111.5K 인스턴스를 포함하는 ChatGPT를 사용하여 구성된 영어 멀티턴 대화 코퍼스이다. Baize를 만들기 위해, “self-chat” <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib175" title="">175</a>]</cite>라는 방법이 목적이며, 여기서 ChatGPT는 사용자와 AI 어시스턴트의 역할을 번갈아 맡아 대화 형식으로 정보를 생성한다.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Alignment Datasets</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">명령어 튜닝과는 별도로 LLMs을 인간 값 및 선호도와 정렬하기 위한 고품질 데이터 세트를 구성하는 것이 중요하다. 이 섹션에서는 HH-RLHF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib170" title="">170</a>]</cite>, SHP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib177" title="">177</a>]</cite>, PKU-SafeRLHF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib181" title="">181</a>]</cite>, Stack Exchange Preferences <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib178" title="">178</a>]</cite> 및 Sandbox Alignment Data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib179" title="">179</a>]</cite>를 포함하여 정렬 조정을 위해 널리 사용되는 여러 데이터 세트를 소개한다. 우리는 표 <a class="ltx_ref" href="#S3.T4" title="TABLE IV ‣ 3.2 Commonly Used Corpora for Pre-training ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">IV</span></a>에서 그들의 세부사항을 보여준다.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS2.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p2.1.m1.1"><semantics id="S3.SS3.SSS2.p2.1.m1.1a"><mo id="S3.SS3.SSS2.p2.1.m1.1.1" xref="S3.SS3.SSS2.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.1.m1.1b"><ci id="S3.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p2.1.1">HH-RLHF</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib170" title="">170</a>]</cite>는 약 169K개의 인스턴스로 구성되며, 각각 LLM의 유용성과 무해성에 초점을 맞춘 두 부분으로 나눌 수 있다. 각 인스턴스는 도움, 조언 또는 작업 완료에 대한 크라우드 워커와 채팅 모델 간의 개방형 대화입니다. 채팅 모델은 각 사용자 질의에 대해 두 개의 응답을 제공하며, 더 유용하거나 유해한 응답이 주석으로 선택될 것이다.</p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.1.m1.1"><semantics id="S3.SS3.SSS2.p3.1.m1.1a"><mo id="S3.SS3.SSS2.p3.1.m1.1.1" xref="S3.SS3.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.1.m1.1b"><ci id="S3.SS3.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p3.1.1">SHP</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib177" title="">177</a>]</cite>는 응답의 유용성에 초점을 맞춘다. 그것은 요리에서 법률 조언에 이르는 주제에 걸쳐 18개의 다양한 주제 영역에 걸쳐 질문/지침에 대한 응답보다 385K의 집단적 인간 선호도로 구성된다. 각 인스턴스는 질문이나 지시가 포함된 레딧 게시물과 한 쌍의 최상위 댓글이며, 그 중 하나는 레딧 사용자에 의해 더 바람직한 것으로 간주되고 다른 하나는 덜 도움이 되는 것으로 간주된다. HH-RLHF<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib170" title="">170</a>]</cite>와 달리 SHP의 데이터는 자연 발생 및 인간 작성 응답으로 구성된다.</p>
</div>
<div id="S3.SS3.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p4.1.m1.1"><semantics id="S3.SS3.SSS2.p4.1.m1.1a"><mo id="S3.SS3.SSS2.p4.1.m1.1.1" xref="S3.SS3.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p4.1.m1.1b"><ci id="S3.SS3.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p4.1.1">PKU-SafeRLHF</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib181" title="">181</a>]</cite>는 전문가 비교 데이터의 330K개 이상의 인스턴스를 포괄하여 유용성과 무해성에 집중한다. 데이터세트의 각 인스턴스는 질문과 두 개의 응답을 포함하며, 각 응답에 대한 안전 라벨과 유용성과 무해성에 따라 두 응답 사이의 두 개의 선호도 주석이 함께 표시된다. 응답의 무해성은 14개의 모든 피해 범주에 걸쳐 위험 중립으로 분류를 나타내는 반면, 응답의 유용성은 질문 해결의 효율성을 기반으로 평가된다.</p>
</div>
<div id="S3.SS3.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS2.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p5.1.m1.1"><semantics id="S3.SS3.SSS2.p5.1.m1.1a"><mo id="S3.SS3.SSS2.p5.1.m1.1.1" xref="S3.SS3.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p5.1.m1.1b"><ci id="S3.SS3.SSS2.p5.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p5.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p5.1.1">Stack Exchange Preferences</span><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib178" title="">178</a>]</cite> focuses on the helpfulness of answers. 스택 오버플로우의 약 10M 질문과 답변으로 구성되어 있습니다. 각 인스턴스는 질문과 두 개 이상의 대응 답변으로 구성된다. 각 답변에는 투표에 따라 계산된 점수와 선택 여부를 나타내는 레이블로 주석이 달린다.</p>
</div>
<div id="S3.SS3.SSS2.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p6.1.m1.1"><semantics id="S3.SS3.SSS2.p6.1.m1.1a"><mo id="S3.SS3.SSS2.p6.1.m1.1.1" xref="S3.SS3.SSS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p6.1.m1.1b"><ci id="S3.SS3.SSS2.p6.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p6.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p6.1.1">Sandbox Alignment Data</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib179" title="">179</a>]</cite>는 사람이 아닌 LLMs로부터의 피드백을 포함하는 정렬 데이터셋이다. SANDBOX라는 가상 상호작용 환경에서 나온 것으로, 이 모델은 다른 모델과의 사회적 상호작용을 시뮬레이션하고 다른 모델의 피드백에 따라 응답을 수정한다. 데이터 세트에는 169K 인스턴스가 포함되어 있으며 각 인스턴스는 사회적 쿼리, 여러 응답 및 다른 모델의 해당 등급으로 구성된다.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span><span id="S3.SS4.1.1" class="ltx_text ltx_font_italic">Library Resource</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p1.1">이 부분에서는 LLM 개발을 위한 일련의 이용 가능한 라이브러리에 대해 간략하게 소개한다.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><mo id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><ci id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.1">Transformers</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib187" title="">187</a>]</cite>는 Hugging Face에 의해 개발 및 유지되는 Transformer 아키텍처를 사용하는 빌딩 모델용 오픈 소스 Python 라이브러리이다. 간편하고 사용자 친화적인 API가 있어 다양한 사전 훈련 모델을 쉽게 사용하고 커스터마이징할 수 있습니다. 모델과 알고리즘을 정기적으로 업데이트하고 개선하는 사용자와 개발자의 크고 활발한 커뮤니티가 있는 강력한 라이브러리입니다.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p3.1.m1.1"><semantics id="S3.SS4.p3.1.m1.1a"><mo id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><ci id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.1">DeepSpeed</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite>는 Microsoft에 의해 개발된 딥러닝 최적화 라이브러리(compatible with PyTorch)이며, 이는 MT-NLG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib113" title="">113</a>]</cite> 및 BLOOM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>와 같은 다수의 LLMs를 학습하는데 사용되어 왔다. 메모리 최적화(ZeRO 기법, Gradient Checkpointing), 파이프라인 병렬화 등 분산 학습을 위한 다양한 최적화 기법의 지원을 제공한다.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p4.1.m1.1"><semantics id="S3.SS4.p4.1.m1.1a"><mo id="S3.SS4.p4.1.m1.1.1" xref="S3.SS4.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.1.m1.1b"><ci id="S3.SS4.p4.1.m1.1.1.cmml" xref="S3.SS4.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p4.1.1">Megatron-LM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>, <a class="ltx_ref" href="#bib.bib76" title="">76</a>, <a class="ltx_ref" href="#bib.bib77" title="">77</a>]</cite>는 NVIDIA에서 대규모 언어 모델을 훈련하기 위해 개발한 딥러닝 라이브러리이다. 또한 모델 및 데이터 병렬성, 혼합 정밀도 훈련, 플래시 어텐션 등 분산 훈련을 위한 풍부한 최적화 기법을 제공한다. 이러한 최적화 기술은 훈련 효율성과 속도를 크게 향상시켜 GPU 전반에 걸쳐 효율적인 분산 훈련을 가능하게 할 수 있다.</p>
</div>
<div id="S3.SS4.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p5.1.m1.1"><semantics id="S3.SS4.p5.1.m1.1a"><mo id="S3.SS4.p5.1.m1.1.1" xref="S3.SS4.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.1.m1.1b"><ci id="S3.SS4.p5.1.m1.1.1.cmml" xref="S3.SS4.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p5.1.1">JAX</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib188" title="">188</a>]</cite>는 Google에서 개발한 고성능 기계 학습 알고리즘을 위한 Python 라이브러리로, 사용자가 하드웨어 가속으로 어레이에 대한 계산을 쉽게 수행할 수 있도록 한다(<em class="ltx_emph ltx_font_italic" id="S3.SS4.p5.1.2">e.g.,</em> GPU 또는 TPU). 다양한 장치에서 효율적인 연산을 가능하게 하고 자동 미분, 정시 컴파일 등 여러 가지 기능을 지원한다.</p>
</div>
<div id="S3.SS4.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p6.1.m1.1"><semantics id="S3.SS4.p6.1.m1.1a"><mo id="S3.SS4.p6.1.m1.1.1" xref="S3.SS4.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.1.m1.1b"><ci id="S3.SS4.p6.1.m1.1.1.cmml" xref="S3.SS4.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p6.1.1">Colossal-AI</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib189" title="">189</a>]</cite>는 HPC-AI Tech에서 대규모 AI 모델을 훈련하기 위해 개발한 딥러닝 라이브러리이다. PyTorch를 기반으로 구현되며 풍부한 병렬 훈련 전략 모음을 지원합니다. 또한, PatrickStar<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib190" title="">190</a>]</cite>에서 제안한 방법으로 이기종 메모리 관리를 최적화할 수도 있다. 최근 ColossalChat<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib140" title="">140</a>]</cite>라는 ChatGPT 유사 모델이 LLaMA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>를 기반으로 Colossal-AI를 사용하여 개발된 두 가지 버전(7B와 13B)으로 공개적으로 출시되었다.</p>
</div>
<div id="S3.SS4.p7" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p7.1.m1.1"><semantics id="S3.SS4.p7.1.m1.1a"><mo id="S3.SS4.p7.1.m1.1.1" xref="S3.SS4.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.1.m1.1b"><ci id="S3.SS4.p7.1.m1.1.1.cmml" xref="S3.SS4.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p7.1.1">BMTrain</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib191" title="">191</a>]</cite>는 OpenBMB에서 배포 방식으로 대규모 매개 변수를 가진 학습 모델을 위해 개발한 효율적인 라이브러리이며, 이는 코드의 단순성, 낮은 리소스 및 고가용성을 강조한다. BMTrain은 이미 여러 일반적인 LLMs(<em class="ltx_emph ltx_font_italic" id="S3.SS4.p7.1.2">e.g.,</em> Flan-T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite> and GLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>)를 자신의 ModelCenter에 통합했으며, 여기서 개발자는 이러한 모델을 직접 사용할 수 있다.</p>
</div>
<div id="S3.SS4.p8" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p8.1.m1.1"><semantics id="S3.SS4.p8.1.m1.1a"><mo id="S3.SS4.p8.1.m1.1.1" xref="S3.SS4.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p8.1.m1.1b"><ci id="S3.SS4.p8.1.m1.1.1.cmml" xref="S3.SS4.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p8.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p8.1.1">FastMoE</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib192" title="">192</a>]</cite>는 MoE(<em class="ltx_emph ltx_font_italic" id="S3.SS4.p8.1.2">i.e.,</em> mixture-of-experts) 모델에 대한 전문 트레이닝 라이브러리이다. PyTorch를 기반으로 개발되었으며, 디자인에서 효율성과 사용자 친화성을 모두 우선시합니다. FastMoE는 Transformer 모델을 MoE 모델로 전달하는 과정을 단순화하고 훈련 시 데이터 병렬성과 모델 병렬성을 모두 지원한다.</p>
</div>
<div id="S3.SS4.p9" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p9.1.m1.1"><semantics id="S3.SS4.p9.1.m1.1a"><mo id="S3.SS4.p9.1.m1.1.1" xref="S3.SS4.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p9.1.m1.1b"><ci id="S3.SS4.p9.1.m1.1.1.cmml" xref="S3.SS4.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p9.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p9.1.1">vLLM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib193" title="">193</a>]</cite>는 LLM 추론 및 서빙을 위한 빠르고 메모리 효율적이며 사용하기 쉬운 라이브러리이다. 빠른 추론을 가능하게 하기 위해 높은 서빙 처리량, PagedAttention <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib193" title="">193</a>]</cite>, 연속 배칭 및 최적화된 CUDA 커널을 사용하여 효과적인 주의 메모리 관리로 특별히 최적화된다. 또한, vLLM은 다양한 디코딩 알고리즘, 텐서 병렬성 및 스트리밍 출력을 지원한다. 다른 시스템과의 통합을 쉽게 하기 위해 vLLM은 HuggingFace 모델의 사용에 친화적이며 OpenAI 호환 API 서버도 제공한다.</p>
</div>
<div id="S3.SS4.p10" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p10.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p10.1.m1.1"><semantics id="S3.SS4.p10.1.m1.1a"><mo id="S3.SS4.p10.1.m1.1.1" xref="S3.SS4.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p10.1.m1.1b"><ci id="S3.SS4.p10.1.m1.1.1.cmml" xref="S3.SS4.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p10.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p10.1.1">DeepSpeed-MII</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib194" title="">194</a>]</cite>는 DeepSpeed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite>에 의해 개발된 메모리 효율적인 Python 라이브러리이기도 하다. 높은 처리량, 낮은 대기 시간 및 비용 효율성을 우선시하여 LLMs 추론을 민주화하는 것을 목표로 한다. DeepSpeed-MII는 차단된 KV 캐싱, 연속 배치, 동적 분할퓨즈 및 고성능 CUDA 커널의 4가지 필수 기술을 활용하여 가속화된 텍스트 생성 추론을 달성한다. 현재 LLaMA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>, Mistral<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib195" title="">195</a>]</cite>, OPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite> 등 세 가지 인기 모델 아키텍처에 걸쳐 13,000개 이상의 모델을 지원한다.</p>
</div>
<div id="S3.SS4.p11" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p11.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS4.p11.1.m1.1"><semantics id="S3.SS4.p11.1.m1.1a"><mo id="S3.SS4.p11.1.m1.1.1" xref="S3.SS4.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p11.1.m1.1b"><ci id="S3.SS4.p11.1.m1.1.1.cmml" xref="S3.SS4.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p11.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS4.p11.1.1">DeepSpeed-Chat</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib196" title="">196</a>]</cite>는 모델 트레이닝 동안 완전한 RLHF 프로세스의 통합을 가능하게 하는 빠르고 비용 효율적이며 사용하기 쉬운 시스템 프레임워크이다. 본 논문에서는 ChatGPT 유사 모델에 대한 학습 및 추론 과정을 단순화하고, 간단한 스크립트를 사용하여 여러 학습 또는 추론 단계를 구현할 수 있도록 한다. (2) InstructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>의 학습 모드를 복제하고, 세 가지 학습 단계(<em class="ltx_emph ltx_font_italic" id="S3.SS4.p11.1.2">i.e.,</em> SFT, 보상 모델 미세 조정 및 RLHF)에 대한 완전한 파이프라인을 제공한다. (3) Deepspeed의 학습 엔진과 추론 엔진을 RLHF 학습을 위한 통합 하이브리드 엔진(Deepspeed HE)에 통합하여 학습과 추론 모드 간의 원활한 전환을 가능하게 하고, DeepSpeed Inference로부터 다양한 최적화를 활용한다.</p>
</div>
<div id="S3.SS4.p12" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p12.1">위의 라이브러리 리소스 외에도 기존 딥 러닝 프레임워크(<em class="ltx_emph ltx_font_italic" id="S3.SS4.p12.1.1">e.g.,</em> PyTorch <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib197" title="">197</a>]</cite>, TensorFlow <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib198" title="">198</a>]</cite>, MXNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib199" title="">199</a>]</cite>, PaddlePaddle <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib200" title="">200</a>]</cite>, MindSpore <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib136" title="">136</a>]</cite> 및 OneFlow <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib201" title="">201</a>]</cite>)도 대규모 모델 학습에 일반적으로 사용되는 병렬 알고리즘에 대한 지원을 제공했다.</p>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x7.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="194" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 6:</span>기존 LLMs에 대한 사전 트레이닝 데이터에서 다양한 데이터 소스의 비율.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Pre-training</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1">사전 훈련은 LLM의 능력의 기초를 확립한다. 대규모 코퍼라에 대한 사전 교육을 통해 LLMs은 필수 언어 이해와 생성 기술 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>를 습득할 수 있다. 이 과정에서 사전 훈련 말뭉치의 규모와 품질은 LLM이 강력한 능력을 갖추는데 매우 중요하다. 또한 LLM을 효과적으로 사전 학습하기 위해서는 모델 아키텍처, 가속 방법 및 최적화 기술이 잘 설계되어야 한다. 다음에서는 먼저 섹션 <a class="ltx_ref" href="#S4.SS1" title="4.1 Data Collection and Preparation ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.1</span></a>에서 데이터 수집 및 처리에 대해 논의하고, 섹션 <a class="ltx_ref" href="#S4.SS2" title="4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2</span></a>에서 일반적으로 사용되는 모델 아키텍처를 소개하고, 마지막으로 섹션 <a class="ltx_ref" href="#S4.SS3" title="4.3 Model Training ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a>에서 LLM을 안정적이고 효율적으로 최적화하기 위한 훈련 기술을 제시한다.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span id="S4.SS1.1.1" class="ltx_text ltx_font_italic">Data Collection and Preparation</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1">LLM은 소규모 언어 모델과 비교하여 모델 사전 훈련을 위한 고품질 데이터에 대한 수요가 더 강하며, 모델 용량은 사전 훈련 말뭉치와 사전 처리된 방법에 크게 의존한다. 이 부분에서는 데이터 소스, 전처리 방법 및 사전 훈련 데이터가 LLM의 성능에 어떻게 영향을 미치는지에 대한 중요한 분석을 포함하여 사전 훈련 데이터의 수집 및 처리에 대해 논의한다.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Data Source</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">유능한 LLM을 개발하기 위해서는 다양한 데이터 소스로부터 대량의 자연어 코퍼스를 수집하는 것이 핵심이다. 기존의 LLM은 주로 다양한 공개 텍스트 데이터 세트의 혼합물을 사전 훈련 코퍼스로 활용한다. <a class="ltx_ref" href="#S3.F6" title="Figure 6 ‣ 3.4 Library Resource ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>는 다수의 대표적인 LLMs에 대한 사전 트레이닝 데이터의 소스의 분포를 나타낸다.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS1.p2.1">사전 훈련 말뭉치의 출처는 크게 일반 데이터와 전문 데이터의 두 가지 유형으로 분류할 수 있다. 웹 페이지, 책, 대화 텍스트와 같은 일반적인 데이터는 크고 다양하며 접근 가능한 특성으로 인해 대부분의 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite>에 의해 활용되며, 이는 LLMs의 언어 모델링 및 일반화 능력을 향상시킬 수 있다. LLM이 보여주는 인상적인 일반화 능력에 비추어 볼 때, 사전 훈련 코퍼스를 다국어 데이터, 과학 데이터 및 코드와 같은 보다 전문화된 데이터 세트로 확장하여 LLM에 특정 과제 해결 능력<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib35" title="">35</a>, <a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>를 부여하는 연구도 있다. 다음은 이 두 가지 유형의 사전 훈련 데이터 소스와 LLM에 미치는 영향에 대해 설명한다. 일반적으로 사용되는 말뭉치에 대한 자세한 소개는 Section <a class="ltx_ref" href="#S3.SS2" title="3.2 Commonly Used Corpora for Pre-training ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3.2</span></a>를 참조할 수 있다.</p>
</div>
<div id="S4.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS1.p3.1.1">General Text Data. </span> <a class="ltx_ref" href="#S3.F6" title="Figure 6 ‣ 3.4 Library Resource ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>에서 볼 수 있듯이, 대부분의 LLMs은 웹 페이지, 책, 대화 텍스트와 같은 범용 사전 훈련 데이터를 채택하여 다양한 주제에 대해 풍부한 텍스트 소스를 제공한다. 다음으로, 우리는 세 가지 중요한 일반 데이터를 간략하게 요약한다.</p>
</div>
<div id="S4.SS1.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS1.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p4.1.m1.1"><semantics id="S4.SS1.SSS1.p4.1.m1.1a"><mo id="S4.SS1.SSS1.p4.1.m1.1.1" xref="S4.SS1.SSS1.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p4.1.m1.1b"><ci id="S4.SS1.SSS1.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS1.p4.1.1">Webpages. </em> 인터넷의 확산으로 인해 다양한 유형의 데이터가 생성되었으며, 이는 LLM이 다양한 언어 지식을 얻고 일반화 능력을 향상시킬 수 있도록 한다. 이러한 데이터 자원의 편리한 사용을 위해 CommonCrawl <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib163" title="">163</a>]</cite>와 같이 이전 작업에서 웹에서 대량의 데이터를 크롤링한다. 그러나 크롤링된 웹 데이터는 스팸 메일과 같이 위키피디아와 같은 고품질 텍스트와 저품질 텍스트를 모두 포함하는 경향이 있으므로 데이터 품질을 향상시키기 위해서는 웹 페이지를 필터링하고 처리하는 것이 중요하다.</p>
</div>
<div id="S4.SS1.SSS1.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS1.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p5.1.m1.1"><semantics id="S4.SS1.SSS1.p5.1.m1.1a"><mo id="S4.SS1.SSS1.p5.1.m1.1.1" xref="S4.SS1.SSS1.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p5.1.m1.1b"><ci id="S4.SS1.SSS1.p5.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS1.p5.1.1">Conversation text. </em> 대화 데이터는 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite>의 대화 능력을 향상시킬 수 있으며, 잠재적으로 질문 응답 태스크의 범위 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>에서 성능을 향상시킬 수 있다. 연구자들은 공개 대화 말뭉치의 하위 집합(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS1.p5.1.2">e.g.,</em> PushShift.io Reddit corpus) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib202" title="">202</a>, <a class="ltx_ref" href="#bib.bib158" title="">158</a>]</cite>를 활용하거나 온라인 소셜 미디어에서 대화 데이터를 수집할 수 있다. 온라인 대화 데이터는 종종 다수의 참가자 간의 토론을 수반하기 때문에, 효과적인 처리 방법은 대화를 트리 구조로 변환하는 것이며, 여기서 발화는 대응하는 발화와 연결된다. 이러한 방식으로, 다자간 대화 트리는 다수의 서브-대화들로 분할될 수 있으며, 이는 사전 트레이닝 코퍼스에서 수집될 수 있다. 또한, 잠재적 위험은 대화 데이터를 LLM에 과도하게 통합하면 부작용 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite>: 선언적 지시와 직접 질문이 대화의 시작으로 잘못 인식되어 지시의 효율성이 저하될 수 있다.</p>
</div>
<div id="S4.SS1.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS1.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p6.1.m1.1"><semantics id="S4.SS1.SSS1.p6.1.m1.1a"><mo id="S4.SS1.SSS1.p6.1.m1.1.1" xref="S4.SS1.SSS1.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p6.1.m1.1b"><ci id="S4.SS1.SSS1.p6.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS1.p6.1.1">Books. </em> 다른 코퍼스에 비해 책은 LLM이 언어 지식을 배우고 장기 종속성을 모델링하고 내러티브 및 일관된 텍스트를 생성하는 데 잠재적으로 유익한 공식 긴 텍스트의 중요한 소스를 제공한다. 오픈 소스 도서 데이터를 얻기 위해 기존 연구에서는 일반적으로 파일 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib161" title="">161</a>]</cite>에서 사용할 수 있는 Books3 및 Bookcorpus2 데이터 세트를 채택한다.</p>
</div>
<div id="S4.SS1.SSS1.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.SSS1.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS1.p7.1.1">Specialized Text Data. </span> 전문화된 데이터 세트는 다운스트림 작업에서 LLM의 특정 기능을 개선하는 데 유용합니다. 다음으로 세 가지 종류의 전문 데이터를 소개합니다.</p>
</div>
<div id="S4.SS1.SSS1.p8" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS1.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p8.1.m1.1"><semantics id="S4.SS1.SSS1.p8.1.m1.1a"><mo id="S4.SS1.SSS1.p8.1.m1.1.1" xref="S4.SS1.SSS1.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p8.1.m1.1b"><ci id="S4.SS1.SSS1.p8.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p8.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS1.p8.1.1">Multilingual text. </em> 대상 언어의 텍스트 외에도 다국어 코퍼스를 통합하면 언어 이해 및 생성의 다국어 능력을 향상시킬 수 있다. 예를 들어, BLOOM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite> 및 PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>는 사전 훈련 말뭉치 내에서 각각 46개 및 122개 언어를 포함하는 큐레이트된 다국어 데이터를 가지고 있다. FLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib102" title="">102</a>]</cite>는 중국어와 영어 말뭉치를 거의 같은 비율로 섞는다. 이러한 모델은 번역, 다국어 요약 및 다국어 질문 응답과 같은 다국어 작업에서 인상적인 성능을 보여주며, 목표 언어(들)의 코퍼스에서 미세 조정되는 최첨단 모델과 비교되거나 우수한 성능을 달성한다.</p>
</div>
<div id="S4.SS1.SSS1.p9" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS1.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p9.1.m1.1"><semantics id="S4.SS1.SSS1.p9.1.m1.1a"><mo id="S4.SS1.SSS1.p9.1.m1.1.1" xref="S4.SS1.SSS1.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p9.1.m1.1b"><ci id="S4.SS1.SSS1.p9.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p9.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS1.p9.1.1">Scientific text. </em> 인간에 의한 과학 탐구는 과학 출판물의 증가하는 성장에 의해 목격되었다. LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>, <a class="ltx_ref" href="#bib.bib203" title="">203</a>]</cite>에 대한 과학적 지식의 이해를 높이기 위해서는 모델 사전 학습용 과학 말뭉치 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>, <a class="ltx_ref" href="#bib.bib203" title="">203</a>]</cite>를 통합하는 것이 유용하다. 방대한 양의 과학 텍스트를 사전 훈련함으로써 LLMs는 과학적 및 추론 과제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib204" title="">204</a>]</cite>에서 인상적인 성능을 달성할 수 있다. 과학적 코퍼스를 구성하기 위해 기존의 노력은 주로 arXiv 논문, 과학 교과서, 수학 웹 페이지 및 기타 관련 과학 자원을 수집한다. 수학적 기호 및 단백질 서열과 같은 과학 분야에서의 데이터의 복잡한 특성으로 인해, 이러한 상이한 포맷의 데이터를 언어 모델에 의해 처리될 수 있는 통일된 형태로 변환하기 위해 특정 토큰화 및 전처리 기술이 일반적으로 요구된다.</p>
</div>
<div id="S4.SS1.SSS1.p10" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS1.p10.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p10.1.m1.1"><semantics id="S4.SS1.SSS1.p10.1.m1.1a"><mo id="S4.SS1.SSS1.p10.1.m1.1.1" xref="S4.SS1.SSS1.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p10.1.m1.1b"><ci id="S4.SS1.SSS1.p10.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p10.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS1.p10.1.1">Code. </em> 프로그램 합성은 연구 커뮤니티 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib205" title="">205</a>, <a class="ltx_ref" href="#bib.bib206" title="">206</a>, <a class="ltx_ref" href="#bib.bib207" title="">207</a>, <a class="ltx_ref" href="#bib.bib105" title="">105</a>, <a class="ltx_ref" href="#bib.bib208" title="">208</a>]</cite>, 특히 코드 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib209" title="">209</a>, <a class="ltx_ref" href="#bib.bib165" title="">165</a>]</cite>에서 훈련된 PLM의 사용에 대해 널리 연구되었다. 그러나 이러한 PLM(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS1.p10.1.2">e.g.,</em> GPT-J<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib165" title="">165</a>]</cite>)이 고품질 및 정확한 프로그램을 생성하는 것은 여전히 어려운 일이다. 최근 연구<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>, <a class="ltx_ref" href="#bib.bib208" title="">208</a>]</cite>는 방대한 코드 코퍼스에서 LLM을 학습하면 합성된 프로그램의 품질이 크게 향상될 수 있음을 발견했다. 생성된 프로그램은 전문가 설계 단위 테스트 사례 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite>를 성공적으로 통과하거나 경쟁 프로그래밍 문제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib114" title="">114</a>]</cite>를 해결할 수 있다. 일반적으로 사전 훈련 LLM에는 두 가지 유형의 코드 코퍼스가 일반적으로 사용된다. 첫 번째 소스는 Stack Exchange <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib210" title="">210</a>]</cite>와 같은 프로그래밍 질의 응답 커뮤니티에서 나온 것입니다. 두 번째 소스는 GitHub <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>, <a class="ltx_ref" href="#bib.bib208" title="">208</a>, <a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>와 같은 공용 소프트웨어 리포지토리에서 가져온 것으로 코드 데이터(댓글 및 docstrings 포함)가 활용을 위해 수집됩니다. 자연어 텍스트와 비교하여 코드는 프로그래밍 언어의 형식이며, 장거리 종속성 및 정확한 실행 논리 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib211" title="">211</a>]</cite>에 해당한다. 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib47" title="">47</a>]</cite>는 또한 코드에 대한 훈련이 복잡한 추론 능력의 원천일 수 있다고 추측한다(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS1.p10.1.3">e.g.,</em> chain-of-thought ability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>). 또한, 추론 작업을 코드로 포맷하는 것은 LLMs가 더 정확한 결과를 생성하는 데 도움이 될 수 있음을 보였다.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Data Preprocessing</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">많은 양의 텍스트 데이터를 수집한 후 사전 훈련 말뭉치를 구성하기 위해 데이터를 전처리하는 것이 필수적이며, 특히 LLM의 용량과 성능에 큰 영향을 미칠 수 있는 노이즈, 중복, 관련 없는, 잠재적인 독성 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib212" title="">212</a>]</cite>를 제거하는 것이 중요하다. 데이터 처리를 용이하게 하기 위해 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib213" title="">213</a>]</cite>는 50개 이상의 처리 연산자와 도구를 제공하는 Data-Juicer라는 LLMs에 유용한 데이터 처리 시스템을 제안한다. 이 부분에서는 수집된 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>, <a class="ltx_ref" href="#bib.bib112" title="">112</a>, <a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>의 품질을 향상시키기 위한 세부적인 데이터 전처리 전략을 검토한다. LLM에 대한 사전 훈련 데이터를 전처리하는 전형적인 파이프라인은 그림 <a class="ltx_ref" href="#S4.F7" title="Figure 7 ‣ 4.1.2 Data Preprocessing ‣ 4.1 Data Collection and Preparation ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>에 예시되어 있다.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x8.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="95" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 7:</span>대형 언어 모델을 사전 트레이닝하기 위한 전형적인 데이터 전처리 파이프라인의 예시.</figcaption>
</figure>
<div id="S4.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p2.1.1">Quality Filtering. </span> 수집된 코퍼스에서 저품질 데이터를 제거하기 위해 기존 작업은 일반적으로 (1) 분류기 기반과 (2) 휴리스틱 기반 두 가지 접근법을 채택한다. 전자의 접근법은 고품질 텍스트를 기반으로 선택 분류기를 훈련시키고 이를 활용하여 저품질 데이터를 식별하고 필터링한다. 전형적으로, 이들 방법들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib112" title="">112</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>는 잘 분류된 데이터(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p2.1.2">e.g.,</em> Wikipedia pages)를 포지티브 인스턴스들로서, 샘플 후보 데이터를 네거티브 인스턴스들로서 이진 분류기를 트레이닝하고, 각각의 데이터 예의 품질을 측정하는 스코어를 예측한다. 그러나, 여러 연구들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib112" title="">112</a>, <a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>는 분류기 기반 접근법이 방언, 구어체 및 사회전체 언어에서 고품질 텍스트를 의도하지 않게 제거할 수 있으며, 이는 잠재적으로 사전 훈련 말뭉치의 편향을 초래하고 말뭉치의 다양성을 감소시킬 수 있음을 발견했다. 두 번째 접근 방법으로 BLOOM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite> 및 Gopher <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>와 같은 여러 연구에서 잘 설계된 규칙 집합을 통해 저품질 텍스트를 제거하기 위해 휴리스틱 기반 접근법을 사용했으며 다음과 같이 요약할 수 있다.</p>
</div>
<div id="S4.SS1.SSS2.p3" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i1.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i1.p1.1.1">Language based filtering. </em> LLM이 특정 언어의 태스크에서 주로 사용되는 경우, 다른 언어의 텍스트는 필터링될 수 있다.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i2.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i2.p1.1.1">Metric based filtering. </em> 생성된 텍스트에 대한 평가 메트릭인 <em class="ltx_emph ltx_font_italic" id="S4.I1.i2.p1.1.2">e.g.,</em> perplexity를 사용하여 부자연스러운 문장을 감지하고 제거할 수 있다.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i3.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i3.p1.1.1">Statistic based filtering. </em> 말뭉치의 통계적 특징, <em class="ltx_emph ltx_font_italic" id="S4.I1.i3.p1.1.2">e.g.,</em> 구두점 분포, 기호 대 단어 비율 및 문장 길이는 텍스트 품질을 측정하고 저품질 데이터를 필터링하는 데 활용될 수 있다.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i4.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i4.p1.1.1">Keyword based filtering. </em> 특정 키워드 세트를 기반으로 HTML 태그, 하이퍼링크, 상용구 및 불쾌한 단어와 같은 텍스트에서 잡음이 있거나 유용하지 않은 요소를 식별하고 제거할 수 있다.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.SSS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p4.1.1">De-duplication. </span> 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib214" title="">214</a>]</cite>는 코퍼스의 중복 데이터가 언어 모델의 다양성을 감소시켜 훈련 프로세스가 불안정해지고 따라서 모델 성능에 영향을 미칠 수 있음을 발견했다. 따라서 사전 훈련 말뭉치를 탈복할 필요가 있다. 특히, 중복제거는 문장-레벨, 문서-레벨 및 데이터세트-레벨 중복제거를 포함한 상이한 세분도에서 수행될 수 있다. 첫째, 언어 모델링 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib215" title="">215</a>]</cite>에서 반복 패턴을 도입할 수 있으므로 반복되는 단어와 구가 포함된 저화질 문장은 제거해야 한다. 문서 수준에서 기존 연구는 대부분 표면 특징의 중첩 비율(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p4.1.2">e.g.,</em> 단어 및 <math alttext="n" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p4.1.m1.1"><semantics id="S4.SS1.SSS2.p4.1.m1.1a"><mi id="S4.SS1.SSS2.p4.1.m1.1.1" xref="S4.SS1.SSS2.p4.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p4.1.m1.1b"><ci id="S4.SS1.SSS2.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p4.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p4.1.m1.1c">n</annotation></semantics></math>-grams overlap)에 의존하여 유사한 내용을 포함하는 중복 문서를 탐지하고 제거한다. 또한 데이터셋 오염 문제를 피하기 위해 학습 집합에서 중복 가능한 텍스트를 제거함으로써 학습과 평가 집합 사이의 중복을 방지하는 것도 중요하다. 3단계의 중복제거는 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib217" title="">217</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>의 트레이닝을 개선하는데 유용함을 보여주었으며, 이는 실무에서 공동으로 사용되어야 한다.</p>
</div>
<div id="S4.SS1.SSS2.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.SSS2.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p5.1.1">Privacy Reduction. </span> 사전 트레이닝 텍스트 데이터의 대부분은 민감한 정보 또는 개인 정보를 포함하는 사용자 생성 콘텐츠를 포함한 웹 소스로부터 획득되며, 이는 프라이버시 침해의 위험을 증가시킬 수 있다. 따라서 사전 훈련 말뭉치에서 <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p5.1.2">personally identifiable information (PII)</em>을 제거할 필요가 있다. 한 가지 직접적이고 효과적인 접근법은 키워드 스포팅과 같은 규칙 기반 방법을 사용하여 이름, 주소 및 전화 번호 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib162" title="">162</a>]</cite>와 같은 PII를 감지하고 제거하는 것이다. 또한, 연구자들은 프라이버시 공격에서 LLM의 취약성이 사전 훈련 말뭉치 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib219" title="">219</a>]</cite>에 중복 PII 데이터가 존재하기 때문일 수 있음을 발견했다. 따라서 중복제거는 프라이버시 위험도 어느 정도 줄일 수 있다.</p>
</div>
<div id="S4.SS1.SSS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.SSS2.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p6.1.1">Tokenization. </span> 토큰화는 데이터 전처리를 위한 중요한 단계이기도 합니다. 그것은 원시 텍스트를 개별 토큰의 시퀀스로 세그먼트화하는 것을 목표로 하며, 이는 후속적으로 LLM의 입력으로 사용된다. 전통적인 NLP 연구(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p6.1.2">e.g.,</em> sequence labeling with conditional random fields <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib220" title="">220</a>]</cite>)에서 단어 기반 토큰화는 인간의 언어 인지와 더 잘 일치하는 우세한 접근법이다. 그러나 단어 기반 토큰화는 일부 언어에서 동일한 입력에 대해 상이한 세분화 결과를 산출할 수 있다(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p6.1.3">e.g.,</em>중국어 단어 세분화), 많은 저빈도 단어를 포함하는 거대한 단어 어휘를 생성할 수 있고, 또한 "<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p6.1.4">out-of-vocabulary</em>" 이슈를 겪는다. 따라서 여러 신경망 모델은 단어 표현을 유도하기 위해 최소 단위로 <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p6.1.5">character</em>을 사용한다(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p6.1.6">e.g.,</em> a CNN word encoder in ELMo<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib21" title="">21</a>]</cite>). 최근 <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p6.1.7">subword tokenizers</em>은 일반적으로 Byte-Pair Encoding tokenization, WordPiece tokenization 및 Unigram tokenization을 포함하는 Transformer 기반 언어 모델에서 널리 사용되었다. HuggingFace는 실행 예제와 함께 tokenizer<span class="ltx_note ltx_role_footnote" id="footnote22"><sup class="ltx_note_mark">22</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">22</sup><span class="ltx_tag ltx_tag_note">22</span>https://huggingface.co/learn/nlp-course/chapter6</span></span></span>에서 우수한 온라인 NLP 과정을 유지했으며, 이 과정은 초보자를 참조합니다. 다음으로 대표적인 세 가지 토큰화 방법에 대해 간략히 설명한다.</p>
</div>
<div id="S4.SS1.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p7.1.m1.1"><semantics id="S4.SS1.SSS2.p7.1.m1.1a"><mo id="S4.SS1.SSS2.p7.1.m1.1.1" xref="S4.SS1.SSS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p7.1.m1.1b"><ci id="S4.SS1.SSS2.p7.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p7.1.1">Byte-Pair Encoding (BPE) tokenization</em>. BPE는 원래 1994년 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib221" title="">221</a>]</cite>에서 일반적인 데이터 압축 알고리즘으로 제안된 후 토큰화를 위해 NLP에 적응되었다. 기본 기호의 집합으로 시작합니다(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p7.1.2">e.g.,</em> the alphabets and boundary characters). 그리고 코퍼스에서 연속하는 두 토큰의 빈발 쌍을 새로운 토큰으로 반복적으로 결합합니다(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p7.1.3">merge</em>이라고 함). 각각의 합병에 대해, 선택 기준은 두 개의 연속 토큰들의 동시 발생 빈도에 기초한다: 최상위 빈발 쌍이 선택될 것이다. 병합 프로세스는 미리 정의된 크기에 도달할 때까지 계속됩니다. 또한, 바이트 레벨 BPE는 병합을 위한 기본 심볼로 <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p7.1.4">e.g.,</em> the text containing non-ASCII characters)를 고려함으로써 다국어 코퍼스에 대한 토큰화 품질을 향상시키는데 사용되었다. 이러한 토큰화 접근법을 갖는 대표적인 언어 모델에는 GPT-2, BART 및 LLaMA가 포함된다.</p>
</div>
<div id="S4.SS1.SSS2.p8" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS2.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p8.1.m1.1"><semantics id="S4.SS1.SSS2.p8.1.m1.1a"><mo id="S4.SS1.SSS2.p8.1.m1.1.1" xref="S4.SS1.SSS2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p8.1.m1.1b"><ci id="S4.SS1.SSS2.p8.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p8.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p8.1.1">WordPiece tokenization</em>. 워드피스는 구글 내부 서브워드 토큰화 알고리즘이었다. 그것은 원래 구글에 의해 음성 검색 시스템 개발에서 제안되었다.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib223" title="">223</a>]</cite> 그런 다음 2016년 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib224" title="">224</a>]</cite>에서 신경 기계 번역 시스템에 사용되었으며 2018년 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite>에서 BERT용 토큰화기로 채택되었다. WordPiece는 연속 토큰을 반복적으로 병합하는 반면 병합에 대해 약간 다른 선택 기준을 취함으로써 BPE와 매우 유사한 아이디어를 갖는다. 병합을 수행하기 위해 먼저 언어 모델을 훈련하고 가능한 모든 쌍을 점수화하는 데 사용한다. 그런 다음 각 병합에서 학습 데이터의 가능성이 가장 많이 증가하는 쌍을 선택합니다. 구글이 워드피스 알고리즘의 공식 구현을 공개하지 않았기 때문에, HuggingFace는 온라인 NLP 과정에서 더 직관적인 선택 척도를 제공한다: 한 쌍은 훈련 코퍼스를 기반으로 한 쌍에서 두 토큰의 발생 카운트의 곱으로 동시 발생 카운트를 나누어 점수를 매긴다.</p>
</div>
<div id="S4.SS1.SSS2.p9" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS2.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p9.1.m1.1"><semantics id="S4.SS1.SSS2.p9.1.m1.1a"><mo id="S4.SS1.SSS2.p9.1.m1.1.1" xref="S4.SS1.SSS2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p9.1.m1.1b"><ci id="S4.SS1.SSS2.p9.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p9.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p9.1.1">Unigram tokenization</em>. BPE 및 WordPiece와 달리 Unigram tokenization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib225" title="">225</a>]</cite>는 코퍼스에 대해 충분히 큰 가능한 부분 문자열 또는 하위 토큰 집합으로 시작하여 예상 어휘 크기에 도달할 때까지 현재 어휘의 토큰을 반복적으로 제거합니다. 선택 기준으로 현재 어휘에서 일부 토큰이 제거되었다고 가정하여 학습 말뭉치의 산출 가능성 증가를 계산한다. 이 단계는 훈련된 유니그램 언어 모델에 기초하여 수행된다. Unigram 언어 모델을 추정하기 위해 기대-최대화(EM) 알고리즘을 채택한다: 각 반복에서 우리는 먼저 오래된 언어 모델을 기반으로 단어의 현재 최적의 토큰화를 찾은 다음 언어 모델을 업데이트하기 위해 Unigram의 확률을 재추정한다. 이 과정에서 언어 모델이 주어진 단어의 최적 분해 방법을 효율적으로 찾기 위해 동적 프로그래밍 알고리즘(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p9.1.2">i.e.,</em> the Viterbi algorithm)이 사용된다. 이러한 토큰화 접근법을 채택하는 대표적인 모델로는 T5와 mBART가 있다.</p>
</div>
<div id="S4.SS1.SSS2.p10" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS2.p10.1">기존의 토큰화기를 활용하는 것이 편법적이지만(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p10.1.1">e.g.,</em> OPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite> and GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>는 GPT-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>의 토큰화기를 활용하지만, 사전 훈련 말뭉치를 위해 특별히 설계된 토큰화기를 사용하면 특히 다양한 도메인, 언어 및 형식으로 구성된 말뭉치에 매우 유익한 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>가 될 수 있다. 따라서 최근 LLMs은 Byte-level BPE와 Unigram tokenization을 포함하는 SentencePiece 라이브러리 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib226" title="">226</a>]</cite>를 사용하여 사전 학습 코퍼스에 대한 맞춤형 토큰라이저를 특별히 학습시키는 경우가 많다. 참고로 NFKC<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib227" title="">227</a>]</cite>와 같은 BPE의 정규화 기술은 토큰화 성능<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>, <a class="ltx_ref" href="#bib.bib64" title="">64</a>, <a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>를 저하시킬 수 있다. 기존 LLMs(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p10.1.2">i.e.,</em>continual pre-training or instruction tuning)를 확장할 때 사용자 지정 토큰라이저의 잠재적인 부작용도 인식해야 합니다. 예를 들어, LLaMA는 주로 영어 텍스트로 구성된 사전 훈련 코퍼스를 기반으로 BPE 토큰화기를 훈련하며, 도출된 어휘는 비영어 데이터, <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p10.1.3">e.g.,</em> 더 긴 추론 대기 시간을 가져 중국어 텍스트를 생성할 수 있다.</p>
</div>
<div id="S4.SS1.SSS2.p11" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.SSS2.p11.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p11.1.1">Discussion on Effect of Data Quality. </span> 사전 훈련의 경우 사전 훈련 데이터의 품질은 LLM의 모델 용량에 매우 중요합니다. 기존의 연구는 노이즈, 독성 및 중복 데이터와 같은 저품질 코퍼스에 대한 사전 훈련이 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>, <a class="ltx_ref" href="#bib.bib216" title="">216</a>, <a class="ltx_ref" href="#bib.bib219" title="">219</a>, <a class="ltx_ref" href="#bib.bib214" title="">214</a>]</cite>의 성능에 큰 타격을 줄 것임을 보여주었다. T5<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>, GLaM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib112" title="">112</a>]</cite>, Gopher<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>와 같은 최근 연구에서는 데이터 품질이 LLM의 용량에 미치는 영향을 조사했다. 필터링된 코퍼스와 필터링되지 않은 코퍼스에 대해 훈련된 모델의 성능을 비교함으로써, 그들은 청소된 데이터에 대해 LLM을 사전 훈련시키는 것이 모델 성능을 향상시킬 수 있다는 유사한 결론에 도달했다. 보다 구체적으로, 데이터의 중복은 "<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p11.1.2">double descent</em>"(초기에 성능이 악화되고 후속적으로 개선되는 현상을 지칭함) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib214" title="">214</a>, <a class="ltx_ref" href="#bib.bib228" title="">228</a>]</cite>, 또는 심지어 트레이닝 프로세스 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib214" title="">214</a>]</cite>를 압도할 수 있다. 또한, 중복 데이터는 문맥에서 복사하는 LLMs의 능력을 저하시키며, 이는 문맥 내 학습 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib214" title="">214</a>]</cite>를 사용하여 LLMs의 일반화 능력에 더 영향을 미칠 수 있음을 보였다. 따라서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>, <a class="ltx_ref" href="#bib.bib78" title="">78</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib212" title="">212</a>]</cite>에서 제안한 바와 같이 사전 학습 말뭉치를 주의 깊게 청소하기 위해 품질 필터링, 독성 필터링 및 중복 제거와 같은 전처리 방법을 활용하는 것이 필수적이며 (<a class="ltx_ref" href="#S4.SS1.SSS2" title="4.1.2 Data Preprocessing ‣ 4.1 Data Collection and Preparation ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.1.2</span></a> 섹션에서 설명한 바와 같이), 학습 프로세스의 안정성을 향상시키고 모델 성능에 영향을 미치지 않도록 해야 한다.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x9.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="95" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8:</span>Pre-training LLMs에 대한 데이터 스케줄링의 예시.</figcaption>
</figure>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Data Scheduling</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">데이터 전처리 후, 가능한 LLM을 사전 훈련하기 위해 이러한 다중 소스 데이터를 스케줄링하기 위한 적절한 전략을 설계하는 것이 필수적이다. 일반적으로 데이터 스케줄링을 위해서는 각 데이터 소스의 비율(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p1.1.1">data mixture</em>)과 각 데이터 소스가 트레이닝을 위해 스케줄링되는 순서(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p1.1.2">data curriculum</em>)가 세심하게 고려되어야 한다. 다음으로, 두 가지 측면에 대해 자세히 논의한다. 데이터 스케줄링의 예시는 그림 <a class="ltx_ref" href="#S4.F8" title="Figure 8 ‣ 4.1.2 Data Preprocessing ‣ 4.1 Data Collection and Preparation ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">8</span></a>에 제시되어 있다.</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS3.p2.1.1">Data Mixture. </span> 각 종류의 데이터 소스는 LLMs에 대한 특정 용량의 개발과 밀접한 관련이 있기 때문에(<a class="ltx_ref" href="#S4.SS1" title="4.1 Data Collection and Preparation ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.1</span></a>절의 논의를 참조) 이러한 데이터를 혼합하기 위해 적절한 분포를 설정하는 것이 중요하다. 데이터 혼합물은 일반적으로 글로벌 레벨(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p2.1.2">i.e.,</em> 전체 사전 트레이닝 데이터의 분포)로 설정되며, 또한 상이한 트레이닝 스테이지들에서 다양한 비율들로 로컬로 설정될 수 있다. 사전 트레이닝 동안, 상이한 소스들로부터의 데이터 샘플들이 혼합물 비율들에 따라 선택될 것이다: 더 많은 데이터가 더 큰 가중치를 갖는 데이터 소스로부터 샘플링될 것이다. 전형적으로, LLaMA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>와 같은 기존의 LLM들은 사전 트레이닝 데이터로서 특정 데이터 혼합물들을 생성하기 위해 각 소스의 전체 데이터에 업샘플링 또는 다운샘플링을 채용할 수 있다. 도<a class="ltx_ref" href="#S3.F6" title="Figure 6 ‣ 3.4 Library Resource ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>가 예시하는 바와 같이, 기존의 LLM들은 사전 트레이닝 데이터를 구성하기 위해 상이한 데이터 혼합물들을 사용한다. 대표적인 모델로 LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>의 사전 학습 데이터는 GitHub 및 StackExchange의 코드 헤비 데이터 6.5%, 책 4.5%, arXiv의 과학 데이터 2.5%와 함께 웹 페이지(80% 이상)로 구성되어 범용 LLMs 학습에 중요한 참고가 되고 있다. 또한, 특수 데이터 혼합물은 상이한 목적을 용이하게 하기 위해 사용될 수 있다. 예를 들어, Falcon<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib141" title="">141</a>]</cite>는 순수 웹 페이지에서 학습되고, CodeGen<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>는 코드 데이터의 양을 크게 증가시킨다. 실제로, 데이터 혼합물은 종종 경험적으로 결정되며, 우리는 다음과 같이 효과적인 데이터 혼합물을 찾기 위한 몇 가지 일반적인 전략을 요약한다:</p>
</div>
<div id="S4.SS1.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS3.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p3.1.m1.1"><semantics id="S4.SS1.SSS3.p3.1.m1.1a"><mo id="S4.SS1.SSS3.p3.1.m1.1.1" xref="S4.SS1.SSS3.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p3.1.m1.1b"><ci id="S4.SS1.SSS3.p3.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p3.1.1">데이터 소스의 다양성 증가. </em> 최근 연구는 특정 도메인에 대한 과도한 데이터에 대한 훈련이 다른 도메인에서 LLM의 일반화 능력을 저하시킬 것이라는 것을 경험적으로 보여주었다. 대조적으로, 데이터 소스 이질성 증가(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p3.1.2">e.g.,</em> including various data sources)는 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib212" title="">212</a>, <a class="ltx_ref" href="#bib.bib229" title="">229</a>, <a class="ltx_ref" href="#bib.bib230" title="">230</a>]</cite>의 다운스트림 성능을 향상시키는데 중요하다. 다른 데이터 소스의 영향을 추가로 조사하기 위해 일부 연구에서는 각 데이터 소스를 하나씩 제거하고 특별히 선별된 데이터 세트<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib212" title="">212</a>]</cite>를 사용하여 사전 훈련 LLM을 수행하는 절제 실험을 수행했다. 높은 이질성을 갖는 데이터 소스를 드롭하는 것(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p3.1.3">e.g.,</em> webpages)은 낮은 이질성을 갖는 소스를 드롭하는 것(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p3.1.4">e.g.,</em> academic corpus)보다 LLM 능력에 더 심각한 영향을 미치는 것으로 나타났다.</p>
</div>
<div id="S4.SS1.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS3.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.1.m1.1"><semantics id="S4.SS1.SSS3.p4.1.m1.1a"><mo id="S4.SS1.SSS3.p4.1.m1.1.1" xref="S4.SS1.SSS3.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.1.m1.1b"><ci id="S4.SS1.SSS3.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p4.1.1">Optimizing data mixtures. </em> 데이터 혼합물을 수동으로 설정하는 것 외에도 모델 사전 훈련 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib231" title="">231</a>, <a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite>를 개선하기 위해 데이터 혼합물을 최적화하기 위한 여러 연구가 제안되었다. 대상 다운스트림 태스크가 주어지면, 특징 공간 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib231" title="">231</a>]</cite> 또는 다운스트림 태스크 성능에 긍정적인 영향을 주는 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib232" title="">232</a>]</cite>에서 근접성이 높은 사전 훈련 데이터를 선택할 수 있다. 또한, 목표 태스크의 신뢰도를 줄이기 위해 DoReMi<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite>는 주어진 초기 도메인 가중치를 사용하여 작은 참조 모델을 먼저 학습시킨 다음, 두 모델 사이의 우도 불일치가 가장 큰 도메인을 가중하여 다른 작은 프록시 모델을 학습시킨다. 마지막으로, 프락시 모델의 학습된 도메인 가중치를 적용하여 훨씬 더 큰 LLM을 학습한다. 보다 간단한 방법으로, 여러 개의 작은 언어 모델을 서로 다른 데이터 혼합물로 훈련시키고, 가장 바람직한 성능으로 이어지는 데이터 혼합물을 선택할 수 있다. 그러나 이 접근법에서 이루어진 가정은 유사한 방식으로 훈련될 때 작은 모델이 모델 능력 또는 행동에서 큰 모델과 유사할 것이며, 이는 항상 실제로 유지되는 것은 아닐 수 있다.</p>
</div>
<div id="S4.SS1.SSS3.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS3.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p5.1.m1.1"><semantics id="S4.SS1.SSS3.p5.1.m1.1a"><mo id="S4.SS1.SSS3.p5.1.m1.1.1" xref="S4.SS1.SSS3.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p5.1.m1.1b"><ci id="S4.SS1.SSS3.p5.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p5.1.1">Specializing the targeted abilities. </em> LLM의 모델 용량은 데이터 선택과 혼합에 크게 의존하며 특정 데이터 소스의 비율을 높여 특정 모델 능력을 향상시킬 수 있습니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>, <a class="ltx_ref" href="#bib.bib212" title="">212</a>]</cite>. 예를 들어, 수학적 추론과 코딩 능력은 각각 더 많은 수학적 텍스트와 코드 데이터로 훈련함으로써 특별히 향상될 수 있다. 또한 LAMBADA 데이터셋 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib233" title="">233</a>]</cite>에 대한 실험 결과는 장서 데이터의 비율을 증가시키면 텍스트로부터 장기 종속성을 포착하는 모델 용량을 향상시킬 수 있고, C4 데이터셋 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>의 비율을 증가시키면 C4 검증 데이터셋 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>에 대한 성능 향상을 가져올 수 있음을 보여준다. 일반적으로, 데이터 소스와 모델 능력 사이의 더 암묵적인 관계를 식별하는 것이 중요하다. LLM에서 수학 및 코딩과 같은 특정 기술을 향상시키거나 전문화된 LLM을 개발하기 위해 실용적인 방법은 다중 단계 훈련 접근법을 사용하는 것이며, <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p5.1.2">예를 들어,</em> 일반 및 기술 특정 데이터는 두 개의 연속 단계에서 스케줄링될 수 있다. 여러 단계에 걸쳐 데이터의 다양한 출처 또는 비율에 대해 LLM을 훈련하는 이러한 접근법은 "데이터 커리큘럼"으로도 알려져 있으며, 이는 아래에서 소개될 것이다.</p>
</div>
<div id="S4.SS1.SSS3.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.SSS3.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS3.p6.1.1">Data Curriculum. </span>  데이터 혼합을 준비한 후 사전 학습을 위해 특정 데이터가 LLMs에 제시되는 순서를 스케줄링하는 것이 중요합니다. 어떤 경우에, 어떤 스킬을 학습하기 위해, 스킬 세트 시퀀스(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p6.1.2">e.g.,</em> basic skills <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p6.1.m1.1"><semantics id="S4.SS1.SSS3.p6.1.m1.1a"><mo id="S4.SS1.SSS3.p6.1.m1.1.1" stretchy="false" xref="S4.SS1.SSS3.p6.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p6.1.m1.1b"><ci id="S4.SS1.SSS3.p6.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p6.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p6.1.m1.1c">\rightarrow</annotation></semantics></math> target skill)가 타겟 스킬에만 초점을 맞춘 코퍼스로부터의 직접 학습보다 우수한 것으로 나타났다. 커리큘럼 학습 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib236" title="">236</a>]</cite>의 아이디어에 이어 <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p6.1.3">data curriculum</em>은 모델 사전 학습 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib234" title="">234</a>, <a class="ltx_ref" href="#bib.bib237" title="">237</a>, <a class="ltx_ref" href="#bib.bib235" title="">235</a>, <a class="ltx_ref" href="#bib.bib238" title="">238</a>]</cite>에서 제안되어 널리 사용되고 있다. LLM에 대한 사전 훈련 데이터의 다른 부분을 특정 순서로 구성하는 것을 목표로 합니다. <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p6.1.4">e.g.,</em>은 쉬운/일반적인 예제로 시작하여 점진적으로 더 도전적인/전문적인 예제를 도입합니다. 보다 일반적으로, 사전 트레이닝 동안 상이한 소스들에 대한 데이터 비율들의 적응적 조정을 광범위하게 지칭할 수 있다. 데이터 커리큘럼에 대한 기존 작업은 주로 특수 코딩 LLMs(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p6.1.5">e.g.,</em> CodeLLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib235" title="">235</a>]</cite>) 또는 긴 컨텍스트 LLMs(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p6.1.6">e.g.,</em> LongLLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib238" title="">238</a>]</cite>)와 같은 지속적인 사전 훈련에 중점을 둔다. 그러나, 범용 LLMs(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p6.1.7">e.g.,</em> LLaMA)에 대한 데이터 커리큘럼에 대한 보다 상세한 보고는 여전히 부족하다. 데이터 커리큘럼을 결정하기 위해서는 특별히 구성된 평가 벤치마크를 기반으로 LLM의 핵심 능력 개발을 모니터링한 다음 사전 훈련 중에 데이터 혼합을 적응적으로 조정하는 실용적인 접근법이 있다. 다음으로 데이터 커리큘럼의 개념인 <span class="ltx_note ltx_role_footnote" id="footnote23"><sup class="ltx_note_mark">23</sup><span class="ltx_note_outer"><span class="ltx_note_content">23</sup><span class="ltx_note_mark">23</sup><span class="ltx_tag ltx_tag_note">23</span>우리는 데이터 커리큘럼에서 데이터 순서를 나타내기 위해 "<math alttext="\rightarrow" class="ltx_Math" display="inline" id="footnote23.m1.1"><semantics id="footnote23.m1.1b"><mo id="footnote23.m1.1.1" stretchy="false" xref="footnote23.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="footnote23.m1.1c"><ci id="footnote23.m1.1.1.cmml" xref="footnote23.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote23.m1.1d">\rightarrow</annotation></semantics></math>" 기호를 활용한다. 예를 들어, "2T 웹 페이지 토큰 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="footnote23.m2.1"><semantics id="footnote23.m2.1b"><mo id="footnote23.m2.1.1" stretchy="false" xref="footnote23.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="footnote23.m2.1c"><ci id="footnote23.m2.1.1.cmml" xref="footnote23.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote23.m2.1d">\rightarrow</annotation></semantics></math>500B 코드 토큰"은 LLM이 먼저 2T 웹 페이지 토큰으로 트레이닝되고 이어서 500B 코드 데이터 토큰으로 트레이닝된다는 것을 의미한다. </span></span></span>은 연속 사전 훈련에서 적용됩니다.</p>
</div>
<div id="S4.SS1.SSS3.p7" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS3.p7.4"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p7.1.m1.1"><semantics id="S4.SS1.SSS3.p7.1.m1.1a"><mo id="S4.SS1.SSS3.p7.1.m1.1.1" xref="S4.SS1.SSS3.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p7.1.m1.1b"><ci id="S4.SS1.SSS3.p7.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p7.4.1">Coding</em>. LLM의 코딩 능력을 향상시키기 위해, CodeLLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib235" title="">235</a>]</cite>는 LLaMA 2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>(2T 일반 토큰 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p7.2.m2.1"><semantics id="S4.SS1.SSS3.p7.2.m2.1a"><mo id="S4.SS1.SSS3.p7.2.m2.1.1" stretchy="false" xref="S4.SS1.SSS3.p7.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p7.2.m2.1b"><ci id="S4.SS1.SSS3.p7.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p7.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p7.2.m2.1c">\rightarrow</annotation></semantics></math>500B 코드-헤비 토큰)을 기반으로 개발되었으며, 이는 코드 생성 능력을 향상시키고 자연어 이해 능력을 유지하는 것을 목표로 한다. CodeLLaMA는 또한 특정 프로그래밍 언어, 즉 CodeLLaMA-Python에 더욱 특화된 버전을 제공한다(2T 일반 토큰 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p7.3.m3.1"><semantics id="S4.SS1.SSS3.p7.3.m3.1a"><mo id="S4.SS1.SSS3.p7.3.m3.1.1" stretchy="false" xref="S4.SS1.SSS3.p7.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p7.3.m3.1b"><ci id="S4.SS1.SSS3.p7.3.m3.1.1.cmml" xref="S4.SS1.SSS3.p7.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p7.3.m3.1c">\rightarrow</annotation></semantics></math> 500B 코드-헤비 토큰 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p7.4.m4.1"><semantics id="S4.SS1.SSS3.p7.4.m4.1a"><mo id="S4.SS1.SSS3.p7.4.m4.1.1" stretchy="false" xref="S4.SS1.SSS3.p7.4.m4.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p7.4.m4.1b"><ci id="S4.SS1.SSS3.p7.4.m4.1.1.cmml" xref="S4.SS1.SSS3.p7.4.m4.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p7.4.m4.1c">\rightarrow</annotation></semantics></math> 100B Python-헤비 토큰).</p>
</div>
<div id="S4.SS1.SSS3.p8" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS3.p8.4"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p8.1.m1.1"><semantics id="S4.SS1.SSS3.p8.1.m1.1a"><mo id="S4.SS1.SSS3.p8.1.m1.1.1" xref="S4.SS1.SSS3.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p8.1.m1.1b"><ci id="S4.SS1.SSS3.p8.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p8.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p8.4.1">Mathematics. </em> Llemma <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib239" title="">239</a>]</cite>는 범용 LLM의 수학적 능력을 향상시키기 위해 제안되었다. CodeLLaMA를 기반으로 개발되었습니다. CodeLLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib235" title="">235</a>]</cite>는 주로 코딩 능력에 초점을 맞추고 있지만, 수학 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib239" title="">239</a>]</cite>에서는 기본 모델 LLaMA 2보다 성능이 우수함을 실험을 통해 확인하였다. CodeLLaMA에 기초하여, Llemma는 수학적 텍스트 및 코드를 포함하는 과학 논문, 웹 데이터의 혼합물에 대해 지속적으로 트레이닝된다(2T 일반 토큰 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p8.2.m2.1"><semantics id="S4.SS1.SSS3.p8.2.m2.1a"><mo id="S4.SS1.SSS3.p8.2.m2.1.1" stretchy="false" xref="S4.SS1.SSS3.p8.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p8.2.m2.1b"><ci id="S4.SS1.SSS3.p8.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p8.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p8.2.m2.1c">\rightarrow</annotation></semantics></math> 500B 코드-헤비 토큰 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p8.3.m3.1"><semantics id="S4.SS1.SSS3.p8.3.m3.1a"><mo id="S4.SS1.SSS3.p8.3.m3.1.1" stretchy="false" xref="S4.SS1.SSS3.p8.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p8.3.m3.1b"><ci id="S4.SS1.SSS3.p8.3.m3.1.1.cmml" xref="S4.SS1.SSS3.p8.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p8.3.m3.1c">\rightarrow</annotation></semantics></math> 50<math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p8.4.m4.1"><semantics id="S4.SS1.SSS3.p8.4.m4.1a"><mo id="S4.SS1.SSS3.p8.4.m4.1.1" xref="S4.SS1.SSS3.p8.4.m4.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p8.4.m4.1b"><csymbol cd="latexml" id="S4.SS1.SSS3.p8.4.m4.1.1.cmml" xref="S4.SS1.SSS3.p8.4.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p8.4.m4.1c">\sim</annotation></semantics></math>200B 수학-헤비 토큰). Llemma의 사전 훈련 데이터도 정규화의 한 형태로 5%의 일반 도메인 데이터를 포함하고 있음에 유의한다.</p>
</div>
<div id="S4.SS1.SSS3.p9" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS3.p9.3"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p9.1.m1.1"><semantics id="S4.SS1.SSS3.p9.1.m1.1a"><mo id="S4.SS1.SSS3.p9.1.m1.1.1" xref="S4.SS1.SSS3.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p9.1.m1.1b"><ci id="S4.SS1.SSS3.p9.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p9.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p9.3.1">Long context</em>. 긴 컨텍스트 모델링은 LLMs에 중요한 능력이며, 많은 연구에서 LLMs의 컨텍스트 창을 지속적으로 훈련하는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib235" title="">235</a>, <a class="ltx_ref" href="#bib.bib238" title="">238</a>]</cite>를 통해 확장하는 것을 탐구했다. RoPE 기반 LLMs의 위치 임베딩(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS3.p9.3.2">i.e.,</em> position interpolation)에 대한 수정으로, CodeLLaMA는 LLaMA 2의 컨텍스트 창을 추가로 확장한다(4K 컨텍스트 창을 갖는 2.5T 토큰 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p9.2.m2.1"><semantics id="S4.SS1.SSS3.p9.2.m2.1a"><mo id="S4.SS1.SSS3.p9.2.m2.1.1" stretchy="false" xref="S4.SS1.SSS3.p9.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p9.2.m2.1b"><ci id="S4.SS1.SSS3.p9.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p9.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p9.2.m2.1c">\rightarrow</annotation></semantics></math> 16K 컨텍스트 창을 갖는 20B 토큰). LongLLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib238" title="">238</a>]</cite>는 또한 외부 메모리와 고유한 훈련 목적(2K 컨텍스트 창을 가진 1T 토큰 <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p9.3.m3.1"><semantics id="S4.SS1.SSS3.p9.3.m3.1a"><mo id="S4.SS1.SSS3.p9.3.m3.1.1" stretchy="false" xref="S4.SS1.SSS3.p9.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p9.3.m3.1b"><ci id="S4.SS1.SSS3.p9.3.m3.1.1.cmml" xref="S4.SS1.SSS3.p9.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p9.3.m3.1c">\rightarrow</annotation></semantics></math>8K 컨텍스트 창을 가진 10B 토큰)의 도움으로 더 긴 컨텍스트 창을 달성한다.</p>
</div>
</section>
<section id="S4.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4 </span>Summary of Data Preparation</h4>

<div id="S4.SS1.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS4.p1.1">이 부분에서는 LLMs에 대한 사전 훈련 자료를 마련하기 위한 일반적인 절차와 핵심 사항을 정리하는데, 다음 세 가지 측면에서 자세히 설명된다.</p>
</div>
<div id="S4.SS1.SSS4.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS4.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS4.p2.1.m1.1"><semantics id="S4.SS1.SSS4.p2.1.m1.1a"><mo id="S4.SS1.SSS4.p2.1.m1.1.1" xref="S4.SS1.SSS4.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p2.1.m1.1b"><ci id="S4.SS1.SSS4.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS4.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p2.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS4.p2.1.1">Data collection. </em> 사전 훈련 데이터에 다양한 데이터 소스를 포함할 것을 제안한다. Falcon<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib141" title="">141</a>]</cite>는 웹 페이지만으로 강력한 LLM을 훈련할 수 있음을 보여주지만, 보다 전형적인 접근법은 코드, 책, 과학 논문, <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS4.p2.1.2">etc</em>과 같은 다양한 고품질 텍스트를 통합하는 것이다. LLM이 특정 기술로 전문화되면 그에 따라 해당 데이터 소스의 비율이 증가해야 한다. 예를 들어, Gopher <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>와 Chinchilla <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>는 책의 대략 40%의 데이터로 학습된다. PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>]</cite>와 LaMDA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite>는 대략 50%의 회화 데이터를 사용한다.</p>
</div>
<div id="S4.SS1.SSS4.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS4.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS4.p3.1.m1.1"><semantics id="S4.SS1.SSS4.p3.1.m1.1a"><mo id="S4.SS1.SSS4.p3.1.m1.1.1" xref="S4.SS1.SSS4.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p3.1.m1.1b"><ci id="S4.SS1.SSS4.p3.1.m1.1.1.cmml" xref="S4.SS1.SSS4.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS4.p3.1.1">Data cleaning. </em> 데이터 수집 후에는 가능한 한 품질을 향상시키기 위해 원시 말뭉치를 청소하는 것이 중요합니다. 먼저, 중복제거는 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>, <a class="ltx_ref" href="#bib.bib229" title="">229</a>, <a class="ltx_ref" href="#bib.bib141" title="">141</a>]</cite>에서 일반적으로 사용된다. 둘째, 프라이버시 염려가 있는 저품질 텍스트, 독성 콘텐츠 및 데이터는 서로 다른 입도에서 제거되어야 한다(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS4.p3.1.2">e.g.,</em> document, passage 또는 sentence). 실제로 휴리스틱 및 분류기 기반 방법 모두 품질 및 독성 필터링에 사용될 수 있다(<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS4.p3.1.3">e.g.,</em> CCNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib241" title="">241</a>]</cite>, fastText <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib242" title="">242</a>]</cite>, and Data-Juicer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib243" title="">243</a>]</cite>). 셋째, 청소된 데이터를 사용하여 사전 훈련 데이터의 형식을 추가로 통일하거나 지정할 수 있으며, SentencePiece <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib226" title="">226</a>]</cite>와 같은 라이브러리로 필터링되고 중복 제거된 코퍼스에 토큰라이저를 훈련하여 토큰화를 수행할 수 있다.</p>
</div>
<div id="S4.SS1.SSS4.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS4.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS4.p4.1.m1.1"><semantics id="S4.SS1.SSS4.p4.1.m1.1a"><mo id="S4.SS1.SSS4.p4.1.m1.1.1" xref="S4.SS1.SSS4.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p4.1.m1.1b"><ci id="S4.SS1.SSS4.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS4.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS4.p4.1.1">Data scheduling. </em> 전처리된 데이터를 사용하여 다음 단계는 LLM을 사전 훈련하기 위한 데이터 혼합 및 데이터의 특정 순서를 결정하는 것이다. 두 설정을 모두 결정하기 위해 실용적인 방법은 먼저 여러 후보 계획을 가진 여러 작은 언어 모델을 훈련한 다음 그 중 좋은 계획을 선택하는 것이다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite> 전반적으로 적합한 데이터 커리큘럼을 찾기가 더 어렵다. 실제로 특정 평가 벤치마크에 대한 중간 모델 체크포인트의 성능을 모니터링하고 사전 훈련 동안 데이터 혼합 및 분포를 동적으로 조정할 수 있다. 이 과정에서 데이터 소스와 모델 능력 사이의 잠재적 관계를 탐색하여 데이터 커리큘럼 설계를 지도하는 것도 유용하다.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span id="S4.SS2.1.1" class="ltx_text ltx_font_italic">Architecture</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p1.1">이 섹션에서는 LLMs, <em class="ltx_emph ltx_font_italic" id="S4.SS2.p1.1.1">i.e.,</em> 주류 아키텍처, 사전 훈련 목적 및 세부 구성의 아키텍처 설계를 검토한다. Table <a class="ltx_ref" href="#S4.T5" title="TABLE V ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">V</span></a>는 공개 세부 정보를 가진 여러 대표 LLM의 모델 카드를 제시하고 있다.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V:</span>공개 구성 세부 정보를 가진 몇 개의 선택된 LLM의 모델 카드. 여기서, PE는 위치 임베딩을 의미하고, #L은 레이어의 개수를 의미하고, #H는 어텐션 헤드의 개수를 의미하고, <math alttext="d_{model}" class="ltx_Math" display="inline" id="S4.T5.2.m1.1"><semantics id="S4.T5.2.m1.1b"><msub id="S4.T5.2.m1.1.1" xref="S4.T5.2.m1.1.1.cmml"><mi id="S4.T5.2.m1.1.1.2" xref="S4.T5.2.m1.1.1.2.cmml">d</mi><mrow id="S4.T5.2.m1.1.1.3" xref="S4.T5.2.m1.1.1.3.cmml"><mi id="S4.T5.2.m1.1.1.3.2" xref="S4.T5.2.m1.1.1.3.2.cmml">m</mi><mo id="S4.T5.2.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S4.T5.2.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.2.m1.1.1.3.3" xref="S4.T5.2.m1.1.1.3.3.cmml">o</mi><mo id="S4.T5.2.m1.1.1.3.1b" lspace="0em" rspace="0em" xref="S4.T5.2.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.2.m1.1.1.3.4" xref="S4.T5.2.m1.1.1.3.4.cmml">d</mi><mo id="S4.T5.2.m1.1.1.3.1c" lspace="0em" rspace="0em" xref="S4.T5.2.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.2.m1.1.1.3.5" xref="S4.T5.2.m1.1.1.3.5.cmml">e</mi><mo id="S4.T5.2.m1.1.1.3.1d" lspace="0em" rspace="0em" xref="S4.T5.2.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.2.m1.1.1.3.6" xref="S4.T5.2.m1.1.1.3.6.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.2.m1.1c"><apply id="S4.T5.2.m1.1.1.cmml" xref="S4.T5.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.2.m1.1.1.1.cmml" xref="S4.T5.2.m1.1.1">subscript</csymbol><ci id="S4.T5.2.m1.1.1.2.cmml" xref="S4.T5.2.m1.1.1.2">𝑑</ci><apply id="S4.T5.2.m1.1.1.3.cmml" xref="S4.T5.2.m1.1.1.3"><times id="S4.T5.2.m1.1.1.3.1.cmml" xref="S4.T5.2.m1.1.1.3.1"></times><ci id="S4.T5.2.m1.1.1.3.2.cmml" xref="S4.T5.2.m1.1.1.3.2">𝑚</ci><ci id="S4.T5.2.m1.1.1.3.3.cmml" xref="S4.T5.2.m1.1.1.3.3">𝑜</ci><ci id="S4.T5.2.m1.1.1.3.4.cmml" xref="S4.T5.2.m1.1.1.3.4">𝑑</ci><ci id="S4.T5.2.m1.1.1.3.5.cmml" xref="S4.T5.2.m1.1.1.3.5">𝑒</ci><ci id="S4.T5.2.m1.1.1.3.6.cmml" xref="S4.T5.2.m1.1.1.3.6">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.m1.1d">d_{model}</annotation></semantics></math>는 히든 스테이트의 크기를 의미하고, MCL은 트레이닝 시 최대 컨텍스트 길이를 의미한다.</figcaption>
<table id="S4.T5.10" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S4.T5.3.1" class="ltx_tr">
<td id="S4.T5.3.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T5.3.1.2.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S4.T5.3.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.3.1.3.1" class="ltx_text ltx_font_bold">Category</span></td>
<td id="S4.T5.3.1.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="S4.T5.3.1.4.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="S4.T5.3.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.3.1.5.1" class="ltx_text ltx_font_bold">Normalization</span></td>
<td id="S4.T5.3.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.3.1.6.1" class="ltx_text ltx_font_bold">PE</span></td>
<td id="S4.T5.3.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.3.1.7.1" class="ltx_text ltx_font_bold">Activation</span></td>
<td id="S4.T5.3.1.8" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.3.1.8.1" class="ltx_text ltx_font_bold">Bias</span></td>
<td id="S4.T5.3.1.9" class="ltx_td ltx_align_right ltx_border_tt"><span id="S4.T5.3.1.9.1" class="ltx_text ltx_font_bold">#L</span></td>
<td id="S4.T5.3.1.10" class="ltx_td ltx_align_right ltx_border_tt"><span id="S4.T5.3.1.10.1" class="ltx_text ltx_font_bold">#H</span></td>
<td id="S4.T5.3.1.1" class="ltx_td ltx_align_right ltx_border_tt"><math id="S4.T5.3.1.1.m1.1" class="ltx_Math" alttext="d_{model}" display="inline"><semantics id="S4.T5.3.1.1.m1.1a"><msub id="S4.T5.3.1.1.m1.1.1" xref="S4.T5.3.1.1.m1.1.1.cmml"><mi id="S4.T5.3.1.1.m1.1.1.2" xref="S4.T5.3.1.1.m1.1.1.2.cmml">d</mi><mrow id="S4.T5.3.1.1.m1.1.1.3" xref="S4.T5.3.1.1.m1.1.1.3.cmml"><mi id="S4.T5.3.1.1.m1.1.1.3.2" xref="S4.T5.3.1.1.m1.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T5.3.1.1.m1.1.1.3.1" xref="S4.T5.3.1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.3.1.1.m1.1.1.3.3" xref="S4.T5.3.1.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.T5.3.1.1.m1.1.1.3.1a" xref="S4.T5.3.1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.3.1.1.m1.1.1.3.4" xref="S4.T5.3.1.1.m1.1.1.3.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.T5.3.1.1.m1.1.1.3.1b" xref="S4.T5.3.1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.3.1.1.m1.1.1.3.5" xref="S4.T5.3.1.1.m1.1.1.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.T5.3.1.1.m1.1.1.3.1c" xref="S4.T5.3.1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.T5.3.1.1.m1.1.1.3.6" xref="S4.T5.3.1.1.m1.1.1.3.6.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T5.3.1.1.m1.1b"><apply id="S4.T5.3.1.1.m1.1.1.cmml" xref="S4.T5.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.3.1.1.m1.1.1.1.cmml" xref="S4.T5.3.1.1.m1.1.1">subscript</csymbol><ci id="S4.T5.3.1.1.m1.1.1.2.cmml" xref="S4.T5.3.1.1.m1.1.1.2">𝑑</ci><apply id="S4.T5.3.1.1.m1.1.1.3.cmml" xref="S4.T5.3.1.1.m1.1.1.3"><times id="S4.T5.3.1.1.m1.1.1.3.1.cmml" xref="S4.T5.3.1.1.m1.1.1.3.1"></times><ci id="S4.T5.3.1.1.m1.1.1.3.2.cmml" xref="S4.T5.3.1.1.m1.1.1.3.2">𝑚</ci><ci id="S4.T5.3.1.1.m1.1.1.3.3.cmml" xref="S4.T5.3.1.1.m1.1.1.3.3">𝑜</ci><ci id="S4.T5.3.1.1.m1.1.1.3.4.cmml" xref="S4.T5.3.1.1.m1.1.1.3.4">𝑑</ci><ci id="S4.T5.3.1.1.m1.1.1.3.5.cmml" xref="S4.T5.3.1.1.m1.1.1.3.5">𝑒</ci><ci id="S4.T5.3.1.1.m1.1.1.3.6.cmml" xref="S4.T5.3.1.1.m1.1.1.3.6">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.1.1.m1.1c">d_{model}</annotation></semantics></math></td>
<td id="S4.T5.3.1.11" class="ltx_td ltx_align_right ltx_border_tt"><span id="S4.T5.3.1.11.1" class="ltx_text ltx_font_bold">MCL</span></td>
</tr>
<tr id="S4.T5.10.9" class="ltx_tr">
<td id="S4.T5.10.9.1" class="ltx_td ltx_align_left ltx_border_t">GPT3&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>
</td>
<td id="S4.T5.10.9.2" class="ltx_td ltx_align_center ltx_border_t">Causal decoder</td>
<td id="S4.T5.10.9.3" class="ltx_td ltx_align_right ltx_border_t">175B</td>
<td id="S4.T5.10.9.4" class="ltx_td ltx_align_center ltx_border_t">Pre LayerNorm</td>
<td id="S4.T5.10.9.5" class="ltx_td ltx_align_center ltx_border_t">Learned</td>
<td id="S4.T5.10.9.6" class="ltx_td ltx_align_center ltx_border_t">GeLU</td>
<td id="S4.T5.10.9.7" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T5.10.9.8" class="ltx_td ltx_align_right ltx_border_t">96</td>
<td id="S4.T5.10.9.9" class="ltx_td ltx_align_right ltx_border_t">96</td>
<td id="S4.T5.10.9.10" class="ltx_td ltx_align_right ltx_border_t">12288</td>
<td id="S4.T5.10.9.11" class="ltx_td ltx_align_right ltx_border_t">2048</td>
</tr>
<tr id="S4.T5.4.2" class="ltx_tr">
<td id="S4.T5.4.2.1" class="ltx_td ltx_align_left">PanGU-&nbsp;<math id="S4.T5.4.2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T5.4.2.1.m1.1a"><mi id="S4.T5.4.2.1.m1.1.1" xref="S4.T5.4.2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.T5.4.2.1.m1.1b"><ci id="S4.T5.4.2.1.m1.1.1.cmml" xref="S4.T5.4.2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.2.1.m1.1c">\alpha</annotation></semantics></math>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>
</td>
<td id="S4.T5.4.2.2" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.4.2.3" class="ltx_td ltx_align_right">207B</td>
<td id="S4.T5.4.2.4" class="ltx_td ltx_align_center">Pre LayerNorm</td>
<td id="S4.T5.4.2.5" class="ltx_td ltx_align_center">Learned</td>
<td id="S4.T5.4.2.6" class="ltx_td ltx_align_center">GeLU</td>
<td id="S4.T5.4.2.7" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.2.8" class="ltx_td ltx_align_right">64</td>
<td id="S4.T5.4.2.9" class="ltx_td ltx_align_right">128</td>
<td id="S4.T5.4.2.10" class="ltx_td ltx_align_right">16384</td>
<td id="S4.T5.4.2.11" class="ltx_td ltx_align_right">1024</td>
</tr>
<tr id="S4.T5.10.10" class="ltx_tr">
<td id="S4.T5.10.10.1" class="ltx_td ltx_align_left">OPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>
</td>
<td id="S4.T5.10.10.2" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.10.10.3" class="ltx_td ltx_align_right">175B</td>
<td id="S4.T5.10.10.4" class="ltx_td ltx_align_center">Pre LayerNorm</td>
<td id="S4.T5.10.10.5" class="ltx_td ltx_align_center">Learned</td>
<td id="S4.T5.10.10.6" class="ltx_td ltx_align_center">ReLU</td>
<td id="S4.T5.10.10.7" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.10.10.8" class="ltx_td ltx_align_right">96</td>
<td id="S4.T5.10.10.9" class="ltx_td ltx_align_right">96</td>
<td id="S4.T5.10.10.10" class="ltx_td ltx_align_right">12288</td>
<td id="S4.T5.10.10.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.5.3" class="ltx_tr">
<td id="S4.T5.5.3.2" class="ltx_td ltx_align_left">PaLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>
</td>
<td id="S4.T5.5.3.3" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.5.3.4" class="ltx_td ltx_align_right">540B</td>
<td id="S4.T5.5.3.5" class="ltx_td ltx_align_center">Pre LayerNorm</td>
<td id="S4.T5.5.3.6" class="ltx_td ltx_align_center">RoPE</td>
<td id="S4.T5.5.3.7" class="ltx_td ltx_align_center">SwiGLU</td>
<td id="S4.T5.5.3.1" class="ltx_td ltx_align_center"><math id="S4.T5.5.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.5.3.1.m1.1a"><mo id="S4.T5.5.3.1.m1.1.1" xref="S4.T5.5.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T5.5.3.1.m1.1b"><times id="S4.T5.5.3.1.m1.1.1.cmml" xref="S4.T5.5.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.3.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.5.3.8" class="ltx_td ltx_align_right">118</td>
<td id="S4.T5.5.3.9" class="ltx_td ltx_align_right">48</td>
<td id="S4.T5.5.3.10" class="ltx_td ltx_align_right">18432</td>
<td id="S4.T5.5.3.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.10.11" class="ltx_tr">
<td id="S4.T5.10.11.1" class="ltx_td ltx_align_left">BLOOM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>
</td>
<td id="S4.T5.10.11.2" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.10.11.3" class="ltx_td ltx_align_right">176B</td>
<td id="S4.T5.10.11.4" class="ltx_td ltx_align_center">Pre LayerNorm</td>
<td id="S4.T5.10.11.5" class="ltx_td ltx_align_center">ALiBi</td>
<td id="S4.T5.10.11.6" class="ltx_td ltx_align_center">GeLU</td>
<td id="S4.T5.10.11.7" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.10.11.8" class="ltx_td ltx_align_right">70</td>
<td id="S4.T5.10.11.9" class="ltx_td ltx_align_right">112</td>
<td id="S4.T5.10.11.10" class="ltx_td ltx_align_right">14336</td>
<td id="S4.T5.10.11.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.10.12" class="ltx_tr">
<td id="S4.T5.10.12.1" class="ltx_td ltx_align_left">MT-NLG&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite>
</td>
<td id="S4.T5.10.12.2" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.10.12.3" class="ltx_td ltx_align_right">530B</td>
<td id="S4.T5.10.12.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.12.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.12.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.12.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.12.8" class="ltx_td ltx_align_right">105</td>
<td id="S4.T5.10.12.9" class="ltx_td ltx_align_right">128</td>
<td id="S4.T5.10.12.10" class="ltx_td ltx_align_right">20480</td>
<td id="S4.T5.10.12.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.10.13" class="ltx_tr">
<td id="S4.T5.10.13.1" class="ltx_td ltx_align_left">Gopher&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>
</td>
<td id="S4.T5.10.13.2" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.10.13.3" class="ltx_td ltx_align_right">280B</td>
<td id="S4.T5.10.13.4" class="ltx_td ltx_align_center">Pre RMSNorm</td>
<td id="S4.T5.10.13.5" class="ltx_td ltx_align_center">Relative</td>
<td id="S4.T5.10.13.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.13.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.13.8" class="ltx_td ltx_align_right">80</td>
<td id="S4.T5.10.13.9" class="ltx_td ltx_align_right">128</td>
<td id="S4.T5.10.13.10" class="ltx_td ltx_align_right">16384</td>
<td id="S4.T5.10.13.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.10.14" class="ltx_tr">
<td id="S4.T5.10.14.1" class="ltx_td ltx_align_left">Chinchilla&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>
</td>
<td id="S4.T5.10.14.2" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.10.14.3" class="ltx_td ltx_align_right">70B</td>
<td id="S4.T5.10.14.4" class="ltx_td ltx_align_center">Pre RMSNorm</td>
<td id="S4.T5.10.14.5" class="ltx_td ltx_align_center">Relative</td>
<td id="S4.T5.10.14.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.14.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.14.8" class="ltx_td ltx_align_right">80</td>
<td id="S4.T5.10.14.9" class="ltx_td ltx_align_right">64</td>
<td id="S4.T5.10.14.10" class="ltx_td ltx_align_right">8192</td>
<td id="S4.T5.10.14.11" class="ltx_td ltx_align_right">-</td>
</tr>
<tr id="S4.T5.6.4" class="ltx_tr">
<td id="S4.T5.6.4.2" class="ltx_td ltx_align_left">Galactica&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="S4.T5.6.4.3" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.6.4.4" class="ltx_td ltx_align_right">120B</td>
<td id="S4.T5.6.4.5" class="ltx_td ltx_align_center">Pre LayerNorm</td>
<td id="S4.T5.6.4.6" class="ltx_td ltx_align_center">Learned</td>
<td id="S4.T5.6.4.7" class="ltx_td ltx_align_center">GeLU</td>
<td id="S4.T5.6.4.1" class="ltx_td ltx_align_center"><math id="S4.T5.6.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.6.4.1.m1.1a"><mo id="S4.T5.6.4.1.m1.1.1" xref="S4.T5.6.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.4.1.m1.1b"><times id="S4.T5.6.4.1.m1.1.1.cmml" xref="S4.T5.6.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.4.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.6.4.8" class="ltx_td ltx_align_right">96</td>
<td id="S4.T5.6.4.9" class="ltx_td ltx_align_right">80</td>
<td id="S4.T5.6.4.10" class="ltx_td ltx_align_right">10240</td>
<td id="S4.T5.6.4.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.10.15" class="ltx_tr">
<td id="S4.T5.10.15.1" class="ltx_td ltx_align_left">LaMDA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>
</td>
<td id="S4.T5.10.15.2" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.10.15.3" class="ltx_td ltx_align_right">137B</td>
<td id="S4.T5.10.15.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.15.5" class="ltx_td ltx_align_center">Relative</td>
<td id="S4.T5.10.15.6" class="ltx_td ltx_align_center">GeGLU</td>
<td id="S4.T5.10.15.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T5.10.15.8" class="ltx_td ltx_align_right">64</td>
<td id="S4.T5.10.15.9" class="ltx_td ltx_align_right">128</td>
<td id="S4.T5.10.15.10" class="ltx_td ltx_align_right">8192</td>
<td id="S4.T5.10.15.11" class="ltx_td ltx_align_right">-</td>
</tr>
<tr id="S4.T5.10.16" class="ltx_tr">
<td id="S4.T5.10.16.1" class="ltx_td ltx_align_left">Jurassic-1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>
</td>
<td id="S4.T5.10.16.2" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.10.16.3" class="ltx_td ltx_align_right">178B</td>
<td id="S4.T5.10.16.4" class="ltx_td ltx_align_center">Pre LayerNorm</td>
<td id="S4.T5.10.16.5" class="ltx_td ltx_align_center">Learned</td>
<td id="S4.T5.10.16.6" class="ltx_td ltx_align_center">GeLU</td>
<td id="S4.T5.10.16.7" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.10.16.8" class="ltx_td ltx_align_right">76</td>
<td id="S4.T5.10.16.9" class="ltx_td ltx_align_right">96</td>
<td id="S4.T5.10.16.10" class="ltx_td ltx_align_right">13824</td>
<td id="S4.T5.10.16.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.7.5" class="ltx_tr">
<td id="S4.T5.7.5.2" class="ltx_td ltx_align_left">LLaMA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="S4.T5.7.5.3" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.7.5.4" class="ltx_td ltx_align_right">65B</td>
<td id="S4.T5.7.5.5" class="ltx_td ltx_align_center">Pre RMSNorm</td>
<td id="S4.T5.7.5.6" class="ltx_td ltx_align_center">RoPE</td>
<td id="S4.T5.7.5.7" class="ltx_td ltx_align_center">SwiGLU</td>
<td id="S4.T5.7.5.1" class="ltx_td ltx_align_center"><math id="S4.T5.7.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.7.5.1.m1.1a"><mo id="S4.T5.7.5.1.m1.1.1" xref="S4.T5.7.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T5.7.5.1.m1.1b"><times id="S4.T5.7.5.1.m1.1.1.cmml" xref="S4.T5.7.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.5.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.7.5.8" class="ltx_td ltx_align_right">80</td>
<td id="S4.T5.7.5.9" class="ltx_td ltx_align_right">64</td>
<td id="S4.T5.7.5.10" class="ltx_td ltx_align_right">8192</td>
<td id="S4.T5.7.5.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.8.6" class="ltx_tr">
<td id="S4.T5.8.6.2" class="ltx_td ltx_align_left">LLaMA 2&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>
</td>
<td id="S4.T5.8.6.3" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.8.6.4" class="ltx_td ltx_align_right">70B</td>
<td id="S4.T5.8.6.5" class="ltx_td ltx_align_center">Pre RMSNorm</td>
<td id="S4.T5.8.6.6" class="ltx_td ltx_align_center">RePE</td>
<td id="S4.T5.8.6.7" class="ltx_td ltx_align_center">SwiGLU</td>
<td id="S4.T5.8.6.1" class="ltx_td ltx_align_center"><math id="S4.T5.8.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.8.6.1.m1.1a"><mo id="S4.T5.8.6.1.m1.1.1" xref="S4.T5.8.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T5.8.6.1.m1.1b"><times id="S4.T5.8.6.1.m1.1.1.cmml" xref="S4.T5.8.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.6.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.8.6.8" class="ltx_td ltx_align_right">80</td>
<td id="S4.T5.8.6.9" class="ltx_td ltx_align_right">64</td>
<td id="S4.T5.8.6.10" class="ltx_td ltx_align_right">8192</td>
<td id="S4.T5.8.6.11" class="ltx_td ltx_align_right">4096</td>
</tr>
<tr id="S4.T5.9.7" class="ltx_tr">
<td id="S4.T5.9.7.2" class="ltx_td ltx_align_left">Falcon&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite>
</td>
<td id="S4.T5.9.7.3" class="ltx_td ltx_align_center">Causal decoder</td>
<td id="S4.T5.9.7.4" class="ltx_td ltx_align_right">40B</td>
<td id="S4.T5.9.7.5" class="ltx_td ltx_align_center">Pre LayerNorm</td>
<td id="S4.T5.9.7.6" class="ltx_td ltx_align_center">RoPE</td>
<td id="S4.T5.9.7.7" class="ltx_td ltx_align_center">GeLU</td>
<td id="S4.T5.9.7.1" class="ltx_td ltx_align_center"><math id="S4.T5.9.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.9.7.1.m1.1a"><mo id="S4.T5.9.7.1.m1.1.1" xref="S4.T5.9.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T5.9.7.1.m1.1b"><times id="S4.T5.9.7.1.m1.1.1.cmml" xref="S4.T5.9.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.7.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.9.7.8" class="ltx_td ltx_align_right">60</td>
<td id="S4.T5.9.7.9" class="ltx_td ltx_align_right">64</td>
<td id="S4.T5.9.7.10" class="ltx_td ltx_align_right">8192</td>
<td id="S4.T5.9.7.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.10.17" class="ltx_tr">
<td id="S4.T5.10.17.1" class="ltx_td ltx_align_left">GLM-130B&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>
</td>
<td id="S4.T5.10.17.2" class="ltx_td ltx_align_center">Prefix decoder</td>
<td id="S4.T5.10.17.3" class="ltx_td ltx_align_right">130B</td>
<td id="S4.T5.10.17.4" class="ltx_td ltx_align_center">Post DeepNorm</td>
<td id="S4.T5.10.17.5" class="ltx_td ltx_align_center">RoPE</td>
<td id="S4.T5.10.17.6" class="ltx_td ltx_align_center">GeGLU</td>
<td id="S4.T5.10.17.7" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.10.17.8" class="ltx_td ltx_align_right">70</td>
<td id="S4.T5.10.17.9" class="ltx_td ltx_align_right">96</td>
<td id="S4.T5.10.17.10" class="ltx_td ltx_align_right">12288</td>
<td id="S4.T5.10.17.11" class="ltx_td ltx_align_right">2048</td>
</tr>
<tr id="S4.T5.10.8" class="ltx_tr">
<td id="S4.T5.10.8.2" class="ltx_td ltx_align_left ltx_border_bb">T5&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>
</td>
<td id="S4.T5.10.8.3" class="ltx_td ltx_align_center ltx_border_bb">Encoder-decoder</td>
<td id="S4.T5.10.8.4" class="ltx_td ltx_align_right ltx_border_bb">11B</td>
<td id="S4.T5.10.8.5" class="ltx_td ltx_align_center ltx_border_bb">Pre RMSNorm</td>
<td id="S4.T5.10.8.6" class="ltx_td ltx_align_center ltx_border_bb">Relative</td>
<td id="S4.T5.10.8.7" class="ltx_td ltx_align_center ltx_border_bb">ReLU</td>
<td id="S4.T5.10.8.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T5.10.8.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T5.10.8.1.m1.1a"><mo id="S4.T5.10.8.1.m1.1.1" xref="S4.T5.10.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T5.10.8.1.m1.1b"><times id="S4.T5.10.8.1.m1.1.1.cmml" xref="S4.T5.10.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.10.8.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T5.10.8.8" class="ltx_td ltx_align_right ltx_border_bb">24</td>
<td id="S4.T5.10.8.9" class="ltx_td ltx_align_right ltx_border_bb">128</td>
<td id="S4.T5.10.8.10" class="ltx_td ltx_align_right ltx_border_bb">1024</td>
<td id="S4.T5.10.8.11" class="ltx_td ltx_align_right ltx_border_bb">512</td>
</tr>
</tbody></table>
</figure>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Typical Architectures</h4>

<figure id="S4.F9" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x10.png" id="S4.F9.g1" class="ltx_graphics ltx_img_landscape" width="461" height="173" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">그림 9:</span>세 가지 주류 아키텍처에서 주의 패턴의 비교. 여기서, 청색, 녹색, 황색 및 회색의 둥근 직사각형들은 각각 접두사 토큰들 사이의 주의, 접두사와 타겟 토큰들 사이의 주의, 타겟 토큰들 사이의 주의, 마스킹된 주의들을 나타낸다.</figcaption>
</figure>
<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">뛰어난 병렬성과 용량으로 인해 트랜스포머 아키텍처 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>는 다양한 LLM을 개발하는 사실상의 백본이 되어 언어 모델을 수백억 또는 수천억 개의 매개변수로 확장할 수 있게 되었다. 일반적으로 기존 LLM의 주류 아키텍처는 그림<a class="ltx_ref" href="#S4.F9" title="Figure 9 ‣ 4.2.1 Typical Architectures ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">9</span></a>와 같이 인코더-디코더, 인과 디코더, 프리픽스 디코더의 세 가지 주요 유형으로 대별될 수 있다.</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p2.1.1">Encoder-decoder Architecture. </span> 바닐라 트랜스포머 모델은 인코더-디코더 아키텍처 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>에 구축되었으며, 인코더와 디코더는 각각 트랜스포머 블록의 두 스택으로 구성된다. 인코더는 그의 잠재 표현들을 생성하기 위해 입력 시퀀스를 인코딩하기 위해 적층된 멀티헤드 셀프-어텐션 계층들을 채택하는 반면, 디코더는 이들 표현들에 대해 교차-어텐션을 수행하고 타겟 시퀀스를 자동-순차적으로 생성한다. Encoder-decoder PLMs (<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS1.p2.1.2">e.g.,</em> T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite> and BART <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite>)는 다양한 NLP 태스크에 대한 유효성을 보여주었다. 지금까지 인코더-디코더 아키텍처를 기반으로 구축된 LLM은 <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS1.p2.1.3">e.g.,</em> Flan-T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>에 불과하다. 우리는 섹션 <a class="ltx_ref" href="#S4.SS2.SSS6" title="4.2.6 Summary and Discussion ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.6</span></a>에서 아키텍처 선택에 대한 자세한 논의를 남긴다.</p>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p3.1.1">Causal Decoder Architecture. </span> 인과 디코더 아키텍처는 각 입력 토큰이 과거 토큰 및 자체에만 참석할 수 있음을 보장하기 위해 단방향 주의 마스크를 통합한다. 입력 토큰과 출력 토큰은 디코더를 통해 동일한 방식으로 처리된다. 이 아키텍처의 대표적인 언어 모델로서 GPT 계열 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>, <a class="ltx_ref" href="#bib.bib26" title="">26</a>, <a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>는 인과 디코더 아키텍처를 기반으로 개발되었다. 특히 GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>는 LLM의 놀라운 상황 내 학습 능력을 보여주면서 이 아키텍처의 효과를 성공적으로 입증했다. 흥미롭게도 GPT-1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>]</cite>와 GPT-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>는 GPT-3과 같은 우수한 성능을 보이지 않으며, 스케일링이 이 모델 아키텍처의 모델 용량을 증가시키는 데 중요한 역할을 하는 것으로 보인다. 지금까지 인과적 디코더는 OPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite>, BLOOM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>, Gopher<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite> 등 기존의 다양한 LLM에 의해 LLM의 아키텍처로 널리 채택되어 왔다. 다음에 논의되는 인과 디코더 및 프리픽스 디코더는 모두 디코더 전용 아키텍처에 속한다는 점에 유의한다. "디코더 전용 아키텍처"를 언급할 때, 명시되지 않는 한, 주로 기존 문헌에서 인과적 디코더 아키텍처를 언급한다.</p>
</div>
<div id="S4.SS2.SSS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p4.1.1">Prefix Decoder Architecture. </span> prefix 디코더 아키텍처 (<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS1.p4.1.2">a.k.a.,</em> non-causal decoder <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib244" title="">244</a>]</cite>)는 인과 디코더의 마스킹 메커니즘을 수정하여 prefix 토큰에 대해 양방향 어텐션을 수행할 수 있도록 한다. 이러한 방식으로, 인코더-디코더 아키텍처와 같이, 프리픽스 디코더들은 프리픽스 시퀀스를 양방향으로 인코딩하고 출력 토큰들을 하나씩 자동회귀적으로 예측할 수 있으며, 여기서 동일한 파라미터들이 인코딩 및 디코딩 동안 공유된다. 스크래치로부터 사전-훈련 대신에, 실제적인 제안은 인과적 디코더들을 지속적으로 훈련시킨 다음 수렴을 가속화하기 위한 프리픽스 디코더들로 변환하는 것이다 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS1.p4.1.3">e.g.,</em> U-PaLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib118" title="">118</a>]</cite>는 PaLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>에서 유래된다. 접두사 디코더를 기반으로 하는 기존의 대표적인 LLM으로는 GLM-130B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>와 U-PaLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib118" title="">118</a>]</cite>가 있다.</p>
</div>
<div id="S4.SS2.SSS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p5.1.1">Mixture-of-Experts. </span> 위의 세 가지 유형의 아키텍처에 대해, 우리는 각 입력에 대한 신경망 가중치의 하위 집합이 희박하게 활성화되는, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS1.p5.1.2">e.g.,</em> Switch Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite> 및 GLaM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib112" title="">112</a>]</cite>를 통해 이들을 추가로 확장할 수 있다. 주요 장점은 MoE가 일정한 계산 비용 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite>를 유지하면서 모델 매개변수를 확장하는 유연한 방법이라는 것이다. 전문가 수 또는 전체 파라미터 크기 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib246" title="">246</a>]</cite>를 증가시키면 실질적인 성능 향상을 관찰할 수 있음을 보였다. 장점에도 불구하고 대규모 MoE 모델을 훈련하는 것은 라우팅 작업의 복잡하고 하드 스위칭 특성으로 인해 불안정성 문제를 겪을 수 있다. MoE 기반 언어 모델의 학습 안정성을 높이기 위해 라우팅 모듈에서 고정밀 텐서를 선택적으로 사용하거나 더 작은 범위로 모델을 초기화하는 등의 기술이 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite>에 소개되었다. 보다 최근에는 GPT-4가 MoE 아키텍처를 기반으로 개발되었지만 공식 검증이 없다는 추측이 널리 퍼지고 있다.</p>
</div>
<div id="S4.SS2.SSS1.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS1.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p6.1.1">Emergent Architectures. </span> 기존 트랜스포머 아키텍처는 일반적으로 2차 계산 복잡성을 겪습니다. 이 때문에 긴 투입으로 훈련하고 추론을 할 때 효율성이 중요한 이슈가 되었다. 효율성을 개선하기 위해 일부 연구에서는 매개변수화된 상태 공간 모델(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS1.p6.1.2">e.g.,</em> S4<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib247" title="">247</a>]</cite>, GSS<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib248" title="">248</a>]</cite>, 및 H3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib249" title="">249</a>]</cite>), Hyena<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib250" title="">250</a>]</cite>와 같은 긴 컨볼루션 및 재귀적 업데이트 메커니즘을 통합하는 Transformer 유사 아키텍처(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS1.p6.1.3">e.g.,</em> RWKV<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib251" title="">251</a>]</cite> 및 RetNet<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib252" title="">252</a>]</cite>)를 포함하는 언어 모델링을 위한 새로운 아키텍처를 고안하는 것을 목표로 한다. 이러한 새로운 아키텍처의 주요 장점은 두 가지입니다. 첫째, 이들 모델은 RNN과 같이 재귀적으로 출력을 생성할 수 있으며, 이는 디코딩 동안 단일 이전 상태를 참조하기만 하면 된다는 것을 의미한다. 기존의 트랜스포머에서와 같이 이전의 모든 상태를 다시 방문할 필요가 없기 때문에 디코딩 프로세스를 더 효율적으로 만든다. 둘째, 이 모델들은 트랜스포머와 같이 전체 문장을 병렬로 인코딩할 수 있는 능력을 가지고 있다. 이것은 토큰 단위로 문장을 인코딩해야 하는 기존의 RNN과 대조된다. 따라서 병렬 스캔 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib253" title="">253</a>, <a class="ltx_ref" href="#bib.bib254" title="">254</a>]</cite>, FFT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib250" title="">250</a>, <a class="ltx_ref" href="#bib.bib251" title="">251</a>]</cite>, Chunkwise Recurrent <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib252" title="">252</a>]</cite> 등의 기술로 GPU의 병렬성을 얻을 수 있다. 이러한 기술들은 이러한 새로운 아키텍처들을 갖는 모델들이 매우 병렬적이고 효율적인 방식으로 훈련될 수 있게 한다.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Detailed Configuration</h4>

<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VI:</span> 네트워크 구성들에 대한 상세한 공식들이다. 여기서, Sublayer는 Transformer 계층에서 FFN 또는 self-attention 모듈을 의미하고, <math alttext="d" class="ltx_Math" display="inline" id="S4.T6.8.m1.1"><semantics id="S4.T6.8.m1.1b"><mi id="S4.T6.8.m1.1.1" xref="S4.T6.8.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.T6.8.m1.1c"><ci id="S4.T6.8.m1.1.1.cmml" xref="S4.T6.8.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.8.m1.1d">d</annotation></semantics></math>는 hidden state의 크기를 의미하고, <math alttext="\mathbf{p}_{i}" class="ltx_Math" display="inline" id="S4.T6.9.m2.1"><semantics id="S4.T6.9.m2.1b"><msub id="S4.T6.9.m2.1.1" xref="S4.T6.9.m2.1.1.cmml"><mi id="S4.T6.9.m2.1.1.2" xref="S4.T6.9.m2.1.1.2.cmml">𝐩</mi><mi id="S4.T6.9.m2.1.1.3" xref="S4.T6.9.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T6.9.m2.1c"><apply id="S4.T6.9.m2.1.1.cmml" xref="S4.T6.9.m2.1.1"><csymbol cd="ambiguous" id="S4.T6.9.m2.1.1.1.cmml" xref="S4.T6.9.m2.1.1">subscript</csymbol><ci id="S4.T6.9.m2.1.1.2.cmml" xref="S4.T6.9.m2.1.1.2">𝐩</ci><ci id="S4.T6.9.m2.1.1.3.cmml" xref="S4.T6.9.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.9.m2.1d">\mathbf{p}_{i}</annotation></semantics></math>는 위치에서의 위치 임베딩 <math alttext="i" class="ltx_Math" display="inline" id="S4.T6.10.m3.1"><semantics id="S4.T6.10.m3.1b"><mi id="S4.T6.10.m3.1.1" xref="S4.T6.10.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.T6.10.m3.1c"><ci id="S4.T6.10.m3.1.1.cmml" xref="S4.T6.10.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.10.m3.1d">i</annotation></semantics></math>, <math alttext="A_{ij}" class="ltx_Math" display="inline" id="S4.T6.11.m4.1"><semantics id="S4.T6.11.m4.1b"><msub id="S4.T6.11.m4.1.1" xref="S4.T6.11.m4.1.1.cmml"><mi id="S4.T6.11.m4.1.1.2" xref="S4.T6.11.m4.1.1.2.cmml">A</mi><mrow id="S4.T6.11.m4.1.1.3" xref="S4.T6.11.m4.1.1.3.cmml"><mi id="S4.T6.11.m4.1.1.3.2" xref="S4.T6.11.m4.1.1.3.2.cmml">i</mi><mo id="S4.T6.11.m4.1.1.3.1" lspace="0em" rspace="0em" xref="S4.T6.11.m4.1.1.3.1.cmml">​</mo><mi id="S4.T6.11.m4.1.1.3.3" xref="S4.T6.11.m4.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T6.11.m4.1c"><apply id="S4.T6.11.m4.1.1.cmml" xref="S4.T6.11.m4.1.1"><csymbol cd="ambiguous" id="S4.T6.11.m4.1.1.1.cmml" xref="S4.T6.11.m4.1.1">subscript</csymbol><ci id="S4.T6.11.m4.1.1.2.cmml" xref="S4.T6.11.m4.1.1.2">𝐴</ci><apply id="S4.T6.11.m4.1.1.3.cmml" xref="S4.T6.11.m4.1.1.3"><times id="S4.T6.11.m4.1.1.3.1.cmml" xref="S4.T6.11.m4.1.1.3.1"></times><ci id="S4.T6.11.m4.1.1.3.2.cmml" xref="S4.T6.11.m4.1.1.3.2">𝑖</ci><ci id="S4.T6.11.m4.1.1.3.3.cmml" xref="S4.T6.11.m4.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.11.m4.1d">A_{ij}</annotation></semantics></math>는 쿼리와 키 간의 어텐션 스코어를 의미하고, <math alttext="r_{i-j}" class="ltx_Math" display="inline" id="S4.T6.12.m5.1"><semantics id="S4.T6.12.m5.1b"><msub id="S4.T6.12.m5.1.1" xref="S4.T6.12.m5.1.1.cmml"><mi id="S4.T6.12.m5.1.1.2" xref="S4.T6.12.m5.1.1.2.cmml">r</mi><mrow id="S4.T6.12.m5.1.1.3" xref="S4.T6.12.m5.1.1.3.cmml"><mi id="S4.T6.12.m5.1.1.3.2" xref="S4.T6.12.m5.1.1.3.2.cmml">i</mi><mo id="S4.T6.12.m5.1.1.3.1" xref="S4.T6.12.m5.1.1.3.1.cmml">−</mo><mi id="S4.T6.12.m5.1.1.3.3" xref="S4.T6.12.m5.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T6.12.m5.1c"><apply id="S4.T6.12.m5.1.1.cmml" xref="S4.T6.12.m5.1.1"><csymbol cd="ambiguous" id="S4.T6.12.m5.1.1.1.cmml" xref="S4.T6.12.m5.1.1">subscript</csymbol><ci id="S4.T6.12.m5.1.1.2.cmml" xref="S4.T6.12.m5.1.1.2">𝑟</ci><apply id="S4.T6.12.m5.1.1.3.cmml" xref="S4.T6.12.m5.1.1.3"><minus id="S4.T6.12.m5.1.1.3.1.cmml" xref="S4.T6.12.m5.1.1.3.1"></minus><ci id="S4.T6.12.m5.1.1.3.2.cmml" xref="S4.T6.12.m5.1.1.3.2">𝑖</ci><ci id="S4.T6.12.m5.1.1.3.3.cmml" xref="S4.T6.12.m5.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.12.m5.1d">r_{i-j}</annotation></semantics></math>는 쿼리와 키 간의 오프셋을 기반으로 학습 가능한 스칼라를 의미하고, <math alttext="\mathbf{R}_{\Theta,t}" class="ltx_Math" display="inline" id="S4.T6.13.m6.2"><semantics id="S4.T6.13.m6.2b"><msub id="S4.T6.13.m6.2.3" xref="S4.T6.13.m6.2.3.cmml"><mi id="S4.T6.13.m6.2.3.2" xref="S4.T6.13.m6.2.3.2.cmml">𝐑</mi><mrow id="S4.T6.13.m6.2.2.2.4" xref="S4.T6.13.m6.2.2.2.3.cmml"><mi id="S4.T6.13.m6.1.1.1.1" mathvariant="normal" xref="S4.T6.13.m6.1.1.1.1.cmml">Θ</mi><mo id="S4.T6.13.m6.2.2.2.4.1" xref="S4.T6.13.m6.2.2.2.3.cmml">,</mo><mi id="S4.T6.13.m6.2.2.2.2" xref="S4.T6.13.m6.2.2.2.2.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T6.13.m6.2c"><apply id="S4.T6.13.m6.2.3.cmml" xref="S4.T6.13.m6.2.3"><csymbol cd="ambiguous" id="S4.T6.13.m6.2.3.1.cmml" xref="S4.T6.13.m6.2.3">subscript</csymbol><ci id="S4.T6.13.m6.2.3.2.cmml" xref="S4.T6.13.m6.2.3.2">𝐑</ci><list id="S4.T6.13.m6.2.2.2.3.cmml" xref="S4.T6.13.m6.2.2.2.4"><ci id="S4.T6.13.m6.1.1.1.1.cmml" xref="S4.T6.13.m6.1.1.1.1">Θ</ci><ci id="S4.T6.13.m6.2.2.2.2.cmml" xref="S4.T6.13.m6.2.2.2.2">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.13.m6.2d">\mathbf{R}_{\Theta,t}</annotation></semantics></math>는 회전도를 갖는 회전 매트릭스 <math alttext="t\cdot\Theta" class="ltx_Math" display="inline" id="S4.T6.14.m7.1"><semantics id="S4.T6.14.m7.1b"><mrow id="S4.T6.14.m7.1.1" xref="S4.T6.14.m7.1.1.cmml"><mi id="S4.T6.14.m7.1.1.2" xref="S4.T6.14.m7.1.1.2.cmml">t</mi><mo id="S4.T6.14.m7.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.T6.14.m7.1.1.1.cmml">⋅</mo><mi id="S4.T6.14.m7.1.1.3" mathvariant="normal" xref="S4.T6.14.m7.1.1.3.cmml">Θ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.14.m7.1c"><apply id="S4.T6.14.m7.1.1.cmml" xref="S4.T6.14.m7.1.1"><ci id="S4.T6.14.m7.1.1.1.cmml" xref="S4.T6.14.m7.1.1.1">⋅</ci><ci id="S4.T6.14.m7.1.1.2.cmml" xref="S4.T6.14.m7.1.1.2">𝑡</ci><ci id="S4.T6.14.m7.1.1.3.cmml" xref="S4.T6.14.m7.1.1.3">Θ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.14.m7.1d">t\cdot\Theta</annotation></semantics></math>를 의미한다.</figcaption>
<table id="S4.T6.29" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S4.T6.29.16" class="ltx_tr">
<td id="S4.T6.29.16.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T6.29.16.1.1" class="ltx_text ltx_font_bold">Configuration</span></td>
<td id="S4.T6.29.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T6.29.16.2.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S4.T6.29.16.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T6.29.16.3.1" class="ltx_text ltx_font_bold">Equation</span></td>
</tr>
<tr id="S4.T6.15.1" class="ltx_tr">
<td id="S4.T6.15.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T6.15.1.2.1" class="ltx_text">Normalization position</span></td>
<td id="S4.T6.15.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Post Norm&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="S4.T6.15.1.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T6.15.1.1.m1.2" class="ltx_Math" alttext="\mathrm{Norm(}\mathbf{x}\mathrm{+Sublayer(}\mathbf{x}\mathrm{))}" display="inline"><semantics id="S4.T6.15.1.1.m1.2a"><mrow id="S4.T6.15.1.1.m1.2.2" xref="S4.T6.15.1.1.m1.2.2.cmml"><mi id="S4.T6.15.1.1.m1.2.2.3" xref="S4.T6.15.1.1.m1.2.2.3.cmml">Norm</mi><mo lspace="0em" rspace="0em" id="S4.T6.15.1.1.m1.2.2.2" xref="S4.T6.15.1.1.m1.2.2.2.cmml">​</mo><mrow id="S4.T6.15.1.1.m1.2.2.1.1" xref="S4.T6.15.1.1.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.T6.15.1.1.m1.2.2.1.1.2" xref="S4.T6.15.1.1.m1.2.2.1.1.1.cmml">(</mo><mrow id="S4.T6.15.1.1.m1.2.2.1.1.1" xref="S4.T6.15.1.1.m1.2.2.1.1.1.cmml"><mi id="S4.T6.15.1.1.m1.2.2.1.1.1.2" xref="S4.T6.15.1.1.m1.2.2.1.1.1.2.cmml">𝐱</mi><mo id="S4.T6.15.1.1.m1.2.2.1.1.1.1" xref="S4.T6.15.1.1.m1.2.2.1.1.1.1.cmml">+</mo><mrow id="S4.T6.15.1.1.m1.2.2.1.1.1.3" xref="S4.T6.15.1.1.m1.2.2.1.1.1.3.cmml"><mi id="S4.T6.15.1.1.m1.2.2.1.1.1.3.2" xref="S4.T6.15.1.1.m1.2.2.1.1.1.3.2.cmml">Sublayer</mi><mo lspace="0em" rspace="0em" id="S4.T6.15.1.1.m1.2.2.1.1.1.3.1" xref="S4.T6.15.1.1.m1.2.2.1.1.1.3.1.cmml">​</mo><mrow id="S4.T6.15.1.1.m1.2.2.1.1.1.3.3.2" xref="S4.T6.15.1.1.m1.2.2.1.1.1.3.cmml"><mo stretchy="false" id="S4.T6.15.1.1.m1.2.2.1.1.1.3.3.2.1" xref="S4.T6.15.1.1.m1.2.2.1.1.1.3.cmml">(</mo><mi id="S4.T6.15.1.1.m1.1.1" xref="S4.T6.15.1.1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.15.1.1.m1.2.2.1.1.1.3.3.2.2" xref="S4.T6.15.1.1.m1.2.2.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.T6.15.1.1.m1.2.2.1.1.3" xref="S4.T6.15.1.1.m1.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.15.1.1.m1.2b"><apply id="S4.T6.15.1.1.m1.2.2.cmml" xref="S4.T6.15.1.1.m1.2.2"><times id="S4.T6.15.1.1.m1.2.2.2.cmml" xref="S4.T6.15.1.1.m1.2.2.2"></times><ci id="S4.T6.15.1.1.m1.2.2.3.cmml" xref="S4.T6.15.1.1.m1.2.2.3">Norm</ci><apply id="S4.T6.15.1.1.m1.2.2.1.1.1.cmml" xref="S4.T6.15.1.1.m1.2.2.1.1"><plus id="S4.T6.15.1.1.m1.2.2.1.1.1.1.cmml" xref="S4.T6.15.1.1.m1.2.2.1.1.1.1"></plus><ci id="S4.T6.15.1.1.m1.2.2.1.1.1.2.cmml" xref="S4.T6.15.1.1.m1.2.2.1.1.1.2">𝐱</ci><apply id="S4.T6.15.1.1.m1.2.2.1.1.1.3.cmml" xref="S4.T6.15.1.1.m1.2.2.1.1.1.3"><times id="S4.T6.15.1.1.m1.2.2.1.1.1.3.1.cmml" xref="S4.T6.15.1.1.m1.2.2.1.1.1.3.1"></times><ci id="S4.T6.15.1.1.m1.2.2.1.1.1.3.2.cmml" xref="S4.T6.15.1.1.m1.2.2.1.1.1.3.2">Sublayer</ci><ci id="S4.T6.15.1.1.m1.1.1.cmml" xref="S4.T6.15.1.1.m1.1.1">𝐱</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.15.1.1.m1.2c">\mathrm{Norm(}\mathbf{x}\mathrm{+Sublayer(}\mathbf{x}\mathrm{))}</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.16.2" class="ltx_tr">
<td id="S4.T6.16.2.2" class="ltx_td ltx_align_center ltx_border_r">Pre Norm&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</td>
<td id="S4.T6.16.2.1" class="ltx_td ltx_align_left"><math id="S4.T6.16.2.1.m1.2" class="ltx_Math" alttext="\mathbf{x}+\mathrm{Sublayer}(\mathrm{Norm}(\mathbf{x}))" display="inline"><semantics id="S4.T6.16.2.1.m1.2a"><mrow id="S4.T6.16.2.1.m1.2.2" xref="S4.T6.16.2.1.m1.2.2.cmml"><mi id="S4.T6.16.2.1.m1.2.2.3" xref="S4.T6.16.2.1.m1.2.2.3.cmml">𝐱</mi><mo id="S4.T6.16.2.1.m1.2.2.2" xref="S4.T6.16.2.1.m1.2.2.2.cmml">+</mo><mrow id="S4.T6.16.2.1.m1.2.2.1" xref="S4.T6.16.2.1.m1.2.2.1.cmml"><mi id="S4.T6.16.2.1.m1.2.2.1.3" xref="S4.T6.16.2.1.m1.2.2.1.3.cmml">Sublayer</mi><mo lspace="0em" rspace="0em" id="S4.T6.16.2.1.m1.2.2.1.2" xref="S4.T6.16.2.1.m1.2.2.1.2.cmml">​</mo><mrow id="S4.T6.16.2.1.m1.2.2.1.1.1" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.16.2.1.m1.2.2.1.1.1.2" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.T6.16.2.1.m1.2.2.1.1.1.1" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.cmml"><mi id="S4.T6.16.2.1.m1.2.2.1.1.1.1.2" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.2.cmml">Norm</mi><mo lspace="0em" rspace="0em" id="S4.T6.16.2.1.m1.2.2.1.1.1.1.1" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.1.cmml">​</mo><mrow id="S4.T6.16.2.1.m1.2.2.1.1.1.1.3.2" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.16.2.1.m1.2.2.1.1.1.1.3.2.1" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.cmml">(</mo><mi id="S4.T6.16.2.1.m1.1.1" xref="S4.T6.16.2.1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.16.2.1.m1.2.2.1.1.1.1.3.2.2" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.T6.16.2.1.m1.2.2.1.1.1.3" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.16.2.1.m1.2b"><apply id="S4.T6.16.2.1.m1.2.2.cmml" xref="S4.T6.16.2.1.m1.2.2"><plus id="S4.T6.16.2.1.m1.2.2.2.cmml" xref="S4.T6.16.2.1.m1.2.2.2"></plus><ci id="S4.T6.16.2.1.m1.2.2.3.cmml" xref="S4.T6.16.2.1.m1.2.2.3">𝐱</ci><apply id="S4.T6.16.2.1.m1.2.2.1.cmml" xref="S4.T6.16.2.1.m1.2.2.1"><times id="S4.T6.16.2.1.m1.2.2.1.2.cmml" xref="S4.T6.16.2.1.m1.2.2.1.2"></times><ci id="S4.T6.16.2.1.m1.2.2.1.3.cmml" xref="S4.T6.16.2.1.m1.2.2.1.3">Sublayer</ci><apply id="S4.T6.16.2.1.m1.2.2.1.1.1.1.cmml" xref="S4.T6.16.2.1.m1.2.2.1.1.1"><times id="S4.T6.16.2.1.m1.2.2.1.1.1.1.1.cmml" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.1"></times><ci id="S4.T6.16.2.1.m1.2.2.1.1.1.1.2.cmml" xref="S4.T6.16.2.1.m1.2.2.1.1.1.1.2">Norm</ci><ci id="S4.T6.16.2.1.m1.1.1.cmml" xref="S4.T6.16.2.1.m1.1.1">𝐱</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.16.2.1.m1.2c">\mathbf{x}+\mathrm{Sublayer}(\mathrm{Norm}(\mathbf{x}))</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.17.3" class="ltx_tr">
<td id="S4.T6.17.3.2" class="ltx_td ltx_align_center ltx_border_r">Sandwich Norm&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib255" title="" class="ltx_ref">255</a>]</cite>
</td>
<td id="S4.T6.17.3.1" class="ltx_td ltx_align_left"><math id="S4.T6.17.3.1.m1.2" class="ltx_Math" alttext="\mathbf{x}+\mathrm{Norm}(\mathrm{Sublayer}(\mathrm{Norm}(\mathbf{x})))" display="inline"><semantics id="S4.T6.17.3.1.m1.2a"><mrow id="S4.T6.17.3.1.m1.2.2" xref="S4.T6.17.3.1.m1.2.2.cmml"><mi id="S4.T6.17.3.1.m1.2.2.3" xref="S4.T6.17.3.1.m1.2.2.3.cmml">𝐱</mi><mo id="S4.T6.17.3.1.m1.2.2.2" xref="S4.T6.17.3.1.m1.2.2.2.cmml">+</mo><mrow id="S4.T6.17.3.1.m1.2.2.1" xref="S4.T6.17.3.1.m1.2.2.1.cmml"><mi id="S4.T6.17.3.1.m1.2.2.1.3" xref="S4.T6.17.3.1.m1.2.2.1.3.cmml">Norm</mi><mo lspace="0em" rspace="0em" id="S4.T6.17.3.1.m1.2.2.1.2" xref="S4.T6.17.3.1.m1.2.2.1.2.cmml">​</mo><mrow id="S4.T6.17.3.1.m1.2.2.1.1.1" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.17.3.1.m1.2.2.1.1.1.2" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.T6.17.3.1.m1.2.2.1.1.1.1" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.cmml"><mi id="S4.T6.17.3.1.m1.2.2.1.1.1.1.3" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.3.cmml">Sublayer</mi><mo lspace="0em" rspace="0em" id="S4.T6.17.3.1.m1.2.2.1.1.1.1.2" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.2" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.2.cmml">Norm</mi><mo lspace="0em" rspace="0em" id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.3.2.1" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mi id="S4.T6.17.3.1.m1.1.1" xref="S4.T6.17.3.1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.3.2.2" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.3" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.T6.17.3.1.m1.2.2.1.1.1.3" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.17.3.1.m1.2b"><apply id="S4.T6.17.3.1.m1.2.2.cmml" xref="S4.T6.17.3.1.m1.2.2"><plus id="S4.T6.17.3.1.m1.2.2.2.cmml" xref="S4.T6.17.3.1.m1.2.2.2"></plus><ci id="S4.T6.17.3.1.m1.2.2.3.cmml" xref="S4.T6.17.3.1.m1.2.2.3">𝐱</ci><apply id="S4.T6.17.3.1.m1.2.2.1.cmml" xref="S4.T6.17.3.1.m1.2.2.1"><times id="S4.T6.17.3.1.m1.2.2.1.2.cmml" xref="S4.T6.17.3.1.m1.2.2.1.2"></times><ci id="S4.T6.17.3.1.m1.2.2.1.3.cmml" xref="S4.T6.17.3.1.m1.2.2.1.3">Norm</ci><apply id="S4.T6.17.3.1.m1.2.2.1.1.1.1.cmml" xref="S4.T6.17.3.1.m1.2.2.1.1.1"><times id="S4.T6.17.3.1.m1.2.2.1.1.1.1.2.cmml" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.2"></times><ci id="S4.T6.17.3.1.m1.2.2.1.1.1.1.3.cmml" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.3">Sublayer</ci><apply id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1"><times id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.1"></times><ci id="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.T6.17.3.1.m1.2.2.1.1.1.1.1.1.1.2">Norm</ci><ci id="S4.T6.17.3.1.m1.1.1.cmml" xref="S4.T6.17.3.1.m1.1.1">𝐱</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.17.3.1.m1.2c">\mathbf{x}+\mathrm{Norm}(\mathrm{Sublayer}(\mathrm{Norm}(\mathbf{x})))</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.18.4" class="ltx_tr">
<td id="S4.T6.18.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T6.18.4.2.1" class="ltx_text">Normalization method</span></td>
<td id="S4.T6.18.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">LayerNorm&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib256" title="" class="ltx_ref">256</a>]</cite>
</td>
<td id="S4.T6.18.4.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T6.18.4.1.m1.2" class="ltx_math_unparsed" alttext="\frac{\mathbf{x}-\mathbf{\mu}}{\mathbf{\sigma}}\cdot\gamma+\beta,\text{~{}~{}~{}}\mathbf{\mu}=\frac{1}{d}\sum_{i=1}^{d}x_{i},\text{~{}~{}~{}}\mathbf{\sigma}=\sqrt{\frac{1}{d}\sum_{i=1}^{d}(x_{i}-\mathbf{\mu}))^{2}}" display="inline"><semantics id="S4.T6.18.4.1.m1.2a"><mrow id="S4.T6.18.4.1.m1.2.2.2"><mrow id="S4.T6.18.4.1.m1.1.1.1.1"><mrow id="S4.T6.18.4.1.m1.1.1.1.1.2.2"><mrow id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1"><mrow id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.2"><mfrac id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.2.2"><mrow id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.2.2.2"><mi id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.2.2.2.2">𝐱</mi><mo id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.2.2.2.1">−</mo><mi id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.2.2.2.3">μ</mi></mrow><mi id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.2.2.3">σ</mi></mfrac><mo lspace="0.222em" rspace="0.222em" id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.2.1">⋅</mo><mi id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.2.3">γ</mi></mrow><mo id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.1">+</mo><mi id="S4.T6.18.4.1.m1.1.1.1.1.1.1.1.3">β</mi></mrow><mo id="S4.T6.18.4.1.m1.1.1.1.1.2.2.3">,</mo><mrow id="S4.T6.18.4.1.m1.1.1.1.1.2.2.2"><mtext id="S4.T6.18.4.1.m1.1.1.1.1.2.2.2.2">&nbsp;</mtext><mo lspace="0em" rspace="0em" id="S4.T6.18.4.1.m1.1.1.1.1.2.2.2.1">​</mo><mi id="S4.T6.18.4.1.m1.1.1.1.1.2.2.2.3">μ</mi></mrow></mrow><mo id="S4.T6.18.4.1.m1.1.1.1.1.3">=</mo><mrow id="S4.T6.18.4.1.m1.1.1.1.1.4"><mfrac id="S4.T6.18.4.1.m1.1.1.1.1.4.2"><mn id="S4.T6.18.4.1.m1.1.1.1.1.4.2.2">1</mn><mi id="S4.T6.18.4.1.m1.1.1.1.1.4.2.3">d</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.T6.18.4.1.m1.1.1.1.1.4.1">​</mo><mrow id="S4.T6.18.4.1.m1.1.1.1.1.4.3"><msubsup id="S4.T6.18.4.1.m1.1.1.1.1.4.3.1"><mo id="S4.T6.18.4.1.m1.1.1.1.1.4.3.1.2.2">∑</mo><mrow id="S4.T6.18.4.1.m1.1.1.1.1.4.3.1.2.3"><mi id="S4.T6.18.4.1.m1.1.1.1.1.4.3.1.2.3.2">i</mi><mo id="S4.T6.18.4.1.m1.1.1.1.1.4.3.1.2.3.1">=</mo><mn id="S4.T6.18.4.1.m1.1.1.1.1.4.3.1.2.3.3">1</mn></mrow><mi id="S4.T6.18.4.1.m1.1.1.1.1.4.3.1.3">d</mi></msubsup><msub id="S4.T6.18.4.1.m1.1.1.1.1.4.3.2"><mi id="S4.T6.18.4.1.m1.1.1.1.1.4.3.2.2">x</mi><mi id="S4.T6.18.4.1.m1.1.1.1.1.4.3.2.3">i</mi></msub></mrow></mrow></mrow><mo id="S4.T6.18.4.1.m1.2.2.2.3">,</mo><mrow id="S4.T6.18.4.1.m1.2.2.2.2"><mrow id="S4.T6.18.4.1.m1.2.2.2.2.2"><mtext id="S4.T6.18.4.1.m1.2.2.2.2.2.2">&nbsp;</mtext><mo lspace="0em" rspace="0em" id="S4.T6.18.4.1.m1.2.2.2.2.2.1">​</mo><mi id="S4.T6.18.4.1.m1.2.2.2.2.2.3">σ</mi></mrow><mo id="S4.T6.18.4.1.m1.2.2.2.2.1">=</mo><msqrt id="S4.T6.18.4.1.m1.2.2.2.2.3"><mrow id="S4.T6.18.4.1.m1.2.2.2.2.3.2"><mfrac id="S4.T6.18.4.1.m1.2.2.2.2.3.2.1"><mn id="S4.T6.18.4.1.m1.2.2.2.2.3.2.1.2">1</mn><mi id="S4.T6.18.4.1.m1.2.2.2.2.3.2.1.3">d</mi></mfrac><msubsup id="S4.T6.18.4.1.m1.2.2.2.2.3.2.2"><mo rspace="0em" id="S4.T6.18.4.1.m1.2.2.2.2.3.2.2.2.2">∑</mo><mrow id="S4.T6.18.4.1.m1.2.2.2.2.3.2.2.2.3"><mi id="S4.T6.18.4.1.m1.2.2.2.2.3.2.2.2.3.2">i</mi><mo id="S4.T6.18.4.1.m1.2.2.2.2.3.2.2.2.3.1">=</mo><mn id="S4.T6.18.4.1.m1.2.2.2.2.3.2.2.2.3.3">1</mn></mrow><mi id="S4.T6.18.4.1.m1.2.2.2.2.3.2.2.3">d</mi></msubsup><mrow id="S4.T6.18.4.1.m1.2.2.2.2.3.2.3"><mo stretchy="false" id="S4.T6.18.4.1.m1.2.2.2.2.3.2.3.1">(</mo><msub id="S4.T6.18.4.1.m1.2.2.2.2.3.2.3.2"><mi id="S4.T6.18.4.1.m1.2.2.2.2.3.2.3.2.2">x</mi><mi id="S4.T6.18.4.1.m1.2.2.2.2.3.2.3.2.3">i</mi></msub><mo id="S4.T6.18.4.1.m1.2.2.2.2.3.2.3.3">−</mo><mi id="S4.T6.18.4.1.m1.2.2.2.2.3.2.3.4">μ</mi><mo stretchy="false" id="S4.T6.18.4.1.m1.2.2.2.2.3.2.3.5">)</mo></mrow><mo stretchy="false" id="S4.T6.18.4.1.m1.2.2.2.2.3.2.4">)</mo><msup id="S4.T6.18.4.1.m1.2.2.2.2.3.2.5"><mi id="S4.T6.18.4.1.m1.2.2.2.2.3.2.5a"></mi><mn id="S4.T6.18.4.1.m1.2.2.2.2.3.2.5.1">2</mn></msup></mrow></msqrt></mrow></mrow><annotation encoding="application/x-tex" id="S4.T6.18.4.1.m1.2b">\frac{\mathbf{x}-\mathbf{\mu}}{\mathbf{\sigma}}\cdot\gamma+\beta,\text{~{}~{}~{}}\mathbf{\mu}=\frac{1}{d}\sum_{i=1}^{d}x_{i},\text{~{}~{}~{}}\mathbf{\sigma}=\sqrt{\frac{1}{d}\sum_{i=1}^{d}(x_{i}-\mathbf{\mu}))^{2}}</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.19.5" class="ltx_tr">
<td id="S4.T6.19.5.2" class="ltx_td ltx_align_center ltx_border_r">RMSNorm&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib257" title="" class="ltx_ref">257</a>]</cite>
</td>
<td id="S4.T6.19.5.1" class="ltx_td ltx_align_left"><math id="S4.T6.19.5.1.m1.4" class="ltx_Math" alttext="\frac{\mathbf{x}}{\mathrm{RMS}(\mathbf{x})}\cdot\gamma,\text{~{}~{}~{}}\mathrm{RMS}(\mathbf{x})=\sqrt{\frac{1}{d}\sum_{i=1}^{d}x_{i}^{2}}" display="inline"><semantics id="S4.T6.19.5.1.m1.4a"><mrow id="S4.T6.19.5.1.m1.4.4" xref="S4.T6.19.5.1.m1.4.4.cmml"><mrow id="S4.T6.19.5.1.m1.4.4.2.2" xref="S4.T6.19.5.1.m1.4.4.2.3.cmml"><mrow id="S4.T6.19.5.1.m1.3.3.1.1.1" xref="S4.T6.19.5.1.m1.3.3.1.1.1.cmml"><mfrac id="S4.T6.19.5.1.m1.1.1" xref="S4.T6.19.5.1.m1.1.1.cmml"><mi id="S4.T6.19.5.1.m1.1.1.3" xref="S4.T6.19.5.1.m1.1.1.3.cmml">𝐱</mi><mrow id="S4.T6.19.5.1.m1.1.1.1" xref="S4.T6.19.5.1.m1.1.1.1.cmml"><mi id="S4.T6.19.5.1.m1.1.1.1.3" xref="S4.T6.19.5.1.m1.1.1.1.3.cmml">RMS</mi><mo lspace="0em" rspace="0em" id="S4.T6.19.5.1.m1.1.1.1.2" xref="S4.T6.19.5.1.m1.1.1.1.2.cmml">​</mo><mrow id="S4.T6.19.5.1.m1.1.1.1.4.2" xref="S4.T6.19.5.1.m1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.19.5.1.m1.1.1.1.4.2.1" xref="S4.T6.19.5.1.m1.1.1.1.cmml">(</mo><mi id="S4.T6.19.5.1.m1.1.1.1.1" xref="S4.T6.19.5.1.m1.1.1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.19.5.1.m1.1.1.1.4.2.2" xref="S4.T6.19.5.1.m1.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo lspace="0.222em" rspace="0.222em" id="S4.T6.19.5.1.m1.3.3.1.1.1.1" xref="S4.T6.19.5.1.m1.3.3.1.1.1.1.cmml">⋅</mo><mi id="S4.T6.19.5.1.m1.3.3.1.1.1.2" xref="S4.T6.19.5.1.m1.3.3.1.1.1.2.cmml">γ</mi></mrow><mo id="S4.T6.19.5.1.m1.4.4.2.2.3" xref="S4.T6.19.5.1.m1.4.4.2.3.cmml">,</mo><mrow id="S4.T6.19.5.1.m1.4.4.2.2.2" xref="S4.T6.19.5.1.m1.4.4.2.2.2.cmml"><mtext id="S4.T6.19.5.1.m1.4.4.2.2.2.2" xref="S4.T6.19.5.1.m1.4.4.2.2.2.2a.cmml">&nbsp;</mtext><mo lspace="0em" rspace="0em" id="S4.T6.19.5.1.m1.4.4.2.2.2.1" xref="S4.T6.19.5.1.m1.4.4.2.2.2.1.cmml">​</mo><mi id="S4.T6.19.5.1.m1.4.4.2.2.2.3" xref="S4.T6.19.5.1.m1.4.4.2.2.2.3.cmml">RMS</mi><mo lspace="0em" rspace="0em" id="S4.T6.19.5.1.m1.4.4.2.2.2.1a" xref="S4.T6.19.5.1.m1.4.4.2.2.2.1.cmml">​</mo><mrow id="S4.T6.19.5.1.m1.4.4.2.2.2.4.2" xref="S4.T6.19.5.1.m1.4.4.2.2.2.cmml"><mo stretchy="false" id="S4.T6.19.5.1.m1.4.4.2.2.2.4.2.1" xref="S4.T6.19.5.1.m1.4.4.2.2.2.cmml">(</mo><mi id="S4.T6.19.5.1.m1.2.2" xref="S4.T6.19.5.1.m1.2.2.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.19.5.1.m1.4.4.2.2.2.4.2.2" xref="S4.T6.19.5.1.m1.4.4.2.2.2.cmml">)</mo></mrow></mrow></mrow><mo id="S4.T6.19.5.1.m1.4.4.3" xref="S4.T6.19.5.1.m1.4.4.3.cmml">=</mo><msqrt id="S4.T6.19.5.1.m1.4.4.4" xref="S4.T6.19.5.1.m1.4.4.4.cmml"><mrow id="S4.T6.19.5.1.m1.4.4.4.2" xref="S4.T6.19.5.1.m1.4.4.4.2.cmml"><mfrac id="S4.T6.19.5.1.m1.4.4.4.2.2" xref="S4.T6.19.5.1.m1.4.4.4.2.2.cmml"><mn id="S4.T6.19.5.1.m1.4.4.4.2.2.2" xref="S4.T6.19.5.1.m1.4.4.4.2.2.2.cmml">1</mn><mi id="S4.T6.19.5.1.m1.4.4.4.2.2.3" xref="S4.T6.19.5.1.m1.4.4.4.2.2.3.cmml">d</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.T6.19.5.1.m1.4.4.4.2.1" xref="S4.T6.19.5.1.m1.4.4.4.2.1.cmml">​</mo><mrow id="S4.T6.19.5.1.m1.4.4.4.2.3" xref="S4.T6.19.5.1.m1.4.4.4.2.3.cmml"><msubsup id="S4.T6.19.5.1.m1.4.4.4.2.3.1" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.cmml"><mo id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.2" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.2.cmml">∑</mo><mrow id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.cmml"><mi id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.2" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.2.cmml">i</mi><mo id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.1" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.1.cmml">=</mo><mn id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.3" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S4.T6.19.5.1.m1.4.4.4.2.3.1.3" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.3.cmml">d</mi></msubsup><msubsup id="S4.T6.19.5.1.m1.4.4.4.2.3.2" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2.cmml"><mi id="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.2" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.2.cmml">x</mi><mi id="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.3" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.3.cmml">i</mi><mn id="S4.T6.19.5.1.m1.4.4.4.2.3.2.3" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2.3.cmml">2</mn></msubsup></mrow></mrow></msqrt></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.19.5.1.m1.4b"><apply id="S4.T6.19.5.1.m1.4.4.cmml" xref="S4.T6.19.5.1.m1.4.4"><eq id="S4.T6.19.5.1.m1.4.4.3.cmml" xref="S4.T6.19.5.1.m1.4.4.3"></eq><list id="S4.T6.19.5.1.m1.4.4.2.3.cmml" xref="S4.T6.19.5.1.m1.4.4.2.2"><apply id="S4.T6.19.5.1.m1.3.3.1.1.1.cmml" xref="S4.T6.19.5.1.m1.3.3.1.1.1"><ci id="S4.T6.19.5.1.m1.3.3.1.1.1.1.cmml" xref="S4.T6.19.5.1.m1.3.3.1.1.1.1">⋅</ci><apply id="S4.T6.19.5.1.m1.1.1.cmml" xref="S4.T6.19.5.1.m1.1.1"><divide id="S4.T6.19.5.1.m1.1.1.2.cmml" xref="S4.T6.19.5.1.m1.1.1"></divide><ci id="S4.T6.19.5.1.m1.1.1.3.cmml" xref="S4.T6.19.5.1.m1.1.1.3">𝐱</ci><apply id="S4.T6.19.5.1.m1.1.1.1.cmml" xref="S4.T6.19.5.1.m1.1.1.1"><times id="S4.T6.19.5.1.m1.1.1.1.2.cmml" xref="S4.T6.19.5.1.m1.1.1.1.2"></times><ci id="S4.T6.19.5.1.m1.1.1.1.3.cmml" xref="S4.T6.19.5.1.m1.1.1.1.3">RMS</ci><ci id="S4.T6.19.5.1.m1.1.1.1.1.cmml" xref="S4.T6.19.5.1.m1.1.1.1.1">𝐱</ci></apply></apply><ci id="S4.T6.19.5.1.m1.3.3.1.1.1.2.cmml" xref="S4.T6.19.5.1.m1.3.3.1.1.1.2">𝛾</ci></apply><apply id="S4.T6.19.5.1.m1.4.4.2.2.2.cmml" xref="S4.T6.19.5.1.m1.4.4.2.2.2"><times id="S4.T6.19.5.1.m1.4.4.2.2.2.1.cmml" xref="S4.T6.19.5.1.m1.4.4.2.2.2.1"></times><ci id="S4.T6.19.5.1.m1.4.4.2.2.2.2a.cmml" xref="S4.T6.19.5.1.m1.4.4.2.2.2.2"><mtext id="S4.T6.19.5.1.m1.4.4.2.2.2.2.cmml" xref="S4.T6.19.5.1.m1.4.4.2.2.2.2">&nbsp;</mtext></ci><ci id="S4.T6.19.5.1.m1.4.4.2.2.2.3.cmml" xref="S4.T6.19.5.1.m1.4.4.2.2.2.3">RMS</ci><ci id="S4.T6.19.5.1.m1.2.2.cmml" xref="S4.T6.19.5.1.m1.2.2">𝐱</ci></apply></list><apply id="S4.T6.19.5.1.m1.4.4.4.cmml" xref="S4.T6.19.5.1.m1.4.4.4"><root id="S4.T6.19.5.1.m1.4.4.4a.cmml" xref="S4.T6.19.5.1.m1.4.4.4"></root><apply id="S4.T6.19.5.1.m1.4.4.4.2.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2"><times id="S4.T6.19.5.1.m1.4.4.4.2.1.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.1"></times><apply id="S4.T6.19.5.1.m1.4.4.4.2.2.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.2"><divide id="S4.T6.19.5.1.m1.4.4.4.2.2.1.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.2"></divide><cn type="integer" id="S4.T6.19.5.1.m1.4.4.4.2.2.2.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.2.2">1</cn><ci id="S4.T6.19.5.1.m1.4.4.4.2.2.3.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.2.3">𝑑</ci></apply><apply id="S4.T6.19.5.1.m1.4.4.4.2.3.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3"><apply id="S4.T6.19.5.1.m1.4.4.4.2.3.1.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1"><csymbol cd="ambiguous" id="S4.T6.19.5.1.m1.4.4.4.2.3.1.1.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1">superscript</csymbol><apply id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1"><csymbol cd="ambiguous" id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.1.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1">subscript</csymbol><sum id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.2.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.2"></sum><apply id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3"><eq id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.1.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.1"></eq><ci id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.2.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.2">𝑖</ci><cn type="integer" id="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.3.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.2.3.3">1</cn></apply></apply><ci id="S4.T6.19.5.1.m1.4.4.4.2.3.1.3.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.1.3">𝑑</ci></apply><apply id="S4.T6.19.5.1.m1.4.4.4.2.3.2.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2"><csymbol cd="ambiguous" id="S4.T6.19.5.1.m1.4.4.4.2.3.2.1.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2">superscript</csymbol><apply id="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2"><csymbol cd="ambiguous" id="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.1.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2">subscript</csymbol><ci id="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.2.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.2">𝑥</ci><ci id="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.3.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2.2.3">𝑖</ci></apply><cn type="integer" id="S4.T6.19.5.1.m1.4.4.4.2.3.2.3.cmml" xref="S4.T6.19.5.1.m1.4.4.4.2.3.2.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.19.5.1.m1.4c">\frac{\mathbf{x}}{\mathrm{RMS}(\mathbf{x})}\cdot\gamma,\text{~{}~{}~{}}\mathrm{RMS}(\mathbf{x})=\sqrt{\frac{1}{d}\sum_{i=1}^{d}x_{i}^{2}}</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.20.6" class="ltx_tr">
<td id="S4.T6.20.6.2" class="ltx_td ltx_align_center ltx_border_r">DeepNorm&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib258" title="" class="ltx_ref">258</a>]</cite>
</td>
<td id="S4.T6.20.6.1" class="ltx_td ltx_align_left"><math id="S4.T6.20.6.1.m1.2" class="ltx_Math" alttext="\mathrm{LayerNorm}(\alpha\cdot\mathbf{x}+\mathrm{Sublayer}(\mathbf{x}))" display="inline"><semantics id="S4.T6.20.6.1.m1.2a"><mrow id="S4.T6.20.6.1.m1.2.2" xref="S4.T6.20.6.1.m1.2.2.cmml"><mi id="S4.T6.20.6.1.m1.2.2.3" xref="S4.T6.20.6.1.m1.2.2.3.cmml">LayerNorm</mi><mo lspace="0em" rspace="0em" id="S4.T6.20.6.1.m1.2.2.2" xref="S4.T6.20.6.1.m1.2.2.2.cmml">​</mo><mrow id="S4.T6.20.6.1.m1.2.2.1.1" xref="S4.T6.20.6.1.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.T6.20.6.1.m1.2.2.1.1.2" xref="S4.T6.20.6.1.m1.2.2.1.1.1.cmml">(</mo><mrow id="S4.T6.20.6.1.m1.2.2.1.1.1" xref="S4.T6.20.6.1.m1.2.2.1.1.1.cmml"><mrow id="S4.T6.20.6.1.m1.2.2.1.1.1.2" xref="S4.T6.20.6.1.m1.2.2.1.1.1.2.cmml"><mi id="S4.T6.20.6.1.m1.2.2.1.1.1.2.2" xref="S4.T6.20.6.1.m1.2.2.1.1.1.2.2.cmml">α</mi><mo lspace="0.222em" rspace="0.222em" id="S4.T6.20.6.1.m1.2.2.1.1.1.2.1" xref="S4.T6.20.6.1.m1.2.2.1.1.1.2.1.cmml">⋅</mo><mi id="S4.T6.20.6.1.m1.2.2.1.1.1.2.3" xref="S4.T6.20.6.1.m1.2.2.1.1.1.2.3.cmml">𝐱</mi></mrow><mo id="S4.T6.20.6.1.m1.2.2.1.1.1.1" xref="S4.T6.20.6.1.m1.2.2.1.1.1.1.cmml">+</mo><mrow id="S4.T6.20.6.1.m1.2.2.1.1.1.3" xref="S4.T6.20.6.1.m1.2.2.1.1.1.3.cmml"><mi id="S4.T6.20.6.1.m1.2.2.1.1.1.3.2" xref="S4.T6.20.6.1.m1.2.2.1.1.1.3.2.cmml">Sublayer</mi><mo lspace="0em" rspace="0em" id="S4.T6.20.6.1.m1.2.2.1.1.1.3.1" xref="S4.T6.20.6.1.m1.2.2.1.1.1.3.1.cmml">​</mo><mrow id="S4.T6.20.6.1.m1.2.2.1.1.1.3.3.2" xref="S4.T6.20.6.1.m1.2.2.1.1.1.3.cmml"><mo stretchy="false" id="S4.T6.20.6.1.m1.2.2.1.1.1.3.3.2.1" xref="S4.T6.20.6.1.m1.2.2.1.1.1.3.cmml">(</mo><mi id="S4.T6.20.6.1.m1.1.1" xref="S4.T6.20.6.1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.20.6.1.m1.2.2.1.1.1.3.3.2.2" xref="S4.T6.20.6.1.m1.2.2.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.T6.20.6.1.m1.2.2.1.1.3" xref="S4.T6.20.6.1.m1.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.20.6.1.m1.2b"><apply id="S4.T6.20.6.1.m1.2.2.cmml" xref="S4.T6.20.6.1.m1.2.2"><times id="S4.T6.20.6.1.m1.2.2.2.cmml" xref="S4.T6.20.6.1.m1.2.2.2"></times><ci id="S4.T6.20.6.1.m1.2.2.3.cmml" xref="S4.T6.20.6.1.m1.2.2.3">LayerNorm</ci><apply id="S4.T6.20.6.1.m1.2.2.1.1.1.cmml" xref="S4.T6.20.6.1.m1.2.2.1.1"><plus id="S4.T6.20.6.1.m1.2.2.1.1.1.1.cmml" xref="S4.T6.20.6.1.m1.2.2.1.1.1.1"></plus><apply id="S4.T6.20.6.1.m1.2.2.1.1.1.2.cmml" xref="S4.T6.20.6.1.m1.2.2.1.1.1.2"><ci id="S4.T6.20.6.1.m1.2.2.1.1.1.2.1.cmml" xref="S4.T6.20.6.1.m1.2.2.1.1.1.2.1">⋅</ci><ci id="S4.T6.20.6.1.m1.2.2.1.1.1.2.2.cmml" xref="S4.T6.20.6.1.m1.2.2.1.1.1.2.2">𝛼</ci><ci id="S4.T6.20.6.1.m1.2.2.1.1.1.2.3.cmml" xref="S4.T6.20.6.1.m1.2.2.1.1.1.2.3">𝐱</ci></apply><apply id="S4.T6.20.6.1.m1.2.2.1.1.1.3.cmml" xref="S4.T6.20.6.1.m1.2.2.1.1.1.3"><times id="S4.T6.20.6.1.m1.2.2.1.1.1.3.1.cmml" xref="S4.T6.20.6.1.m1.2.2.1.1.1.3.1"></times><ci id="S4.T6.20.6.1.m1.2.2.1.1.1.3.2.cmml" xref="S4.T6.20.6.1.m1.2.2.1.1.1.3.2">Sublayer</ci><ci id="S4.T6.20.6.1.m1.1.1.cmml" xref="S4.T6.20.6.1.m1.1.1">𝐱</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.20.6.1.m1.2c">\mathrm{LayerNorm}(\alpha\cdot\mathbf{x}+\mathrm{Sublayer}(\mathbf{x}))</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.21.7" class="ltx_tr">
<td id="S4.T6.21.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="5"><span id="S4.T6.21.7.2.1" class="ltx_text">Activation function</span></td>
<td id="S4.T6.21.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ReLU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib259" title="" class="ltx_ref">259</a>]</cite>
</td>
<td id="S4.T6.21.7.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T6.21.7.1.m1.4" class="ltx_Math" alttext="\mathrm{ReLU}(\mathbf{x})=\max(\mathbf{x},\mathbf{0})" display="inline"><semantics id="S4.T6.21.7.1.m1.4a"><mrow id="S4.T6.21.7.1.m1.4.5" xref="S4.T6.21.7.1.m1.4.5.cmml"><mrow id="S4.T6.21.7.1.m1.4.5.2" xref="S4.T6.21.7.1.m1.4.5.2.cmml"><mi id="S4.T6.21.7.1.m1.4.5.2.2" xref="S4.T6.21.7.1.m1.4.5.2.2.cmml">ReLU</mi><mo lspace="0em" rspace="0em" id="S4.T6.21.7.1.m1.4.5.2.1" xref="S4.T6.21.7.1.m1.4.5.2.1.cmml">​</mo><mrow id="S4.T6.21.7.1.m1.4.5.2.3.2" xref="S4.T6.21.7.1.m1.4.5.2.cmml"><mo stretchy="false" id="S4.T6.21.7.1.m1.4.5.2.3.2.1" xref="S4.T6.21.7.1.m1.4.5.2.cmml">(</mo><mi id="S4.T6.21.7.1.m1.1.1" xref="S4.T6.21.7.1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.21.7.1.m1.4.5.2.3.2.2" xref="S4.T6.21.7.1.m1.4.5.2.cmml">)</mo></mrow></mrow><mo id="S4.T6.21.7.1.m1.4.5.1" xref="S4.T6.21.7.1.m1.4.5.1.cmml">=</mo><mrow id="S4.T6.21.7.1.m1.4.5.3.2" xref="S4.T6.21.7.1.m1.4.5.3.1.cmml"><mi id="S4.T6.21.7.1.m1.2.2" xref="S4.T6.21.7.1.m1.2.2.cmml">max</mi><mo id="S4.T6.21.7.1.m1.4.5.3.2a" xref="S4.T6.21.7.1.m1.4.5.3.1.cmml">⁡</mo><mrow id="S4.T6.21.7.1.m1.4.5.3.2.1" xref="S4.T6.21.7.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="S4.T6.21.7.1.m1.4.5.3.2.1.1" xref="S4.T6.21.7.1.m1.4.5.3.1.cmml">(</mo><mi id="S4.T6.21.7.1.m1.3.3" xref="S4.T6.21.7.1.m1.3.3.cmml">𝐱</mi><mo id="S4.T6.21.7.1.m1.4.5.3.2.1.2" xref="S4.T6.21.7.1.m1.4.5.3.1.cmml">,</mo><mn id="S4.T6.21.7.1.m1.4.4" xref="S4.T6.21.7.1.m1.4.4.cmml">𝟎</mn><mo stretchy="false" id="S4.T6.21.7.1.m1.4.5.3.2.1.3" xref="S4.T6.21.7.1.m1.4.5.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.21.7.1.m1.4b"><apply id="S4.T6.21.7.1.m1.4.5.cmml" xref="S4.T6.21.7.1.m1.4.5"><eq id="S4.T6.21.7.1.m1.4.5.1.cmml" xref="S4.T6.21.7.1.m1.4.5.1"></eq><apply id="S4.T6.21.7.1.m1.4.5.2.cmml" xref="S4.T6.21.7.1.m1.4.5.2"><times id="S4.T6.21.7.1.m1.4.5.2.1.cmml" xref="S4.T6.21.7.1.m1.4.5.2.1"></times><ci id="S4.T6.21.7.1.m1.4.5.2.2.cmml" xref="S4.T6.21.7.1.m1.4.5.2.2">ReLU</ci><ci id="S4.T6.21.7.1.m1.1.1.cmml" xref="S4.T6.21.7.1.m1.1.1">𝐱</ci></apply><apply id="S4.T6.21.7.1.m1.4.5.3.1.cmml" xref="S4.T6.21.7.1.m1.4.5.3.2"><max id="S4.T6.21.7.1.m1.2.2.cmml" xref="S4.T6.21.7.1.m1.2.2"></max><ci id="S4.T6.21.7.1.m1.3.3.cmml" xref="S4.T6.21.7.1.m1.3.3">𝐱</ci><cn type="integer" id="S4.T6.21.7.1.m1.4.4.cmml" xref="S4.T6.21.7.1.m1.4.4">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.21.7.1.m1.4c">\mathrm{ReLU}(\mathbf{x})=\max(\mathbf{x},\mathbf{0})</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.22.8" class="ltx_tr">
<td id="S4.T6.22.8.2" class="ltx_td ltx_align_center ltx_border_r">GeLU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib260" title="" class="ltx_ref">260</a>]</cite>
</td>
<td id="S4.T6.22.8.1" class="ltx_td ltx_align_left"><math id="S4.T6.22.8.1.m1.4" class="ltx_Math" alttext="\mathrm{GeLU}(\mathbf{x})=\mathrm{0.5}\mathbf{x}\otimes[1+\mathrm{erf}(\mathbf{x}/\sqrt{2})],\text{~{}~{}~{}}\mathrm{erf}(x)=\frac{2}{\sqrt{\pi}}\int_{0}^{x}e^{-t^{2}}dt" display="inline"><semantics id="S4.T6.22.8.1.m1.4a"><mrow id="S4.T6.22.8.1.m1.4.4.2" xref="S4.T6.22.8.1.m1.4.4.3.cmml"><mrow id="S4.T6.22.8.1.m1.3.3.1.1" xref="S4.T6.22.8.1.m1.3.3.1.1.cmml"><mrow id="S4.T6.22.8.1.m1.3.3.1.1.3" xref="S4.T6.22.8.1.m1.3.3.1.1.3.cmml"><mi id="S4.T6.22.8.1.m1.3.3.1.1.3.2" xref="S4.T6.22.8.1.m1.3.3.1.1.3.2.cmml">GeLU</mi><mo lspace="0em" rspace="0em" id="S4.T6.22.8.1.m1.3.3.1.1.3.1" xref="S4.T6.22.8.1.m1.3.3.1.1.3.1.cmml">​</mo><mrow id="S4.T6.22.8.1.m1.3.3.1.1.3.3.2" xref="S4.T6.22.8.1.m1.3.3.1.1.3.cmml"><mo stretchy="false" id="S4.T6.22.8.1.m1.3.3.1.1.3.3.2.1" xref="S4.T6.22.8.1.m1.3.3.1.1.3.cmml">(</mo><mi id="S4.T6.22.8.1.m1.1.1" xref="S4.T6.22.8.1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.22.8.1.m1.3.3.1.1.3.3.2.2" xref="S4.T6.22.8.1.m1.3.3.1.1.3.cmml">)</mo></mrow></mrow><mo id="S4.T6.22.8.1.m1.3.3.1.1.2" xref="S4.T6.22.8.1.m1.3.3.1.1.2.cmml">=</mo><mrow id="S4.T6.22.8.1.m1.3.3.1.1.1" xref="S4.T6.22.8.1.m1.3.3.1.1.1.cmml"><mrow id="S4.T6.22.8.1.m1.3.3.1.1.1.3" xref="S4.T6.22.8.1.m1.3.3.1.1.1.3.cmml"><mn id="S4.T6.22.8.1.m1.3.3.1.1.1.3.2" xref="S4.T6.22.8.1.m1.3.3.1.1.1.3.2.cmml">0.5</mn><mo lspace="0em" rspace="0em" id="S4.T6.22.8.1.m1.3.3.1.1.1.3.1" xref="S4.T6.22.8.1.m1.3.3.1.1.1.3.1.cmml">​</mo><mi id="S4.T6.22.8.1.m1.3.3.1.1.1.3.3" xref="S4.T6.22.8.1.m1.3.3.1.1.1.3.3.cmml">𝐱</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S4.T6.22.8.1.m1.3.3.1.1.1.2" xref="S4.T6.22.8.1.m1.3.3.1.1.1.2.cmml">⊗</mo><mrow id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.2" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.2.1.cmml">[</mo><mrow id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.cmml"><mn id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.3" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.3.cmml">1</mn><mo id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.2" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.2.cmml">+</mo><mrow id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.3" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.3.cmml">erf</mi><mo lspace="0em" rspace="0em" id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.2" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mo id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">/</mo><msqrt id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml"><mn id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml">2</mn></msqrt></mrow><mo stretchy="false" id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.3" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S4.T6.22.8.1.m1.4.4.2.3" xref="S4.T6.22.8.1.m1.4.4.3a.cmml">,</mo><mrow id="S4.T6.22.8.1.m1.4.4.2.2" xref="S4.T6.22.8.1.m1.4.4.2.2.cmml"><mrow id="S4.T6.22.8.1.m1.4.4.2.2.2" xref="S4.T6.22.8.1.m1.4.4.2.2.2.cmml"><mtext id="S4.T6.22.8.1.m1.4.4.2.2.2.2" xref="S4.T6.22.8.1.m1.4.4.2.2.2.2a.cmml">&nbsp;</mtext><mo lspace="0em" rspace="0em" id="S4.T6.22.8.1.m1.4.4.2.2.2.1" xref="S4.T6.22.8.1.m1.4.4.2.2.2.1.cmml">​</mo><mi id="S4.T6.22.8.1.m1.4.4.2.2.2.3" xref="S4.T6.22.8.1.m1.4.4.2.2.2.3.cmml">erf</mi><mo lspace="0em" rspace="0em" id="S4.T6.22.8.1.m1.4.4.2.2.2.1a" xref="S4.T6.22.8.1.m1.4.4.2.2.2.1.cmml">​</mo><mrow id="S4.T6.22.8.1.m1.4.4.2.2.2.4.2" xref="S4.T6.22.8.1.m1.4.4.2.2.2.cmml"><mo stretchy="false" id="S4.T6.22.8.1.m1.4.4.2.2.2.4.2.1" xref="S4.T6.22.8.1.m1.4.4.2.2.2.cmml">(</mo><mi id="S4.T6.22.8.1.m1.2.2" xref="S4.T6.22.8.1.m1.2.2.cmml">x</mi><mo stretchy="false" id="S4.T6.22.8.1.m1.4.4.2.2.2.4.2.2" xref="S4.T6.22.8.1.m1.4.4.2.2.2.cmml">)</mo></mrow></mrow><mo id="S4.T6.22.8.1.m1.4.4.2.2.1" xref="S4.T6.22.8.1.m1.4.4.2.2.1.cmml">=</mo><mrow id="S4.T6.22.8.1.m1.4.4.2.2.3" xref="S4.T6.22.8.1.m1.4.4.2.2.3.cmml"><mfrac id="S4.T6.22.8.1.m1.4.4.2.2.3.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2.cmml"><mn id="S4.T6.22.8.1.m1.4.4.2.2.3.2.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2.2.cmml">2</mn><msqrt id="S4.T6.22.8.1.m1.4.4.2.2.3.2.3" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2.3.cmml"><mi id="S4.T6.22.8.1.m1.4.4.2.2.3.2.3.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2.3.2.cmml">π</mi></msqrt></mfrac><mo lspace="0em" rspace="0em" id="S4.T6.22.8.1.m1.4.4.2.2.3.1" xref="S4.T6.22.8.1.m1.4.4.2.2.3.1.cmml">​</mo><mrow id="S4.T6.22.8.1.m1.4.4.2.2.3.3" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.cmml"><msubsup id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.cmml"><mo id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.2.cmml">∫</mo><mn id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.3" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.3.cmml">0</mn><mi id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.3" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.3.cmml">x</mi></msubsup><mrow id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.cmml"><msup id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.cmml"><mi id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.2.cmml">e</mi><mrow id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.cmml"><mo id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3a" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.cmml">−</mo><msup id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.cmml"><mi id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.2.cmml">t</mi><mn id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.3" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.3.cmml">2</mn></msup></mrow></msup><mo lspace="0em" rspace="0em" id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.1" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.1.cmml">​</mo><mrow id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.cmml"><mo rspace="0em" id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.1" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.1.cmml">𝑑</mo><mi id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.2" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.2.cmml">t</mi></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.22.8.1.m1.4b"><apply id="S4.T6.22.8.1.m1.4.4.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2"><csymbol cd="ambiguous" id="S4.T6.22.8.1.m1.4.4.3a.cmml" xref="S4.T6.22.8.1.m1.4.4.2.3">formulae-sequence</csymbol><apply id="S4.T6.22.8.1.m1.3.3.1.1.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1"><eq id="S4.T6.22.8.1.m1.3.3.1.1.2.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.2"></eq><apply id="S4.T6.22.8.1.m1.3.3.1.1.3.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.3"><times id="S4.T6.22.8.1.m1.3.3.1.1.3.1.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.3.1"></times><ci id="S4.T6.22.8.1.m1.3.3.1.1.3.2.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.3.2">GeLU</ci><ci id="S4.T6.22.8.1.m1.1.1.cmml" xref="S4.T6.22.8.1.m1.1.1">𝐱</ci></apply><apply id="S4.T6.22.8.1.m1.3.3.1.1.1.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1"><csymbol cd="latexml" id="S4.T6.22.8.1.m1.3.3.1.1.1.2.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.2">tensor-product</csymbol><apply id="S4.T6.22.8.1.m1.3.3.1.1.1.3.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.3"><times id="S4.T6.22.8.1.m1.3.3.1.1.1.3.1.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.3.1"></times><cn type="float" id="S4.T6.22.8.1.m1.3.3.1.1.1.3.2.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.3.2">0.5</cn><ci id="S4.T6.22.8.1.m1.3.3.1.1.1.3.3.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.3.3">𝐱</ci></apply><apply id="S4.T6.22.8.1.m1.3.3.1.1.1.1.2.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S4.T6.22.8.1.m1.3.3.1.1.1.1.2.1.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1"><plus id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.2"></plus><cn type="integer" id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.3">1</cn><apply id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1"><times id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.2"></times><ci id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.3">erf</ci><apply id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1"><divide id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"></divide><ci id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.2">𝐱</ci><apply id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3"><root id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3"></root><cn type="integer" id="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.T6.22.8.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2">2</cn></apply></apply></apply></apply></apply></apply></apply><apply id="S4.T6.22.8.1.m1.4.4.2.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2"><eq id="S4.T6.22.8.1.m1.4.4.2.2.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.1"></eq><apply id="S4.T6.22.8.1.m1.4.4.2.2.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.2"><times id="S4.T6.22.8.1.m1.4.4.2.2.2.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.2.1"></times><ci id="S4.T6.22.8.1.m1.4.4.2.2.2.2a.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.2.2"><mtext id="S4.T6.22.8.1.m1.4.4.2.2.2.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.2.2">&nbsp;</mtext></ci><ci id="S4.T6.22.8.1.m1.4.4.2.2.2.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.2.3">erf</ci><ci id="S4.T6.22.8.1.m1.2.2.cmml" xref="S4.T6.22.8.1.m1.2.2">𝑥</ci></apply><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3"><times id="S4.T6.22.8.1.m1.4.4.2.2.3.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.1"></times><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2"><divide id="S4.T6.22.8.1.m1.4.4.2.2.3.2.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2"></divide><cn type="integer" id="S4.T6.22.8.1.m1.4.4.2.2.3.2.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2.2">2</cn><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.2.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2.3"><root id="S4.T6.22.8.1.m1.4.4.2.2.3.2.3a.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2.3"></root><ci id="S4.T6.22.8.1.m1.4.4.2.2.3.2.3.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.2.3.2">𝜋</ci></apply></apply><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3"><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1"><csymbol cd="ambiguous" id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1">superscript</csymbol><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1"><csymbol cd="ambiguous" id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1">subscript</csymbol><int id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.2"></int><cn type="integer" id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.2.3">0</cn></apply><ci id="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.1.3">𝑥</ci></apply><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2"><times id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.1"></times><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2"><csymbol cd="ambiguous" id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2">superscript</csymbol><ci id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.2">𝑒</ci><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3"><minus id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3"></minus><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2"><csymbol cd="ambiguous" id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2">superscript</csymbol><ci id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.2">𝑡</ci><cn type="integer" id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.2.3.2.3">2</cn></apply></apply></apply><apply id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3"><csymbol cd="latexml" id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.1.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.1">differential-d</csymbol><ci id="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.2.cmml" xref="S4.T6.22.8.1.m1.4.4.2.2.3.3.2.3.2">𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.22.8.1.m1.4c">\mathrm{GeLU}(\mathbf{x})=\mathrm{0.5}\mathbf{x}\otimes[1+\mathrm{erf}(\mathbf{x}/\sqrt{2})],\text{~{}~{}~{}}\mathrm{erf}(x)=\frac{2}{\sqrt{\pi}}\int_{0}^{x}e^{-t^{2}}dt</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.23.9" class="ltx_tr">
<td id="S4.T6.23.9.2" class="ltx_td ltx_align_center ltx_border_r">Swish&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib261" title="" class="ltx_ref">261</a>]</cite>
</td>
<td id="S4.T6.23.9.1" class="ltx_td ltx_align_left"><math id="S4.T6.23.9.1.m1.2" class="ltx_Math" alttext="\mathrm{Swish}(\mathbf{x})=\mathbf{x}\otimes\mathrm{sigmoid}(\mathbf{x})" display="inline"><semantics id="S4.T6.23.9.1.m1.2a"><mrow id="S4.T6.23.9.1.m1.2.3" xref="S4.T6.23.9.1.m1.2.3.cmml"><mrow id="S4.T6.23.9.1.m1.2.3.2" xref="S4.T6.23.9.1.m1.2.3.2.cmml"><mi id="S4.T6.23.9.1.m1.2.3.2.2" xref="S4.T6.23.9.1.m1.2.3.2.2.cmml">Swish</mi><mo lspace="0em" rspace="0em" id="S4.T6.23.9.1.m1.2.3.2.1" xref="S4.T6.23.9.1.m1.2.3.2.1.cmml">​</mo><mrow id="S4.T6.23.9.1.m1.2.3.2.3.2" xref="S4.T6.23.9.1.m1.2.3.2.cmml"><mo stretchy="false" id="S4.T6.23.9.1.m1.2.3.2.3.2.1" xref="S4.T6.23.9.1.m1.2.3.2.cmml">(</mo><mi id="S4.T6.23.9.1.m1.1.1" xref="S4.T6.23.9.1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.23.9.1.m1.2.3.2.3.2.2" xref="S4.T6.23.9.1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S4.T6.23.9.1.m1.2.3.1" xref="S4.T6.23.9.1.m1.2.3.1.cmml">=</mo><mrow id="S4.T6.23.9.1.m1.2.3.3" xref="S4.T6.23.9.1.m1.2.3.3.cmml"><mrow id="S4.T6.23.9.1.m1.2.3.3.2" xref="S4.T6.23.9.1.m1.2.3.3.2.cmml"><mi id="S4.T6.23.9.1.m1.2.3.3.2.2" xref="S4.T6.23.9.1.m1.2.3.3.2.2.cmml">𝐱</mi><mo lspace="0.222em" rspace="0.222em" id="S4.T6.23.9.1.m1.2.3.3.2.1" xref="S4.T6.23.9.1.m1.2.3.3.2.1.cmml">⊗</mo><mi id="S4.T6.23.9.1.m1.2.3.3.2.3" xref="S4.T6.23.9.1.m1.2.3.3.2.3.cmml">sigmoid</mi></mrow><mo lspace="0em" rspace="0em" id="S4.T6.23.9.1.m1.2.3.3.1" xref="S4.T6.23.9.1.m1.2.3.3.1.cmml">​</mo><mrow id="S4.T6.23.9.1.m1.2.3.3.3.2" xref="S4.T6.23.9.1.m1.2.3.3.cmml"><mo stretchy="false" id="S4.T6.23.9.1.m1.2.3.3.3.2.1" xref="S4.T6.23.9.1.m1.2.3.3.cmml">(</mo><mi id="S4.T6.23.9.1.m1.2.2" xref="S4.T6.23.9.1.m1.2.2.cmml">𝐱</mi><mo stretchy="false" id="S4.T6.23.9.1.m1.2.3.3.3.2.2" xref="S4.T6.23.9.1.m1.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.23.9.1.m1.2b"><apply id="S4.T6.23.9.1.m1.2.3.cmml" xref="S4.T6.23.9.1.m1.2.3"><eq id="S4.T6.23.9.1.m1.2.3.1.cmml" xref="S4.T6.23.9.1.m1.2.3.1"></eq><apply id="S4.T6.23.9.1.m1.2.3.2.cmml" xref="S4.T6.23.9.1.m1.2.3.2"><times id="S4.T6.23.9.1.m1.2.3.2.1.cmml" xref="S4.T6.23.9.1.m1.2.3.2.1"></times><ci id="S4.T6.23.9.1.m1.2.3.2.2.cmml" xref="S4.T6.23.9.1.m1.2.3.2.2">Swish</ci><ci id="S4.T6.23.9.1.m1.1.1.cmml" xref="S4.T6.23.9.1.m1.1.1">𝐱</ci></apply><apply id="S4.T6.23.9.1.m1.2.3.3.cmml" xref="S4.T6.23.9.1.m1.2.3.3"><times id="S4.T6.23.9.1.m1.2.3.3.1.cmml" xref="S4.T6.23.9.1.m1.2.3.3.1"></times><apply id="S4.T6.23.9.1.m1.2.3.3.2.cmml" xref="S4.T6.23.9.1.m1.2.3.3.2"><csymbol cd="latexml" id="S4.T6.23.9.1.m1.2.3.3.2.1.cmml" xref="S4.T6.23.9.1.m1.2.3.3.2.1">tensor-product</csymbol><ci id="S4.T6.23.9.1.m1.2.3.3.2.2.cmml" xref="S4.T6.23.9.1.m1.2.3.3.2.2">𝐱</ci><ci id="S4.T6.23.9.1.m1.2.3.3.2.3.cmml" xref="S4.T6.23.9.1.m1.2.3.3.2.3">sigmoid</ci></apply><ci id="S4.T6.23.9.1.m1.2.2.cmml" xref="S4.T6.23.9.1.m1.2.2">𝐱</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.23.9.1.m1.2c">\mathrm{Swish}(\mathbf{x})=\mathbf{x}\otimes\mathrm{sigmoid}(\mathbf{x})</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.24.10" class="ltx_tr">
<td id="S4.T6.24.10.2" class="ltx_td ltx_align_center ltx_border_r">SwiGLU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib262" title="" class="ltx_ref">262</a>]</cite>
</td>
<td id="S4.T6.24.10.1" class="ltx_td ltx_align_left"><math id="S4.T6.24.10.1.m1.3" class="ltx_Math" alttext="\mathrm{SwiGLU}(\mathbf{x}_{1},\mathbf{x}_{2})=\mathrm{Swish}(\mathbf{x_{1}})\otimes\mathbf{x_{2}}" display="inline"><semantics id="S4.T6.24.10.1.m1.3a"><mrow id="S4.T6.24.10.1.m1.3.3" xref="S4.T6.24.10.1.m1.3.3.cmml"><mrow id="S4.T6.24.10.1.m1.2.2.2" xref="S4.T6.24.10.1.m1.2.2.2.cmml"><mi id="S4.T6.24.10.1.m1.2.2.2.4" xref="S4.T6.24.10.1.m1.2.2.2.4.cmml">SwiGLU</mi><mo lspace="0em" rspace="0em" id="S4.T6.24.10.1.m1.2.2.2.3" xref="S4.T6.24.10.1.m1.2.2.2.3.cmml">​</mo><mrow id="S4.T6.24.10.1.m1.2.2.2.2.2" xref="S4.T6.24.10.1.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S4.T6.24.10.1.m1.2.2.2.2.2.3" xref="S4.T6.24.10.1.m1.2.2.2.2.3.cmml">(</mo><msub id="S4.T6.24.10.1.m1.1.1.1.1.1.1" xref="S4.T6.24.10.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.T6.24.10.1.m1.1.1.1.1.1.1.2" xref="S4.T6.24.10.1.m1.1.1.1.1.1.1.2.cmml">𝐱</mi><mn id="S4.T6.24.10.1.m1.1.1.1.1.1.1.3" xref="S4.T6.24.10.1.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.T6.24.10.1.m1.2.2.2.2.2.4" xref="S4.T6.24.10.1.m1.2.2.2.2.3.cmml">,</mo><msub id="S4.T6.24.10.1.m1.2.2.2.2.2.2" xref="S4.T6.24.10.1.m1.2.2.2.2.2.2.cmml"><mi id="S4.T6.24.10.1.m1.2.2.2.2.2.2.2" xref="S4.T6.24.10.1.m1.2.2.2.2.2.2.2.cmml">𝐱</mi><mn id="S4.T6.24.10.1.m1.2.2.2.2.2.2.3" xref="S4.T6.24.10.1.m1.2.2.2.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S4.T6.24.10.1.m1.2.2.2.2.2.5" xref="S4.T6.24.10.1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S4.T6.24.10.1.m1.3.3.4" xref="S4.T6.24.10.1.m1.3.3.4.cmml">=</mo><mrow id="S4.T6.24.10.1.m1.3.3.3" xref="S4.T6.24.10.1.m1.3.3.3.cmml"><mrow id="S4.T6.24.10.1.m1.3.3.3.1" xref="S4.T6.24.10.1.m1.3.3.3.1.cmml"><mi id="S4.T6.24.10.1.m1.3.3.3.1.3" xref="S4.T6.24.10.1.m1.3.3.3.1.3.cmml">Swish</mi><mo lspace="0em" rspace="0em" id="S4.T6.24.10.1.m1.3.3.3.1.2" xref="S4.T6.24.10.1.m1.3.3.3.1.2.cmml">​</mo><mrow id="S4.T6.24.10.1.m1.3.3.3.1.1.1" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.24.10.1.m1.3.3.3.1.1.1.2" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.cmml">(</mo><msub id="S4.T6.24.10.1.m1.3.3.3.1.1.1.1" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.cmml"><mi id="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.2" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.2.cmml">𝐱</mi><mn id="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.3" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.3.cmml">𝟏</mn></msub><mo rspace="0.055em" stretchy="false" id="S4.T6.24.10.1.m1.3.3.3.1.1.1.3" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.T6.24.10.1.m1.3.3.3.2" xref="S4.T6.24.10.1.m1.3.3.3.2.cmml">⊗</mo><msub id="S4.T6.24.10.1.m1.3.3.3.3" xref="S4.T6.24.10.1.m1.3.3.3.3.cmml"><mi id="S4.T6.24.10.1.m1.3.3.3.3.2" xref="S4.T6.24.10.1.m1.3.3.3.3.2.cmml">𝐱</mi><mn id="S4.T6.24.10.1.m1.3.3.3.3.3" xref="S4.T6.24.10.1.m1.3.3.3.3.3.cmml">𝟐</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.24.10.1.m1.3b"><apply id="S4.T6.24.10.1.m1.3.3.cmml" xref="S4.T6.24.10.1.m1.3.3"><eq id="S4.T6.24.10.1.m1.3.3.4.cmml" xref="S4.T6.24.10.1.m1.3.3.4"></eq><apply id="S4.T6.24.10.1.m1.2.2.2.cmml" xref="S4.T6.24.10.1.m1.2.2.2"><times id="S4.T6.24.10.1.m1.2.2.2.3.cmml" xref="S4.T6.24.10.1.m1.2.2.2.3"></times><ci id="S4.T6.24.10.1.m1.2.2.2.4.cmml" xref="S4.T6.24.10.1.m1.2.2.2.4">SwiGLU</ci><interval closure="open" id="S4.T6.24.10.1.m1.2.2.2.2.3.cmml" xref="S4.T6.24.10.1.m1.2.2.2.2.2"><apply id="S4.T6.24.10.1.m1.1.1.1.1.1.1.cmml" xref="S4.T6.24.10.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.T6.24.10.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.T6.24.10.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.T6.24.10.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.T6.24.10.1.m1.1.1.1.1.1.1.2">𝐱</ci><cn type="integer" id="S4.T6.24.10.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.T6.24.10.1.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S4.T6.24.10.1.m1.2.2.2.2.2.2.cmml" xref="S4.T6.24.10.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T6.24.10.1.m1.2.2.2.2.2.2.1.cmml" xref="S4.T6.24.10.1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S4.T6.24.10.1.m1.2.2.2.2.2.2.2.cmml" xref="S4.T6.24.10.1.m1.2.2.2.2.2.2.2">𝐱</ci><cn type="integer" id="S4.T6.24.10.1.m1.2.2.2.2.2.2.3.cmml" xref="S4.T6.24.10.1.m1.2.2.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S4.T6.24.10.1.m1.3.3.3.cmml" xref="S4.T6.24.10.1.m1.3.3.3"><csymbol cd="latexml" id="S4.T6.24.10.1.m1.3.3.3.2.cmml" xref="S4.T6.24.10.1.m1.3.3.3.2">tensor-product</csymbol><apply id="S4.T6.24.10.1.m1.3.3.3.1.cmml" xref="S4.T6.24.10.1.m1.3.3.3.1"><times id="S4.T6.24.10.1.m1.3.3.3.1.2.cmml" xref="S4.T6.24.10.1.m1.3.3.3.1.2"></times><ci id="S4.T6.24.10.1.m1.3.3.3.1.3.cmml" xref="S4.T6.24.10.1.m1.3.3.3.1.3">Swish</ci><apply id="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.cmml" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.1.cmml" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1">subscript</csymbol><ci id="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.2.cmml" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.2">𝐱</ci><cn type="integer" id="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.3.cmml" xref="S4.T6.24.10.1.m1.3.3.3.1.1.1.1.3">1</cn></apply></apply><apply id="S4.T6.24.10.1.m1.3.3.3.3.cmml" xref="S4.T6.24.10.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S4.T6.24.10.1.m1.3.3.3.3.1.cmml" xref="S4.T6.24.10.1.m1.3.3.3.3">subscript</csymbol><ci id="S4.T6.24.10.1.m1.3.3.3.3.2.cmml" xref="S4.T6.24.10.1.m1.3.3.3.3.2">𝐱</ci><cn type="integer" id="S4.T6.24.10.1.m1.3.3.3.3.3.cmml" xref="S4.T6.24.10.1.m1.3.3.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.24.10.1.m1.3c">\mathrm{SwiGLU}(\mathbf{x}_{1},\mathbf{x}_{2})=\mathrm{Swish}(\mathbf{x_{1}})\otimes\mathbf{x_{2}}</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.25.11" class="ltx_tr">
<td id="S4.T6.25.11.2" class="ltx_td ltx_align_center ltx_border_r">GeGLU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib262" title="" class="ltx_ref">262</a>]</cite>
</td>
<td id="S4.T6.25.11.1" class="ltx_td ltx_align_left"><math id="S4.T6.25.11.1.m1.3" class="ltx_Math" alttext="\mathrm{GeGLU}(\mathbf{x}_{1},\mathbf{x}_{2})=\mathrm{GeLU}(\mathbf{x_{1}})\otimes\mathbf{x_{2}}" display="inline"><semantics id="S4.T6.25.11.1.m1.3a"><mrow id="S4.T6.25.11.1.m1.3.3" xref="S4.T6.25.11.1.m1.3.3.cmml"><mrow id="S4.T6.25.11.1.m1.2.2.2" xref="S4.T6.25.11.1.m1.2.2.2.cmml"><mi id="S4.T6.25.11.1.m1.2.2.2.4" xref="S4.T6.25.11.1.m1.2.2.2.4.cmml">GeGLU</mi><mo lspace="0em" rspace="0em" id="S4.T6.25.11.1.m1.2.2.2.3" xref="S4.T6.25.11.1.m1.2.2.2.3.cmml">​</mo><mrow id="S4.T6.25.11.1.m1.2.2.2.2.2" xref="S4.T6.25.11.1.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S4.T6.25.11.1.m1.2.2.2.2.2.3" xref="S4.T6.25.11.1.m1.2.2.2.2.3.cmml">(</mo><msub id="S4.T6.25.11.1.m1.1.1.1.1.1.1" xref="S4.T6.25.11.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.T6.25.11.1.m1.1.1.1.1.1.1.2" xref="S4.T6.25.11.1.m1.1.1.1.1.1.1.2.cmml">𝐱</mi><mn id="S4.T6.25.11.1.m1.1.1.1.1.1.1.3" xref="S4.T6.25.11.1.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.T6.25.11.1.m1.2.2.2.2.2.4" xref="S4.T6.25.11.1.m1.2.2.2.2.3.cmml">,</mo><msub id="S4.T6.25.11.1.m1.2.2.2.2.2.2" xref="S4.T6.25.11.1.m1.2.2.2.2.2.2.cmml"><mi id="S4.T6.25.11.1.m1.2.2.2.2.2.2.2" xref="S4.T6.25.11.1.m1.2.2.2.2.2.2.2.cmml">𝐱</mi><mn id="S4.T6.25.11.1.m1.2.2.2.2.2.2.3" xref="S4.T6.25.11.1.m1.2.2.2.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S4.T6.25.11.1.m1.2.2.2.2.2.5" xref="S4.T6.25.11.1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S4.T6.25.11.1.m1.3.3.4" xref="S4.T6.25.11.1.m1.3.3.4.cmml">=</mo><mrow id="S4.T6.25.11.1.m1.3.3.3" xref="S4.T6.25.11.1.m1.3.3.3.cmml"><mrow id="S4.T6.25.11.1.m1.3.3.3.1" xref="S4.T6.25.11.1.m1.3.3.3.1.cmml"><mi id="S4.T6.25.11.1.m1.3.3.3.1.3" xref="S4.T6.25.11.1.m1.3.3.3.1.3.cmml">GeLU</mi><mo lspace="0em" rspace="0em" id="S4.T6.25.11.1.m1.3.3.3.1.2" xref="S4.T6.25.11.1.m1.3.3.3.1.2.cmml">​</mo><mrow id="S4.T6.25.11.1.m1.3.3.3.1.1.1" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.25.11.1.m1.3.3.3.1.1.1.2" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.cmml">(</mo><msub id="S4.T6.25.11.1.m1.3.3.3.1.1.1.1" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.cmml"><mi id="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.2" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.2.cmml">𝐱</mi><mn id="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.3" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.3.cmml">𝟏</mn></msub><mo rspace="0.055em" stretchy="false" id="S4.T6.25.11.1.m1.3.3.3.1.1.1.3" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.T6.25.11.1.m1.3.3.3.2" xref="S4.T6.25.11.1.m1.3.3.3.2.cmml">⊗</mo><msub id="S4.T6.25.11.1.m1.3.3.3.3" xref="S4.T6.25.11.1.m1.3.3.3.3.cmml"><mi id="S4.T6.25.11.1.m1.3.3.3.3.2" xref="S4.T6.25.11.1.m1.3.3.3.3.2.cmml">𝐱</mi><mn id="S4.T6.25.11.1.m1.3.3.3.3.3" xref="S4.T6.25.11.1.m1.3.3.3.3.3.cmml">𝟐</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.25.11.1.m1.3b"><apply id="S4.T6.25.11.1.m1.3.3.cmml" xref="S4.T6.25.11.1.m1.3.3"><eq id="S4.T6.25.11.1.m1.3.3.4.cmml" xref="S4.T6.25.11.1.m1.3.3.4"></eq><apply id="S4.T6.25.11.1.m1.2.2.2.cmml" xref="S4.T6.25.11.1.m1.2.2.2"><times id="S4.T6.25.11.1.m1.2.2.2.3.cmml" xref="S4.T6.25.11.1.m1.2.2.2.3"></times><ci id="S4.T6.25.11.1.m1.2.2.2.4.cmml" xref="S4.T6.25.11.1.m1.2.2.2.4">GeGLU</ci><interval closure="open" id="S4.T6.25.11.1.m1.2.2.2.2.3.cmml" xref="S4.T6.25.11.1.m1.2.2.2.2.2"><apply id="S4.T6.25.11.1.m1.1.1.1.1.1.1.cmml" xref="S4.T6.25.11.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.T6.25.11.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.T6.25.11.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.T6.25.11.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.T6.25.11.1.m1.1.1.1.1.1.1.2">𝐱</ci><cn type="integer" id="S4.T6.25.11.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.T6.25.11.1.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S4.T6.25.11.1.m1.2.2.2.2.2.2.cmml" xref="S4.T6.25.11.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T6.25.11.1.m1.2.2.2.2.2.2.1.cmml" xref="S4.T6.25.11.1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S4.T6.25.11.1.m1.2.2.2.2.2.2.2.cmml" xref="S4.T6.25.11.1.m1.2.2.2.2.2.2.2">𝐱</ci><cn type="integer" id="S4.T6.25.11.1.m1.2.2.2.2.2.2.3.cmml" xref="S4.T6.25.11.1.m1.2.2.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S4.T6.25.11.1.m1.3.3.3.cmml" xref="S4.T6.25.11.1.m1.3.3.3"><csymbol cd="latexml" id="S4.T6.25.11.1.m1.3.3.3.2.cmml" xref="S4.T6.25.11.1.m1.3.3.3.2">tensor-product</csymbol><apply id="S4.T6.25.11.1.m1.3.3.3.1.cmml" xref="S4.T6.25.11.1.m1.3.3.3.1"><times id="S4.T6.25.11.1.m1.3.3.3.1.2.cmml" xref="S4.T6.25.11.1.m1.3.3.3.1.2"></times><ci id="S4.T6.25.11.1.m1.3.3.3.1.3.cmml" xref="S4.T6.25.11.1.m1.3.3.3.1.3">GeLU</ci><apply id="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.cmml" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.1.cmml" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1">subscript</csymbol><ci id="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.2.cmml" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.2">𝐱</ci><cn type="integer" id="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.3.cmml" xref="S4.T6.25.11.1.m1.3.3.3.1.1.1.1.3">1</cn></apply></apply><apply id="S4.T6.25.11.1.m1.3.3.3.3.cmml" xref="S4.T6.25.11.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S4.T6.25.11.1.m1.3.3.3.3.1.cmml" xref="S4.T6.25.11.1.m1.3.3.3.3">subscript</csymbol><ci id="S4.T6.25.11.1.m1.3.3.3.3.2.cmml" xref="S4.T6.25.11.1.m1.3.3.3.3.2">𝐱</ci><cn type="integer" id="S4.T6.25.11.1.m1.3.3.3.3.3.cmml" xref="S4.T6.25.11.1.m1.3.3.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.25.11.1.m1.3c">\mathrm{GeGLU}(\mathbf{x}_{1},\mathbf{x}_{2})=\mathrm{GeLU}(\mathbf{x_{1}})\otimes\mathbf{x_{2}}</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.26.12" class="ltx_tr">
<td id="S4.T6.26.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T6.26.12.2.1" class="ltx_text">Position embedding</span></td>
<td id="S4.T6.26.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Absolute&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="S4.T6.26.12.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T6.26.12.1.m1.1" class="ltx_Math" alttext="\mathbf{x}_{i}=\mathbf{x}_{i}+\mathbf{p}_{i}" display="inline"><semantics id="S4.T6.26.12.1.m1.1a"><mrow id="S4.T6.26.12.1.m1.1.1" xref="S4.T6.26.12.1.m1.1.1.cmml"><msub id="S4.T6.26.12.1.m1.1.1.2" xref="S4.T6.26.12.1.m1.1.1.2.cmml"><mi id="S4.T6.26.12.1.m1.1.1.2.2" xref="S4.T6.26.12.1.m1.1.1.2.2.cmml">𝐱</mi><mi id="S4.T6.26.12.1.m1.1.1.2.3" xref="S4.T6.26.12.1.m1.1.1.2.3.cmml">i</mi></msub><mo id="S4.T6.26.12.1.m1.1.1.1" xref="S4.T6.26.12.1.m1.1.1.1.cmml">=</mo><mrow id="S4.T6.26.12.1.m1.1.1.3" xref="S4.T6.26.12.1.m1.1.1.3.cmml"><msub id="S4.T6.26.12.1.m1.1.1.3.2" xref="S4.T6.26.12.1.m1.1.1.3.2.cmml"><mi id="S4.T6.26.12.1.m1.1.1.3.2.2" xref="S4.T6.26.12.1.m1.1.1.3.2.2.cmml">𝐱</mi><mi id="S4.T6.26.12.1.m1.1.1.3.2.3" xref="S4.T6.26.12.1.m1.1.1.3.2.3.cmml">i</mi></msub><mo id="S4.T6.26.12.1.m1.1.1.3.1" xref="S4.T6.26.12.1.m1.1.1.3.1.cmml">+</mo><msub id="S4.T6.26.12.1.m1.1.1.3.3" xref="S4.T6.26.12.1.m1.1.1.3.3.cmml"><mi id="S4.T6.26.12.1.m1.1.1.3.3.2" xref="S4.T6.26.12.1.m1.1.1.3.3.2.cmml">𝐩</mi><mi id="S4.T6.26.12.1.m1.1.1.3.3.3" xref="S4.T6.26.12.1.m1.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.26.12.1.m1.1b"><apply id="S4.T6.26.12.1.m1.1.1.cmml" xref="S4.T6.26.12.1.m1.1.1"><eq id="S4.T6.26.12.1.m1.1.1.1.cmml" xref="S4.T6.26.12.1.m1.1.1.1"></eq><apply id="S4.T6.26.12.1.m1.1.1.2.cmml" xref="S4.T6.26.12.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T6.26.12.1.m1.1.1.2.1.cmml" xref="S4.T6.26.12.1.m1.1.1.2">subscript</csymbol><ci id="S4.T6.26.12.1.m1.1.1.2.2.cmml" xref="S4.T6.26.12.1.m1.1.1.2.2">𝐱</ci><ci id="S4.T6.26.12.1.m1.1.1.2.3.cmml" xref="S4.T6.26.12.1.m1.1.1.2.3">𝑖</ci></apply><apply id="S4.T6.26.12.1.m1.1.1.3.cmml" xref="S4.T6.26.12.1.m1.1.1.3"><plus id="S4.T6.26.12.1.m1.1.1.3.1.cmml" xref="S4.T6.26.12.1.m1.1.1.3.1"></plus><apply id="S4.T6.26.12.1.m1.1.1.3.2.cmml" xref="S4.T6.26.12.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S4.T6.26.12.1.m1.1.1.3.2.1.cmml" xref="S4.T6.26.12.1.m1.1.1.3.2">subscript</csymbol><ci id="S4.T6.26.12.1.m1.1.1.3.2.2.cmml" xref="S4.T6.26.12.1.m1.1.1.3.2.2">𝐱</ci><ci id="S4.T6.26.12.1.m1.1.1.3.2.3.cmml" xref="S4.T6.26.12.1.m1.1.1.3.2.3">𝑖</ci></apply><apply id="S4.T6.26.12.1.m1.1.1.3.3.cmml" xref="S4.T6.26.12.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.T6.26.12.1.m1.1.1.3.3.1.cmml" xref="S4.T6.26.12.1.m1.1.1.3.3">subscript</csymbol><ci id="S4.T6.26.12.1.m1.1.1.3.3.2.cmml" xref="S4.T6.26.12.1.m1.1.1.3.3.2">𝐩</ci><ci id="S4.T6.26.12.1.m1.1.1.3.3.3.cmml" xref="S4.T6.26.12.1.m1.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.26.12.1.m1.1c">\mathbf{x}_{i}=\mathbf{x}_{i}+\mathbf{p}_{i}</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.27.13" class="ltx_tr">
<td id="S4.T6.27.13.2" class="ltx_td ltx_align_center ltx_border_r">Relative&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>
</td>
<td id="S4.T6.27.13.1" class="ltx_td ltx_align_left"><math id="S4.T6.27.13.1.m1.1" class="ltx_Math" alttext="A_{ij}=\mathbf{W}_{q}\mathbf{x}_{i}\mathbf{x}_{j}^{T}\mathbf{W}_{k}^{T}+r_{i-j}" display="inline"><semantics id="S4.T6.27.13.1.m1.1a"><mrow id="S4.T6.27.13.1.m1.1.1" xref="S4.T6.27.13.1.m1.1.1.cmml"><msub id="S4.T6.27.13.1.m1.1.1.2" xref="S4.T6.27.13.1.m1.1.1.2.cmml"><mi id="S4.T6.27.13.1.m1.1.1.2.2" xref="S4.T6.27.13.1.m1.1.1.2.2.cmml">A</mi><mrow id="S4.T6.27.13.1.m1.1.1.2.3" xref="S4.T6.27.13.1.m1.1.1.2.3.cmml"><mi id="S4.T6.27.13.1.m1.1.1.2.3.2" xref="S4.T6.27.13.1.m1.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.T6.27.13.1.m1.1.1.2.3.1" xref="S4.T6.27.13.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.T6.27.13.1.m1.1.1.2.3.3" xref="S4.T6.27.13.1.m1.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S4.T6.27.13.1.m1.1.1.1" xref="S4.T6.27.13.1.m1.1.1.1.cmml">=</mo><mrow id="S4.T6.27.13.1.m1.1.1.3" xref="S4.T6.27.13.1.m1.1.1.3.cmml"><mrow id="S4.T6.27.13.1.m1.1.1.3.2" xref="S4.T6.27.13.1.m1.1.1.3.2.cmml"><msub id="S4.T6.27.13.1.m1.1.1.3.2.2" xref="S4.T6.27.13.1.m1.1.1.3.2.2.cmml"><mi id="S4.T6.27.13.1.m1.1.1.3.2.2.2" xref="S4.T6.27.13.1.m1.1.1.3.2.2.2.cmml">𝐖</mi><mi id="S4.T6.27.13.1.m1.1.1.3.2.2.3" xref="S4.T6.27.13.1.m1.1.1.3.2.2.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.27.13.1.m1.1.1.3.2.1" xref="S4.T6.27.13.1.m1.1.1.3.2.1.cmml">​</mo><msub id="S4.T6.27.13.1.m1.1.1.3.2.3" xref="S4.T6.27.13.1.m1.1.1.3.2.3.cmml"><mi id="S4.T6.27.13.1.m1.1.1.3.2.3.2" xref="S4.T6.27.13.1.m1.1.1.3.2.3.2.cmml">𝐱</mi><mi id="S4.T6.27.13.1.m1.1.1.3.2.3.3" xref="S4.T6.27.13.1.m1.1.1.3.2.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.27.13.1.m1.1.1.3.2.1a" xref="S4.T6.27.13.1.m1.1.1.3.2.1.cmml">​</mo><msubsup id="S4.T6.27.13.1.m1.1.1.3.2.4" xref="S4.T6.27.13.1.m1.1.1.3.2.4.cmml"><mi id="S4.T6.27.13.1.m1.1.1.3.2.4.2.2" xref="S4.T6.27.13.1.m1.1.1.3.2.4.2.2.cmml">𝐱</mi><mi id="S4.T6.27.13.1.m1.1.1.3.2.4.2.3" xref="S4.T6.27.13.1.m1.1.1.3.2.4.2.3.cmml">j</mi><mi id="S4.T6.27.13.1.m1.1.1.3.2.4.3" xref="S4.T6.27.13.1.m1.1.1.3.2.4.3.cmml">T</mi></msubsup><mo lspace="0em" rspace="0em" id="S4.T6.27.13.1.m1.1.1.3.2.1b" xref="S4.T6.27.13.1.m1.1.1.3.2.1.cmml">​</mo><msubsup id="S4.T6.27.13.1.m1.1.1.3.2.5" xref="S4.T6.27.13.1.m1.1.1.3.2.5.cmml"><mi id="S4.T6.27.13.1.m1.1.1.3.2.5.2.2" xref="S4.T6.27.13.1.m1.1.1.3.2.5.2.2.cmml">𝐖</mi><mi id="S4.T6.27.13.1.m1.1.1.3.2.5.2.3" xref="S4.T6.27.13.1.m1.1.1.3.2.5.2.3.cmml">k</mi><mi id="S4.T6.27.13.1.m1.1.1.3.2.5.3" xref="S4.T6.27.13.1.m1.1.1.3.2.5.3.cmml">T</mi></msubsup></mrow><mo id="S4.T6.27.13.1.m1.1.1.3.1" xref="S4.T6.27.13.1.m1.1.1.3.1.cmml">+</mo><msub id="S4.T6.27.13.1.m1.1.1.3.3" xref="S4.T6.27.13.1.m1.1.1.3.3.cmml"><mi id="S4.T6.27.13.1.m1.1.1.3.3.2" xref="S4.T6.27.13.1.m1.1.1.3.3.2.cmml">r</mi><mrow id="S4.T6.27.13.1.m1.1.1.3.3.3" xref="S4.T6.27.13.1.m1.1.1.3.3.3.cmml"><mi id="S4.T6.27.13.1.m1.1.1.3.3.3.2" xref="S4.T6.27.13.1.m1.1.1.3.3.3.2.cmml">i</mi><mo id="S4.T6.27.13.1.m1.1.1.3.3.3.1" xref="S4.T6.27.13.1.m1.1.1.3.3.3.1.cmml">−</mo><mi id="S4.T6.27.13.1.m1.1.1.3.3.3.3" xref="S4.T6.27.13.1.m1.1.1.3.3.3.3.cmml">j</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.27.13.1.m1.1b"><apply id="S4.T6.27.13.1.m1.1.1.cmml" xref="S4.T6.27.13.1.m1.1.1"><eq id="S4.T6.27.13.1.m1.1.1.1.cmml" xref="S4.T6.27.13.1.m1.1.1.1"></eq><apply id="S4.T6.27.13.1.m1.1.1.2.cmml" xref="S4.T6.27.13.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T6.27.13.1.m1.1.1.2.1.cmml" xref="S4.T6.27.13.1.m1.1.1.2">subscript</csymbol><ci id="S4.T6.27.13.1.m1.1.1.2.2.cmml" xref="S4.T6.27.13.1.m1.1.1.2.2">𝐴</ci><apply id="S4.T6.27.13.1.m1.1.1.2.3.cmml" xref="S4.T6.27.13.1.m1.1.1.2.3"><times id="S4.T6.27.13.1.m1.1.1.2.3.1.cmml" xref="S4.T6.27.13.1.m1.1.1.2.3.1"></times><ci id="S4.T6.27.13.1.m1.1.1.2.3.2.cmml" xref="S4.T6.27.13.1.m1.1.1.2.3.2">𝑖</ci><ci id="S4.T6.27.13.1.m1.1.1.2.3.3.cmml" xref="S4.T6.27.13.1.m1.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S4.T6.27.13.1.m1.1.1.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3"><plus id="S4.T6.27.13.1.m1.1.1.3.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.1"></plus><apply id="S4.T6.27.13.1.m1.1.1.3.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2"><times id="S4.T6.27.13.1.m1.1.1.3.2.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.1"></times><apply id="S4.T6.27.13.1.m1.1.1.3.2.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.T6.27.13.1.m1.1.1.3.2.2.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.2">subscript</csymbol><ci id="S4.T6.27.13.1.m1.1.1.3.2.2.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.2.2">𝐖</ci><ci id="S4.T6.27.13.1.m1.1.1.3.2.2.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.2.3">𝑞</ci></apply><apply id="S4.T6.27.13.1.m1.1.1.3.2.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.T6.27.13.1.m1.1.1.3.2.3.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.3">subscript</csymbol><ci id="S4.T6.27.13.1.m1.1.1.3.2.3.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.3.2">𝐱</ci><ci id="S4.T6.27.13.1.m1.1.1.3.2.3.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.3.3">𝑖</ci></apply><apply id="S4.T6.27.13.1.m1.1.1.3.2.4.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.4"><csymbol cd="ambiguous" id="S4.T6.27.13.1.m1.1.1.3.2.4.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.4">superscript</csymbol><apply id="S4.T6.27.13.1.m1.1.1.3.2.4.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.4"><csymbol cd="ambiguous" id="S4.T6.27.13.1.m1.1.1.3.2.4.2.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.4">subscript</csymbol><ci id="S4.T6.27.13.1.m1.1.1.3.2.4.2.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.4.2.2">𝐱</ci><ci id="S4.T6.27.13.1.m1.1.1.3.2.4.2.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.4.2.3">𝑗</ci></apply><ci id="S4.T6.27.13.1.m1.1.1.3.2.4.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.4.3">𝑇</ci></apply><apply id="S4.T6.27.13.1.m1.1.1.3.2.5.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.5"><csymbol cd="ambiguous" id="S4.T6.27.13.1.m1.1.1.3.2.5.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.5">superscript</csymbol><apply id="S4.T6.27.13.1.m1.1.1.3.2.5.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.5"><csymbol cd="ambiguous" id="S4.T6.27.13.1.m1.1.1.3.2.5.2.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.5">subscript</csymbol><ci id="S4.T6.27.13.1.m1.1.1.3.2.5.2.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.5.2.2">𝐖</ci><ci id="S4.T6.27.13.1.m1.1.1.3.2.5.2.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.5.2.3">𝑘</ci></apply><ci id="S4.T6.27.13.1.m1.1.1.3.2.5.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.2.5.3">𝑇</ci></apply></apply><apply id="S4.T6.27.13.1.m1.1.1.3.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.T6.27.13.1.m1.1.1.3.3.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.3">subscript</csymbol><ci id="S4.T6.27.13.1.m1.1.1.3.3.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.3.2">𝑟</ci><apply id="S4.T6.27.13.1.m1.1.1.3.3.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.3.3"><minus id="S4.T6.27.13.1.m1.1.1.3.3.3.1.cmml" xref="S4.T6.27.13.1.m1.1.1.3.3.3.1"></minus><ci id="S4.T6.27.13.1.m1.1.1.3.3.3.2.cmml" xref="S4.T6.27.13.1.m1.1.1.3.3.3.2">𝑖</ci><ci id="S4.T6.27.13.1.m1.1.1.3.3.3.3.cmml" xref="S4.T6.27.13.1.m1.1.1.3.3.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.27.13.1.m1.1c">A_{ij}=\mathbf{W}_{q}\mathbf{x}_{i}\mathbf{x}_{j}^{T}\mathbf{W}_{k}^{T}+r_{i-j}</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.28.14" class="ltx_tr">
<td id="S4.T6.28.14.2" class="ltx_td ltx_align_center ltx_border_r">RoPE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib263" title="" class="ltx_ref">263</a>]</cite>
</td>
<td id="S4.T6.28.14.1" class="ltx_td ltx_align_left"><math id="S4.T6.28.14.1.m1.8" class="ltx_Math" alttext="A_{ij}=\mathbf{W}_{q}\mathbf{x}_{i}\mathbf{R}_{\Theta,i-j}\mathbf{x}_{j}^{T}\mathbf{W}_{k}^{T}=(\mathbf{W}_{q}\mathbf{x}_{i}\mathbf{R}_{\Theta,i})(\mathbf{W}_{k}\mathbf{x}_{j}R_{\Theta,j})^{T}" display="inline"><semantics id="S4.T6.28.14.1.m1.8a"><mrow id="S4.T6.28.14.1.m1.8.8" xref="S4.T6.28.14.1.m1.8.8.cmml"><msub id="S4.T6.28.14.1.m1.8.8.4" xref="S4.T6.28.14.1.m1.8.8.4.cmml"><mi id="S4.T6.28.14.1.m1.8.8.4.2" xref="S4.T6.28.14.1.m1.8.8.4.2.cmml">A</mi><mrow id="S4.T6.28.14.1.m1.8.8.4.3" xref="S4.T6.28.14.1.m1.8.8.4.3.cmml"><mi id="S4.T6.28.14.1.m1.8.8.4.3.2" xref="S4.T6.28.14.1.m1.8.8.4.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.8.8.4.3.1" xref="S4.T6.28.14.1.m1.8.8.4.3.1.cmml">​</mo><mi id="S4.T6.28.14.1.m1.8.8.4.3.3" xref="S4.T6.28.14.1.m1.8.8.4.3.3.cmml">j</mi></mrow></msub><mo id="S4.T6.28.14.1.m1.8.8.5" xref="S4.T6.28.14.1.m1.8.8.5.cmml">=</mo><mrow id="S4.T6.28.14.1.m1.8.8.6" xref="S4.T6.28.14.1.m1.8.8.6.cmml"><msub id="S4.T6.28.14.1.m1.8.8.6.2" xref="S4.T6.28.14.1.m1.8.8.6.2.cmml"><mi id="S4.T6.28.14.1.m1.8.8.6.2.2" xref="S4.T6.28.14.1.m1.8.8.6.2.2.cmml">𝐖</mi><mi id="S4.T6.28.14.1.m1.8.8.6.2.3" xref="S4.T6.28.14.1.m1.8.8.6.2.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.8.8.6.1" xref="S4.T6.28.14.1.m1.8.8.6.1.cmml">​</mo><msub id="S4.T6.28.14.1.m1.8.8.6.3" xref="S4.T6.28.14.1.m1.8.8.6.3.cmml"><mi id="S4.T6.28.14.1.m1.8.8.6.3.2" xref="S4.T6.28.14.1.m1.8.8.6.3.2.cmml">𝐱</mi><mi id="S4.T6.28.14.1.m1.8.8.6.3.3" xref="S4.T6.28.14.1.m1.8.8.6.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.8.8.6.1a" xref="S4.T6.28.14.1.m1.8.8.6.1.cmml">​</mo><msub id="S4.T6.28.14.1.m1.8.8.6.4" xref="S4.T6.28.14.1.m1.8.8.6.4.cmml"><mi id="S4.T6.28.14.1.m1.8.8.6.4.2" xref="S4.T6.28.14.1.m1.8.8.6.4.2.cmml">𝐑</mi><mrow id="S4.T6.28.14.1.m1.2.2.2.2" xref="S4.T6.28.14.1.m1.2.2.2.3.cmml"><mi mathvariant="normal" id="S4.T6.28.14.1.m1.1.1.1.1" xref="S4.T6.28.14.1.m1.1.1.1.1.cmml">Θ</mi><mo id="S4.T6.28.14.1.m1.2.2.2.2.2" xref="S4.T6.28.14.1.m1.2.2.2.3.cmml">,</mo><mrow id="S4.T6.28.14.1.m1.2.2.2.2.1" xref="S4.T6.28.14.1.m1.2.2.2.2.1.cmml"><mi id="S4.T6.28.14.1.m1.2.2.2.2.1.2" xref="S4.T6.28.14.1.m1.2.2.2.2.1.2.cmml">i</mi><mo id="S4.T6.28.14.1.m1.2.2.2.2.1.1" xref="S4.T6.28.14.1.m1.2.2.2.2.1.1.cmml">−</mo><mi id="S4.T6.28.14.1.m1.2.2.2.2.1.3" xref="S4.T6.28.14.1.m1.2.2.2.2.1.3.cmml">j</mi></mrow></mrow></msub><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.8.8.6.1b" xref="S4.T6.28.14.1.m1.8.8.6.1.cmml">​</mo><msubsup id="S4.T6.28.14.1.m1.8.8.6.5" xref="S4.T6.28.14.1.m1.8.8.6.5.cmml"><mi id="S4.T6.28.14.1.m1.8.8.6.5.2.2" xref="S4.T6.28.14.1.m1.8.8.6.5.2.2.cmml">𝐱</mi><mi id="S4.T6.28.14.1.m1.8.8.6.5.2.3" xref="S4.T6.28.14.1.m1.8.8.6.5.2.3.cmml">j</mi><mi id="S4.T6.28.14.1.m1.8.8.6.5.3" xref="S4.T6.28.14.1.m1.8.8.6.5.3.cmml">T</mi></msubsup><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.8.8.6.1c" xref="S4.T6.28.14.1.m1.8.8.6.1.cmml">​</mo><msubsup id="S4.T6.28.14.1.m1.8.8.6.6" xref="S4.T6.28.14.1.m1.8.8.6.6.cmml"><mi id="S4.T6.28.14.1.m1.8.8.6.6.2.2" xref="S4.T6.28.14.1.m1.8.8.6.6.2.2.cmml">𝐖</mi><mi id="S4.T6.28.14.1.m1.8.8.6.6.2.3" xref="S4.T6.28.14.1.m1.8.8.6.6.2.3.cmml">k</mi><mi id="S4.T6.28.14.1.m1.8.8.6.6.3" xref="S4.T6.28.14.1.m1.8.8.6.6.3.cmml">T</mi></msubsup></mrow><mo id="S4.T6.28.14.1.m1.8.8.7" xref="S4.T6.28.14.1.m1.8.8.7.cmml">=</mo><mrow id="S4.T6.28.14.1.m1.8.8.2" xref="S4.T6.28.14.1.m1.8.8.2.cmml"><mrow id="S4.T6.28.14.1.m1.7.7.1.1.1" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.28.14.1.m1.7.7.1.1.1.2" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.cmml">(</mo><mrow id="S4.T6.28.14.1.m1.7.7.1.1.1.1" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.cmml"><msub id="S4.T6.28.14.1.m1.7.7.1.1.1.1.2" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.cmml"><mi id="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.2" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.2.cmml">𝐖</mi><mi id="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.3" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.7.7.1.1.1.1.1" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.1.cmml">​</mo><msub id="S4.T6.28.14.1.m1.7.7.1.1.1.1.3" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.cmml"><mi id="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.2" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.2.cmml">𝐱</mi><mi id="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.3" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.7.7.1.1.1.1.1a" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.1.cmml">​</mo><msub id="S4.T6.28.14.1.m1.7.7.1.1.1.1.4" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.4.cmml"><mi id="S4.T6.28.14.1.m1.7.7.1.1.1.1.4.2" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.4.2.cmml">𝐑</mi><mrow id="S4.T6.28.14.1.m1.4.4.2.4" xref="S4.T6.28.14.1.m1.4.4.2.3.cmml"><mi mathvariant="normal" id="S4.T6.28.14.1.m1.3.3.1.1" xref="S4.T6.28.14.1.m1.3.3.1.1.cmml">Θ</mi><mo id="S4.T6.28.14.1.m1.4.4.2.4.1" xref="S4.T6.28.14.1.m1.4.4.2.3.cmml">,</mo><mi id="S4.T6.28.14.1.m1.4.4.2.2" xref="S4.T6.28.14.1.m1.4.4.2.2.cmml">i</mi></mrow></msub></mrow><mo stretchy="false" id="S4.T6.28.14.1.m1.7.7.1.1.1.3" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.8.8.2.3" xref="S4.T6.28.14.1.m1.8.8.2.3.cmml">​</mo><msup id="S4.T6.28.14.1.m1.8.8.2.2" xref="S4.T6.28.14.1.m1.8.8.2.2.cmml"><mrow id="S4.T6.28.14.1.m1.8.8.2.2.1.1" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.T6.28.14.1.m1.8.8.2.2.1.1.2" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.cmml">(</mo><mrow id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.cmml"><msub id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.cmml"><mi id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.2" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.2.cmml">𝐖</mi><mi id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.3" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.1" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.1.cmml">​</mo><msub id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.cmml"><mi id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.2" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.2.cmml">𝐱</mi><mi id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.3" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.1a" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.1.cmml">​</mo><msub id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4.cmml"><mi id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4.2" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4.2.cmml">R</mi><mrow id="S4.T6.28.14.1.m1.6.6.2.4" xref="S4.T6.28.14.1.m1.6.6.2.3.cmml"><mi mathvariant="normal" id="S4.T6.28.14.1.m1.5.5.1.1" xref="S4.T6.28.14.1.m1.5.5.1.1.cmml">Θ</mi><mo id="S4.T6.28.14.1.m1.6.6.2.4.1" xref="S4.T6.28.14.1.m1.6.6.2.3.cmml">,</mo><mi id="S4.T6.28.14.1.m1.6.6.2.2" xref="S4.T6.28.14.1.m1.6.6.2.2.cmml">j</mi></mrow></msub></mrow><mo stretchy="false" id="S4.T6.28.14.1.m1.8.8.2.2.1.1.3" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.cmml">)</mo></mrow><mi id="S4.T6.28.14.1.m1.8.8.2.2.3" xref="S4.T6.28.14.1.m1.8.8.2.2.3.cmml">T</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.28.14.1.m1.8b"><apply id="S4.T6.28.14.1.m1.8.8.cmml" xref="S4.T6.28.14.1.m1.8.8"><and id="S4.T6.28.14.1.m1.8.8a.cmml" xref="S4.T6.28.14.1.m1.8.8"></and><apply id="S4.T6.28.14.1.m1.8.8b.cmml" xref="S4.T6.28.14.1.m1.8.8"><eq id="S4.T6.28.14.1.m1.8.8.5.cmml" xref="S4.T6.28.14.1.m1.8.8.5"></eq><apply id="S4.T6.28.14.1.m1.8.8.4.cmml" xref="S4.T6.28.14.1.m1.8.8.4"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.4.1.cmml" xref="S4.T6.28.14.1.m1.8.8.4">subscript</csymbol><ci id="S4.T6.28.14.1.m1.8.8.4.2.cmml" xref="S4.T6.28.14.1.m1.8.8.4.2">𝐴</ci><apply id="S4.T6.28.14.1.m1.8.8.4.3.cmml" xref="S4.T6.28.14.1.m1.8.8.4.3"><times id="S4.T6.28.14.1.m1.8.8.4.3.1.cmml" xref="S4.T6.28.14.1.m1.8.8.4.3.1"></times><ci id="S4.T6.28.14.1.m1.8.8.4.3.2.cmml" xref="S4.T6.28.14.1.m1.8.8.4.3.2">𝑖</ci><ci id="S4.T6.28.14.1.m1.8.8.4.3.3.cmml" xref="S4.T6.28.14.1.m1.8.8.4.3.3">𝑗</ci></apply></apply><apply id="S4.T6.28.14.1.m1.8.8.6.cmml" xref="S4.T6.28.14.1.m1.8.8.6"><times id="S4.T6.28.14.1.m1.8.8.6.1.cmml" xref="S4.T6.28.14.1.m1.8.8.6.1"></times><apply id="S4.T6.28.14.1.m1.8.8.6.2.cmml" xref="S4.T6.28.14.1.m1.8.8.6.2"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.6.2.1.cmml" xref="S4.T6.28.14.1.m1.8.8.6.2">subscript</csymbol><ci id="S4.T6.28.14.1.m1.8.8.6.2.2.cmml" xref="S4.T6.28.14.1.m1.8.8.6.2.2">𝐖</ci><ci id="S4.T6.28.14.1.m1.8.8.6.2.3.cmml" xref="S4.T6.28.14.1.m1.8.8.6.2.3">𝑞</ci></apply><apply id="S4.T6.28.14.1.m1.8.8.6.3.cmml" xref="S4.T6.28.14.1.m1.8.8.6.3"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.6.3.1.cmml" xref="S4.T6.28.14.1.m1.8.8.6.3">subscript</csymbol><ci id="S4.T6.28.14.1.m1.8.8.6.3.2.cmml" xref="S4.T6.28.14.1.m1.8.8.6.3.2">𝐱</ci><ci id="S4.T6.28.14.1.m1.8.8.6.3.3.cmml" xref="S4.T6.28.14.1.m1.8.8.6.3.3">𝑖</ci></apply><apply id="S4.T6.28.14.1.m1.8.8.6.4.cmml" xref="S4.T6.28.14.1.m1.8.8.6.4"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.6.4.1.cmml" xref="S4.T6.28.14.1.m1.8.8.6.4">subscript</csymbol><ci id="S4.T6.28.14.1.m1.8.8.6.4.2.cmml" xref="S4.T6.28.14.1.m1.8.8.6.4.2">𝐑</ci><list id="S4.T6.28.14.1.m1.2.2.2.3.cmml" xref="S4.T6.28.14.1.m1.2.2.2.2"><ci id="S4.T6.28.14.1.m1.1.1.1.1.cmml" xref="S4.T6.28.14.1.m1.1.1.1.1">Θ</ci><apply id="S4.T6.28.14.1.m1.2.2.2.2.1.cmml" xref="S4.T6.28.14.1.m1.2.2.2.2.1"><minus id="S4.T6.28.14.1.m1.2.2.2.2.1.1.cmml" xref="S4.T6.28.14.1.m1.2.2.2.2.1.1"></minus><ci id="S4.T6.28.14.1.m1.2.2.2.2.1.2.cmml" xref="S4.T6.28.14.1.m1.2.2.2.2.1.2">𝑖</ci><ci id="S4.T6.28.14.1.m1.2.2.2.2.1.3.cmml" xref="S4.T6.28.14.1.m1.2.2.2.2.1.3">𝑗</ci></apply></list></apply><apply id="S4.T6.28.14.1.m1.8.8.6.5.cmml" xref="S4.T6.28.14.1.m1.8.8.6.5"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.6.5.1.cmml" xref="S4.T6.28.14.1.m1.8.8.6.5">superscript</csymbol><apply id="S4.T6.28.14.1.m1.8.8.6.5.2.cmml" xref="S4.T6.28.14.1.m1.8.8.6.5"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.6.5.2.1.cmml" xref="S4.T6.28.14.1.m1.8.8.6.5">subscript</csymbol><ci id="S4.T6.28.14.1.m1.8.8.6.5.2.2.cmml" xref="S4.T6.28.14.1.m1.8.8.6.5.2.2">𝐱</ci><ci id="S4.T6.28.14.1.m1.8.8.6.5.2.3.cmml" xref="S4.T6.28.14.1.m1.8.8.6.5.2.3">𝑗</ci></apply><ci id="S4.T6.28.14.1.m1.8.8.6.5.3.cmml" xref="S4.T6.28.14.1.m1.8.8.6.5.3">𝑇</ci></apply><apply id="S4.T6.28.14.1.m1.8.8.6.6.cmml" xref="S4.T6.28.14.1.m1.8.8.6.6"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.6.6.1.cmml" xref="S4.T6.28.14.1.m1.8.8.6.6">superscript</csymbol><apply id="S4.T6.28.14.1.m1.8.8.6.6.2.cmml" xref="S4.T6.28.14.1.m1.8.8.6.6"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.6.6.2.1.cmml" xref="S4.T6.28.14.1.m1.8.8.6.6">subscript</csymbol><ci id="S4.T6.28.14.1.m1.8.8.6.6.2.2.cmml" xref="S4.T6.28.14.1.m1.8.8.6.6.2.2">𝐖</ci><ci id="S4.T6.28.14.1.m1.8.8.6.6.2.3.cmml" xref="S4.T6.28.14.1.m1.8.8.6.6.2.3">𝑘</ci></apply><ci id="S4.T6.28.14.1.m1.8.8.6.6.3.cmml" xref="S4.T6.28.14.1.m1.8.8.6.6.3">𝑇</ci></apply></apply></apply><apply id="S4.T6.28.14.1.m1.8.8c.cmml" xref="S4.T6.28.14.1.m1.8.8"><eq id="S4.T6.28.14.1.m1.8.8.7.cmml" xref="S4.T6.28.14.1.m1.8.8.7"></eq><share href="#S4.T6.28.14.1.m1.8.8.6.cmml" id="S4.T6.28.14.1.m1.8.8d.cmml" xref="S4.T6.28.14.1.m1.8.8"></share><apply id="S4.T6.28.14.1.m1.8.8.2.cmml" xref="S4.T6.28.14.1.m1.8.8.2"><times id="S4.T6.28.14.1.m1.8.8.2.3.cmml" xref="S4.T6.28.14.1.m1.8.8.2.3"></times><apply id="S4.T6.28.14.1.m1.7.7.1.1.1.1.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1"><times id="S4.T6.28.14.1.m1.7.7.1.1.1.1.1.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.1"></times><apply id="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.1.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.2">subscript</csymbol><ci id="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.2.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.2">𝐖</ci><ci id="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.3.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.2.3">𝑞</ci></apply><apply id="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.1.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.3">subscript</csymbol><ci id="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.2.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.2">𝐱</ci><ci id="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.3.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.3.3">𝑖</ci></apply><apply id="S4.T6.28.14.1.m1.7.7.1.1.1.1.4.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.4"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.7.7.1.1.1.1.4.1.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.4">subscript</csymbol><ci id="S4.T6.28.14.1.m1.7.7.1.1.1.1.4.2.cmml" xref="S4.T6.28.14.1.m1.7.7.1.1.1.1.4.2">𝐑</ci><list id="S4.T6.28.14.1.m1.4.4.2.3.cmml" xref="S4.T6.28.14.1.m1.4.4.2.4"><ci id="S4.T6.28.14.1.m1.3.3.1.1.cmml" xref="S4.T6.28.14.1.m1.3.3.1.1">Θ</ci><ci id="S4.T6.28.14.1.m1.4.4.2.2.cmml" xref="S4.T6.28.14.1.m1.4.4.2.2">𝑖</ci></list></apply></apply><apply id="S4.T6.28.14.1.m1.8.8.2.2.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.2.2.2.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2">superscript</csymbol><apply id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1"><times id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.1.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.1"></times><apply id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.1.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2">subscript</csymbol><ci id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.2.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.2">𝐖</ci><ci id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.3.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.2.3">𝑘</ci></apply><apply id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.1.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3">subscript</csymbol><ci id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.2.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.2">𝐱</ci><ci id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.3.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.3.3">𝑗</ci></apply><apply id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4"><csymbol cd="ambiguous" id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4.1.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4">subscript</csymbol><ci id="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4.2.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.1.1.1.4.2">𝑅</ci><list id="S4.T6.28.14.1.m1.6.6.2.3.cmml" xref="S4.T6.28.14.1.m1.6.6.2.4"><ci id="S4.T6.28.14.1.m1.5.5.1.1.cmml" xref="S4.T6.28.14.1.m1.5.5.1.1">Θ</ci><ci id="S4.T6.28.14.1.m1.6.6.2.2.cmml" xref="S4.T6.28.14.1.m1.6.6.2.2">𝑗</ci></list></apply></apply><ci id="S4.T6.28.14.1.m1.8.8.2.2.3.cmml" xref="S4.T6.28.14.1.m1.8.8.2.2.3">𝑇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.28.14.1.m1.8c">A_{ij}=\mathbf{W}_{q}\mathbf{x}_{i}\mathbf{R}_{\Theta,i-j}\mathbf{x}_{j}^{T}\mathbf{W}_{k}^{T}=(\mathbf{W}_{q}\mathbf{x}_{i}\mathbf{R}_{\Theta,i})(\mathbf{W}_{k}\mathbf{x}_{j}R_{\Theta,j})^{T}</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.29.15" class="ltx_tr">
<td id="S4.T6.29.15.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">ALiBi&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib264" title="" class="ltx_ref">264</a>]</cite>
</td>
<td id="S4.T6.29.15.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T6.29.15.1.m1.1" class="ltx_Math" alttext="A_{ij}=\mathbf{W}_{q}\mathbf{x}_{i}\mathbf{x}_{j}^{T}\mathbf{W}_{k}^{T}-m(i-j)" display="inline"><semantics id="S4.T6.29.15.1.m1.1a"><mrow id="S4.T6.29.15.1.m1.1.1" xref="S4.T6.29.15.1.m1.1.1.cmml"><msub id="S4.T6.29.15.1.m1.1.1.3" xref="S4.T6.29.15.1.m1.1.1.3.cmml"><mi id="S4.T6.29.15.1.m1.1.1.3.2" xref="S4.T6.29.15.1.m1.1.1.3.2.cmml">A</mi><mrow id="S4.T6.29.15.1.m1.1.1.3.3" xref="S4.T6.29.15.1.m1.1.1.3.3.cmml"><mi id="S4.T6.29.15.1.m1.1.1.3.3.2" xref="S4.T6.29.15.1.m1.1.1.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.T6.29.15.1.m1.1.1.3.3.1" xref="S4.T6.29.15.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S4.T6.29.15.1.m1.1.1.3.3.3" xref="S4.T6.29.15.1.m1.1.1.3.3.3.cmml">j</mi></mrow></msub><mo id="S4.T6.29.15.1.m1.1.1.2" xref="S4.T6.29.15.1.m1.1.1.2.cmml">=</mo><mrow id="S4.T6.29.15.1.m1.1.1.1" xref="S4.T6.29.15.1.m1.1.1.1.cmml"><mrow id="S4.T6.29.15.1.m1.1.1.1.3" xref="S4.T6.29.15.1.m1.1.1.1.3.cmml"><msub id="S4.T6.29.15.1.m1.1.1.1.3.2" xref="S4.T6.29.15.1.m1.1.1.1.3.2.cmml"><mi id="S4.T6.29.15.1.m1.1.1.1.3.2.2" xref="S4.T6.29.15.1.m1.1.1.1.3.2.2.cmml">𝐖</mi><mi id="S4.T6.29.15.1.m1.1.1.1.3.2.3" xref="S4.T6.29.15.1.m1.1.1.1.3.2.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.29.15.1.m1.1.1.1.3.1" xref="S4.T6.29.15.1.m1.1.1.1.3.1.cmml">​</mo><msub id="S4.T6.29.15.1.m1.1.1.1.3.3" xref="S4.T6.29.15.1.m1.1.1.1.3.3.cmml"><mi id="S4.T6.29.15.1.m1.1.1.1.3.3.2" xref="S4.T6.29.15.1.m1.1.1.1.3.3.2.cmml">𝐱</mi><mi id="S4.T6.29.15.1.m1.1.1.1.3.3.3" xref="S4.T6.29.15.1.m1.1.1.1.3.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.T6.29.15.1.m1.1.1.1.3.1a" xref="S4.T6.29.15.1.m1.1.1.1.3.1.cmml">​</mo><msubsup id="S4.T6.29.15.1.m1.1.1.1.3.4" xref="S4.T6.29.15.1.m1.1.1.1.3.4.cmml"><mi id="S4.T6.29.15.1.m1.1.1.1.3.4.2.2" xref="S4.T6.29.15.1.m1.1.1.1.3.4.2.2.cmml">𝐱</mi><mi id="S4.T6.29.15.1.m1.1.1.1.3.4.2.3" xref="S4.T6.29.15.1.m1.1.1.1.3.4.2.3.cmml">j</mi><mi id="S4.T6.29.15.1.m1.1.1.1.3.4.3" xref="S4.T6.29.15.1.m1.1.1.1.3.4.3.cmml">T</mi></msubsup><mo lspace="0em" rspace="0em" id="S4.T6.29.15.1.m1.1.1.1.3.1b" xref="S4.T6.29.15.1.m1.1.1.1.3.1.cmml">​</mo><msubsup id="S4.T6.29.15.1.m1.1.1.1.3.5" xref="S4.T6.29.15.1.m1.1.1.1.3.5.cmml"><mi id="S4.T6.29.15.1.m1.1.1.1.3.5.2.2" xref="S4.T6.29.15.1.m1.1.1.1.3.5.2.2.cmml">𝐖</mi><mi id="S4.T6.29.15.1.m1.1.1.1.3.5.2.3" xref="S4.T6.29.15.1.m1.1.1.1.3.5.2.3.cmml">k</mi><mi id="S4.T6.29.15.1.m1.1.1.1.3.5.3" xref="S4.T6.29.15.1.m1.1.1.1.3.5.3.cmml">T</mi></msubsup></mrow><mo id="S4.T6.29.15.1.m1.1.1.1.2" xref="S4.T6.29.15.1.m1.1.1.1.2.cmml">−</mo><mrow id="S4.T6.29.15.1.m1.1.1.1.1" xref="S4.T6.29.15.1.m1.1.1.1.1.cmml"><mi id="S4.T6.29.15.1.m1.1.1.1.1.3" xref="S4.T6.29.15.1.m1.1.1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.T6.29.15.1.m1.1.1.1.1.2" xref="S4.T6.29.15.1.m1.1.1.1.1.2.cmml">​</mo><mrow id="S4.T6.29.15.1.m1.1.1.1.1.1.1" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.T6.29.15.1.m1.1.1.1.1.1.1.2" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.T6.29.15.1.m1.1.1.1.1.1.1.1" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.2" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.2.cmml">i</mi><mo id="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.1" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.3" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.3.cmml">j</mi></mrow><mo stretchy="false" id="S4.T6.29.15.1.m1.1.1.1.1.1.1.3" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.29.15.1.m1.1b"><apply id="S4.T6.29.15.1.m1.1.1.cmml" xref="S4.T6.29.15.1.m1.1.1"><eq id="S4.T6.29.15.1.m1.1.1.2.cmml" xref="S4.T6.29.15.1.m1.1.1.2"></eq><apply id="S4.T6.29.15.1.m1.1.1.3.cmml" xref="S4.T6.29.15.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T6.29.15.1.m1.1.1.3.1.cmml" xref="S4.T6.29.15.1.m1.1.1.3">subscript</csymbol><ci id="S4.T6.29.15.1.m1.1.1.3.2.cmml" xref="S4.T6.29.15.1.m1.1.1.3.2">𝐴</ci><apply id="S4.T6.29.15.1.m1.1.1.3.3.cmml" xref="S4.T6.29.15.1.m1.1.1.3.3"><times id="S4.T6.29.15.1.m1.1.1.3.3.1.cmml" xref="S4.T6.29.15.1.m1.1.1.3.3.1"></times><ci id="S4.T6.29.15.1.m1.1.1.3.3.2.cmml" xref="S4.T6.29.15.1.m1.1.1.3.3.2">𝑖</ci><ci id="S4.T6.29.15.1.m1.1.1.3.3.3.cmml" xref="S4.T6.29.15.1.m1.1.1.3.3.3">𝑗</ci></apply></apply><apply id="S4.T6.29.15.1.m1.1.1.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1"><minus id="S4.T6.29.15.1.m1.1.1.1.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.2"></minus><apply id="S4.T6.29.15.1.m1.1.1.1.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3"><times id="S4.T6.29.15.1.m1.1.1.1.3.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.1"></times><apply id="S4.T6.29.15.1.m1.1.1.1.3.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.T6.29.15.1.m1.1.1.1.3.2.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.2">subscript</csymbol><ci id="S4.T6.29.15.1.m1.1.1.1.3.2.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.2.2">𝐖</ci><ci id="S4.T6.29.15.1.m1.1.1.1.3.2.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.2.3">𝑞</ci></apply><apply id="S4.T6.29.15.1.m1.1.1.1.3.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.T6.29.15.1.m1.1.1.1.3.3.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.3">subscript</csymbol><ci id="S4.T6.29.15.1.m1.1.1.1.3.3.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.3.2">𝐱</ci><ci id="S4.T6.29.15.1.m1.1.1.1.3.3.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.3.3">𝑖</ci></apply><apply id="S4.T6.29.15.1.m1.1.1.1.3.4.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.4"><csymbol cd="ambiguous" id="S4.T6.29.15.1.m1.1.1.1.3.4.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.4">superscript</csymbol><apply id="S4.T6.29.15.1.m1.1.1.1.3.4.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.4"><csymbol cd="ambiguous" id="S4.T6.29.15.1.m1.1.1.1.3.4.2.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.4">subscript</csymbol><ci id="S4.T6.29.15.1.m1.1.1.1.3.4.2.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.4.2.2">𝐱</ci><ci id="S4.T6.29.15.1.m1.1.1.1.3.4.2.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.4.2.3">𝑗</ci></apply><ci id="S4.T6.29.15.1.m1.1.1.1.3.4.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.4.3">𝑇</ci></apply><apply id="S4.T6.29.15.1.m1.1.1.1.3.5.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.5"><csymbol cd="ambiguous" id="S4.T6.29.15.1.m1.1.1.1.3.5.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.5">superscript</csymbol><apply id="S4.T6.29.15.1.m1.1.1.1.3.5.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.5"><csymbol cd="ambiguous" id="S4.T6.29.15.1.m1.1.1.1.3.5.2.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.5">subscript</csymbol><ci id="S4.T6.29.15.1.m1.1.1.1.3.5.2.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.5.2.2">𝐖</ci><ci id="S4.T6.29.15.1.m1.1.1.1.3.5.2.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.5.2.3">𝑘</ci></apply><ci id="S4.T6.29.15.1.m1.1.1.1.3.5.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.3.5.3">𝑇</ci></apply></apply><apply id="S4.T6.29.15.1.m1.1.1.1.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.1"><times id="S4.T6.29.15.1.m1.1.1.1.1.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.1.2"></times><ci id="S4.T6.29.15.1.m1.1.1.1.1.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.1.3">𝑚</ci><apply id="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1"><minus id="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.1"></minus><ci id="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.2">𝑖</ci><ci id="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.T6.29.15.1.m1.1.1.1.1.1.1.1.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.29.15.1.m1.1c">A_{ij}=\mathbf{W}_{q}\mathbf{x}_{i}\mathbf{x}_{j}^{T}\mathbf{W}_{k}^{T}-m(i-j)</annotation></semantics></math></td>
</tr>
</tbody></table>
</figure>
<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">트랜스포머<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>의 출시 이후, 훈련 안정성, 성능 및 계산 효율성을 높이기 위한 다양한 개선 사항이 제안되었다. 이 부분에서는 정규화, 위치 임베딩, 활성화 함수, 주의 및 편향 등 트랜스포머의 4가지 주요 부분에 대한 해당 구성에 대해 논의할 것이다. 이 조사를 보다 독립적으로 만들기 위해 표 <a class="ltx_ref" href="#S4.T6" title="TABLE VI ‣ 4.2.2 Detailed Configuration ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">VI</span></a>에서 이러한 구성에 대한 자세한 공식을 제시한다.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p2.1.1">Normalization Methods. </span> 훈련 불안정성은 사전 훈련 LLM에 대한 어려운 문제이다. 이 문제를 완화하기 위해 정규화는 신경망의 학습을 안정화하기 위해 널리 채택되는 전략이다. 바닐라 트랜스포머<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>에서는 LayerNorm<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib256" title="">256</a>]</cite>가 채용된다. 최근에는 LayerNorm, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p2.1.2">e.g.,</em> RMSNorm 및 DeepNorm에 대한 대안으로 몇 가지 고급 정규화 기술이 제안되었다.</p>
</div>
<div id="S4.SS2.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.1.m1.1"><semantics id="S4.SS2.SSS2.p3.1.m1.1a"><mo id="S4.SS2.SSS2.p3.1.m1.1.1" xref="S4.SS2.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.1.m1.1b"><ci id="S4.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p3.1.1">LayerNorm. </em> 초기 연구에서 BatchNorm<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib265" title="">265</a>]</cite>는 일반적으로 사용되는 정규화 방법이다. 그러나 가변 길이의 시퀀스 데이터와 소규모 배치 데이터는 다루기가 어렵다. 따라서, LayerNorm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib256" title="">256</a>]</cite>가 도입되어 레이어별 정규화가 수행된다. 구체적으로, 층당 모든 활성화들에 대한 평균 및 분산은 활성화들의 중심을 재조정하고 재스케일링하기 위해 계산된다.</p>
</div>
<div id="S4.SS2.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.1.m1.1"><semantics id="S4.SS2.SSS2.p4.1.m1.1a"><mo id="S4.SS2.SSS2.p4.1.m1.1.1" xref="S4.SS2.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.1.m1.1b"><ci id="S4.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p4.1.1">RMSNorm. </em> LayerNorm(LN)의 학습 속도를 향상시키기 위해 RMSNorm<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib257" title="">257</a>]</cite>는 평균과 분산 대신 합산된 활성화의 RMS(root mean square)만으로 활성화를 재스케일링하여 제안한다. 관련 연구에서는 Transformer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib266" title="">266</a>]</cite>에 대한 학습 속도와 성능에서 우수성을 입증하였다. RMSNorm을 채택한 대표적인 모델로는 Gopher <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>와 Chinchilla <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>가 있다.</p>
</div>
<div id="S4.SS2.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.1.m1.1"><semantics id="S4.SS2.SSS2.p5.1.m1.1a"><mo id="S4.SS2.SSS2.p5.1.m1.1.1" xref="S4.SS2.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.1.m1.1b"><ci id="S4.SS2.SSS2.p5.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p5.1.1">DeepNorm. </em>DeepNorm is proposed by Microsoft <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib258" title="">258</a>]</cite> to stabilize the training of deep Transformers. DeepNorm을 잔차 연결로 사용하면 트랜스포머는 최대 1,000층까지 확장될 수 있습니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib258" title="">258</a>]</cite>는 안정성과 좋은 성능의 장점을 보여 줍니다. GLM-130B<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>에 의해 채택되었다.</p>
</div>
<div id="S4.SS2.SSS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS2.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p6.1.1">Normalization Position. </span> 정규화 방법 외에도 정규화 위치도 LLMs에서 중요한 역할을 한다. 정규화 위치에는 일반적으로 <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p6.1.2">i.e.,</em> post-LN, pre-LN 및 sandwich-LN의 세 가지 선택이 있다.</p>
</div>
<div id="S4.SS2.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p7.1.m1.1"><semantics id="S4.SS2.SSS2.p7.1.m1.1a"><mo id="S4.SS2.SSS2.p7.1.m1.1.1" xref="S4.SS2.SSS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p7.1.m1.1b"><ci id="S4.SS2.SSS2.p7.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p7.1.1">Post-LN. </em>Post-LN은 잔차 블록 사이에 배치되는 바닐라 트랜스포머 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>에서 사용된다. 그러나 기존 연구에서는 출력층 근처의 큰 기울기로 인해 post-LN을 갖는 트랜스포머의 트레이닝이 불안정한 경향이 있음을 발견했다. 따라서, 포스트-LN은 다른 전략들과 결합된 것을 제외하고는 기존의 LLM들에서 거의 채용되지 않는다(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p7.1.2">e.g.,</em> combining post-LN with pre-LN in GLM-130B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>).</p>
</div>
<div id="S4.SS2.SSS2.p8" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p8.1.m1.1"><semantics id="S4.SS2.SSS2.p8.1.m1.1a"><mo id="S4.SS2.SSS2.p8.1.m1.1.1" xref="S4.SS2.SSS2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p8.1.m1.1b"><ci id="S4.SS2.SSS2.p8.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p8.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p8.1.1">Pre-LN. </em> post-LN과 다르게 pre-LN<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib268" title="">268</a>]</cite>가 각 하위 계층 앞에 적용되고 최종 예측 전에 추가 LN이 배치된다. Post-LN과 비교하여, Pre-LN을 갖는 트랜스포머는 훈련에서 더 안정적이다. 그러나 post-LN<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib269" title="">269</a>]</cite>를 갖는 변이체보다 더 나쁜 성능을 보인다. 성능 감소에도 불구하고 대부분의 LLM은 훈련 안정성 때문에 여전히 사전 LN을 채택한다. 그러나 한 가지 예외는 훈련 모델이 100B 이상의 매개변수 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>일 때 GLM에서 pre-LN이 불안정하게 발견되었다는 것이다.</p>
</div>
<div id="S4.SS2.SSS2.p9" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p9.1.m1.1"><semantics id="S4.SS2.SSS2.p9.1.m1.1a"><mo id="S4.SS2.SSS2.p9.1.m1.1.1" xref="S4.SS2.SSS2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p9.1.m1.1b"><ci id="S4.SS2.SSS2.p9.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p9.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p9.1.1">Sandwich-LN. </em> Pre-LN을 기반으로 Sandwich-LN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib255" title="">255</a>]</cite>는 Transformer 레이어 출력에서 값 폭발 문제를 피하기 위해 잔여 연결 전에 추가 LN을 추가합니다. 그러나 Sandwich-LN은 때때로 LLM의 훈련을 안정화시키지 못하고 훈련<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>의 붕괴로 이어질 수 있다는 것이 밝혀졌다.</p>
</div>
<div id="S4.SS2.SSS2.p10" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS2.p10.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p10.1.1">Activation Functions. </span> 좋은 성능을 얻으려면 활성화 함수도 피드포워드 네트워크에서 적절하게 설정되어야 합니다. 기존의 LLMs에서는 GeLU activations<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib270" title="">270</a>]</cite>가 널리 사용되고 있다. 특히, 최신 LLMs(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p10.1.2">e.g.,</em> PaLM and LaMDA), GLU 활성화의 변형들 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib271" title="">271</a>, <a class="ltx_ref" href="#bib.bib262" title="">262</a>]</cite>도 활용되었으며, 특히 SwiGLU 및 GeGLU 변형들은 종종 [cite idx=2></cite>]에서 더 나은 성능을 달성한다. 그러나 GeLU와 비교하여 피드포워드 네트워크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib272" title="">272</a>]</cite>에서는 추가 파라미터(약 50%)가 필요하다.</p>
</div>
<div id="S4.SS2.SSS2.p11" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS2.p11.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p11.1.1">Position Embeddings. </span> Transformer에서 self-attention module은 permutation equivariant이기 때문에 모델링 시퀀스를 위한 절대 또는 상대 위치 정보를 주입하기 위해 위치 임베딩(PE)을 사용한다.</p>
</div>
<div id="S4.SS2.SSS2.p12" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p12.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p12.1.m1.1"><semantics id="S4.SS2.SSS2.p12.1.m1.1a"><mo id="S4.SS2.SSS2.p12.1.m1.1.1" xref="S4.SS2.SSS2.p12.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p12.1.m1.1b"><ci id="S4.SS2.SSS2.p12.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p12.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p12.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p12.1.1">Absolute position embedding. </em> 바닐라 트랜스포머<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>에서는 절대 위치 임베딩을 채용한다. 인코더 및 디코더의 바닥에서, 절대 위치 임베딩들은 입력 임베딩들에 추가된다. 바닐라 트랜스포머 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p12.1.2">i.e.,</em> 정현파 및 학습된 위치 임베딩에 제안된 절대 위치 임베딩의 두 가지 변형이 있으며, 후자는 기존의 사전 학습된 언어 모델에서 일반적으로 사용된다.</p>
</div>
<div id="S4.SS2.SSS2.p13" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p13.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p13.1.m1.1"><semantics id="S4.SS2.SSS2.p13.1.m1.1a"><mo id="S4.SS2.SSS2.p13.1.m1.1.1" xref="S4.SS2.SSS2.p13.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p13.1.m1.1b"><ci id="S4.SS2.SSS2.p13.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p13.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p13.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p13.1.1">Relative position embedding. </em> 절대 위치 임베딩과 달리 키와 쿼리 사이의 오프셋에 따라 상대적 위치 임베딩이 생성됩니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib273" title="">273</a>]</cite> Relative PE의 인기 있는 변형은 Transformer-XL<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib274" title="">274</a>, <a class="ltx_ref" href="#bib.bib275" title="">275</a>]</cite>에 도입되었다. 키들과 쿼리들 사이의 어텐션 스코어들의 계산은 상대 위치들에 대응하는 학습가능한 임베딩들을 도입하도록 수정되었다. T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>는 더 단순화된 상대적 위치 임베딩으로, 이후 Gopher <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>에 의해 채택되었다. 구체적으로, 주의 점수에 학습 가능한 스칼라들을 추가하는데, 여기서 스칼라들은 질의의 위치들과 키 사이의 거리들에 기초하여 계산된다. 절대 PE와 비교하여 상대적 위치 임베딩을 갖는 트랜스포머는 트레이닝을 위한 시퀀스보다 긴 시퀀스, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p13.1.2">i.e.,</em> extrapolation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib264" title="">264</a>]</cite>로 일반화할 수 있다.</p>
</div>
<div id="S4.SS2.SSS2.p14" class="ltx_para">
<p id="S4.SS2.SSS2.p14.10" class="ltx_p"><math id="S4.SS2.SSS2.p14.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S4.SS2.SSS2.p14.1.m1.1a"><mo id="S4.SS2.SSS2.p14.1.m1.1.1" xref="S4.SS2.SSS2.p14.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.1.m1.1b"><ci id="S4.SS2.SSS2.p14.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p14.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.1.m1.1c">\bullet</annotation></semantics></math> <em id="S4.SS2.SSS2.p14.10.1" class="ltx_emph ltx_font_italic">Rotary Position Embedding.</em> Rotary position embedding (RoPE)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib263" title="" class="ltx_ref">263</a>]</cite> sets specific rotatory matrices based on the absolute position of each key or query. The scores between keys and queries can be computed with relative position information (Table&nbsp;<a href="#S4.T6" title="TABLE VI ‣ 4.2.2 Detailed Configuration ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>). RoPE combines each consecutive pair of elements in query and key vectors as <em id="S4.SS2.SSS2.p14.10.2" class="ltx_emph ltx_font_italic">a dimension</em>, so there are <math id="S4.SS2.SSS2.p14.2.m2.1" class="ltx_Math" alttext="d/2" display="inline"><semantics id="S4.SS2.SSS2.p14.2.m2.1a"><mrow id="S4.SS2.SSS2.p14.2.m2.1.1" xref="S4.SS2.SSS2.p14.2.m2.1.1.cmml"><mi id="S4.SS2.SSS2.p14.2.m2.1.1.2" xref="S4.SS2.SSS2.p14.2.m2.1.1.2.cmml">d</mi><mo id="S4.SS2.SSS2.p14.2.m2.1.1.1" xref="S4.SS2.SSS2.p14.2.m2.1.1.1.cmml">/</mo><mn id="S4.SS2.SSS2.p14.2.m2.1.1.3" xref="S4.SS2.SSS2.p14.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.2.m2.1b"><apply id="S4.SS2.SSS2.p14.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p14.2.m2.1.1"><divide id="S4.SS2.SSS2.p14.2.m2.1.1.1.cmml" xref="S4.SS2.SSS2.p14.2.m2.1.1.1"></divide><ci id="S4.SS2.SSS2.p14.2.m2.1.1.2.cmml" xref="S4.SS2.SSS2.p14.2.m2.1.1.2">𝑑</ci><cn type="integer" id="S4.SS2.SSS2.p14.2.m2.1.1.3.cmml" xref="S4.SS2.SSS2.p14.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.2.m2.1c">d/2</annotation></semantics></math> dimensions for an original <math id="S4.SS2.SSS2.p14.3.m3.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S4.SS2.SSS2.p14.3.m3.1a"><mi id="S4.SS2.SSS2.p14.3.m3.1.1" xref="S4.SS2.SSS2.p14.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.3.m3.1b"><ci id="S4.SS2.SSS2.p14.3.m3.1.1.cmml" xref="S4.SS2.SSS2.p14.3.m3.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.3.m3.1c">d</annotation></semantics></math>-length embedding. For each dimension <math id="S4.SS2.SSS2.p14.4.m4.3" class="ltx_Math" alttext="i\in\{1,\dots,d/2\}" display="inline"><semantics id="S4.SS2.SSS2.p14.4.m4.3a"><mrow id="S4.SS2.SSS2.p14.4.m4.3.3" xref="S4.SS2.SSS2.p14.4.m4.3.3.cmml"><mi id="S4.SS2.SSS2.p14.4.m4.3.3.3" xref="S4.SS2.SSS2.p14.4.m4.3.3.3.cmml">i</mi><mo id="S4.SS2.SSS2.p14.4.m4.3.3.2" xref="S4.SS2.SSS2.p14.4.m4.3.3.2.cmml">∈</mo><mrow id="S4.SS2.SSS2.p14.4.m4.3.3.1.1" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.2.cmml"><mo stretchy="false" id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.2" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.2.cmml">{</mo><mn id="S4.SS2.SSS2.p14.4.m4.1.1" xref="S4.SS2.SSS2.p14.4.m4.1.1.cmml">1</mn><mo id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.3" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.2.cmml">,</mo><mi mathvariant="normal" id="S4.SS2.SSS2.p14.4.m4.2.2" xref="S4.SS2.SSS2.p14.4.m4.2.2.cmml">…</mi><mo id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.4" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.2.cmml">,</mo><mrow id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.cmml"><mi id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.2" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.2.cmml">d</mi><mo id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.1" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.1.cmml">/</mo><mn id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.3" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.3.cmml">2</mn></mrow><mo stretchy="false" id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.5" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.4.m4.3b"><apply id="S4.SS2.SSS2.p14.4.m4.3.3.cmml" xref="S4.SS2.SSS2.p14.4.m4.3.3"><in id="S4.SS2.SSS2.p14.4.m4.3.3.2.cmml" xref="S4.SS2.SSS2.p14.4.m4.3.3.2"></in><ci id="S4.SS2.SSS2.p14.4.m4.3.3.3.cmml" xref="S4.SS2.SSS2.p14.4.m4.3.3.3">𝑖</ci><set id="S4.SS2.SSS2.p14.4.m4.3.3.1.2.cmml" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.1"><cn type="integer" id="S4.SS2.SSS2.p14.4.m4.1.1.cmml" xref="S4.SS2.SSS2.p14.4.m4.1.1">1</cn><ci id="S4.SS2.SSS2.p14.4.m4.2.2.cmml" xref="S4.SS2.SSS2.p14.4.m4.2.2">…</ci><apply id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.cmml" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1"><divide id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.1.cmml" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.1"></divide><ci id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.2.cmml" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.2">𝑑</ci><cn type="integer" id="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.3.cmml" xref="S4.SS2.SSS2.p14.4.m4.3.3.1.1.1.3">2</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.4.m4.3c">i\in\{1,\dots,d/2\}</annotation></semantics></math>, the pair of involved elements will rotate based on the rotation angle <math id="S4.SS2.SSS2.p14.5.m5.1" class="ltx_Math" alttext="t\cdot\theta_{i}" display="inline"><semantics id="S4.SS2.SSS2.p14.5.m5.1a"><mrow id="S4.SS2.SSS2.p14.5.m5.1.1" xref="S4.SS2.SSS2.p14.5.m5.1.1.cmml"><mi id="S4.SS2.SSS2.p14.5.m5.1.1.2" xref="S4.SS2.SSS2.p14.5.m5.1.1.2.cmml">t</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.SSS2.p14.5.m5.1.1.1" xref="S4.SS2.SSS2.p14.5.m5.1.1.1.cmml">⋅</mo><msub id="S4.SS2.SSS2.p14.5.m5.1.1.3" xref="S4.SS2.SSS2.p14.5.m5.1.1.3.cmml"><mi id="S4.SS2.SSS2.p14.5.m5.1.1.3.2" xref="S4.SS2.SSS2.p14.5.m5.1.1.3.2.cmml">θ</mi><mi id="S4.SS2.SSS2.p14.5.m5.1.1.3.3" xref="S4.SS2.SSS2.p14.5.m5.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.5.m5.1b"><apply id="S4.SS2.SSS2.p14.5.m5.1.1.cmml" xref="S4.SS2.SSS2.p14.5.m5.1.1"><ci id="S4.SS2.SSS2.p14.5.m5.1.1.1.cmml" xref="S4.SS2.SSS2.p14.5.m5.1.1.1">⋅</ci><ci id="S4.SS2.SSS2.p14.5.m5.1.1.2.cmml" xref="S4.SS2.SSS2.p14.5.m5.1.1.2">𝑡</ci><apply id="S4.SS2.SSS2.p14.5.m5.1.1.3.cmml" xref="S4.SS2.SSS2.p14.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p14.5.m5.1.1.3.1.cmml" xref="S4.SS2.SSS2.p14.5.m5.1.1.3">subscript</csymbol><ci id="S4.SS2.SSS2.p14.5.m5.1.1.3.2.cmml" xref="S4.SS2.SSS2.p14.5.m5.1.1.3.2">𝜃</ci><ci id="S4.SS2.SSS2.p14.5.m5.1.1.3.3.cmml" xref="S4.SS2.SSS2.p14.5.m5.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.5.m5.1c">t\cdot\theta_{i}</annotation></semantics></math>, where <math id="S4.SS2.SSS2.p14.6.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.SSS2.p14.6.m6.1a"><mi id="S4.SS2.SSS2.p14.6.m6.1.1" xref="S4.SS2.SSS2.p14.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.6.m6.1b"><ci id="S4.SS2.SSS2.p14.6.m6.1.1.cmml" xref="S4.SS2.SSS2.p14.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.6.m6.1c">t</annotation></semantics></math> denotes the position index and <math id="S4.SS2.SSS2.p14.7.m7.1" class="ltx_Math" alttext="\theta_{i}" display="inline"><semantics id="S4.SS2.SSS2.p14.7.m7.1a"><msub id="S4.SS2.SSS2.p14.7.m7.1.1" xref="S4.SS2.SSS2.p14.7.m7.1.1.cmml"><mi id="S4.SS2.SSS2.p14.7.m7.1.1.2" xref="S4.SS2.SSS2.p14.7.m7.1.1.2.cmml">θ</mi><mi id="S4.SS2.SSS2.p14.7.m7.1.1.3" xref="S4.SS2.SSS2.p14.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.7.m7.1b"><apply id="S4.SS2.SSS2.p14.7.m7.1.1.cmml" xref="S4.SS2.SSS2.p14.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p14.7.m7.1.1.1.cmml" xref="S4.SS2.SSS2.p14.7.m7.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p14.7.m7.1.1.2.cmml" xref="S4.SS2.SSS2.p14.7.m7.1.1.2">𝜃</ci><ci id="S4.SS2.SSS2.p14.7.m7.1.1.3.cmml" xref="S4.SS2.SSS2.p14.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.7.m7.1c">\theta_{i}</annotation></semantics></math> is the basis in the dimension. Following sinusoidal position embeddings&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, RoPE defines the <em id="S4.SS2.SSS2.p14.10.3" class="ltx_emph ltx_font_italic">basis</em> <math id="S4.SS2.SSS2.p14.8.m8.1" class="ltx_Math" alttext="\theta_{i}" display="inline"><semantics id="S4.SS2.SSS2.p14.8.m8.1a"><msub id="S4.SS2.SSS2.p14.8.m8.1.1" xref="S4.SS2.SSS2.p14.8.m8.1.1.cmml"><mi id="S4.SS2.SSS2.p14.8.m8.1.1.2" xref="S4.SS2.SSS2.p14.8.m8.1.1.2.cmml">θ</mi><mi id="S4.SS2.SSS2.p14.8.m8.1.1.3" xref="S4.SS2.SSS2.p14.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.8.m8.1b"><apply id="S4.SS2.SSS2.p14.8.m8.1.1.cmml" xref="S4.SS2.SSS2.p14.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p14.8.m8.1.1.1.cmml" xref="S4.SS2.SSS2.p14.8.m8.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p14.8.m8.1.1.2.cmml" xref="S4.SS2.SSS2.p14.8.m8.1.1.2">𝜃</ci><ci id="S4.SS2.SSS2.p14.8.m8.1.1.3.cmml" xref="S4.SS2.SSS2.p14.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.8.m8.1c">\theta_{i}</annotation></semantics></math> as an exponentiation of the <em id="S4.SS2.SSS2.p14.10.4" class="ltx_emph ltx_font_italic">base</em> <math id="S4.SS2.SSS2.p14.9.m9.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S4.SS2.SSS2.p14.9.m9.1a"><mi id="S4.SS2.SSS2.p14.9.m9.1.1" xref="S4.SS2.SSS2.p14.9.m9.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.9.m9.1b"><ci id="S4.SS2.SSS2.p14.9.m9.1.1.cmml" xref="S4.SS2.SSS2.p14.9.m9.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.9.m9.1c">b</annotation></semantics></math> (set to <math id="S4.SS2.SSS2.p14.10.m10.1" class="ltx_Math" alttext="10000" display="inline"><semantics id="S4.SS2.SSS2.p14.10.m10.1a"><mn id="S4.SS2.SSS2.p14.10.m10.1.1" xref="S4.SS2.SSS2.p14.10.m10.1.1.cmml">10000</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.10.m10.1b"><cn type="integer" id="S4.SS2.SSS2.p14.10.m10.1.1.cmml" xref="S4.SS2.SSS2.p14.10.m10.1.1">10000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.10.m10.1c">10000</annotation></semantics></math> by default):</p>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.5" class="ltx_Math" alttext="\Theta=\{\theta_{i}=b^{-2(i-1)/d}|i\in\{1,2,\dots,d/2\}\}." display="block"><semantics id="S4.E4.m1.5a"><mrow id="S4.E4.m1.5.5.1" xref="S4.E4.m1.5.5.1.1.cmml"><mrow id="S4.E4.m1.5.5.1.1" xref="S4.E4.m1.5.5.1.1.cmml"><mi mathvariant="normal" id="S4.E4.m1.5.5.1.1.4" xref="S4.E4.m1.5.5.1.1.4.cmml">Θ</mi><mo id="S4.E4.m1.5.5.1.1.3" xref="S4.E4.m1.5.5.1.1.3.cmml">=</mo><mrow id="S4.E4.m1.5.5.1.1.2.2" xref="S4.E4.m1.5.5.1.1.2.3.cmml"><mo stretchy="false" id="S4.E4.m1.5.5.1.1.2.2.3" xref="S4.E4.m1.5.5.1.1.2.3.1.cmml">{</mo><mrow id="S4.E4.m1.5.5.1.1.1.1.1" xref="S4.E4.m1.5.5.1.1.1.1.1.cmml"><msub id="S4.E4.m1.5.5.1.1.1.1.1.2" xref="S4.E4.m1.5.5.1.1.1.1.1.2.cmml"><mi id="S4.E4.m1.5.5.1.1.1.1.1.2.2" xref="S4.E4.m1.5.5.1.1.1.1.1.2.2.cmml">θ</mi><mi id="S4.E4.m1.5.5.1.1.1.1.1.2.3" xref="S4.E4.m1.5.5.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.E4.m1.5.5.1.1.1.1.1.1" xref="S4.E4.m1.5.5.1.1.1.1.1.1.cmml">=</mo><msup id="S4.E4.m1.5.5.1.1.1.1.1.3" xref="S4.E4.m1.5.5.1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.5.5.1.1.1.1.1.3.2" xref="S4.E4.m1.5.5.1.1.1.1.1.3.2.cmml">b</mi><mrow id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.cmml"><mo id="S4.E4.m1.1.1.1a" xref="S4.E4.m1.1.1.1.cmml">−</mo><mrow id="S4.E4.m1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><mrow id="S4.E4.m1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.cmml"><mn id="S4.E4.m1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.3.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.E4.m1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.cmml">i</mi><mo id="S4.E4.m1.1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S4.E4.m1.1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.2.cmml">/</mo><mi id="S4.E4.m1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.3.cmml">d</mi></mrow></mrow></msup></mrow><mo lspace="0em" rspace="0em" id="S4.E4.m1.5.5.1.1.2.2.4" xref="S4.E4.m1.5.5.1.1.2.3.1.cmml">|</mo><mrow id="S4.E4.m1.5.5.1.1.2.2.2" xref="S4.E4.m1.5.5.1.1.2.2.2.cmml"><mi id="S4.E4.m1.5.5.1.1.2.2.2.3" xref="S4.E4.m1.5.5.1.1.2.2.2.3.cmml">i</mi><mo id="S4.E4.m1.5.5.1.1.2.2.2.2" xref="S4.E4.m1.5.5.1.1.2.2.2.2.cmml">∈</mo><mrow id="S4.E4.m1.5.5.1.1.2.2.2.1.1" xref="S4.E4.m1.5.5.1.1.2.2.2.1.2.cmml"><mo stretchy="false" id="S4.E4.m1.5.5.1.1.2.2.2.1.1.2" xref="S4.E4.m1.5.5.1.1.2.2.2.1.2.cmml">{</mo><mn id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml">1</mn><mo id="S4.E4.m1.5.5.1.1.2.2.2.1.1.3" xref="S4.E4.m1.5.5.1.1.2.2.2.1.2.cmml">,</mo><mn id="S4.E4.m1.3.3" xref="S4.E4.m1.3.3.cmml">2</mn><mo id="S4.E4.m1.5.5.1.1.2.2.2.1.1.4" xref="S4.E4.m1.5.5.1.1.2.2.2.1.2.cmml">,</mo><mi mathvariant="normal" id="S4.E4.m1.4.4" xref="S4.E4.m1.4.4.cmml">…</mi><mo id="S4.E4.m1.5.5.1.1.2.2.2.1.1.5" xref="S4.E4.m1.5.5.1.1.2.2.2.1.2.cmml">,</mo><mrow id="S4.E4.m1.5.5.1.1.2.2.2.1.1.1" xref="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.cmml"><mi id="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.2" xref="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.2.cmml">d</mi><mo id="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.1" xref="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.1.cmml">/</mo><mn id="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.3" xref="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.3.cmml">2</mn></mrow><mo stretchy="false" id="S4.E4.m1.5.5.1.1.2.2.2.1.1.6" xref="S4.E4.m1.5.5.1.1.2.2.2.1.2.cmml">}</mo></mrow></mrow><mo stretchy="false" id="S4.E4.m1.5.5.1.1.2.2.5" xref="S4.E4.m1.5.5.1.1.2.3.1.cmml">}</mo></mrow></mrow><mo lspace="0em" id="S4.E4.m1.5.5.1.2" xref="S4.E4.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.5b"><apply id="S4.E4.m1.5.5.1.1.cmml" xref="S4.E4.m1.5.5.1"><eq id="S4.E4.m1.5.5.1.1.3.cmml" xref="S4.E4.m1.5.5.1.1.3"></eq><ci id="S4.E4.m1.5.5.1.1.4.cmml" xref="S4.E4.m1.5.5.1.1.4">Θ</ci><apply id="S4.E4.m1.5.5.1.1.2.3.cmml" xref="S4.E4.m1.5.5.1.1.2.2"><csymbol cd="latexml" id="S4.E4.m1.5.5.1.1.2.3.1.cmml" xref="S4.E4.m1.5.5.1.1.2.2.3">conditional-set</csymbol><apply id="S4.E4.m1.5.5.1.1.1.1.1.cmml" xref="S4.E4.m1.5.5.1.1.1.1.1"><eq id="S4.E4.m1.5.5.1.1.1.1.1.1.cmml" xref="S4.E4.m1.5.5.1.1.1.1.1.1"></eq><apply id="S4.E4.m1.5.5.1.1.1.1.1.2.cmml" xref="S4.E4.m1.5.5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.5.5.1.1.1.1.1.2.1.cmml" xref="S4.E4.m1.5.5.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E4.m1.5.5.1.1.1.1.1.2.2.cmml" xref="S4.E4.m1.5.5.1.1.1.1.1.2.2">𝜃</ci><ci id="S4.E4.m1.5.5.1.1.1.1.1.2.3.cmml" xref="S4.E4.m1.5.5.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S4.E4.m1.5.5.1.1.1.1.1.3.cmml" xref="S4.E4.m1.5.5.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.5.5.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.5.5.1.1.1.1.1.3">superscript</csymbol><ci id="S4.E4.m1.5.5.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.5.5.1.1.1.1.1.3.2">𝑏</ci><apply id="S4.E4.m1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><minus id="S4.E4.m1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1"></minus><apply id="S4.E4.m1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1"><divide id="S4.E4.m1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.2"></divide><apply id="S4.E4.m1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1"><times id="S4.E4.m1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.2"></times><cn type="integer" id="S4.E4.m1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.3">2</cn><apply id="S4.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1"><minus id="S4.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.1"></minus><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2">𝑖</ci><cn type="integer" id="S4.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3">1</cn></apply></apply><ci id="S4.E4.m1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.3">𝑑</ci></apply></apply></apply></apply><apply id="S4.E4.m1.5.5.1.1.2.2.2.cmml" xref="S4.E4.m1.5.5.1.1.2.2.2"><in id="S4.E4.m1.5.5.1.1.2.2.2.2.cmml" xref="S4.E4.m1.5.5.1.1.2.2.2.2"></in><ci id="S4.E4.m1.5.5.1.1.2.2.2.3.cmml" xref="S4.E4.m1.5.5.1.1.2.2.2.3">𝑖</ci><set id="S4.E4.m1.5.5.1.1.2.2.2.1.2.cmml" xref="S4.E4.m1.5.5.1.1.2.2.2.1.1"><cn type="integer" id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2">1</cn><cn type="integer" id="S4.E4.m1.3.3.cmml" xref="S4.E4.m1.3.3">2</cn><ci id="S4.E4.m1.4.4.cmml" xref="S4.E4.m1.4.4">…</ci><apply id="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.cmml" xref="S4.E4.m1.5.5.1.1.2.2.2.1.1.1"><divide id="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.1.cmml" xref="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.1"></divide><ci id="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.2.cmml" xref="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.2">𝑑</ci><cn type="integer" id="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.3.cmml" xref="S4.E4.m1.5.5.1.1.2.2.2.1.1.1.3">2</cn></apply></set></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.5c">\Theta=\{\theta_{i}=b^{-2(i-1)/d}|i\in\{1,2,\dots,d/2\}\}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS2.p14.11">더욱이, 최근의 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib276" title="">276</a>]</cite>는 각 차원에 대해 한 사이클을 회전시키는데 필요한 거리(<math alttext="2\pi" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p14.11.m1.1"><semantics id="S4.SS2.SSS2.p14.11.m1.1a"><mrow id="S4.SS2.SSS2.p14.11.m1.1.1" xref="S4.SS2.SSS2.p14.11.m1.1.1.cmml"><mn id="S4.SS2.SSS2.p14.11.m1.1.1.2" xref="S4.SS2.SSS2.p14.11.m1.1.1.2.cmml">2</mn><mo id="S4.SS2.SSS2.p14.11.m1.1.1.1" lspace="0em" rspace="0em" xref="S4.SS2.SSS2.p14.11.m1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS2.p14.11.m1.1.1.3" xref="S4.SS2.SSS2.p14.11.m1.1.1.3.cmml">π</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p14.11.m1.1b"><apply id="S4.SS2.SSS2.p14.11.m1.1.1.cmml" xref="S4.SS2.SSS2.p14.11.m1.1.1"><times id="S4.SS2.SSS2.p14.11.m1.1.1.1.cmml" xref="S4.SS2.SSS2.p14.11.m1.1.1.1"></times><cn id="S4.SS2.SSS2.p14.11.m1.1.1.2.cmml" type="integer" xref="S4.SS2.SSS2.p14.11.m1.1.1.2">2</cn><ci id="S4.SS2.SSS2.p14.11.m1.1.1.3.cmml" xref="S4.SS2.SSS2.p14.11.m1.1.1.3">𝜋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p14.11.m1.1c">2\pi</annotation></semantics></math>)를 파장으로 정의한다:</p>
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E5.m1.2" class="ltx_Math" alttext="\lambda_{i}=2\pi b^{2(i-1)/d}=2\pi/\theta_{i}." display="block"><semantics id="S4.E5.m1.2a"><mrow id="S4.E5.m1.2.2.1" xref="S4.E5.m1.2.2.1.1.cmml"><mrow id="S4.E5.m1.2.2.1.1" xref="S4.E5.m1.2.2.1.1.cmml"><msub id="S4.E5.m1.2.2.1.1.2" xref="S4.E5.m1.2.2.1.1.2.cmml"><mi id="S4.E5.m1.2.2.1.1.2.2" xref="S4.E5.m1.2.2.1.1.2.2.cmml">λ</mi><mi id="S4.E5.m1.2.2.1.1.2.3" xref="S4.E5.m1.2.2.1.1.2.3.cmml">i</mi></msub><mo id="S4.E5.m1.2.2.1.1.3" xref="S4.E5.m1.2.2.1.1.3.cmml">=</mo><mrow id="S4.E5.m1.2.2.1.1.4" xref="S4.E5.m1.2.2.1.1.4.cmml"><mn id="S4.E5.m1.2.2.1.1.4.2" xref="S4.E5.m1.2.2.1.1.4.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.4.1" xref="S4.E5.m1.2.2.1.1.4.1.cmml">​</mo><mi id="S4.E5.m1.2.2.1.1.4.3" xref="S4.E5.m1.2.2.1.1.4.3.cmml">π</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.4.1a" xref="S4.E5.m1.2.2.1.1.4.1.cmml">​</mo><msup id="S4.E5.m1.2.2.1.1.4.4" xref="S4.E5.m1.2.2.1.1.4.4.cmml"><mi id="S4.E5.m1.2.2.1.1.4.4.2" xref="S4.E5.m1.2.2.1.1.4.4.2.cmml">b</mi><mrow id="S4.E5.m1.1.1.1" xref="S4.E5.m1.1.1.1.cmml"><mrow id="S4.E5.m1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.cmml"><mn id="S4.E5.m1.1.1.1.1.3" xref="S4.E5.m1.1.1.1.1.3.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.E5.m1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E5.m1.1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.1.1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E5.m1.1.1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.E5.m1.1.1.1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.1.1.1.2.cmml">i</mi><mo id="S4.E5.m1.1.1.1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S4.E5.m1.1.1.1.1.1.1.1.3" xref="S4.E5.m1.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S4.E5.m1.1.1.1.1.1.1.3" xref="S4.E5.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E5.m1.1.1.1.2" xref="S4.E5.m1.1.1.1.2.cmml">/</mo><mi id="S4.E5.m1.1.1.1.3" xref="S4.E5.m1.1.1.1.3.cmml">d</mi></mrow></msup></mrow><mo id="S4.E5.m1.2.2.1.1.5" xref="S4.E5.m1.2.2.1.1.5.cmml">=</mo><mrow id="S4.E5.m1.2.2.1.1.6" xref="S4.E5.m1.2.2.1.1.6.cmml"><mrow id="S4.E5.m1.2.2.1.1.6.2" xref="S4.E5.m1.2.2.1.1.6.2.cmml"><mn id="S4.E5.m1.2.2.1.1.6.2.2" xref="S4.E5.m1.2.2.1.1.6.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.6.2.1" xref="S4.E5.m1.2.2.1.1.6.2.1.cmml">​</mo><mi id="S4.E5.m1.2.2.1.1.6.2.3" xref="S4.E5.m1.2.2.1.1.6.2.3.cmml">π</mi></mrow><mo id="S4.E5.m1.2.2.1.1.6.1" xref="S4.E5.m1.2.2.1.1.6.1.cmml">/</mo><msub id="S4.E5.m1.2.2.1.1.6.3" xref="S4.E5.m1.2.2.1.1.6.3.cmml"><mi id="S4.E5.m1.2.2.1.1.6.3.2" xref="S4.E5.m1.2.2.1.1.6.3.2.cmml">θ</mi><mi id="S4.E5.m1.2.2.1.1.6.3.3" xref="S4.E5.m1.2.2.1.1.6.3.3.cmml">i</mi></msub></mrow></mrow><mo lspace="0em" id="S4.E5.m1.2.2.1.2" xref="S4.E5.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.2b"><apply id="S4.E5.m1.2.2.1.1.cmml" xref="S4.E5.m1.2.2.1"><and id="S4.E5.m1.2.2.1.1a.cmml" xref="S4.E5.m1.2.2.1"></and><apply id="S4.E5.m1.2.2.1.1b.cmml" xref="S4.E5.m1.2.2.1"><eq id="S4.E5.m1.2.2.1.1.3.cmml" xref="S4.E5.m1.2.2.1.1.3"></eq><apply id="S4.E5.m1.2.2.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.2.1.cmml" xref="S4.E5.m1.2.2.1.1.2">subscript</csymbol><ci id="S4.E5.m1.2.2.1.1.2.2.cmml" xref="S4.E5.m1.2.2.1.1.2.2">𝜆</ci><ci id="S4.E5.m1.2.2.1.1.2.3.cmml" xref="S4.E5.m1.2.2.1.1.2.3">𝑖</ci></apply><apply id="S4.E5.m1.2.2.1.1.4.cmml" xref="S4.E5.m1.2.2.1.1.4"><times id="S4.E5.m1.2.2.1.1.4.1.cmml" xref="S4.E5.m1.2.2.1.1.4.1"></times><cn type="integer" id="S4.E5.m1.2.2.1.1.4.2.cmml" xref="S4.E5.m1.2.2.1.1.4.2">2</cn><ci id="S4.E5.m1.2.2.1.1.4.3.cmml" xref="S4.E5.m1.2.2.1.1.4.3">𝜋</ci><apply id="S4.E5.m1.2.2.1.1.4.4.cmml" xref="S4.E5.m1.2.2.1.1.4.4"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.4.4.1.cmml" xref="S4.E5.m1.2.2.1.1.4.4">superscript</csymbol><ci id="S4.E5.m1.2.2.1.1.4.4.2.cmml" xref="S4.E5.m1.2.2.1.1.4.4.2">𝑏</ci><apply id="S4.E5.m1.1.1.1.cmml" xref="S4.E5.m1.1.1.1"><divide id="S4.E5.m1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.2"></divide><apply id="S4.E5.m1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1"><times id="S4.E5.m1.1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.1.2"></times><cn type="integer" id="S4.E5.m1.1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.1.3">2</cn><apply id="S4.E5.m1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1"><minus id="S4.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1"></minus><ci id="S4.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.2">𝑖</ci><cn type="integer" id="S4.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.3">1</cn></apply></apply><ci id="S4.E5.m1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.3">𝑑</ci></apply></apply></apply></apply><apply id="S4.E5.m1.2.2.1.1c.cmml" xref="S4.E5.m1.2.2.1"><eq id="S4.E5.m1.2.2.1.1.5.cmml" xref="S4.E5.m1.2.2.1.1.5"></eq><share href="#S4.E5.m1.2.2.1.1.4.cmml" id="S4.E5.m1.2.2.1.1d.cmml" xref="S4.E5.m1.2.2.1"></share><apply id="S4.E5.m1.2.2.1.1.6.cmml" xref="S4.E5.m1.2.2.1.1.6"><divide id="S4.E5.m1.2.2.1.1.6.1.cmml" xref="S4.E5.m1.2.2.1.1.6.1"></divide><apply id="S4.E5.m1.2.2.1.1.6.2.cmml" xref="S4.E5.m1.2.2.1.1.6.2"><times id="S4.E5.m1.2.2.1.1.6.2.1.cmml" xref="S4.E5.m1.2.2.1.1.6.2.1"></times><cn type="integer" id="S4.E5.m1.2.2.1.1.6.2.2.cmml" xref="S4.E5.m1.2.2.1.1.6.2.2">2</cn><ci id="S4.E5.m1.2.2.1.1.6.2.3.cmml" xref="S4.E5.m1.2.2.1.1.6.2.3">𝜋</ci></apply><apply id="S4.E5.m1.2.2.1.1.6.3.cmml" xref="S4.E5.m1.2.2.1.1.6.3"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.6.3.1.cmml" xref="S4.E5.m1.2.2.1.1.6.3">subscript</csymbol><ci id="S4.E5.m1.2.2.1.1.6.3.2.cmml" xref="S4.E5.m1.2.2.1.1.6.3.2">𝜃</ci><ci id="S4.E5.m1.2.2.1.1.6.3.3.cmml" xref="S4.E5.m1.2.2.1.1.6.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.2c">\lambda_{i}=2\pi b^{2(i-1)/d}=2\pi/\theta_{i}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS2.p14.12">뛰어난 성능과 장기적인 감쇠 특성으로 인해 RoPE는 최신 LLM, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p14.12.1">e.g.,</em> PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite> 및 LLaMA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>에 널리 채택되었다. RoPE를 기반으로 xPos<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib277" title="">277</a>]</cite>는 Transformer의 번역 불변성과 길이 외삽을 더욱 향상시킨다. 회전각 벡터의 각 차원에서 xPos는 기저가 더 클 때 더 작은 특별한 지수 감쇠를 추가한다. 거리가 멀어질수록 훈련 시 불안정한 현상을 완화할 수 있다.</p>
</div>
<div id="S4.SS2.SSS2.p15" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p15.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p15.1.m1.1"><semantics id="S4.SS2.SSS2.p15.1.m1.1a"><mo id="S4.SS2.SSS2.p15.1.m1.1.1" xref="S4.SS2.SSS2.p15.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p15.1.m1.1b"><ci id="S4.SS2.SSS2.p15.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p15.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p15.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p15.1.1">ALiBi. </em> ALiBi<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib264" title="">264</a>]</cite>는 Transformer의 외삽을 개선하기 위해 제안되었다. 상대적 위치 임베딩과 유사하게, 그것은 키들과 쿼리들 사이의 거리들에 기초하여 페널티를 갖는 주의 스코어들을 편향시킨다. T5<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>와 같은 상대적 위치 임베딩 방법과 달리 ALiBi에서 벌점 점수는 훈련 가능한 매개 변수 없이 미리 정의된다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib264" title="">264</a>]</cite>의 실험 결과는 ALiBi가 정현파 PE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>, RoPE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib263" title="">263</a>]</cite>, T5 bias<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>와 같은 여러 가지 일반적인 위치 임베딩 방법보다 훈련에 비해 긴 시퀀스에 대해 더 나은 외삽 성능을 가짐을 보여주었다. 또한, ALiBi는 BLOOM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>에서도 훈련 안정성을 향상시킬 수 있음을 보였다.</p>
</div>
<div id="S4.SS2.SSS2.p16" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS2.p16.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p16.1.1">Attention. </span> Attention mechanism is a critical component of Transformer. 그것은 시퀀스에 걸친 토큰들이 서로 상호작용하고 입력 및 출력 시퀀스의 표현들을 계산할 수 있게 한다.</p>
</div>
<div id="S4.SS2.SSS2.p17" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p17.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p17.1.m1.1"><semantics id="S4.SS2.SSS2.p17.1.m1.1a"><mo id="S4.SS2.SSS2.p17.1.m1.1.1" xref="S4.SS2.SSS2.p17.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p17.1.m1.1b"><ci id="S4.SS2.SSS2.p17.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p17.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p17.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p17.1.1">Full attention</em>. 바닐라 트랜스포머<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>에서 어텐션 메커니즘은 시퀀스의 모든 토큰 쌍 간의 관계를 고려하여 쌍으로 수행된다. 숨겨진 상태를 쿼리, 키 및 값으로 매핑하는 스케일링된 dot-product attention를 채택한다. 또한 Transformer는 단일 어텐션 대신 다중 헤드 어텐션을 사용하여 쿼리, 키 및 값을 서로 다른 헤드에 투영합니다. 각 헤드의 출력의 연결은 최종 출력으로 간주된다.</p>
</div>
<div id="S4.SS2.SSS2.p18" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p18.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p18.1.m1.1"><semantics id="S4.SS2.SSS2.p18.1.m1.1a"><mo id="S4.SS2.SSS2.p18.1.m1.1.1" xref="S4.SS2.SSS2.p18.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p18.1.m1.1b"><ci id="S4.SS2.SSS2.p18.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p18.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p18.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p18.1.1">Sparse attention</em>. 완전한 관심의 중요한 과제는 긴 수열을 다룰 때 부담이 되는 2차 계산 복잡도이다. 따라서 주의 메커니즘 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib278" title="">278</a>, <a class="ltx_ref" href="#bib.bib279" title="">279</a>]</cite>의 계산 복잡도를 줄이기 위해 다양한 효율적인 트랜스포머 변형이 제안된다. 예를 들어, 국부적으로 대역화된 희소 주의력(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p18.1.2">i.e.,</em> Factorized Attention <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib280" title="">280</a>]</cite>는 GPT-3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>에서 채택되었다. 전체 시퀀스 대신 각 쿼리는 위치에 따라 토큰의 하위 집합에만 참석할 수 있습니다.</p>
</div>
<div id="S4.SS2.SSS2.p19" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p19.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p19.1.m1.1"><semantics id="S4.SS2.SSS2.p19.1.m1.1a"><mo id="S4.SS2.SSS2.p19.1.m1.1.1" xref="S4.SS2.SSS2.p19.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p19.1.m1.1b"><ci id="S4.SS2.SSS2.p19.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p19.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p19.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p19.1.1">Multi-query/grouped-query attention</em>. 다중 쿼리 주의는 키 및 값 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib281" title="">281</a>]</cite>에서 서로 다른 헤드가 동일한 선형 변환 행렬을 공유하는 주의 변형을 나타냅니다. 모델 품질에서 약간의 희생만으로 더 높은 추론 속도를 달성합니다. 다중 쿼리 주의를 가진 대표적인 모델로는 PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>와 StarCoder<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib98" title="">98</a>]</cite>가 있다. 멀티-쿼리 어텐션과 멀티-헤드 어텐션 사이의 트레이드오프를 만들기 위해 그룹화된-쿼리 어텐션(GQA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib282" title="">282</a>]</cite>가 탐색되었다. GQA에서 헤드는 다른 그룹으로 할당되며 동일한 그룹에 속하는 헤드는 동일한 변환 행렬을 공유한다. 특히, GQA는 최근 발표된 LLaMA 2 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>에서 채택되고 경험적으로 테스트되었다.</p>
</div>
<div id="S4.SS2.SSS2.p20" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p20.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p20.1.m1.1"><semantics id="S4.SS2.SSS2.p20.1.m1.1a"><mo id="S4.SS2.SSS2.p20.1.m1.1.1" xref="S4.SS2.SSS2.p20.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p20.1.m1.1b"><ci id="S4.SS2.SSS2.p20.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p20.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p20.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p20.2.1">FlashAttention</em>. 플래시 어텐션<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib283" title="">283</a>]</cite>는 컴퓨팅 효율을 향상시키기 위해 모델 품질을 트레이드오프하는 기존의 근사 어텐션 방법과 달리, IO 인식 관점에서 GPU에 대한 어텐션 모듈의 속도와 메모리 소비를 최적화할 것을 제안한다. 현대 GPU에는 다양한 수준의 메모리가 존재하며, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p20.2.2">e.g.,</em> SRAM with a fast IO and HBM with a relatively slow IO. 플래시 어텐션은 빠른 메모리 SRAM을 더 잘 사용하기 위해 입력을 블록으로 구성하고 필요한 재계산을 도입한다. CUDA에서 융합 커널로 구현된 FlashAttention는 PyTorch<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib197" title="">197</a>]</cite>, DeepSpeed<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite>, Megatron-LM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>]</cite>에 통합되었다. 업데이트된 버전 FlashAttention-2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib284" title="">284</a>]</cite>는 GPU 스레드 블록 및 워프의 작업 분할을 더욱 최적화하여 원래 FlashAttention와 비교할 때 약 2<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p20.2.m2.1"><semantics id="S4.SS2.SSS2.p20.2.m2.1a"><mo id="S4.SS2.SSS2.p20.2.m2.1.1" xref="S4.SS2.SSS2.p20.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p20.2.m2.1b"><times id="S4.SS2.SSS2.p20.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p20.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p20.2.m2.1c">\times</annotation></semantics></math> speedup으로 이어진다.</p>
</div>
<div id="S4.SS2.SSS2.p21" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p21.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p21.1.m1.1"><semantics id="S4.SS2.SSS2.p21.1.m1.1a"><mo id="S4.SS2.SSS2.p21.1.m1.1.1" xref="S4.SS2.SSS2.p21.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p21.1.m1.1b"><ci id="S4.SS2.SSS2.p21.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p21.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p21.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p21.1.1">PagedAttention</em>. LLM이 서버에 배포될 때 GPU 메모리는 캐시된 주의 키와 값 텐서(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p21.1.2">KV 캐시</em>이라고 함)에 의해 크게 점유됩니다. 주요 이유는 입력 길이가 종종 다양하여 단편화 및 과잉 예약 문제로 이어지기 때문이다. 운영 체제에서 고전적인 페이징 기술에 영감을 받아, PagedAttention는 배포된 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib285" title="">285</a>]</cite>의 메모리 효율과 처리량을 개선하기 위해 제안되었다. 세부적으로, PagedAttention는 각 시퀀스를 서브시퀀스로 분할하고, 이들 서브시퀀스의 대응하는 KV 캐시는 비연속 물리 블록으로 할당된다. 페이징 기법은 GPU 활용도를 높이고 병렬 샘플링에서 효율적인 메모리 공유를 가능하게 한다.</p>
</div>
<div id="S4.SS2.SSS2.p22" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p22.1">이 모든 논의를 종합하기 위해 세부 구성을 위한 기존 문헌의 제안을 요약한다. 더 강력한 일반화 및 훈련 안정성을 위해 계층 정규화를 위한 사전 RMSNorm을 선택하고 활성화 함수로 SwiGLU 또는 GeGLU를 선택하는 것이 제안된다. 또한, LN은 레이어 임베딩 직후에 사용되지 않을 수 있으며, 이는 성능 저하를 초래할 가능성이 있다. 위치 임베딩의 경우, RoPE 또는 ALiBi는 긴 시퀀스에서 더 잘 수행되기 때문에 더 나은 선택이다.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Pre-training Tasks</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS3.p1.1">사전 훈련은 대규모 코퍼스에서 대규모 모델 매개변수로 일반 지식을 인코딩하는 중요한 역할을 한다. LLM 트레이닝을 위해, 일반적으로 사용되는 사전 트레이닝 태스크들, 즉 언어 모델링 및 노이즈 제거 오토인코딩이 있다.</p>
</div>
<div id="S4.SS2.SSS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.SSS3.p2.3" class="ltx_p"><span id="S4.SS2.SSS3.p2.3.1" class="ltx_text ltx_font_bold">Language Modeling.</span> The language modeling task (LM) is the most commonly used objective to pre-train decoder-only LLMs, <em id="S4.SS2.SSS3.p2.3.2" class="ltx_emph ltx_font_italic">e.g.,</em> GPT3&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> and PaLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. Given a sequence of tokens <math id="S4.SS2.SSS3.p2.1.m1.3" class="ltx_Math" alttext="\mathbf{x}=\{x_{1},\dots,x_{n}\}" display="inline"><semantics id="S4.SS2.SSS3.p2.1.m1.3a"><mrow id="S4.SS2.SSS3.p2.1.m1.3.3" xref="S4.SS2.SSS3.p2.1.m1.3.3.cmml"><mi id="S4.SS2.SSS3.p2.1.m1.3.3.4" xref="S4.SS2.SSS3.p2.1.m1.3.3.4.cmml">𝐱</mi><mo id="S4.SS2.SSS3.p2.1.m1.3.3.3" xref="S4.SS2.SSS3.p2.1.m1.3.3.3.cmml">=</mo><mrow id="S4.SS2.SSS3.p2.1.m1.3.3.2.2" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.3" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.3.cmml">{</mo><msub id="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1" xref="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.cmml"><mi id="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.2" xref="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.2.cmml">x</mi><mn id="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.3" xref="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.4" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S4.SS2.SSS3.p2.1.m1.1.1" xref="S4.SS2.SSS3.p2.1.m1.1.1.cmml">…</mi><mo id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.5" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.3.cmml">,</mo><msub id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.cmml"><mi id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.2" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.2.cmml">x</mi><mi id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.3" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.6" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.1.m1.3b"><apply id="S4.SS2.SSS3.p2.1.m1.3.3.cmml" xref="S4.SS2.SSS3.p2.1.m1.3.3"><eq id="S4.SS2.SSS3.p2.1.m1.3.3.3.cmml" xref="S4.SS2.SSS3.p2.1.m1.3.3.3"></eq><ci id="S4.SS2.SSS3.p2.1.m1.3.3.4.cmml" xref="S4.SS2.SSS3.p2.1.m1.3.3.4">𝐱</ci><set id="S4.SS2.SSS3.p2.1.m1.3.3.2.3.cmml" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.2"><apply id="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.cmml" xref="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.1.cmml" xref="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.2.cmml" xref="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.3.cmml" xref="S4.SS2.SSS3.p2.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S4.SS2.SSS3.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p2.1.m1.1.1">…</ci><apply id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.cmml" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.1.cmml" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.2.cmml" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.2">𝑥</ci><ci id="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.3.cmml" xref="S4.SS2.SSS3.p2.1.m1.3.3.2.2.2.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.1.m1.3c">\mathbf{x}=\{x_{1},\dots,x_{n}\}</annotation></semantics></math>, the LM task aims to autoregressively predict the target tokens <math id="S4.SS2.SSS3.p2.2.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S4.SS2.SSS3.p2.2.m2.1a"><msub id="S4.SS2.SSS3.p2.2.m2.1.1" xref="S4.SS2.SSS3.p2.2.m2.1.1.cmml"><mi id="S4.SS2.SSS3.p2.2.m2.1.1.2" xref="S4.SS2.SSS3.p2.2.m2.1.1.2.cmml">x</mi><mi id="S4.SS2.SSS3.p2.2.m2.1.1.3" xref="S4.SS2.SSS3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.2.m2.1b"><apply id="S4.SS2.SSS3.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p2.2.m2.1.1.1.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p2.2.m2.1.1.2.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.1.2">𝑥</ci><ci id="S4.SS2.SSS3.p2.2.m2.1.1.3.cmml" xref="S4.SS2.SSS3.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.2.m2.1c">x_{i}</annotation></semantics></math> based on the preceding tokens <math id="S4.SS2.SSS3.p2.3.m3.1" class="ltx_Math" alttext="x_{<i}" display="inline"><semantics id="S4.SS2.SSS3.p2.3.m3.1a"><msub id="S4.SS2.SSS3.p2.3.m3.1.1" xref="S4.SS2.SSS3.p2.3.m3.1.1.cmml"><mi id="S4.SS2.SSS3.p2.3.m3.1.1.2" xref="S4.SS2.SSS3.p2.3.m3.1.1.2.cmml">x</mi><mrow id="S4.SS2.SSS3.p2.3.m3.1.1.3" xref="S4.SS2.SSS3.p2.3.m3.1.1.3.cmml"><mi id="S4.SS2.SSS3.p2.3.m3.1.1.3.2" xref="S4.SS2.SSS3.p2.3.m3.1.1.3.2.cmml"></mi><mo id="S4.SS2.SSS3.p2.3.m3.1.1.3.1" xref="S4.SS2.SSS3.p2.3.m3.1.1.3.1.cmml">&lt;</mo><mi id="S4.SS2.SSS3.p2.3.m3.1.1.3.3" xref="S4.SS2.SSS3.p2.3.m3.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.3.m3.1b"><apply id="S4.SS2.SSS3.p2.3.m3.1.1.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p2.3.m3.1.1.1.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p2.3.m3.1.1.2.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.1.2">𝑥</ci><apply id="S4.SS2.SSS3.p2.3.m3.1.1.3.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.1.3"><lt id="S4.SS2.SSS3.p2.3.m3.1.1.3.1.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.1.3.1"></lt><csymbol cd="latexml" id="S4.SS2.SSS3.p2.3.m3.1.1.3.2.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.1.3.2">absent</csymbol><ci id="S4.SS2.SSS3.p2.3.m3.1.1.3.3.cmml" xref="S4.SS2.SSS3.p2.3.m3.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.3.m3.1c">x_{&lt;i}</annotation></semantics></math> in a sequence. A general training objective is to maximize the following likelihood:</p>
<table id="S4.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E6.m1.2" class="ltx_Math" alttext="\mathcal{L}_{LM}(\mathbf{x})=\sum_{i=1}^{n}\log P(x_{i}|\mathbf{x}_{<i})." display="block"><semantics id="S4.E6.m1.2a"><mrow id="S4.E6.m1.2.2.1" xref="S4.E6.m1.2.2.1.1.cmml"><mrow id="S4.E6.m1.2.2.1.1" xref="S4.E6.m1.2.2.1.1.cmml"><mrow id="S4.E6.m1.2.2.1.1.3" xref="S4.E6.m1.2.2.1.1.3.cmml"><msub id="S4.E6.m1.2.2.1.1.3.2" xref="S4.E6.m1.2.2.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.2.2.1.1.3.2.2" xref="S4.E6.m1.2.2.1.1.3.2.2.cmml">ℒ</mi><mrow id="S4.E6.m1.2.2.1.1.3.2.3" xref="S4.E6.m1.2.2.1.1.3.2.3.cmml"><mi id="S4.E6.m1.2.2.1.1.3.2.3.2" xref="S4.E6.m1.2.2.1.1.3.2.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.2.2.1.1.3.2.3.1" xref="S4.E6.m1.2.2.1.1.3.2.3.1.cmml">​</mo><mi id="S4.E6.m1.2.2.1.1.3.2.3.3" xref="S4.E6.m1.2.2.1.1.3.2.3.3.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E6.m1.2.2.1.1.3.1" xref="S4.E6.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S4.E6.m1.2.2.1.1.3.3.2" xref="S4.E6.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S4.E6.m1.2.2.1.1.3.3.2.1" xref="S4.E6.m1.2.2.1.1.3.cmml">(</mo><mi id="S4.E6.m1.1.1" xref="S4.E6.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.E6.m1.2.2.1.1.3.3.2.2" xref="S4.E6.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S4.E6.m1.2.2.1.1.2" xref="S4.E6.m1.2.2.1.1.2.cmml">=</mo><mrow id="S4.E6.m1.2.2.1.1.1" xref="S4.E6.m1.2.2.1.1.1.cmml"><munderover id="S4.E6.m1.2.2.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.2.cmml"><mo movablelimits="false" id="S4.E6.m1.2.2.1.1.1.2.2.2" xref="S4.E6.m1.2.2.1.1.1.2.2.2.cmml">∑</mo><mrow id="S4.E6.m1.2.2.1.1.1.2.2.3" xref="S4.E6.m1.2.2.1.1.1.2.2.3.cmml"><mi id="S4.E6.m1.2.2.1.1.1.2.2.3.2" xref="S4.E6.m1.2.2.1.1.1.2.2.3.2.cmml">i</mi><mo id="S4.E6.m1.2.2.1.1.1.2.2.3.1" xref="S4.E6.m1.2.2.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E6.m1.2.2.1.1.1.2.2.3.3" xref="S4.E6.m1.2.2.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E6.m1.2.2.1.1.1.2.3" xref="S4.E6.m1.2.2.1.1.1.2.3.cmml">n</mi></munderover><mrow id="S4.E6.m1.2.2.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.cmml"><mrow id="S4.E6.m1.2.2.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.3.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.3.1" xref="S4.E6.m1.2.2.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S4.E6.m1.2.2.1.1.1.1.3a" xref="S4.E6.m1.2.2.1.1.1.1.3.cmml">⁡</mo><mi id="S4.E6.m1.2.2.1.1.1.1.3.2" xref="S4.E6.m1.2.2.1.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E6.m1.2.2.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E6.m1.2.2.1.1.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S4.E6.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">𝐱</mi><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msub></mrow><mo stretchy="false" id="S4.E6.m1.2.2.1.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S4.E6.m1.2.2.1.2" xref="S4.E6.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.2b"><apply id="S4.E6.m1.2.2.1.1.cmml" xref="S4.E6.m1.2.2.1"><eq id="S4.E6.m1.2.2.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.2"></eq><apply id="S4.E6.m1.2.2.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.3"><times id="S4.E6.m1.2.2.1.1.3.1.cmml" xref="S4.E6.m1.2.2.1.1.3.1"></times><apply id="S4.E6.m1.2.2.1.1.3.2.cmml" xref="S4.E6.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.3.2.1.cmml" xref="S4.E6.m1.2.2.1.1.3.2">subscript</csymbol><ci id="S4.E6.m1.2.2.1.1.3.2.2.cmml" xref="S4.E6.m1.2.2.1.1.3.2.2">ℒ</ci><apply id="S4.E6.m1.2.2.1.1.3.2.3.cmml" xref="S4.E6.m1.2.2.1.1.3.2.3"><times id="S4.E6.m1.2.2.1.1.3.2.3.1.cmml" xref="S4.E6.m1.2.2.1.1.3.2.3.1"></times><ci id="S4.E6.m1.2.2.1.1.3.2.3.2.cmml" xref="S4.E6.m1.2.2.1.1.3.2.3.2">𝐿</ci><ci id="S4.E6.m1.2.2.1.1.3.2.3.3.cmml" xref="S4.E6.m1.2.2.1.1.3.2.3.3">𝑀</ci></apply></apply><ci id="S4.E6.m1.1.1.cmml" xref="S4.E6.m1.1.1">𝐱</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1"><apply id="S4.E6.m1.2.2.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.2.1.cmml" xref="S4.E6.m1.2.2.1.1.1.2">superscript</csymbol><apply id="S4.E6.m1.2.2.1.1.1.2.2.cmml" xref="S4.E6.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.2.2.1.cmml" xref="S4.E6.m1.2.2.1.1.1.2">subscript</csymbol><sum id="S4.E6.m1.2.2.1.1.1.2.2.2.cmml" xref="S4.E6.m1.2.2.1.1.1.2.2.2"></sum><apply id="S4.E6.m1.2.2.1.1.1.2.2.3.cmml" xref="S4.E6.m1.2.2.1.1.1.2.2.3"><eq id="S4.E6.m1.2.2.1.1.1.2.2.3.1.cmml" xref="S4.E6.m1.2.2.1.1.1.2.2.3.1"></eq><ci id="S4.E6.m1.2.2.1.1.1.2.2.3.2.cmml" xref="S4.E6.m1.2.2.1.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S4.E6.m1.2.2.1.1.1.2.2.3.3.cmml" xref="S4.E6.m1.2.2.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E6.m1.2.2.1.1.1.2.3.cmml" xref="S4.E6.m1.2.2.1.1.1.2.3">𝑛</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1"><times id="S4.E6.m1.2.2.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.2"></times><apply id="S4.E6.m1.2.2.1.1.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.3"><log id="S4.E6.m1.2.2.1.1.1.1.3.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.3.1"></log><ci id="S4.E6.m1.2.2.1.1.1.1.3.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.3.2">𝑃</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.2">𝐱</ci><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3"><lt id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.2c">\mathcal{L}_{LM}(\mathbf{x})=\sum_{i=1}^{n}\log P(x_{i}|\mathbf{x}_{&lt;i}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS2.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS3.p3.1">대부분의 언어 태스크들은 입력에 기초하여 예측 문제로서 캐스팅될 수 있기 때문에, 이러한 디코더-전용 LLM들은 통합 LM 방식으로 이러한 태스크들을 달성하는 방법을 암묵적으로 학습하는데 잠재적으로 유리할 수 있다. 또한 일부 연구에서는 디코더 전용 LLM이 미세 조정 없이 다음 토큰 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>, <a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>를 자동으로 예측하여 특정 태스크로 자연스럽게 전달될 수 있음을 밝혔다. LM의 중요한 변형은 prefix 디코더 아키텍처를 가진 사전 훈련 모델을 위해 설계된 <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS3.p3.1.1">prefix language modeling</em> 작업이다. 임의로 선택된 접두사 내의 토큰은 접두사 언어 모델링의 손실을 계산하는 데 사용되지 않는다. 사전 훈련 동안 볼 수 있는 동일한 양의 토큰으로, 프리픽스 언어 모델링은 언어 모델링보다 약간 더 나쁜 성능을 수행하는데, 이는 모델 사전 훈련 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>]</cite>에 대해 시퀀스 내의 더 적은 토큰이 관여하기 때문이다.</p>
</div>
<div id="S4.SS2.SSS3.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS3.p4.2"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS3.p4.2.1">Denoising Autoencoding. </span>  기존의 LM 외에도 디노이징 오토인코딩 태스크(DAE)는 사전 훈련 언어 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>, <a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>에도 널리 사용되었다. DAE 작업에 대한 입력 <math alttext="\mathbf{x}_{\backslash\tilde{\mathbf{x}}}" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p4.1.m1.1"><semantics id="S4.SS2.SSS3.p4.1.m1.1a"><msub id="S4.SS2.SSS3.p4.1.m1.1.1" xref="S4.SS2.SSS3.p4.1.m1.1.1.cmml"><mi id="S4.SS2.SSS3.p4.1.m1.1.1.2" xref="S4.SS2.SSS3.p4.1.m1.1.1.2.cmml">𝐱</mi><mrow id="S4.SS2.SSS3.p4.1.m1.1.1.3" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.cmml"><mi id="S4.SS2.SSS3.p4.1.m1.1.1.3.2" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.2.cmml"></mi><mo id="S4.SS2.SSS3.p4.1.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.1.cmml">\</mo><mover accent="true" id="S4.SS2.SSS3.p4.1.m1.1.1.3.3" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.3.cmml"><mi id="S4.SS2.SSS3.p4.1.m1.1.1.3.3.2" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.3.2.cmml">𝐱</mi><mo id="S4.SS2.SSS3.p4.1.m1.1.1.3.3.1" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.3.1.cmml">~</mo></mover></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p4.1.m1.1b"><apply id="S4.SS2.SSS3.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p4.1.m1.1.1.1.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p4.1.m1.1.1.2.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1.2">𝐱</ci><apply id="S4.SS2.SSS3.p4.1.m1.1.1.3.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1.3"><ci id="S4.SS2.SSS3.p4.1.m1.1.1.3.1.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.1">\</ci><csymbol cd="latexml" id="S4.SS2.SSS3.p4.1.m1.1.1.3.2.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.2">absent</csymbol><apply id="S4.SS2.SSS3.p4.1.m1.1.1.3.3.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.3"><ci id="S4.SS2.SSS3.p4.1.m1.1.1.3.3.1.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.3.1">~</ci><ci id="S4.SS2.SSS3.p4.1.m1.1.1.3.3.2.cmml" xref="S4.SS2.SSS3.p4.1.m1.1.1.3.3.2">𝐱</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p4.1.m1.1c">\mathbf{x}_{\backslash\tilde{\mathbf{x}}}</annotation></semantics></math>는 무작위로 대체된 스팬으로 손상된 텍스트이다. 그런 다음, 언어 모델들은 교체된 토큰들 <math alttext="\tilde{\mathbf{x}}" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p4.2.m2.1"><semantics id="S4.SS2.SSS3.p4.2.m2.1a"><mover accent="true" id="S4.SS2.SSS3.p4.2.m2.1.1" xref="S4.SS2.SSS3.p4.2.m2.1.1.cmml"><mi id="S4.SS2.SSS3.p4.2.m2.1.1.2" xref="S4.SS2.SSS3.p4.2.m2.1.1.2.cmml">𝐱</mi><mo id="S4.SS2.SSS3.p4.2.m2.1.1.1" xref="S4.SS2.SSS3.p4.2.m2.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p4.2.m2.1b"><apply id="S4.SS2.SSS3.p4.2.m2.1.1.cmml" xref="S4.SS2.SSS3.p4.2.m2.1.1"><ci id="S4.SS2.SSS3.p4.2.m2.1.1.1.cmml" xref="S4.SS2.SSS3.p4.2.m2.1.1.1">~</ci><ci id="S4.SS2.SSS3.p4.2.m2.1.1.2.cmml" xref="S4.SS2.SSS3.p4.2.m2.1.1.2">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p4.2.m2.1c">\tilde{\mathbf{x}}</annotation></semantics></math>를 복구하도록 트레이닝된다. 형식적으로, DAE의 트레이닝 목적은 다음과 같이 표시된다:</p>
<table id="S4.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E7.m1.2" class="ltx_Math" alttext="\mathcal{L}_{DAE}(\mathbf{x})=\log P(\tilde{\mathbf{x}}|\mathbf{x}_{\backslash\tilde{\mathbf{x}}})." display="block"><semantics id="S4.E7.m1.2a"><mrow id="S4.E7.m1.2.2.1" xref="S4.E7.m1.2.2.1.1.cmml"><mrow id="S4.E7.m1.2.2.1.1" xref="S4.E7.m1.2.2.1.1.cmml"><mrow id="S4.E7.m1.2.2.1.1.3" xref="S4.E7.m1.2.2.1.1.3.cmml"><msub id="S4.E7.m1.2.2.1.1.3.2" xref="S4.E7.m1.2.2.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E7.m1.2.2.1.1.3.2.2" xref="S4.E7.m1.2.2.1.1.3.2.2.cmml">ℒ</mi><mrow id="S4.E7.m1.2.2.1.1.3.2.3" xref="S4.E7.m1.2.2.1.1.3.2.3.cmml"><mi id="S4.E7.m1.2.2.1.1.3.2.3.2" xref="S4.E7.m1.2.2.1.1.3.2.3.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.2.2.1.1.3.2.3.1" xref="S4.E7.m1.2.2.1.1.3.2.3.1.cmml">​</mo><mi id="S4.E7.m1.2.2.1.1.3.2.3.3" xref="S4.E7.m1.2.2.1.1.3.2.3.3.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.2.2.1.1.3.2.3.1a" xref="S4.E7.m1.2.2.1.1.3.2.3.1.cmml">​</mo><mi id="S4.E7.m1.2.2.1.1.3.2.3.4" xref="S4.E7.m1.2.2.1.1.3.2.3.4.cmml">E</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E7.m1.2.2.1.1.3.1" xref="S4.E7.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S4.E7.m1.2.2.1.1.3.3.2" xref="S4.E7.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S4.E7.m1.2.2.1.1.3.3.2.1" xref="S4.E7.m1.2.2.1.1.3.cmml">(</mo><mi id="S4.E7.m1.1.1" xref="S4.E7.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.E7.m1.2.2.1.1.3.3.2.2" xref="S4.E7.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S4.E7.m1.2.2.1.1.2" xref="S4.E7.m1.2.2.1.1.2.cmml">=</mo><mrow id="S4.E7.m1.2.2.1.1.1" xref="S4.E7.m1.2.2.1.1.1.cmml"><mrow id="S4.E7.m1.2.2.1.1.1.3" xref="S4.E7.m1.2.2.1.1.1.3.cmml"><mi id="S4.E7.m1.2.2.1.1.1.3.1" xref="S4.E7.m1.2.2.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S4.E7.m1.2.2.1.1.1.3a" xref="S4.E7.m1.2.2.1.1.1.3.cmml">⁡</mo><mi id="S4.E7.m1.2.2.1.1.1.3.2" xref="S4.E7.m1.2.2.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E7.m1.2.2.1.1.1.2" xref="S4.E7.m1.2.2.1.1.1.2.cmml">​</mo><mrow id="S4.E7.m1.2.2.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E7.m1.2.2.1.1.1.1.1.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E7.m1.2.2.1.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.E7.m1.2.2.1.1.1.1.1.1.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.2.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.2.2.cmml">𝐱</mi><mo id="S4.E7.m1.2.2.1.1.1.1.1.1.2.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mo fence="false" id="S4.E7.m1.2.2.1.1.1.1.1.1.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1.cmml">|</mo><msub id="S4.E7.m1.2.2.1.1.1.1.1.1.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.3.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.2.cmml">𝐱</mi><mrow id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.1.cmml">\</mo><mover accent="true" id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.cmml"><mi id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.2" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.2.cmml">𝐱</mi><mo id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.1" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.1.cmml">~</mo></mover></mrow></msub></mrow><mo stretchy="false" id="S4.E7.m1.2.2.1.1.1.1.1.3" xref="S4.E7.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S4.E7.m1.2.2.1.2" xref="S4.E7.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.2b"><apply id="S4.E7.m1.2.2.1.1.cmml" xref="S4.E7.m1.2.2.1"><eq id="S4.E7.m1.2.2.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.2"></eq><apply id="S4.E7.m1.2.2.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.3"><times id="S4.E7.m1.2.2.1.1.3.1.cmml" xref="S4.E7.m1.2.2.1.1.3.1"></times><apply id="S4.E7.m1.2.2.1.1.3.2.cmml" xref="S4.E7.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.3.2.1.cmml" xref="S4.E7.m1.2.2.1.1.3.2">subscript</csymbol><ci id="S4.E7.m1.2.2.1.1.3.2.2.cmml" xref="S4.E7.m1.2.2.1.1.3.2.2">ℒ</ci><apply id="S4.E7.m1.2.2.1.1.3.2.3.cmml" xref="S4.E7.m1.2.2.1.1.3.2.3"><times id="S4.E7.m1.2.2.1.1.3.2.3.1.cmml" xref="S4.E7.m1.2.2.1.1.3.2.3.1"></times><ci id="S4.E7.m1.2.2.1.1.3.2.3.2.cmml" xref="S4.E7.m1.2.2.1.1.3.2.3.2">𝐷</ci><ci id="S4.E7.m1.2.2.1.1.3.2.3.3.cmml" xref="S4.E7.m1.2.2.1.1.3.2.3.3">𝐴</ci><ci id="S4.E7.m1.2.2.1.1.3.2.3.4.cmml" xref="S4.E7.m1.2.2.1.1.3.2.3.4">𝐸</ci></apply></apply><ci id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1">𝐱</ci></apply><apply id="S4.E7.m1.2.2.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1"><times id="S4.E7.m1.2.2.1.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.1.2"></times><apply id="S4.E7.m1.2.2.1.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.1.3"><log id="S4.E7.m1.2.2.1.1.1.3.1.cmml" xref="S4.E7.m1.2.2.1.1.1.3.1"></log><ci id="S4.E7.m1.2.2.1.1.1.3.2.cmml" xref="S4.E7.m1.2.2.1.1.1.3.2">𝑃</ci></apply><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S4.E7.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.1">conditional</csymbol><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.2"><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.2.1">~</ci><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.2.2">𝐱</ci></apply><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.2">𝐱</ci><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3"><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.1">\</ci><csymbol cd="latexml" id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.2">absent</csymbol><apply id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3"><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.1.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.1">~</ci><ci id="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.2.cmml" xref="S4.E7.m1.2.2.1.1.1.1.1.1.3.3.3.2">𝐱</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.2c">\mathcal{L}_{DAE}(\mathbf{x})=\log P(\tilde{\mathbf{x}}|\mathbf{x}_{\backslash\tilde{\mathbf{x}}}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS2.SSS3.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS3.p5.1">그러나 DAE 작업은 LM 작업보다 실행이 더 복잡해 보인다. 그 결과, 대형 언어 모델을 사전 훈련하는 데 널리 사용되지 않았다. DAE를 사전 훈련 목표로 삼는 기존의 LLM에는 T5<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>와 GLM-130B<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>가 있다. 이러한 모델은 주로 자기회귀 방식으로 교체된 경간을 복구하도록 훈련된다.</p>
</div>
<div id="S4.SS2.SSS3.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS3.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS3.p6.1.1">Mixture-of-Denoisers. UL2 손실이라고도 하는 MoD(Mixture-of-Denoisers) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib89" title="">89</a>]</cite>는 사전 훈련 언어 모델에 대한 통일된 목표로 도입되었다. MoD는 LM과 DAE 목표를 모두 다른 유형의 노이즈 제거 작업, 즉 S-denoiser(LM), R-denoiser(DAE, 짧은 스팬 및 낮은 부패), X-denoiser(DAE, 긴 스팬 또는 높은 부패)로 간주한다. 세 가지 노이즈 제거 작업 중 S-denoiser는 기존의 LM 목적(식 (<a class="ltx_ref" href="#S4.E6" title="In 4.2.3 Pre-training Tasks ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>))과 유사하지만 R-denoiser와 X-denoiser는 DAE 목적(식 (<a class="ltx_ref" href="#S4.E7" title="In 4.2.3 Pre-training Tasks ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>))과 유사하지만 스팬의 길이와 손상된 텍스트의 비율에서 서로 다르다. 다른 특수 토큰으로 시작된 입력 문장의 경우(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS3.p6.1.2">i.e.,</em> {<span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS3.p6.1.3">[R]</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS3.p6.1.4">[S]</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS3.p6.1.5">[X]</span>}), 해당 데노이저를 사용하여 모델을 최적화합니다. MoD는 최신 PaLM 2 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib120" title="">120</a>]</cite>에 적용되었다.</p>
</div>
<figure id="S4.F10" class="ltx_figure">
<table id="S4.F10.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S4.F10.1.1" class="ltx_tr">
<td id="S4.F10.1.1.1" class="ltx_td ltx_align_center" colspan="6">I am sleepy. I start a pot of _____</td>
</tr>
<tr id="S4.F10.1.2" class="ltx_tr">
<td id="S4.F10.1.2.1" class="ltx_td ltx_align_left ltx_border_t">coffee</td>
<td id="S4.F10.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.661</td>
<td id="S4.F10.1.2.3" class="ltx_td ltx_align_left ltx_border_t">strong</td>
<td id="S4.F10.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.008</td>
<td id="S4.F10.1.2.5" class="ltx_td ltx_align_left ltx_border_t">soup</td>
<td id="S4.F10.1.2.6" class="ltx_td ltx_align_center ltx_border_t">0.005</td>
</tr>
<tr id="S4.F10.1.3" class="ltx_tr">
<td id="S4.F10.1.3.1" class="ltx_td ltx_align_left">water</td>
<td id="S4.F10.1.3.2" class="ltx_td ltx_align_center ltx_border_r">0.119</td>
<td id="S4.F10.1.3.3" class="ltx_td ltx_align_left">black</td>
<td id="S4.F10.1.3.4" class="ltx_td ltx_align_center ltx_border_r">0.008</td>
<td id="S4.F10.1.3.5" class="ltx_td ltx_align_left">…</td>
<td id="S4.F10.1.3.6" class="ltx_td ltx_align_center">…</td>
</tr>
<tr id="S4.F10.1.4" class="ltx_tr">
<td id="S4.F10.1.4.1" class="ltx_td ltx_align_left">tea</td>
<td id="S4.F10.1.4.2" class="ltx_td ltx_align_center ltx_border_r">0.057</td>
<td id="S4.F10.1.4.3" class="ltx_td ltx_align_left">hot</td>
<td id="S4.F10.1.4.4" class="ltx_td ltx_align_center ltx_border_r">0.007</td>
<td id="S4.F10.1.4.5" class="ltx_td ltx_align_left">happy</td>
<td id="S4.F10.1.4.6" class="ltx_td ltx_align_center">4.3e-6</td>
</tr>
<tr id="S4.F10.1.5" class="ltx_tr">
<td id="S4.F10.1.5.1" class="ltx_td ltx_align_left">rice</td>
<td id="S4.F10.1.5.2" class="ltx_td ltx_align_center ltx_border_r">0.017</td>
<td id="S4.F10.1.5.3" class="ltx_td ltx_align_left">oat</td>
<td id="S4.F10.1.5.4" class="ltx_td ltx_align_center ltx_border_r">0.006</td>
<td id="S4.F10.1.5.5" class="ltx_td ltx_align_left">Boh</td>
<td id="S4.F10.1.5.6" class="ltx_td ltx_align_center">4.3e-6</td>
</tr>
<tr id="S4.F10.1.6" class="ltx_tr">
<td id="S4.F10.1.6.1" class="ltx_td ltx_align_left">chai</td>
<td id="S4.F10.1.6.2" class="ltx_td ltx_align_center ltx_border_r">0.012</td>
<td id="S4.F10.1.6.3" class="ltx_td ltx_align_left">beans</td>
<td id="S4.F10.1.6.4" class="ltx_td ltx_align_center ltx_border_r">0.006</td>
<td id="S4.F10.1.6.5" class="ltx_td ltx_align_left">…</td>
<td id="S4.F10.1.6.6" class="ltx_td ltx_align_center">…</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 10:</span>The probability distribution over the vocabulary in descending order for the next token of the context "<em class="ltx_emph ltx_font_italic" id="S4.F10.3.1">I am sleepy. I start a pot of</em>." 논의의 용이성을 위해, 이 예는 서브워드 유닛 대신에 워드 유닛으로 주어진다.</figcaption>
</figure>
</section>
<section id="S4.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4 </span>Long Context Modeling</h4>

<div id="S4.SS2.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p1.1">실제 응용에서 PDF 처리 및 스토리 작성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib286" title="">286</a>]</cite>와 같은 LLM의 긴 컨텍스트 모델링 용량에 대한 요구가 증가하고 있다. 많은 폐쇄 소스 LLM은 긴 텍스트 처리를 위한 전문적인 지원을 제공한다. 예를 들어 OpenAI는 128K 컨텍스트 창을 가진 GPT-4 Turbo를, Anthropic은 200K 컨텍스트 창을 가진 Claude 2.1을 방출한다. 긴 컨텍스트 모델링 능력을 향상시키기 위해 일반적으로 위치 임베딩의 크기 조정과 컨텍스트 윈도우의 적응이라는 두 가지 실행 가능한 방향이 있다. 다음으로, 두 부분에 대해 상세히 소개한다.</p>
</div>
<div id="S4.SS2.SSS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS4.p2.1.1">Scaling Position Embeddings. </span> Transformer 기반 LLMs은 최대 학습 길이 내에서 효과적인 위치 임베딩을 학습할 수 있다. 따라서, LLM들을 최대 트레이닝 길이를 넘어 언어 태스크들에 적응시킬 때, 더 큰 포지션 인덱스들로 스케일링하는 것이 필요하다. 일부 특정 위치 임베딩은 훈련 길이를 넘어 텍스트로 일반화하는 특정 정도의 능력을 갖는 것으로 나타났으며, 이는 형식적으로 T5 바이어스 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>, ALiBi <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib264" title="">264</a>]</cite>, xPos <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib277" title="">277</a>]</cite> 및 심지어 NoPE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib287" title="">287</a>]</cite>를 포함하는 <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS4.p2.1.2">extrapolation capability</span>이라고 불린다. 그러나, 기존의 위치 임베딩 방법 중 하나인 RoPE는 경험적 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib240" title="">240</a>]</cite>에서 제한된 외삽 능력을 보인다. 아래에서는 RoPE를 더 긴 텍스트로 확장할 수 있는 몇 가지 방법에 대해 논의한다.</p>
</div>
<div id="S4.SS2.SSS4.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p3.3"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p3.1.m1.1"><semantics id="S4.SS2.SSS4.p3.1.m1.1a"><mo id="S4.SS2.SSS4.p3.1.m1.1.1" xref="S4.SS2.SSS4.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p3.1.m1.1b"><ci id="S4.SS2.SSS4.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p3.3.1">Direct model fine-tuning. </em> LLM을 긴 컨텍스트 창에 적용하기 위해 간단한 접근법은 원하는 길이로 긴 텍스트에서 모델을 직접 미세 조정하는 것이다. 컨텍스트 확장은 다단계 접근법에서 증가된 길이로 스케줄링될 수 있다(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p3.3.2">e.g.,</em>2K <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p3.2.m2.1"><semantics id="S4.SS2.SSS4.p3.2.m2.1a"><mo id="S4.SS2.SSS4.p3.2.m2.1.1" stretchy="false" xref="S4.SS2.SSS4.p3.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p3.2.m2.1b"><ci id="S4.SS2.SSS4.p3.2.m2.1.1.cmml" xref="S4.SS2.SSS4.p3.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p3.2.m2.1c">\rightarrow</annotation></semantics></math>8K <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p3.3.m3.1"><semantics id="S4.SS2.SSS4.p3.3.m3.1a"><mo id="S4.SS2.SSS4.p3.3.m3.1.1" stretchy="false" xref="S4.SS2.SSS4.p3.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p3.3.m3.1b"><ci id="S4.SS2.SSS4.p3.3.m3.1.1.cmml" xref="S4.SS2.SSS4.p3.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p3.3.m3.1c">\rightarrow</annotation></semantics></math>32K). 효과적인 확장을 수행하기 위해서는 훈련을 위해 특별히 준비된 긴 텍스트가 필요하다. 특히, 최근 일부 연구에서는 긴 컨텍스트 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib288" title="">288</a>]</cite>에서 학습 텍스트의 길이보다 품질이 더 중요하다는 것을 보여주었다. 그러나 최근 연구에서는 긴 텍스트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib240" title="">240</a>]</cite>에 LLM을 적용할 때 미세 조정 접근법이 본질적으로 느린 경향이 있음을 강조했다.</p>
</div>
<div id="S4.SS2.SSS4.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p4.5"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p4.1.m1.1"><semantics id="S4.SS2.SSS4.p4.1.m1.1a"><mo id="S4.SS2.SSS4.p4.1.m1.1.1" xref="S4.SS2.SSS4.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p4.1.m1.1b"><ci id="S4.SS2.SSS4.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p4.5.1">Position interpolation. </em> 이 방법은 사전 훈련 동안 분포 외 회전 각도를 피하기 위해 원래 컨텍스트 창 내의 위치 인덱스를 다운스케일링합니다. 보다 구체적으로, 이 접근법은 모든 위치 인덱스들에 계수 <math alttext="L/L^{\prime}" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p4.2.m2.1"><semantics id="S4.SS2.SSS4.p4.2.m2.1a"><mrow id="S4.SS2.SSS4.p4.2.m2.1.1" xref="S4.SS2.SSS4.p4.2.m2.1.1.cmml"><mi id="S4.SS2.SSS4.p4.2.m2.1.1.2" xref="S4.SS2.SSS4.p4.2.m2.1.1.2.cmml">L</mi><mo id="S4.SS2.SSS4.p4.2.m2.1.1.1" xref="S4.SS2.SSS4.p4.2.m2.1.1.1.cmml">/</mo><msup id="S4.SS2.SSS4.p4.2.m2.1.1.3" xref="S4.SS2.SSS4.p4.2.m2.1.1.3.cmml"><mi id="S4.SS2.SSS4.p4.2.m2.1.1.3.2" xref="S4.SS2.SSS4.p4.2.m2.1.1.3.2.cmml">L</mi><mo id="S4.SS2.SSS4.p4.2.m2.1.1.3.3" xref="S4.SS2.SSS4.p4.2.m2.1.1.3.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p4.2.m2.1b"><apply id="S4.SS2.SSS4.p4.2.m2.1.1.cmml" xref="S4.SS2.SSS4.p4.2.m2.1.1"><divide id="S4.SS2.SSS4.p4.2.m2.1.1.1.cmml" xref="S4.SS2.SSS4.p4.2.m2.1.1.1"></divide><ci id="S4.SS2.SSS4.p4.2.m2.1.1.2.cmml" xref="S4.SS2.SSS4.p4.2.m2.1.1.2">𝐿</ci><apply id="S4.SS2.SSS4.p4.2.m2.1.1.3.cmml" xref="S4.SS2.SSS4.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p4.2.m2.1.1.3.1.cmml" xref="S4.SS2.SSS4.p4.2.m2.1.1.3">superscript</csymbol><ci id="S4.SS2.SSS4.p4.2.m2.1.1.3.2.cmml" xref="S4.SS2.SSS4.p4.2.m2.1.1.3.2">𝐿</ci><ci id="S4.SS2.SSS4.p4.2.m2.1.1.3.3.cmml" xref="S4.SS2.SSS4.p4.2.m2.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p4.2.m2.1c">L/L^{\prime}</annotation></semantics></math>(<math alttext="L&lt;L^{\prime}" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p4.3.m3.1"><semantics id="S4.SS2.SSS4.p4.3.m3.1a"><mrow id="S4.SS2.SSS4.p4.3.m3.1.1" xref="S4.SS2.SSS4.p4.3.m3.1.1.cmml"><mi id="S4.SS2.SSS4.p4.3.m3.1.1.2" xref="S4.SS2.SSS4.p4.3.m3.1.1.2.cmml">L</mi><mo id="S4.SS2.SSS4.p4.3.m3.1.1.1" xref="S4.SS2.SSS4.p4.3.m3.1.1.1.cmml">&lt;</mo><msup id="S4.SS2.SSS4.p4.3.m3.1.1.3" xref="S4.SS2.SSS4.p4.3.m3.1.1.3.cmml"><mi id="S4.SS2.SSS4.p4.3.m3.1.1.3.2" xref="S4.SS2.SSS4.p4.3.m3.1.1.3.2.cmml">L</mi><mo id="S4.SS2.SSS4.p4.3.m3.1.1.3.3" xref="S4.SS2.SSS4.p4.3.m3.1.1.3.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p4.3.m3.1b"><apply id="S4.SS2.SSS4.p4.3.m3.1.1.cmml" xref="S4.SS2.SSS4.p4.3.m3.1.1"><lt id="S4.SS2.SSS4.p4.3.m3.1.1.1.cmml" xref="S4.SS2.SSS4.p4.3.m3.1.1.1"></lt><ci id="S4.SS2.SSS4.p4.3.m3.1.1.2.cmml" xref="S4.SS2.SSS4.p4.3.m3.1.1.2">𝐿</ci><apply id="S4.SS2.SSS4.p4.3.m3.1.1.3.cmml" xref="S4.SS2.SSS4.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p4.3.m3.1.1.3.1.cmml" xref="S4.SS2.SSS4.p4.3.m3.1.1.3">superscript</csymbol><ci id="S4.SS2.SSS4.p4.3.m3.1.1.3.2.cmml" xref="S4.SS2.SSS4.p4.3.m3.1.1.3.2">𝐿</ci><ci id="S4.SS2.SSS4.p4.3.m3.1.1.3.3.cmml" xref="S4.SS2.SSS4.p4.3.m3.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p4.3.m3.1c">L&lt;L^{\prime}</annotation></semantics></math>)를 곱하고, 여기서 <math alttext="L" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p4.4.m4.1"><semantics id="S4.SS2.SSS4.p4.4.m4.1a"><mi id="S4.SS2.SSS4.p4.4.m4.1.1" xref="S4.SS2.SSS4.p4.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p4.4.m4.1b"><ci id="S4.SS2.SSS4.p4.4.m4.1.1.cmml" xref="S4.SS2.SSS4.p4.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p4.4.m4.1c">L</annotation></semantics></math> 및 <math alttext="L^{\prime}" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p4.5.m5.1"><semantics id="S4.SS2.SSS4.p4.5.m5.1a"><msup id="S4.SS2.SSS4.p4.5.m5.1.1" xref="S4.SS2.SSS4.p4.5.m5.1.1.cmml"><mi id="S4.SS2.SSS4.p4.5.m5.1.1.2" xref="S4.SS2.SSS4.p4.5.m5.1.1.2.cmml">L</mi><mo id="S4.SS2.SSS4.p4.5.m5.1.1.3" xref="S4.SS2.SSS4.p4.5.m5.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p4.5.m5.1b"><apply id="S4.SS2.SSS4.p4.5.m5.1.1.cmml" xref="S4.SS2.SSS4.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p4.5.m5.1.1.1.cmml" xref="S4.SS2.SSS4.p4.5.m5.1.1">superscript</csymbol><ci id="S4.SS2.SSS4.p4.5.m5.1.1.2.cmml" xref="S4.SS2.SSS4.p4.5.m5.1.1.2">𝐿</ci><ci id="S4.SS2.SSS4.p4.5.m5.1.1.3.cmml" xref="S4.SS2.SSS4.p4.5.m5.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p4.5.m5.1c">L^{\prime}</annotation></semantics></math>는 각각 오리지널 및 타깃 컨텍스트 윈도우 길이를 나타낸다. 실험 결과 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib240" title="">240</a>]</cite>는 이 방법이 직접 모델 미세 조정에 대한 위의 접근 방식과 비교하여 컨텍스트 창을 효과적이고 효율적으로 확장할 수 있음을 보여주었다. 그러나 이 기술은 더 짧은 텍스트<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib240" title="">240</a>, <a class="ltx_ref" href="#bib.bib290" title="">290</a>]</cite>를 처리할 때 모델의 성능에 부정적인 영향을 미칠 수 있다는 점에 주목할 필요가 있다.</p>
</div>
<div id="S4.SS2.SSS4.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p5.1.m1.1"><semantics id="S4.SS2.SSS4.p5.1.m1.1a"><mo id="S4.SS2.SSS4.p5.1.m1.1.1" xref="S4.SS2.SSS4.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p5.1.m1.1b"><ci id="S4.SS2.SSS4.p5.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p5.1.1">Position truncation. </em> 분포 외 회전 각도에 의해 제기되는 문제를 완화하기 위해, 또 다른 실용적인 접근법은 최대 트레이닝 길이의 요구 사항을 만족시키기 위해 더 긴 상대 위치를 절단하는 것이다. 구체적으로 ReRoPE와 LeakyReRoPE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib291" title="">291</a>]</cite>는 최대 학습 길이보다 작은 미리 정의된 윈도우 길이를 도입한다. 이 미리 정의된 윈도우 내의 위치 인덱스는 유지되는 반면, 윈도우를 벗어난 인덱스들은 미리 정의된 윈도우 길이로 잘려지거나 최대 트레이닝 길이와 정렬되도록 보간된다. 이 전략은 지역 위치 관계를 예약하고 외삽 능력을 향상시킬 수 있다. 그러나, 이 방법은 추가적인 계산 예산을 수용하여 주의 행렬을 두 번 계산해야 한다.</p>
</div>
<div id="S4.SS2.SSS4.p6" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p6.5"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p6.1.m1.1"><semantics id="S4.SS2.SSS4.p6.1.m1.1a"><mo id="S4.SS2.SSS4.p6.1.m1.1.1" xref="S4.SS2.SSS4.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p6.1.m1.1b"><ci id="S4.SS2.SSS4.p6.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p6.5.1">Base modification. </em> LLMs는 보통 미리 설정된 최대 트레이닝 길이, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p6.5.2">e.g.,</em> 4096 in Llama 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>로 트레이닝된다. 그러나 RoPE의 특정 차원의 파장은 더 긴 텍스트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib276" title="">276</a>]</cite>에 대한 학습 길이를 초과할 수 있으므로 언어 모델이 이러한 차원의 충분한 학습을 거치지 않았다(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p6.5.3">i.e.,</em> a complete rotation cycle). 따라서 LLM을 더 긴 텍스트에 적용할 때 특정 치수에 대한 회전 각도는 훈련 단계 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib292" title="">292</a>]</cite>에서 볼 수 없다. 고정 회전 각도 <math alttext="t\cdot\theta_{i}" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p6.2.m2.1"><semantics id="S4.SS2.SSS4.p6.2.m2.1a"><mrow id="S4.SS2.SSS4.p6.2.m2.1.1" xref="S4.SS2.SSS4.p6.2.m2.1.1.cmml"><mi id="S4.SS2.SSS4.p6.2.m2.1.1.2" xref="S4.SS2.SSS4.p6.2.m2.1.1.2.cmml">t</mi><mo id="S4.SS2.SSS4.p6.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.SSS4.p6.2.m2.1.1.1.cmml">⋅</mo><msub id="S4.SS2.SSS4.p6.2.m2.1.1.3" xref="S4.SS2.SSS4.p6.2.m2.1.1.3.cmml"><mi id="S4.SS2.SSS4.p6.2.m2.1.1.3.2" xref="S4.SS2.SSS4.p6.2.m2.1.1.3.2.cmml">θ</mi><mi id="S4.SS2.SSS4.p6.2.m2.1.1.3.3" xref="S4.SS2.SSS4.p6.2.m2.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p6.2.m2.1b"><apply id="S4.SS2.SSS4.p6.2.m2.1.1.cmml" xref="S4.SS2.SSS4.p6.2.m2.1.1"><ci id="S4.SS2.SSS4.p6.2.m2.1.1.1.cmml" xref="S4.SS2.SSS4.p6.2.m2.1.1.1">⋅</ci><ci id="S4.SS2.SSS4.p6.2.m2.1.1.2.cmml" xref="S4.SS2.SSS4.p6.2.m2.1.1.2">𝑡</ci><apply id="S4.SS2.SSS4.p6.2.m2.1.1.3.cmml" xref="S4.SS2.SSS4.p6.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p6.2.m2.1.1.3.1.cmml" xref="S4.SS2.SSS4.p6.2.m2.1.1.3">subscript</csymbol><ci id="S4.SS2.SSS4.p6.2.m2.1.1.3.2.cmml" xref="S4.SS2.SSS4.p6.2.m2.1.1.3.2">𝜃</ci><ci id="S4.SS2.SSS4.p6.2.m2.1.1.3.3.cmml" xref="S4.SS2.SSS4.p6.2.m2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p6.2.m2.1c">t\cdot\theta_{i}</annotation></semantics></math>, 더 작은 기저 <math alttext="\theta_{i}" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p6.3.m3.1"><semantics id="S4.SS2.SSS4.p6.3.m3.1a"><msub id="S4.SS2.SSS4.p6.3.m3.1.1" xref="S4.SS2.SSS4.p6.3.m3.1.1.cmml"><mi id="S4.SS2.SSS4.p6.3.m3.1.1.2" xref="S4.SS2.SSS4.p6.3.m3.1.1.2.cmml">θ</mi><mi id="S4.SS2.SSS4.p6.3.m3.1.1.3" xref="S4.SS2.SSS4.p6.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p6.3.m3.1b"><apply id="S4.SS2.SSS4.p6.3.m3.1.1.cmml" xref="S4.SS2.SSS4.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p6.3.m3.1.1.1.cmml" xref="S4.SS2.SSS4.p6.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.SSS4.p6.3.m3.1.1.2.cmml" xref="S4.SS2.SSS4.p6.3.m3.1.1.2">𝜃</ci><ci id="S4.SS2.SSS4.p6.3.m3.1.1.3.cmml" xref="S4.SS2.SSS4.p6.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p6.3.m3.1c">\theta_{i}</annotation></semantics></math>는 더 큰 거리 <math alttext="t" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p6.4.m4.1"><semantics id="S4.SS2.SSS4.p6.4.m4.1a"><mi id="S4.SS2.SSS4.p6.4.m4.1.1" xref="S4.SS2.SSS4.p6.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p6.4.m4.1b"><ci id="S4.SS2.SSS4.p6.4.m4.1.1.cmml" xref="S4.SS2.SSS4.p6.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p6.4.m4.1c">t</annotation></semantics></math>, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p6.5.4">i.e.,</em> enabling the modeling of longer texts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib276" title="">276</a>, <a class="ltx_ref" href="#bib.bib235" title="">235</a>, <a class="ltx_ref" href="#bib.bib288" title="">288</a>]</cite>. 수학식 <a class="ltx_ref" href="#S4.E4" title="In 4.2.2 Detailed Configuration ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>의 수식 <math alttext="\theta_{i}=b^{-2(i-1)/d}" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p6.5.m5.1"><semantics id="S4.SS2.SSS4.p6.5.m5.1a"><mrow id="S4.SS2.SSS4.p6.5.m5.1.2" xref="S4.SS2.SSS4.p6.5.m5.1.2.cmml"><msub id="S4.SS2.SSS4.p6.5.m5.1.2.2" xref="S4.SS2.SSS4.p6.5.m5.1.2.2.cmml"><mi id="S4.SS2.SSS4.p6.5.m5.1.2.2.2" xref="S4.SS2.SSS4.p6.5.m5.1.2.2.2.cmml">θ</mi><mi id="S4.SS2.SSS4.p6.5.m5.1.2.2.3" xref="S4.SS2.SSS4.p6.5.m5.1.2.2.3.cmml">i</mi></msub><mo id="S4.SS2.SSS4.p6.5.m5.1.2.1" xref="S4.SS2.SSS4.p6.5.m5.1.2.1.cmml">=</mo><msup id="S4.SS2.SSS4.p6.5.m5.1.2.3" xref="S4.SS2.SSS4.p6.5.m5.1.2.3.cmml"><mi id="S4.SS2.SSS4.p6.5.m5.1.2.3.2" xref="S4.SS2.SSS4.p6.5.m5.1.2.3.2.cmml">b</mi><mrow id="S4.SS2.SSS4.p6.5.m5.1.1.1" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.cmml"><mo id="S4.SS2.SSS4.p6.5.m5.1.1.1a" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.cmml">−</mo><mrow id="S4.SS2.SSS4.p6.5.m5.1.1.1.1" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.cmml"><mrow id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.cmml"><mn id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.3" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.3.cmml">2</mn><mo id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.cmml"><mo id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.2" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.2.cmml">i</mi><mo id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.1" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.3" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.2" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.2.cmml">/</mo><mi id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.3" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.3.cmml">d</mi></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p6.5.m5.1b"><apply id="S4.SS2.SSS4.p6.5.m5.1.2.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.2"><eq id="S4.SS2.SSS4.p6.5.m5.1.2.1.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.2.1"></eq><apply id="S4.SS2.SSS4.p6.5.m5.1.2.2.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.2.2"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p6.5.m5.1.2.2.1.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.2.2">subscript</csymbol><ci id="S4.SS2.SSS4.p6.5.m5.1.2.2.2.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.2.2.2">𝜃</ci><ci id="S4.SS2.SSS4.p6.5.m5.1.2.2.3.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.2.2.3">𝑖</ci></apply><apply id="S4.SS2.SSS4.p6.5.m5.1.2.3.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.2.3"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p6.5.m5.1.2.3.1.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.2.3">superscript</csymbol><ci id="S4.SS2.SSS4.p6.5.m5.1.2.3.2.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.2.3.2">𝑏</ci><apply id="S4.SS2.SSS4.p6.5.m5.1.1.1.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1"><minus id="S4.SS2.SSS4.p6.5.m5.1.1.1.2.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1"></minus><apply id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1"><divide id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.2.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.2"></divide><apply id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1"><times id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.2.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.2"></times><cn id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.3.cmml" type="integer" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.3">2</cn><apply id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1"><minus id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.1"></minus><ci id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.2">𝑖</ci><cn id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.1.1.1.1.3">1</cn></apply></apply><ci id="S4.SS2.SSS4.p6.5.m5.1.1.1.1.3.cmml" xref="S4.SS2.SSS4.p6.5.m5.1.1.1.1.3">𝑑</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p6.5.m5.1c">\theta_{i}=b^{-2(i-1)/d}</annotation></semantics></math>에 따르면, 기저를 감소시키는 것은 기저의 값을 증가시킴으로써 달성될 수 있다. 또한, 기저를 감소시키는 것은 또한 트레이닝 길이 미만의 모든 차원들의 파장들을 재스케일링하는 것을 도울 수 있는 반면, LLMs들을 긴 컨텍스트 윈도우들 [cite idx=2></cite>]에 적응시키기 위해 종종 연속적인 사전 트레이닝이 필요하다. 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib292" title="">292</a>]</cite>는 이 두 가지 염기 수정 방법을 경험적으로 비교한 결과, 염기를 줄이면 훈련 길이 이상의 외삽 용량이 더 나은 반면, 염기를 늘리면 훈련 길이 내에서 더 나은 외삽 용량을 보이는 것으로 나타났다.</p>
</div>
<div id="S4.SS2.SSS4.p7" class="ltx_para">
<p id="S4.SS2.SSS4.p7.8" class="ltx_p"><math id="S4.SS2.SSS4.p7.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S4.SS2.SSS4.p7.1.m1.1a"><mo id="S4.SS2.SSS4.p7.1.m1.1.1" xref="S4.SS2.SSS4.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p7.1.m1.1b"><ci id="S4.SS2.SSS4.p7.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p7.1.m1.1c">\bullet</annotation></semantics></math> <em id="S4.SS2.SSS4.p7.8.1" class="ltx_emph ltx_font_italic">Basis truncation.</em> Similar to the base modification, the truncation of the basis also concentrates on dealing with the singular dimensions with wavelengths exceeding the training length&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib293" title="" class="ltx_ref">293</a>]</cite>. According to the definition <math id="S4.SS2.SSS4.p7.2.m2.1" class="ltx_Math" alttext="\lambda_{i}=2\pi/\theta_{i}" display="inline"><semantics id="S4.SS2.SSS4.p7.2.m2.1a"><mrow id="S4.SS2.SSS4.p7.2.m2.1.1" xref="S4.SS2.SSS4.p7.2.m2.1.1.cmml"><msub id="S4.SS2.SSS4.p7.2.m2.1.1.2" xref="S4.SS2.SSS4.p7.2.m2.1.1.2.cmml"><mi id="S4.SS2.SSS4.p7.2.m2.1.1.2.2" xref="S4.SS2.SSS4.p7.2.m2.1.1.2.2.cmml">λ</mi><mi id="S4.SS2.SSS4.p7.2.m2.1.1.2.3" xref="S4.SS2.SSS4.p7.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS2.SSS4.p7.2.m2.1.1.1" xref="S4.SS2.SSS4.p7.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS2.SSS4.p7.2.m2.1.1.3" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.cmml"><mrow id="S4.SS2.SSS4.p7.2.m2.1.1.3.2" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.2.cmml"><mn id="S4.SS2.SSS4.p7.2.m2.1.1.3.2.2" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS2.SSS4.p7.2.m2.1.1.3.2.1" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.2.1.cmml">​</mo><mi id="S4.SS2.SSS4.p7.2.m2.1.1.3.2.3" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.2.3.cmml">π</mi></mrow><mo id="S4.SS2.SSS4.p7.2.m2.1.1.3.1" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.1.cmml">/</mo><msub id="S4.SS2.SSS4.p7.2.m2.1.1.3.3" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.3.cmml"><mi id="S4.SS2.SSS4.p7.2.m2.1.1.3.3.2" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.3.2.cmml">θ</mi><mi id="S4.SS2.SSS4.p7.2.m2.1.1.3.3.3" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p7.2.m2.1b"><apply id="S4.SS2.SSS4.p7.2.m2.1.1.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1"><eq id="S4.SS2.SSS4.p7.2.m2.1.1.1.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.1"></eq><apply id="S4.SS2.SSS4.p7.2.m2.1.1.2.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p7.2.m2.1.1.2.1.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS2.SSS4.p7.2.m2.1.1.2.2.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.2.2">𝜆</ci><ci id="S4.SS2.SSS4.p7.2.m2.1.1.2.3.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.2.3">𝑖</ci></apply><apply id="S4.SS2.SSS4.p7.2.m2.1.1.3.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3"><divide id="S4.SS2.SSS4.p7.2.m2.1.1.3.1.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.1"></divide><apply id="S4.SS2.SSS4.p7.2.m2.1.1.3.2.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.2"><times id="S4.SS2.SSS4.p7.2.m2.1.1.3.2.1.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.2.1"></times><cn type="integer" id="S4.SS2.SSS4.p7.2.m2.1.1.3.2.2.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.2.2">2</cn><ci id="S4.SS2.SSS4.p7.2.m2.1.1.3.2.3.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.2.3">𝜋</ci></apply><apply id="S4.SS2.SSS4.p7.2.m2.1.1.3.3.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p7.2.m2.1.1.3.3.1.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.3">subscript</csymbol><ci id="S4.SS2.SSS4.p7.2.m2.1.1.3.3.2.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.3.2">𝜃</ci><ci id="S4.SS2.SSS4.p7.2.m2.1.1.3.3.3.cmml" xref="S4.SS2.SSS4.p7.2.m2.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p7.2.m2.1c">\lambda_{i}=2\pi/\theta_{i}</annotation></semantics></math> in Equation&nbsp;<a href="#S4.E5" title="In 4.2.2 Detailed Configuration ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, the dimension with a large wavelength <math id="S4.SS2.SSS4.p7.3.m3.1" class="ltx_Math" alttext="\lambda_{i}" display="inline"><semantics id="S4.SS2.SSS4.p7.3.m3.1a"><msub id="S4.SS2.SSS4.p7.3.m3.1.1" xref="S4.SS2.SSS4.p7.3.m3.1.1.cmml"><mi id="S4.SS2.SSS4.p7.3.m3.1.1.2" xref="S4.SS2.SSS4.p7.3.m3.1.1.2.cmml">λ</mi><mi id="S4.SS2.SSS4.p7.3.m3.1.1.3" xref="S4.SS2.SSS4.p7.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p7.3.m3.1b"><apply id="S4.SS2.SSS4.p7.3.m3.1.1.cmml" xref="S4.SS2.SSS4.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p7.3.m3.1.1.1.cmml" xref="S4.SS2.SSS4.p7.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.SSS4.p7.3.m3.1.1.2.cmml" xref="S4.SS2.SSS4.p7.3.m3.1.1.2">𝜆</ci><ci id="S4.SS2.SSS4.p7.3.m3.1.1.3.cmml" xref="S4.SS2.SSS4.p7.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p7.3.m3.1c">\lambda_{i}</annotation></semantics></math> has a small basis <math id="S4.SS2.SSS4.p7.4.m4.1" class="ltx_Math" alttext="\theta_{i}" display="inline"><semantics id="S4.SS2.SSS4.p7.4.m4.1a"><msub id="S4.SS2.SSS4.p7.4.m4.1.1" xref="S4.SS2.SSS4.p7.4.m4.1.1.cmml"><mi id="S4.SS2.SSS4.p7.4.m4.1.1.2" xref="S4.SS2.SSS4.p7.4.m4.1.1.2.cmml">θ</mi><mi id="S4.SS2.SSS4.p7.4.m4.1.1.3" xref="S4.SS2.SSS4.p7.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p7.4.m4.1b"><apply id="S4.SS2.SSS4.p7.4.m4.1.1.cmml" xref="S4.SS2.SSS4.p7.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p7.4.m4.1.1.1.cmml" xref="S4.SS2.SSS4.p7.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.SSS4.p7.4.m4.1.1.2.cmml" xref="S4.SS2.SSS4.p7.4.m4.1.1.2">𝜃</ci><ci id="S4.SS2.SSS4.p7.4.m4.1.1.3.cmml" xref="S4.SS2.SSS4.p7.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p7.4.m4.1c">\theta_{i}</annotation></semantics></math> accordingly. Based on this observation, this approach first defines a basis range <math id="S4.SS2.SSS4.p7.5.m5.2" class="ltx_Math" alttext="[a,c]" display="inline"><semantics id="S4.SS2.SSS4.p7.5.m5.2a"><mrow id="S4.SS2.SSS4.p7.5.m5.2.3.2" xref="S4.SS2.SSS4.p7.5.m5.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.SSS4.p7.5.m5.2.3.2.1" xref="S4.SS2.SSS4.p7.5.m5.2.3.1.cmml">[</mo><mi id="S4.SS2.SSS4.p7.5.m5.1.1" xref="S4.SS2.SSS4.p7.5.m5.1.1.cmml">a</mi><mo id="S4.SS2.SSS4.p7.5.m5.2.3.2.2" xref="S4.SS2.SSS4.p7.5.m5.2.3.1.cmml">,</mo><mi id="S4.SS2.SSS4.p7.5.m5.2.2" xref="S4.SS2.SSS4.p7.5.m5.2.2.cmml">c</mi><mo stretchy="false" id="S4.SS2.SSS4.p7.5.m5.2.3.2.3" xref="S4.SS2.SSS4.p7.5.m5.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p7.5.m5.2b"><interval closure="closed" id="S4.SS2.SSS4.p7.5.m5.2.3.1.cmml" xref="S4.SS2.SSS4.p7.5.m5.2.3.2"><ci id="S4.SS2.SSS4.p7.5.m5.1.1.cmml" xref="S4.SS2.SSS4.p7.5.m5.1.1">𝑎</ci><ci id="S4.SS2.SSS4.p7.5.m5.2.2.cmml" xref="S4.SS2.SSS4.p7.5.m5.2.2">𝑐</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p7.5.m5.2c">[a,c]</annotation></semantics></math>.  Given the basis range, the value of basis is modified according to the following ways: (1) when <math id="S4.SS2.SSS4.p7.6.m6.1" class="ltx_Math" alttext="\theta_{i}\geq c" display="inline"><semantics id="S4.SS2.SSS4.p7.6.m6.1a"><mrow id="S4.SS2.SSS4.p7.6.m6.1.1" xref="S4.SS2.SSS4.p7.6.m6.1.1.cmml"><msub id="S4.SS2.SSS4.p7.6.m6.1.1.2" xref="S4.SS2.SSS4.p7.6.m6.1.1.2.cmml"><mi id="S4.SS2.SSS4.p7.6.m6.1.1.2.2" xref="S4.SS2.SSS4.p7.6.m6.1.1.2.2.cmml">θ</mi><mi id="S4.SS2.SSS4.p7.6.m6.1.1.2.3" xref="S4.SS2.SSS4.p7.6.m6.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS2.SSS4.p7.6.m6.1.1.1" xref="S4.SS2.SSS4.p7.6.m6.1.1.1.cmml">≥</mo><mi id="S4.SS2.SSS4.p7.6.m6.1.1.3" xref="S4.SS2.SSS4.p7.6.m6.1.1.3.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p7.6.m6.1b"><apply id="S4.SS2.SSS4.p7.6.m6.1.1.cmml" xref="S4.SS2.SSS4.p7.6.m6.1.1"><geq id="S4.SS2.SSS4.p7.6.m6.1.1.1.cmml" xref="S4.SS2.SSS4.p7.6.m6.1.1.1"></geq><apply id="S4.SS2.SSS4.p7.6.m6.1.1.2.cmml" xref="S4.SS2.SSS4.p7.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p7.6.m6.1.1.2.1.cmml" xref="S4.SS2.SSS4.p7.6.m6.1.1.2">subscript</csymbol><ci id="S4.SS2.SSS4.p7.6.m6.1.1.2.2.cmml" xref="S4.SS2.SSS4.p7.6.m6.1.1.2.2">𝜃</ci><ci id="S4.SS2.SSS4.p7.6.m6.1.1.2.3.cmml" xref="S4.SS2.SSS4.p7.6.m6.1.1.2.3">𝑖</ci></apply><ci id="S4.SS2.SSS4.p7.6.m6.1.1.3.cmml" xref="S4.SS2.SSS4.p7.6.m6.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p7.6.m6.1c">\theta_{i}\geq c</annotation></semantics></math>, the value is retained, (2) when <math id="S4.SS2.SSS4.p7.7.m7.1" class="ltx_Math" alttext="\theta_{i}\leq a" display="inline"><semantics id="S4.SS2.SSS4.p7.7.m7.1a"><mrow id="S4.SS2.SSS4.p7.7.m7.1.1" xref="S4.SS2.SSS4.p7.7.m7.1.1.cmml"><msub id="S4.SS2.SSS4.p7.7.m7.1.1.2" xref="S4.SS2.SSS4.p7.7.m7.1.1.2.cmml"><mi id="S4.SS2.SSS4.p7.7.m7.1.1.2.2" xref="S4.SS2.SSS4.p7.7.m7.1.1.2.2.cmml">θ</mi><mi id="S4.SS2.SSS4.p7.7.m7.1.1.2.3" xref="S4.SS2.SSS4.p7.7.m7.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS2.SSS4.p7.7.m7.1.1.1" xref="S4.SS2.SSS4.p7.7.m7.1.1.1.cmml">≤</mo><mi id="S4.SS2.SSS4.p7.7.m7.1.1.3" xref="S4.SS2.SSS4.p7.7.m7.1.1.3.cmml">a</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p7.7.m7.1b"><apply id="S4.SS2.SSS4.p7.7.m7.1.1.cmml" xref="S4.SS2.SSS4.p7.7.m7.1.1"><leq id="S4.SS2.SSS4.p7.7.m7.1.1.1.cmml" xref="S4.SS2.SSS4.p7.7.m7.1.1.1"></leq><apply id="S4.SS2.SSS4.p7.7.m7.1.1.2.cmml" xref="S4.SS2.SSS4.p7.7.m7.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p7.7.m7.1.1.2.1.cmml" xref="S4.SS2.SSS4.p7.7.m7.1.1.2">subscript</csymbol><ci id="S4.SS2.SSS4.p7.7.m7.1.1.2.2.cmml" xref="S4.SS2.SSS4.p7.7.m7.1.1.2.2">𝜃</ci><ci id="S4.SS2.SSS4.p7.7.m7.1.1.2.3.cmml" xref="S4.SS2.SSS4.p7.7.m7.1.1.2.3">𝑖</ci></apply><ci id="S4.SS2.SSS4.p7.7.m7.1.1.3.cmml" xref="S4.SS2.SSS4.p7.7.m7.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p7.7.m7.1c">\theta_{i}\leq a</annotation></semantics></math>, the value is set to zero, and (3) when <math id="S4.SS2.SSS4.p7.8.m8.1" class="ltx_Math" alttext="a<\theta_{i}<c" display="inline"><semantics id="S4.SS2.SSS4.p7.8.m8.1a"><mrow id="S4.SS2.SSS4.p7.8.m8.1.1" xref="S4.SS2.SSS4.p7.8.m8.1.1.cmml"><mi id="S4.SS2.SSS4.p7.8.m8.1.1.2" xref="S4.SS2.SSS4.p7.8.m8.1.1.2.cmml">a</mi><mo id="S4.SS2.SSS4.p7.8.m8.1.1.3" xref="S4.SS2.SSS4.p7.8.m8.1.1.3.cmml">&lt;</mo><msub id="S4.SS2.SSS4.p7.8.m8.1.1.4" xref="S4.SS2.SSS4.p7.8.m8.1.1.4.cmml"><mi id="S4.SS2.SSS4.p7.8.m8.1.1.4.2" xref="S4.SS2.SSS4.p7.8.m8.1.1.4.2.cmml">θ</mi><mi id="S4.SS2.SSS4.p7.8.m8.1.1.4.3" xref="S4.SS2.SSS4.p7.8.m8.1.1.4.3.cmml">i</mi></msub><mo id="S4.SS2.SSS4.p7.8.m8.1.1.5" xref="S4.SS2.SSS4.p7.8.m8.1.1.5.cmml">&lt;</mo><mi id="S4.SS2.SSS4.p7.8.m8.1.1.6" xref="S4.SS2.SSS4.p7.8.m8.1.1.6.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p7.8.m8.1b"><apply id="S4.SS2.SSS4.p7.8.m8.1.1.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1"><and id="S4.SS2.SSS4.p7.8.m8.1.1a.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1"></and><apply id="S4.SS2.SSS4.p7.8.m8.1.1b.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1"><lt id="S4.SS2.SSS4.p7.8.m8.1.1.3.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1.3"></lt><ci id="S4.SS2.SSS4.p7.8.m8.1.1.2.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1.2">𝑎</ci><apply id="S4.SS2.SSS4.p7.8.m8.1.1.4.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1.4"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p7.8.m8.1.1.4.1.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1.4">subscript</csymbol><ci id="S4.SS2.SSS4.p7.8.m8.1.1.4.2.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1.4.2">𝜃</ci><ci id="S4.SS2.SSS4.p7.8.m8.1.1.4.3.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1.4.3">𝑖</ci></apply></apply><apply id="S4.SS2.SSS4.p7.8.m8.1.1c.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1"><lt id="S4.SS2.SSS4.p7.8.m8.1.1.5.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1.5"></lt><share href="#S4.SS2.SSS4.p7.8.m8.1.1.4.cmml" id="S4.SS2.SSS4.p7.8.m8.1.1d.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1"></share><ci id="S4.SS2.SSS4.p7.8.m8.1.1.6.cmml" xref="S4.SS2.SSS4.p7.8.m8.1.1.6">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p7.8.m8.1c">a&lt;\theta_{i}&lt;c</annotation></semantics></math>, the value is truncated to a fixed small value. Via basis truncation, the out-of-distribution rotation angles can be avoided at larger position indices. However, this approach does not perform very well at long context tasks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib293" title="" class="ltx_ref">293</a>]</cite>.</p>
</div>
<div id="S4.SS2.SSS4.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS4.p8.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS4.p8.1.1">Adapting Context Window. </span> Transformer 기반 LLMs은 컨텍스트 윈도우가 제한적이기 때문에 컨텍스트 윈도우를 초과하는 긴 시퀀스의 전체 정보를 직접 통합하거나 활용할 수 없다. 제한을 완화하기 위해 아래에서 논의되는 바와 같이 LLM을 긴 컨텍스트에 적응시키는 몇 가지 방법이 제안되었다.</p>
</div>
<div id="S4.SS2.SSS4.p9" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p9.1.m1.1"><semantics id="S4.SS2.SSS4.p9.1.m1.1a"><mo id="S4.SS2.SSS4.p9.1.m1.1.1" xref="S4.SS2.SSS4.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p9.1.m1.1b"><ci id="S4.SS2.SSS4.p9.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p9.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p9.1.1">Parallel context window. </em> Inspired by fusion-in-decoder <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib294" title="">294</a>]</cite>, parallel context window methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib295" title="">295</a>, <a class="ltx_ref" href="#bib.bib296" title="">296</a>]</cite> adopt divide-and-conquer strategy to processing input text. 특히, 입력 텍스트를 다수의 세그먼트로 분할하고, 각각 독립적으로 공유 위치 임베딩으로 인코딩한다. 생성 단계에서, 어텐션 마스크들은 후속 토큰들이 각각의 세그먼트에서의 이전 토큰들에 액세스할 수 있도록 수정된다. 그럼에도 불구하고, 이 방법은 특정 태스크들에 대한 모델 용량을 제약하면서 상이한 세그먼트들의 순서를 구별할 수 없다.</p>
</div>
<div id="S4.SS2.SSS4.p10" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p10.3"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p10.1.m1.1"><semantics id="S4.SS2.SSS4.p10.1.m1.1a"><mo id="S4.SS2.SSS4.p10.1.m1.1.1" xref="S4.SS2.SSS4.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p10.1.m1.1b"><ci id="S4.SS2.SSS4.p10.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p10.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p10.2.1"><math alttext="\Lambda" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p10.2.1.m1.1"><semantics id="S4.SS2.SSS4.p10.2.1.m1.1a"><mi id="S4.SS2.SSS4.p10.2.1.m1.1.1" mathvariant="normal" xref="S4.SS2.SSS4.p10.2.1.m1.1.1.cmml">Λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p10.2.1.m1.1b"><ci id="S4.SS2.SSS4.p10.2.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p10.2.1.m1.1.1">Λ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p10.2.1.m1.1c">\Lambda</annotation></semantics></math>-shaped context window. </em> 일부 선행 연구는 LLMs가 "<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p10.3.2">lost in the middle</em>" phenomenon <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib299" title="">299</a>]</cite>라고 불리는 모든 이전 토큰 중 시작 및 가장 가까운 토큰에 더 큰 주의 가중치를 할당하는 경향이 있음을 보여주었다. 이 관찰을 기반으로 LM-Infinite <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib300" title="">300</a>]</cite> 및 StreamingLLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib298" title="">298</a>]</cite>는 "<math alttext="\Lambda" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p10.3.m2.1"><semantics id="S4.SS2.SSS4.p10.3.m2.1a"><mi id="S4.SS2.SSS4.p10.3.m2.1.1" mathvariant="normal" xref="S4.SS2.SSS4.p10.3.m2.1.1.cmml">Λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p10.3.m2.1b"><ci id="S4.SS2.SSS4.p10.3.m2.1.1.cmml" xref="S4.SS2.SSS4.p10.3.m2.1.1">Λ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p10.3.m2.1c">\Lambda</annotation></semantics></math>-shaped" 어텐션 마스크를 사용할 것을 제안하며, 이는 초기 토큰과 각 쿼리가 참석할 수 있는 가장 가까운 토큰을 선택적으로 보존한 다음 이 범위를 벗어나는 모든 토큰을 폐기한다. 실험은 이 방법이 고정된 메모리 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib298" title="">298</a>]</cite>로 여분의 긴 텍스트 생성을 용이하게 할 수 있음을 보여준다. 그러나 폐기된 토큰 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib298" title="">298</a>]</cite>의 정보를 효과적으로 활용할 수 없기 때문에 프롬프트에서 장거리 종속성을 모델링하는 데 어려움을 겪을 수 있다.</p>
</div>
<div id="S4.SS2.SSS4.p11" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p11.5"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p11.1.m1.1"><semantics id="S4.SS2.SSS4.p11.1.m1.1a"><mo id="S4.SS2.SSS4.p11.1.m1.1.1" xref="S4.SS2.SSS4.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p11.1.m1.1b"><ci id="S4.SS2.SSS4.p11.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p11.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p11.5.1">External memory. 트랜스포머 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib301" title="">301</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p11.5.2">i.e.,</em> the top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p11.2.m2.1"><semantics id="S4.SS2.SSS4.p11.2.m2.1a"><mi id="S4.SS2.SSS4.p11.2.m2.1.1" xref="S4.SS2.SSS4.p11.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p11.2.m2.1b"><ci id="S4.SS2.SSS4.p11.2.m2.1.1.cmml" xref="S4.SS2.SSS4.p11.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p11.2.m2.1c">k</annotation></semantics></math> attention keys can well approximate the original full attention. 따라서, 다수의 연구들은 과거 키들을 외부 메모리에 저장하고, <math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p11.3.m3.1"><semantics id="S4.SS2.SSS4.p11.3.m3.1a"><mi id="S4.SS2.SSS4.p11.3.m3.1.1" xref="S4.SS2.SSS4.p11.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p11.3.m3.1b"><ci id="S4.SS2.SSS4.p11.3.m3.1.1.cmml" xref="S4.SS2.SSS4.p11.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p11.3.m3.1c">k</annotation></semantics></math>-NN 검색 방법을 활용하여 <math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p11.4.m4.1"><semantics id="S4.SS2.SSS4.p11.4.m4.1a"><mi id="S4.SS2.SSS4.p11.4.m4.1.1" xref="S4.SS2.SSS4.p11.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p11.4.m4.1b"><ci id="S4.SS2.SSS4.p11.4.m4.1.1.cmml" xref="S4.SS2.SSS4.p11.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p11.4.m4.1c">k</annotation></semantics></math> 가장 관련성이 높은 토큰들을 생성<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib302" title="">302</a>, <a class="ltx_ref" href="#bib.bib301" title="">301</a>, <a class="ltx_ref" href="#bib.bib238" title="">238</a>]</cite>에 대해 검색할 것을 제안한다. 디코더 모델의 경우 일반적으로 하나의 특정 계층을 사용하여 이러한 top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p11.5.m5.1"><semantics id="S4.SS2.SSS4.p11.5.m5.1a"><mi id="S4.SS2.SSS4.p11.5.m5.1.1" xref="S4.SS2.SSS4.p11.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p11.5.m5.1b"><ci id="S4.SS2.SSS4.p11.5.m5.1.1.cmml" xref="S4.SS2.SSS4.p11.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p11.5.m5.1c">k</annotation></semantics></math> 외부 토큰에 액세스하는 반면, 나머지 계층에서는 여전히 정상적인 컨텍스트 창을 채택한다.</p>
</div>
<div id="S4.SS2.SSS4.p12" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p12.1">바닐라 트랜스포머를 기반으로 한 연구 외에도, 긴 텍스트를 모델링하기 위한 높은 계산 비용을 완화하기 위해 효율적인 관심 및 기타 효율적인 아키텍처를 가진 트랜스포머 변형이 급증하고 있다. 이러한 연구는 섹션 <a class="ltx_ref" href="#S4.SS2.SSS1" title="4.2.1 Typical Architectures ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.1</span></a> 및 섹션 <a class="ltx_ref" href="#S4.SS2.SSS2" title="4.2.2 Detailed Configuration ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.2</span></a>에서 광범위하게 논의되었다. 또한 컨텍스트 압축 및 프롬프트 기술(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS4.p12.1.1">e.g.,</em>iterative reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib303" title="">303</a>]</cite>)도 모델 적응의 필요 없이 긴 텍스트 작업을 처리하기 위한 실행 가능한 전략임이 입증되었다.</p>
</div>
</section>
<section id="S4.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.5 </span>Decoding Strategy</h4>

<div id="S4.SS2.SSS5.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p1.1">LLM들이 사전 트레이닝된 후, LLM들로부터 적절한 출력을 생성하기 위해 특정 디코딩 전략을 채용하는 것이 필수적이다.</p>
</div>
<div id="S4.SS2.SSS5.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS5.p2.4"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS5.p2.4.1">Background. </span> 우리는 일반적인 디코더 전용 아키텍처로 논의를 시작하고 자동 회귀 디코딩 메커니즘을 소개한다. 이러한 LLMs는 언어 모델링 작업(수학식 <a class="ltx_ref" href="#S4.E6" title="In 4.2.3 Pre-training Tasks ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>)에 기초하여 사전 트레이닝되기 때문에, 기본적인 디코딩 방법은 이전에 생성된 토큰들에 기초하여 각 단계에서 가장 가능성이 높은 토큰을 예측하는 <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p2.4.2">greedy search</em>이며, 형식적으로 모델링된다:</p>
<table id="S4.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E8.m1.1" class="ltx_Math" alttext="{x_{i}=\underset{x}{\arg\max}P(x|\mathbf{x}_{<i}),}" display="block"><semantics id="S4.E8.m1.1a"><mrow id="S4.E8.m1.1.1.1" xref="S4.E8.m1.1.1.1.1.cmml"><mrow id="S4.E8.m1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.cmml"><msub id="S4.E8.m1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.3.cmml"><mi id="S4.E8.m1.1.1.1.1.3.2" xref="S4.E8.m1.1.1.1.1.3.2.cmml">x</mi><mi id="S4.E8.m1.1.1.1.1.3.3" xref="S4.E8.m1.1.1.1.1.3.3.cmml">i</mi></msub><mo id="S4.E8.m1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.2.cmml">=</mo><mrow id="S4.E8.m1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.cmml"><munder accentunder="true" id="S4.E8.m1.1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.1.3.cmml"><mrow id="S4.E8.m1.1.1.1.1.1.3.2" xref="S4.E8.m1.1.1.1.1.1.3.2.cmml"><mi id="S4.E8.m1.1.1.1.1.1.3.2.1" xref="S4.E8.m1.1.1.1.1.1.3.2.1.cmml">arg</mi><mo lspace="0.167em" id="S4.E8.m1.1.1.1.1.1.3.2a" xref="S4.E8.m1.1.1.1.1.1.3.2.cmml">⁡</mo><mi id="S4.E8.m1.1.1.1.1.1.3.2.2" xref="S4.E8.m1.1.1.1.1.1.3.2.2.cmml">max</mi></mrow><mo id="S4.E8.m1.1.1.1.1.1.3.1" xref="S4.E8.m1.1.1.1.1.1.3.1.cmml">𝑥</mo></munder><mo lspace="0.167em" rspace="0em" id="S4.E8.m1.1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.1.2.cmml">​</mo><mi id="S4.E8.m1.1.1.1.1.1.4" xref="S4.E8.m1.1.1.1.1.1.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E8.m1.1.1.1.1.1.2a" xref="S4.E8.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E8.m1.1.1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E8.m1.1.1.1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E8.m1.1.1.1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E8.m1.1.1.1.1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S4.E8.m1.1.1.1.1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S4.E8.m1.1.1.1.1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E8.m1.1.1.1.1.1.1.1.1.3.2" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.2.cmml">𝐱</mi><mrow id="S4.E8.m1.1.1.1.1.1.1.1.1.3.3" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.2" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.1" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.3" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msub></mrow><mo stretchy="false" id="S4.E8.m1.1.1.1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E8.m1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E8.m1.1b"><apply id="S4.E8.m1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1"><eq id="S4.E8.m1.1.1.1.1.2.cmml" xref="S4.E8.m1.1.1.1.1.2"></eq><apply id="S4.E8.m1.1.1.1.1.3.cmml" xref="S4.E8.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E8.m1.1.1.1.1.3.1.cmml" xref="S4.E8.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E8.m1.1.1.1.1.3.2.cmml" xref="S4.E8.m1.1.1.1.1.3.2">𝑥</ci><ci id="S4.E8.m1.1.1.1.1.3.3.cmml" xref="S4.E8.m1.1.1.1.1.3.3">𝑖</ci></apply><apply id="S4.E8.m1.1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1.1"><times id="S4.E8.m1.1.1.1.1.1.2.cmml" xref="S4.E8.m1.1.1.1.1.1.2"></times><apply id="S4.E8.m1.1.1.1.1.1.3.cmml" xref="S4.E8.m1.1.1.1.1.1.3"><ci id="S4.E8.m1.1.1.1.1.1.3.1.cmml" xref="S4.E8.m1.1.1.1.1.1.3.1">𝑥</ci><apply id="S4.E8.m1.1.1.1.1.1.3.2.cmml" xref="S4.E8.m1.1.1.1.1.1.3.2"><arg id="S4.E8.m1.1.1.1.1.1.3.2.1.cmml" xref="S4.E8.m1.1.1.1.1.1.3.2.1"></arg><max id="S4.E8.m1.1.1.1.1.1.3.2.2.cmml" xref="S4.E8.m1.1.1.1.1.1.3.2.2"></max></apply></apply><ci id="S4.E8.m1.1.1.1.1.1.4.cmml" xref="S4.E8.m1.1.1.1.1.1.4">𝑃</ci><apply id="S4.E8.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E8.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S4.E8.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.2">𝑥</ci><apply id="S4.E8.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E8.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E8.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.2">𝐱</ci><apply id="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.3"><lt id="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8.m1.1c">{x_{i}=\underset{x}{\arg\max}P(x|\mathbf{x}_{&lt;i}),}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS5.p2.3">여기서 <math alttext="x_{i}" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p2.1.m1.1"><semantics id="S4.SS2.SSS5.p2.1.m1.1a"><msub id="S4.SS2.SSS5.p2.1.m1.1.1" xref="S4.SS2.SSS5.p2.1.m1.1.1.cmml"><mi id="S4.SS2.SSS5.p2.1.m1.1.1.2" xref="S4.SS2.SSS5.p2.1.m1.1.1.2.cmml">x</mi><mi id="S4.SS2.SSS5.p2.1.m1.1.1.3" xref="S4.SS2.SSS5.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p2.1.m1.1b"><apply id="S4.SS2.SSS5.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS5.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS5.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS5.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS5.p2.1.m1.1.1.2">𝑥</ci><ci id="S4.SS2.SSS5.p2.1.m1.1.1.3.cmml" xref="S4.SS2.SSS5.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p2.1.m1.1c">x_{i}</annotation></semantics></math>는 컨텍스트 <math alttext="\mathbf{x}_{&lt;i}" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p2.3.m3.1"><semantics id="S4.SS2.SSS5.p2.3.m3.1a"><msub id="S4.SS2.SSS5.p2.3.m3.1.1" xref="S4.SS2.SSS5.p2.3.m3.1.1.cmml"><mi id="S4.SS2.SSS5.p2.3.m3.1.1.2" xref="S4.SS2.SSS5.p2.3.m3.1.1.2.cmml">𝐱</mi><mrow id="S4.SS2.SSS5.p2.3.m3.1.1.3" xref="S4.SS2.SSS5.p2.3.m3.1.1.3.cmml"><mi id="S4.SS2.SSS5.p2.3.m3.1.1.3.2" xref="S4.SS2.SSS5.p2.3.m3.1.1.3.2.cmml"></mi><mo id="S4.SS2.SSS5.p2.3.m3.1.1.3.1" xref="S4.SS2.SSS5.p2.3.m3.1.1.3.1.cmml">&lt;</mo><mi id="S4.SS2.SSS5.p2.3.m3.1.1.3.3" xref="S4.SS2.SSS5.p2.3.m3.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p2.3.m3.1b"><apply id="S4.SS2.SSS5.p2.3.m3.1.1.cmml" xref="S4.SS2.SSS5.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS5.p2.3.m3.1.1.1.cmml" xref="S4.SS2.SSS5.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.SSS5.p2.3.m3.1.1.2.cmml" xref="S4.SS2.SSS5.p2.3.m3.1.1.2">𝐱</ci><apply id="S4.SS2.SSS5.p2.3.m3.1.1.3.cmml" xref="S4.SS2.SSS5.p2.3.m3.1.1.3"><lt id="S4.SS2.SSS5.p2.3.m3.1.1.3.1.cmml" xref="S4.SS2.SSS5.p2.3.m3.1.1.3.1"></lt><csymbol cd="latexml" id="S4.SS2.SSS5.p2.3.m3.1.1.3.2.cmml" xref="S4.SS2.SSS5.p2.3.m3.1.1.3.2">absent</csymbol><ci id="S4.SS2.SSS5.p2.3.m3.1.1.3.3.cmml" xref="S4.SS2.SSS5.p2.3.m3.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p2.3.m3.1c">\mathbf{x}_{&lt;i}</annotation></semantics></math>에 조건된 생성의 <math alttext="i" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p2.2.m2.1"><semantics id="S4.SS2.SSS5.p2.2.m2.1a"><mi id="S4.SS2.SSS5.p2.2.m2.1.1" xref="S4.SS2.SSS5.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p2.2.m2.1b"><ci id="S4.SS2.SSS5.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS5.p2.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p2.2.m2.1c">i</annotation></semantics></math>-th step에서 가장 높은 확률을 갖는 토큰이다. 예를 들어 그림 <a class="ltx_ref" href="#S4.F10" title="Figure 10 ‣ 4.2.3 Pre-training Tasks ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">10</span></a>에서 문장 <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p2.3.1">“I am sleepy. "</em>의 포트를 시작합니다. 탐욕스러운 검색은 현재 단계에서 가장 높은 확률을 가진 토큰 "coffee"를 선택합니다. 그리디 검색은 텍스트 생성 작업(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p2.3.2">e.g.,</em> 기계 번역 및 텍스트 요약)에서 만족스러운 결과를 얻을 수 있으며, 여기서 출력은 입력 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib307" title="">307</a>]</cite>에 크게 의존한다. 그러나 개방형 생성 태스크(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p2.3.3">e.g.,</em> story generation and dialog) 측면에서 그리디 검색은 때때로 어색하고 반복적인 문장을 생성하는 경향이 있다.</p>
</div>
<div id="S4.SS2.SSS5.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p3.1">다른 대안적인 디코딩 전략으로서, 생성 동안 랜덤성 및 다양성을 향상시키기 위해 확률 분포에 기초하여 다음 토큰을 랜덤하게 선택하는 샘플링-기반 방법들이 제안된다:</p>
<table id="S4.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E9.m1.1" class="ltx_Math" alttext="x_{i}\sim P(x|\mathbf{x}_{<i})." display="block"><semantics id="S4.E9.m1.1a"><mrow id="S4.E9.m1.1.1.1" xref="S4.E9.m1.1.1.1.1.cmml"><mrow id="S4.E9.m1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.cmml"><msub id="S4.E9.m1.1.1.1.1.3" xref="S4.E9.m1.1.1.1.1.3.cmml"><mi id="S4.E9.m1.1.1.1.1.3.2" xref="S4.E9.m1.1.1.1.1.3.2.cmml">x</mi><mi id="S4.E9.m1.1.1.1.1.3.3" xref="S4.E9.m1.1.1.1.1.3.3.cmml">i</mi></msub><mo id="S4.E9.m1.1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.2.cmml">∼</mo><mrow id="S4.E9.m1.1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.1.cmml"><mi id="S4.E9.m1.1.1.1.1.1.3" xref="S4.E9.m1.1.1.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E9.m1.1.1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E9.m1.1.1.1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E9.m1.1.1.1.1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E9.m1.1.1.1.1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E9.m1.1.1.1.1.1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S4.E9.m1.1.1.1.1.1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S4.E9.m1.1.1.1.1.1.1.1.1.3" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E9.m1.1.1.1.1.1.1.1.1.3.2" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.2.cmml">𝐱</mi><mrow id="S4.E9.m1.1.1.1.1.1.1.1.1.3.3" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.2" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.1" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.3" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msub></mrow><mo stretchy="false" id="S4.E9.m1.1.1.1.1.1.1.1.3" xref="S4.E9.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S4.E9.m1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E9.m1.1b"><apply id="S4.E9.m1.1.1.1.1.cmml" xref="S4.E9.m1.1.1.1"><csymbol cd="latexml" id="S4.E9.m1.1.1.1.1.2.cmml" xref="S4.E9.m1.1.1.1.1.2">similar-to</csymbol><apply id="S4.E9.m1.1.1.1.1.3.cmml" xref="S4.E9.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.1.3.1.cmml" xref="S4.E9.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E9.m1.1.1.1.1.3.2.cmml" xref="S4.E9.m1.1.1.1.1.3.2">𝑥</ci><ci id="S4.E9.m1.1.1.1.1.3.3.cmml" xref="S4.E9.m1.1.1.1.1.3.3">𝑖</ci></apply><apply id="S4.E9.m1.1.1.1.1.1.cmml" xref="S4.E9.m1.1.1.1.1.1"><times id="S4.E9.m1.1.1.1.1.1.2.cmml" xref="S4.E9.m1.1.1.1.1.1.2"></times><ci id="S4.E9.m1.1.1.1.1.1.3.cmml" xref="S4.E9.m1.1.1.1.1.1.3">𝑃</ci><apply id="S4.E9.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E9.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S4.E9.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1.2">𝑥</ci><apply id="S4.E9.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E9.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.2">𝐱</ci><apply id="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.3"><lt id="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E9.m1.1c">x_{i}\sim P(x|\mathbf{x}_{&lt;i}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS5.p3.2">그림 <a class="ltx_ref" href="#S4.F10" title="Figure 10 ‣ 4.2.3 Pre-training Tasks ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">10</span></a>의 예에 대해 샘플링 기반 방법은 더 높은 확률로 단어 "coffee"를 샘플링하는 동시에 나머지 단어, "물", "tea", "쌀", <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p3.2.1">etc</em>을 선택할 수 있는 가능성을 유지한다.</p>
</div>
<div id="S4.SS2.SSS5.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p4.1">디코더 전용 아키텍처에 제한되지 않고, 이 두 디코딩 방법은 일반적으로 유사한 방식으로 인코더-디코더 모델 및 프리픽스 디코더 모델에 적용될 수 있다.</p>
</div>
<div id="S4.SS2.SSS5.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS5.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS5.p5.1.1">Improvement for Greedy Search. </span> 각 단계에서 가장 높은 확률로 토큰을 선택하면 전체 확률은 높지만 로컬 추정은 낮은 문장을 간과할 수 있습니다. 다음으로 이 문제를 완화하기 위한 몇 가지 개선 전략을 소개한다.</p>
</div>
<div id="S4.SS2.SSS5.p6" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p6.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p6.1.m1.1"><semantics id="S4.SS2.SSS5.p6.1.m1.1a"><mo id="S4.SS2.SSS5.p6.1.m1.1.1" xref="S4.SS2.SSS5.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p6.1.m1.1b"><ci id="S4.SS2.SSS5.p6.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p6.2.1">Beam search. </em> Beam search <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib309" title="">309</a>]</cite>는 디코딩 과정 중 각 단계에서 <math alttext="n" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p6.2.m2.1"><semantics id="S4.SS2.SSS5.p6.2.m2.1a"><mi id="S4.SS2.SSS5.p6.2.m2.1.1" xref="S4.SS2.SSS5.p6.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p6.2.m2.1b"><ci id="S4.SS2.SSS5.p6.2.m2.1.1.cmml" xref="S4.SS2.SSS5.p6.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p6.2.m2.1c">n</annotation></semantics></math>(beam size)의 확률이 가장 높은 문장을 유지하고, 최종적으로 생성된 응답을 최상위 확률로 선택한다. 일반적으로 빔 크기는 3~6 범위 내에서 구성됩니다. 그러나 더 큰 빔 크기를 선택하면 성능 [cite idx=1></cite>]이 저하될 수 있습니다.</p>
</div>
<div id="S4.SS2.SSS5.p7" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p7.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p7.1.m1.1"><semantics id="S4.SS2.SSS5.p7.1.m1.1a"><mo id="S4.SS2.SSS5.p7.1.m1.1.1" xref="S4.SS2.SSS5.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p7.1.m1.1b"><ci id="S4.SS2.SSS5.p7.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p7.2.1">Length penalty. 빔 탐색은 더 짧은 문장을 선호하기 때문에, 길이 페널티를 부과하는 것(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p7.2.2">a.k.a.,</em> length normalization)은 문장 길이에 따라 문장 확률을 정규화하는 이 문제를 극복하기 위해 일반적으로 사용되는 기법이다.</p>
</div>
<div id="S4.SS2.SSS5.p8" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p8.1">또한, 일부 연구자들은 반복 생성의 문제를 완화하기 위해 이전에 생성된 토큰 또는 <math alttext="n" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p8.1.m1.1"><semantics id="S4.SS2.SSS5.p8.1.m1.1a"><mi id="S4.SS2.SSS5.p8.1.m1.1.1" xref="S4.SS2.SSS5.p8.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p8.1.m1.1b"><ci id="S4.SS2.SSS5.p8.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p8.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p8.1.m1.1c">n</annotation></semantics></math>-grams의 생성에 페널티를 부여할 것을 제안한다. 또한 다양한 빔 탐색 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib313" title="">313</a>]</cite>를 활용하여 동일한 입력을 기반으로 다양한 출력 집합을 생성할 수 있다.</p>
</div>
<div id="S4.SS2.SSS5.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS5.p9.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS5.p9.1.1">Improvement for Random Sampling. </span> 샘플링 기반 방법은 전체 어휘에 걸쳐 토큰을 샘플링하며, 이는 컨텍스트에 기초하여 잘못되거나 관련 없는 토큰(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p9.1.2">e.g.,</em> "happy" and "Boh" in Figure <a class="ltx_ref" href="#S4.F10" title="Figure 10 ‣ 4.2.3 Pre-training Tasks ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">10</span></a>)을 선택할 수 있다. 생성 품질을 개선하기 위해 확률이 매우 낮은 단어의 선택을 완화하거나 방지하기 위한 몇 가지 전략이 제안되었다.</p>
</div>
<div id="S4.SS2.SSS5.p10" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p10.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p10.1.m1.1"><semantics id="S4.SS2.SSS5.p10.1.m1.1a"><mo id="S4.SS2.SSS5.p10.1.m1.1.1" xref="S4.SS2.SSS5.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p10.1.m1.1b"><ci id="S4.SS2.SSS5.p10.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p10.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p10.2.1">Temperature sampling. </em> 샘플링의 랜덤성을 변조하기 위해, 실용적인 방법은 어휘를 통해 <math alttext="j" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p10.2.m2.1"><semantics id="S4.SS2.SSS5.p10.2.m2.1a"><mi id="S4.SS2.SSS5.p10.2.m2.1.1" xref="S4.SS2.SSS5.p10.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p10.2.m2.1b"><ci id="S4.SS2.SSS5.p10.2.m2.1.1.cmml" xref="S4.SS2.SSS5.p10.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p10.2.m2.1c">j</annotation></semantics></math>-th 토큰의 확률을 계산하기 위한 소프트맥스 함수의 온도 계수를 조정하는 것이다:</p>
<table id="S4.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E10.m1.5" class="ltx_Math" alttext="P(x_{j}|\mathbf{x}_{<i})=\frac{\exp{(l_{j}/t)}}{\sum_{j^{\prime}}\exp{(l_{j^{\prime}}/t)}}," display="block"><semantics id="S4.E10.m1.5a"><mrow id="S4.E10.m1.5.5.1" xref="S4.E10.m1.5.5.1.1.cmml"><mrow id="S4.E10.m1.5.5.1.1" xref="S4.E10.m1.5.5.1.1.cmml"><mrow id="S4.E10.m1.5.5.1.1.1" xref="S4.E10.m1.5.5.1.1.1.cmml"><mi id="S4.E10.m1.5.5.1.1.1.3" xref="S4.E10.m1.5.5.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E10.m1.5.5.1.1.1.2" xref="S4.E10.m1.5.5.1.1.1.2.cmml">​</mo><mrow id="S4.E10.m1.5.5.1.1.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E10.m1.5.5.1.1.1.1.1.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E10.m1.5.5.1.1.1.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.cmml"><msub id="S4.E10.m1.5.5.1.1.1.1.1.1.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.2.cmml"><mi id="S4.E10.m1.5.5.1.1.1.1.1.1.2.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S4.E10.m1.5.5.1.1.1.1.1.1.2.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.2.3.cmml">j</mi></msub><mo fence="false" id="S4.E10.m1.5.5.1.1.1.1.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.cmml">|</mo><msub id="S4.E10.m1.5.5.1.1.1.1.1.1.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.cmml"><mi id="S4.E10.m1.5.5.1.1.1.1.1.1.3.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.2.cmml">𝐱</mi><mrow id="S4.E10.m1.5.5.1.1.1.1.1.1.3.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msub></mrow><mo stretchy="false" id="S4.E10.m1.5.5.1.1.1.1.1.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E10.m1.5.5.1.1.2" xref="S4.E10.m1.5.5.1.1.2.cmml">=</mo><mfrac id="S4.E10.m1.4.4" xref="S4.E10.m1.4.4.cmml"><mrow id="S4.E10.m1.2.2.2.2" xref="S4.E10.m1.2.2.2.3.cmml"><mi id="S4.E10.m1.1.1.1.1" xref="S4.E10.m1.1.1.1.1.cmml">exp</mi><mo id="S4.E10.m1.2.2.2.2a" xref="S4.E10.m1.2.2.2.3.cmml">⁡</mo><mrow id="S4.E10.m1.2.2.2.2.1" xref="S4.E10.m1.2.2.2.3.cmml"><mo stretchy="false" id="S4.E10.m1.2.2.2.2.1.2" xref="S4.E10.m1.2.2.2.3.cmml">(</mo><mrow id="S4.E10.m1.2.2.2.2.1.1" xref="S4.E10.m1.2.2.2.2.1.1.cmml"><msub id="S4.E10.m1.2.2.2.2.1.1.2" xref="S4.E10.m1.2.2.2.2.1.1.2.cmml"><mi id="S4.E10.m1.2.2.2.2.1.1.2.2" xref="S4.E10.m1.2.2.2.2.1.1.2.2.cmml">l</mi><mi id="S4.E10.m1.2.2.2.2.1.1.2.3" xref="S4.E10.m1.2.2.2.2.1.1.2.3.cmml">j</mi></msub><mo id="S4.E10.m1.2.2.2.2.1.1.1" xref="S4.E10.m1.2.2.2.2.1.1.1.cmml">/</mo><mi id="S4.E10.m1.2.2.2.2.1.1.3" xref="S4.E10.m1.2.2.2.2.1.1.3.cmml">t</mi></mrow><mo stretchy="false" id="S4.E10.m1.2.2.2.2.1.3" xref="S4.E10.m1.2.2.2.3.cmml">)</mo></mrow></mrow><mrow id="S4.E10.m1.4.4.4" xref="S4.E10.m1.4.4.4.cmml"><msub id="S4.E10.m1.4.4.4.3" xref="S4.E10.m1.4.4.4.3.cmml"><mo id="S4.E10.m1.4.4.4.3.2" xref="S4.E10.m1.4.4.4.3.2.cmml">∑</mo><msup id="S4.E10.m1.4.4.4.3.3" xref="S4.E10.m1.4.4.4.3.3.cmml"><mi id="S4.E10.m1.4.4.4.3.3.2" xref="S4.E10.m1.4.4.4.3.3.2.cmml">j</mi><mo id="S4.E10.m1.4.4.4.3.3.3" xref="S4.E10.m1.4.4.4.3.3.3.cmml">′</mo></msup></msub><mrow id="S4.E10.m1.4.4.4.2.1" xref="S4.E10.m1.4.4.4.2.2.cmml"><mi id="S4.E10.m1.3.3.3.1" xref="S4.E10.m1.3.3.3.1.cmml">exp</mi><mo id="S4.E10.m1.4.4.4.2.1a" xref="S4.E10.m1.4.4.4.2.2.cmml">⁡</mo><mrow id="S4.E10.m1.4.4.4.2.1.1" xref="S4.E10.m1.4.4.4.2.2.cmml"><mo stretchy="false" id="S4.E10.m1.4.4.4.2.1.1.2" xref="S4.E10.m1.4.4.4.2.2.cmml">(</mo><mrow id="S4.E10.m1.4.4.4.2.1.1.1" xref="S4.E10.m1.4.4.4.2.1.1.1.cmml"><msub id="S4.E10.m1.4.4.4.2.1.1.1.2" xref="S4.E10.m1.4.4.4.2.1.1.1.2.cmml"><mi id="S4.E10.m1.4.4.4.2.1.1.1.2.2" xref="S4.E10.m1.4.4.4.2.1.1.1.2.2.cmml">l</mi><msup id="S4.E10.m1.4.4.4.2.1.1.1.2.3" xref="S4.E10.m1.4.4.4.2.1.1.1.2.3.cmml"><mi id="S4.E10.m1.4.4.4.2.1.1.1.2.3.2" xref="S4.E10.m1.4.4.4.2.1.1.1.2.3.2.cmml">j</mi><mo id="S4.E10.m1.4.4.4.2.1.1.1.2.3.3" xref="S4.E10.m1.4.4.4.2.1.1.1.2.3.3.cmml">′</mo></msup></msub><mo id="S4.E10.m1.4.4.4.2.1.1.1.1" xref="S4.E10.m1.4.4.4.2.1.1.1.1.cmml">/</mo><mi id="S4.E10.m1.4.4.4.2.1.1.1.3" xref="S4.E10.m1.4.4.4.2.1.1.1.3.cmml">t</mi></mrow><mo stretchy="false" id="S4.E10.m1.4.4.4.2.1.1.3" xref="S4.E10.m1.4.4.4.2.2.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><mo id="S4.E10.m1.5.5.1.2" xref="S4.E10.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E10.m1.5b"><apply id="S4.E10.m1.5.5.1.1.cmml" xref="S4.E10.m1.5.5.1"><eq id="S4.E10.m1.5.5.1.1.2.cmml" xref="S4.E10.m1.5.5.1.1.2"></eq><apply id="S4.E10.m1.5.5.1.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1"><times id="S4.E10.m1.5.5.1.1.1.2.cmml" xref="S4.E10.m1.5.5.1.1.1.2"></times><ci id="S4.E10.m1.5.5.1.1.1.3.cmml" xref="S4.E10.m1.5.5.1.1.1.3">𝑃</ci><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1"><csymbol cd="latexml" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1">conditional</csymbol><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.2.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.2.3">𝑗</ci></apply><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.1.1.1.1.3.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.3.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.2">𝐱</ci><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.3"><lt id="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply><apply id="S4.E10.m1.4.4.cmml" xref="S4.E10.m1.4.4"><divide id="S4.E10.m1.4.4.5.cmml" xref="S4.E10.m1.4.4"></divide><apply id="S4.E10.m1.2.2.2.3.cmml" xref="S4.E10.m1.2.2.2.2"><exp id="S4.E10.m1.1.1.1.1.cmml" xref="S4.E10.m1.1.1.1.1"></exp><apply id="S4.E10.m1.2.2.2.2.1.1.cmml" xref="S4.E10.m1.2.2.2.2.1.1"><divide id="S4.E10.m1.2.2.2.2.1.1.1.cmml" xref="S4.E10.m1.2.2.2.2.1.1.1"></divide><apply id="S4.E10.m1.2.2.2.2.1.1.2.cmml" xref="S4.E10.m1.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.2.2.2.2.1.1.2.1.cmml" xref="S4.E10.m1.2.2.2.2.1.1.2">subscript</csymbol><ci id="S4.E10.m1.2.2.2.2.1.1.2.2.cmml" xref="S4.E10.m1.2.2.2.2.1.1.2.2">𝑙</ci><ci id="S4.E10.m1.2.2.2.2.1.1.2.3.cmml" xref="S4.E10.m1.2.2.2.2.1.1.2.3">𝑗</ci></apply><ci id="S4.E10.m1.2.2.2.2.1.1.3.cmml" xref="S4.E10.m1.2.2.2.2.1.1.3">𝑡</ci></apply></apply><apply id="S4.E10.m1.4.4.4.cmml" xref="S4.E10.m1.4.4.4"><apply id="S4.E10.m1.4.4.4.3.cmml" xref="S4.E10.m1.4.4.4.3"><csymbol cd="ambiguous" id="S4.E10.m1.4.4.4.3.1.cmml" xref="S4.E10.m1.4.4.4.3">subscript</csymbol><sum id="S4.E10.m1.4.4.4.3.2.cmml" xref="S4.E10.m1.4.4.4.3.2"></sum><apply id="S4.E10.m1.4.4.4.3.3.cmml" xref="S4.E10.m1.4.4.4.3.3"><csymbol cd="ambiguous" id="S4.E10.m1.4.4.4.3.3.1.cmml" xref="S4.E10.m1.4.4.4.3.3">superscript</csymbol><ci id="S4.E10.m1.4.4.4.3.3.2.cmml" xref="S4.E10.m1.4.4.4.3.3.2">𝑗</ci><ci id="S4.E10.m1.4.4.4.3.3.3.cmml" xref="S4.E10.m1.4.4.4.3.3.3">′</ci></apply></apply><apply id="S4.E10.m1.4.4.4.2.2.cmml" xref="S4.E10.m1.4.4.4.2.1"><exp id="S4.E10.m1.3.3.3.1.cmml" xref="S4.E10.m1.3.3.3.1"></exp><apply id="S4.E10.m1.4.4.4.2.1.1.1.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1"><divide id="S4.E10.m1.4.4.4.2.1.1.1.1.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1.1"></divide><apply id="S4.E10.m1.4.4.4.2.1.1.1.2.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.4.4.4.2.1.1.1.2.1.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1.2">subscript</csymbol><ci id="S4.E10.m1.4.4.4.2.1.1.1.2.2.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1.2.2">𝑙</ci><apply id="S4.E10.m1.4.4.4.2.1.1.1.2.3.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.E10.m1.4.4.4.2.1.1.1.2.3.1.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1.2.3">superscript</csymbol><ci id="S4.E10.m1.4.4.4.2.1.1.1.2.3.2.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1.2.3.2">𝑗</ci><ci id="S4.E10.m1.4.4.4.2.1.1.1.2.3.3.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1.2.3.3">′</ci></apply></apply><ci id="S4.E10.m1.4.4.4.2.1.1.1.3.cmml" xref="S4.E10.m1.4.4.4.2.1.1.1.3">𝑡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E10.m1.5c">P(x_{j}|\mathbf{x}_{&lt;i})=\frac{\exp{(l_{j}/t)}}{\sum_{j^{\prime}}\exp{(l_{j^{\prime}}/t)}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS5.p10.8">여기서 <math alttext="l_{j^{\prime}}" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p10.3.m1.1"><semantics id="S4.SS2.SSS5.p10.3.m1.1a"><msub id="S4.SS2.SSS5.p10.3.m1.1.1" xref="S4.SS2.SSS5.p10.3.m1.1.1.cmml"><mi id="S4.SS2.SSS5.p10.3.m1.1.1.2" xref="S4.SS2.SSS5.p10.3.m1.1.1.2.cmml">l</mi><msup id="S4.SS2.SSS5.p10.3.m1.1.1.3" xref="S4.SS2.SSS5.p10.3.m1.1.1.3.cmml"><mi id="S4.SS2.SSS5.p10.3.m1.1.1.3.2" xref="S4.SS2.SSS5.p10.3.m1.1.1.3.2.cmml">j</mi><mo id="S4.SS2.SSS5.p10.3.m1.1.1.3.3" xref="S4.SS2.SSS5.p10.3.m1.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p10.3.m1.1b"><apply id="S4.SS2.SSS5.p10.3.m1.1.1.cmml" xref="S4.SS2.SSS5.p10.3.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS5.p10.3.m1.1.1.1.cmml" xref="S4.SS2.SSS5.p10.3.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS5.p10.3.m1.1.1.2.cmml" xref="S4.SS2.SSS5.p10.3.m1.1.1.2">𝑙</ci><apply id="S4.SS2.SSS5.p10.3.m1.1.1.3.cmml" xref="S4.SS2.SSS5.p10.3.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS5.p10.3.m1.1.1.3.1.cmml" xref="S4.SS2.SSS5.p10.3.m1.1.1.3">superscript</csymbol><ci id="S4.SS2.SSS5.p10.3.m1.1.1.3.2.cmml" xref="S4.SS2.SSS5.p10.3.m1.1.1.3.2">𝑗</ci><ci id="S4.SS2.SSS5.p10.3.m1.1.1.3.3.cmml" xref="S4.SS2.SSS5.p10.3.m1.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p10.3.m1.1c">l_{j^{\prime}}</annotation></semantics></math>는 각 단어의 로짓이고 <math alttext="t" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p10.4.m2.1"><semantics id="S4.SS2.SSS5.p10.4.m2.1a"><mi id="S4.SS2.SSS5.p10.4.m2.1.1" xref="S4.SS2.SSS5.p10.4.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p10.4.m2.1b"><ci id="S4.SS2.SSS5.p10.4.m2.1.1.cmml" xref="S4.SS2.SSS5.p10.4.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p10.4.m2.1c">t</annotation></semantics></math>는 온도 계수이다. <math alttext="t" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p10.5.m3.1"><semantics id="S4.SS2.SSS5.p10.5.m3.1a"><mi id="S4.SS2.SSS5.p10.5.m3.1.1" xref="S4.SS2.SSS5.p10.5.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p10.5.m3.1b"><ci id="S4.SS2.SSS5.p10.5.m3.1.1.cmml" xref="S4.SS2.SSS5.p10.5.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p10.5.m3.1c">t</annotation></semantics></math>의 온도를 낮추면 확률이 높은 단어를 선택할 확률이 높아지는 반면 확률이 낮은 단어를 선택할 확률은 낮아진다. <math alttext="t" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p10.6.m4.1"><semantics id="S4.SS2.SSS5.p10.6.m4.1a"><mi id="S4.SS2.SSS5.p10.6.m4.1.1" xref="S4.SS2.SSS5.p10.6.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p10.6.m4.1b"><ci id="S4.SS2.SSS5.p10.6.m4.1.1.cmml" xref="S4.SS2.SSS5.p10.6.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p10.6.m4.1c">t</annotation></semantics></math>가 1로 설정되면, 디폴트 랜덤 샘플링이 되고, <math alttext="t" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p10.7.m5.1"><semantics id="S4.SS2.SSS5.p10.7.m5.1a"><mi id="S4.SS2.SSS5.p10.7.m5.1.1" xref="S4.SS2.SSS5.p10.7.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p10.7.m5.1b"><ci id="S4.SS2.SSS5.p10.7.m5.1.1.cmml" xref="S4.SS2.SSS5.p10.7.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p10.7.m5.1c">t</annotation></semantics></math>가 0에 가까워지면, 그리디 검색에 상당한다. 또한, <math alttext="t" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p10.8.m6.1"><semantics id="S4.SS2.SSS5.p10.8.m6.1a"><mi id="S4.SS2.SSS5.p10.8.m6.1.1" xref="S4.SS2.SSS5.p10.8.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p10.8.m6.1b"><ci id="S4.SS2.SSS5.p10.8.m6.1.1.cmml" xref="S4.SS2.SSS5.p10.8.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p10.8.m6.1c">t</annotation></semantics></math>가 무한대로 가면, 균일 샘플링으로 퇴화된다.</p>
</div>
<div id="S4.SS2.SSS5.p11" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p11.5"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p11.1.m1.1"><semantics id="S4.SS2.SSS5.p11.1.m1.1a"><mo id="S4.SS2.SSS5.p11.1.m1.1.1" xref="S4.SS2.SSS5.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p11.1.m1.1b"><ci id="S4.SS2.SSS5.p11.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p11.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p11.2.1">Top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p11.2.1.m1.1"><semantics id="S4.SS2.SSS5.p11.2.1.m1.1a"><mi id="S4.SS2.SSS5.p11.2.1.m1.1.1" xref="S4.SS2.SSS5.p11.2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p11.2.1.m1.1b"><ci id="S4.SS2.SSS5.p11.2.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p11.2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p11.2.1.m1.1c">k</annotation></semantics></math> sampling. </em> 온도 샘플링과 달리 top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p11.3.m2.1"><semantics id="S4.SS2.SSS5.p11.3.m2.1a"><mi id="S4.SS2.SSS5.p11.3.m2.1.1" xref="S4.SS2.SSS5.p11.3.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p11.3.m2.1b"><ci id="S4.SS2.SSS5.p11.3.m2.1.1.cmml" xref="S4.SS2.SSS5.p11.3.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p11.3.m2.1c">k</annotation></semantics></math> 샘플링은 낮은 확률로 토큰을 직접 잘라내고 top<math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p11.4.m3.1"><semantics id="S4.SS2.SSS5.p11.4.m3.1a"><mi id="S4.SS2.SSS5.p11.4.m3.1.1" xref="S4.SS2.SSS5.p11.4.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p11.4.m3.1b"><ci id="S4.SS2.SSS5.p11.4.m3.1.1.cmml" xref="S4.SS2.SSS5.p11.4.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p11.4.m3.1c">k</annotation></semantics></math>가장 높은 확률<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib314" title="">314</a>]</cite>를 가진 토큰의 샘플만 잘라낸다. 예를 들어, 그림 <a class="ltx_ref" href="#S4.F10" title="Figure 10 ‣ 4.2.3 Pre-training Tasks ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">10</span></a>, top-<math alttext="5" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p11.5.m4.1"><semantics id="S4.SS2.SSS5.p11.5.m4.1a"><mn id="S4.SS2.SSS5.p11.5.m4.1.1" xref="S4.SS2.SSS5.p11.5.m4.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p11.5.m4.1b"><cn id="S4.SS2.SSS5.p11.5.m4.1.1.cmml" type="integer" xref="S4.SS2.SSS5.p11.5.m4.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p11.5.m4.1c">5</annotation></semantics></math> 샘플링은 "커피", "물", "차", "쌀", 및 "차이"라는 단어를 그들의 재스케일된 확률로부터 샘플링할 것이다.</p>
</div>
<div id="S4.SS2.SSS5.p12" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p12.7"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p12.1.m1.1"><semantics id="S4.SS2.SSS5.p12.1.m1.1a"><mo id="S4.SS2.SSS5.p12.1.m1.1.1" xref="S4.SS2.SSS5.p12.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p12.1.m1.1b"><ci id="S4.SS2.SSS5.p12.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p12.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p12.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p12.2.1">Top-<math alttext="p" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p12.2.1.m1.1"><semantics id="S4.SS2.SSS5.p12.2.1.m1.1a"><mi id="S4.SS2.SSS5.p12.2.1.m1.1.1" xref="S4.SS2.SSS5.p12.2.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p12.2.1.m1.1b"><ci id="S4.SS2.SSS5.p12.2.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p12.2.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p12.2.1.m1.1c">p</annotation></semantics></math> sampling. </em> top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p12.3.m2.1"><semantics id="S4.SS2.SSS5.p12.3.m2.1a"><mi id="S4.SS2.SSS5.p12.3.m2.1.1" xref="S4.SS2.SSS5.p12.3.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p12.3.m2.1b"><ci id="S4.SS2.SSS5.p12.3.m2.1.1.cmml" xref="S4.SS2.SSS5.p12.3.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p12.3.m2.1c">k</annotation></semantics></math> sampling은 전체적인 가능성 분포를 고려하지 않기 때문에, <math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p12.4.m3.1"><semantics id="S4.SS2.SSS5.p12.4.m3.1a"><mi id="S4.SS2.SSS5.p12.4.m3.1.1" xref="S4.SS2.SSS5.p12.4.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p12.4.m3.1b"><ci id="S4.SS2.SSS5.p12.4.m3.1.1.cmml" xref="S4.SS2.SSS5.p12.4.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p12.4.m3.1c">k</annotation></semantics></math>의 상수 값은 서로 다른 컨텍스트에 적합하지 않을 수 있다. 따라서, top-<math alttext="p" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p12.5.m4.1"><semantics id="S4.SS2.SSS5.p12.5.m4.1a"><mi id="S4.SS2.SSS5.p12.5.m4.1.1" xref="S4.SS2.SSS5.p12.5.m4.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p12.5.m4.1b"><ci id="S4.SS2.SSS5.p12.5.m4.1.1.cmml" xref="S4.SS2.SSS5.p12.5.m4.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p12.5.m4.1c">p</annotation></semantics></math> 샘플링(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p12.7.2">a.k.a.,</em> nucleus sampling)은 상기(또는 동일) <math alttext="p" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p12.6.m5.1"><semantics id="S4.SS2.SSS5.p12.6.m5.1a"><mi id="S4.SS2.SSS5.p12.6.m5.1.1" xref="S4.SS2.SSS5.p12.6.m5.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p12.6.m5.1b"><ci id="S4.SS2.SSS5.p12.6.m5.1.1.cmml" xref="S4.SS2.SSS5.p12.6.m5.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p12.6.m5.1c">p</annotation></semantics></math><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib308" title="">308</a>]</cite>의 누적 확률을 갖는 가장 작은 집합으로부터 샘플링함으로써 제안된다. 실제로 가장 작은 집합은 생성 확률의 내림차순으로 정렬된 어휘부터 그 누적값이 <math alttext="p" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p12.7.m6.1"><semantics id="S4.SS2.SSS5.p12.7.m6.1a"><mi id="S4.SS2.SSS5.p12.7.m6.1.1" xref="S4.SS2.SSS5.p12.7.m6.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p12.7.m6.1b"><ci id="S4.SS2.SSS5.p12.7.m6.1.1.cmml" xref="S4.SS2.SSS5.p12.7.m6.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p12.7.m6.1c">p</annotation></semantics></math>를 초과할 때까지 점진적으로 토큰을 추가하여 구성할 수 있다.</p>
</div>
<div id="S4.SS2.SSS5.p13" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p13.2">최근 연구자들은 LLM에 대한 다른 샘플링 전략도 탐구했다. 예를 들어, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p13.1.1"><math alttext="\eta" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p13.1.1.m1.1"><semantics id="S4.SS2.SSS5.p13.1.1.m1.1a"><mi id="S4.SS2.SSS5.p13.1.1.m1.1.1" xref="S4.SS2.SSS5.p13.1.1.m1.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p13.1.1.m1.1b"><ci id="S4.SS2.SSS5.p13.1.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p13.1.1.m1.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p13.1.1.m1.1c">\eta</annotation></semantics></math>-sampling</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib315" title="">315</a>]</cite>는 확률 분포에 기초한 동적 임계값을 도입함으로써 top-<math alttext="p" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p13.2.m1.1"><semantics id="S4.SS2.SSS5.p13.2.m1.1a"><mi id="S4.SS2.SSS5.p13.2.m1.1.1" xref="S4.SS2.SSS5.p13.2.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p13.2.m1.1b"><ci id="S4.SS2.SSS5.p13.2.m1.1.1.cmml" xref="S4.SS2.SSS5.p13.2.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p13.2.m1.1c">p</annotation></semantics></math> 샘플링을 더욱 향상시킨다. 또한, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p13.2.2">contrastive search</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib316" title="">316</a>]</cite> 및 <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p13.2.3">typical sampling</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib317" title="">317</a>]</cite>는 디코딩 시 생성 일관성 향상에 활용될 수 있다. 큰 모델은 작은 모델에 비해 중요한 토큰에 더 높은 확률을 할당하는 경향이 있다는 것이 발견되었기 때문에, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p13.2.4">contrastive decoding</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib318" title="">318</a>]</cite>는 더 큰 LM(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p13.2.5">e.g.,</em> OPT-13B)과 더 작은 LM(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p13.2.6">e.g.,</em> OPT-125M)을 활용하여 로그 우도 차이를 측정한다. 이어서 확률분포의 델타 값을 기준으로 토큰을 샘플링하여 중요 토큰의 영향을 증폭시킨다. 이 대조적인 아이디어에 기초하여, DoLa<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib319" title="">319</a>]</cite>는 상위 계층들이 중요한 토큰들에 더 많은 가중치를 할당하는 경향이 있기 때문에, 단일 LLM의 상이한 계층들에 걸쳐 로짓들을 대조하는 것으로 이 접근법을 추가로 확장한다.</p>
</div>
<div id="S4.SS2.SSS5.1.p1" class="ltx_para ltx_noindent ltx_align_center">
<svg id="S4.SS2.SSS5.1.p1.pic1" class="ltx_picture" height="315.68" overflow="visible" version="1.1" width="288"><g transform="translate(0,315.68) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00008C" fill-opacity="1.0"><path d="M 0 5.91 L 0 309.77 C 0 313.03 2.64 315.68 5.91 315.68 L 282.09 315.68 C 285.35 315.68 288 313.03 288 309.77 L 288 5.91 C 288 2.64 285.35 0 282.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 291.57 L 286.03 291.57 L 286.03 5.91 C 286.03 3.73 284.27 1.97 282.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 297.47)"><foreignObject width="244.69" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S4.SS2.SSS5.1.p1.pic1.15.15.15.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:176.8pt;">
<span id="S4.SS2.SSS5.1.p1.pic1.15.15.15.1.1.1" class="ltx_p">Memory Wall</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="244.69" height="265.98" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:176.8pt;">
<span id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.15" class="ltx_p">When generating a new token, the most time-consuming steps revolve around data transfer and weight computation. A main issue is the significant amount of time overwhelmed by data transfer, often referred to as the <em id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.15.1" class="ltx_emph ltx_font_italic">memory wall</em> issue.</span>
<span id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8" class="ltx_p">To address this issue, researchers formally quantify data transfer from GPU memory to GPU caches using the number of bytes in I/O, and they assess weight computation by measuring the number of FLOPs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib320" title="" class="ltx_ref">320</a>]</cite>. Specifically, let <math id="S4.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="S4.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S4.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">b</annotation></semantics></math>, <math id="S4.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mi id="S4.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S4.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="S4.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">s</annotation></semantics></math>, <math id="S4.SS2.SSS5.1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1a"><mi id="S4.SS2.SSS5.1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1" xref="S4.SS2.SSS5.1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1b"><ci id="S4.SS2.SSS5.1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1c">n</annotation></semantics></math>, <math id="S4.SS2.SSS5.1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1a"><mi id="S4.SS2.SSS5.1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1" xref="S4.SS2.SSS5.1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1b"><ci id="S4.SS2.SSS5.1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1c">d</annotation></semantics></math>, and <math id="S4.SS2.SSS5.1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1a"><mi id="S4.SS2.SSS5.1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1" xref="S4.SS2.SSS5.1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1b"><ci id="S4.SS2.SSS5.1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1c">h</annotation></semantics></math> denote the batch size, sequence length, number of attention heads, hidden size of each head, and overall hidden size (<math id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1" class="ltx_Math" alttext="h=n\cdot d" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1a"><mrow id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.cmml"><mi id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.2" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.2.cmml">h</mi><mo id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.1" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.1.cmml">=</mo><mrow id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.cmml"><mi id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.2" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.1" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.1.cmml">⋅</mo><mi id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.3" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.3.cmml">d</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1b"><apply id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1"><eq id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.1"></eq><ci id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.2.cmml" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.2">ℎ</ci><apply id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.cmml" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3"><ci id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.1">⋅</ci><ci id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.2.cmml" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.2">𝑛</ci><ci id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.3.cmml" xref="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1c">h=n\cdot d</annotation></semantics></math>), respectively. During the layer-wise multi-head self-attention calculation in causal decoder, the I/O bytes and FLOPs at each decoding step can be expressed as <math id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1" class="ltx_Math" alttext="8bsn+4bsnd+4bnd" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1a"><mrow id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.cmml"><mrow id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.cmml"><mn id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.2" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.2.cmml">8</mn><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.1" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.3" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.1a" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.4" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.1b" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.5" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.5.cmml">n</mi></mrow><mo id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.1" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.1.cmml">+</mo><mrow id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.cmml"><mn id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.2" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.2.cmml">4</mn><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.3" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1a" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.4" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1b" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.5" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1c" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.6" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.6.cmml">d</mi></mrow><mo id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.1a" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.1.cmml">+</mo><mrow id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.cmml"><mn id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.2" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.2.cmml">4</mn><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.1" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.3" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.1a" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.4" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.1b" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.5" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.5.cmml">d</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1b"><apply id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1"><plus id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.1"></plus><apply id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2"><times id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.1"></times><cn type="integer" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.2.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.2">8</cn><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.3.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.3">𝑏</ci><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.4.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.4">𝑠</ci><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.5.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.2.5">𝑛</ci></apply><apply id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3"><times id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.1"></times><cn type="integer" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.2.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.2">4</cn><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.3.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.3">𝑏</ci><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.4.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.4">𝑠</ci><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.5.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.5">𝑛</ci><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.6.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.3.6">𝑑</ci></apply><apply id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4"><times id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.1"></times><cn type="integer" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.2.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.2">4</cn><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.3.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.3">𝑏</ci><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.4.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.4">𝑛</ci><ci id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.5.cmml" xref="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1.1.4.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m7.1c">8bsn+4bsnd+4bnd</annotation></semantics></math> and <math id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1" class="ltx_Math" alttext="8bsnd" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1a"><mrow id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.cmml"><mn id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.2" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.2.cmml">8</mn><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.3" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1a" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.4" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1b" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.5" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1c" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.6" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.6.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1b"><apply id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1"><times id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.1"></times><cn type="integer" id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.2.cmml" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.2">8</cn><ci id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.3.cmml" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.3">𝑏</ci><ci id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.4.cmml" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.4">𝑠</ci><ci id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.5.cmml" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.5">𝑛</ci><ci id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.6.cmml" xref="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1.1.6">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m8.1c">8bsnd</annotation></semantics></math>, respectively&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib320" title="" class="ltx_ref">320</a>]</cite>.</span>
<span id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.16" class="ltx_p"><em id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.16.1" class="ltx_emph ltx_font_italic">Arithmetic intensity</em> is further defined as the ratio of FLOPs to I/O bytes:</span>
<span id="S4.E11" class="ltx_equation ltx_eqn_table">

<span><span class="ltx_equation ltx_eqn_row ltx_align_baseline">
<span class="ltx_eqn_cell ltx_eqn_center_padleft"></span>
<span class="ltx_eqn_cell ltx_align_center"><math id="S4.E11.m1.1" class="ltx_Math" alttext="\text{intensity}=\frac{\text{FLOPs}}{\text{I/O bytes}}=\frac{2}{1+\frac{2}{d}+\frac{1}{s}}" display="block"><semantics id="S4.E11.m1.1a"><mrow id="S4.E11.m1.1.1" xref="S4.E11.m1.1.1.cmml"><mtext id="S4.E11.m1.1.1.2" xref="S4.E11.m1.1.1.2a.cmml">intensity</mtext><mo id="S4.E11.m1.1.1.3" xref="S4.E11.m1.1.1.3.cmml">=</mo><mfrac id="S4.E11.m1.1.1.4" xref="S4.E11.m1.1.1.4.cmml"><mtext id="S4.E11.m1.1.1.4.2" xref="S4.E11.m1.1.1.4.2a.cmml">FLOPs</mtext><mtext id="S4.E11.m1.1.1.4.3" xref="S4.E11.m1.1.1.4.3a.cmml">I/O bytes</mtext></mfrac><mo id="S4.E11.m1.1.1.5" xref="S4.E11.m1.1.1.5.cmml">=</mo><mfrac id="S4.E11.m1.1.1.6" xref="S4.E11.m1.1.1.6.cmml"><mn id="S4.E11.m1.1.1.6.2" xref="S4.E11.m1.1.1.6.2.cmml">2</mn><mrow id="S4.E11.m1.1.1.6.3" xref="S4.E11.m1.1.1.6.3.cmml"><mn id="S4.E11.m1.1.1.6.3.2" xref="S4.E11.m1.1.1.6.3.2.cmml">1</mn><mo id="S4.E11.m1.1.1.6.3.1" xref="S4.E11.m1.1.1.6.3.1.cmml">+</mo><mfrac id="S4.E11.m1.1.1.6.3.3" xref="S4.E11.m1.1.1.6.3.3.cmml"><mn id="S4.E11.m1.1.1.6.3.3.2" xref="S4.E11.m1.1.1.6.3.3.2.cmml">2</mn><mi id="S4.E11.m1.1.1.6.3.3.3" xref="S4.E11.m1.1.1.6.3.3.3.cmml">d</mi></mfrac><mo id="S4.E11.m1.1.1.6.3.1a" xref="S4.E11.m1.1.1.6.3.1.cmml">+</mo><mfrac id="S4.E11.m1.1.1.6.3.4" xref="S4.E11.m1.1.1.6.3.4.cmml"><mn id="S4.E11.m1.1.1.6.3.4.2" xref="S4.E11.m1.1.1.6.3.4.2.cmml">1</mn><mi id="S4.E11.m1.1.1.6.3.4.3" xref="S4.E11.m1.1.1.6.3.4.3.cmml">s</mi></mfrac></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E11.m1.1b"><apply id="S4.E11.m1.1.1.cmml" xref="S4.E11.m1.1.1"><and id="S4.E11.m1.1.1a.cmml" xref="S4.E11.m1.1.1"></and><apply id="S4.E11.m1.1.1b.cmml" xref="S4.E11.m1.1.1"><eq id="S4.E11.m1.1.1.3.cmml" xref="S4.E11.m1.1.1.3"></eq><ci id="S4.E11.m1.1.1.2a.cmml" xref="S4.E11.m1.1.1.2"><mtext id="S4.E11.m1.1.1.2.cmml" xref="S4.E11.m1.1.1.2">intensity</mtext></ci><apply id="S4.E11.m1.1.1.4.cmml" xref="S4.E11.m1.1.1.4"><divide id="S4.E11.m1.1.1.4.1.cmml" xref="S4.E11.m1.1.1.4"></divide><ci id="S4.E11.m1.1.1.4.2a.cmml" xref="S4.E11.m1.1.1.4.2"><mtext id="S4.E11.m1.1.1.4.2.cmml" xref="S4.E11.m1.1.1.4.2">FLOPs</mtext></ci><ci id="S4.E11.m1.1.1.4.3a.cmml" xref="S4.E11.m1.1.1.4.3"><mtext id="S4.E11.m1.1.1.4.3.cmml" xref="S4.E11.m1.1.1.4.3">I/O bytes</mtext></ci></apply></apply><apply id="S4.E11.m1.1.1c.cmml" xref="S4.E11.m1.1.1"><eq id="S4.E11.m1.1.1.5.cmml" xref="S4.E11.m1.1.1.5"></eq><share href="#S4.E11.m1.1.1.4.cmml" id="S4.E11.m1.1.1d.cmml" xref="S4.E11.m1.1.1"></share><apply id="S4.E11.m1.1.1.6.cmml" xref="S4.E11.m1.1.1.6"><divide id="S4.E11.m1.1.1.6.1.cmml" xref="S4.E11.m1.1.1.6"></divide><cn type="integer" id="S4.E11.m1.1.1.6.2.cmml" xref="S4.E11.m1.1.1.6.2">2</cn><apply id="S4.E11.m1.1.1.6.3.cmml" xref="S4.E11.m1.1.1.6.3"><plus id="S4.E11.m1.1.1.6.3.1.cmml" xref="S4.E11.m1.1.1.6.3.1"></plus><cn type="integer" id="S4.E11.m1.1.1.6.3.2.cmml" xref="S4.E11.m1.1.1.6.3.2">1</cn><apply id="S4.E11.m1.1.1.6.3.3.cmml" xref="S4.E11.m1.1.1.6.3.3"><divide id="S4.E11.m1.1.1.6.3.3.1.cmml" xref="S4.E11.m1.1.1.6.3.3"></divide><cn type="integer" id="S4.E11.m1.1.1.6.3.3.2.cmml" xref="S4.E11.m1.1.1.6.3.3.2">2</cn><ci id="S4.E11.m1.1.1.6.3.3.3.cmml" xref="S4.E11.m1.1.1.6.3.3.3">𝑑</ci></apply><apply id="S4.E11.m1.1.1.6.3.4.cmml" xref="S4.E11.m1.1.1.6.3.4"><divide id="S4.E11.m1.1.1.6.3.4.1.cmml" xref="S4.E11.m1.1.1.6.3.4"></divide><cn type="integer" id="S4.E11.m1.1.1.6.3.4.2.cmml" xref="S4.E11.m1.1.1.6.3.4.2">1</cn><ci id="S4.E11.m1.1.1.6.3.4.3.cmml" xref="S4.E11.m1.1.1.6.3.4.3">𝑠</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E11.m1.1c">\text{intensity}=\frac{\text{FLOPs}}{\text{I/O bytes}}=\frac{2}{1+\frac{2}{d}+\frac{1}{s}}</annotation></semantics></math></span>
<span class="ltx_eqn_cell ltx_eqn_center_padright"></span>
<span rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></span></span></span>
</span>
<span id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14" class="ltx_p">Let’s consider LLaMA 13B (<math id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1" class="ltx_Math" alttext="d=128" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1a"><mrow id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1" xref="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.cmml"><mi id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.2" xref="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.2.cmml">d</mi><mo id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.1" xref="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.3" xref="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1b"><apply id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1"><eq id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.1"></eq><ci id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.2.cmml" xref="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.2">𝑑</ci><cn type="integer" id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.3.cmml" xref="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m1.1c">d=128</annotation></semantics></math>) with a sequence length of 1024 (<math id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1" class="ltx_Math" alttext="s=1024" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1a"><mrow id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1" xref="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.cmml"><mi id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.2" xref="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.2.cmml">s</mi><mo id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.1" xref="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.3" xref="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1b"><apply id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1"><eq id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.1"></eq><ci id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.2.cmml" xref="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.2">𝑠</ci><cn type="integer" id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.3.cmml" xref="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m2.1c">s=1024</annotation></semantics></math>) as an example. The calculated arithmetic intensity is <math id="S4.SS2.SSS5.1.p1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m3.1" class="ltx_Math" alttext="1.97" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m3.1a"><mn id="S4.SS2.SSS5.1.p1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m3.1.1" xref="S4.SS2.SSS5.1.p1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m3.1.1.cmml">1.97</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m3.1b"><cn type="float" id="S4.SS2.SSS5.1.p1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m3.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m3.1.1">1.97</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m3.1c">1.97</annotation></semantics></math>. However, the A100 80G GPU can perform <math id="S4.SS2.SSS5.1.p1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m4.1" class="ltx_Math" alttext="312" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m4.1a"><mn id="S4.SS2.SSS5.1.p1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m4.1.1" xref="S4.SS2.SSS5.1.p1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m4.1.1.cmml">312</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m4.1b"><cn type="integer" id="S4.SS2.SSS5.1.p1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m4.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m4.1.1">312</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m4.1c">312</annotation></semantics></math> TFLOPs and transfer <math id="S4.SS2.SSS5.1.p1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1a"><mn id="S4.SS2.SSS5.1.p1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1.1" xref="S4.SS2.SSS5.1.p1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1b"><cn type="integer" id="S4.SS2.SSS5.1.p1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m5.1c">2</annotation></semantics></math> TB of data in one second, <em id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.1" class="ltx_emph ltx_font_italic">i.e.,</em> its ideal arithmetic intensity is <math id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m6.1" class="ltx_Math" alttext="156" display="inline"><semantics id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m6.1a"><mn id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m6.1.1" xref="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m6.1.1.cmml">156</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m6.1b"><cn type="integer" id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m6.1.1.cmml" xref="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m6.1.1">156</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m6.1c">156</annotation></semantics></math>. This indicates that the bottleneck in attention calculation lies in the process of data transfer (<em id="S4.SS2.SSS5.1.p1.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.2" class="ltx_emph ltx_font_italic">i.e.,</em> excessive I/O loading).</span>
</span></foreignObject></g></g></svg>
</div>
<div id="S4.SS2.SSS5.p14" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS5.p14.2"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS5.p14.2.1">Decoding Efficiency Issues. </span> 이 부분에서는 LLM의 디코딩 효율 문제를 간략히 분석한다. 전반적으로, LLM의 디코딩 프로세스는 오버헤드 분석을 위해 (1) 입력 시퀀스의 숨겨진 상태를 계산하는 <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p14.2.2">prefill</em> 스테이지와 (2) 토큰을 생성하고 숨겨진 상태를 자동 회귀 방식으로 업데이트하는 <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p14.2.3">incremental decoding</em> 스테이지로 나눌 수 있다. 상기 <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p14.2.4">memory wall</em> 박스에 도시된 바와 같이, 증분 디코딩 단계의 산술 강도는 기대값 156(A100 80GB GPU의 표준 구성에 따라 계산됨)과는 거리가 먼 <math alttext="1.97" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p14.1.m1.1"><semantics id="S4.SS2.SSS5.p14.1.m1.1a"><mn id="S4.SS2.SSS5.p14.1.m1.1.1" xref="S4.SS2.SSS5.p14.1.m1.1.1.cmml">1.97</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p14.1.m1.1b"><cn id="S4.SS2.SSS5.p14.1.m1.1.1.cmml" type="float" xref="S4.SS2.SSS5.p14.1.m1.1.1">1.97</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p14.1.m1.1c">1.97</annotation></semantics></math>일 뿐이다. 대조적으로, 프리필 스테이지의 산술 강도는 LLaMA-13B에 대해 <math alttext="113.78" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p14.2.m2.1"><semantics id="S4.SS2.SSS5.p14.2.m2.1a"><mn id="S4.SS2.SSS5.p14.2.m2.1.1" xref="S4.SS2.SSS5.p14.2.m2.1.1.cmml">113.78</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p14.2.m2.1b"><cn id="S4.SS2.SSS5.p14.2.m2.1.1.cmml" type="float" xref="S4.SS2.SSS5.p14.2.m2.1.1">113.78</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p14.2.m2.1c">113.78</annotation></semantics></math>를 달성한다. 결과적으로, 기존 연구는 주로 증분 디코딩 알고리즘의 효율성을 향상시키는 방법을 조사하는데, 이는 크게 두 가지 접근법으로 분류될 수 있다:</p>
</div>
<div id="S4.SS2.SSS5.p15" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p15.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p15.1.m1.1"><semantics id="S4.SS2.SSS5.p15.1.m1.1a"><mo id="S4.SS2.SSS5.p15.1.m1.1.1" xref="S4.SS2.SSS5.p15.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p15.1.m1.1b"><ci id="S4.SS2.SSS5.p15.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p15.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p15.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p15.1.1">Reducing data transfer</em>은 주로 GPU 메모리 액세스를 최적화하는데 초점을 맞추고, 이에 따라 산술 강도를 증가시킨다. 섹션 <a class="ltx_ref" href="#S4.SS2.SSS2" title="4.2.2 Detailed Configuration ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.2</span></a>에서 소개한 바와 같이 KV 캐시는 이전 토큰의 중복 계산을 피할 수 있으며 PagedAttention는 메모리 단편화를 줄이기 위해 KV 캐시를 연속 블록으로 할당한다. 또한 Flash-Decoding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib322" title="">322</a>]</cite>는 키와 값을 병렬로 로드하여 어텐션 연산을 빠르게 하며, 특히 긴 텍스트 생성에 효과적이다. 다른 대안적 접근법으로서, 다중-쿼리 및 그룹화된-쿼리 주의는 KV 파라미터들을 공유함으로써 GPU 메모리 대역폭 오버헤드를 감소시킬 수 있다(더 적은 가중치들을 로딩함).</p>
</div>
<div id="S4.SS2.SSS5.p16" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p16.4"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p16.1.m1.1"><semantics id="S4.SS2.SSS5.p16.1.m1.1a"><mo id="S4.SS2.SSS5.p16.1.m1.1.1" xref="S4.SS2.SSS5.p16.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p16.1.m1.1b"><ci id="S4.SS2.SSS5.p16.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p16.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p16.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p16.4.1">Decoding strategy optimization</em>은 auto-regressive generation manner의 순차적 성질을 서로 다른 방식으로 개선하는 것을 목표로 한다. 대표적인 연구로서, <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p16.4.2">추측 디코딩</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib323" title="">323</a>, <a class="ltx_ref" href="#bib.bib324" title="">324</a>]</cite>는 먼저 작지만 효율적인 모델(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p16.4.3">e.g.,</em> a <math alttext="n" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p16.2.m2.1"><semantics id="S4.SS2.SSS5.p16.2.m2.1a"><mi id="S4.SS2.SSS5.p16.2.m2.1.1" xref="S4.SS2.SSS5.p16.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p16.2.m2.1b"><ci id="S4.SS2.SSS5.p16.2.m2.1.1.cmml" xref="S4.SS2.SSS5.p16.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p16.2.m2.1c">n</annotation></semantics></math>-gram model or a small PLM)을 활용하여 짧은 세그먼트를 생성한 후 LLM을 활용하여 이러한 드래프트를 검증하고 수정한다. 생성 품질을 손상시키지 않으면서 주목할만한 2<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p16.3.m3.1"><semantics id="S4.SS2.SSS5.p16.3.m3.1a"><mo id="S4.SS2.SSS5.p16.3.m3.1.1" xref="S4.SS2.SSS5.p16.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p16.3.m3.1b"><times id="S4.SS2.SSS5.p16.3.m3.1.1.cmml" xref="S4.SS2.SSS5.p16.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p16.3.m3.1c">\times</annotation></semantics></math> 내지 3<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p16.4.m4.1"><semantics id="S4.SS2.SSS5.p16.4.m4.1a"><mo id="S4.SS2.SSS5.p16.4.m4.1.1" xref="S4.SS2.SSS5.p16.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p16.4.m4.1b"><times id="S4.SS2.SSS5.p16.4.m4.1.1.cmml" xref="S4.SS2.SSS5.p16.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p16.4.m4.1c">\times</annotation></semantics></math> 속도 향상으로 이어질 수 있다. 연구자들은 또한 이 접근법의 효율성을 향상시키기 위해 몇 가지 변형예를 제안하는데, 예를 들어 여러 작은 모델<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib325" title="">325</a>]</cite>를 결합하는 학습 기반 방법 및 작은 LM을 먼저 가속하기 위해 더 작은 LM을 사용하는 단계별 가속이다. 또한 모든 계층을 통과하지 않고 하위 트랜스포머 계층에서 토큰을 생성할 수 있는 토큰 수준의 조기 종료 기술이 제안되었다. 그것은 더 큰 속도 향상을 달성할 수 있지만, 발전 품질을 희생하는 대가를 치르게 된다.</p>
</div>
<div id="S4.SS2.SSS5.p17" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS5.p17.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS5.p17.1.1">Practical Settings. </span> 실제로 기존 라이브러리(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p17.1.2">e.g.,</em> Transformers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib187" title="">187</a>]</cite>) 및 LLMs의 공용 API(<em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p17.1.3">e.g.,</em> OpenAI)는 텍스트 생성의 다양한 시나리오를 제공하기 위해 다양한 디코딩 전략을 지원했습니다. 다음으로, 우리는 몇몇 대표적인 LLM의 디코딩 설정을 제시한다:</p>
</div>
<div id="S4.SS2.SSS5.p18" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p18.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p18.1.m1.1"><semantics id="S4.SS2.SSS5.p18.1.m1.1a"><mo id="S4.SS2.SSS5.p18.1.m1.1.1" xref="S4.SS2.SSS5.p18.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p18.1.m1.1b"><ci id="S4.SS2.SSS5.p18.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p18.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p18.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p18.1.1">T5</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>는 greedy search를 기본 설정으로 활용하고, 번역 및 요약 작업에 대해 길이 벌점이 0.6인 beam search(beam size of 4)를 적용한다.</p>
</div>
<div id="S4.SS2.SSS5.p19" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p19.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p19.1.m1.1"><semantics id="S4.SS2.SSS5.p19.1.m1.1a"><mo id="S4.SS2.SSS5.p19.1.m1.1.1" xref="S4.SS2.SSS5.p19.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p19.1.m1.1b"><ci id="S4.SS2.SSS5.p19.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p19.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p19.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p19.1.1">GPT-3</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>는 모든 생성 작업에 대해 빔 크기가 4이고 길이 벌점이 0.6인 빔 검색을 채용한다.</p>
</div>
<div id="S4.SS2.SSS5.p20" class="ltx_para">
<p id="S4.SS2.SSS5.p20.5" class="ltx_p"><math id="S4.SS2.SSS5.p20.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S4.SS2.SSS5.p20.1.m1.1a"><mo id="S4.SS2.SSS5.p20.1.m1.1.1" xref="S4.SS2.SSS5.p20.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p20.1.m1.1b"><ci id="S4.SS2.SSS5.p20.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p20.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p20.1.m1.1c">\bullet</annotation></semantics></math> <em id="S4.SS2.SSS5.p20.5.1" class="ltx_emph ltx_font_italic">Alpaca</em>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite> utilizes sampling-based strategies with top-<math id="S4.SS2.SSS5.p20.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS2.SSS5.p20.2.m2.1a"><mi id="S4.SS2.SSS5.p20.2.m2.1.1" xref="S4.SS2.SSS5.p20.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p20.2.m2.1b"><ci id="S4.SS2.SSS5.p20.2.m2.1.1.cmml" xref="S4.SS2.SSS5.p20.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p20.2.m2.1c">k</annotation></semantics></math> (<math id="S4.SS2.SSS5.p20.3.m3.1" class="ltx_Math" alttext="k=50" display="inline"><semantics id="S4.SS2.SSS5.p20.3.m3.1a"><mrow id="S4.SS2.SSS5.p20.3.m3.1.1" xref="S4.SS2.SSS5.p20.3.m3.1.1.cmml"><mi id="S4.SS2.SSS5.p20.3.m3.1.1.2" xref="S4.SS2.SSS5.p20.3.m3.1.1.2.cmml">k</mi><mo id="S4.SS2.SSS5.p20.3.m3.1.1.1" xref="S4.SS2.SSS5.p20.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS5.p20.3.m3.1.1.3" xref="S4.SS2.SSS5.p20.3.m3.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p20.3.m3.1b"><apply id="S4.SS2.SSS5.p20.3.m3.1.1.cmml" xref="S4.SS2.SSS5.p20.3.m3.1.1"><eq id="S4.SS2.SSS5.p20.3.m3.1.1.1.cmml" xref="S4.SS2.SSS5.p20.3.m3.1.1.1"></eq><ci id="S4.SS2.SSS5.p20.3.m3.1.1.2.cmml" xref="S4.SS2.SSS5.p20.3.m3.1.1.2">𝑘</ci><cn type="integer" id="S4.SS2.SSS5.p20.3.m3.1.1.3.cmml" xref="S4.SS2.SSS5.p20.3.m3.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p20.3.m3.1c">k=50</annotation></semantics></math>), top-<math id="S4.SS2.SSS5.p20.4.m4.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.SSS5.p20.4.m4.1a"><mi id="S4.SS2.SSS5.p20.4.m4.1.1" xref="S4.SS2.SSS5.p20.4.m4.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p20.4.m4.1b"><ci id="S4.SS2.SSS5.p20.4.m4.1.1.cmml" xref="S4.SS2.SSS5.p20.4.m4.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p20.4.m4.1c">p</annotation></semantics></math> (<math id="S4.SS2.SSS5.p20.5.m5.1" class="ltx_Math" alttext="p=0.9" display="inline"><semantics id="S4.SS2.SSS5.p20.5.m5.1a"><mrow id="S4.SS2.SSS5.p20.5.m5.1.1" xref="S4.SS2.SSS5.p20.5.m5.1.1.cmml"><mi id="S4.SS2.SSS5.p20.5.m5.1.1.2" xref="S4.SS2.SSS5.p20.5.m5.1.1.2.cmml">p</mi><mo id="S4.SS2.SSS5.p20.5.m5.1.1.1" xref="S4.SS2.SSS5.p20.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS5.p20.5.m5.1.1.3" xref="S4.SS2.SSS5.p20.5.m5.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p20.5.m5.1b"><apply id="S4.SS2.SSS5.p20.5.m5.1.1.cmml" xref="S4.SS2.SSS5.p20.5.m5.1.1"><eq id="S4.SS2.SSS5.p20.5.m5.1.1.1.cmml" xref="S4.SS2.SSS5.p20.5.m5.1.1.1"></eq><ci id="S4.SS2.SSS5.p20.5.m5.1.1.2.cmml" xref="S4.SS2.SSS5.p20.5.m5.1.1.2">𝑝</ci><cn type="float" id="S4.SS2.SSS5.p20.5.m5.1.1.3.cmml" xref="S4.SS2.SSS5.p20.5.m5.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p20.5.m5.1c">p=0.9</annotation></semantics></math>), and temperature of 0.7 for open-ended generation.</p>
</div>
<div id="S4.SS2.SSS5.p21" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p21.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p21.1.m1.1"><semantics id="S4.SS2.SSS5.p21.1.m1.1a"><mo id="S4.SS2.SSS5.p21.1.m1.1.1" xref="S4.SS2.SSS5.p21.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p21.1.m1.1b"><ci id="S4.SS2.SSS5.p21.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p21.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p21.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p21.1.1">LLaMA</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>는 특정 작업에 맞춘 다양한 디코딩 전략을 적용한다. 예를 들어, 코드 생성을 위해 0.1(pass@1) 및 0.8(pass@100)의 온도 설정으로 샘플링 전략을 사용하는 동안 질문 응답 작업에 대한 탐욕 검색을 사용합니다.</p>
</div>
<div id="S4.SS2.SSS5.p22" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p22.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS5.p22.1.m1.1"><semantics id="S4.SS2.SSS5.p22.1.m1.1a"><mo id="S4.SS2.SSS5.p22.1.m1.1.1" xref="S4.SS2.SSS5.p22.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p22.1.m1.1b"><ci id="S4.SS2.SSS5.p22.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p22.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p22.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS5.p22.1.1">OpenAI API</em>는 그리디 검색(설정 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS5.p22.1.2">temperature</span> to 0)을 포함한 여러 기본 디코딩 전략을 지원합니다. 빔 검색(설정 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS5.p22.1.3">best_of</span>)과 온도 샘플링(설정 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS5.p22.1.4">temperature</span>)과 핵 샘플링(설정 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS5.p22. 또한 파라미터 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS5.p22.1.6">presence_penalty</span> 및 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS5.p22.1.7">frequency_penalty</span>을 도입하여 생성의 반복 정도를 제어한다. OpenAI의 문서에 따르면, 그들의 API들은 입력과 하이퍼-파라미터들이 동일하더라도 상이한 출력들을 생성할 것이다. 온도를 0으로 설정하면 변동 가능성은 약간 있지만 더 결정적 출력을 산출할 수 있다.</p>
</div>
</section>
<section id="S4.SS2.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.6 </span>Summary and Discussion</h4>

<div id="S4.SS2.SSS6.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS6.p1.1">아키텍처 및 사전 훈련 작업의 선택은 LLM에 대해 상이한 귀납적 편향을 야기할 수 있고, 이는 상이한 모델 용량으로 이어질 수 있다. 이 부분에서는 LLM에 대한 아키텍처 선택에 대한 한 가지 열린 문제에 대해 논의한다.</p>
</div>
<div id="S4.SS2.SSS6.1.p1" class="ltx_para ltx_noindent ltx_align_center">
<svg id="S4.SS2.SSS6.1.p1.pic1" class="ltx_picture" height="326.36" overflow="visible" version="1.1" width="288"><g transform="translate(0,326.36) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00008C" fill-opacity="1.0"><path d="M 0 5.91 L 0 320.46 C 0 323.72 2.64 326.36 5.91 326.36 L 282.09 326.36 C 285.35 326.36 288 323.72 288 320.46 L 288 5.91 C 288 2.64 285.35 0 282.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 288.34 L 286.03 288.34 L 286.03 5.91 C 286.03 3.73 284.27 1.97 282.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 294.25)"><foreignObject width="244.69" height="26.21" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S4.SS2.SSS6.1.p1.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:176.8pt;">
<span id="S4.SS2.SSS6.1.p1.pic1.1.1.1.1.1.1" class="ltx_p">Why does Predicting the Next Word Works?</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="244.69" height="262.75" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S4.SS2.SSS6.1.p1.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:176.8pt;">
<span id="S4.SS2.SSS6.1.p1.pic1.2.2.2.1.1.1" class="ltx_p">The essence of decoder-only architecture is to <em id="S4.SS2.SSS6.1.p1.pic1.2.2.2.1.1.1.1" class="ltx_emph ltx_font_italic">accurately predict the next word</em> for reconstructing the pre-training data. Till now, there has been no formal study that theoretically demonstrates its advantage over other architectures. An interesting explanation was from Ilya Sutskever during the interview held by Jensen Huang<span id="footnote24" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">24</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">24</sup><span class="ltx_tag ltx_tag_note">24</span>https://www.nvidia.com/en-us/on-demand/session/gtcspring23-S52092/</span></span></span>.
The original transcript from the interview was copied below<span id="footnote25" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">25</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">25</sup><span class="ltx_tag ltx_tag_note">25</span>https://lifearchitect.ai/ilya/</span></span></span>:</span>
<span id="S4.SS2.SSS6.1.p1.pic1.2.2.2.1.1.2" class="ltx_p"><span id="S4.SS2.SSS6.1.p1.pic1.2.2.2.1.1.2.1" class="ltx_text ltx_font_typewriter">Say you read a detective novel. It’s like complicated plot, a storyline, different characters, lots of events, mysteries like clues, it’s unclear. Then, let’s say that at the last page of the book, the detective has gathered all the clues, gathered all the people and saying, "okay, I’m going to reveal the identity of whoever committed the crime and that person’s name is". Predict that word. ...
<br class="ltx_break">Now, there are many different words. But predicting those words better and better, the understanding of the text keeps on increasing. GPT-4 predicts the next word better.
</span></span>
</span></foreignObject></g></g></svg>
</div>
<div id="S4.SS2.SSS6.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.SSS6.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS6.p2.1.1">Architecture Choice</span>. 사전 훈련된 언어 모델의 초기 문헌에서는 다양한 아키텍처의 효과에 대한 많은 논의가 있다. 그러나 대부분의 LLM은 인과 디코더 구조를 기반으로 개발되었으며, 다른 대안들에 비해 그 장점에 대한 이론적 분석이 부족하다. 다음으로, 이 문제에 대한 기존의 논의를 간략히 정리한다.</p>
</div>
<div id="S4.SS2.SSS6.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS6.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS6.p3.1.m1.1"><semantics id="S4.SS2.SSS6.p3.1.m1.1a"><mo id="S4.SS2.SSS6.p3.1.m1.1.1" xref="S4.SS2.SSS6.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS6.p3.1.m1.1b"><ci id="S4.SS2.SSS6.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS6.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS6.p3.1.m1.1c">\bullet</annotation></semantics></math> LM 대물렌즈로 사전 트레이닝함으로써, 인과적 디코더 아키텍처는 우수한 제로-샷 및 소수-샷 일반화 용량을 달성할 수 있는 것으로 보인다. 기존의 연구는 멀티-태스크 미세-조정 없이, 인과적 디코더가 다른 아키텍처들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>]</cite>보다 더 나은 제로-샷 성능을 갖는다는 것을 보여주었다. GPT-3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>의 성공은 큰 인과 디코더 모델이 좋은 소수의 샷 학습자가 될 수 있음을 보여준다. 또한, 섹션 <a class="ltx_ref" href="#S5" title="5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>에서 논의된 명령어 튜닝 및 정렬 튜닝은 대형 인과 디코더 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>, <a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>의 능력을 더욱 향상시키는 것으로 입증되었다.</p>
</div>
<div id="S4.SS2.SSS6.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS6.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS6.p4.1.m1.1"><semantics id="S4.SS2.SSS6.p4.1.m1.1a"><mo id="S4.SS2.SSS6.p4.1.m1.1.1" xref="S4.SS2.SSS6.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS6.p4.1.m1.1b"><ci id="S4.SS2.SSS6.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS6.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS6.p4.1.m1.1c">\bullet</annotation></semantics></math> Scaling law is widely observed in causal decoder. 모델 크기, 데이터 세트 크기 및 전체 계산을 스케일링함으로써 인과적 디코더의 성능을 실질적으로 개선할 수 있다. 따라서, 스케일링을 통해 인과 디코더의 모델 용량을 증가시키는 것이 중요한 전략이 되었다. 그러나, 인코더-디코더 모델에 대한 보다 상세한 연구는 여전히 부족하며, 인코더-디코더 모델의 성능을 대규모로 조사하기 위한 더 많은 노력이 필요하다.</p>
</div>
<div id="S4.SS2.SSS6.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS6.p5.1">특히 인코더-디코더 아키텍처의 경우, 아키텍처 및 사전 트레이닝 태스크의 선택이 LLM의 용량에 어떻게 영향을 미치는지 분석하기 위해서는 아키텍처 및 사전 트레이닝 목표에 대한 논의에 대한 더 많은 연구 노력이 필요하다. 디코더 전용 아키텍처의 효과에도 불구하고, 아키텍처 설계에 대한 보다 다양한 탐색이 제안된다. 주요 아키텍처 외에도 LLM의 세부 구성도 주목할 가치가 있으며, 이는 섹션 <a class="ltx_ref" href="#S4.SS2.SSS2" title="4.2.2 Detailed Configuration ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.2</span></a>에서 논의되었다.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VII:</span> 여러 기존 LLM의 상세 최적화 설정.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>Detailed optimization settings of several existing LLMs.
</figcaption>
<div id="S4.T7.20" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:888.9pt;height:499.8pt;vertical-align:-1.4pt;"><span class="ltx_transformed_inner" style="transform:translate(118.6pt,-66.5pt) scale(1.36393496387527,1.36393496387527) ;">
<table id="S4.T7.20.20" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S4.T7.20.20.21" class="ltx_tr">
<td id="S4.T7.20.20.21.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T7.20.20.21.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S4.T7.20.20.21.2" class="ltx_td ltx_align_right ltx_border_tt">
<table id="S4.T7.20.20.21.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S4.T7.20.20.21.2.1.1" class="ltx_tr">
<td id="S4.T7.20.20.21.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_right"><span id="S4.T7.20.20.21.2.1.1.1.1" class="ltx_text ltx_font_bold">Batch Size</span></td>
</tr>
<tr id="S4.T7.20.20.21.2.1.2" class="ltx_tr">
<td id="S4.T7.20.20.21.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_right"><span id="S4.T7.20.20.21.2.1.2.1.1" class="ltx_text ltx_font_bold">(#tokens)</span></td>
</tr>
</tbody></table>
</td>
<td id="S4.T7.20.20.21.3" class="ltx_td ltx_align_right ltx_border_tt">
<table id="S4.T7.20.20.21.3.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S4.T7.20.20.21.3.1.1" class="ltx_tr">
<td id="S4.T7.20.20.21.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_right"><span id="S4.T7.20.20.21.3.1.1.1.1" class="ltx_text ltx_font_bold">Learning</span></td>
</tr>
<tr id="S4.T7.20.20.21.3.1.2" class="ltx_tr">
<td id="S4.T7.20.20.21.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_right"><span id="S4.T7.20.20.21.3.1.2.1.1" class="ltx_text ltx_font_bold">Rate</span></td>
</tr>
</tbody></table>
</td>
<td id="S4.T7.20.20.21.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.20.20.21.4.1" class="ltx_text ltx_font_bold">Warmup</span></td>
<td id="S4.T7.20.20.21.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.20.20.21.5.1" class="ltx_text ltx_font_bold">Decay Method</span></td>
<td id="S4.T7.20.20.21.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.20.20.21.6.1" class="ltx_text ltx_font_bold">Optimizer</span></td>
<td id="S4.T7.20.20.21.7" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T7.20.20.21.7.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S4.T7.20.20.21.7.1.1" class="ltx_tr">
<td id="S4.T7.20.20.21.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T7.20.20.21.7.1.1.1.1" class="ltx_text ltx_font_bold">Precision</span></td>
</tr>
<tr id="S4.T7.20.20.21.7.1.2" class="ltx_tr">
<td id="S4.T7.20.20.21.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T7.20.20.21.7.1.2.1.1" class="ltx_text ltx_font_bold">Type</span></td>
</tr>
</tbody></table>
</td>
<td id="S4.T7.20.20.21.8" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T7.20.20.21.8.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S4.T7.20.20.21.8.1.1" class="ltx_tr">
<td id="S4.T7.20.20.21.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T7.20.20.21.8.1.1.1.1" class="ltx_text ltx_font_bold">Weight</span></td>
</tr>
<tr id="S4.T7.20.20.21.8.1.2" class="ltx_tr">
<td id="S4.T7.20.20.21.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T7.20.20.21.8.1.2.1.1" class="ltx_text ltx_font_bold">Decay</span></td>
</tr>
</tbody></table>
</td>
<td id="S4.T7.20.20.21.9" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T7.20.20.21.9.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S4.T7.20.20.21.9.1.1" class="ltx_tr">
<td id="S4.T7.20.20.21.9.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T7.20.20.21.9.1.1.1.1" class="ltx_text ltx_font_bold">Grad</span></td>
</tr>
<tr id="S4.T7.20.20.21.9.1.2" class="ltx_tr">
<td id="S4.T7.20.20.21.9.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T7.20.20.21.9.1.2.1.1" class="ltx_text ltx_font_bold">Clip</span></td>
</tr>
</tbody></table>
</td>
<td id="S4.T7.20.20.21.10" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.20.20.21.10.1" class="ltx_text ltx_font_bold">Dropout</span></td>
</tr>
<tr id="S4.T7.1.1.1" class="ltx_tr">
<td id="S4.T7.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t">GPT3&nbsp;(175B)</td>
<td id="S4.T7.1.1.1.3" class="ltx_td ltx_align_right ltx_border_t">32K→3.2M</td>
<td id="S4.T7.1.1.1.1" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T7.1.1.1.1.m1.1" class="ltx_Math" alttext="6\times 10^{-5}" display="inline"><semantics id="S4.T7.1.1.1.1.m1.1a"><mrow id="S4.T7.1.1.1.1.m1.1.1" xref="S4.T7.1.1.1.1.m1.1.1.cmml"><mn id="S4.T7.1.1.1.1.m1.1.1.2" xref="S4.T7.1.1.1.1.m1.1.1.2.cmml">6</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.1.1.1.1.m1.1.1.1" xref="S4.T7.1.1.1.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.1.1.1.1.m1.1.1.3" xref="S4.T7.1.1.1.1.m1.1.1.3.cmml"><mn id="S4.T7.1.1.1.1.m1.1.1.3.2" xref="S4.T7.1.1.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.1.1.1.1.m1.1.1.3.3" xref="S4.T7.1.1.1.1.m1.1.1.3.3.cmml"><mo id="S4.T7.1.1.1.1.m1.1.1.3.3a" xref="S4.T7.1.1.1.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.1.1.1.1.m1.1.1.3.3.2" xref="S4.T7.1.1.1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.1.1.1.1.m1.1b"><apply id="S4.T7.1.1.1.1.m1.1.1.cmml" xref="S4.T7.1.1.1.1.m1.1.1"><times id="S4.T7.1.1.1.1.m1.1.1.1.cmml" xref="S4.T7.1.1.1.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.1.1.1.1.m1.1.1.2.cmml" xref="S4.T7.1.1.1.1.m1.1.1.2">6</cn><apply id="S4.T7.1.1.1.1.m1.1.1.3.cmml" xref="S4.T7.1.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.1.1.1.1.m1.1.1.3.1.cmml" xref="S4.T7.1.1.1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.1.1.1.1.m1.1.1.3.2.cmml" xref="S4.T7.1.1.1.1.m1.1.1.3.2">10</cn><apply id="S4.T7.1.1.1.1.m1.1.1.3.3.cmml" xref="S4.T7.1.1.1.1.m1.1.1.3.3"><minus id="S4.T7.1.1.1.1.m1.1.1.3.3.1.cmml" xref="S4.T7.1.1.1.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.1.1.1.1.m1.1.1.3.3.2.cmml" xref="S4.T7.1.1.1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.1.1.1.1.m1.1c">6\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T7.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">yes</td>
<td id="S4.T7.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">cosine decay to 10%</td>
<td id="S4.T7.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">Adam</td>
<td id="S4.T7.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t">FP16</td>
<td id="S4.T7.1.1.1.8" class="ltx_td ltx_align_center ltx_border_t">0.1</td>
<td id="S4.T7.1.1.1.9" class="ltx_td ltx_align_center ltx_border_t">1.0</td>
<td id="S4.T7.1.1.1.10" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T7.3.3.3" class="ltx_tr">
<td id="S4.T7.2.2.2.1" class="ltx_td ltx_align_left">PanGu-<math id="S4.T7.2.2.2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.T7.2.2.2.1.m1.1a"><mi id="S4.T7.2.2.2.1.m1.1.1" xref="S4.T7.2.2.2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.T7.2.2.2.1.m1.1b"><ci id="S4.T7.2.2.2.1.m1.1.1.cmml" xref="S4.T7.2.2.2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.2.2.2.1.m1.1c">\alpha</annotation></semantics></math>&nbsp;(200B)</td>
<td id="S4.T7.3.3.3.3" class="ltx_td ltx_align_right">-</td>
<td id="S4.T7.3.3.3.2" class="ltx_td ltx_align_right"><math id="S4.T7.3.3.3.2.m1.1" class="ltx_Math" alttext="2\times 10^{-5}" display="inline"><semantics id="S4.T7.3.3.3.2.m1.1a"><mrow id="S4.T7.3.3.3.2.m1.1.1" xref="S4.T7.3.3.3.2.m1.1.1.cmml"><mn id="S4.T7.3.3.3.2.m1.1.1.2" xref="S4.T7.3.3.3.2.m1.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.3.3.3.2.m1.1.1.1" xref="S4.T7.3.3.3.2.m1.1.1.1.cmml">×</mo><msup id="S4.T7.3.3.3.2.m1.1.1.3" xref="S4.T7.3.3.3.2.m1.1.1.3.cmml"><mn id="S4.T7.3.3.3.2.m1.1.1.3.2" xref="S4.T7.3.3.3.2.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.3.3.3.2.m1.1.1.3.3" xref="S4.T7.3.3.3.2.m1.1.1.3.3.cmml"><mo id="S4.T7.3.3.3.2.m1.1.1.3.3a" xref="S4.T7.3.3.3.2.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.3.3.3.2.m1.1.1.3.3.2" xref="S4.T7.3.3.3.2.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.3.3.3.2.m1.1b"><apply id="S4.T7.3.3.3.2.m1.1.1.cmml" xref="S4.T7.3.3.3.2.m1.1.1"><times id="S4.T7.3.3.3.2.m1.1.1.1.cmml" xref="S4.T7.3.3.3.2.m1.1.1.1"></times><cn type="integer" id="S4.T7.3.3.3.2.m1.1.1.2.cmml" xref="S4.T7.3.3.3.2.m1.1.1.2">2</cn><apply id="S4.T7.3.3.3.2.m1.1.1.3.cmml" xref="S4.T7.3.3.3.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.3.3.3.2.m1.1.1.3.1.cmml" xref="S4.T7.3.3.3.2.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.3.3.3.2.m1.1.1.3.2.cmml" xref="S4.T7.3.3.3.2.m1.1.1.3.2">10</cn><apply id="S4.T7.3.3.3.2.m1.1.1.3.3.cmml" xref="S4.T7.3.3.3.2.m1.1.1.3.3"><minus id="S4.T7.3.3.3.2.m1.1.1.3.3.1.cmml" xref="S4.T7.3.3.3.2.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.3.3.3.2.m1.1.1.3.3.2.cmml" xref="S4.T7.3.3.3.2.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.3.3.3.2.m1.1c">2\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T7.3.3.3.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.3.3.3.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.3.3.3.6" class="ltx_td ltx_align_center">Adam</td>
<td id="S4.T7.3.3.3.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.3.3.3.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.3.3.3.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.3.3.3.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.4.4.4" class="ltx_tr">
<td id="S4.T7.4.4.4.2" class="ltx_td ltx_align_left">OPT&nbsp;(175B)</td>
<td id="S4.T7.4.4.4.3" class="ltx_td ltx_align_right">2M</td>
<td id="S4.T7.4.4.4.1" class="ltx_td ltx_align_right"><math id="S4.T7.4.4.4.1.m1.1" class="ltx_Math" alttext="1.2\times 10^{-4}" display="inline"><semantics id="S4.T7.4.4.4.1.m1.1a"><mrow id="S4.T7.4.4.4.1.m1.1.1" xref="S4.T7.4.4.4.1.m1.1.1.cmml"><mn id="S4.T7.4.4.4.1.m1.1.1.2" xref="S4.T7.4.4.4.1.m1.1.1.2.cmml">1.2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.4.4.4.1.m1.1.1.1" xref="S4.T7.4.4.4.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.4.4.4.1.m1.1.1.3" xref="S4.T7.4.4.4.1.m1.1.1.3.cmml"><mn id="S4.T7.4.4.4.1.m1.1.1.3.2" xref="S4.T7.4.4.4.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.4.4.4.1.m1.1.1.3.3" xref="S4.T7.4.4.4.1.m1.1.1.3.3.cmml"><mo id="S4.T7.4.4.4.1.m1.1.1.3.3a" xref="S4.T7.4.4.4.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.4.4.4.1.m1.1.1.3.3.2" xref="S4.T7.4.4.4.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.4.4.4.1.m1.1b"><apply id="S4.T7.4.4.4.1.m1.1.1.cmml" xref="S4.T7.4.4.4.1.m1.1.1"><times id="S4.T7.4.4.4.1.m1.1.1.1.cmml" xref="S4.T7.4.4.4.1.m1.1.1.1"></times><cn type="float" id="S4.T7.4.4.4.1.m1.1.1.2.cmml" xref="S4.T7.4.4.4.1.m1.1.1.2">1.2</cn><apply id="S4.T7.4.4.4.1.m1.1.1.3.cmml" xref="S4.T7.4.4.4.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.4.4.4.1.m1.1.1.3.1.cmml" xref="S4.T7.4.4.4.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.4.4.4.1.m1.1.1.3.2.cmml" xref="S4.T7.4.4.4.1.m1.1.1.3.2">10</cn><apply id="S4.T7.4.4.4.1.m1.1.1.3.3.cmml" xref="S4.T7.4.4.4.1.m1.1.1.3.3"><minus id="S4.T7.4.4.4.1.m1.1.1.3.3.1.cmml" xref="S4.T7.4.4.4.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.4.4.4.1.m1.1.1.3.3.2.cmml" xref="S4.T7.4.4.4.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.4.4.4.1.m1.1c">1.2\times 10^{-4}</annotation></semantics></math></td>
<td id="S4.T7.4.4.4.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.4.4.4.5" class="ltx_td ltx_align_center">manual decay</td>
<td id="S4.T7.4.4.4.6" class="ltx_td ltx_align_center">AdamW</td>
<td id="S4.T7.4.4.4.7" class="ltx_td ltx_align_center">FP16</td>
<td id="S4.T7.4.4.4.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.4.4.4.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.4.4.4.10" class="ltx_td ltx_align_center">0.1</td>
</tr>
<tr id="S4.T7.6.6.6" class="ltx_tr">
<td id="S4.T7.6.6.6.3" class="ltx_td ltx_align_left">PaLM&nbsp;(540B)</td>
<td id="S4.T7.6.6.6.4" class="ltx_td ltx_align_right">1M→4M</td>
<td id="S4.T7.5.5.5.1" class="ltx_td ltx_align_right"><math id="S4.T7.5.5.5.1.m1.1" class="ltx_Math" alttext="1\times 10^{-2}" display="inline"><semantics id="S4.T7.5.5.5.1.m1.1a"><mrow id="S4.T7.5.5.5.1.m1.1.1" xref="S4.T7.5.5.5.1.m1.1.1.cmml"><mn id="S4.T7.5.5.5.1.m1.1.1.2" xref="S4.T7.5.5.5.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.5.5.5.1.m1.1.1.1" xref="S4.T7.5.5.5.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.5.5.5.1.m1.1.1.3" xref="S4.T7.5.5.5.1.m1.1.1.3.cmml"><mn id="S4.T7.5.5.5.1.m1.1.1.3.2" xref="S4.T7.5.5.5.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.5.5.5.1.m1.1.1.3.3" xref="S4.T7.5.5.5.1.m1.1.1.3.3.cmml"><mo id="S4.T7.5.5.5.1.m1.1.1.3.3a" xref="S4.T7.5.5.5.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.5.5.5.1.m1.1.1.3.3.2" xref="S4.T7.5.5.5.1.m1.1.1.3.3.2.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.5.5.5.1.m1.1b"><apply id="S4.T7.5.5.5.1.m1.1.1.cmml" xref="S4.T7.5.5.5.1.m1.1.1"><times id="S4.T7.5.5.5.1.m1.1.1.1.cmml" xref="S4.T7.5.5.5.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.5.5.5.1.m1.1.1.2.cmml" xref="S4.T7.5.5.5.1.m1.1.1.2">1</cn><apply id="S4.T7.5.5.5.1.m1.1.1.3.cmml" xref="S4.T7.5.5.5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.5.5.5.1.m1.1.1.3.1.cmml" xref="S4.T7.5.5.5.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.5.5.5.1.m1.1.1.3.2.cmml" xref="S4.T7.5.5.5.1.m1.1.1.3.2">10</cn><apply id="S4.T7.5.5.5.1.m1.1.1.3.3.cmml" xref="S4.T7.5.5.5.1.m1.1.1.3.3"><minus id="S4.T7.5.5.5.1.m1.1.1.3.3.1.cmml" xref="S4.T7.5.5.5.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.5.5.5.1.m1.1.1.3.3.2.cmml" xref="S4.T7.5.5.5.1.m1.1.1.3.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.5.5.5.1.m1.1c">1\times 10^{-2}</annotation></semantics></math></td>
<td id="S4.T7.6.6.6.5" class="ltx_td ltx_align_center">no</td>
<td id="S4.T7.6.6.6.6" class="ltx_td ltx_align_center">inverse square root</td>
<td id="S4.T7.6.6.6.7" class="ltx_td ltx_align_center">Adafactor</td>
<td id="S4.T7.6.6.6.8" class="ltx_td ltx_align_center">BF16</td>
<td id="S4.T7.6.6.6.2" class="ltx_td ltx_align_center"><math id="S4.T7.6.6.6.2.m1.1" class="ltx_Math" alttext="lr^{2}" display="inline"><semantics id="S4.T7.6.6.6.2.m1.1a"><mrow id="S4.T7.6.6.6.2.m1.1.1" xref="S4.T7.6.6.6.2.m1.1.1.cmml"><mi id="S4.T7.6.6.6.2.m1.1.1.2" xref="S4.T7.6.6.6.2.m1.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.T7.6.6.6.2.m1.1.1.1" xref="S4.T7.6.6.6.2.m1.1.1.1.cmml">​</mo><msup id="S4.T7.6.6.6.2.m1.1.1.3" xref="S4.T7.6.6.6.2.m1.1.1.3.cmml"><mi id="S4.T7.6.6.6.2.m1.1.1.3.2" xref="S4.T7.6.6.6.2.m1.1.1.3.2.cmml">r</mi><mn id="S4.T7.6.6.6.2.m1.1.1.3.3" xref="S4.T7.6.6.6.2.m1.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.6.6.6.2.m1.1b"><apply id="S4.T7.6.6.6.2.m1.1.1.cmml" xref="S4.T7.6.6.6.2.m1.1.1"><times id="S4.T7.6.6.6.2.m1.1.1.1.cmml" xref="S4.T7.6.6.6.2.m1.1.1.1"></times><ci id="S4.T7.6.6.6.2.m1.1.1.2.cmml" xref="S4.T7.6.6.6.2.m1.1.1.2">𝑙</ci><apply id="S4.T7.6.6.6.2.m1.1.1.3.cmml" xref="S4.T7.6.6.6.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.6.6.6.2.m1.1.1.3.1.cmml" xref="S4.T7.6.6.6.2.m1.1.1.3">superscript</csymbol><ci id="S4.T7.6.6.6.2.m1.1.1.3.2.cmml" xref="S4.T7.6.6.6.2.m1.1.1.3.2">𝑟</ci><cn type="integer" id="S4.T7.6.6.6.2.m1.1.1.3.3.cmml" xref="S4.T7.6.6.6.2.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.6.6.6.2.m1.1c">lr^{2}</annotation></semantics></math></td>
<td id="S4.T7.6.6.6.9" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T7.6.6.6.10" class="ltx_td ltx_align_center">0.1</td>
</tr>
<tr id="S4.T7.7.7.7" class="ltx_tr">
<td id="S4.T7.7.7.7.2" class="ltx_td ltx_align_left">BLOOM&nbsp;(176B)</td>
<td id="S4.T7.7.7.7.3" class="ltx_td ltx_align_right">4M</td>
<td id="S4.T7.7.7.7.1" class="ltx_td ltx_align_right"><math id="S4.T7.7.7.7.1.m1.1" class="ltx_Math" alttext="6\times 10^{-5}" display="inline"><semantics id="S4.T7.7.7.7.1.m1.1a"><mrow id="S4.T7.7.7.7.1.m1.1.1" xref="S4.T7.7.7.7.1.m1.1.1.cmml"><mn id="S4.T7.7.7.7.1.m1.1.1.2" xref="S4.T7.7.7.7.1.m1.1.1.2.cmml">6</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.7.7.7.1.m1.1.1.1" xref="S4.T7.7.7.7.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.7.7.7.1.m1.1.1.3" xref="S4.T7.7.7.7.1.m1.1.1.3.cmml"><mn id="S4.T7.7.7.7.1.m1.1.1.3.2" xref="S4.T7.7.7.7.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.7.7.7.1.m1.1.1.3.3" xref="S4.T7.7.7.7.1.m1.1.1.3.3.cmml"><mo id="S4.T7.7.7.7.1.m1.1.1.3.3a" xref="S4.T7.7.7.7.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.7.7.7.1.m1.1.1.3.3.2" xref="S4.T7.7.7.7.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.7.7.7.1.m1.1b"><apply id="S4.T7.7.7.7.1.m1.1.1.cmml" xref="S4.T7.7.7.7.1.m1.1.1"><times id="S4.T7.7.7.7.1.m1.1.1.1.cmml" xref="S4.T7.7.7.7.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.7.7.7.1.m1.1.1.2.cmml" xref="S4.T7.7.7.7.1.m1.1.1.2">6</cn><apply id="S4.T7.7.7.7.1.m1.1.1.3.cmml" xref="S4.T7.7.7.7.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.7.7.7.1.m1.1.1.3.1.cmml" xref="S4.T7.7.7.7.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.7.7.7.1.m1.1.1.3.2.cmml" xref="S4.T7.7.7.7.1.m1.1.1.3.2">10</cn><apply id="S4.T7.7.7.7.1.m1.1.1.3.3.cmml" xref="S4.T7.7.7.7.1.m1.1.1.3.3"><minus id="S4.T7.7.7.7.1.m1.1.1.3.3.1.cmml" xref="S4.T7.7.7.7.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.7.7.7.1.m1.1.1.3.3.2.cmml" xref="S4.T7.7.7.7.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.7.7.7.1.m1.1c">6\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T7.7.7.7.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.7.7.7.5" class="ltx_td ltx_align_center">cosine decay to 10%</td>
<td id="S4.T7.7.7.7.6" class="ltx_td ltx_align_center">Adam</td>
<td id="S4.T7.7.7.7.7" class="ltx_td ltx_align_center">BF16</td>
<td id="S4.T7.7.7.7.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.7.7.7.9" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T7.7.7.7.10" class="ltx_td ltx_align_center">0.0</td>
</tr>
<tr id="S4.T7.8.8.8" class="ltx_tr">
<td id="S4.T7.8.8.8.2" class="ltx_td ltx_align_left">MT-NLG&nbsp;(530B)</td>
<td id="S4.T7.8.8.8.3" class="ltx_td ltx_align_right">64 K→3.75M</td>
<td id="S4.T7.8.8.8.1" class="ltx_td ltx_align_right"><math id="S4.T7.8.8.8.1.m1.1" class="ltx_Math" alttext="5\times 10^{-5}" display="inline"><semantics id="S4.T7.8.8.8.1.m1.1a"><mrow id="S4.T7.8.8.8.1.m1.1.1" xref="S4.T7.8.8.8.1.m1.1.1.cmml"><mn id="S4.T7.8.8.8.1.m1.1.1.2" xref="S4.T7.8.8.8.1.m1.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.8.8.8.1.m1.1.1.1" xref="S4.T7.8.8.8.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.8.8.8.1.m1.1.1.3" xref="S4.T7.8.8.8.1.m1.1.1.3.cmml"><mn id="S4.T7.8.8.8.1.m1.1.1.3.2" xref="S4.T7.8.8.8.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.8.8.8.1.m1.1.1.3.3" xref="S4.T7.8.8.8.1.m1.1.1.3.3.cmml"><mo id="S4.T7.8.8.8.1.m1.1.1.3.3a" xref="S4.T7.8.8.8.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.8.8.8.1.m1.1.1.3.3.2" xref="S4.T7.8.8.8.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.8.8.8.1.m1.1b"><apply id="S4.T7.8.8.8.1.m1.1.1.cmml" xref="S4.T7.8.8.8.1.m1.1.1"><times id="S4.T7.8.8.8.1.m1.1.1.1.cmml" xref="S4.T7.8.8.8.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.8.8.8.1.m1.1.1.2.cmml" xref="S4.T7.8.8.8.1.m1.1.1.2">5</cn><apply id="S4.T7.8.8.8.1.m1.1.1.3.cmml" xref="S4.T7.8.8.8.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.8.8.8.1.m1.1.1.3.1.cmml" xref="S4.T7.8.8.8.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.8.8.8.1.m1.1.1.3.2.cmml" xref="S4.T7.8.8.8.1.m1.1.1.3.2">10</cn><apply id="S4.T7.8.8.8.1.m1.1.1.3.3.cmml" xref="S4.T7.8.8.8.1.m1.1.1.3.3"><minus id="S4.T7.8.8.8.1.m1.1.1.3.3.1.cmml" xref="S4.T7.8.8.8.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.8.8.8.1.m1.1.1.3.3.2.cmml" xref="S4.T7.8.8.8.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.8.8.8.1.m1.1c">5\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T7.8.8.8.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.8.8.8.5" class="ltx_td ltx_align_center">cosine decay to 10%</td>
<td id="S4.T7.8.8.8.6" class="ltx_td ltx_align_center">Adam</td>
<td id="S4.T7.8.8.8.7" class="ltx_td ltx_align_center">BF16</td>
<td id="S4.T7.8.8.8.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.8.8.8.9" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T7.8.8.8.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.9.9.9" class="ltx_tr">
<td id="S4.T7.9.9.9.2" class="ltx_td ltx_align_left">Gopher&nbsp;(280B)</td>
<td id="S4.T7.9.9.9.3" class="ltx_td ltx_align_right">3M→6M</td>
<td id="S4.T7.9.9.9.1" class="ltx_td ltx_align_right"><math id="S4.T7.9.9.9.1.m1.1" class="ltx_Math" alttext="4\times 10^{-5}" display="inline"><semantics id="S4.T7.9.9.9.1.m1.1a"><mrow id="S4.T7.9.9.9.1.m1.1.1" xref="S4.T7.9.9.9.1.m1.1.1.cmml"><mn id="S4.T7.9.9.9.1.m1.1.1.2" xref="S4.T7.9.9.9.1.m1.1.1.2.cmml">4</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.9.9.9.1.m1.1.1.1" xref="S4.T7.9.9.9.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.9.9.9.1.m1.1.1.3" xref="S4.T7.9.9.9.1.m1.1.1.3.cmml"><mn id="S4.T7.9.9.9.1.m1.1.1.3.2" xref="S4.T7.9.9.9.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.9.9.9.1.m1.1.1.3.3" xref="S4.T7.9.9.9.1.m1.1.1.3.3.cmml"><mo id="S4.T7.9.9.9.1.m1.1.1.3.3a" xref="S4.T7.9.9.9.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.9.9.9.1.m1.1.1.3.3.2" xref="S4.T7.9.9.9.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.9.9.9.1.m1.1b"><apply id="S4.T7.9.9.9.1.m1.1.1.cmml" xref="S4.T7.9.9.9.1.m1.1.1"><times id="S4.T7.9.9.9.1.m1.1.1.1.cmml" xref="S4.T7.9.9.9.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.9.9.9.1.m1.1.1.2.cmml" xref="S4.T7.9.9.9.1.m1.1.1.2">4</cn><apply id="S4.T7.9.9.9.1.m1.1.1.3.cmml" xref="S4.T7.9.9.9.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.9.9.9.1.m1.1.1.3.1.cmml" xref="S4.T7.9.9.9.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.9.9.9.1.m1.1.1.3.2.cmml" xref="S4.T7.9.9.9.1.m1.1.1.3.2">10</cn><apply id="S4.T7.9.9.9.1.m1.1.1.3.3.cmml" xref="S4.T7.9.9.9.1.m1.1.1.3.3"><minus id="S4.T7.9.9.9.1.m1.1.1.3.3.1.cmml" xref="S4.T7.9.9.9.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.9.9.9.1.m1.1.1.3.3.2.cmml" xref="S4.T7.9.9.9.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.9.9.9.1.m1.1c">4\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T7.9.9.9.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.9.9.9.5" class="ltx_td ltx_align_center">cosine decay to 10%</td>
<td id="S4.T7.9.9.9.6" class="ltx_td ltx_align_center">Adam</td>
<td id="S4.T7.9.9.9.7" class="ltx_td ltx_align_center">BF16</td>
<td id="S4.T7.9.9.9.8" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.9.9.9.9" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T7.9.9.9.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.10.10.10" class="ltx_tr">
<td id="S4.T7.10.10.10.2" class="ltx_td ltx_align_left">Chinchilla&nbsp;(70B)</td>
<td id="S4.T7.10.10.10.3" class="ltx_td ltx_align_right">1.5M→3M</td>
<td id="S4.T7.10.10.10.1" class="ltx_td ltx_align_right"><math id="S4.T7.10.10.10.1.m1.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S4.T7.10.10.10.1.m1.1a"><mrow id="S4.T7.10.10.10.1.m1.1.1" xref="S4.T7.10.10.10.1.m1.1.1.cmml"><mn id="S4.T7.10.10.10.1.m1.1.1.2" xref="S4.T7.10.10.10.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.10.10.10.1.m1.1.1.1" xref="S4.T7.10.10.10.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.10.10.10.1.m1.1.1.3" xref="S4.T7.10.10.10.1.m1.1.1.3.cmml"><mn id="S4.T7.10.10.10.1.m1.1.1.3.2" xref="S4.T7.10.10.10.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.10.10.10.1.m1.1.1.3.3" xref="S4.T7.10.10.10.1.m1.1.1.3.3.cmml"><mo id="S4.T7.10.10.10.1.m1.1.1.3.3a" xref="S4.T7.10.10.10.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.10.10.10.1.m1.1.1.3.3.2" xref="S4.T7.10.10.10.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.10.10.10.1.m1.1b"><apply id="S4.T7.10.10.10.1.m1.1.1.cmml" xref="S4.T7.10.10.10.1.m1.1.1"><times id="S4.T7.10.10.10.1.m1.1.1.1.cmml" xref="S4.T7.10.10.10.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.10.10.10.1.m1.1.1.2.cmml" xref="S4.T7.10.10.10.1.m1.1.1.2">1</cn><apply id="S4.T7.10.10.10.1.m1.1.1.3.cmml" xref="S4.T7.10.10.10.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.10.10.10.1.m1.1.1.3.1.cmml" xref="S4.T7.10.10.10.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.10.10.10.1.m1.1.1.3.2.cmml" xref="S4.T7.10.10.10.1.m1.1.1.3.2">10</cn><apply id="S4.T7.10.10.10.1.m1.1.1.3.3.cmml" xref="S4.T7.10.10.10.1.m1.1.1.3.3"><minus id="S4.T7.10.10.10.1.m1.1.1.3.3.1.cmml" xref="S4.T7.10.10.10.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.10.10.10.1.m1.1.1.3.3.2.cmml" xref="S4.T7.10.10.10.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.10.10.10.1.m1.1c">1\times 10^{-4}</annotation></semantics></math></td>
<td id="S4.T7.10.10.10.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.10.10.10.5" class="ltx_td ltx_align_center">cosine decay to 10%</td>
<td id="S4.T7.10.10.10.6" class="ltx_td ltx_align_center">AdamW</td>
<td id="S4.T7.10.10.10.7" class="ltx_td ltx_align_center">BF16</td>
<td id="S4.T7.10.10.10.8" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.10.10.10.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.10.10.10.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.11.11.11" class="ltx_tr">
<td id="S4.T7.11.11.11.2" class="ltx_td ltx_align_left">Galactica&nbsp;(120B)</td>
<td id="S4.T7.11.11.11.3" class="ltx_td ltx_align_right">2M</td>
<td id="S4.T7.11.11.11.1" class="ltx_td ltx_align_right"><math id="S4.T7.11.11.11.1.m1.1" class="ltx_Math" alttext="7\times 10^{-6}" display="inline"><semantics id="S4.T7.11.11.11.1.m1.1a"><mrow id="S4.T7.11.11.11.1.m1.1.1" xref="S4.T7.11.11.11.1.m1.1.1.cmml"><mn id="S4.T7.11.11.11.1.m1.1.1.2" xref="S4.T7.11.11.11.1.m1.1.1.2.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.11.11.11.1.m1.1.1.1" xref="S4.T7.11.11.11.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.11.11.11.1.m1.1.1.3" xref="S4.T7.11.11.11.1.m1.1.1.3.cmml"><mn id="S4.T7.11.11.11.1.m1.1.1.3.2" xref="S4.T7.11.11.11.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.11.11.11.1.m1.1.1.3.3" xref="S4.T7.11.11.11.1.m1.1.1.3.3.cmml"><mo id="S4.T7.11.11.11.1.m1.1.1.3.3a" xref="S4.T7.11.11.11.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.11.11.11.1.m1.1.1.3.3.2" xref="S4.T7.11.11.11.1.m1.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.11.11.11.1.m1.1b"><apply id="S4.T7.11.11.11.1.m1.1.1.cmml" xref="S4.T7.11.11.11.1.m1.1.1"><times id="S4.T7.11.11.11.1.m1.1.1.1.cmml" xref="S4.T7.11.11.11.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.11.11.11.1.m1.1.1.2.cmml" xref="S4.T7.11.11.11.1.m1.1.1.2">7</cn><apply id="S4.T7.11.11.11.1.m1.1.1.3.cmml" xref="S4.T7.11.11.11.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.11.11.11.1.m1.1.1.3.1.cmml" xref="S4.T7.11.11.11.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.11.11.11.1.m1.1.1.3.2.cmml" xref="S4.T7.11.11.11.1.m1.1.1.3.2">10</cn><apply id="S4.T7.11.11.11.1.m1.1.1.3.3.cmml" xref="S4.T7.11.11.11.1.m1.1.1.3.3"><minus id="S4.T7.11.11.11.1.m1.1.1.3.3.1.cmml" xref="S4.T7.11.11.11.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.11.11.11.1.m1.1.1.3.3.2.cmml" xref="S4.T7.11.11.11.1.m1.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.11.11.11.1.m1.1c">7\times 10^{-6}</annotation></semantics></math></td>
<td id="S4.T7.11.11.11.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.11.11.11.5" class="ltx_td ltx_align_center">linear decay to 10%</td>
<td id="S4.T7.11.11.11.6" class="ltx_td ltx_align_center">AdamW</td>
<td id="S4.T7.11.11.11.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.11.11.11.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.11.11.11.9" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T7.11.11.11.10" class="ltx_td ltx_align_center">0.1</td>
</tr>
<tr id="S4.T7.20.20.22" class="ltx_tr">
<td id="S4.T7.20.20.22.1" class="ltx_td ltx_align_left">LaMDA&nbsp;(137B)</td>
<td id="S4.T7.20.20.22.2" class="ltx_td ltx_align_right">256K</td>
<td id="S4.T7.20.20.22.3" class="ltx_td ltx_align_right">-</td>
<td id="S4.T7.20.20.22.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.20.20.22.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.20.20.22.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.20.20.22.7" class="ltx_td ltx_align_center">BF16</td>
<td id="S4.T7.20.20.22.8" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.20.20.22.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.20.20.22.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.12.12.12" class="ltx_tr">
<td id="S4.T7.12.12.12.2" class="ltx_td ltx_align_left">Jurassic-1&nbsp;(178B)</td>
<td id="S4.T7.12.12.12.3" class="ltx_td ltx_align_right">32 K→3.2M</td>
<td id="S4.T7.12.12.12.1" class="ltx_td ltx_align_right"><math id="S4.T7.12.12.12.1.m1.1" class="ltx_Math" alttext="6\times 10^{-5}" display="inline"><semantics id="S4.T7.12.12.12.1.m1.1a"><mrow id="S4.T7.12.12.12.1.m1.1.1" xref="S4.T7.12.12.12.1.m1.1.1.cmml"><mn id="S4.T7.12.12.12.1.m1.1.1.2" xref="S4.T7.12.12.12.1.m1.1.1.2.cmml">6</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.12.12.12.1.m1.1.1.1" xref="S4.T7.12.12.12.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.12.12.12.1.m1.1.1.3" xref="S4.T7.12.12.12.1.m1.1.1.3.cmml"><mn id="S4.T7.12.12.12.1.m1.1.1.3.2" xref="S4.T7.12.12.12.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.12.12.12.1.m1.1.1.3.3" xref="S4.T7.12.12.12.1.m1.1.1.3.3.cmml"><mo id="S4.T7.12.12.12.1.m1.1.1.3.3a" xref="S4.T7.12.12.12.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.12.12.12.1.m1.1.1.3.3.2" xref="S4.T7.12.12.12.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.12.12.12.1.m1.1b"><apply id="S4.T7.12.12.12.1.m1.1.1.cmml" xref="S4.T7.12.12.12.1.m1.1.1"><times id="S4.T7.12.12.12.1.m1.1.1.1.cmml" xref="S4.T7.12.12.12.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.12.12.12.1.m1.1.1.2.cmml" xref="S4.T7.12.12.12.1.m1.1.1.2">6</cn><apply id="S4.T7.12.12.12.1.m1.1.1.3.cmml" xref="S4.T7.12.12.12.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.12.12.12.1.m1.1.1.3.1.cmml" xref="S4.T7.12.12.12.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.12.12.12.1.m1.1.1.3.2.cmml" xref="S4.T7.12.12.12.1.m1.1.1.3.2">10</cn><apply id="S4.T7.12.12.12.1.m1.1.1.3.3.cmml" xref="S4.T7.12.12.12.1.m1.1.1.3.3"><minus id="S4.T7.12.12.12.1.m1.1.1.3.3.1.cmml" xref="S4.T7.12.12.12.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.12.12.12.1.m1.1.1.3.3.2.cmml" xref="S4.T7.12.12.12.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.12.12.12.1.m1.1c">6\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T7.12.12.12.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.12.12.12.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.12.12.12.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.12.12.12.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.12.12.12.8" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.12.12.12.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.12.12.12.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.13.13.13" class="ltx_tr">
<td id="S4.T7.13.13.13.2" class="ltx_td ltx_align_left">LLaMA&nbsp;(65B)</td>
<td id="S4.T7.13.13.13.3" class="ltx_td ltx_align_right">4M</td>
<td id="S4.T7.13.13.13.1" class="ltx_td ltx_align_right"><math id="S4.T7.13.13.13.1.m1.1" class="ltx_Math" alttext="1.5\times 10^{-4}" display="inline"><semantics id="S4.T7.13.13.13.1.m1.1a"><mrow id="S4.T7.13.13.13.1.m1.1.1" xref="S4.T7.13.13.13.1.m1.1.1.cmml"><mn id="S4.T7.13.13.13.1.m1.1.1.2" xref="S4.T7.13.13.13.1.m1.1.1.2.cmml">1.5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.13.13.13.1.m1.1.1.1" xref="S4.T7.13.13.13.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.13.13.13.1.m1.1.1.3" xref="S4.T7.13.13.13.1.m1.1.1.3.cmml"><mn id="S4.T7.13.13.13.1.m1.1.1.3.2" xref="S4.T7.13.13.13.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.13.13.13.1.m1.1.1.3.3" xref="S4.T7.13.13.13.1.m1.1.1.3.3.cmml"><mo id="S4.T7.13.13.13.1.m1.1.1.3.3a" xref="S4.T7.13.13.13.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.13.13.13.1.m1.1.1.3.3.2" xref="S4.T7.13.13.13.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.13.13.13.1.m1.1b"><apply id="S4.T7.13.13.13.1.m1.1.1.cmml" xref="S4.T7.13.13.13.1.m1.1.1"><times id="S4.T7.13.13.13.1.m1.1.1.1.cmml" xref="S4.T7.13.13.13.1.m1.1.1.1"></times><cn type="float" id="S4.T7.13.13.13.1.m1.1.1.2.cmml" xref="S4.T7.13.13.13.1.m1.1.1.2">1.5</cn><apply id="S4.T7.13.13.13.1.m1.1.1.3.cmml" xref="S4.T7.13.13.13.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.13.13.13.1.m1.1.1.3.1.cmml" xref="S4.T7.13.13.13.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.13.13.13.1.m1.1.1.3.2.cmml" xref="S4.T7.13.13.13.1.m1.1.1.3.2">10</cn><apply id="S4.T7.13.13.13.1.m1.1.1.3.3.cmml" xref="S4.T7.13.13.13.1.m1.1.1.3.3"><minus id="S4.T7.13.13.13.1.m1.1.1.3.3.1.cmml" xref="S4.T7.13.13.13.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.13.13.13.1.m1.1.1.3.3.2.cmml" xref="S4.T7.13.13.13.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.13.13.13.1.m1.1c">1.5\times 10^{-4}</annotation></semantics></math></td>
<td id="S4.T7.13.13.13.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.13.13.13.5" class="ltx_td ltx_align_center">cosine decay to 10%</td>
<td id="S4.T7.13.13.13.6" class="ltx_td ltx_align_center">AdamW</td>
<td id="S4.T7.13.13.13.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.13.13.13.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.13.13.13.9" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T7.13.13.13.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.14.14.14" class="ltx_tr">
<td id="S4.T7.14.14.14.2" class="ltx_td ltx_align_left">LLaMA 2&nbsp;(70B)</td>
<td id="S4.T7.14.14.14.3" class="ltx_td ltx_align_right">4M</td>
<td id="S4.T7.14.14.14.1" class="ltx_td ltx_align_right"><math id="S4.T7.14.14.14.1.m1.1" class="ltx_Math" alttext="1.5\times 10^{-4}" display="inline"><semantics id="S4.T7.14.14.14.1.m1.1a"><mrow id="S4.T7.14.14.14.1.m1.1.1" xref="S4.T7.14.14.14.1.m1.1.1.cmml"><mn id="S4.T7.14.14.14.1.m1.1.1.2" xref="S4.T7.14.14.14.1.m1.1.1.2.cmml">1.5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.14.14.14.1.m1.1.1.1" xref="S4.T7.14.14.14.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.14.14.14.1.m1.1.1.3" xref="S4.T7.14.14.14.1.m1.1.1.3.cmml"><mn id="S4.T7.14.14.14.1.m1.1.1.3.2" xref="S4.T7.14.14.14.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.14.14.14.1.m1.1.1.3.3" xref="S4.T7.14.14.14.1.m1.1.1.3.3.cmml"><mo id="S4.T7.14.14.14.1.m1.1.1.3.3a" xref="S4.T7.14.14.14.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.14.14.14.1.m1.1.1.3.3.2" xref="S4.T7.14.14.14.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.14.14.14.1.m1.1b"><apply id="S4.T7.14.14.14.1.m1.1.1.cmml" xref="S4.T7.14.14.14.1.m1.1.1"><times id="S4.T7.14.14.14.1.m1.1.1.1.cmml" xref="S4.T7.14.14.14.1.m1.1.1.1"></times><cn type="float" id="S4.T7.14.14.14.1.m1.1.1.2.cmml" xref="S4.T7.14.14.14.1.m1.1.1.2">1.5</cn><apply id="S4.T7.14.14.14.1.m1.1.1.3.cmml" xref="S4.T7.14.14.14.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.14.14.14.1.m1.1.1.3.1.cmml" xref="S4.T7.14.14.14.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.14.14.14.1.m1.1.1.3.2.cmml" xref="S4.T7.14.14.14.1.m1.1.1.3.2">10</cn><apply id="S4.T7.14.14.14.1.m1.1.1.3.3.cmml" xref="S4.T7.14.14.14.1.m1.1.1.3.3"><minus id="S4.T7.14.14.14.1.m1.1.1.3.3.1.cmml" xref="S4.T7.14.14.14.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.14.14.14.1.m1.1.1.3.3.2.cmml" xref="S4.T7.14.14.14.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.14.14.14.1.m1.1c">1.5\times 10^{-4}</annotation></semantics></math></td>
<td id="S4.T7.14.14.14.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.14.14.14.5" class="ltx_td ltx_align_center">cosine decay to 10%</td>
<td id="S4.T7.14.14.14.6" class="ltx_td ltx_align_center">AdamW</td>
<td id="S4.T7.14.14.14.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.14.14.14.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.14.14.14.9" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T7.14.14.14.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.15.15.15" class="ltx_tr">
<td id="S4.T7.15.15.15.2" class="ltx_td ltx_align_left">Falcon&nbsp;(40B)</td>
<td id="S4.T7.15.15.15.3" class="ltx_td ltx_align_right">2M</td>
<td id="S4.T7.15.15.15.1" class="ltx_td ltx_align_right"><math id="S4.T7.15.15.15.1.m1.1" class="ltx_Math" alttext="1.85\times 10^{-4}" display="inline"><semantics id="S4.T7.15.15.15.1.m1.1a"><mrow id="S4.T7.15.15.15.1.m1.1.1" xref="S4.T7.15.15.15.1.m1.1.1.cmml"><mn id="S4.T7.15.15.15.1.m1.1.1.2" xref="S4.T7.15.15.15.1.m1.1.1.2.cmml">1.85</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.15.15.15.1.m1.1.1.1" xref="S4.T7.15.15.15.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.15.15.15.1.m1.1.1.3" xref="S4.T7.15.15.15.1.m1.1.1.3.cmml"><mn id="S4.T7.15.15.15.1.m1.1.1.3.2" xref="S4.T7.15.15.15.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.15.15.15.1.m1.1.1.3.3" xref="S4.T7.15.15.15.1.m1.1.1.3.3.cmml"><mo id="S4.T7.15.15.15.1.m1.1.1.3.3a" xref="S4.T7.15.15.15.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.15.15.15.1.m1.1.1.3.3.2" xref="S4.T7.15.15.15.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.15.15.15.1.m1.1b"><apply id="S4.T7.15.15.15.1.m1.1.1.cmml" xref="S4.T7.15.15.15.1.m1.1.1"><times id="S4.T7.15.15.15.1.m1.1.1.1.cmml" xref="S4.T7.15.15.15.1.m1.1.1.1"></times><cn type="float" id="S4.T7.15.15.15.1.m1.1.1.2.cmml" xref="S4.T7.15.15.15.1.m1.1.1.2">1.85</cn><apply id="S4.T7.15.15.15.1.m1.1.1.3.cmml" xref="S4.T7.15.15.15.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.15.15.15.1.m1.1.1.3.1.cmml" xref="S4.T7.15.15.15.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.15.15.15.1.m1.1.1.3.2.cmml" xref="S4.T7.15.15.15.1.m1.1.1.3.2">10</cn><apply id="S4.T7.15.15.15.1.m1.1.1.3.3.cmml" xref="S4.T7.15.15.15.1.m1.1.1.3.3"><minus id="S4.T7.15.15.15.1.m1.1.1.3.3.1.cmml" xref="S4.T7.15.15.15.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.15.15.15.1.m1.1.1.3.3.2.cmml" xref="S4.T7.15.15.15.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.15.15.15.1.m1.1c">1.85\times 10^{-4}</annotation></semantics></math></td>
<td id="S4.T7.15.15.15.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.15.15.15.5" class="ltx_td ltx_align_center">cosine decay to 10%</td>
<td id="S4.T7.15.15.15.6" class="ltx_td ltx_align_center">AdamW</td>
<td id="S4.T7.15.15.15.7" class="ltx_td ltx_align_center">BF16</td>
<td id="S4.T7.15.15.15.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.15.15.15.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.15.15.15.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.16.16.16" class="ltx_tr">
<td id="S4.T7.16.16.16.2" class="ltx_td ltx_align_left">GLM&nbsp;(130B)</td>
<td id="S4.T7.16.16.16.3" class="ltx_td ltx_align_right">0.4M→8.25M</td>
<td id="S4.T7.16.16.16.1" class="ltx_td ltx_align_right"><math id="S4.T7.16.16.16.1.m1.1" class="ltx_Math" alttext="8\times 10^{-5}" display="inline"><semantics id="S4.T7.16.16.16.1.m1.1a"><mrow id="S4.T7.16.16.16.1.m1.1.1" xref="S4.T7.16.16.16.1.m1.1.1.cmml"><mn id="S4.T7.16.16.16.1.m1.1.1.2" xref="S4.T7.16.16.16.1.m1.1.1.2.cmml">8</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.16.16.16.1.m1.1.1.1" xref="S4.T7.16.16.16.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.16.16.16.1.m1.1.1.3" xref="S4.T7.16.16.16.1.m1.1.1.3.cmml"><mn id="S4.T7.16.16.16.1.m1.1.1.3.2" xref="S4.T7.16.16.16.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.16.16.16.1.m1.1.1.3.3" xref="S4.T7.16.16.16.1.m1.1.1.3.3.cmml"><mo id="S4.T7.16.16.16.1.m1.1.1.3.3a" xref="S4.T7.16.16.16.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.16.16.16.1.m1.1.1.3.3.2" xref="S4.T7.16.16.16.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.16.16.16.1.m1.1b"><apply id="S4.T7.16.16.16.1.m1.1.1.cmml" xref="S4.T7.16.16.16.1.m1.1.1"><times id="S4.T7.16.16.16.1.m1.1.1.1.cmml" xref="S4.T7.16.16.16.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.16.16.16.1.m1.1.1.2.cmml" xref="S4.T7.16.16.16.1.m1.1.1.2">8</cn><apply id="S4.T7.16.16.16.1.m1.1.1.3.cmml" xref="S4.T7.16.16.16.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.16.16.16.1.m1.1.1.3.1.cmml" xref="S4.T7.16.16.16.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.16.16.16.1.m1.1.1.3.2.cmml" xref="S4.T7.16.16.16.1.m1.1.1.3.2">10</cn><apply id="S4.T7.16.16.16.1.m1.1.1.3.3.cmml" xref="S4.T7.16.16.16.1.m1.1.1.3.3"><minus id="S4.T7.16.16.16.1.m1.1.1.3.3.1.cmml" xref="S4.T7.16.16.16.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.16.16.16.1.m1.1.1.3.3.2.cmml" xref="S4.T7.16.16.16.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.16.16.16.1.m1.1c">8\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T7.16.16.16.4" class="ltx_td ltx_align_center">yes</td>
<td id="S4.T7.16.16.16.5" class="ltx_td ltx_align_center">cosine decay to 10%</td>
<td id="S4.T7.16.16.16.6" class="ltx_td ltx_align_center">AdamW</td>
<td id="S4.T7.16.16.16.7" class="ltx_td ltx_align_center">FP16</td>
<td id="S4.T7.16.16.16.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.16.16.16.9" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T7.16.16.16.10" class="ltx_td ltx_align_center">0.1</td>
</tr>
<tr id="S4.T7.17.17.17" class="ltx_tr">
<td id="S4.T7.17.17.17.2" class="ltx_td ltx_align_left">T5&nbsp;(11B)</td>
<td id="S4.T7.17.17.17.3" class="ltx_td ltx_align_right">64K</td>
<td id="S4.T7.17.17.17.1" class="ltx_td ltx_align_right"><math id="S4.T7.17.17.17.1.m1.1" class="ltx_Math" alttext="1\times 10^{-2}" display="inline"><semantics id="S4.T7.17.17.17.1.m1.1a"><mrow id="S4.T7.17.17.17.1.m1.1.1" xref="S4.T7.17.17.17.1.m1.1.1.cmml"><mn id="S4.T7.17.17.17.1.m1.1.1.2" xref="S4.T7.17.17.17.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.17.17.17.1.m1.1.1.1" xref="S4.T7.17.17.17.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.17.17.17.1.m1.1.1.3" xref="S4.T7.17.17.17.1.m1.1.1.3.cmml"><mn id="S4.T7.17.17.17.1.m1.1.1.3.2" xref="S4.T7.17.17.17.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.17.17.17.1.m1.1.1.3.3" xref="S4.T7.17.17.17.1.m1.1.1.3.3.cmml"><mo id="S4.T7.17.17.17.1.m1.1.1.3.3a" xref="S4.T7.17.17.17.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.17.17.17.1.m1.1.1.3.3.2" xref="S4.T7.17.17.17.1.m1.1.1.3.3.2.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.17.17.17.1.m1.1b"><apply id="S4.T7.17.17.17.1.m1.1.1.cmml" xref="S4.T7.17.17.17.1.m1.1.1"><times id="S4.T7.17.17.17.1.m1.1.1.1.cmml" xref="S4.T7.17.17.17.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.17.17.17.1.m1.1.1.2.cmml" xref="S4.T7.17.17.17.1.m1.1.1.2">1</cn><apply id="S4.T7.17.17.17.1.m1.1.1.3.cmml" xref="S4.T7.17.17.17.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.17.17.17.1.m1.1.1.3.1.cmml" xref="S4.T7.17.17.17.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.17.17.17.1.m1.1.1.3.2.cmml" xref="S4.T7.17.17.17.1.m1.1.1.3.2">10</cn><apply id="S4.T7.17.17.17.1.m1.1.1.3.3.cmml" xref="S4.T7.17.17.17.1.m1.1.1.3.3"><minus id="S4.T7.17.17.17.1.m1.1.1.3.3.1.cmml" xref="S4.T7.17.17.17.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.17.17.17.1.m1.1.1.3.3.2.cmml" xref="S4.T7.17.17.17.1.m1.1.1.3.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.17.17.17.1.m1.1c">1\times 10^{-2}</annotation></semantics></math></td>
<td id="S4.T7.17.17.17.4" class="ltx_td ltx_align_center">no</td>
<td id="S4.T7.17.17.17.5" class="ltx_td ltx_align_center">inverse square root</td>
<td id="S4.T7.17.17.17.6" class="ltx_td ltx_align_center">AdaFactor</td>
<td id="S4.T7.17.17.17.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.17.17.17.8" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.17.17.17.9" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.17.17.17.10" class="ltx_td ltx_align_center">0.1</td>
</tr>
<tr id="S4.T7.18.18.18" class="ltx_tr">
<td id="S4.T7.18.18.18.2" class="ltx_td ltx_align_left">ERNIE 3.0 Titan&nbsp;(260B)</td>
<td id="S4.T7.18.18.18.3" class="ltx_td ltx_align_right">-</td>
<td id="S4.T7.18.18.18.1" class="ltx_td ltx_align_right"><math id="S4.T7.18.18.18.1.m1.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S4.T7.18.18.18.1.m1.1a"><mrow id="S4.T7.18.18.18.1.m1.1.1" xref="S4.T7.18.18.18.1.m1.1.1.cmml"><mn id="S4.T7.18.18.18.1.m1.1.1.2" xref="S4.T7.18.18.18.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.18.18.18.1.m1.1.1.1" xref="S4.T7.18.18.18.1.m1.1.1.1.cmml">×</mo><msup id="S4.T7.18.18.18.1.m1.1.1.3" xref="S4.T7.18.18.18.1.m1.1.1.3.cmml"><mn id="S4.T7.18.18.18.1.m1.1.1.3.2" xref="S4.T7.18.18.18.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.18.18.18.1.m1.1.1.3.3" xref="S4.T7.18.18.18.1.m1.1.1.3.3.cmml"><mo id="S4.T7.18.18.18.1.m1.1.1.3.3a" xref="S4.T7.18.18.18.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.18.18.18.1.m1.1.1.3.3.2" xref="S4.T7.18.18.18.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.18.18.18.1.m1.1b"><apply id="S4.T7.18.18.18.1.m1.1.1.cmml" xref="S4.T7.18.18.18.1.m1.1.1"><times id="S4.T7.18.18.18.1.m1.1.1.1.cmml" xref="S4.T7.18.18.18.1.m1.1.1.1"></times><cn type="integer" id="S4.T7.18.18.18.1.m1.1.1.2.cmml" xref="S4.T7.18.18.18.1.m1.1.1.2">1</cn><apply id="S4.T7.18.18.18.1.m1.1.1.3.cmml" xref="S4.T7.18.18.18.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.18.18.18.1.m1.1.1.3.1.cmml" xref="S4.T7.18.18.18.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.18.18.18.1.m1.1.1.3.2.cmml" xref="S4.T7.18.18.18.1.m1.1.1.3.2">10</cn><apply id="S4.T7.18.18.18.1.m1.1.1.3.3.cmml" xref="S4.T7.18.18.18.1.m1.1.1.3.3"><minus id="S4.T7.18.18.18.1.m1.1.1.3.3.1.cmml" xref="S4.T7.18.18.18.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.18.18.18.1.m1.1.1.3.3.2.cmml" xref="S4.T7.18.18.18.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.18.18.18.1.m1.1c">1\times 10^{-4}</annotation></semantics></math></td>
<td id="S4.T7.18.18.18.4" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.18.18.18.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T7.18.18.18.6" class="ltx_td ltx_align_center">Adam</td>
<td id="S4.T7.18.18.18.7" class="ltx_td ltx_align_center">FP16</td>
<td id="S4.T7.18.18.18.8" class="ltx_td ltx_align_center">0.1</td>
<td id="S4.T7.18.18.18.9" class="ltx_td ltx_align_center">1.0</td>
<td id="S4.T7.18.18.18.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T7.20.20.20" class="ltx_tr">
<td id="S4.T7.19.19.19.1" class="ltx_td ltx_align_left ltx_border_bb">PanGu-<math id="S4.T7.19.19.19.1.m1.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S4.T7.19.19.19.1.m1.1a"><mi mathvariant="normal" id="S4.T7.19.19.19.1.m1.1.1" xref="S4.T7.19.19.19.1.m1.1.1.cmml">Σ</mi><annotation-xml encoding="MathML-Content" id="S4.T7.19.19.19.1.m1.1b"><ci id="S4.T7.19.19.19.1.m1.1.1.cmml" xref="S4.T7.19.19.19.1.m1.1.1">Σ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.19.19.19.1.m1.1c">\Sigma</annotation></semantics></math>&nbsp;(1.085T)</td>
<td id="S4.T7.20.20.20.3" class="ltx_td ltx_align_right ltx_border_bb">0.5M</td>
<td id="S4.T7.20.20.20.2" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T7.20.20.20.2.m1.1" class="ltx_Math" alttext="2\times 10^{-5}" display="inline"><semantics id="S4.T7.20.20.20.2.m1.1a"><mrow id="S4.T7.20.20.20.2.m1.1.1" xref="S4.T7.20.20.20.2.m1.1.1.cmml"><mn id="S4.T7.20.20.20.2.m1.1.1.2" xref="S4.T7.20.20.20.2.m1.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T7.20.20.20.2.m1.1.1.1" xref="S4.T7.20.20.20.2.m1.1.1.1.cmml">×</mo><msup id="S4.T7.20.20.20.2.m1.1.1.3" xref="S4.T7.20.20.20.2.m1.1.1.3.cmml"><mn id="S4.T7.20.20.20.2.m1.1.1.3.2" xref="S4.T7.20.20.20.2.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T7.20.20.20.2.m1.1.1.3.3" xref="S4.T7.20.20.20.2.m1.1.1.3.3.cmml"><mo id="S4.T7.20.20.20.2.m1.1.1.3.3a" xref="S4.T7.20.20.20.2.m1.1.1.3.3.cmml">−</mo><mn id="S4.T7.20.20.20.2.m1.1.1.3.3.2" xref="S4.T7.20.20.20.2.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T7.20.20.20.2.m1.1b"><apply id="S4.T7.20.20.20.2.m1.1.1.cmml" xref="S4.T7.20.20.20.2.m1.1.1"><times id="S4.T7.20.20.20.2.m1.1.1.1.cmml" xref="S4.T7.20.20.20.2.m1.1.1.1"></times><cn type="integer" id="S4.T7.20.20.20.2.m1.1.1.2.cmml" xref="S4.T7.20.20.20.2.m1.1.1.2">2</cn><apply id="S4.T7.20.20.20.2.m1.1.1.3.cmml" xref="S4.T7.20.20.20.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T7.20.20.20.2.m1.1.1.3.1.cmml" xref="S4.T7.20.20.20.2.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T7.20.20.20.2.m1.1.1.3.2.cmml" xref="S4.T7.20.20.20.2.m1.1.1.3.2">10</cn><apply id="S4.T7.20.20.20.2.m1.1.1.3.3.cmml" xref="S4.T7.20.20.20.2.m1.1.1.3.3"><minus id="S4.T7.20.20.20.2.m1.1.1.3.3.1.cmml" xref="S4.T7.20.20.20.2.m1.1.1.3.3"></minus><cn type="integer" id="S4.T7.20.20.20.2.m1.1.1.3.3.2.cmml" xref="S4.T7.20.20.20.2.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.20.20.20.2.m1.1c">2\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T7.20.20.20.4" class="ltx_td ltx_align_center ltx_border_bb">yes</td>
<td id="S4.T7.20.20.20.5" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T7.20.20.20.6" class="ltx_td ltx_align_center ltx_border_bb">Adam</td>
<td id="S4.T7.20.20.20.7" class="ltx_td ltx_align_center ltx_border_bb">FP16</td>
<td id="S4.T7.20.20.20.8" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T7.20.20.20.9" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T7.20.20.20.10" class="ltx_td ltx_align_center ltx_border_bb">-</td>
</tr>
</tbody></table>
</span></div>
</figure>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span><span id="S4.SS3.1.1" class="ltx_text ltx_font_italic">Model Training</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.p1.1">이 부분에서는 LLM을 훈련하기 위한 중요한 설정, 기술 또는 트릭을 검토한다.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Optimization Setting</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">LLM의 매개변수 최적화를 위해 배치 학습, 학습률, 최적화기 및 훈련 안정성에 일반적으로 사용되는 설정을 제시한다.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS1.p2.1.1">Batch Training. </span> 언어 모델 사전 훈련의 경우 기존 작업은 일반적으로 일괄 처리 크기를 많은 수(<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p2.1.2">e.g.,</em> 2,048 예제 또는 4M 토큰)로 설정하여 훈련 안정성 및 처리량을 향상시킵니다. GPT-3 및 PaLM과 같은 LLM에 대해, 그들은 훈련 동안 배치 크기를 동적으로 증가시켜 궁극적으로 백만 척도에 도달하는 새로운 전략을 도입했다. 구체적으로 GPT-3의 배치 크기는 32K에서 3.2M 토큰으로 점차 증가하고 있다. 실험 결과는 배치 크기의 동적 스케줄이 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>의 훈련 과정을 효과적으로 안정화시킬 수 있음을 보여주었다.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS1.p3.3"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS1.p3.3.1">Learning Rate. </span> 기존 LLM은 사전 훈련 중 웜업 및 감쇠 전략과 유사한 학습률 일정을 채택한다. 구체적으로, 트레이닝 단계들의 초기 0.1% 내지 0.5%에서, 선형 웜업 스케줄은 대략 <math alttext="5\times 10^{-5}" class="ltx_Math" display="inline" id="S4.SS3.SSS1.p3.1.m1.1"><semantics id="S4.SS3.SSS1.p3.1.m1.1a"><mrow id="S4.SS3.SSS1.p3.1.m1.1.1" xref="S4.SS3.SSS1.p3.1.m1.1.1.cmml"><mn id="S4.SS3.SSS1.p3.1.m1.1.1.2" xref="S4.SS3.SSS1.p3.1.m1.1.1.2.cmml">5</mn><mo id="S4.SS3.SSS1.p3.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.SSS1.p3.1.m1.1.1.1.cmml">×</mo><msup id="S4.SS3.SSS1.p3.1.m1.1.1.3" xref="S4.SS3.SSS1.p3.1.m1.1.1.3.cmml"><mn id="S4.SS3.SSS1.p3.1.m1.1.1.3.2" xref="S4.SS3.SSS1.p3.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.SS3.SSS1.p3.1.m1.1.1.3.3" xref="S4.SS3.SSS1.p3.1.m1.1.1.3.3.cmml"><mo id="S4.SS3.SSS1.p3.1.m1.1.1.3.3a" xref="S4.SS3.SSS1.p3.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.SS3.SSS1.p3.1.m1.1.1.3.3.2" xref="S4.SS3.SSS1.p3.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.1.m1.1b"><apply id="S4.SS3.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS3.SSS1.p3.1.m1.1.1"><times id="S4.SS3.SSS1.p3.1.m1.1.1.1.cmml" xref="S4.SS3.SSS1.p3.1.m1.1.1.1"></times><cn id="S4.SS3.SSS1.p3.1.m1.1.1.2.cmml" type="integer" xref="S4.SS3.SSS1.p3.1.m1.1.1.2">5</cn><apply id="S4.SS3.SSS1.p3.1.m1.1.1.3.cmml" xref="S4.SS3.SSS1.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p3.1.m1.1.1.3.1.cmml" xref="S4.SS3.SSS1.p3.1.m1.1.1.3">superscript</csymbol><cn id="S4.SS3.SSS1.p3.1.m1.1.1.3.2.cmml" type="integer" xref="S4.SS3.SSS1.p3.1.m1.1.1.3.2">10</cn><apply id="S4.SS3.SSS1.p3.1.m1.1.1.3.3.cmml" xref="S4.SS3.SSS1.p3.1.m1.1.1.3.3"><minus id="S4.SS3.SSS1.p3.1.m1.1.1.3.3.1.cmml" xref="S4.SS3.SSS1.p3.1.m1.1.1.3.3"></minus><cn id="S4.SS3.SSS1.p3.1.m1.1.1.3.3.2.cmml" type="integer" xref="S4.SS3.SSS1.p3.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.1.m1.1c">5\times 10^{-5}</annotation></semantics></math> 내지 <math alttext="1\times 10^{-4}" class="ltx_Math" display="inline" id="S4.SS3.SSS1.p3.2.m2.1"><semantics id="S4.SS3.SSS1.p3.2.m2.1a"><mrow id="S4.SS3.SSS1.p3.2.m2.1.1" xref="S4.SS3.SSS1.p3.2.m2.1.1.cmml"><mn id="S4.SS3.SSS1.p3.2.m2.1.1.2" xref="S4.SS3.SSS1.p3.2.m2.1.1.2.cmml">1</mn><mo id="S4.SS3.SSS1.p3.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.SSS1.p3.2.m2.1.1.1.cmml">×</mo><msup id="S4.SS3.SSS1.p3.2.m2.1.1.3" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.cmml"><mn id="S4.SS3.SSS1.p3.2.m2.1.1.3.2" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.2.cmml">10</mn><mrow id="S4.SS3.SSS1.p3.2.m2.1.1.3.3" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.3.cmml"><mo id="S4.SS3.SSS1.p3.2.m2.1.1.3.3a" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.3.cmml">−</mo><mn id="S4.SS3.SSS1.p3.2.m2.1.1.3.3.2" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.2.m2.1b"><apply id="S4.SS3.SSS1.p3.2.m2.1.1.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1"><times id="S4.SS3.SSS1.p3.2.m2.1.1.1.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.1"></times><cn id="S4.SS3.SSS1.p3.2.m2.1.1.2.cmml" type="integer" xref="S4.SS3.SSS1.p3.2.m2.1.1.2">1</cn><apply id="S4.SS3.SSS1.p3.2.m2.1.1.3.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p3.2.m2.1.1.3.1.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.3">superscript</csymbol><cn id="S4.SS3.SSS1.p3.2.m2.1.1.3.2.cmml" type="integer" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.2">10</cn><apply id="S4.SS3.SSS1.p3.2.m2.1.1.3.3.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.3"><minus id="S4.SS3.SSS1.p3.2.m2.1.1.3.3.1.cmml" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.3"></minus><cn id="S4.SS3.SSS1.p3.2.m2.1.1.3.3.2.cmml" type="integer" xref="S4.SS3.SSS1.p3.2.m2.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.2.m2.1c">1\times 10^{-4}</annotation></semantics></math> 범위의 최대값까지 학습 레이트를 점진적으로 증가시키기 위해 채용된다(<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS1.p3.3.2">e.g.,</em> <math alttext="6\times 10^{-5}" class="ltx_Math" display="inline" id="S4.SS3.SSS1.p3.3.m3.1"><semantics id="S4.SS3.SSS1.p3.3.m3.1a"><mrow id="S4.SS3.SSS1.p3.3.m3.1.1" xref="S4.SS3.SSS1.p3.3.m3.1.1.cmml"><mn id="S4.SS3.SSS1.p3.3.m3.1.1.2" xref="S4.SS3.SSS1.p3.3.m3.1.1.2.cmml">6</mn><mo id="S4.SS3.SSS1.p3.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.SSS1.p3.3.m3.1.1.1.cmml">×</mo><msup id="S4.SS3.SSS1.p3.3.m3.1.1.3" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.cmml"><mn id="S4.SS3.SSS1.p3.3.m3.1.1.3.2" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.2.cmml">10</mn><mrow id="S4.SS3.SSS1.p3.3.m3.1.1.3.3" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.3.cmml"><mo id="S4.SS3.SSS1.p3.3.m3.1.1.3.3a" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.3.cmml">−</mo><mn id="S4.SS3.SSS1.p3.3.m3.1.1.3.3.2" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p3.3.m3.1b"><apply id="S4.SS3.SSS1.p3.3.m3.1.1.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1"><times id="S4.SS3.SSS1.p3.3.m3.1.1.1.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.1"></times><cn id="S4.SS3.SSS1.p3.3.m3.1.1.2.cmml" type="integer" xref="S4.SS3.SSS1.p3.3.m3.1.1.2">6</cn><apply id="S4.SS3.SSS1.p3.3.m3.1.1.3.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p3.3.m3.1.1.3.1.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.3">superscript</csymbol><cn id="S4.SS3.SSS1.p3.3.m3.1.1.3.2.cmml" type="integer" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.2">10</cn><apply id="S4.SS3.SSS1.p3.3.m3.1.1.3.3.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.3"><minus id="S4.SS3.SSS1.p3.3.m3.1.1.3.3.1.cmml" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.3"></minus><cn id="S4.SS3.SSS1.p3.3.m3.1.1.3.3.2.cmml" type="integer" xref="S4.SS3.SSS1.p3.3.m3.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p3.3.m3.1c">6\times 10^{-5}</annotation></semantics></math> for GPT-3). 그런 다음, 훈련 손실이 수렴할 때까지 학습률을 최대값의 약 10%로 점진적으로 줄이는 코사인 감쇠 전략을 후속 단계에서 채택한다.</p>
</div>
<div id="S4.SS3.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS3.SSS1.p4.6" class="ltx_p"><span id="S4.SS3.SSS1.p4.6.1" class="ltx_text ltx_font_bold">Optimizer.</span> The Adam optimizer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib328" title="" class="ltx_ref">328</a>]</cite> and AdamW optimizer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib329" title="" class="ltx_ref">329</a>]</cite> are widely utilized for training LLMs (<em id="S4.SS3.SSS1.p4.6.2" class="ltx_emph ltx_font_italic">e.g.,</em> GPT-3), which are based on adaptive estimates of lower-order moments for first-order gradient-based optimization. Commonly, its hyper-parameters are set as follows: <math id="S4.SS3.SSS1.p4.1.m1.1" class="ltx_Math" alttext="\beta_{1}=0.9" display="inline"><semantics id="S4.SS3.SSS1.p4.1.m1.1a"><mrow id="S4.SS3.SSS1.p4.1.m1.1.1" xref="S4.SS3.SSS1.p4.1.m1.1.1.cmml"><msub id="S4.SS3.SSS1.p4.1.m1.1.1.2" xref="S4.SS3.SSS1.p4.1.m1.1.1.2.cmml"><mi id="S4.SS3.SSS1.p4.1.m1.1.1.2.2" xref="S4.SS3.SSS1.p4.1.m1.1.1.2.2.cmml">β</mi><mn id="S4.SS3.SSS1.p4.1.m1.1.1.2.3" xref="S4.SS3.SSS1.p4.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS3.SSS1.p4.1.m1.1.1.1" xref="S4.SS3.SSS1.p4.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS1.p4.1.m1.1.1.3" xref="S4.SS3.SSS1.p4.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p4.1.m1.1b"><apply id="S4.SS3.SSS1.p4.1.m1.1.1.cmml" xref="S4.SS3.SSS1.p4.1.m1.1.1"><eq id="S4.SS3.SSS1.p4.1.m1.1.1.1.cmml" xref="S4.SS3.SSS1.p4.1.m1.1.1.1"></eq><apply id="S4.SS3.SSS1.p4.1.m1.1.1.2.cmml" xref="S4.SS3.SSS1.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p4.1.m1.1.1.2.1.cmml" xref="S4.SS3.SSS1.p4.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS1.p4.1.m1.1.1.2.2.cmml" xref="S4.SS3.SSS1.p4.1.m1.1.1.2.2">𝛽</ci><cn type="integer" id="S4.SS3.SSS1.p4.1.m1.1.1.2.3.cmml" xref="S4.SS3.SSS1.p4.1.m1.1.1.2.3">1</cn></apply><cn type="float" id="S4.SS3.SSS1.p4.1.m1.1.1.3.cmml" xref="S4.SS3.SSS1.p4.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p4.1.m1.1c">\beta_{1}=0.9</annotation></semantics></math>, <math id="S4.SS3.SSS1.p4.2.m2.1" class="ltx_Math" alttext="\beta_{2}=0.95" display="inline"><semantics id="S4.SS3.SSS1.p4.2.m2.1a"><mrow id="S4.SS3.SSS1.p4.2.m2.1.1" xref="S4.SS3.SSS1.p4.2.m2.1.1.cmml"><msub id="S4.SS3.SSS1.p4.2.m2.1.1.2" xref="S4.SS3.SSS1.p4.2.m2.1.1.2.cmml"><mi id="S4.SS3.SSS1.p4.2.m2.1.1.2.2" xref="S4.SS3.SSS1.p4.2.m2.1.1.2.2.cmml">β</mi><mn id="S4.SS3.SSS1.p4.2.m2.1.1.2.3" xref="S4.SS3.SSS1.p4.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="S4.SS3.SSS1.p4.2.m2.1.1.1" xref="S4.SS3.SSS1.p4.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS1.p4.2.m2.1.1.3" xref="S4.SS3.SSS1.p4.2.m2.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p4.2.m2.1b"><apply id="S4.SS3.SSS1.p4.2.m2.1.1.cmml" xref="S4.SS3.SSS1.p4.2.m2.1.1"><eq id="S4.SS3.SSS1.p4.2.m2.1.1.1.cmml" xref="S4.SS3.SSS1.p4.2.m2.1.1.1"></eq><apply id="S4.SS3.SSS1.p4.2.m2.1.1.2.cmml" xref="S4.SS3.SSS1.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p4.2.m2.1.1.2.1.cmml" xref="S4.SS3.SSS1.p4.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS1.p4.2.m2.1.1.2.2.cmml" xref="S4.SS3.SSS1.p4.2.m2.1.1.2.2">𝛽</ci><cn type="integer" id="S4.SS3.SSS1.p4.2.m2.1.1.2.3.cmml" xref="S4.SS3.SSS1.p4.2.m2.1.1.2.3">2</cn></apply><cn type="float" id="S4.SS3.SSS1.p4.2.m2.1.1.3.cmml" xref="S4.SS3.SSS1.p4.2.m2.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p4.2.m2.1c">\beta_{2}=0.95</annotation></semantics></math> and <math id="S4.SS3.SSS1.p4.3.m3.1" class="ltx_Math" alttext="\epsilon=10^{-8}" display="inline"><semantics id="S4.SS3.SSS1.p4.3.m3.1a"><mrow id="S4.SS3.SSS1.p4.3.m3.1.1" xref="S4.SS3.SSS1.p4.3.m3.1.1.cmml"><mi id="S4.SS3.SSS1.p4.3.m3.1.1.2" xref="S4.SS3.SSS1.p4.3.m3.1.1.2.cmml">ϵ</mi><mo id="S4.SS3.SSS1.p4.3.m3.1.1.1" xref="S4.SS3.SSS1.p4.3.m3.1.1.1.cmml">=</mo><msup id="S4.SS3.SSS1.p4.3.m3.1.1.3" xref="S4.SS3.SSS1.p4.3.m3.1.1.3.cmml"><mn id="S4.SS3.SSS1.p4.3.m3.1.1.3.2" xref="S4.SS3.SSS1.p4.3.m3.1.1.3.2.cmml">10</mn><mrow id="S4.SS3.SSS1.p4.3.m3.1.1.3.3" xref="S4.SS3.SSS1.p4.3.m3.1.1.3.3.cmml"><mo id="S4.SS3.SSS1.p4.3.m3.1.1.3.3a" xref="S4.SS3.SSS1.p4.3.m3.1.1.3.3.cmml">−</mo><mn id="S4.SS3.SSS1.p4.3.m3.1.1.3.3.2" xref="S4.SS3.SSS1.p4.3.m3.1.1.3.3.2.cmml">8</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p4.3.m3.1b"><apply id="S4.SS3.SSS1.p4.3.m3.1.1.cmml" xref="S4.SS3.SSS1.p4.3.m3.1.1"><eq id="S4.SS3.SSS1.p4.3.m3.1.1.1.cmml" xref="S4.SS3.SSS1.p4.3.m3.1.1.1"></eq><ci id="S4.SS3.SSS1.p4.3.m3.1.1.2.cmml" xref="S4.SS3.SSS1.p4.3.m3.1.1.2">italic-ϵ</ci><apply id="S4.SS3.SSS1.p4.3.m3.1.1.3.cmml" xref="S4.SS3.SSS1.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p4.3.m3.1.1.3.1.cmml" xref="S4.SS3.SSS1.p4.3.m3.1.1.3">superscript</csymbol><cn type="integer" id="S4.SS3.SSS1.p4.3.m3.1.1.3.2.cmml" xref="S4.SS3.SSS1.p4.3.m3.1.1.3.2">10</cn><apply id="S4.SS3.SSS1.p4.3.m3.1.1.3.3.cmml" xref="S4.SS3.SSS1.p4.3.m3.1.1.3.3"><minus id="S4.SS3.SSS1.p4.3.m3.1.1.3.3.1.cmml" xref="S4.SS3.SSS1.p4.3.m3.1.1.3.3"></minus><cn type="integer" id="S4.SS3.SSS1.p4.3.m3.1.1.3.3.2.cmml" xref="S4.SS3.SSS1.p4.3.m3.1.1.3.3.2">8</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p4.3.m3.1c">\epsilon=10^{-8}</annotation></semantics></math>. Meanwhile, the Adafactor optimizer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib330" title="" class="ltx_ref">330</a>]</cite> has also been utilized in training LLMs (<em id="S4.SS3.SSS1.p4.6.3" class="ltx_emph ltx_font_italic">e.g.,</em> PaLM and T5), which is a variant of the Adam optimizer specially designed for conserving GPU memory during training. The hyper-parameters of the Adafactor optimizer are set as: <math id="S4.SS3.SSS1.p4.4.m4.1" class="ltx_Math" alttext="\beta_{1}=0.9" display="inline"><semantics id="S4.SS3.SSS1.p4.4.m4.1a"><mrow id="S4.SS3.SSS1.p4.4.m4.1.1" xref="S4.SS3.SSS1.p4.4.m4.1.1.cmml"><msub id="S4.SS3.SSS1.p4.4.m4.1.1.2" xref="S4.SS3.SSS1.p4.4.m4.1.1.2.cmml"><mi id="S4.SS3.SSS1.p4.4.m4.1.1.2.2" xref="S4.SS3.SSS1.p4.4.m4.1.1.2.2.cmml">β</mi><mn id="S4.SS3.SSS1.p4.4.m4.1.1.2.3" xref="S4.SS3.SSS1.p4.4.m4.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS3.SSS1.p4.4.m4.1.1.1" xref="S4.SS3.SSS1.p4.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS1.p4.4.m4.1.1.3" xref="S4.SS3.SSS1.p4.4.m4.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p4.4.m4.1b"><apply id="S4.SS3.SSS1.p4.4.m4.1.1.cmml" xref="S4.SS3.SSS1.p4.4.m4.1.1"><eq id="S4.SS3.SSS1.p4.4.m4.1.1.1.cmml" xref="S4.SS3.SSS1.p4.4.m4.1.1.1"></eq><apply id="S4.SS3.SSS1.p4.4.m4.1.1.2.cmml" xref="S4.SS3.SSS1.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p4.4.m4.1.1.2.1.cmml" xref="S4.SS3.SSS1.p4.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS1.p4.4.m4.1.1.2.2.cmml" xref="S4.SS3.SSS1.p4.4.m4.1.1.2.2">𝛽</ci><cn type="integer" id="S4.SS3.SSS1.p4.4.m4.1.1.2.3.cmml" xref="S4.SS3.SSS1.p4.4.m4.1.1.2.3">1</cn></apply><cn type="float" id="S4.SS3.SSS1.p4.4.m4.1.1.3.cmml" xref="S4.SS3.SSS1.p4.4.m4.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p4.4.m4.1c">\beta_{1}=0.9</annotation></semantics></math> and <math id="S4.SS3.SSS1.p4.5.m5.1" class="ltx_Math" alttext="\beta_{2}=1.0-k^{-0.8}" display="inline"><semantics id="S4.SS3.SSS1.p4.5.m5.1a"><mrow id="S4.SS3.SSS1.p4.5.m5.1.1" xref="S4.SS3.SSS1.p4.5.m5.1.1.cmml"><msub id="S4.SS3.SSS1.p4.5.m5.1.1.2" xref="S4.SS3.SSS1.p4.5.m5.1.1.2.cmml"><mi id="S4.SS3.SSS1.p4.5.m5.1.1.2.2" xref="S4.SS3.SSS1.p4.5.m5.1.1.2.2.cmml">β</mi><mn id="S4.SS3.SSS1.p4.5.m5.1.1.2.3" xref="S4.SS3.SSS1.p4.5.m5.1.1.2.3.cmml">2</mn></msub><mo id="S4.SS3.SSS1.p4.5.m5.1.1.1" xref="S4.SS3.SSS1.p4.5.m5.1.1.1.cmml">=</mo><mrow id="S4.SS3.SSS1.p4.5.m5.1.1.3" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.cmml"><mn id="S4.SS3.SSS1.p4.5.m5.1.1.3.2" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.2.cmml">1.0</mn><mo id="S4.SS3.SSS1.p4.5.m5.1.1.3.1" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.1.cmml">−</mo><msup id="S4.SS3.SSS1.p4.5.m5.1.1.3.3" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3.cmml"><mi id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.2" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3.2.cmml">k</mi><mrow id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3.cmml"><mo id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3a" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3.cmml">−</mo><mn id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3.2" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3.2.cmml">0.8</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p4.5.m5.1b"><apply id="S4.SS3.SSS1.p4.5.m5.1.1.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1"><eq id="S4.SS3.SSS1.p4.5.m5.1.1.1.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.1"></eq><apply id="S4.SS3.SSS1.p4.5.m5.1.1.2.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p4.5.m5.1.1.2.1.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS1.p4.5.m5.1.1.2.2.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.2.2">𝛽</ci><cn type="integer" id="S4.SS3.SSS1.p4.5.m5.1.1.2.3.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.2.3">2</cn></apply><apply id="S4.SS3.SSS1.p4.5.m5.1.1.3.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.3"><minus id="S4.SS3.SSS1.p4.5.m5.1.1.3.1.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.1"></minus><cn type="float" id="S4.SS3.SSS1.p4.5.m5.1.1.3.2.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.2">1.0</cn><apply id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.1.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3">superscript</csymbol><ci id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.2.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3.2">𝑘</ci><apply id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3"><minus id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3.1.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3"></minus><cn type="float" id="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3.2.cmml" xref="S4.SS3.SSS1.p4.5.m5.1.1.3.3.3.2">0.8</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p4.5.m5.1c">\beta_{2}=1.0-k^{-0.8}</annotation></semantics></math>, where <math id="S4.SS3.SSS1.p4.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.SSS1.p4.6.m6.1a"><mi id="S4.SS3.SSS1.p4.6.m6.1.1" xref="S4.SS3.SSS1.p4.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p4.6.m6.1b"><ci id="S4.SS3.SSS1.p4.6.m6.1.1.cmml" xref="S4.SS3.SSS1.p4.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p4.6.m6.1c">k</annotation></semantics></math> denotes the number of training steps.</p>
</div>
<div id="S4.SS3.SSS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS1.p5.1.1">Stabilizing the Training. </span> LLM을 사전 훈련하는 동안 종종 훈련 불안정성 문제를 겪으며, 이는 모델 붕괴를 유발할 수 있다. 이 문제를 해결하기 위해 가중치 감소 및 기울기 클리핑이 널리 활용되었으며, 기존 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib90" title="">90</a>, <a class="ltx_ref" href="#bib.bib78" title="">78</a>, <a class="ltx_ref" href="#bib.bib113" title="">113</a>, <a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>는 일반적으로 기울기 클리핑의 임계값을 1.0으로, 가중치 감소율을 0.1로 설정했다. 그러나 LLM의 스케일링으로 인해 훈련 손실 스파이크도 발생할 가능성이 높아 불안정한 훈련으로 이어진다. 이 문제를 완화하기 위해 PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite> 및 OPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite>는 스파이크가 발생하기 전에 이전 체크포인트에서 훈련 프로세스를 다시 시작하고 문제를 일으켰을 수 있는 데이터를 건너뛰는 간단한 전략을 사용합니다. 또한, GLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>는 임베딩 레이어의 비정상적인 기울기가 보통 스파이크로 이어진다는 것을 발견하고, 이를 완화하기 위해 임베딩 레이어 기울기를 축소할 것을 제안한다.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Scalable Training Techniques</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">모델 및 데이터 크기가 증가함에 따라 제한된 계산 자원 하에서 LLM을 효율적으로 훈련시키는 것이 어려워졌다. 특히, <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p1.1.1">i.e.,</em> 훈련 처리량을 증가시키고 GPU 메모리에 더 큰 모델을 로드하는 두 가지 주요 기술적 문제가 해결되어야 한다. 이 부분에서 우리는 위의 두 가지 과제, 즉 3D 병렬성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib331" title="">331</a>, <a class="ltx_ref" href="#bib.bib332" title="">332</a>, <a class="ltx_ref" href="#bib.bib75" title="">75</a>]</cite>, ZeRO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib333" title="">333</a>]</cite>, 혼합 정밀 훈련 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib334" title="">334</a>]</cite>를 해결하기 위해 기존 연구에서 널리 사용되는 몇 가지 접근법을 검토하고 이를 훈련에 활용하는 방법에 대한 일반적인 제안을 한다.</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS2.p2.1.1">3D Parallelism. </span>3D 병렬성은 실제로 일반적으로 사용되는 세 가지 병렬 훈련 기술, 즉 데이터 병렬성, 파이프라인 병렬성<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib331" title="">331</a>, <a class="ltx_ref" href="#bib.bib332" title="">332</a>]</cite> 및 텐서 병렬성<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>]</cite><span class="ltx_note ltx_role_footnote" id="footnote26"><sup class="ltx_note_mark">26</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">26</sup><span class="ltx_tag ltx_tag_note">26</span>Model parallelism is a more broader term that includes tensor parallelism and pipeline parallelism in some work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>]</cite>.</span></span></span>의 조합이다. 다음으로 세 가지 병렬 훈련 기법을 소개한다.</p>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p3.1.m1.1"><semantics id="S4.SS3.SSS2.p3.1.m1.1a"><mo id="S4.SS3.SSS2.p3.1.m1.1.1" xref="S4.SS3.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p3.1.m1.1b"><ci id="S4.SS3.SSS2.p3.1.m1.1.1.cmml" xref="S4.SS3.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p3.1.1">Data parallelism. </em> 데이터 병렬성은 훈련 처리량을 향상시키기 위한 가장 근본적인 접근법 중 하나이다. 여러 GPU에 걸쳐 모델 매개 변수 및 최적화 상태를 복제한 다음 전체 훈련 코퍼스를 이러한 GPU에 분산합니다. 이러한 방식으로, 각각의 GPU는 그것에 대해 할당된 데이터를 프로세싱하기만 하면 되고, 그래디언트들을 획득하기 위해 순방향 및 역방향 전파를 수행한다. 다른 GPU에서 계산된 기울기는 모든 GPU에서 모델을 업데이트하기 위한 전체 배치의 기울기를 얻기 위해 추가로 집계됩니다. 이러한 방식으로, 기울기들의 계산들이 상이한 GPU들에 대해 독립적으로 수행됨에 따라, 데이터 병렬화 메커니즘은 고도로 확장가능하여, 트레이닝 처리량을 개선하기 위해 GPU들의 수를 증가시키는 방법을 가능하게 한다. 또한, 이 기법은 구현이 간단하며, 기존의 대부분의 인기 있는 딥러닝 라이브러리들은 이미 TensorFlow 및 PyTorch와 같은 데이터 병렬성을 구현했다.</p>
</div>
<div id="S4.SS3.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p4.1.m1.1"><semantics id="S4.SS3.SSS2.p4.1.m1.1a"><mo id="S4.SS3.SSS2.p4.1.m1.1.1" xref="S4.SS3.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p4.1.m1.1b"><ci id="S4.SS3.SSS2.p4.1.m1.1.1.cmml" xref="S4.SS3.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p4.1.1">Pipeline parallelism. </em> Pipeline parallelism aims to distribute the different layers of a LLM to multiple GPU. 특히 Transformer 모델의 경우 파이프라인 병렬화는 GPU 간의 연산된 은닉 상태나 그라디언트 전송 비용을 줄이기 위해 동일한 GPU에 연속적인 레이어를 로딩한다. 그러나 파이프라인 병렬성의 순진한 구현은 각 GPU가 계산을 완료하기 위해 이전 GPU를 기다려야 하기 때문에 GPU 사용률이 낮아질 수 있으며, 이로 인해 <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p4.1.2">bubbles overhead</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib331" title="">331</a>]</cite>의 불필요한 비용이 발생할 수 있다. 파이프라인 병렬처리에서 이러한 버블을 줄이기 위해 GPipe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib331" title="">331</a>]</cite>와 PipeDream <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib332" title="">332</a>]</cite>는 파이프라인 효율을 향상시키기 위해 데이터의 여러 배치를 패딩하는 기법과 비동기식 기울기 갱신을 제안한다.</p>
</div>
<div id="S4.SS3.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS2.p5.8"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p5.1.m1.1"><semantics id="S4.SS3.SSS2.p5.1.m1.1a"><mo id="S4.SS3.SSS2.p5.1.m1.1.1" xref="S4.SS3.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p5.1.m1.1b"><ci id="S4.SS3.SSS2.p5.1.m1.1.1.cmml" xref="S4.SS3.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p5.8.1">Tensor parallelism. </em> 텐서 병렬성은 다중 GPU 로딩을 위해 LLM을 분해하는 것을 목표로 하는 일반적으로 사용되는 기술이기도 하다. 파이프라인 병렬성과 달리 텐서 병렬성은 LLM의 텐서(매개변수 행렬)를 분해하는 데 중점을 둔다. LLM에서 행렬 곱셈 연산 <math alttext="Y=XA" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p5.2.m2.1"><semantics id="S4.SS3.SSS2.p5.2.m2.1a"><mrow id="S4.SS3.SSS2.p5.2.m2.1.1" xref="S4.SS3.SSS2.p5.2.m2.1.1.cmml"><mi id="S4.SS3.SSS2.p5.2.m2.1.1.2" xref="S4.SS3.SSS2.p5.2.m2.1.1.2.cmml">Y</mi><mo id="S4.SS3.SSS2.p5.2.m2.1.1.1" xref="S4.SS3.SSS2.p5.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS3.SSS2.p5.2.m2.1.1.3" xref="S4.SS3.SSS2.p5.2.m2.1.1.3.cmml"><mi id="S4.SS3.SSS2.p5.2.m2.1.1.3.2" xref="S4.SS3.SSS2.p5.2.m2.1.1.3.2.cmml">X</mi><mo id="S4.SS3.SSS2.p5.2.m2.1.1.3.1" lspace="0em" rspace="0em" xref="S4.SS3.SSS2.p5.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS3.SSS2.p5.2.m2.1.1.3.3" xref="S4.SS3.SSS2.p5.2.m2.1.1.3.3.cmml">A</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p5.2.m2.1b"><apply id="S4.SS3.SSS2.p5.2.m2.1.1.cmml" xref="S4.SS3.SSS2.p5.2.m2.1.1"><eq id="S4.SS3.SSS2.p5.2.m2.1.1.1.cmml" xref="S4.SS3.SSS2.p5.2.m2.1.1.1"></eq><ci id="S4.SS3.SSS2.p5.2.m2.1.1.2.cmml" xref="S4.SS3.SSS2.p5.2.m2.1.1.2">𝑌</ci><apply id="S4.SS3.SSS2.p5.2.m2.1.1.3.cmml" xref="S4.SS3.SSS2.p5.2.m2.1.1.3"><times id="S4.SS3.SSS2.p5.2.m2.1.1.3.1.cmml" xref="S4.SS3.SSS2.p5.2.m2.1.1.3.1"></times><ci id="S4.SS3.SSS2.p5.2.m2.1.1.3.2.cmml" xref="S4.SS3.SSS2.p5.2.m2.1.1.3.2">𝑋</ci><ci id="S4.SS3.SSS2.p5.2.m2.1.1.3.3.cmml" xref="S4.SS3.SSS2.p5.2.m2.1.1.3.3">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p5.2.m2.1c">Y=XA</annotation></semantics></math>에 대해, 파라미터 행렬 <math alttext="A" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p5.3.m3.1"><semantics id="S4.SS3.SSS2.p5.3.m3.1a"><mi id="S4.SS3.SSS2.p5.3.m3.1.1" xref="S4.SS3.SSS2.p5.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p5.3.m3.1b"><ci id="S4.SS3.SSS2.p5.3.m3.1.1.cmml" xref="S4.SS3.SSS2.p5.3.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p5.3.m3.1c">A</annotation></semantics></math>는 열별로 두 개의 하위 행렬, <math alttext="A_{1}" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p5.4.m4.1"><semantics id="S4.SS3.SSS2.p5.4.m4.1a"><msub id="S4.SS3.SSS2.p5.4.m4.1.1" xref="S4.SS3.SSS2.p5.4.m4.1.1.cmml"><mi id="S4.SS3.SSS2.p5.4.m4.1.1.2" xref="S4.SS3.SSS2.p5.4.m4.1.1.2.cmml">A</mi><mn id="S4.SS3.SSS2.p5.4.m4.1.1.3" xref="S4.SS3.SSS2.p5.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p5.4.m4.1b"><apply id="S4.SS3.SSS2.p5.4.m4.1.1.cmml" xref="S4.SS3.SSS2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS2.p5.4.m4.1.1.1.cmml" xref="S4.SS3.SSS2.p5.4.m4.1.1">subscript</csymbol><ci id="S4.SS3.SSS2.p5.4.m4.1.1.2.cmml" xref="S4.SS3.SSS2.p5.4.m4.1.1.2">𝐴</ci><cn id="S4.SS3.SSS2.p5.4.m4.1.1.3.cmml" type="integer" xref="S4.SS3.SSS2.p5.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p5.4.m4.1c">A_{1}</annotation></semantics></math>와 <math alttext="A_{2}" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p5.5.m5.1"><semantics id="S4.SS3.SSS2.p5.5.m5.1a"><msub id="S4.SS3.SSS2.p5.5.m5.1.1" xref="S4.SS3.SSS2.p5.5.m5.1.1.cmml"><mi id="S4.SS3.SSS2.p5.5.m5.1.1.2" xref="S4.SS3.SSS2.p5.5.m5.1.1.2.cmml">A</mi><mn id="S4.SS3.SSS2.p5.5.m5.1.1.3" xref="S4.SS3.SSS2.p5.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p5.5.m5.1b"><apply id="S4.SS3.SSS2.p5.5.m5.1.1.cmml" xref="S4.SS3.SSS2.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS2.p5.5.m5.1.1.1.cmml" xref="S4.SS3.SSS2.p5.5.m5.1.1">subscript</csymbol><ci id="S4.SS3.SSS2.p5.5.m5.1.1.2.cmml" xref="S4.SS3.SSS2.p5.5.m5.1.1.2">𝐴</ci><cn id="S4.SS3.SSS2.p5.5.m5.1.1.3.cmml" type="integer" xref="S4.SS3.SSS2.p5.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p5.5.m5.1c">A_{2}</annotation></semantics></math>로 분할될 수 있으며, 이는 <math alttext="Y=[XA_{1},XA_{2}]" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p5.6.m6.2"><semantics id="S4.SS3.SSS2.p5.6.m6.2a"><mrow id="S4.SS3.SSS2.p5.6.m6.2.2" xref="S4.SS3.SSS2.p5.6.m6.2.2.cmml"><mi id="S4.SS3.SSS2.p5.6.m6.2.2.4" xref="S4.SS3.SSS2.p5.6.m6.2.2.4.cmml">Y</mi><mo id="S4.SS3.SSS2.p5.6.m6.2.2.3" xref="S4.SS3.SSS2.p5.6.m6.2.2.3.cmml">=</mo><mrow id="S4.SS3.SSS2.p5.6.m6.2.2.2.2" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.3.cmml"><mo id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.3" stretchy="false" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.3.cmml">[</mo><mrow id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.cmml"><mi id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.2" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.2.cmml">X</mi><mo id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.1.cmml">​</mo><msub id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.cmml"><mi id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.2" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.2.cmml">A</mi><mn id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.3" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.4" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.3.cmml">,</mo><mrow id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.cmml"><mi id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.2" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.2.cmml">X</mi><mo id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.1" lspace="0em" rspace="0em" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.1.cmml">​</mo><msub id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.cmml"><mi id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.2" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.2.cmml">A</mi><mn id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.3" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.3.cmml">2</mn></msub></mrow><mo id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.5" stretchy="false" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p5.6.m6.2b"><apply id="S4.SS3.SSS2.p5.6.m6.2.2.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2"><eq id="S4.SS3.SSS2.p5.6.m6.2.2.3.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2.3"></eq><ci id="S4.SS3.SSS2.p5.6.m6.2.2.4.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2.4">𝑌</ci><interval closure="closed" id="S4.SS3.SSS2.p5.6.m6.2.2.2.3.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2"><apply id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.cmml" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1"><times id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.1"></times><ci id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.2">𝑋</ci><apply id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.1.cmml" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.2.cmml" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.2">𝐴</ci><cn id="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.3.cmml" type="integer" xref="S4.SS3.SSS2.p5.6.m6.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2"><times id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.1.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.1"></times><ci id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.2.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.2">𝑋</ci><apply id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.1.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3">subscript</csymbol><ci id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.2.cmml" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.2">𝐴</ci><cn id="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.3.cmml" type="integer" xref="S4.SS3.SSS2.p5.6.m6.2.2.2.2.2.3.3">2</cn></apply></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p5.6.m6.2c">Y=[XA_{1},XA_{2}]</annotation></semantics></math>로 표현될 수 있다. 매트릭스 <math alttext="A_{1}" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p5.7.m7.1"><semantics id="S4.SS3.SSS2.p5.7.m7.1a"><msub id="S4.SS3.SSS2.p5.7.m7.1.1" xref="S4.SS3.SSS2.p5.7.m7.1.1.cmml"><mi id="S4.SS3.SSS2.p5.7.m7.1.1.2" xref="S4.SS3.SSS2.p5.7.m7.1.1.2.cmml">A</mi><mn id="S4.SS3.SSS2.p5.7.m7.1.1.3" xref="S4.SS3.SSS2.p5.7.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p5.7.m7.1b"><apply id="S4.SS3.SSS2.p5.7.m7.1.1.cmml" xref="S4.SS3.SSS2.p5.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS2.p5.7.m7.1.1.1.cmml" xref="S4.SS3.SSS2.p5.7.m7.1.1">subscript</csymbol><ci id="S4.SS3.SSS2.p5.7.m7.1.1.2.cmml" xref="S4.SS3.SSS2.p5.7.m7.1.1.2">𝐴</ci><cn id="S4.SS3.SSS2.p5.7.m7.1.1.3.cmml" type="integer" xref="S4.SS3.SSS2.p5.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p5.7.m7.1c">A_{1}</annotation></semantics></math> 및 <math alttext="A_{2}" class="ltx_Math" display="inline" id="S4.SS3.SSS2.p5.8.m8.1"><semantics id="S4.SS3.SSS2.p5.8.m8.1a"><msub id="S4.SS3.SSS2.p5.8.m8.1.1" xref="S4.SS3.SSS2.p5.8.m8.1.1.cmml"><mi id="S4.SS3.SSS2.p5.8.m8.1.1.2" xref="S4.SS3.SSS2.p5.8.m8.1.1.2.cmml">A</mi><mn id="S4.SS3.SSS2.p5.8.m8.1.1.3" xref="S4.SS3.SSS2.p5.8.m8.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p5.8.m8.1b"><apply id="S4.SS3.SSS2.p5.8.m8.1.1.cmml" xref="S4.SS3.SSS2.p5.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS2.p5.8.m8.1.1.1.cmml" xref="S4.SS3.SSS2.p5.8.m8.1.1">subscript</csymbol><ci id="S4.SS3.SSS2.p5.8.m8.1.1.2.cmml" xref="S4.SS3.SSS2.p5.8.m8.1.1.2">𝐴</ci><cn id="S4.SS3.SSS2.p5.8.m8.1.1.3.cmml" type="integer" xref="S4.SS3.SSS2.p5.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p5.8.m8.1c">A_{2}</annotation></semantics></math>를 서로 다른 GPU에 배치함으로써, 매트릭스 곱셈 연산은 두 GPU에서 병렬로 호출될 것이고, 최종 결과는 두 GPU로부터의 출력들을 across-GPU 통신을 통해 조합함으로써 얻어질 수 있다. 현재 텐서 병렬성은 여러 오픈 소스 라이브러리인 <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p5.8.2">e.g.,</em> Megatron-LM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>]</cite>에서 지원되었으며 더 높은 차원의 텐서로 확장될 수 있다. 또한 Colossal-AI는 고차원 텐서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib335" title="">335</a>, <a class="ltx_ref" href="#bib.bib336" title="">336</a>, <a class="ltx_ref" href="#bib.bib337" title="">337</a>]</cite>에 대해 텐서 병렬성을 구현하였으며, 특히 시퀀스 데이터에 대해 제안된 시퀀스 병렬성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib338" title="">338</a>]</cite>를 구현하여 Transformer 모델의 어텐션 연산을 더욱 분해할 수 있다.</p>
</div>
<div id="S4.SS3.SSS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS2.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS2.p6.1.1">ZeRO. DeepSpeed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite> 라이브러리에 의해 제안된</span> ZeRO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib333" title="">333</a>]</cite> 기법은 데이터 병렬성에서의 메모리 중복성 문제에 초점을 맞춘다. 앞서 언급한 바와 같이, 데이터 병렬성은 각 GPU가 모델 파라미터, 모델 구배 및 최적화기 파라미터를 포함하여 LL의 동일한 사본을 저장해야 한다. 반면, 위의 모든 데이터가 각각의 GPU에 보유될 필요는 없으며, 이는 메모리 중복 문제를 야기할 것이다. 이를 해결하기 위해 ZeRO 기법은 각 GPU에 일부 데이터만 유지하는 것을 목표로 하며, 나머지 데이터는 필요할 때 다른 GPU에서 검색할 수 있다. 구체적으로 ZeRO는 데이터의 세 부분을 어떻게 저장하느냐에 따라 최적화 상태 분할, 그래디언트 분할, 파라미터 분할 등 세 가지 솔루션을 제공한다. 실험 결과는 처음 두 해는 통신 오버헤드를 증가시키지 않으며, 세 번째 해는 약 50%의 통신 오버헤드를 증가시키지만 GPU의 수에 비례하는 메모리를 절약함을 보여준다. PyTorch는 FSDP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib339" title="">339</a>]</cite>라고 불리는 ZeRO와 유사한 기술을 구현했다.</p>
</div>
<div id="S4.SS3.SSS2.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS2.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS2.p7.1.1">Mixed Precision Training. </span> 이전 PLMs (<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p7.1.2">e.g.,</em>BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite>), FP32로도 알려진 32비트 부동 소수점 숫자는 주로 사전 훈련에 사용되었다. 최근 들어, 매우 큰 언어 모델들을 사전 트레이닝하기 위해, 메모리 사용량 및 통신 오버헤드를 감소시키는 16-비트 부동 소수점 수들(FP16)을 활용하기 위한 몇몇 연구들<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib334" title="">334</a>]</cite>가 시작되었다. 추가적으로, 인기 있는 NVIDIA GPU들(<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p7.1.3">e.g.,</em> A100)이 FP32보다 두 배 많은 FP16 연산 유닛들을 가짐으로써, FP16의 연산 효율이 더욱 향상될 수 있다. 그러나 기존 연구에서는 FP16이 최종 모델 성능에 영향을 미치는 계산 정확도 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>, <a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>의 손실을 초래할 수 있음을 발견했다. 이를 완화하기 위해 <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p7.1.4">Brain Floating Point (BF16)</em>이 학습에 사용되었으며, 이는 FP16보다 더 많은 지수 비트와 더 적은 유의 비트를 할당한다. 사전 학습의 경우, BF16은 일반적으로 표현 정확도 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>에서 FP16보다 더 나은 성능을 수행한다.</p>
</div>
<div id="S4.SS3.SSS2.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS2.p8.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.SSS2.p8.1.1">Overall Training Suggestion. </span> 실제로, 위의 트레이닝 기술들, 특히 3D 병렬성은 종종 트레이닝 처리량 및 큰 모델 로딩을 개선하기 위해 공동으로 사용된다. 예를 들어, 연구자들은 8-웨이 데이터 병렬성, 4-웨이 텐서 병렬성 및 12-웨이 파이프라인 병렬성을 통합하여 384개의 A100 GPU에서 BLOOM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>의 훈련을 가능하게 했다. 현재 DeepSpeed<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite>, Colossal-AI<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib189" title="">189</a>]</cite>, Alpa<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib340" title="">340</a>]</cite>와 같은 오픈 소스 라이브러리는 세 가지 병렬 훈련 방법을 잘 지원할 수 있다. 메모리 중복성을 줄이기 위해 ZeRO, FSDP 및 활성화 재계산 기술 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib341" title="">341</a>, <a class="ltx_ref" href="#bib.bib77" title="">77</a>]</cite>는 이미 DeepSpeed, PyTorch 및 Megatron-LM에 통합된 LLM 훈련에도 사용할 수 있다. 또한, BF16과 같은 혼합 정밀도 훈련 기법은 훈련 효율을 향상시키고 GPU 메모리 사용량을 감소시키기 위해 레버리지될 수 있는 반면, 하드웨어에 대한 필요한 지원이 필요하다(<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p8.1.2">e.g.,</em> A100 GPU). 대규모 모델을 훈련하는 것은 시간 집약적인 과정이기 때문에 모델 성능을 예측하고 초기 단계에서 비정상적인 문제를 감지하는 것이 유용할 것이다. 이를 위해 GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>는 최근 딥러닝 스택에 구축된 <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p8.1.3">predictable scaling</em>이라는 새로운 메커니즘을 도입하여 훨씬 작은 모델로 큰 모델의 성능 예측을 가능하게 하며, 이는 LLMs 개발에 상당히 유용할 수 있다. 실제로, 주류 딥 러닝 프레임워크의 지원 훈련 기술을 더 활용할 수 있다. 예를 들어, PyTorch는 데이터 병렬 훈련 알고리즘 FSDP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib339" title="">339</a>]</cite> (<em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p8.1.4">i.e.,</em> fully sharded data parallel)을 지원하며, 이는 원하는 경우 CPU에 대한 훈련 계산의 부분적인 오프로딩을 허용한다.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Adaptation of LLMs</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p" id="S5.p1.1">사전 훈련 후 LLM은 다양한 과제 해결을 위한 일반적인 능력을 습득할 수 있다. 그러나, 점점 더 많은 연구가 LLM의 능력이 특정 목표에 따라 더 적응될 수 있다는 것을 보여주었다. 이 절에서는 사전 훈련된 LLM을 적응시키기 위한 두 가지 주요 접근법, 즉 명령어 튜닝과 정렬 튜닝을 소개한다. 전자의 접근법은 주로 LLM의 능력을 향상(또는 해제)하는 것을 목표로 하는 반면, 후자의 접근법은 LLM의 행동을 인간의 가치 또는 선호도와 정렬하는 것을 목표로 한다. 또한, 자원 제한 설정에서 모델 적응을 위한 효율적인 튜닝 및 양자화에 대해서도 논의할 것이다. 이하에서는 네 가지 부분에 대해 구체적으로 소개하고자 한다.</p>
</div>
<figure id="S5.F11" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x11.png" id="S5.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 11:</span>Instance formatting and three different methods for constructing the instruction-formatted instances.</figcaption>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span><span id="S5.SS1.1.1" class="ltx_text ltx_font_italic">Instruction Tuning</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.p1.1">본질적으로, 명령어 튜닝은 자연 언어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite> 형태의 포맷된 인스턴스 모음에서 미리 훈련된 LLMs를 미세 조정하는 접근법이며, 이는 감독된 미세 조정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite> 및 다중 태스크 프롬프트 훈련 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>와 관련이 높다. 명령어 튜닝을 수행하기 위해서는 먼저 명령어 형식의 인스턴스를 수집하거나 구성해야 한다. 그런 다음, 이러한 포맷된 인스턴스를 사용하여 지도 학습 방식으로 LLM을 미세 조정한다(<em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.1">e.g.,</em> training with the sequence-to-sequence loss). 명령어 튜닝 후 LLMs은 다국어 설정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib94" title="">94</a>]</cite>에서도 보이지 않는 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>로 일반화하는 우수한 능력을 발휘할 수 있다.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS1.p2.1">최근 설문 조사 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib342" title="">342</a>]</cite>는 명령어 튜닝에 대한 연구의 체계적인 개요를 제시한다. 이에 비해 주로 수업 튜닝이 LLMs에 미치는 영향에 초점을 맞추고 사례 수집 및 튜닝을 위한 세부 지침이나 전략을 제공한다. 또한, 기존의 LLMs, <em class="ltx_emph ltx_font_italic" id="S5.SS1.p2.1.1">e.g.,</em> InstructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite> 및 GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>에서 널리 적용되고 있는 사용자의 실제 요구를 만족시키기 위한 명령어 튜닝의 사용에 대해서도 논의한다.</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Formatted Instance Construction</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1">일반적으로 명령 형식 인스턴스는 작업 설명(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p1.1.1">instruction</em>이라고 함), 선택적 입력, 해당 출력 및 적은 수의 시연(선택 사항)으로 구성됩니다. 중요한 공개 자원으로서, 기존 연구들은 자연어로 포맷된 많은 수의 라벨링된 데이터(표<a class="ltx_ref" href="#S3.T3" title="TABLE III ‣ 3.2 Commonly Used Corpora for Pre-training ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">III</span></a>의 가용 자원 목록을 참조)를 섹션<a class="ltx_ref" href="#S3.SS3.SSS1" title="3.3.1 Instruction Tuning Datasets ‣ 3.3 Commonly Used Datasets for Fine-tuning ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>에서 소개한 바와 같이 공개했다. 다음으로 형식화된 인스턴스를 구성하기 위한 세 가지 주요 방법(<a class="ltx_ref" href="#S5.F11" title="Figure 11 ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">11</span></a>의 그림 참조)을 소개하고 인스턴스 구성을 위한 몇 가지 주요 요인에 대해 논의한다.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p2.1.1">Formatting NLP Task Datasets. </span> 명령어 튜닝이 제안되기 전에 여러 초기 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib343" title="">343</a>, <a class="ltx_ref" href="#bib.bib344" title="">344</a>, <a class="ltx_ref" href="#bib.bib168" title="">168</a>]</cite>는 다양한 범위의 전통적인 NLP 작업(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.2">e.g.,</em> 텍스트 요약, 텍스트 분류 및 번역)에서 인스턴스를 수집하여 감독된 다중 작업 훈련 데이터 세트를 생성했다. 명령어 튜닝 인스턴스의 주요 소스로서, 이러한 다중 태스크 트레이닝 데이터 세트를 자연어 태스크 설명으로 포맷하는 것이 편리하다. 구체적으로, 최근 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>, <a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib88" title="">88</a>]</cite>는 사람이 작성한 작업 설명으로 라벨링된 데이터 세트를 증강시키며, 이는 LLMs에게 작업 목표를 설명함으로써 작업을 이해하도록 지시한다. 예를 들어, Figure <a class="ltx_ref" href="#S5.F11" title="Figure 11 ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">11</span></a>(a)에서는 질문-답변 태스크에서 각 예제에 대해 “<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.3">Please answer this question</em>”이 추가된다. 명령어 튜닝 후 LLMs는 태스크 설명 [cite idx=2></cite>]을 따름으로써 보이지 않는 다른 태스크에 잘 일반화할 수 있다. 특히, 명령어들이 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>에 대한 태스크 일반화 능력에 중요한 요소임을 알 수 있었다. 명령어 튜닝을 위한 레이블된 인스턴스를 더 잘 생성하기 위해, 크라우드 소싱 플랫폼인 PromptSource<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib167" title="">167</a>]</cite>가 서로 다른 데이터 세트에 대한 작업 설명을 효과적으로 생성, 공유 및 검증하기 위해 제안되었다. 훈련 인스턴스를 강화하기 위해 여러 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>, <a class="ltx_ref" href="#bib.bib168" title="">168</a>, <a class="ltx_ref" href="#bib.bib345" title="">345</a>]</cite>도 명령어 튜닝을 위해 특별히 설계된 작업 설명으로 기존 인스턴스의 입력-출력 쌍을 반전시키려고 한다. 예를 들어 질문-응답자 쌍이 주어지면 답변 조건 질문을 예측하여 새 인스턴스를 만들 수 있습니다 (<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.4">e.g.,</em> <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p2.1.5">“Please generate a question based on the answer:”</em>).</p>
</div>
<div id="S5.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p3.1.1">Formatting Daily Chat Data. </span> 많은 수의 훈련 인스턴스가 명령어로 포맷되었지만 주로 명령어의 다양성이 부족하거나 실제 인간의 요구와 일치하지 않는 공개 NLP 데이터 세트에서 나온다. 이를 극복하기 위해 InstructGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>는 실제 사용자가 OpenAI API에 제출한 쿼리를 태스크 설명으로 취하는 것을 제안한다. 또한 작업 다양성을 풍부하게 하기 위해 인간 라벨러도 개방형 생성, 개방형 질문 응답, 브레인스토밍 및 채팅을 포함한 실제 작업에 대한 지침을 작성하도록 요청받는다. 그런 다음 다른 레이블러 그룹이 이러한 지침에 직접 응답하도록 출력으로 허용합니다. 마지막으로, 훈련 인스턴스로서 하나의 명령어(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.2">i.e.,</em> the collected user query)와 예상 출력(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p3.1.3">i.e.,</em> the human-written answer)을 페어링한다. InstructGPT는 또한 정렬 튜닝(섹션<a class="ltx_ref" href="#S5.SS2" title="5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.2</span></a>에서 논의됨)을 위해 자연 언어로 포맷된 이들 실세계 태스크들을 채용한다는 것에 유의한다. 또한 GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>는 잠재적으로 고위험 지침을 설계하고 안전 문제에 대한 감독 미세 조정을 통해 이러한 지침을 거부하도록 모델을 안내했다. 고품질 공개 채팅 데이터의 부재를 고려하여 여러 연구에서도 사용자의 채팅 요청을 입력 데이터로 수집한 후 ChatGPT 또는 GPT-4를 활용하여 응답을 출력 데이터로 생성하였다. 이러한 데이터 세트의 주목할만한 예는 ShareGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>의 대화 데이터이다. 또한, Dolly<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib172" title="">172</a>]</cite>와 OpenAssistant<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib173" title="">173</a>]</cite>는 높은 수준의 품질을 얻기 위해 인간 주석자에 의해 신중하게 라벨링된 대화 데이터를 추가로 공개했다.</p>
</div>
<div id="S5.SS1.SSS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p4.1.1">Formatting Synthetic Data. </span> 인간 주석 또는 수동 수집의 부담을 줄이기 위해 기존 인스턴스를 LLMs에 공급하여 다양한 작업 설명 및 인스턴스를 합성함으로써 인스턴스를 구성하기 위한 몇 가지 반자동 접근법 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>가 제안되었다. <a class="ltx_ref" href="#S5.F11" title="Figure 11 ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">11</span></a>(c)에 예시된 바와 같이, Self-Instruct 방법은 초기 태스크 풀로서 175개의 인스턴스들만을 필요로 한다. 그런 다음 풀에서 몇 개의 인스턴스를 시범으로 무작위로 선택하고 LLM을 프롬프트하여 새 명령어와 해당 입력 출력 쌍을 생성합니다. 품질 및 다양성 필터링 후 새로 생성된 인스턴스가 작업 풀에 추가됩니다. 따라서, 합성 방법은 LLMs에 대한 대규모 명령어 데이터를 생성하는데 효과적이고 경제적인 방법이다. 그러나 Self-Instruct 방법에 의해 생성된 인스턴스는 단순하거나 다양성이 부족할 수 있다. 합성 인트의 품질을 향상시키기 위해 WizardLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib346" title="">346</a>]</cite>는 인스턴스의 복잡성과 다양성을 풍부하게 하기 위해 진화하는 깊고 광범위한 것을 제안하여 Evol-Instruct를 도입한다. 또한 Self-Align<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib347" title="">347</a>]</cite>는 합성된 인스턴스를 필터링하기 위해 여러 인간 정렬 원칙을 수립한다. 그런 다음 이러한 인스턴스를 사용하여 LLM을 훈련하여 더 정렬된 인스턴스를 생성합니다. 인스턴스 출력의 품질을 높이기 위해 연구자들은 직접 인간이 쓴 텍스트를 출력으로 채택하고 ICL 예제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib348" title="">348</a>]</cite>를 사용하여 해당 명령어를 합성한다.</p>
</div>
<div id="S5.SS1.SSS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p5.1.1">Key Factors for Instance Construction. </span> 명령어 인스턴스의 품질은 모델의 성능에 중요한 영향을 미칩니다. 여기서는 건설과 같은 몇 가지 필수 요소에 대해 논의합니다.</p>
</div>
<div id="S5.SS1.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS1.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p6.1.m1.1"><semantics id="S5.SS1.SSS1.p6.1.m1.1a"><mo id="S5.SS1.SSS1.p6.1.m1.1.1" xref="S5.SS1.SSS1.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p6.1.m1.1b"><ci id="S5.SS1.SSS1.p6.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p6.1.1">Scaling the instructions. </em> 작업 수를 스케일링하면 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>, <a class="ltx_ref" href="#bib.bib88" title="">88</a>]</cite>의 일반화 능력을 크게 향상시킬 수 있다는 것이 널리 알려져 있다. 작업 수가 증가함에 따라 모델 성능은 처음에는 지속적인 성장 패턴을 보이는 반면, 특정 수준 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib88" title="">88</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>에 도달하면 이득은 무시할 수 있다. 그럴듯한 추측은 특정 수의 대표 태스크가 상대적으로 충분한 지식을 제공할 수 있고 더 많은 태스크를 추가하면 추가 이득을 가져오지 않을 수 있다는 것이다. 또한, 길이, 구조, 창의성 등 여러 가지 측면에서 과제 묘사의 다양성을 높이는 것이 유익하다. 작업당 인스턴스 수는 보통 소수의 인스턴스가 특정 작업을 수행하기 위해 모델의 일반화 성능을 포화시킬 수 있는 것으로 나타났다. 특히, 최근의 몇 가지 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib349" title="">349</a>, <a class="ltx_ref" href="#bib.bib350" title="">350</a>]</cite>는 소량의 고품질 명령어 데이터(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p6.1.2">e.g.,</em> 1개 또는 수천 개의 인스턴스)로 미세 조정 효과를 탐구하여 평가 작업에 매우 유망한 결과를 보여주었다. 대조적으로, 또 다른 연구 라인은 명령어 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib351" title="">351</a>, <a class="ltx_ref" href="#bib.bib352" title="">352</a>]</cite>의 스케일링 효과를 계속 탐구한다. 예를 들어 Orca<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib351" title="">351</a>]</cite>는 단계별 설명을 통해 합성된 인스턴스를 500만 개로 확장하고, 명령어 데이터로 튜닝된 방법에 비해 광범위한 태스크에서 우수한 성능을 달성한다.</p>
</div>
<div id="S5.SS1.SSS1.p7" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS1.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p7.1.m1.1"><semantics id="S5.SS1.SSS1.p7.1.m1.1a"><mo id="S5.SS1.SSS1.p7.1.m1.1.1" xref="S5.SS1.SSS1.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p7.1.m1.1b"><ci id="S5.SS1.SSS1.p7.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p7.1.1">Formatting design. </em> 중요한 요소로서 자연어 포맷의 설계는 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib88" title="">88</a>]</cite>의 일반화 성능에도 큰 영향을 미친다. 일반적으로 기존 데이터 세트의 입력-출력 쌍에 작업 설명 및 선택적 데모를 추가할 수 있으며, 여기서 작업 설명은 LLM이 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib88" title="">88</a>]</cite>를 이해하는 데 가장 중요한 부분이다. 또한, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>의 예시로 적절한 수의 예시들을 사용함으로써 실질적인 개선으로 이어질 수 있으며, 이는 또한 수업공학 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>에 대한 모델 민감도를 완화시킨다. 그러나, 다른 컴포넌트들(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p7.1.2">e.g.,</em> things to avoid, reasons, suggestions)을 명령어에 통합하는 것은 LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib166" title="">166</a>, <a class="ltx_ref" href="#bib.bib88" title="">88</a>]</cite>의 성능에 무시할 수 있거나 심지어 악영향을 미칠 수 있다. 최근 LLM의 단계별 추론 능력을 도출하기 위해 산술 추론과 같은 일부 추론 데이터 세트에 대한 CoT(Chain-of-thought) 예제를 포함하는 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>가 제안한다. CoT 및 비-CoT 예 모두를 갖는 미세-조정 LLM은 다중-홉 추론 능력을 필요로 하는 것(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p7.1.3">e.g.,</em> 상식 질문 응답 및 산술 추론) 뿐만 아니라 그러한 추론 방식이 필요하지 않은 것(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS1.p7.1.4">e.g.,</em> 감정 분석 및 추출 질문 응답)을 포함하여 다양한 추론 작업에 걸쳐 양호한 성능을 유도할 수 있음이 나타났다.</p>
</div>
<div id="S5.SS1.SSS1.p8" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS1.p8.1">요약하면, InstructGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>와 LLaMA-2-Chat<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>는 Flan-series LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>보다 적은 수의 다양한 명령(또는 인스턴스)을 사용하기 때문에 명령의 다양성과 품질이 인스턴스 수보다 더 중요한 것으로 보인다. 그러나, 많은 양의 트레이닝 데이터는 고품질 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib351" title="">351</a>]</cite>의 부재를 보상할 수 있다. 또한 데이터 세트별 작업을 사용하는 것보다 레이블러를 불러 사람이 필요한 작업을 구성하는 것이 더 유용합니다. 그러나 여전히 인간이 필요로 하는 인스턴스에 주석을 달기 위한 일반적인 지침이 부족하여 작업 구성이 어떻게든 휴리스틱하게 만든다. 인간의 노력을 줄이기 위해 기존 포맷 데이터 세트(표<a class="ltx_ref" href="#S3.T3" title="TABLE III ‣ 3.2 Commonly Used Corpora for Pre-training ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">III</span></a>)를 재사용하거나 기존 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>를 사용하여 명령어를 자동으로 구성할 수 있다. <a class="ltx_ref" href="#S5.SS1.SSS4" title="5.1.4 Empirical Analysis for Instruction Tuning ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1.4</span></a> 절에서 서로 다른 시공 방법의 효과를 보여주기 위한 예비 실험을 진행한다.</p>
</div>
<figure id="S5.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VIII:</span>필요한 GPU 수, 튜닝 시간, 디바이스당 배치 크기(BS로 표시됨)(풀 튜닝 및 LoRA 튜닝), 추론 속도(초당 생성된 토크의 수)의 기본 통계. 실험은 각각 6개의 NVSwitch와 8개의 3090-24G GPU를 가진 8개의 A800-80G SXM4 GPU를 가진 두 개의 리눅스 서버를 기반으로 수행되었다. A800과 A100의 주요 차이점은 NVLink 상호 연결 속도에 있습니다. 따라서 학습 및 추론 효율성에 대한 추정은 A100에 대해 약간 개선되는 반면 나머지 메모리 소비는 동일하게 유지된다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span>Basic statistics of the required number of GPUs, tuning time, batch size (denoted as BS) per device (full tuning and LoRA tuning), and inference rate (the number of generated tokes per second). Our experiments are conducted based on two Linux servers having 8 A800-80G SXM4 GPUs with 6 NVSwitch and 8 3090-24G GPUs, respectively. The major difference between A800 and A100 lies in the NVLink interconnect speed. Thus, our estimations about training and inference efficiency would be slightly improved for A100, while the rest memory consumption would remain the same.

For full tuning experiments, we use data parallel training, ZeRO Stage 3, BF16, and gradient checkpointing. Additionally, the LoRA tuning can be executed on one 80G GPU utilizing INT8 quantization with the rank setting set to 16. All the experiments are conducted with Alpaca-52K dataset by training LLaMA models three epochs. The max sequence length for both training settings is set to 512. The inference experiments are performed with the batch size set to 1.
</figcaption>
<table id="S5.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S5.T8.1.1" class="ltx_tr">
<td id="S5.T8.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="2"><span id="S5.T8.1.1.1.1" class="ltx_text ltx_font_bold">Models</span></td>
<td id="S5.T8.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;" colspan="3"><span id="S5.T8.1.1.2.1" class="ltx_text ltx_font_bold">A800 Full Training</span></td>
<td id="S5.T8.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;" colspan="3"><span id="S5.T8.1.1.3.1" class="ltx_text ltx_font_bold">A800 LoRA Training</span></td>
<td id="S5.T8.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;" colspan="2"><span id="S5.T8.1.1.4.1" class="ltx_text ltx_font_bold">A800 Inference (16-bit)</span></td>
<td id="S5.T8.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;" colspan="2"><span id="S5.T8.1.1.5.1" class="ltx_text ltx_font_bold">3090 Inference (16-bit)</span></td>
<td id="S5.T8.1.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;" colspan="2"><span id="S5.T8.1.1.6.1" class="ltx_text ltx_font_bold">3090 Inference (8-bit)</span></td>
</tr>
<tr id="S5.T8.1.2" class="ltx_tr">
<td id="S5.T8.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">#GPU</td>
<td id="S5.T8.1.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">BS</td>
<td id="S5.T8.1.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">Time</td>
<td id="S5.T8.1.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">#GPU</td>
<td id="S5.T8.1.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">BS</td>
<td id="S5.T8.1.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">Time</td>
<td id="S5.T8.1.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">#GPU</td>
<td id="S5.T8.1.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">#Token/s</td>
<td id="S5.T8.1.2.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">#GPU</td>
<td id="S5.T8.1.2.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">#Token/s</td>
<td id="S5.T8.1.2.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">#GPU</td>
<td id="S5.T8.1.2.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">#Token/s</td>
</tr>
<tr id="S5.T8.1.3" class="ltx_tr">
<td id="S5.T8.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">LLaMA (7B)</td>
<td id="S5.T8.1.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">2</td>
<td id="S5.T8.1.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">8</td>
<td id="S5.T8.1.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">3.0h</td>
<td id="S5.T8.1.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">80</td>
<td id="S5.T8.1.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">3.5h</td>
<td id="S5.T8.1.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.3.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">36.6</td>
<td id="S5.T8.1.3.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.3.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">24.3</td>
<td id="S5.T8.1.3.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.3.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">7.5</td>
</tr>
<tr id="S5.T8.1.4" class="ltx_tr">
<td id="S5.T8.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">LLaMA (13B)</td>
<td id="S5.T8.1.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">4</td>
<td id="S5.T8.1.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">8</td>
<td id="S5.T8.1.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">3.1h</td>
<td id="S5.T8.1.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">48</td>
<td id="S5.T8.1.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">5.1h</td>
<td id="S5.T8.1.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.4.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">26.8</td>
<td id="S5.T8.1.4.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">2</td>
<td id="S5.T8.1.4.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">9.9</td>
<td id="S5.T8.1.4.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.4.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">4.5</td>
</tr>
<tr id="S5.T8.1.5" class="ltx_tr">
<td id="S5.T8.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">LLaMA (30B)</td>
<td id="S5.T8.1.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">8</td>
<td id="S5.T8.1.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">4</td>
<td id="S5.T8.1.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">6.1h</td>
<td id="S5.T8.1.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.5.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">24</td>
<td id="S5.T8.1.5.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">14.3h</td>
<td id="S5.T8.1.5.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.5.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">17.7</td>
<td id="S5.T8.1.5.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">4</td>
<td id="S5.T8.1.5.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">3.8</td>
<td id="S5.T8.1.5.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">2</td>
<td id="S5.T8.1.5.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">2.6</td>
</tr>
<tr id="S5.T8.1.6" class="ltx_tr">
<td id="S5.T8.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">LLaMA (65B)</td>
<td id="S5.T8.1.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">16</td>
<td id="S5.T8.1.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">2</td>
<td id="S5.T8.1.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">11.2h</td>
<td id="S5.T8.1.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">1</td>
<td id="S5.T8.1.6.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">4</td>
<td id="S5.T8.1.6.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">60.6h</td>
<td id="S5.T8.1.6.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">2</td>
<td id="S5.T8.1.6.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">8.8</td>
<td id="S5.T8.1.6.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">8</td>
<td id="S5.T8.1.6.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">2.0</td>
<td id="S5.T8.1.6.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">4</td>
<td id="S5.T8.1.6.13" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">1.5</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Instruction Tuning Strategies</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS2.p1.1">사전 트레이닝과 달리, 트레이닝을 위해 적당한 수의 인스턴스들만이 사용되기 때문에, 명령어 튜닝은 종종 더 효율적이다. 명령어 튜닝은 지도 훈련 프로세스로 간주될 수 있기 때문에, 그것의 최적화는 훈련 목적(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p1.1.1">i.e.,</em>sequence-to-sequence loss) 및 최적화 구성(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p1.1.2">e.g.,</em> smaller batch size and learning rate)과 같은 여러 측면에서 사전 훈련과는 다르다. 이러한 최적화 구성들 외에도, 명령어 튜닝을 위해 고려해야 할 네 가지 중요한 측면들이 또한 존재한다:</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p2.1.1">Balancing the Data Distribution. </span> 명령어 튜닝은 서로 다른 태스크들의 혼합을 수반하기 때문에, 미세-튜닝 동안 서로 다른 태스크들의 비율의 균형을 맞추는 것이 중요하다. 널리 사용되는 방법은 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p2.1.2">examples-proportional mixing</em> strategy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p2.1.3">i.e.,</em> 모든 데이터 세트를 결합하고 혼합된 데이터 세트에서 각 인스턴스를 동일하게 샘플링하는 것이다. 또한, 고품질 컬렉션(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p2.1.4">e.g.,</em> FLAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite> and P3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib167" title="">167</a>]</cite>)의 샘플링 비율을 높이면 일반적으로 최근 연구 결과 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>, <a class="ltx_ref" href="#bib.bib95" title="">95</a>]</cite>에 따라 성능 향상을 가져올 수 있다. 또한, 명령 튜닝 중에 데이터 세트가 포함할 수 있는 최대 예제의 수를 제어하기 위해 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p2.1.5">maximum cap</em>을 설정하는 것이 일반적이며, 이는 더 큰 데이터 세트가 전체 분포를 압도하는 것을 방지하기 위해 설정된 것이다. 실제로, 최대 캡은 상이한 데이터세트들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>에 따라 전형적으로 수 천 또는 수만 개로 설정된다. 최근, 기존의 명령어 데이터셋(표<a class="ltx_ref" href="#S3.T3" title="TABLE III ‣ 3.2 Commonly Used Corpora for Pre-training ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">III</span></a>)은 주로 특정 측면에서 LLMs의 성능을 향상시키는 데 초점을 맞추고 있으며, 단일 데이터셋만으로는 모델 용량<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib353" title="">353</a>]</cite>의 종합적인 향상으로 이어질 수 없다는 것이 실증적으로 밝혀졌다. 따라서 NLP 작업 데이터(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p2.1.6">e.g.,</em> FLAN v2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib292" title="">292</a>]</cite>), 채팅 데이터(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p2.1.7">e.g.,</em>ShareGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>), 합성 데이터(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p2.1.8">e.g.,</em> GPT4-Alpaca <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib354" title="">354</a>]</cite>)를 포함하여 서로 다른 용량에서 균형 잡힌 개선을 달성하기 위해 기존 명령 데이터 세트의 혼합물을 사용하는 것이 종종 제안된다.</p>
</div>
<div id="S5.SS1.SSS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p3.1.1">Combining Instruction Tuning and Pre-Training. </span> 튜닝 프로세스를 보다 효과적이고 안정적으로 만들기 위해, OPT-IML <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib95" title="">95</a>]</cite>는 명령어 튜닝 동안 사전 트레이닝 데이터를 통합하는데, 이는 모델 튜닝을 위한 정규화로 간주될 수 있다. 또한, 별도의 2단계 프로세스(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p3.1.2">pre-training</em> then <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p3.1.3">instruction tuning</em>)를 사용하는 대신, 일부 연구에서는 멀티 태스크 학습을 사용하여 사전 학습 데이터(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p3.1.4">i.e.,</em> plain texts)와 명령어 튜닝 데이터(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p3.1.5">i.e.,</em> formatted datasets)의 혼합물로 모델을 처음부터 학습하려고 시도합니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>. 특히 GLM-130B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>와 Galactica <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite>는 사전 학습 말뭉치의 작은 비율로 명령어 형식의 데이터셋을 사전 학습 LLMs에 통합함으로써 사전 학습과 명령어 튜닝의 장점을 동시에 달성할 수 있다.</p>
</div>
<div id="S5.SS1.SSS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p4.1.1">Multi-stage Instruction Tuning. </span> 명령어 튜닝을 위해 중요한 명령어 데이터에는 작업 형식 명령어와 일일 채팅 명령어의 두 종류가 있다. 일반적으로, 전자는 후자에 비해 상당히 큰 부피를 갖는다. 훈련과 두 종류의 훈련 데이터의 균형을 맞추는 것이 중요하다. 서로 다른 명령어 데이터를 신중하게 혼합하는 것 외에도 LLM이 먼저 대규모 태스크 형식의 명령어로 미세 조정되고 이후 일일 채팅에서 미세 조정되는 다중 단계 명령어 튜닝 전략 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib352" title="">352</a>]</cite>를 채택할 수 있다. 용량 망각 문제를 방지하기 위해 두 번째 단계에서 작업 형식 지침을 추가하는 것도 유용합니다. 실제로 이러한 다단계 튜닝 전략은 명령어 튜닝을 위한 다른 설정에도 적용될 수 있다. 예를 들어, 난이도 및 복잡도에 대해 점진적으로 증가된 레벨을 갖는 상이한 미세 조정 단계를 스케줄링할 수 있고, 복잡한 지시를 따르도록 LLM의 용량을 점진적으로 개선할 수 있다.</p>
</div>
<div id="S5.SS1.SSS2.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS2.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p5.1.1">Other Practical Tricks. </span> 실제로 LLM의 미세 조정 성능을 향상시키는 데 도움이 되는 몇 가지 유용한 전략과 트릭도 있다. 우리는 다음과 같이 몇 가지 대표적인 것을 나열한다.</p>
</div>
<div id="S5.SS1.SSS2.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p6.1.m1.1"><semantics id="S5.SS1.SSS2.p6.1.m1.1a"><mo id="S5.SS1.SSS2.p6.1.m1.1.1" xref="S5.SS1.SSS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p6.1.m1.1b"><ci id="S5.SS1.SSS2.p6.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p6.1.1">Efficient training for multi-turn chat data. </em> 다중 턴 채팅 예제(사용자와 챗봇 간의 대화)가 주어지면 간단한 미세 조정 방법은 학습을 위해 여러 컨텍스트-응답 쌍으로 분할하는 것입니다. LLM은 모든 분할에 대한 해당 컨텍스트를 기반으로 응답을 생성하기 위해 미세 조정됩니다(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p6.1.2">i.e.,</em>). 이러한 미세 조정 방식으로, 대화로부터 분리된 예들에서 중복되는 발화가 존재하는 것은 명백하다. 훈련 비용을 줄이기 위해 Vicuna<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>는 대화 전체를 LLM에 공급하는 효율적인 방법을 채택했지만, 훈련을 위해 챗봇의 응답에 대한 손실만을 계산하는 손실 마스크에 의존한다. 이는 중첩된 발화로부터 도출되는 계산 비용을 상당히 감소시킬 수 있다.</p>
</div>
<div id="S5.SS1.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p7.1.m1.1"><semantics id="S5.SS1.SSS2.p7.1.m1.1a"><mo id="S5.SS1.SSS2.p7.1.m1.1.1" xref="S5.SS1.SSS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p7.1.m1.1b"><ci id="S5.SS1.SSS2.p7.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p7.1.1">Establishing self-identification for LLM. </em> 실제 응용 프로그램에 LLM을 배포 하려면 id를 설정 하 고 LLM이 이름, 개발자 및 소속과 같은 id 정보를 인식 하도록 해야 합니다. 실제적인 방법은 LLM을 미세 조정하기 위한 ID 관련 지침을 만드는 것이다. 자체 식별 프롬프트, <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p7.1.2">e.g.,</em> "<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p7.1.3">다음은 <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS2.p7.1.3.1">ChatbotName</span> <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS2.p7.1.3.2">Developer</span></em>이라고 하는 인간과 AI 어시스턴트 간의 대화입니다. 여기서 <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS2.p7.1.4">ChatbotName</span> 및 <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS2.p7.1.5">Developer</span>은 각각 챗봇의 이름과 개발자를 의미한다.</p>
</div>
<div id="S5.SS1.SSS2.p8" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS2.p8.1">위의 실용적인 전략 및 트릭 외에도 기존 작업에서는 다른 트릭인 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS2.p8.1.1">e.g.,</em> 여러 예제를 단일 시퀀스로 연결 하 여 최대 길이 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib355" title="">355</a>]</cite>에 접근 합니다.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>The Effect of Instruction Tuning</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS3.p1.1">이 부분에서는 수업 튜닝이 LLMs에 미치는 영향을 크게 세 가지 측면에서 논의한다.</p>
</div>
<div id="S5.SS1.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS3.p2.1.1">Performance Improvement. </span> 적당한 수의 인스턴스에서 튜닝되었음에도 불구하고, 명령어 튜닝은 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>의 능력을 향상시키거나 잠금 해제하는 중요한 방법이 되었다. 최근 연구에서는 여러 척도(77M에서 540B까지)의 언어 모델을 실험하여 서로 다른 척도의 모델이 모두 명령어 튜닝의 이점을 얻을 수 있음을 보여주었으며, 매개변수 척도가 증가함에 따라 향상된 성능을 보였다. 또한, 명령어 튜닝을 갖는 더 작은 모델들은 심지어 미세-튜닝 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>를 갖지 않는 더 큰 모델들보다 더 잘 수행할 수 있다. 모델 규모 외에도 명령어 튜닝은 다양한 모델 아키텍처, 사전 훈련 목표 및 모델 적응 방법 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>에서 일관된 개선을 보여준다. 실제로, 명령어 튜닝은 기존 언어 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite> (작은 크기의 PLM 포함)의 능력을 향상시키는 일반적인 접근법을 제공한다. 또한, LLMs에 의해 요구되는 명령어 데이터의 양이 사전 트레이닝 데이터보다 상당히 작기 때문에 사전 트레이닝보다 훨씬 비용이 적게 든다.</p>
</div>
<div id="S5.SS1.SSS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS3.p3.1.1">Task Generalization. </span> 명령어 튜닝은 모델이 태스크 완료를 위한 자연어 명령어를 이해하도록 장려한다. 그것은 LLMs에게 인간의 지시를 따르는 능력(종종 창발 능력으로 간주됨)을 부여한다.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>는 보이지 않는 작업에서도 시연 없이 특정 작업을 수행할 수 있다.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite> 많은 연구에서 보이는 태스크와 보이지 않는 태스크 모두에서 우수한 성능을 달성하기 위한 명령어 튜닝의 효과를 확인했다. 또한 명령어 튜닝은 LLMs(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS3.p3.1.2">e.g.,</em> 반복 생성 또는 특정 작업을 수행하지 않고 입력을 보완하는 것)의 몇 가지 약점을 완화하는데 유용한 것으로 나타났다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite> LLMs에 대한 실제 작업을 해결하는 데 탁월한 용량으로 이어진다. 또한, 명령어 튜닝을 통해 훈련된 LLM은 언어 전반에 걸쳐 관련 작업에 일반화할 수 있다. 예를 들어, BLOOMZ-P3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib94" title="">94</a>]</cite>는 영어 전용 작업 모음 P3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib167" title="">167</a>]</cite>를 사용하여 BLOOM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>를 기반으로 미세 조정된다. 흥미롭게도 BLOOMZ-P3는 BLOOM에 비해 다국어 문장 완성 작업에서 50% 이상의 향상을 달성할 수 있으며, 이는 명령어 튜닝이 LLMs가 영어 전용 데이터 세트에서 일반적인 작업 기술을 습득하고 그러한 기술을 다른 언어로 옮기는 데 도움이 될 수 있음을 보여준다. 또한 영어 전용 명령어를 사용하면 다국어 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib94" title="">94</a>]</cite>에서 만족스러운 결과를 얻을 수 있어 특정 언어에 대한 명령어 엔지니어링의 노력을 줄이는 데 도움이 되는 것으로 나타났다.</p>
</div>
<div id="S5.SS1.SSS3.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS3.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS3.p4.1.1">Domain Specialization. </span> 기존 LLM은 기존 NLP 작업(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS3.p4.1.2">e.g.,</em> 생성 및 추론) 및 일일 질문에서 우수한 성능을 보여주었다. 그러나, 그들은 여전히 의학, 법률 및 금융과 같은 특정 작업을 달성하기 위한 도메인 지식이 부족할 수 있다(다른 애플리케이션에서 LLMs에 대한 상세한 논의는 섹션 <a class="ltx_ref" href="#S8" title="8 Applications ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">8</span></a> 참조). 명령어 조정은 기존의 일반적인 LLM을 도메인별 전문가가 되도록 적응시키는 효과적인 접근법이다. 예를 들어, 연구자들은 의료 데이터 세트를 사용하여 플랜-PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>를 미세 조정하여 전문 임상의와 유사한 성능 수준을 달성하는 의료 지식 보조인 Med-PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib356" title="">356</a>]</cite>를 만들 것을 제안한다. 또한 최근 자연어 명령어를 이용한 전자상거래 추천 시스템을 지원하기 위한 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib357" title="">357</a>]</cite> fine-tunes FLAN-T5의 연구가 진행되어 다양한 추천 작업에서 강한 성능을 보이고 있다. 또한 BenTsao<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib358" title="">358</a>]</cite>와 같이 LLaMA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>를 기반으로 하는 몇 가지 오픈 소스 의료 모델도 있다. 또한 연구자들은 법률<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib359" title="">359</a>]</cite>, 금융<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib360" title="">360</a>]</cite>, 연산연산<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib361" title="">361</a>]</cite>에 대한 명령어 튜닝을 탐구한다.</p>
</div>
<figure id="S5.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IX:</span> 채팅 및 QA 설정 하에서 LLaMA(7B) 및 LLaMA(13B) 모델을 기반으로 하는 명령어 튜닝 실험(단일 턴 대화에서 모두)의 결과. S5.T9.13.1">i.e.,</em> enhancing the complexity (<em class="ltx_emph ltx_font_italic" id="S5.T9.14.2">w/ complexity</em>), increasing the diversity (<em class="ltx_emph ltx_font_italic" id="S5.T9.15.3">w/ diversity</em>), balancing the difficulty (<em class="ltx_emph ltx_font_italic" id="S5.T9.16.4">w/ difficulty</em>), scaling the instruction number (<em class="ltx_emph ltx_font_italic" id="S5.T9.17.5">w/ scaling</em>)를 사용하였다. <sup class="ltx_sup" id="S5.T9.18.6">∗</sup>LLaMA (7B)/(13B) model fine-tuned on Self-Instruct-52K를 베이스라인으로 선택하기 때문에 Self-Instruct-52K against self-tuned model의 승률을 생략한다.</figcaption>
<div id="S5.T9.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:693.8pt;height:675.1pt;vertical-align:-1.5pt;"><span class="ltx_transformed_inner" style="transform:translate(120.7pt,-117.2pt) scale(1.53364483040195,1.53364483040195) ;">
<table id="S5.T9.6.4" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S5.T9.6.4.5" class="ltx_tr">
<td id="S5.T9.6.4.5.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S5.T9.6.4.5.1.1" class="ltx_text ltx_font_bold">Models</span></td>
<td id="S5.T9.6.4.5.2" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S5.T9.6.4.5.2.1" class="ltx_text">
<span id="S5.T9.6.4.5.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.5.2.1.1.1" class="ltx_tr">
<span id="S5.T9.6.4.5.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T9.6.4.5.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span></span>
<span id="S5.T9.6.4.5.2.1.1.2" class="ltx_tr">
<span id="S5.T9.6.4.5.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T9.6.4.5.2.1.1.2.1.1" class="ltx_text ltx_font_bold">Mixtures</span></span></span>
</span></span></td>
<td id="S5.T9.6.4.5.3" class="ltx_td ltx_align_right ltx_border_tt" rowspan="2"><span id="S5.T9.6.4.5.3.1" class="ltx_text">
<span id="S5.T9.6.4.5.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.5.3.1.1.1" class="ltx_tr">
<span id="S5.T9.6.4.5.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T9.6.4.5.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Instruction</span></span></span>
<span id="S5.T9.6.4.5.3.1.1.2" class="ltx_tr">
<span id="S5.T9.6.4.5.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T9.6.4.5.3.1.1.2.1.1" class="ltx_text ltx_font_bold">Numbers</span></span></span>
</span></span></td>
<td id="S5.T9.6.4.5.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S5.T9.6.4.5.4.1" class="ltx_text">
<span id="S5.T9.6.4.5.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.5.4.1.1.1" class="ltx_tr">
<span id="S5.T9.6.4.5.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T9.6.4.5.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Lexical</span></span></span>
<span id="S5.T9.6.4.5.4.1.1.2" class="ltx_tr">
<span id="S5.T9.6.4.5.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T9.6.4.5.4.1.1.2.1.1" class="ltx_text ltx_font_bold">Diversity</span></span></span>
</span></span></td>
<td id="S5.T9.6.4.5.5" class="ltx_td ltx_nopad_r ltx_border_r ltx_border_tt" rowspan="2"></td>
<td id="S5.T9.6.4.5.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T9.6.4.5.6.1" class="ltx_text ltx_font_bold">Chat</span></td>
<td id="S5.T9.6.4.5.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T9.6.4.5.7.1" class="ltx_text ltx_font_bold">QA</span></td>
</tr>
<tr id="S5.T9.6.4.6" class="ltx_tr">
<td id="S5.T9.6.4.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_t"></td>
<td id="S5.T9.6.4.6.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">AlpacaFarm</td>
<td id="S5.T9.6.4.6.3" class="ltx_td ltx_align_center ltx_border_t">MMLU</td>
<td id="S5.T9.6.4.6.4" class="ltx_td ltx_align_center ltx_border_t">BBH3k</td>
</tr>
<tr id="S5.T9.6.4.7" class="ltx_tr">
<td id="S5.T9.6.4.7.1" class="ltx_td ltx_align_left ltx_border_t">LLaMA&nbsp;(7B)</td>
<td id="S5.T9.6.4.7.2" class="ltx_td ltx_align_left ltx_border_t">①&nbsp;FLAN-T5</td>
<td id="S5.T9.6.4.7.3" class="ltx_td ltx_align_right ltx_border_t">80,000</td>
<td id="S5.T9.6.4.7.4" class="ltx_td ltx_align_center ltx_border_t">48.48</td>
<td id="S5.T9.6.4.7.5" class="ltx_td ltx_nopad_r ltx_border_r ltx_border_t"></td>
<td id="S5.T9.6.4.7.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_t"></td>
<td id="S5.T9.6.4.7.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">23.77</td>
<td id="S5.T9.6.4.7.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C4DDEC;"><span id="S5.T9.6.4.7.8.1" class="ltx_text" style="background-color:#C4DDEC;">38.58</span></td>
<td id="S5.T9.6.4.7.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;"><span id="S5.T9.6.4.7.9.1" class="ltx_text" style="background-color:#A7CBE2;">32.79</span></td>
</tr>
<tr id="S5.T9.6.4.8" class="ltx_tr">
<td id="S5.T9.6.4.8.1" class="ltx_td"></td>
<td id="S5.T9.6.4.8.2" class="ltx_td ltx_align_left">②&nbsp;ShareGPT</td>
<td id="S5.T9.6.4.8.3" class="ltx_td ltx_align_right">63,184</td>
<td id="S5.T9.6.4.8.4" class="ltx_td ltx_align_center">77.31</td>
<td id="S5.T9.6.4.8.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.8.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.8.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#A7CBE2;"><span id="S5.T9.6.4.8.7.1" class="ltx_text" style="background-color:#A7CBE2;">81.30</span></td>
<td id="S5.T9.6.4.8.8" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;"><span id="S5.T9.6.4.8.8.1" class="ltx_text" style="background-color:#E5F0F7;">38.11</span></td>
<td id="S5.T9.6.4.8.9" class="ltx_td ltx_align_center">27.71</td>
</tr>
<tr id="S5.T9.3.1.1" class="ltx_tr">
<td id="S5.T9.3.1.1.2" class="ltx_td"></td>
<td id="S5.T9.3.1.1.3" class="ltx_td ltx_align_left">③&nbsp;Self-Instruct-52K</td>
<td id="S5.T9.3.1.1.4" class="ltx_td ltx_align_right">82,439</td>
<td id="S5.T9.3.1.1.5" class="ltx_td ltx_align_center">25.92</td>
<td id="S5.T9.3.1.1.6" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.3.1.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.3.1.1.1" class="ltx_td ltx_nopad_l ltx_align_center">/<sup id="S5.T9.3.1.1.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S5.T9.3.1.1.8" class="ltx_td ltx_align_center">37.52</td>
<td id="S5.T9.3.1.1.9" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;"><span id="S5.T9.3.1.1.9.1" class="ltx_text" style="background-color:#E5F0F7;">29.81</span></td>
</tr>
<tr id="S5.T9.6.4.9" class="ltx_tr">
<td id="S5.T9.6.4.9.1" class="ltx_td"></td>
<td id="S5.T9.6.4.9.2" class="ltx_td ltx_align_left">② + ③</td>
<td id="S5.T9.6.4.9.3" class="ltx_td ltx_align_right">145,623</td>
<td id="S5.T9.6.4.9.4" class="ltx_td ltx_align_center">48.22</td>
<td id="S5.T9.6.4.9.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.9.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.9.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#E5F0F7;"><span id="S5.T9.6.4.9.7.1" class="ltx_text" style="background-color:#E5F0F7;">71.36</span></td>
<td id="S5.T9.6.4.9.8" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;"><span id="S5.T9.6.4.9.8.1" class="ltx_text" style="background-color:#A7CBE2;">41.26</span></td>
<td id="S5.T9.6.4.9.9" class="ltx_td ltx_align_center">28.36</td>
</tr>
<tr id="S5.T9.6.4.10" class="ltx_tr">
<td id="S5.T9.6.4.10.1" class="ltx_td"></td>
<td id="S5.T9.6.4.10.2" class="ltx_td ltx_align_left">① + ② + ③</td>
<td id="S5.T9.6.4.10.3" class="ltx_td ltx_align_right">225,623</td>
<td id="S5.T9.6.4.10.4" class="ltx_td ltx_align_center">48.28</td>
<td id="S5.T9.6.4.10.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.10.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.10.7" class="ltx_td ltx_nopad_l ltx_align_center">70.00</td>
<td id="S5.T9.6.4.10.8" class="ltx_td ltx_align_center" style="background-color:#92BFDB;"><span id="S5.T9.6.4.10.8.1" class="ltx_text" style="background-color:#92BFDB;">43.69</span></td>
<td id="S5.T9.6.4.10.9" class="ltx_td ltx_align_center">29.69</td>
</tr>
<tr id="S5.T9.4.2.2" class="ltx_tr">
<td id="S5.T9.4.2.2.2" class="ltx_td"></td>
<td id="S5.T9.4.2.2.3" class="ltx_td ltx_align_left ltx_border_t">③&nbsp;Self-Instruct-52K</td>
<td id="S5.T9.4.2.2.4" class="ltx_td ltx_align_right ltx_border_t">82,439</td>
<td id="S5.T9.4.2.2.5" class="ltx_td ltx_align_center ltx_border_t">25.92</td>
<td id="S5.T9.4.2.2.6" class="ltx_td ltx_nopad_r ltx_border_r ltx_border_t"></td>
<td id="S5.T9.4.2.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_t"></td>
<td id="S5.T9.4.2.2.1" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">/<sup id="S5.T9.4.2.2.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S5.T9.4.2.2.8" class="ltx_td ltx_align_center ltx_border_t">37.52</td>
<td id="S5.T9.4.2.2.9" class="ltx_td ltx_align_center ltx_border_t">29.81</td>
</tr>
<tr id="S5.T9.6.4.11" class="ltx_tr">
<td id="S5.T9.6.4.11.1" class="ltx_td"></td>
<td id="S5.T9.6.4.11.2" class="ltx_td ltx_align_left">
<span id="S5.T9.6.4.11.2.1" class="ltx_text"></span><span id="S5.T9.6.4.11.2.2" class="ltx_text">
<span id="S5.T9.6.4.11.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.11.2.2.1.1" class="ltx_tr">
<span id="S5.T9.6.4.11.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">w/ complexity</span></span>
</span></span><span id="S5.T9.6.4.11.2.3" class="ltx_text"></span></td>
<td id="S5.T9.6.4.11.3" class="ltx_td ltx_align_right">70,000</td>
<td id="S5.T9.6.4.11.4" class="ltx_td ltx_align_center">70.43</td>
<td id="S5.T9.6.4.11.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.11.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.11.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#C4DDEC;"><span id="S5.T9.6.4.11.7.1" class="ltx_text" style="background-color:#C4DDEC;">76.96</span></td>
<td id="S5.T9.6.4.11.8" class="ltx_td ltx_align_center" style="background-color:#C6DEED;"><span id="S5.T9.6.4.11.8.1" class="ltx_text" style="background-color:#C6DEED;">39.73</span></td>
<td id="S5.T9.6.4.11.9" class="ltx_td ltx_align_center" style="background-color:#92BFDB;"><span id="S5.T9.6.4.11.9.1" class="ltx_text" style="background-color:#92BFDB;">33.25</span></td>
</tr>
<tr id="S5.T9.6.4.12" class="ltx_tr">
<td id="S5.T9.6.4.12.1" class="ltx_td"></td>
<td id="S5.T9.6.4.12.2" class="ltx_td ltx_align_left">
<span id="S5.T9.6.4.12.2.1" class="ltx_text"></span><span id="S5.T9.6.4.12.2.2" class="ltx_text">
<span id="S5.T9.6.4.12.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.12.2.2.1.1" class="ltx_tr">
<span id="S5.T9.6.4.12.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">w/ diversity</span></span>
</span></span><span id="S5.T9.6.4.12.2.3" class="ltx_text"></span></td>
<td id="S5.T9.6.4.12.3" class="ltx_td ltx_align_right">70,000</td>
<td id="S5.T9.6.4.12.4" class="ltx_td ltx_align_center">75.59</td>
<td id="S5.T9.6.4.12.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.12.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.12.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#92BFDB;"><span id="S5.T9.6.4.12.7.1" class="ltx_text" style="background-color:#92BFDB;">81.55</span></td>
<td id="S5.T9.6.4.12.8" class="ltx_td ltx_align_center">38.01</td>
<td id="S5.T9.6.4.12.9" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;"><span id="S5.T9.6.4.12.9.1" class="ltx_text" style="background-color:#C4DDEC;">30.03</span></td>
</tr>
<tr id="S5.T9.6.4.13" class="ltx_tr">
<td id="S5.T9.6.4.13.1" class="ltx_td"></td>
<td id="S5.T9.6.4.13.2" class="ltx_td ltx_align_left">
<span id="S5.T9.6.4.13.2.1" class="ltx_text"></span><span id="S5.T9.6.4.13.2.2" class="ltx_text">
<span id="S5.T9.6.4.13.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.13.2.2.1.1" class="ltx_tr">
<span id="S5.T9.6.4.13.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">w/ difficulty</span></span>
</span></span><span id="S5.T9.6.4.13.2.3" class="ltx_text"></span></td>
<td id="S5.T9.6.4.13.3" class="ltx_td ltx_align_right">70,000</td>
<td id="S5.T9.6.4.13.4" class="ltx_td ltx_align_center">73.48</td>
<td id="S5.T9.6.4.13.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.13.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.13.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#C6DEED;"><span id="S5.T9.6.4.13.7.1" class="ltx_text" style="background-color:#C6DEED;">79.15</span></td>
<td id="S5.T9.6.4.13.8" class="ltx_td ltx_align_center">32.55</td>
<td id="S5.T9.6.4.13.9" class="ltx_td ltx_align_center" style="background-color:#C6DEED;"><span id="S5.T9.6.4.13.9.1" class="ltx_text" style="background-color:#C6DEED;">31.25</span></td>
</tr>
<tr id="S5.T9.6.4.14" class="ltx_tr">
<td id="S5.T9.6.4.14.1" class="ltx_td"></td>
<td id="S5.T9.6.4.14.2" class="ltx_td ltx_align_left">
<span id="S5.T9.6.4.14.2.1" class="ltx_text"></span><span id="S5.T9.6.4.14.2.2" class="ltx_text">
<span id="S5.T9.6.4.14.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.14.2.2.1.1" class="ltx_tr">
<span id="S5.T9.6.4.14.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">w/ scaling</span></span>
</span></span><span id="S5.T9.6.4.14.2.3" class="ltx_text"></span></td>
<td id="S5.T9.6.4.14.3" class="ltx_td ltx_align_right">220,000</td>
<td id="S5.T9.6.4.14.4" class="ltx_td ltx_align_center">57.78</td>
<td id="S5.T9.6.4.14.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.14.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.14.7" class="ltx_td ltx_nopad_l ltx_align_center">51.13</td>
<td id="S5.T9.6.4.14.8" class="ltx_td ltx_align_center">33.81</td>
<td id="S5.T9.6.4.14.9" class="ltx_td ltx_align_center">26.63</td>
</tr>
<tr id="S5.T9.6.4.15" class="ltx_tr">
<td id="S5.T9.6.4.15.1" class="ltx_td ltx_align_left ltx_border_t">LLaMA&nbsp;(13B)</td>
<td id="S5.T9.6.4.15.2" class="ltx_td ltx_align_left ltx_border_t">①&nbsp;FLAN-T5</td>
<td id="S5.T9.6.4.15.3" class="ltx_td ltx_align_right ltx_border_t">80,000</td>
<td id="S5.T9.6.4.15.4" class="ltx_td ltx_align_center ltx_border_t">48.48</td>
<td id="S5.T9.6.4.15.5" class="ltx_td ltx_nopad_r ltx_border_r ltx_border_t"></td>
<td id="S5.T9.6.4.15.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_t"></td>
<td id="S5.T9.6.4.15.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">22.12</td>
<td id="S5.T9.6.4.15.8" class="ltx_td ltx_align_center ltx_border_t">34.12</td>
<td id="S5.T9.6.4.15.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C4DDEC;"><span id="S5.T9.6.4.15.9.1" class="ltx_text" style="background-color:#C4DDEC;">34.05</span></td>
</tr>
<tr id="S5.T9.6.4.16" class="ltx_tr">
<td id="S5.T9.6.4.16.1" class="ltx_td"></td>
<td id="S5.T9.6.4.16.2" class="ltx_td ltx_align_left">②&nbsp;ShareGPT</td>
<td id="S5.T9.6.4.16.3" class="ltx_td ltx_align_right">63,184</td>
<td id="S5.T9.6.4.16.4" class="ltx_td ltx_align_center">77.31</td>
<td id="S5.T9.6.4.16.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.16.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.16.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#C4DDEC;"><span id="S5.T9.6.4.16.7.1" class="ltx_text" style="background-color:#C4DDEC;">77.13</span></td>
<td id="S5.T9.6.4.16.8" class="ltx_td ltx_align_center" style="background-color:#92BFDB;"><span id="S5.T9.6.4.16.8.1" class="ltx_text" style="background-color:#92BFDB;">47.49</span></td>
<td id="S5.T9.6.4.16.9" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;"><span id="S5.T9.6.4.16.9.1" class="ltx_text" style="background-color:#E5F0F7;">33.82</span></td>
</tr>
<tr id="S5.T9.5.3.3" class="ltx_tr">
<td id="S5.T9.5.3.3.2" class="ltx_td"></td>
<td id="S5.T9.5.3.3.3" class="ltx_td ltx_align_left">③&nbsp;Self-Instruct-52K</td>
<td id="S5.T9.5.3.3.4" class="ltx_td ltx_align_right">82,439</td>
<td id="S5.T9.5.3.3.5" class="ltx_td ltx_align_center">25.92</td>
<td id="S5.T9.5.3.3.6" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.5.3.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.5.3.3.1" class="ltx_td ltx_nopad_l ltx_align_center">/<sup id="S5.T9.5.3.3.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S5.T9.5.3.3.8" class="ltx_td ltx_align_center">36.73</td>
<td id="S5.T9.5.3.3.9" class="ltx_td ltx_align_center">25.43</td>
</tr>
<tr id="S5.T9.6.4.17" class="ltx_tr">
<td id="S5.T9.6.4.17.1" class="ltx_td"></td>
<td id="S5.T9.6.4.17.2" class="ltx_td ltx_align_left">② + ③</td>
<td id="S5.T9.6.4.17.3" class="ltx_td ltx_align_right">145,623</td>
<td id="S5.T9.6.4.17.4" class="ltx_td ltx_align_center">48.22</td>
<td id="S5.T9.6.4.17.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.17.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.17.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#E5F0F7;"><span id="S5.T9.6.4.17.7.1" class="ltx_text" style="background-color:#E5F0F7;">72.85</span></td>
<td id="S5.T9.6.4.17.8" class="ltx_td ltx_align_center">41.16</td>
<td id="S5.T9.6.4.17.9" class="ltx_td ltx_align_center">29.49</td>
</tr>
<tr id="S5.T9.6.4.18" class="ltx_tr">
<td id="S5.T9.6.4.18.1" class="ltx_td"></td>
<td id="S5.T9.6.4.18.2" class="ltx_td ltx_align_left">① + ② + ③</td>
<td id="S5.T9.6.4.18.3" class="ltx_td ltx_align_right">225,623</td>
<td id="S5.T9.6.4.18.4" class="ltx_td ltx_align_center">48.28</td>
<td id="S5.T9.6.4.18.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.18.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.18.7" class="ltx_td ltx_nopad_l ltx_align_center">69.49</td>
<td id="S5.T9.6.4.18.8" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;"><span id="S5.T9.6.4.18.8.1" class="ltx_text" style="background-color:#C4DDEC;">43.50</span></td>
<td id="S5.T9.6.4.18.9" class="ltx_td ltx_align_center">31.16</td>
</tr>
<tr id="S5.T9.6.4.4" class="ltx_tr">
<td id="S5.T9.6.4.4.2" class="ltx_td"></td>
<td id="S5.T9.6.4.4.3" class="ltx_td ltx_align_left ltx_border_t">③&nbsp;Self-Instruct-52K</td>
<td id="S5.T9.6.4.4.4" class="ltx_td ltx_align_right ltx_border_t">82,439</td>
<td id="S5.T9.6.4.4.5" class="ltx_td ltx_align_center ltx_border_t">25.92</td>
<td id="S5.T9.6.4.4.6" class="ltx_td ltx_nopad_r ltx_border_r ltx_border_t"></td>
<td id="S5.T9.6.4.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_t"></td>
<td id="S5.T9.6.4.4.1" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">/<sup id="S5.T9.6.4.4.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S5.T9.6.4.4.8" class="ltx_td ltx_align_center ltx_border_t">36.73</td>
<td id="S5.T9.6.4.4.9" class="ltx_td ltx_align_center ltx_border_t">25.43</td>
</tr>
<tr id="S5.T9.6.4.19" class="ltx_tr">
<td id="S5.T9.6.4.19.1" class="ltx_td"></td>
<td id="S5.T9.6.4.19.2" class="ltx_td ltx_align_left">
<span id="S5.T9.6.4.19.2.1" class="ltx_text"></span><span id="S5.T9.6.4.19.2.2" class="ltx_text">
<span id="S5.T9.6.4.19.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.19.2.2.1.1" class="ltx_tr">
<span id="S5.T9.6.4.19.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">w/ complexity</span></span>
</span></span><span id="S5.T9.6.4.19.2.3" class="ltx_text"></span></td>
<td id="S5.T9.6.4.19.3" class="ltx_td ltx_align_right">70,000</td>
<td id="S5.T9.6.4.19.4" class="ltx_td ltx_align_center">70.43</td>
<td id="S5.T9.6.4.19.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.19.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.19.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#C6DEED;"><span id="S5.T9.6.4.19.7.1" class="ltx_text" style="background-color:#C6DEED;">77.94</span></td>
<td id="S5.T9.6.4.19.8" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;"><span id="S5.T9.6.4.19.8.1" class="ltx_text" style="background-color:#A7CBE2;">46.89</span></td>
<td id="S5.T9.6.4.19.9" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;"><span id="S5.T9.6.4.19.9.1" class="ltx_text" style="background-color:#A7CBE2;">35.75</span></td>
</tr>
<tr id="S5.T9.6.4.20" class="ltx_tr">
<td id="S5.T9.6.4.20.1" class="ltx_td"></td>
<td id="S5.T9.6.4.20.2" class="ltx_td ltx_align_left">
<span id="S5.T9.6.4.20.2.1" class="ltx_text"></span><span id="S5.T9.6.4.20.2.2" class="ltx_text">
<span id="S5.T9.6.4.20.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.20.2.2.1.1" class="ltx_tr">
<span id="S5.T9.6.4.20.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">w/ diversity</span></span>
</span></span><span id="S5.T9.6.4.20.2.3" class="ltx_text"></span></td>
<td id="S5.T9.6.4.20.3" class="ltx_td ltx_align_right">70,000</td>
<td id="S5.T9.6.4.20.4" class="ltx_td ltx_align_center">75.59</td>
<td id="S5.T9.6.4.20.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.20.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.20.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#A7CBE2;"><span id="S5.T9.6.4.20.7.1" class="ltx_text" style="background-color:#A7CBE2;">78.92</span></td>
<td id="S5.T9.6.4.20.8" class="ltx_td ltx_align_center" style="background-color:#C6DEED;"><span id="S5.T9.6.4.20.8.1" class="ltx_text" style="background-color:#C6DEED;">44.97</span></td>
<td id="S5.T9.6.4.20.9" class="ltx_td ltx_align_center" style="background-color:#92BFDB;"><span id="S5.T9.6.4.20.9.1" class="ltx_text" style="background-color:#92BFDB;">36.40</span></td>
</tr>
<tr id="S5.T9.6.4.21" class="ltx_tr">
<td id="S5.T9.6.4.21.1" class="ltx_td"></td>
<td id="S5.T9.6.4.21.2" class="ltx_td ltx_align_left">
<span id="S5.T9.6.4.21.2.1" class="ltx_text"></span><span id="S5.T9.6.4.21.2.2" class="ltx_text">
<span id="S5.T9.6.4.21.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.21.2.2.1.1" class="ltx_tr">
<span id="S5.T9.6.4.21.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">w/ difficulty</span></span>
</span></span><span id="S5.T9.6.4.21.2.3" class="ltx_text"></span></td>
<td id="S5.T9.6.4.21.3" class="ltx_td ltx_align_right">70,000</td>
<td id="S5.T9.6.4.21.4" class="ltx_td ltx_align_center">73.48</td>
<td id="S5.T9.6.4.21.5" class="ltx_td ltx_nopad_r ltx_border_r"></td>
<td id="S5.T9.6.4.21.6" class="ltx_td ltx_nopad_l ltx_nopad_r"></td>
<td id="S5.T9.6.4.21.7" class="ltx_td ltx_nopad_l ltx_align_center" style="background-color:#92BFDB;"><span id="S5.T9.6.4.21.7.1" class="ltx_text" style="background-color:#92BFDB;">80.45</span></td>
<td id="S5.T9.6.4.21.8" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;"><span id="S5.T9.6.4.21.8.1" class="ltx_text" style="background-color:#E5F0F7;">43.15</span></td>
<td id="S5.T9.6.4.21.9" class="ltx_td ltx_align_center" style="background-color:#C6DEED;"><span id="S5.T9.6.4.21.9.1" class="ltx_text" style="background-color:#C6DEED;">34.59</span></td>
</tr>
<tr id="S5.T9.6.4.22" class="ltx_tr">
<td id="S5.T9.6.4.22.1" class="ltx_td ltx_border_bb"></td>
<td id="S5.T9.6.4.22.2" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S5.T9.6.4.22.2.1" class="ltx_text"></span><span id="S5.T9.6.4.22.2.2" class="ltx_text">
<span id="S5.T9.6.4.22.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T9.6.4.22.2.2.1.1" class="ltx_tr">
<span id="S5.T9.6.4.22.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">w/ scaling</span></span>
</span></span><span id="S5.T9.6.4.22.2.3" class="ltx_text"></span></td>
<td id="S5.T9.6.4.22.3" class="ltx_td ltx_align_right ltx_border_bb">220,000</td>
<td id="S5.T9.6.4.22.4" class="ltx_td ltx_align_center ltx_border_bb">57.78</td>
<td id="S5.T9.6.4.22.5" class="ltx_td ltx_nopad_r ltx_border_bb ltx_border_r"></td>
<td id="S5.T9.6.4.22.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_bb"></td>
<td id="S5.T9.6.4.22.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">58.12</td>
<td id="S5.T9.6.4.22.8" class="ltx_td ltx_align_center ltx_border_bb">38.07</td>
<td id="S5.T9.6.4.22.9" class="ltx_td ltx_align_center ltx_border_bb">27.28</td>
</tr>
</tbody></table>
</span></div>
</figure>
</section>
<section id="S5.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.4 </span>Empirical Analysis for Instruction Tuning</h4>

<div id="S5.SS1.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p1.1">서로 다른 명령어 세트를 갖는 미세 조정 LLM은 다운스트림 태스크에서 다양한 성능을 갖는 모델 변형으로 이어지는 경향이 있다. 본 절에서는 LLMs(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p1.1.1">i.e.,</em> LLaMA (7B) 및 LLaMA (13B)<span class="ltx_note ltx_role_footnote" id="footnote27"><sup class="ltx_note_mark">27</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">27</sup><span class="ltx_tag ltx_tag_note">27</span>Due to the limit of computational resources, we cannot conduct large-scale experiments on larger LLaMA variants right now, which would be scheduled in a future version.</span></span></span>)의 미세 조정에서 다양한 유형의 명령어의 효과를 탐색하고 몇 가지 명령어의 개선 전략의 유용성을 검토한다.</p>
</div>
<div id="S5.SS1.SSS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS4.p2.1.1">Instruction Datasets. </span> 섹션 <a class="ltx_ref" href="#S5.SS1.SSS1" title="5.1.1 Formatted Instance Construction ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1.1</span></a>의 논의에 따르면, 우리는 주로 다음과 같은 세 가지 일반적인 종류의 지침을 고려한다:</p>
</div>
<div id="S5.SS1.SSS4.p3" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p3.1">• <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p3.1.1">Task-specific instructions. 첫 번째 유형의 명령어에는 가장 일반적으로 사용되는 다중 작업 명령어 데이터 세트인 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p3.1.2">FLAN-T5</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>를 채택했으며, 이 데이터 세트에는 1,836개의 태스크와 이전 작업의 4개의 데이터 혼합물을 결합하여 15M 이상의 명령어를 포함한다.</p>
</div>
<div id="S5.SS1.SSS4.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p4.1">• <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p4.1.1">Daily chat instructions. </em> 이러한 유형의 지침은 실생활 시나리오와 더 밀접하게 관련된 일상 생활에 대해 사용자가 제기하는 대화입니다. 우리는 63K개의 실제 사용자 지침으로 구성된 ShareGPT 인스트루시톤 세트를 채택한다. 비쿠나의 핵심 지침으로 사용되었습니다.</p>
</div>
<div id="S5.SS1.SSS4.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p5.1">• <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p5.1.1">Synthetic instructions. </em> 기존 명령어를 재사용하는 것 외에도 LLM을 사용하여 대량의 명령어를 자동으로 합성할 수도 있다. 우리는 약 82K 인스턴스 입력 및 출력과 쌍을 이루는 52K 명령어로 구성된 인기 있는 합성 명령어 데이터 세트 Self-Instruct-52K <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>를 채택한다. 이러한 생성된 명령어는 인간이 작성한 시드 작업과 유사한 데이터 분포를 갖는다(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p5.1.2">e.g.,</em> 문법 검사, 브레인스토밍).</p>
</div>
<div id="S5.SS1.SSS4.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p6.1">원래 FLAN-T5 데이터 세트는 매우 크기 때문에(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p6.1.1">i.e.,</em> over 15M), 다른 명령어 데이터 세트(<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p6.1.2">i.e.,</em> ShareGPT 및 Self-Instruct-52K)와 유사한 척도로 공정한 비교를 수행하기 위해 무작위로 80,000개의 명령어를 샘플링한다. 실험에서는 각 개별 명령 집합에 대해 테스트하여 자신의 효과를 탐색하고 모델 성능에 대한 조합 효과를 조사한다.</p>
</div>
<div id="S5.SS1.SSS4.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS4.p7.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS4.p7.1.1">Improvement Strategies. </span> 인간 사용자의 실제 지침은 LLM을 미세 조정하는 데 더 적합하지만 대규모로 수집하는 것은 어렵다. 인간 생성 명령의 대안으로 기존의 대부분의 연구는 주로 LLMs에 의해 생성된 합성 명령을 채택한다. 그러나, 잘못된 주제 다양성과 고르지 못한 수업 난이도(너무 단순하거나 너무 어렵거나)와 같은 합성 수업에 대한 몇 가지 잠재적인 문제가 있다. 따라서 합성 지침의 품질을 개선할 필요가 있다. 다음으로 기존 작업에서 널리 사용되고 있는 4대 개선 전략을 정리하면 다음과 같다.</p>
</div>
<div id="S5.SS1.SSS4.p8" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p8.1">• <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p8.1.1">Enhancing the instruction complexity. </em> 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib346" title="">346</a>]</cite>에서 논의한 바와 같이, 명령의 복잡성을 강화하면 다음 복잡한 명령에서 LLM의 모델 용량을 향상시킬 수 있습니다. <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p8.1.2">e.g.,</em>은 더 많은 작업 요구 사항을 포함하거나 더 많은 추론 단계를 필요로 합니다. 이 전략의 유효성을 검사하기 위해 복잡도 수준, <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p8.1.3">e.g.,</em> 제약 조건 추가, 추론 단계 증가 및 입력 복잡도를 점진적으로 증가시켜 WizardLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib346" title="">346</a>]</cite>를 따릅니다. 공개된 WizardLM-70K 명령어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib346" title="">346</a>]</cite>를 복잡도 향상 명령어 데이터세트로 활용하였으며, 이는 Self-Instruct-52K 데이터세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib346" title="">346</a>]</cite>를 기반으로 위의 향상 방법을 통해 생성되었다.</p>
</div>
<div id="S5.SS1.SSS4.p9" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p9.1">• <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p9.1.1">Increasing the topic diversity. </em> 복잡성 외에도 명령어 데이터 세트의 주제 다양성을 향상시키면 실제 세계에서 다양한 작업에 대한 LLM의 다양한 능력을 이끌어내는 데 도움이 될 수 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib347" title="">347</a>]</cite> 그러나, 다양한 명령어를 생성하기 위한 자체 명령어 프로세스를 직접 제어하는 것은 어렵다. 우리는 YuLan-Chat <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib352" title="">352</a>]</cite>에 이어 ChatGPT를 사용하여 Self-Instruct-52K 데이터셋의 명령어를 특정 프롬프트를 통해 293개의 토픽으로 재작성한다. 마지막으로, 다양성 증가 데이터세트로 70K 명령어를 획득한다.</p>
</div>
<div id="S5.SS1.SSS4.p10" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p10.1">• <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p10.1.1">Scaling the instruction number. </em> 이상의 측면 외에도 명령어 수는 모델 성능에 영향을 미칠 수 있는 중요한 요소이기도 하다. 특히, 더 많은 명령어를 사용하면 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>에 대한 작업 지식을 확장하고 명령어 수행 능력을 향상시킬 수 있다. 이 전략을 검토하기 위해 MOSS 프로젝트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib362" title="">362</a>]</cite>에서 출시된 합성 명령어 세트에서 동일한 자체 명령어 방법 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>를 사용하여 합성되기 때문에 새로운 명령어를 샘플링한다. 이를 Self-Instruct-52K 데이터셋과 혼합하여 220K 명령어를 포함하는 더 큰 데이터셋을 구성한다.</p>
</div>
<div id="S5.SS1.SSS4.p11" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p11.1">• <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p11.1.1">Balancing the instruction difficulty. </em> 합성 지침은 너무 쉽거나 딱딱한 것을 포함하는 경향이 있기 때문에 LLM에 대한 훈련 불안정성 또는 심지어 과적합으로 이어질 가능성이 있다. 잠재적인 효과를 탐색하기 위해 LLM의 복잡도 점수를 활용하여 지침의 난이도를 추정하고 너무 쉽거나 어려운 지침을 제거한다. 공정한 비교를 위해 동일한 크기의 명령어를 생성하기 위해 LLaMA (7B) 모델을 채택하여 대용량 명령어 데이터셋으로부터 220K개의 명령어에 대한 복잡도를 계산하고, 70K개의 중간 복잡도 점수를 난이도 균형 데이터셋으로 유지한다.</p>
</div>
<div id="S5.SS1.SSS4.p12" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS4.p12.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS4.p12.1.1">Experimental Setup. </span> 명령어 데이터의 영향에 대한 실험을 수행하기 위해 명령어 튜닝에 널리 사용되는 LLM 백본인 LLaMA를 튜닝하기 위해 이러한 새로운 명령어 데이터 세트를 활용한다. 실험은 YuLan-Chat<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib352" title="">352</a>]</cite>의 코드를 사용하였으며, 8개의 A800-80G GPU의 서버에서 LLaMA 7B와 13B를 학습시킨다. 모든 하이퍼 매개 변수 설정은 스탠포드 알파카와 동일하게 유지됩니다. 미세 조정 모델의 명령어 추종 능력을 더 잘 평가하기 위해 두 가지 설정, 즉 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p12.1.2">Chat setting</em> 및 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p12.1.3">QA setting</em>을 고려한다. 채팅 설정은 주로 일일 채팅의 사용자 명령 및 쿼리를 활용하는 반면, QA 설정은 주로 기존 NLP 데이터 세트의 질문 응답 예를 사용한다. 채팅 설정에 대한 평가는 AlpacaFarm 평가 세트<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib363" title="">363</a>]</cite>에 기초하여 수행된다. 전체 쌍별 비교를 사용하는 대신 Self-Instruct-52K에서 미세 조정된 LLaMA 7B 및 13B 모델을 참조 기준선으로 선택한 다음 각각 다른 지침을 사용하여 미세 조정된 다른 LLaMA 7B 및 13B 모델과 비교한다. 우리의 초점은 지침을 생성하기 위한 다양한 전략의 유용성을 조사하는 것이기 때문에 Self-Instruct-52K에서 미세 조정된 모델은 좋은 참조가 될 수 있다. AlpacaFarm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib363" title="">363</a>]</cite>에 이어, 각 비교를 위해 ChatGPT를 사용하여 매번 두 개의 비교 모델로부터 어떤 응답이 사용자 쿼리에 가장 적합한지 자동으로 주석하고 승률(%)을 평가 메트릭으로 보고한다. QA 설정을 위해 두 개의 벤치마크인 MMLU<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib364" title="">364</a>]</cite>와 BBH<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib365" title="">365</a>]</cite>를 선택하고 휴리스틱 규칙을 사용하여 이러한 LLM의 답변을 구문 분석하여 기본 설정에 따라 정확도를 평가한다.</p>
</div>
<div id="S5.SS1.SSS4.p13" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p13.2">명령어 튜닝 및 평가 모두에 대해 다음과 같은 프롬프트를 채택합니다. "<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p13.2.2">다음은 인간과 AI 어시스턴트 간의 대화입니다. AI 어시스턴트는 사용자의 질문에 도움이 되고 상세하며 예의바른 답변을 제공합니다.<math alttext="\backslash" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p13.1.1.m1.1"><semantics id="S5.SS1.SSS4.p13.1.1.m1.1a"><mo id="S5.SS1.SSS4.p13.1.1.m1.1.1" xref="S5.SS1.SSS4.p13.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p13.1.1.m1.1b"><ci id="S5.SS1.SSS4.p13.1.1.m1.1.1.cmml" xref="S5.SS1.SSS4.p13.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p13.1.1.m1.1c">\backslash</annotation></semantics></math>n [|Human|]:<span class="ltx_text ltx_font_upright" id="S5.SS1.SSS4.p13.2.2.2">{</span>input<span class="ltx_text ltx_font_upright" id="S5.SS1.SSS4.p13.2.2.1">}<math alttext="\backslash" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p13.2.2.1.m1.1"><semantics id="S5.SS1.SSS4.p13.2.2.1.m1.1a"><mo id="S5.SS1.SSS4.p13.2.2.1.m1.1.1" xref="S5.SS1.SSS4.p13.2.2.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p13.2.2.1.m1.1b"><ci id="S5.SS1.SSS4.p13.2.2.1.m1.1.1.cmml" xref="S5.SS1.SSS4.p13.2.2.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p13.2.2.1.m1.1c">\backslash</annotation></semantics></math></span>n[|AI|]:</em>. 우리의 결과를 재현하기 위해 우리는 링크에서 코드와 데이터를 릴리스한다: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/RUCAIBox/LLMSurvey/tree/main/Experiments" target="_blank" title="">https://github.com/RUCAIBox/LLMSurvey/tree/main/Experiments</a>.</p>
</div>
<div id="S5.SS1.SSS4.p14" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.SSS4.p14.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS4.p14.1.1">Results and Analysis. </span> 7B 및 13B LLaMA를 기반으로 하는 서로 다른 명령 데이터 세트를 사용한 결과는 표 <a class="ltx_ref" href="#S5.T9" title="TABLE IX ‣ 5.1.3 The Effect of Instruction Tuning ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">IX</span></a>에 있다. 다음으로, 우리의 연구 결과를 자세히 요약하고 분석한다.</p>
</div>
<div id="S5.SS1.SSS4.p15" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p15.1">•<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p15.1.1">Task-formatted 명령어는 QA 설정에 더 적합하지만 채팅 설정에는 유용하지 않을 수 있습니다. </em> FLAN-T5를 사용한 명령어 튜닝의 성능을 ShareGPT 및 Self-Instruct-52K와 비교하여, 채팅 환경에서 ShareGPT보다 성능이 낮은 반면, FLAN-T5는 대부분 QA 벤치마크에서 더 나은 성능을 달성함을 관찰할 수 있다. 그 이유는 FLAN-T5가 기존의 NLP 태스크들, <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p15.1.2">e.g.,</em> 번역 및 읽기 이해의 명령어와 예제의 혼합물로 구성되어 있기 때문이다. 결과적으로 FLAN-T5로 미세 조정된 LLaMA는 QA 작업에서는 더 나은 성능을 보이지만 사용자 쿼리에서는 좋지 않다. 대조적으로, ShareGPT는 실제 인간-ChatGPT 대화로 구성되며, 이는 일상 생활에서 사용자 지시를 따르도록 LLaMA를 더 잘 이끌어낼 수 있지만 QA 작업을 수행하기에 적합하지 않을 수 있다.</p>
</div>
<div id="S5.SS1.SSS4.p16" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p16.1">•<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p16.1.1">A mixture of different kinds of instructions is helpful to improve the comprehensive abilities of LLMs. </em> Fine-tuning을 위한 세 종류의 명령어를 혼합한 후, 도출된 LLaMA 변형(with FLAN-T5, ShareGPT and Self-Instruct-52K)이 두 태스크 설정에서 모두 잘 수행됨을 알 수 있다. MLU에서 LLaMA (7B)의 성능은 개별 명령어 집합인 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p16.1.2">i.e.,</em> 43.69 vs. 38.58 (FLAN-T5). 이는 명령어 데이터 집합의 여러 소스를 혼합하는 것이 명령어 수를 확장하고 다양성을 증가시키는 명령어 조정 LLM의 성능을 향상시키는 데 도움이 된다는 것을 보여준다.</p>
</div>
<div id="S5.SS1.SSS4.p17" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p17.1">•<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p17.1.1">Enhancing the complexity and diversity of instructions leads to improved model performance. </em> Self-Instruct-52K 데이터셋의 복잡도와 다양성을 각각 증가시킴으로써 LLaMA의 채팅과 QA 성능을 지속적으로 향상시킬 수 있다. <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p17.1.2">e.g.,</em> in 37.52 to 39.73 in MMLU for LLaMA (7B). 두 전략 모두 LLM의 수업 추종 능력을 향상시키는 데 유용함을 보여준다. 또한, 복잡도를 개선하면 QA 작업에서 더 큰 성능 향상을 얻을 수 있음을 알 수 있다. 그 이유는 QA 과제는 대부분 LLM을 평가하기 어려운 문항으로 구성되어 있으며, 미세 조정 단계에서 복잡한 지시를 배운 LLM이 더 잘 해결할 수 있기 때문이다.</p>
</div>
<div id="S5.SS1.SSS4.p18" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p18.1">•<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p18.1.1">명령어의 수를 단순히 증가시키는 것은 그렇게 유용하지 않을 수 있으며, 난이도의 균형을 맞추는 것이 항상 도움이 되는 것은 아니다. </em> 표 <a class="ltx_ref" href="#S5.T9" title="TABLE IX ‣ 5.1.3 The Effect of Instruction Tuning ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">IX</span></a>에 나타난 바와 같이 난이도 균형과 미세 조정 명령어 수 증가는 본 실험에서 큰 도움이 되지 않는다. 특히 명령어 수를 스케일링하는 경우, LLaMA (7B)에 대한 BBH에서 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p18.1.2">e.g.,</em>이 29.81에서 26.63으로 감소하는 성능까지 손상시킨다. 이는 품질 관리 없이 단순히 합성 명령어의 수를 스케일링하는 것이 성능 향상에 효과적이지 않을 수 있음을 보여준다. 또한, 중간 난이도의 명령어에 대한 미세 조정은 채팅 설정에서도 잘 수행되지만 QA 설정에서는 약간 성능이 저하된다. 가능한 이유는 복잡성 점수가 큰 복잡하고 어려운 지침을 필터링하여 복잡한 질문에 응답하는 모델 성능을 손상시키기 때문이다.</p>
</div>
<div id="S5.SS1.SSS4.p19" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p19.1">•<em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p19.1.1">A larger model scale lead to the better instruction following performance. </em> 동일한 명령어 데이터로 미세 조정된 LLaMA(7B) 모델과 LLaMA(13B) 모델의 성능을 비교하여 LLaMA(13B) 모델이 대부분 더 나은 성능을 달성한다는 것을 알 수 있다. 이는 모델 크기를 스케일링하는 것이 명령어 추종 능력을 향상시키는데 도움이 된다는 것을 나타낸다. 또한, MMLU에서 <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS4.p19.1.2">e.g.,</em>이 38.11에서 47.49로 QA 성능이 많이 향상되었음을 알 수 있다. 더 큰 모델은 일반적으로 더 복잡한 질문에 정확하게 대답할 수 있는 지식 활용 및 추론 능력 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>, <a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>가 더 우수하기 때문일 수 있다.</p>
</div>
<div id="S5.SS1.SSS4.1.p1" class="ltx_para ltx_noindent ltx_align_center">
<svg id="S5.SS1.SSS4.1.p1.pic1" class="ltx_picture" height="345.66" overflow="visible" version="1.1" width="288"><g transform="translate(0,345.66) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00008C" fill-opacity="1.0"><path d="M 0 5.91 L 0 339.75 C 0 343.02 2.64 345.66 5.91 345.66 L 282.09 345.66 C 285.35 345.66 288 343.02 288 339.75 L 288 5.91 C 288 2.64 285.35 0 282.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 321.7 L 286.03 321.7 L 286.03 5.91 C 286.03 3.73 284.27 1.97 282.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 327.61)"><foreignObject width="244.69" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S5.SS1.SSS4.1.p1.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:176.8pt;">
<span id="S5.SS1.SSS4.1.p1.pic1.1.1.1.1.1.1" class="ltx_p">Instruction Tuning Suggestions</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="244.69" height="296.11" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S5.SS1.SSS4.1.p1.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:176.8pt;">
<span id="S5.SS1.SSS4.1.p1.pic1.2.2.2.1.1.1" class="ltx_p">To conduct instruction tuning on LLMs, one can prepare the computational resources according to the basic statistics about the required number of GPUs and tuning time in Table&nbsp;<a href="#S5.T8" title="TABLE VIII ‣ 5.1.1 Formatted Instance Construction ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a>.
After setting up the development environment, we recommend beginners to follow the code of Alpaca repository&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>]</cite> for instruction tuning. Subsequently, one should select the base model and construct the instruction datasets as we discuss in this section.
When computational resources for training are constrained, users can utilize LoRA for parameter-efficient tuning (see Section&nbsp;<a href="#S5.SS3" title="5.3 Parameter-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>). As for inference, users can further use quantization methods to deploy LLMs on fewer or smaller GPUs (see Section&nbsp;<a href="#S5.SS4" title="5.4 Memory-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.4</span></a>).</span>
</span></foreignObject></g></g></svg>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span><span id="S5.SS2.1.1" class="ltx_text ltx_font_italic">Alignment Tuning</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.p1.1">이 부분은 먼저 정렬의 배경과 그 정의 및 기준을 제시하고, LLM을 정렬하기 위한 인간 피드백 데이터 수집에 초점을 맞추고, 마지막으로 정렬 조정을 위한 인간 피드백(RLHF)으로부터의 강화 학습의 핵심 기술에 대해 논의한다.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Background and Criteria for Alignment</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p1.1.1">Background. </span> LLMs은 광범위한 NLP 작업에서 놀라운 능력을 보여주었다. 그러나 이러한 모델은 간혹 의도하지 않은 행동, 즉 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p1.1.2">e.g.,</em> 허위 정보 조작, 부정확한 목표 추구, 유해, 오도 및 편향된 표현 생성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib366" title="">366</a>]</cite>를 나타낼 수 있다. LLM의 경우 언어 모델링 목표는 인간의 가치나 선호도에 대한 고려가 부족하면서 단어 예측에 의해 모델 매개변수를 사전 훈련한다. 이러한 예상치 못한 행동을 방지하기 위해 LLM이 인간의 기대 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib367" title="">367</a>]</cite>에 따라 행동하도록 하는 인간 정렬이 제안되었다. 그러나 원래 사전 훈련 및 적응 조정 (<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p1.1.3">e.g.,</em> instruction tuning)과 달리 이러한 정렬은 매우 다른 기준을 고려 해야 합니다 (<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p1.1.4">e.g.,</em> helpfulness, honesty 및 harmlessness). 정렬은 LLM의 일반적인 능력을 어느 정도 손상시킬 수 있음을 보여주었으며, 관련 문헌에서 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p1.1.5">정렬 tax</em></cite idx=3></cite>라고 한다.</p>
</div>
<div id="S5.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p2.1.1">Alignment Criteria. <span> 최근 LLM의 행동을 규제하기 위한 다양한 기준을 개발하는 것에 대한 관심이 증가하고 있다. 여기서는 기존 문헌 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib368" title="">368</a>, <a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>에서 널리 채택된 논의의 예로 세 가지 대표적인 정렬 기준(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p2.1.2">i.e.,</em> helpful, honest, harmless)을 취한다. 또한, 행동, 의도, 인센티브, 및 내부 측면들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib366" title="">366</a>]</cite>를 포함하는 상이한 관점들로부터의 LLMs에 대한 다른 정렬 기준들이 존재하며, 이들은 본질적으로 상기 세 가지 기준들과 유사(또는 적어도 유사한 정렬 기법들을 가짐)하다. 또한 특정 요구 사항에 따라 세 가지 기준, 즉 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p2.1.3">e.g.,</em> honesty with correctness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>를 수정하는 것도 가능하다. 다음으로 대표적인 세 가지 정렬 기준에 대해 간략히 설명한다:</p>
</div>
<div id="S5.SS2.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS1.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p3.1.m1.1"><semantics id="S5.SS2.SSS1.p3.1.m1.1a"><mo id="S5.SS2.SSS1.p3.1.m1.1.1" xref="S5.SS2.SSS1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p3.1.m1.1b"><ci id="S5.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.1">Helpfulness. </em> 도움이 되려면 LLM은 사용자가 작업을 해결하거나 질문에 가능한 간결하고 효율적인 방식으로 답변하는 데 도움이 되는 명확한 시도를 보여야 한다. 더 높은 수준에서 추가 설명이 필요할 때 LLM은 관련 질문을 통해 추가 관련 정보를 이끌어내는 능력을 입증하고 적절한 수준의 민감도, 통찰력 및 신중성<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib368" title="">368</a>]</cite>를 보여야 한다. LLM은 사용자의 의도를 정확하게 정의하고 측정하기 어렵기 때문에 유용한 행동의 정렬을 실현하는 것이 어렵다.</p>
</div>
<div id="S5.SS2.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS1.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p4.1.m1.1"><semantics id="S5.SS2.SSS1.p4.1.m1.1a"><mo id="S5.SS2.SSS1.p4.1.m1.1.1" xref="S5.SS2.SSS1.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p4.1.m1.1b"><ci id="S5.SS2.SSS1.p4.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p4.1.1">Honesty. </em> 기본 수준에서 정직하게 정렬된 LLM은 정보를 조작하는 대신 사용자에게 정확한 콘텐츠를 제공해야 한다. 또한 LLM은 정보의 기만이나 잘못된 표현을 피하기 위해 산출물에 적절한 정도의 불확실성을 전달하는 것이 중요하다. 이것은 모델이 자신의 능력 및 지식 수준에 대해 알 것을 요구한다(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p4.1.2">e.g.,</em> "know unknowns") <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib368" title="">368</a>]</cite>의 논의에 따르면 정직은 유용성과 무해성에 비해 더 객관적인 기준이므로 정직 정렬은 잠재적으로 인간의 노력에 덜 의존하여 개발될 수 있다.</p>
</div>
<div id="S5.SS2.SSS1.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS1.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p5.1.m1.1"><semantics id="S5.SS2.SSS1.p5.1.m1.1a"><mo id="S5.SS2.SSS1.p5.1.m1.1.1" xref="S5.SS2.SSS1.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p5.1.m1.1b"><ci id="S5.SS2.SSS1.p5.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p5.1.1">Harmlessness. </em> 무해하기 위해서는 모델에 의해 생성된 언어가 모욕적이거나 차별적이어서는 안 된다는 것을 요구한다. 최선의 능력으로, 모델은 악의적인 목적으로 요청을 요청하는 것을 목표로 하는 은밀한 시도를 탐지할 수 있어야 한다. 이상적으로, 모델이 위험한 행동을 하도록 유도되었을 때(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p5.1.2">e.g.,</em> commit a crime), LLM은 정중하게 거절해야 한다. 그럼에도 불구하고, <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p5.1.3">what behaviors</em>은 유해한 것으로 간주되며, <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p5.1.4">to what extent</em>은 개인 또는 사회 간에 다양합니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib368" title="">368</a>]</cite>는 누가 LLM을 사용하고 있는지, 제기된 질문의 유형 및 LLM이 사용되는 컨텍스트(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p5.1.5">e.g.,</em> time)에 크게 의존한다.</p>
</div>
<div id="S5.SS2.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS1.p6.1">우리가 볼 수 있듯이, 이러한 기준은 상당히 주관적이며, 인간의 인지를 기반으로 개발된다. 따라서 LLM에 대한 최적화 목표로 직접 공식화하는 것은 어렵다. 기존 작업에서는 LLM을 정렬할 때 이러한 기준을 충족하는 방법이 많이 있다. 유망한 기술은 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p6.1.1">red teaming</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib369" title="">369</a>]</cite>이며, 이는 수동 또는 자동화된 수단을 사용하여 적대적인 방식으로 LLM을 프로브하여 유해한 출력을 생성한 다음 이러한 출력을 방지하기 위해 LLM을 업데이트하는 것을 포함한다.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Collecting Human Feedback</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS2.p1.1">사전 훈련 단계에서 LLM은 대규모 코퍼스에서 언어 모델링 목표를 사용하여 훈련된다. 그러나 인간에 의한 LLM 출력의 주관적 및 정성적 평가(이 조사에서 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p1.1.1">인간 피드백</em>이라고 함)를 고려할 수 없다. 고품질의 인간 피드백은 LLM을 인간의 선호도 및 가치와 정렬하는 데 매우 중요하다. 이 부분에서는 피드백 데이터 수집을 위해 인간 레이블러 팀을 선택하는 방법에 대해 논의한다.</p>
</div>
<div id="S5.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.p2.1.1">Human Labeler Selection. </span> 기존 작업에서 인간 피드백 데이터를 생성하는 지배적인 방법은 인간 주석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib367" title="">367</a>, <a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>이다. 이것은 적절한 인간 라벨러를 선택하는 중요한 역할을 강조한다. 고품질 피드백을 제공하기 위해 인간 라벨러는 자격 있는 수준의 교육과 우수한 영어 능력을 갖추어야 합니다. 예를 들어, Sparrow<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>는 인간 라벨러가 적어도 학부 수준의 교육 자격을 획득한 영국 기반 원어민 화자가 되어야 한다. 그럼에도 불구하고, 여러 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib367" title="">367</a>]</cite>는 연구자와 인간 라벨러의 의도 사이에 여전히 불일치가 있음을 발견했으며, 이는 낮은 품질의 인간 피드백으로 이어질 수 있고 LLM이 예상치 못한 출력을 생성하게 할 수 있다. 이 문제를 해결하기 위해 InstructGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>는 인간 라벨러와 연구자 간의 일치를 평가하여 라벨러를 필터링하는 스크리닝 프로세스를 추가로 수행한다. 구체적으로, 연구자들은 먼저 소량의 데이터에 라벨을 붙인 다음 자신과 인간 라벨러 사이의 일치를 측정한다. 일치도가 가장 높은 레이블러를 선택하여 후속 주석 작업을 진행합니다. 일부 다른 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib370" title="">370</a>]</cite>에서는 "super raters"가 인간 피드백의 높은 품질을 보장하기 위해 사용된다. 연구자들은 인간 라벨러의 성능을 평가하고 성능이 좋은 인간 라벨러 그룹(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p2.1.2">e.g.,</em> high agreement)을 슈퍼 래터로 선택한다. 초평가자들은 후속 연구에서 연구자들과 협력하는 것이 우선시될 것이다. 인간 라벨러가 LLM의 출력에 주석을 달 때, 상세한 지침을 지정하고 인간 라벨러에 대한 즉각적인 안내를 제공하는 것이 도움이 되며, 이는 라벨러의 주석을 추가로 규제할 수 있다.</p>
</div>
<div id="S5.SS2.SSS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.p3.1.1">Human Feedback Collection. </span> 기존 작업에서 인간 레이블러로부터 피드백 및 선호도 데이터를 수집하는 접근 방식은 크게 세 가지가 있다.</p>
</div>
<div id="S5.SS2.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p4.1.m1.1"><semantics id="S5.SS2.SSS2.p4.1.m1.1a"><mo id="S5.SS2.SSS2.p4.1.m1.1.1" xref="S5.SS2.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p4.1.m1.1b"><ci id="S5.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p4.1.1">Ranking-based approach. </em> 초기 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib367" title="">367</a>]</cite>에서 인간 라벨러는 종종 더 세밀한 정렬 기준을 고려하지 않고 거친 입도의 방식으로 모델 생성 출력을 평가합니다 (<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p4.1.2">i.e.,</em> only selecting the best). 그럼에도 불구하고, 다른 라벨러는 최상의 후보 출력 선택에 대해 다양한 의견을 가질 수 있으며, 이 방법은 선택되지 않은 샘플을 무시하여 부정확하거나 불완전한 인간 피드백으로 이어질 수 있다. 이 문제를 해결하기 위해 후속 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>에서는 Elo 등급제를 도입하여 후보 산출물을 비교하여 선호도 순위를 도출한다. 출력의 순위는 모델이 다른 출력보다 특정 출력을 선호하도록 안내하는 훈련 신호 역할을 하며, 따라서 더 신뢰할 수 있고 안전한 출력을 유도한다.</p>
</div>
<div id="S5.SS2.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS2.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p5.1.m1.1"><semantics id="S5.SS2.SSS2.p5.1.m1.1a"><mo id="S5.SS2.SSS2.p5.1.m1.1.1" xref="S5.SS2.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p5.1.m1.1b"><ci id="S5.SS2.SSS2.p5.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p5.1.1">Question-based approach. 또한, 인간 라벨러는 LLM에 대한 추가 제약 조건뿐만 아니라 정렬 기준을 포괄하는 연구자들이 디자인한 특정 질문에 대한 답변 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>를 통해 보다 자세한 피드백을 제공할 수 있다. 특히 WebGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>에서는 검색된 문서에서 관련 정보를 필터링하고 활용하는 데 모델을 지원하기 위해 인간 레이블러는 검색된 문서가 주어진 입력에 응답하는 데 유용한지 여부에 대한 여러 옵션으로 질문에 응답해야 한다.</p>
</div>
<div id="S5.SS2.SSS2.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p6.1.m1.1"><semantics id="S5.SS2.SSS2.p6.1.m1.1a"><mo id="S5.SS2.SSS2.p6.1.m1.1.1" xref="S5.SS2.SSS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p6.1.m1.1b"><ci id="S5.SS2.SSS2.p6.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p6.1.1">Rule-based approach. </em> 많은 연구에서 더 자세한 인간 피드백을 제공하기 위해 규칙 기반 방법을 개발하기도 한다. 대표적인 사례로 Sparrow<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>는 레이블러가 가장 잘 생각하는 응답을 선택할 뿐만 아니라 일련의 규칙을 사용하여 모델 생성 응답이 유용하고 정확하며 무해하다는 정렬 기준을 충족하는지 테스트한다. 이러한 방식으로, 두 종류의 인간 피드백 데이터가 획득될 수 있다 : (1) 응답 선호도 피드백은 모델 생성 출력의 품질을 쌍으로 비교함으로써 획득되고, (2) 규칙 위반 피드백은 인간 라벨러로부터 평가를 수집함으로써 획득된다(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS2.p6.1.2">i.e.,</em> 생성된 출력이 규칙을 어느 정도 위반했는지 나타내는 점수. 또한, GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>는 규칙 기반 보상 모델로서 제로 샷 분류기 세트(GPT-4 자체에 기반함)를 활용하며, 이는 모델 생성 출력이 인간 작성 규칙 세트를 위반하는지 여부를 자동으로 결정할 수 있다.</p>
</div>
<div id="S5.SS2.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS2.p7.1">이하에서는 ChatGPT와 같은 최근 강력한 LLMs에서 널리 사용되고 있는 인간 피드백(RLHF)으로부터의 강화 학습(reinforcement learning) 기술에 초점을 맞춘다. 아래에서 논의되는 바와 같이, 섹션 <a class="ltx_ref" href="#S5.SS2.SSS1" title="5.2.1 Background and Criteria for Alignment ‣ 5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.2.1</span></a>에서 소개된 정렬 기준은 사용자 질의에 대한 LLM의 응답에 대한 인간 피드백으로부터 학습함으로써 충족될 수 있다.</p>
</div>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3 </span>Reinforcement Learning from Human Feedback</h4>

<figure id="S5.F12" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x12.png" id="S5.F12.g1" class="ltx_graphics ltx_centering ltx_img_square" width="230" height="208" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 12:</span>RLHF 알고리즘의 워크플로우.</figcaption>
</figure>
<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS3.p1.1">LLM을 인간 값과 정렬하기 위해, 수집된 인간 피드백 데이터로 LLM을 미세 조정하기 위해 인간 피드백으로부터의 강화 학습(RLHF) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>, <a class="ltx_ref" href="#bib.bib367" title="">367</a>]</cite>가 제안되었으며, 이는 정렬 기준을 개선하는데 유용하다(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p1.1.1">e.g.,</em> helpfulness, honesty 및 harmless). RLHF는 보상 모델을 학습하여 LLMs를 인간 피드백에 적응시키기 위해 강화 학습 알고리즘(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p1.1.2">e.g.,</em> Proximal Policy Optimization (PPO) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib128" title="">128</a>]</cite>)을 사용한다. 이러한 접근법은 InstructGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>에 의해 예시된 바와 같이, 잘 정렬된 LLMs를 개발하기 위한 트레이닝 루프에 인간을 통합한다.</p>
</div>
<figure id="S5.F13" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x13.png" id="S5.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="91" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 13:</span> 네 가지 다른 매개 변수 효율적인 미세 조정 방법의 예입니다. MHA와 FFN은 각각 트랜스포머 계층에서 멀티헤드 어텐션 네트워크와 피드포워드 네트워크를 나타낸다.</figcaption>
</figure>
<div id="S5.SS2.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS3.p2.1.1">RLHF System. </span> RLHF 시스템은 주로 정렬될 사전 훈련된 LM, 인간 피드백으로부터의 보상 모델 학습 및 LM을 훈련시키는 RL 알고리즘의 세 가지 주요 구성 요소로 구성된다. 구체적으로, <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS3.p2.1.2">pre-trained LM</span>은 일반적으로 기존의 pre-trained LM 파라미터로 초기화되는 생성 모델이다. 예를 들어 OpenAI는 첫 번째 인기 있는 RLHF 모델인 InstructGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>에 175B GPT-3를 사용하고, DeepMind는 GopherCite 모델인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>에 2,800억 파라미터 모델인 Gopher<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib370" title="">370</a>]</cite>를 사용한다. 또한, <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS3.p2.1.3">reward model (RM)</span>은 LM에 의해 생성된 텍스트에 대한 인간의 선호도를 반영하는 (학습된) 안내 신호를 일반적으로 스칼라 값의 형태로 제공한다. 보상 모델은 미세 조정된 LM 또는 인간 선호도 데이터를 사용하여 LM 트레이닝된 새로운 두 가지 형태를 취할 수 있다. 기존의 작업은 통상적으로 정렬된 LM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib370" title="">370</a>, <a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>와 다른 파라미터 스케일을 갖는 보상 모델들을 채용한다. 예를 들어 OpenAI는 6B GPT-3를, DeepMind는 7B Gopher를 각각 보상 모델로 사용한다. 마지막으로 보상 모델의 신호를 사용하여 사전 훈련된 LM을 최적화하기 위해 특정 <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS3.p2.1.4">RL 알고리즘</span>이 대규모 모델 튜닝을 위해 설계되었다. 구체적으로, PPO(Proximal Policy Optimization) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib128" title="">128</a>]</cite>는 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib370" title="">370</a>, <a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>에서 정렬을 위해 널리 사용되는 RL 알고리즘이다.</p>
</div>
<div id="S5.SS2.SSS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS3.p3.1.1">RLHF용 Key Steps. </span> Figure <a class="ltx_ref" href="#S5.F12" title="Figure 12 ‣ 5.2.3 Reinforcement Learning from Human Feedback ‣ 5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">12</span></a>는 이하에서 소개한 RLHF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>의 전체 3단계 과정을 나타낸 것이다.</p>
</div>
<div id="S5.SS2.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS3.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p4.1.m1.1"><semantics id="S5.SS2.SSS3.p4.1.m1.1a"><mo id="S5.SS2.SSS3.p4.1.m1.1.1" xref="S5.SS2.SSS3.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p4.1.m1.1b"><ci id="S5.SS2.SSS3.p4.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p4.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS3.p4.1.1">Supervised fine-tuning. </span> LM이 처음에 원하는 동작을 수행하도록 하려면 일반적으로 LM을 미세 조정하기 위해 입력 프롬프트(명령어) 및 원하는 출력을 포함하는 감독된 데이터 세트를 수집해야 한다. 이러한 프롬프트 및 출력은 작업의 다양성을 보장하면서 일부 특정 작업에 대해 인간 라벨러에 의해 작성될 수 있다. 예를 들어, InstructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>는 인간 레이블러에게 프롬프트를 작성하도록 요청합니다(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p4.1.2">e.g.,</em> "<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p4.1.3">List five ideas for how to regain enthusiasm for my career</em>) 및 open QA, brainstorming, chatting, rewriting과 같은 여러 생성 작업에 대한 원하는 출력. 첫 번째 단계는 특정 설정 또는 시나리오에서 선택 사항입니다.</p>
</div>
<div id="S5.SS2.SSS3.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS3.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p5.1.m1.1"><semantics id="S5.SS2.SSS3.p5.1.m1.1a"><mo id="S5.SS2.SSS3.p5.1.m1.1.1" xref="S5.SS2.SSS3.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p5.1.m1.1b"><ci id="S5.SS2.SSS3.p5.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p5.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS3.p5.1.1">Reward model training. </span> 두 번째 단계는 인간 피드백 데이터를 사용하여 RM을 훈련하는 것이다. 특히 LM을 사용하여 샘플링된 프롬프트(감독 데이터 세트 또는 인간 생성 프롬프트 중 하나)를 입력으로 사용하여 특정 수의 출력 텍스트를 생성한다. 그런 다음 인간 라벨러를 초대하여 이러한 쌍에 대한 기본 설정에 주석을 달습니다. 어노테이션 과정은 여러 형태로 진행될 수 있으며, 공통적인 접근 방식은 생성된 후보 텍스트들의 순위를 매겨 주석하는 것으로 주석자 간의 불일치를 줄일 수 있다. 그런 다음, RM은 인간이 선호하는 출력을 예측하도록 훈련된다. InstructGPT에서 레이블러는 모델 생성 출력을 베스트에서 워스트로 순위를 매기고 RM(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p5.1.2">i.e.,</em>6B GPT-3)은 순위를 예측하도록 훈련된다. 최근 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib371" title="">371</a>]</cite>에서 응답 쌍에 대한 선호도 주석은 인간 대신 AI 에이전트(일반적으로 정렬된 LLM)에 의해 수행되었으며, 이를 "<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p5.1.3">AI 피드백으로부터의 강화 학습(RLAIF)</em>"이라고 한다. 전형적인 RLHF 알고리즘으로 훈련된 LLLM은 덜 도움이 되는 무해한 응답을 생성하는 경향이 있으며, 이를 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p5.1.4">evasion problem</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib371" title="">371</a>]</cite>라고 한다. RLAIF는 무해성과 유용성을 모두 보장하기 위해 명령어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib371" title="">371</a>, <a class="ltx_ref" href="#bib.bib372" title="">372</a>]</cite>에서 미리 설정된 정렬 원칙에 따라 AI 피드백을 생성하므로 인간 주석의 노력을 줄일 수 있다.</p>
</div>
<div id="S5.SS2.SSS3.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS3.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p6.1.m1.1"><semantics id="S5.SS2.SSS3.p6.1.m1.1a"><mo id="S5.SS2.SSS3.p6.1.m1.1.1" xref="S5.SS2.SSS3.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p6.1.m1.1b"><ci id="S5.SS2.SSS3.p6.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p6.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS3.p6.1.1">RL fine-tuning. </span> 이 단계에서 LM을 정렬(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p6.1.2">i.e.,</em> fine-tuning)하면 RL 문제로 형식화된다. 이 설정에서, 미리 훈련된 LM은 프롬프트를 입력으로서 취하고 출력 텍스트를 반환하는 정책으로서 동작하고, 그것의 동작 공간은 어휘이고, 상태는 현재 생성된 토큰 시퀀스이고, 보상은 RM에 의해 제공된다. 초기(튜닝 전) LM에서 크게 벗어나는 것을 방지하기 위해, 벌칙 항은 일반적으로 보상 함수에 통합된다. 예를 들어, InstructGPT는 PPO 알고리즘을 사용하여 RM에 대해 LM을 최적화한다. 각 입력 프롬프트에 대해, InstructGPT는 현재 LM으로부터 생성된 결과들과 초기 LM 사이의 KL 발산을 패널티로서 계산한다. 두 번째 및 마지막 단계는 LLM을 더 잘 정렬하기 위해 여러 턴으로 반복될 수 있다는 점에 유의한다. RL 알고리즘의 불안정성으로 인해 최근 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib373" title="">373</a>]</cite>는 더 높은 보상을 가진 가장 순위가 높은 샘플을 재사용하여 RL 튜닝을 다른 감독된 미세 조정으로 대체한다.</p>
</div>
<div id="S5.SS2.SSS3.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS3.p7.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS3.p7.1.1">Practical Strategies for RLHF. </span> RLHF는 인간과의 LLM의 정렬을 효과적으로 개선하는 것이 유망하지만, 연구자들이 성공적으로 구현하는 것은 현실적으로 어렵다. 이 부분에서는 RLHF의 효과와 효율성을 개선하기 위한 몇 가지 유용한 전략과 요령을 논의하는 데 중점을 둔다. 구체적으로 보상 모델의 효과적인 훈련과 효율적인 RL 훈련에 중점을 둔다.</p>
</div>
<div id="S5.SS2.SSS3.p8" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS3.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p8.1.m1.1"><semantics id="S5.SS2.SSS3.p8.1.m1.1a"><mo id="S5.SS2.SSS3.p8.1.m1.1.1" xref="S5.SS2.SSS3.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p8.1.m1.1b"><ci id="S5.SS2.SSS3.p8.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p8.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS3.p8.1.1">Effective reward model training. </span> InstructGPT가 작은 보상 모델(6B GPT 모델)을 사용했음에도 불구하고, 작업 증가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>는 큰 보상 모델(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p8.1.2">e.g.,</em> 원래 모델 크기보다 같거나 큰)을 사용하는 것이 더 효과적인 것으로 나타났는데, 이는 큰 보상 모델이 일반적으로 LLM 생성 출력의 품질을 더 잘 판단하기 때문이다. LLaMa 2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>에서 사전 훈련된 채팅 모델 체크포인트는 보상 모델을 초기화하기 위해 사용되며, 이러한 접근법은 동일한 사전 훈련 지식을 공유함으로써 정렬될 모델과 보상 모델 사이의 정보 불일치를 효과적으로 감소시킬 수 있다고 주장한다. 반면, 대규모 보상 모델을 훈련할 때 과적합 문제에 직면하는 것이 일반적이다. 단순하면서도 효과적인 해결책으로 기존의 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib374" title="">374</a>, <a class="ltx_ref" href="#bib.bib375" title="">375</a>]</cite>는 인간 주석이 달린 정렬 데이터세트로부터 입력 프롬프트의 선호 응답에 대한 LM 손실을 정규화기로 도입하여 이진 분류 작업에서 보상 모델의 과적합을 완화시켰다. 또한, 정렬에 대한 여러 기준(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p8.1.3">e.g.,</em> helpfulness and honesty)이 존재하기 때문에, 정렬 기준을 모두 만족시킬 수 있는 단일 보상 모델을 트레이닝하는 것은 종종 어렵다. 따라서 서로 다른 정렬 기준에 초점을 맞춘 여러 보상 모델을 훈련하고 특별한 조합 전략을 통해 생성된 보상 모델을 기반으로 최종 보상을 계산하는 것이 유용하다(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p8.1.4">e.g.,</em> mean pooling and weighted sum). 이러한 방법은 여러 기준, <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p8.1.5">e.g.,</em> 유용성에 대한 요구 사항을 완화하면서 유해성에 대한 더 엄격한 제한을 설정할 수 있습니다.</p>
</div>
<div id="S5.SS2.SSS3.p9" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS3.p9.3"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p9.1.m1.1"><semantics id="S5.SS2.SSS3.p9.1.m1.1a"><mo id="S5.SS2.SSS3.p9.1.m1.1.1" xref="S5.SS2.SSS3.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p9.1.m1.1b"><ci id="S5.SS2.SSS3.p9.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p9.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS3.p9.3.2">Effective RL training. </span> RL 훈련 과정이 불안정하고 하이퍼-파라미터에 민감한 경향이 있기 때문에, 언어 모델은 좋은 모델 용량에 도달하기 위해 RL 훈련 전에 잘 감독되고 미세 조정되어야 한다고 제안된다. 일반적으로 사용되는 방법은 정렬 데이터 세트에서 RL 이전 수렴까지 프롬프트의 최상의 출력(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p9.3.3">rejection sampling</em> 또는 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p9.2.1">best-of-<math alttext="N" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p9.2.1.m1.1"><semantics id="S5.SS2.SSS3.p9.2.1.m1.1a"><mi id="S5.SS2.SSS3.p9.2.1.m1.1.1" xref="S5.SS2.SSS3.p9.2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p9.2.1.m1.1b"><ci id="S5.SS2.SSS3.p9.2.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p9.2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p9.2.1.m1.1c">N</annotation></semantics></math></em>)에서 LLM을 미세 조정하는 것입니다. 프롬프트가 주어지면, LLM은 샘플링 알고리즘을 통해 먼저 <math alttext="N" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p9.3.m2.1"><semantics id="S5.SS2.SSS3.p9.3.m2.1a"><mi id="S5.SS2.SSS3.p9.3.m2.1.1" xref="S5.SS2.SSS3.p9.3.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p9.3.m2.1b"><ci id="S5.SS2.SSS3.p9.3.m2.1.1.cmml" xref="S5.SS2.SSS3.p9.3.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p9.3.m2.1c">N</annotation></semantics></math> 출력을 생성하고, 그 다음 모델로부터의 최상의 후보는 학습을 위한 보상 모델에 의해 선택될 것이다. 수렴될 때까지 최상의 샘플에서 LLM을 미세 조정한 후, 성능을 더욱 향상시키기 위해 RL 프로세스가 수행될 것이다. LLaMA 2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>는 5가지 버전의 RLHF 모델을 연속적으로 훈련시켰으며, LLM은 보상 모델의 개선과 함께 점진적으로 개선되었다. 이러한 방식으로, 수집된 인간 선호도 데이터의 프롬프트 및 주석은 현재 모델 체크포인트의 문제를 더 잘 반영할 수 있고, 따라서 이러한 문제를 해결하기 위해 특별한 튜닝을 할 수 있다. 또한 LLaMA 2는 반복 최적화 동안 가능한 용량 회귀 문제를 완화하기 위해 이전 반복의 샘플을 후속 샘플에 추가한다.</p>
</div>
<div id="S5.SS2.SSS3.p10" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS3.p10.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS3.p10.1.m1.1"><semantics id="S5.SS2.SSS3.p10.1.m1.1a"><mo id="S5.SS2.SSS3.p10.1.m1.1.1" xref="S5.SS2.SSS3.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p10.1.m1.1b"><ci id="S5.SS2.SSS3.p10.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p10.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS3.p10.1.1">Efficient RL training. </span> RL 트레이닝은 LLM 및 보상 모델 모두의 추론 프로세스를 반복해야 하기 때문에, 특히 더 큰 보상 모델 및 LLM에 대해 총 메모리 및 계산 비용을 크게 증가시킬 것이다. 실제 속임수로 우리는 별도의 서버에 보상 모델을 배포하고 해당 API를 호출하여 자체 서버에서 LLM과 작동할 수 있다. 또한, RLHF는 다수의 후보 출력을 생성하기 위해 LLM을 요구하므로, 샘플 디코딩 절차를 여러 번 호출하는 대신, 빔 서치 디코딩 알고리즘<span class="ltx_note ltx_role_footnote" id="footnote28"><sup class="ltx_note_mark">28</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">28</sup><span class="ltx_tag ltx_tag_note">28</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/docs/transformers/v4.31.0/en/main_classes/text_generation#transformers.GenerationMixin.group_beam_search" target="_blank" title="">https://huggingface.co/docs/transformers/v4.31.0/en/main_classes/text_generation#transformers.GenerationMixin.group_beam_search</a></span></span></span>을 활용하는 것이 더 효율적이다. 응답 생성을 위해 원패스 디코딩만 수행하면 되는 반면, 그러한 전략은 또한 생성된 후보 응답들의 다양성을 향상시킬 수 있다.</p>
</div>
<div id="S5.SS2.SSS3.p11" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS3.p11.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS3.p11.1.1">Process-Supervised RLHF. </span>  RLHF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib376" title="">376</a>]</cite>의 기존 문헌에서 RL 훈련을 위한 감독 신호는 일반적으로 결과-감독 신호와 프로세스-감독 신호의 두 가지 별개의 범주로 분류될 수 있다. 결과 감독 RLHF는 LLM에 의해 생성된 전체 텍스트의 품질을 평가하기 위해 정량적 점수를 사용한다. 대조적으로, 프로세스-감독된 RLHF는 생성된 콘텐츠 내에서 각각의 개별 컴포넌트(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p11.1.2">e.g.,</em> 문장, 단어 또는 추론 단계)에 대한 평가를 제공하며, 이는 트레이닝을 안내하기 위해 세밀한 감독 신호를 제공하여 LLMs가 원하지 않는 생성 콘텐츠 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib376" title="">376</a>, <a class="ltx_ref" href="#bib.bib377" title="">377</a>]</cite>를 정제하는 것을 도울 수 있다. OpenAI는 12K 프로세스 주석이 달린 수학적 문제(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p11.1.3">i.e.,</em> MATH dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib378" title="">378</a>]</cite>)로 구성된 PRM800k <cite>라는 세분화된 주석 데이터 세트를 제안했으며, 여기서 수학적 문제의 각 추론 단계는 PRM800k에서 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p11.1.4">positive</em>, <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p11.1.5">negative</em> 또는 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS3.p11.1.6">neutral</em>로 표시된다. 이 세립화된 데이터셋은 기존의 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib379" title="">379</a>, <a class="ltx_ref" href="#bib.bib377" title="">377</a>]</cite>에서 프로세스 감독 보상 모델(PRM)을 학습하기 위해 활용되었으며, RLHF 절차 중 각 레이블의 예측으로 인한 확률을 감독 신호로 간주할 수 있다. PRM의 프로세스-감독 신호를 효과적으로 활용하기 위해 기존의 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib376" title="">376</a>]</cite>는 전문가 정책으로부터 학습을 통해 기본 정책을 개선하는 효과적인 RL 알고리즘인 전문가 반복 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib380" title="">380</a>, <a class="ltx_ref" href="#bib.bib381" title="">381</a>]</cite>를 활용했다. 일반적으로 전문가 반복은 정책 개선과 증류<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib376" title="">376</a>]</cite>의 두 가지 주요 단계를 포함한다. 정책 개선 단계에서는 전문가 정책에서 체계적인 검색 절차를 처리하여 표본을 생성한다. PRM은 검색 절차에서 전문가 정책을 안내하고 샘플의 품질을 향상시키기 위해 프로세스 감독 신호를 제공한다. 이후 증류 단계에서는 1단계의 전문가 정책에 의해 생성된 샘플을 활용하여 감독 미세 조정을 통해 기본 정책을 개선한다. PRM은 전문가 반복 외에도 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib377" title="">377</a>]</cite>에 의해 생성된 최종 답변의 후보를 재순위화하거나 단계별 추론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib379" title="">379</a>, <a class="ltx_ref" href="#bib.bib382" title="">382</a>]</cite> 동안 더 나은 중간 추론 단계를 선택하기 위해 활용될 수도 있다.</p>
</div>
</section>
<section id="S5.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.4 </span>Alignment without RLHF</h4>

<div id="S5.SS2.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS4.p1.1">RLHF는 LLM의 행동을 인간의 가치 및 선호도와 정렬하는 데 큰 성공을 거두었지만 주목할 만한 한계도 가지고 있다. 첫째, RLHF는 정렬되는 모델, 보상 모델 및 참조 모델을 동시에 포함하는 다수의 LMs를 훈련시킬 필요가 있으며, 이는 알고리즘 절차에서 지루하고 실제로 메모리를 소모한다. 게다가, RLHF에서 일반적으로 사용되는 PPO 알고리즘은 다소 복잡하고 종종 하이퍼-파라미터에 민감하다. 대안으로서, 증가하는 연구는 강화 학습 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib349" title="">349</a>]</cite> 없이 감독 미세 조정을 사용하여 인간 선호도에 따르도록 LLM을 직접 최적화하기 위해 탐구한다.</p>
</div>
<div id="S5.SS2.SSS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS4.p2.1.1">Overview. </span> 비-RL 정렬 접근법의 기본 아이디어는 고품질 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS4.p2.1.2">지도 학습</em>을 사용하여 LLM을 직접 미세 조정하는 것입니다. 기본적으로 안전하지 않은 행동을 방지하기 위한 응답 피드백 또는 황금 규칙이 특수하게 선별된 정렬 데이터 세트에 주입되거나 포함되어 LLM이 적절한 미세 조정 전략을 통해 이러한 시연 데이터에서 정렬된 행동을 직접 학습할 수 있다고 가정한다. 따라서 이 방법을 구현하기 위해 두 가지 주요 문제는 정렬 데이터 세트의 구성과 미세 조정 손실 설계이다. 첫 번째 이슈에 대해, 정렬 데이터세트는 인간이 작성한 안전 원칙들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib347" title="">347</a>]</cite>에 따라 정렬된 LLMs에 의해 자동으로 구성되거나 편집 작업들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib383" title="">383</a>]</cite>를 사용하여 기존 예들을 정제할 수 있다. 또한 기존 리워드 모델을 재사용하여 기존 휴먼 피드백 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib373" title="">373</a>]</cite>에서 높은 평가를 받은 응답을 선택할 수도 있다. 두 번째 문제에 대해, 비-RL 정렬 접근법은 주로 고품질 정렬 데이터 세트에서 지도 학습 방식으로 LLM을 미세 조정(원래 명령어 튜닝 손실과 동일)하는 반면, 보조 학습 목표는 정렬 성능을 향상시키기 위해 사용될 수 있으며, <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS4.p2.1.4">예를 들어,</em> 순위 응답 또는 대조 명령-응답 쌍이다.</p>
</div>
<div id="S5.SS2.SSS4.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS4.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS4.p3.1.1">Alignment Data Collection. </span> 선형 데이터의 구성은 LLM의 행동을 인간의 선호도와 효과적으로 정렬하는 데 중요하다. 고품질 정렬 데이터를 수집하기 위해 일부 작업은 기존 보상 모델을 재사용하여 등급이 높은 응답을 선택하고 다른 작업은 강력한 LLM(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS4.p3.1.2">예:</em> ChatGPT)을 활용하거나 시뮬레이션 환경을 구축하여 합성 정렬 예제를 생성합니다. 다음으로, 우리는 이 세 가지 연구 라인에 대해 논의할 것이다.</p>
</div>
<div id="S5.SS2.SSS4.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS4.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS4.p4.1.m1.1"><semantics id="S5.SS2.SSS4.p4.1.m1.1a"><mo id="S5.SS2.SSS4.p4.1.m1.1.1" xref="S5.SS2.SSS4.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p4.1.m1.1b"><ci id="S5.SS2.SSS4.p4.1.m1.1.1.cmml" xref="S5.SS2.SSS4.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p4.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS4.p4.1.1">Reward model based approaches. </span> RLHF에서의 보상 모델은 LLMs들의 응답들에 대한 정렬 정도를 측정하기 위해 훈련되었다. 기존 보상 모델을 활용하여 고품질 반응을 후속 미세 조정을 위한 정렬 데이터로 선택하는 것은 간단합니다. 이 아이디어를 바탕으로 RAFT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib373" title="">373</a>]</cite>는 인간 선호도 데이터에 대해 학습된 보상 모델을 채택하여 LLM의 응답을 순위화하고 감독 미세 조정에 대해 더 높은 보상을 갖는 모델을 수집한다. 또한, 보상 모델은 모델 응답들을 스코어링하고 상이한 품질 그룹들에 할당하기 위해 또한 사용될 수 있다. Quark <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib384" title="">384</a>]</cite>는 보상 점수에 따라 LLM의 응답을 다른 분위수로 정렬한다. 각 분위에는 분위의 보상 수준을 나타내기 위해 특별한 보상 토큰이 부착되어 있다. 최고 리워드 토큰에 대해 조건화된 LLM은 후속적으로 고품질 응답을 생성하도록 프롬프트된다. 초기 답변과 그에 대응하는 인간 피드백이 주어지면, ILF<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib385" title="">385</a>]</cite>는 먼저 LLMs를 채택하여 정제된 답변을 생성한 다음, 보상 모델을 활용하여 추가 훈련을 위해 피드백과 가장 일치하는 답변을 선택한다. LLM을 정렬하기 위한 귀중한 자원으로서, OpenAssistant<span class="ltx_note ltx_role_footnote" id="footnote29"><sup class="ltx_note_mark">29</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">29</sup><span class="ltx_tag ltx_tag_note">29</span>https://huggingface.co/OpenAssistant</span></span></span>의 DeBERTa-base/large/xxlarge>, Fudan<span class="ltx_note ltx_role_footnote" id="footnote30"><sup class="ltx_note_mark">30</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">30</sup><span class="ltx_tag ltx_tag_note">30</span>https://github.com/OpenLMLab/MOSS-RLHF</span></span></span>의 Moss-7B, Stanford<span class="ltx_note ltx_role_footnote" id="footnote31"><sup class="ltx_note_mark">31</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">31</sup><span class="ltx_tag ltx_tag_note">31</span>https://huggingface.co/stanfordnlp/SteamSHP-flan-t5-xl</span></span></span>의 Flan-T5-xl 등 여러 보상 모델이 출시되었다.</p>
</div>
<div id="S5.SS2.SSS4.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS4.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS4.p5.1.m1.1"><semantics id="S5.SS2.SSS4.p5.1.m1.1a"><mo id="S5.SS2.SSS4.p5.1.m1.1.1" xref="S5.SS2.SSS4.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p5.1.m1.1b"><ci id="S5.SS2.SSS4.p5.1.m1.1.1.cmml" xref="S5.SS2.SSS4.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p5.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS4.p5.1.1">LLM 기반 생성 접근법. </span> 보상 모델은 모델 응답에서 정렬된 데이터를 선택하는 데 도움이 됩니다. 그러나 훈련 보상 모델 자체는 일반적으로 비싸고 공급이 부족한 상당한 고품질 인간 라벨 데이터를 필요로 한다. 또한 기존 보상 모델은 재사용할 수 있지만 별도로 훈련된 다른 LLM에서 정렬되지 않은 행동을 정확하게 포착할 수 없을 수 있다. 따라서 일부 작업에서는 강력한 LLM을 활용하여 인간 정렬 데이터를 자동으로 생성합니다. 대표적인 작업으로, 헌법 AI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib371" title="">371</a>]</cite>는 AI 행동을 지배하는 일련의 원리(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS4.p5.1.2">i.e.,</em> 자연어 명령어)에서 인간 감독이 나온다고 제안한다. 이러한 원칙에 따라 LLMs은 자신의 해로운 반응을 비판하고 최종적으로 정렬된 반응으로 반복적으로 수정한다. 마찬가지로, Self-Align <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib347" title="">347</a>]</cite>는 먼저 Self-instruct <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>를 채택하여 다양한 주제를 다루는 데 초점을 맞춘 명령어를 생성한다. 그런 다음 모델은 또한 정렬 데이터로서 유용하고 윤리적이며 신뢰할 수 있는 응답을 생성하기 위해 예상되는 모델 행동의 규칙을 설명하는 여러 인간 작성 원칙으로 프롬프트된다. 원래의 SFT 방법이 긍정적인 반응으로부터만 배울 수 있는 한계를 완화하기 위해, FIGA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib386" title="">386</a>]</cite>는 개선된 감독 정렬 접근법을 개발하는데, 여기서 부정적인 반응(낮은 품질의 원래 출력)과 긍정적인 반응(LLM에 의한 정제된 출력)은 모두 대조적인 방식으로 레버리지되어 LLM이 실제로 어떤 세밀한 수정이 좋은 반응으로 이어지는지를 깊이 이해할 수 있게 한다.</p>
</div>
<div id="S5.SS2.SSS4.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS4.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS4.p6.1.m1.1"><semantics id="S5.SS2.SSS4.p6.1.m1.1a"><mo id="S5.SS2.SSS4.p6.1.m1.1.1" xref="S5.SS2.SSS4.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p6.1.m1.1b"><ci id="S5.SS2.SSS4.p6.1.m1.1.1.cmml" xref="S5.SS2.SSS4.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p6.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS4.p6.1.1">LLM 기반 대화형 접근법. </span> 대부분의 기존 접근법은 외부 피드백 신호를 통해 자신을 개선하기 위해 실제 환경에 LLM이 존재하지 않는 LLM을 단독으로 훈련한다. 비교로서 인간은 사회적 환경<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib387" title="">387</a>]</cite>에서 타인과의 상호 작용으로부터 사회적 규범과 가치를 학습한다. 이러한 학습 접근 방식을 모방하기 위해 Stable Alignment<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib179" title="">179</a>]</cite>는 다수의 LLM 에이전트로 구성된 시뮬레이션된 상호작용 환경을 구축하며, 여기서 AI 에이전트는 계속 상호 작용하고 개선에 대한 피드백을 받는다. 중앙 에이전트가 명령을 받으면 응답을 생성하여 주변 에이전트와 공유합니다. 이러한 비평가 에이전트는 응답 및 수정 제안에 대한 평점을 포함하는 피드백을 생성한다. 그런 다음 중앙 에이전트는 이러한 제안에 따라 원래 응답을 수정합니다. 이러한 정렬 접근법은 인간과의 실제 환경으로도 확장될 수 있다.</p>
</div>
<div id="S5.SS2.SSS4.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS4.p7.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS4.p7.1.1">Supervised Alignment Tuning. </span> 정렬 데이터를 얻은 후 직접 정렬을 위한 적절한 미세 조정 전략을 설계하는 것도 중요하다. 간단한 접근법은 정렬 데이터를 기반으로 하는 기존의 서열 대 서열 목표를 사용하여 LLM을 최적화하는 것이다. 기존의 최적화 목적 외에도 여러 연구에서 정렬 데이터로부터 학습을 향상시키는 보조 손실을 추가로 탐구한다.</p>
</div>
<div id="S5.SS2.SSS4.p8" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS4.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS4.p8.1.m1.1"><semantics id="S5.SS2.SSS4.p8.1.m1.1a"><mo id="S5.SS2.SSS4.p8.1.m1.1.1" xref="S5.SS2.SSS4.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p8.1.m1.1b"><ci id="S5.SS2.SSS4.p8.1.m1.1.1.cmml" xref="S5.SS2.SSS4.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p8.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS4.p8.1.1">Primary training objective. </span> 정렬 데이터는 일반적으로 입력 명령어와 출력 응답으로 구성되므로 기본 훈련 손실은 여전히 시퀀스 대 시퀀스 학습을 위한 전통적인 교차 엔트로피 손실이다. 이러한 손실을 기반으로 많은 연구에서 감독 정렬 튜닝을 향상시키기 위한 여러 개선 변형을 제안한다. 예를 들어 CoH <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib388" title="">388</a>]</cite>는 주석이 달린 좋은 응답과 나쁜 응답에 각각 "<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS4.p8.1.2">A helpful answer:</em>" 및 "<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS4.p8.1.3">An unhelpful answer:</em>"를 앞에 붙여 학습 데이터를 구성하며, 특수 마스킹이 있는 해당 응답 토큰에 대해서만 손실을 계산합니다. Quark <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib384" title="">384</a>]</cite> 모델 응답을 다양한 정렬 품질을 가진 다른 분위수로 정렬하고, 응답의 보상 수준을 나타내기 위해 각 모델 응답에 특별한 보상 토큰을 준비합니다. 또한, 최대 우도 목표를 통해 선호도 모델링을 가능하게 하기 위해 DPO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib389" title="">389</a>]</cite> 먼저 정책 모델을 사용하여 응답 보상을 재매개 변수화(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS4.p8.1.4">i.e.,</em> the language model is optimized)한 다음, 원래 보상 모델링 목표는 정책 모델에 의해서만 재구성될 수 있다. 이러한 방식으로, DPO는 명시적 보상 모델링 단계를 제거하고, 정책 모델만을 포함하는 새로운 학습 목표를 최적화하는 것은 보상을 최적화하는 것과 동등하다. 또한, FIGA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib386" title="">386</a>]</cite>는 바람직한 토큰들을 장려하고, 바람직하지 않은 토큰들에 벌점을 주고, 사소한 토큰들을 무시하는 것을 목표로 하는 세밀한 대비 손실을 설계한다.</p>
</div>
<div id="S5.SS2.SSS4.p9" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS4.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS4.p9.1.m1.1"><semantics id="S5.SS2.SSS4.p9.1.m1.1a"><mo id="S5.SS2.SSS4.p9.1.m1.1.1" xref="S5.SS2.SSS4.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS4.p9.1.m1.1b"><ci id="S5.SS2.SSS4.p9.1.m1.1.1.cmml" xref="S5.SS2.SSS4.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS4.p9.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS4.p9.1.1">Auxiliary optimization objectives. </span> 1차 교차 엔트로피 손실 외에도 여러 연구에서 정렬 데이터로부터 학습을 향상시키기 위한 보조 훈련 손실을 제안한다. 먼저, 각 명령어의 응답은 보상 모델에 의해 스코어링될 수 있기 때문에, 랭킹 손실은 이들 응답의 랭킹 순서를 보존하기 위해 모델을 트레이닝하는데 사용될 수 있다. 예를 들어 RRHF<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib390" title="">390</a>]</cite>는 모델 자체, ChatGPT 및 GPT-4에서 파생된 응답과 같은 모델 생성 응답뿐만 아니라 고품질 및 저품질 인스턴스에 걸쳐 있는 인간 작성 응답을 포함하여 여러 소스에서 응답을 샘플링합니다. 보상 모델의 점수와 일치하기 위해 모델이 더 높은 순위를 갖는 응답에 대해 더 높은 조건부 로그 확률을 갖도록 장려함으로써 순위 손실을 더욱 최적화한다. SLiC-HF<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib391" title="">391</a>]</cite>는 잠재 공간에서의 거리를 통해 모델 출력과 인간 선호도 사이의 유사성을 평가하고 인간 선호도 데이터를 기반으로 후보 시퀀스를 보정하기 위해 특정 보정 및 정규화 손실을 도입한다. 둘째, 응답과 명령어 사이의 관련성을 높이기 위해, 일부 연구에서는 대조적 학습을 도입하여 올바른 명령어-응답 쌍의 확률을 높이고 잘못된 명령어-응답 쌍을 밀어내린다. 구체적으로, 출력 응답에 대해, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib392" title="">392</a>]</cite>에서 제안된 접근법은 타겟 명령어를 다른 관련 없는 명령어와 대조한다. 그렇게 함으로써, 그것은 모델이 명령어와 응답들 사이의 올바른 상관 관계를 학습할 수 있게 할 수 있다.</p>
</div>
</section>
<section id="S5.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.5 </span>Remarks on SFT and RLHF</h4>

<div id="S5.SS2.SSS5.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS5.p1.1">섹션 <a class="ltx_ref" href="#S5.SS1" title="5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1</span></a>에서 논의된 바와 같이, 명령어 튜닝은 포맷된 데모 데이터(원하는 출력과 쌍을 이루는 명령어)로 사전 트레이닝된 언어 모델을 트레이닝하는 프로세스이다. 초기 탐색에서 명령어 데이터는 주로 NLP 작업 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>]에서 수집되었지만, 현재는 입력 및 출력 텍스트를 쌍으로 하는 보다 다양한 감독 데이터로 확장되었다 (<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p1.1.1">e.g.,</em> the utterances of open-ended dialogues). 이러한 쌍을 이루는 텍스트를 사용한 훈련은 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>의 맥락에서 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p1.1.2">supervised fine-tuning(SFT)</em>이라고도 한다. 이 부분에서는 단순성과 인기로 인해 토론용 약어 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p1.1.3">SFT</em>을 주로 사용하지만 명령어 튜닝은 사용하지 않는다.</p>
</div>
<div id="S5.SS2.SSS5.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS5.p2.1">SFT와 RLHF는 LLM에 대한 두 가지 주요 적응 조정 방법이기 때문에 LLM 간의 연결과 차이점을 이해하는 것이 중요하다. 다음으로, 우리는 이 이슈 <span class="ltx_note ltx_role_footnote" id="footnote32"><sup class="ltx_note_mark">32</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">32</sup><span class="ltx_tag ltx_tag_note">32</span>This part would be somehow subjective, mainly based on the authors’ opinions and experiences. Comments or corrections are welcome to enhance this part. </span></span></span>에 대해 몇 가지 논의를 한다.</p>
</div>
<div id="S5.SS2.SSS5.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS5.p3.1.1">Overall Comparison with RL Formulation</span>. <a class="ltx_ref" href="#S5.SS2.SSS3" title="5.2.3 Reinforcement Learning from Human Feedback ‣ 5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.2.3</span></a>(RL 훈련과 관련된 부분) 절의 논의에 이어, 텍스트 생성 문제는 RL에 기반한 의사결정 과정으로 공식화될 수 있다. 프롬프트를 입력으로 하여, LLM의 태스크는 프롬프트에 적절하게 응답하는 텍스트 완성을 생성하는 것이다. 이 작업은 단계별로 완료될 것입니다. 각 단계에서 에이전트(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p3.1.2">i.e.,</em> LLM)는 현재 상태(현재 생성된 토큰 시퀀스 및 기타 사용 가능한 컨텍스트 정보)에 조건화된 정책(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p3.1.3">i.e.,</em> token 생성)에 따라 액션(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p3.1.4">i.e.,</em> the generative probability distribution of LLM)을 수행할 것이다. 전체 응답을 바탕으로 큰 보상 점수를 얻을 수 있는 LLM에 의해 고품질의 산출 텍스트가 생산될 것으로 기대된다. 전반적으로, RLHF와 SFT는 LLMs에 대한 위의 의사 결정 프로세스를 최적화하기 위한 두 가지 다른 훈련 접근법으로 간주될 수 있다. 특히, RLHF는 먼저 보상 모델을 학습한 후, RL 트레이닝을 통해 LLM을 개선한다(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p3.1.5">e.g.,</em> PPO). 비교로 SFT는 교사 강제 접근 방식을 채택하여 시연 출력의 가능성을 직접 최적화한다. 이러한 토큰 수준의 훈련 방법은 본질적으로 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p3.1.6">behavior cloning</em>(모방 학습의 특수 알고리즘<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib393" title="">393</a>]</cite>): 전문가의 행동(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p3.1.7">i.e.,</em> the target token at each step)을 감독 레이블로 활용하고 일반적인 RL 알고리즘과 같이 보상 모델을 지정하지 않고 전문가로부터 데모를 모방하도록 직접 학습한다. 원하는 정책을 학습하기 위해 SFT는 데모 데이터를 기반으로 "로컬" 최적화 방식(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p3.1.8">i.e.,</em> token-level loss)을 채택하는 반면, RLHF는 인간 선호도를 수반하여 "글로벌" 최적화 방식(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p3.1.9">i.e.,</em> text-level loss)을 채택한다. 모방 학습 및 강화 학습에 대한 보다 이론적 분석은 관련 RL 문헌 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib393" title="">393</a>, <a class="ltx_ref" href="#bib.bib394" title="">394</a>]</cite>를 참조할 수 있다.</p>
</div>
<div id="S5.SS2.SSS5.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS5.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS5.p4.1.1">Pros and Cons of SFT</span>. SFT는 태스크 일반화 능력을 크게 향상시키고 특정 기능을 유연하게 부여할 수 있는 다양한 벤치마크에서 LLM의 성능을 향상시키는 효과적인 접근법인 것으로 나타났다 (<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p4.1.2">e.g.,</em> establishing the chatbot's identity). SFT의 유용성에 대한 더 많은 논의는 섹션 <a class="ltx_ref" href="#S5.SS1.SSS3" title="5.1.3 The Effect of Instruction Tuning ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1.3</span></a>에서 찾을 수 있다. SFT는 주로 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p4.1.3">unlocks</em> the abilities가 아닌 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p4.1.4">inject</em> new abilities into LLMs. 따라서 SFT를 통해 LLM의 비내인성 능력을 자극하려고 할 때 문제가 될 수 있다. 구체적인 시나리오로, 시연 데이터가 LLM, <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p4.1.5">e.g.,</em> 훈련 LLM이 알려지지 않은 사실에 대한 질문에 답할 때 환각 행동을 잠재적으로 옹호할 것이다. RLHF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib395" title="">395</a>]</cite>에 대한 John Schulman의 강연에서 흥미로운 점은 우수한 모델을 증류하여 덜 능력 있는 모델을 훈련시킨다는 것이다(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p4.1.6">e.g.,</em> prompting GPT-4 to generate the response as fine-tuning data) 또한, 행동 복제 방법으로 SFT는 시연 데이터를 구성하는 전문가의 행동(탐구 없이)을 모방하는 것을 목표로 한다. 그러나 데모 데이터의 쓰기 스타일, 품질 및 선호도에 대한 주석자 간의 차이가 종종 존재하며, 이는 SFT의 학습 성능에 영향을 미치는 경향이 있다. 따라서, SFT 단계 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite> 동안 LLMs의 효과적인 학습을 위해서는 양질의 학습 데이터(수량은 아님)가 주요 요인이다.</p>
</div>
<div id="S5.SS2.SSS5.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS5.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.SSS5.p5.1.1">Pros and Cons of RLHF</span>. RLHF는 심층 RL<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>]</cite>의 문헌에서 일찍이 탐색되었고, 언어 모델의 용량을 개선하기 위해 차용되었다 (<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p5.1.2">e.g.,</em> 요약</cite idx=1></cite>). 이후 InstructGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>를 개발하기 위한 기본 기술로 채택되었다. 최근 증가하는 증거 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>, <a class="ltx_ref" href="#bib.bib371" title="">371</a>]</cite>는 유해 반응을 완화하고 모델 용량을 향상시키는 RLHF의 효과를 입증했다. 특히, LLaMA 2는 RLHF가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>의 유용성과 무해성 점수를 모두 향상시킬 수 있음을 입증했으며, 이는 데이터 주석에 대한 인간-LLM 시너지 효과가 더 우수하기 때문이다. 이러한 이유를 크게 두 가지 측면에서 설명하면 다음과 같다. 첫째, 인간 주석자는 주로 RLHF에 대한 선호 주석을 제공하기 때문에 SFT에서와 같이 주석자의 불일치를 크게 완화할 수 있다. 둘째, 선호 주석은 데모 데이터를 작성하는 것보다 훨씬 쉽고, 주석자는 자신이 만드는 것보다 더 우수한 세대의 품질을 판단할 수 있어 인간 주석자가 입증할 수 있는 것 이상의 광범위한 상태 공간을 탐색할 수 있다. 또 다른 핵심 사항은 RLHF가 본질적으로 LLM이 자체 생성된 응답(좋은 응답과 나쁜 응답을 구별함)을 대조함으로써 올바른 정책을 배우도록 장려한다는 것이다. 더 이상 모델이 외부 시연 데이터를 모방하도록 강요하지 않으므로 위에서 논의한 SFT의 환각 문제를 완화할 수 있다<span class="ltx_note ltx_role_footnote" id="footnote33"><sup class="ltx_note_mark">33</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">33</sup><span class="ltx_tag ltx_tag_note">33</span>In RLHF, it seems to be also important that reward models should be aware of the knowledge or ability of a LLM to be aligned. For example, LLaMA 2 adopts pre-trained chat model checkpoints to initialize reward models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>. </span></span></span>. 실제로 RLHF는 GPT-4<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>에서 환각 행동을 줄이는 중요한 접근법임이 입증되었다. 그러나 RLHF는 고전적인 RL 알고리즘인 <em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p5.1.3">e.g.,</em> sample inefficiency and training instability. LLM에 적응될 때, RLHF는 우수한 성능을 효율적으로 달성하기 위한 초기 모델 체크포인트로서 강한 SFT 모델에 추가로 의존한다. 또한, 인간 주석자는 복잡한 반복 최적화 프로세스에 관여하며, 여기서 다수의 중요한 세부 사항(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p5.1.4">e.g.,</em> 프롬프트 선택, 보상 모델 훈련 및 PPO 훈련 일정, 하이퍼-파라미터의 설정)이 전체 모델 성능에 중요한 영향을 미친다.</p>
</div>
<div id="S5.SS2.SSS5.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS5.p6.1">전반적으로, SFT는 사전 훈련 직후 사전 훈련된 모델 체크포인트의 모델 용량을 증가시키는 데 특히 유용한 반면, RLHF는 SFT 모델의 모델 용량을 더욱 향상시킬 것으로 유망하다. 그러나 RLHF는 구현이 어렵고 잘 탐구되지 않았으며(공공 문헌에 따르면), 더 많은 개선(<em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS5.p6.1.1">e.g.,</em> 효율적이고 신뢰할 수 있는 주석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib371" title="">371</a>]</cite> 및 단순화된 최적화 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib389" title="">389</a>]</cite>)이 추가 연구를 위해 여전히 필요하다.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span><span id="S5.SS3.1.1" class="ltx_text ltx_font_italic">Parameter-Efficient Model Adaptation</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS3.p1.1">위에서 우리는 특정 목표에 따라 LLM을 적응시키기 위한 명령어 튜닝 및 정렬 튜닝의 접근법에 대해 논의했다. LLM은 많은 양의 모델 파라미터로 구성되기 때문에 전체 파라미터 튜닝을 수행하는 데 많은 비용이 든다. 이 절에서는 LLM에 대한 효율적인 튜닝을 수행하는 방법에 대해 논의할 것이다. 먼저 트랜스포머 언어 모델에 대한 대표적인 파라미터 효율적인 미세 조정 방법을 검토하고, 파라미터 효율적인 미세 조정 LLM에 대한 기존 연구를 요약한다.</p>
</div>
<section id="S5.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1 </span>Parameter-Efficient Fine-Tuning Methods</h4>

<div id="S5.SS3.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS3.SSS1.p1.1">기존 문헌에서 파라미터 효율적인 미세 조정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib396" title="">396</a>, <a class="ltx_ref" href="#bib.bib397" title="">397</a>, <a class="ltx_ref" href="#bib.bib145" title="">145</a>]</cite>는 좋은 성능을 유지하면서 훈련 가능한 파라미터의 수를 줄이는 것을 목표로 하는 중요한 주제였다. 다음은 어댑터 튜닝, 접두사 튜닝, 프롬프트 튜닝 및 LoRA를 포함한 트랜스포머 언어 모델에 대한 4가지 매개변수 효율적인 미세 조정 방법을 간략하게 검토한다. 이 네 가지 방법의 예시는 그림 <a class="ltx_ref" href="#S5.F13" title="Figure 13 ‣ 5.2.3 Reinforcement Learning from Human Feedback ‣ 5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">13</span></a>에 나와 있다.</p>
</div>
<div id="S5.SS3.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS1.p2.1.1">Adapter Tuning</span>. 어댑터 튜닝은 작은 신경망 모듈(<em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p2.1.2">adapter</em>)을 트랜스포머 모델</cite idx=0></cite>로 통합한다. 어댑터 모듈을 구현하기 위해 먼저 원본 특징 벡터를 더 작은 차원(비선형 변환에 따라)으로 압축한 다음 원래 차원으로 복원하는 병목 구조가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib398" title="">398</a>, <a class="ltx_ref" href="#bib.bib399" title="">399</a>]</cite>에서 제안되었다. 어댑터 모듈은 일반적으로 트랜스포머 계층의 두 코어 부분(<em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p2.1.3">i.e.,</em> attention layer and feed-forward layer) 각각 후에 직렬 삽입을 사용하여 각 트랜스포머 계층에 통합될 것이다. 대안적으로, 병렬 어댑터들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib400" title="">400</a>]</cite>는 트랜스포머 층들에서도 사용될 수 있으며, 여기서 어텐션 층 및 그에 따라 피드포워드 층과 병렬로 두 개의 어댑터 모듈들을 배치한다. 미세 조정 동안 어댑터 모듈은 특정 작업 목표에 따라 최적화되는 반면 원래 언어 모델의 매개변수는 이 프로세스에서 동결된다. 이러한 방식으로, 미세 조정 동안 훈련 가능한 파라미터의 수를 효과적으로 감소시킬 수 있다.</p>
</div>
<div id="S5.SS3.SSS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS1.p3.1.1">Prefix Tuning</span>. Prefix tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib396" title="">396</a>]</cite>는 학습 가능한 연속 벡터의 집합인 prefix의 시퀀스를 언어 모델의 각 Transformer 계층에 prepend한다. 이러한 접두사 벡터들은 태스크-특정적이며, 이는 가상 토큰 임베딩들로서 간주될 수 있다. 접두사 벡터를 최적화하기 위해 접두사를 직접 최적화하는 대신 더 작은 행렬을 접두사의 매개변수 행렬에 매핑하는 MLP 함수를 학습하여 재매개변수화 트릭 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib396" title="">396</a>]</cite>를 제안하였다. 이 트릭이 안정적인 훈련에 유용한 것으로 나타났다. 최적화 후에, 매핑 함수는 폐기될 것이고, 도출된 프리픽스 벡터들만이 태스크-특정 성능을 향상시키기 위해 유지된다. 접두사 매개변수만 학습되기 때문에 매개변수 효율적인 모델 최적화로 이어질 수 있다. 프리픽스 튜닝과 유사하게 p-튜닝 v2<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib401" title="">401</a>]</cite>는 자연어 이해를 위해 특별히 계층별 프롬프트 벡터를 트랜스포머 아키텍처에 통합하며, 공유 프롬프트를 공동으로 최적화하기 위해 다중 작업 학습도 활용한다. 자연어 이해 과제에 대한 다양한 매개변수 척도의 모델 성능을 개선하는 데 유용한 것으로 나타났다.</p>
</div>
<div id="S5.SS3.SSS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS1.p4.1.1">Prompt Tuning</span>. 접두사 튜닝과는 달리, 프롬프트 튜닝 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib402" title="">402</a>, <a class="ltx_ref" href="#bib.bib397" title="">397</a>]</cite>는 주로 입력 레이어<span class="ltx_note ltx_role_footnote" id="footnote34"><sup class="ltx_note_mark">34</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">34</sup><span class="ltx_tag ltx_tag_note">34</span>Here, prompt tuning denotes a category of related efficient tuning methods exemplified by the work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib402" title="">402</a>, <a class="ltx_ref" href="#bib.bib397" title="">397</a>, <a class="ltx_ref" href="#bib.bib403" title="">403</a>]</cite>, instead of a specific method as used in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib397" title="">397</a>]</cite>. Indeed, the prefix based tuning methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib396" title="">396</a>, <a class="ltx_ref" href="#bib.bib401" title="">401</a>]</cite> can be also considered as prompting methods, which are called <em class="ltx_emph ltx_font_italic" id="footnote34.1">deep prompting tuning</em> in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib401" title="">401</a>]</cite>. In this survey, prompt tuning specially refer to the methods that only include the prompt tokens at the input layer, in the context of LLMs. We assign p-tuning v2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib401" title="">401</a>]</cite> to the category of prefix tuning, because it incorporates layerwise prompts in langauge models. </span></span></span>에서 훈련 가능한 프롬프트 벡터를 통합하는 것에 초점을 맞춘다. 이산 프롬프트 방법<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib404" title="">404</a>, <a class="ltx_ref" href="#bib.bib405" title="">405</a>]</cite>를 기반으로 소프트 프롬프트 토큰 그룹(자유 형식<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib402" title="">402</a>]</cite> 또는 접두사 형식<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib397" title="">397</a>]</cite>)을 포함하여 입력 텍스트를 증강한 다음, 특정 다운스트림 작업을 해결하기 위해 프롬프트 증강 입력을 취한다. 구현에서, 태스크-특정 프롬프트 임베딩들은 입력 텍스트 임베딩들과 조합되고, 이들은 후속적으로 언어 모델들로 공급된다. P-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib402" title="">402</a>]</cite>는 컨텍스트, 프롬프트 및 타겟 토큰을 결합하는 자유 형식을 제안했으며, 이는 자연어 이해와 생성을 위한 아키텍처에 적용될 수 있다. 그들은 양방향 LSTM에 의한 소프트 프롬프트 토큰들의 표현들을 더 학습한다. 또 다른 대표적인 접근 방식인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib397" title="">397</a>]</cite>는 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p4.1.2">prompt tuning</em>은 prefix prompts를 입력에 직접 전치합니다. 훈련 중에는 태스크별 감독에 따라 신속한 임베딩만 학습한다. 이 방법은 입력 계층에서 훈련 가능한 소수의 파라미터만을 포함하기 때문에, 성능은 기본 언어 모델들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib397" title="">397</a>]</cite>의 모델 용량에 크게 의존하는 것으로 밝혀졌다.</p>
</div>
<div id="S5.SS3.SSS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.SSS1.p5.8"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS1.p5.8.1">Low-Rank Adaptation (LoRA)</span>. LoRA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib145" title="">145</a>]</cite>는 다운스트림 작업에 적응하기 위한 훈련 가능한 매개변수를 줄이기 위해 각 밀집 계층에서 업데이트 행렬을 근사화하기 위해 낮은 순위 제약을 부과한다. 매개변수 행렬 <math alttext="\mathbf{W}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p5.1.m1.1"><semantics id="S5.SS3.SSS1.p5.1.m1.1a"><mi id="S5.SS3.SSS1.p5.1.m1.1.1" xref="S5.SS3.SSS1.p5.1.m1.1.1.cmml">𝐖</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p5.1.m1.1b"><ci id="S5.SS3.SSS1.p5.1.m1.1.1.cmml" xref="S5.SS3.SSS1.p5.1.m1.1.1">𝐖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p5.1.m1.1c">\mathbf{W}</annotation></semantics></math>를 최적화하는 경우를 생각해 보자. 업데이트 과정은 <math alttext="\mathbf{W}\leftarrow\mathbf{W}+\Delta\mathbf{W}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p5.2.m2.1"><semantics id="S5.SS3.SSS1.p5.2.m2.1a"><mrow id="S5.SS3.SSS1.p5.2.m2.1.1" xref="S5.SS3.SSS1.p5.2.m2.1.1.cmml"><mi id="S5.SS3.SSS1.p5.2.m2.1.1.2" xref="S5.SS3.SSS1.p5.2.m2.1.1.2.cmml">𝐖</mi><mo id="S5.SS3.SSS1.p5.2.m2.1.1.1" stretchy="false" xref="S5.SS3.SSS1.p5.2.m2.1.1.1.cmml">←</mo><mrow id="S5.SS3.SSS1.p5.2.m2.1.1.3" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.cmml"><mi id="S5.SS3.SSS1.p5.2.m2.1.1.3.2" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.2.cmml">𝐖</mi><mo id="S5.SS3.SSS1.p5.2.m2.1.1.3.1" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.1.cmml">+</mo><mrow id="S5.SS3.SSS1.p5.2.m2.1.1.3.3" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.3.cmml"><mi id="S5.SS3.SSS1.p5.2.m2.1.1.3.3.2" mathvariant="normal" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.3.2.cmml">Δ</mi><mo id="S5.SS3.SSS1.p5.2.m2.1.1.3.3.1" lspace="0em" rspace="0em" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.3.1.cmml">​</mo><mi id="S5.SS3.SSS1.p5.2.m2.1.1.3.3.3" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.3.3.cmml">𝐖</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p5.2.m2.1b"><apply id="S5.SS3.SSS1.p5.2.m2.1.1.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1"><ci id="S5.SS3.SSS1.p5.2.m2.1.1.1.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1.1">←</ci><ci id="S5.SS3.SSS1.p5.2.m2.1.1.2.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1.2">𝐖</ci><apply id="S5.SS3.SSS1.p5.2.m2.1.1.3.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1.3"><plus id="S5.SS3.SSS1.p5.2.m2.1.1.3.1.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.1"></plus><ci id="S5.SS3.SSS1.p5.2.m2.1.1.3.2.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.2">𝐖</ci><apply id="S5.SS3.SSS1.p5.2.m2.1.1.3.3.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.3"><times id="S5.SS3.SSS1.p5.2.m2.1.1.3.3.1.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.3.1"></times><ci id="S5.SS3.SSS1.p5.2.m2.1.1.3.3.2.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.3.2">Δ</ci><ci id="S5.SS3.SSS1.p5.2.m2.1.1.3.3.3.cmml" xref="S5.SS3.SSS1.p5.2.m2.1.1.3.3.3">𝐖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p5.2.m2.1c">\mathbf{W}\leftarrow\mathbf{W}+\Delta\mathbf{W}</annotation></semantics></math>와 같이 일반적인 형태로 작성될 수 있다. LoRA의 기본 아이디어는 파라미터 업데이트 <math alttext="\Delta\mathbf{W}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p5.4.m4.1"><semantics id="S5.SS3.SSS1.p5.4.m4.1a"><mrow id="S5.SS3.SSS1.p5.4.m4.1.1" xref="S5.SS3.SSS1.p5.4.m4.1.1.cmml"><mi id="S5.SS3.SSS1.p5.4.m4.1.1.2" mathvariant="normal" xref="S5.SS3.SSS1.p5.4.m4.1.1.2.cmml">Δ</mi><mo id="S5.SS3.SSS1.p5.4.m4.1.1.1" lspace="0em" rspace="0em" xref="S5.SS3.SSS1.p5.4.m4.1.1.1.cmml">​</mo><mi id="S5.SS3.SSS1.p5.4.m4.1.1.3" xref="S5.SS3.SSS1.p5.4.m4.1.1.3.cmml">𝐖</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p5.4.m4.1b"><apply id="S5.SS3.SSS1.p5.4.m4.1.1.cmml" xref="S5.SS3.SSS1.p5.4.m4.1.1"><times id="S5.SS3.SSS1.p5.4.m4.1.1.1.cmml" xref="S5.SS3.SSS1.p5.4.m4.1.1.1"></times><ci id="S5.SS3.SSS1.p5.4.m4.1.1.2.cmml" xref="S5.SS3.SSS1.p5.4.m4.1.1.2">Δ</ci><ci id="S5.SS3.SSS1.p5.4.m4.1.1.3.cmml" xref="S5.SS3.SSS1.p5.4.m4.1.1.3">𝐖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p5.4.m4.1c">\Delta\mathbf{W}</annotation></semantics></math>를 낮은 순위 분해 행렬로 근사하면서 원래의 행렬 <math alttext="\mathbf{W}\in\mathbb{R}^{m\times n}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p5.3.m3.1"><semantics id="S5.SS3.SSS1.p5.3.m3.1a"><mrow id="S5.SS3.SSS1.p5.3.m3.1.1" xref="S5.SS3.SSS1.p5.3.m3.1.1.cmml"><mi id="S5.SS3.SSS1.p5.3.m3.1.1.2" xref="S5.SS3.SSS1.p5.3.m3.1.1.2.cmml">𝐖</mi><mo id="S5.SS3.SSS1.p5.3.m3.1.1.1" xref="S5.SS3.SSS1.p5.3.m3.1.1.1.cmml">∈</mo><msup id="S5.SS3.SSS1.p5.3.m3.1.1.3" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.cmml"><mi id="S5.SS3.SSS1.p5.3.m3.1.1.3.2" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S5.SS3.SSS1.p5.3.m3.1.1.3.3" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.3.cmml"><mi id="S5.SS3.SSS1.p5.3.m3.1.1.3.3.2" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.3.2.cmml">m</mi><mo id="S5.SS3.SSS1.p5.3.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S5.SS3.SSS1.p5.3.m3.1.1.3.3.3" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.3.3.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p5.3.m3.1b"><apply id="S5.SS3.SSS1.p5.3.m3.1.1.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1"><in id="S5.SS3.SSS1.p5.3.m3.1.1.1.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1.1"></in><ci id="S5.SS3.SSS1.p5.3.m3.1.1.2.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1.2">𝐖</ci><apply id="S5.SS3.SSS1.p5.3.m3.1.1.3.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p5.3.m3.1.1.3.1.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1.3">superscript</csymbol><ci id="S5.SS3.SSS1.p5.3.m3.1.1.3.2.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.2">ℝ</ci><apply id="S5.SS3.SSS1.p5.3.m3.1.1.3.3.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.3"><times id="S5.SS3.SSS1.p5.3.m3.1.1.3.3.1.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.3.1"></times><ci id="S5.SS3.SSS1.p5.3.m3.1.1.3.3.2.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.3.2">𝑚</ci><ci id="S5.SS3.SSS1.p5.3.m3.1.1.3.3.3.cmml" xref="S5.SS3.SSS1.p5.3.m3.1.1.3.3.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p5.3.m3.1c">\mathbf{W}\in\mathbb{R}^{m\times n}</annotation></semantics></math>를 동결하는 것이며, <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p5.8.2">i.e.,</em> <math alttext="\Delta\mathbf{W}=\mathbf{A}\cdot\mathbf{B}^{\top}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p5.5.m5.1"><semantics id="S5.SS3.SSS1.p5.5.m5.1a"><mrow id="S5.SS3.SSS1.p5.5.m5.1.1" xref="S5.SS3.SSS1.p5.5.m5.1.1.cmml"><mrow id="S5.SS3.SSS1.p5.5.m5.1.1.2" xref="S5.SS3.SSS1.p5.5.m5.1.1.2.cmml"><mi id="S5.SS3.SSS1.p5.5.m5.1.1.2.2" mathvariant="normal" xref="S5.SS3.SSS1.p5.5.m5.1.1.2.2.cmml">Δ</mi><mo id="S5.SS3.SSS1.p5.5.m5.1.1.2.1" lspace="0em" rspace="0em" xref="S5.SS3.SSS1.p5.5.m5.1.1.2.1.cmml">​</mo><mi id="S5.SS3.SSS1.p5.5.m5.1.1.2.3" xref="S5.SS3.SSS1.p5.5.m5.1.1.2.3.cmml">𝐖</mi></mrow><mo id="S5.SS3.SSS1.p5.5.m5.1.1.1" xref="S5.SS3.SSS1.p5.5.m5.1.1.1.cmml">=</mo><mrow id="S5.SS3.SSS1.p5.5.m5.1.1.3" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.cmml"><mi id="S5.SS3.SSS1.p5.5.m5.1.1.3.2" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.2.cmml">𝐀</mi><mo id="S5.SS3.SSS1.p5.5.m5.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.1.cmml">⋅</mo><msup id="S5.SS3.SSS1.p5.5.m5.1.1.3.3" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.3.cmml"><mi id="S5.SS3.SSS1.p5.5.m5.1.1.3.3.2" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.3.2.cmml">𝐁</mi><mo id="S5.SS3.SSS1.p5.5.m5.1.1.3.3.3" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.3.3.cmml">⊤</mo></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p5.5.m5.1b"><apply id="S5.SS3.SSS1.p5.5.m5.1.1.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1"><eq id="S5.SS3.SSS1.p5.5.m5.1.1.1.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.1"></eq><apply id="S5.SS3.SSS1.p5.5.m5.1.1.2.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.2"><times id="S5.SS3.SSS1.p5.5.m5.1.1.2.1.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.2.1"></times><ci id="S5.SS3.SSS1.p5.5.m5.1.1.2.2.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.2.2">Δ</ci><ci id="S5.SS3.SSS1.p5.5.m5.1.1.2.3.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.2.3">𝐖</ci></apply><apply id="S5.SS3.SSS1.p5.5.m5.1.1.3.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.3"><ci id="S5.SS3.SSS1.p5.5.m5.1.1.3.1.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.1">⋅</ci><ci id="S5.SS3.SSS1.p5.5.m5.1.1.3.2.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.2">𝐀</ci><apply id="S5.SS3.SSS1.p5.5.m5.1.1.3.3.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.3"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p5.5.m5.1.1.3.3.1.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.3">superscript</csymbol><ci id="S5.SS3.SSS1.p5.5.m5.1.1.3.3.2.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.3.2">𝐁</ci><csymbol cd="latexml" id="S5.SS3.SSS1.p5.5.m5.1.1.3.3.3.cmml" xref="S5.SS3.SSS1.p5.5.m5.1.1.3.3.3">top</csymbol></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p5.5.m5.1c">\Delta\mathbf{W}=\mathbf{A}\cdot\mathbf{B}^{\top}</annotation></semantics></math>, 여기서 <math alttext="\mathbf{A}\in\mathbb{R}^{m\times k}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p5.6.m6.1"><semantics id="S5.SS3.SSS1.p5.6.m6.1a"><mrow id="S5.SS3.SSS1.p5.6.m6.1.1" xref="S5.SS3.SSS1.p5.6.m6.1.1.cmml"><mi id="S5.SS3.SSS1.p5.6.m6.1.1.2" xref="S5.SS3.SSS1.p5.6.m6.1.1.2.cmml">𝐀</mi><mo id="S5.SS3.SSS1.p5.6.m6.1.1.1" xref="S5.SS3.SSS1.p5.6.m6.1.1.1.cmml">∈</mo><msup id="S5.SS3.SSS1.p5.6.m6.1.1.3" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.cmml"><mi id="S5.SS3.SSS1.p5.6.m6.1.1.3.2" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.2.cmml">ℝ</mi><mrow id="S5.SS3.SSS1.p5.6.m6.1.1.3.3" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.3.cmml"><mi id="S5.SS3.SSS1.p5.6.m6.1.1.3.3.2" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.3.2.cmml">m</mi><mo id="S5.SS3.SSS1.p5.6.m6.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.3.1.cmml">×</mo><mi id="S5.SS3.SSS1.p5.6.m6.1.1.3.3.3" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p5.6.m6.1b"><apply id="S5.SS3.SSS1.p5.6.m6.1.1.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1"><in id="S5.SS3.SSS1.p5.6.m6.1.1.1.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1.1"></in><ci id="S5.SS3.SSS1.p5.6.m6.1.1.2.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1.2">𝐀</ci><apply id="S5.SS3.SSS1.p5.6.m6.1.1.3.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1.3"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p5.6.m6.1.1.3.1.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1.3">superscript</csymbol><ci id="S5.SS3.SSS1.p5.6.m6.1.1.3.2.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.2">ℝ</ci><apply id="S5.SS3.SSS1.p5.6.m6.1.1.3.3.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.3"><times id="S5.SS3.SSS1.p5.6.m6.1.1.3.3.1.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.3.1"></times><ci id="S5.SS3.SSS1.p5.6.m6.1.1.3.3.2.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.3.2">𝑚</ci><ci id="S5.SS3.SSS1.p5.6.m6.1.1.3.3.3.cmml" xref="S5.SS3.SSS1.p5.6.m6.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p5.6.m6.1c">\mathbf{A}\in\mathbb{R}^{m\times k}</annotation></semantics></math> 및 <math alttext="\mathbf{B}\in\mathbb{R}^{n\times k}" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p5.7.m7.1"><semantics id="S5.SS3.SSS1.p5.7.m7.1a"><mrow id="S5.SS3.SSS1.p5.7.m7.1.1" xref="S5.SS3.SSS1.p5.7.m7.1.1.cmml"><mi id="S5.SS3.SSS1.p5.7.m7.1.1.2" xref="S5.SS3.SSS1.p5.7.m7.1.1.2.cmml">𝐁</mi><mo id="S5.SS3.SSS1.p5.7.m7.1.1.1" xref="S5.SS3.SSS1.p5.7.m7.1.1.1.cmml">∈</mo><msup id="S5.SS3.SSS1.p5.7.m7.1.1.3" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.cmml"><mi id="S5.SS3.SSS1.p5.7.m7.1.1.3.2" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.2.cmml">ℝ</mi><mrow id="S5.SS3.SSS1.p5.7.m7.1.1.3.3" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.3.cmml"><mi id="S5.SS3.SSS1.p5.7.m7.1.1.3.3.2" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.3.2.cmml">n</mi><mo id="S5.SS3.SSS1.p5.7.m7.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.3.1.cmml">×</mo><mi id="S5.SS3.SSS1.p5.7.m7.1.1.3.3.3" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p5.7.m7.1b"><apply id="S5.SS3.SSS1.p5.7.m7.1.1.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1"><in id="S5.SS3.SSS1.p5.7.m7.1.1.1.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1.1"></in><ci id="S5.SS3.SSS1.p5.7.m7.1.1.2.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1.2">𝐁</ci><apply id="S5.SS3.SSS1.p5.7.m7.1.1.3.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1.3"><csymbol cd="ambiguous" id="S5.SS3.SSS1.p5.7.m7.1.1.3.1.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1.3">superscript</csymbol><ci id="S5.SS3.SSS1.p5.7.m7.1.1.3.2.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.2">ℝ</ci><apply id="S5.SS3.SSS1.p5.7.m7.1.1.3.3.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.3"><times id="S5.SS3.SSS1.p5.7.m7.1.1.3.3.1.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.3.1"></times><ci id="S5.SS3.SSS1.p5.7.m7.1.1.3.3.2.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.3.2">𝑛</ci><ci id="S5.SS3.SSS1.p5.7.m7.1.1.3.3.3.cmml" xref="S5.SS3.SSS1.p5.7.m7.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p5.7.m7.1c">\mathbf{B}\in\mathbb{R}^{n\times k}</annotation></semantics></math>는 작업 적응을 위한 훈련 가능한 파라미터이고 <math alttext="k\ll\min(m,n)" class="ltx_Math" display="inline" id="S5.SS3.SSS1.p5.8.m8.3"><semantics id="S5.SS3.SSS1.p5.8.m8.3a"><mrow id="S5.SS3.SSS1.p5.8.m8.3.4" xref="S5.SS3.SSS1.p5.8.m8.3.4.cmml"><mi id="S5.SS3.SSS1.p5.8.m8.3.4.2" xref="S5.SS3.SSS1.p5.8.m8.3.4.2.cmml">k</mi><mo id="S5.SS3.SSS1.p5.8.m8.3.4.1" xref="S5.SS3.SSS1.p5.8.m8.3.4.1.cmml">≪</mo><mrow id="S5.SS3.SSS1.p5.8.m8.3.4.3.2" xref="S5.SS3.SSS1.p5.8.m8.3.4.3.1.cmml"><mi id="S5.SS3.SSS1.p5.8.m8.1.1" xref="S5.SS3.SSS1.p5.8.m8.1.1.cmml">min</mi><mo id="S5.SS3.SSS1.p5.8.m8.3.4.3.2a" xref="S5.SS3.SSS1.p5.8.m8.3.4.3.1.cmml">⁡</mo><mrow id="S5.SS3.SSS1.p5.8.m8.3.4.3.2.1" xref="S5.SS3.SSS1.p5.8.m8.3.4.3.1.cmml"><mo id="S5.SS3.SSS1.p5.8.m8.3.4.3.2.1.1" stretchy="false" xref="S5.SS3.SSS1.p5.8.m8.3.4.3.1.cmml">(</mo><mi id="S5.SS3.SSS1.p5.8.m8.2.2" xref="S5.SS3.SSS1.p5.8.m8.2.2.cmml">m</mi><mo id="S5.SS3.SSS1.p5.8.m8.3.4.3.2.1.2" xref="S5.SS3.SSS1.p5.8.m8.3.4.3.1.cmml">,</mo><mi id="S5.SS3.SSS1.p5.8.m8.3.3" xref="S5.SS3.SSS1.p5.8.m8.3.3.cmml">n</mi><mo id="S5.SS3.SSS1.p5.8.m8.3.4.3.2.1.3" stretchy="false" xref="S5.SS3.SSS1.p5.8.m8.3.4.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS1.p5.8.m8.3b"><apply id="S5.SS3.SSS1.p5.8.m8.3.4.cmml" xref="S5.SS3.SSS1.p5.8.m8.3.4"><csymbol cd="latexml" id="S5.SS3.SSS1.p5.8.m8.3.4.1.cmml" xref="S5.SS3.SSS1.p5.8.m8.3.4.1">much-less-than</csymbol><ci id="S5.SS3.SSS1.p5.8.m8.3.4.2.cmml" xref="S5.SS3.SSS1.p5.8.m8.3.4.2">𝑘</ci><apply id="S5.SS3.SSS1.p5.8.m8.3.4.3.1.cmml" xref="S5.SS3.SSS1.p5.8.m8.3.4.3.2"><min id="S5.SS3.SSS1.p5.8.m8.1.1.cmml" xref="S5.SS3.SSS1.p5.8.m8.1.1"></min><ci id="S5.SS3.SSS1.p5.8.m8.2.2.cmml" xref="S5.SS3.SSS1.p5.8.m8.2.2">𝑚</ci><ci id="S5.SS3.SSS1.p5.8.m8.3.3.cmml" xref="S5.SS3.SSS1.p5.8.m8.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS1.p5.8.m8.3c">k\ll\min(m,n)</annotation></semantics></math>는 감소된 순위이다. LoRA의 주요 장점은 메모리 및 스토리지 사용량을 크게 절약할 수 있다는 것이다(<em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p5.8.3">e.g.,</em> VRAM). 또한, 상이한 다운스트림 태스크들에 적응하기 위한 다수의 태스크-특정 저순위 분해 매트릭스들을 유지하면서, 단일 대형 모델 복사본만을 유지할 수 있다. 또한 여러 연구에서 더 원칙적인 접근 방식인 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS1.p5.8.4">e.g.,</em> 중요도 점수 기반 할당 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib406" title="">406</a>]</cite> 및 검색 없는 최적 순위 선택 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib407" title="">407</a>]</cite>에서 순위를 설정하는 방법에 대해서도 논의했다.</p>
</div>
<div id="S5.SS3.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS3.SSS1.p6.1">위의 방법 외에도 트랜스포머 언어 모델의 효율적인 튜닝에 대한 광범위한 연구가 있다. 그러나 효율적인 튜닝에 대한 보다 포괄적인 논의는 이 주제의 관련 논문에서 찾을 수 있는 이 기사의 범위를 벗어난다.</p>
</div>
</section>
<section id="S5.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2 </span>Parameter-Efficient Fine-Tuning on LLMs</h4>

<div id="S5.SS3.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS3.SSS2.p1.1">LLM이 증가함에 따라, 효율적인 튜닝은 다운스트림 태스크에서 보다 가벼운 적응 접근법을 개발하기 위해 증가하는 연구 관심을 끌었다.</p>
</div>
<div id="S5.SS3.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS3.SSS2.p2.1">특히 LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib145" title="">145</a>]</cite>는 파라미터 효율적인 미세 조정을 위해 오픈 소스 LLMs(<em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p2.1.1">e.g.,</em> LLaMA and BLOOM)에 널리 적용되어 왔다. 이러한 연구 시도 중 LLaMA와 그 변형은 매개변수 효율적인 조정을 위해 많은 관심을 받았다. 예를 들어, Alpaca-LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib144" title="">144</a>]</cite>는 Alpaca <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>의 경량 조정된 버전으로서 LoRA를 사용하여 훈련되었다(52K 인간 데모 명령어 후속을 갖는 미세 조정된 7B LLaMA 모델). 다양한 언어 또는 모델 크기의 Alpaca-LoRA 범위에 대한 광범위한 탐색이 있으며, 이는 모음 페이지<span class="ltx_note ltx_role_footnote" id="footnote35"><sup class="ltx_note_mark">35</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">35</sup><span class="ltx_tag ltx_tag_note">35</span>https://github.com/tloen/alpaca-lora</span></span></span>에서 찾을 수 있다. 최근 LLaMA-Adapter <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib409" title="">409</a>]</cite>는 학습 가능한 프롬프트 벡터를 각 Transformer 계층에 삽입하는데, 이 과정에서 과소 적합 프롬프트 벡터의 영향을 완화하여 학습을 향상시키기 위한 제로 초기 주의 집중이 제안되었다. 그들은 또한 이 접근법을 멀티모달 설정인 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p2.1.2">e.g.,</em> 시각적 질문 응답으로 확장한다.</p>
</div>
<div id="S5.SS3.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S5.SS3.SSS2.p3.1">또한, 다양한 튜닝 방법이 언어 모델에 미치는 영향을 조사하기 위해 경험적 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib399" title="">399</a>]</cite>가 수행되었다. 이를 위해 3개의 오픈소스 LLMs(GPT-J(6B), BLOOM(7.1B), LLaMA(7B)에 대해 직렬 어댑터 튜닝</cite>, 병렬 어댑터 튜닝</cite></cite>, LoRA</cite idx=3></cite>의 4가지 효율적인 튜닝 방법을 비교하였다. 6개의 수학 추론 데이터 세트에 대한 실험 결과를 바탕으로, 이러한 효율적인 조정 방법은 어려운 과제에서는 기준 기준 GPT-3.5를 과소 수행하지만 간단한 과제에서는 유사한 성능을 달성한다는 것을 보여준다. 전반적으로 LoRA는 훨씬 적은 훈련 가능한 매개변수를 사용하여 이러한 비교 방법 중에서 비교적 잘 수행한다.</p>
</div>
<div id="S5.SS3.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS3.SSS2.p4.1">중요한 리소스로서 라이브러리 <em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p4.1.1">PEFT</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib411" title="">411</a>]</cite> (standing for parameter-efficient fine-tuning) is released on GitHub<span class="ltx_note ltx_role_footnote" id="footnote36"><sup class="ltx_note_mark">36</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">36</sup><span class="ltx_tag ltx_tag_note">36</span>https://github.com/huggingface/peft</span></span></span>. 이는 LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib145" title="">145</a>]</cite>/AdaLoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib406" title="">406</a>]</cite>, prefix-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib396" title="">396</a>, <a class="ltx_ref" href="#bib.bib401" title="">401</a>]</cite>, P-Tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib402" title="">402</a>]</cite>, prompt-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib397" title="">397</a>]</cite> 등 널리 사용되는 여러 가지 효율적인 튜닝 방법을 포함하고 있다. 또한 GPT-2 및 LLaMA와 같은 여러 언어 모델을 지원하며 여러 대표적인 비전 트랜스포머 모델(<em class="ltx_emph ltx_font_italic" id="S5.SS3.SSS2.p4.1.2">e.g.,</em> ViT 및 Swin Transformer)도 포함한다.</p>
</div>
<div id="S5.SS3.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS3.SSS2.p5.1"><a class="ltx_ref" href="#S5.SS3.SSS1" title="5.3.1 Parameter-Efficient Fine-Tuning Methods ‣ 5.3 Parameter-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.3.1</span></a>절에서 살펴본 바와 같이, 기존 문헌에서 제안된 많은 효율적인 튜닝 방법들이 있었다. 그러나, 이러한 접근법들의 대부분은 LLMs 대신에 작은 크기의 사전 훈련된 언어 모델들에 대해 테스트된다. 지금까지, 상이한 설정 또는 태스크에서 상이한 효율적인 튜닝 방법이 대형 언어 모델에 미치는 영향에 대한 철저한 조사는 여전히 부족하다.</p>
</div>
</section>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span><span id="S5.SS4.1.1" class="ltx_text ltx_font_italic">Memory-Efficient Model Adaptation</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.p1.1">많은 수의 모델 파라미터로 인해 LLM은 추론을 위해 상당한 메모리 공간을 차지하므로 실제 응용 프로그램에 배포하는 데 매우 비용이 많이 든다. 이 섹션에서는 인기 있는 모델 압축 접근법(<em class="ltx_emph ltx_font_italic" id="S5.SS4.p1.1.1">i.e.,</em> 모델 양자화)을 통해 LLM의 메모리 풋프린트를 줄이는 방법에 대해 논의하여 대규모 LLM이 리소스 제한 설정에서 사용될 수 있으며, 이는 추론 지연 시간도 줄일 수 있다.</p>
</div>
<section id="S5.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.1 </span>Background for Quantization</h4>

<div id="S5.SS4.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS1.p1.1">이 부분에서는 신경망에 대한 양자화 기술에 대한 일반적인 소개를 제시한다.</p>
</div>
<div id="S5.SS4.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS1.p2.8">신경망 압축에서 양자화는 종종 부동 소수점 숫자에서 정수로의 매핑 과정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib412" title="">412</a>]</cite>, 특히 8비트 정수 양자화를 지칭한다(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS1.p2.8.1">i.e.,</em> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS1.p2.8.2">INT8 양자화</em>). 신경망 모델의 경우 일반적으로 양자화할 두 가지 종류의 데이터, 즉 원래 부동 소수점 숫자로 표시되는 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS1.p2.8.3">weights</em> (모델 매개변수) 및 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS1.p2.8.4">activations</em> (은닉 활성화)가 있다. 모델 양자화의 본질적인 아이디어를 설명하기 위해, 부동수 <math alttext="x" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p2.2.m2.1"><semantics id="S5.SS4.SSS1.p2.2.m2.1a"><mi id="S5.SS4.SSS1.p2.2.m2.1.1" xref="S5.SS4.SSS1.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p2.2.m2.1b"><ci id="S5.SS4.SSS1.p2.2.m2.1.1.cmml" xref="S5.SS4.SSS1.p2.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p2.2.m2.1c">x</annotation></semantics></math>를 양자화된 값 <math alttext="x_{q}" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p2.3.m3.1"><semantics id="S5.SS4.SSS1.p2.3.m3.1a"><msub id="S5.SS4.SSS1.p2.3.m3.1.1" xref="S5.SS4.SSS1.p2.3.m3.1.1.cmml"><mi id="S5.SS4.SSS1.p2.3.m3.1.1.2" xref="S5.SS4.SSS1.p2.3.m3.1.1.2.cmml">x</mi><mi id="S5.SS4.SSS1.p2.3.m3.1.1.3" xref="S5.SS4.SSS1.p2.3.m3.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p2.3.m3.1b"><apply id="S5.SS4.SSS1.p2.3.m3.1.1.cmml" xref="S5.SS4.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS4.SSS1.p2.3.m3.1.1.1.cmml" xref="S5.SS4.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S5.SS4.SSS1.p2.3.m3.1.1.2.cmml" xref="S5.SS4.SSS1.p2.3.m3.1.1.2">𝑥</ci><ci id="S5.SS4.SSS1.p2.3.m3.1.1.3.cmml" xref="S5.SS4.SSS1.p2.3.m3.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p2.3.m3.1c">x_{q}</annotation></semantics></math>로 변환하는 간단하면서도 대중적인 양자화 함수 <math alttext="x_{q}=R(x/S)-Z" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p2.1.m1.1"><semantics id="S5.SS4.SSS1.p2.1.m1.1a"><mrow id="S5.SS4.SSS1.p2.1.m1.1.1" xref="S5.SS4.SSS1.p2.1.m1.1.1.cmml"><msub id="S5.SS4.SSS1.p2.1.m1.1.1.3" xref="S5.SS4.SSS1.p2.1.m1.1.1.3.cmml"><mi id="S5.SS4.SSS1.p2.1.m1.1.1.3.2" xref="S5.SS4.SSS1.p2.1.m1.1.1.3.2.cmml">x</mi><mi id="S5.SS4.SSS1.p2.1.m1.1.1.3.3" xref="S5.SS4.SSS1.p2.1.m1.1.1.3.3.cmml">q</mi></msub><mo id="S5.SS4.SSS1.p2.1.m1.1.1.2" xref="S5.SS4.SSS1.p2.1.m1.1.1.2.cmml">=</mo><mrow id="S5.SS4.SSS1.p2.1.m1.1.1.1" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.cmml"><mrow id="S5.SS4.SSS1.p2.1.m1.1.1.1.1" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.cmml"><mi id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.3" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.3.cmml">R</mi><mo id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.2.cmml">​</mo><mrow id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.cmml"><mo id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.2" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.1" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.1.cmml">/</mo><mi id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.3" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml">S</mi></mrow><mo id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.SS4.SSS1.p2.1.m1.1.1.1.2" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.2.cmml">−</mo><mi id="S5.SS4.SSS1.p2.1.m1.1.1.1.3" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.3.cmml">Z</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p2.1.m1.1b"><apply id="S5.SS4.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1"><eq id="S5.SS4.SSS1.p2.1.m1.1.1.2.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.2"></eq><apply id="S5.SS4.SSS1.p2.1.m1.1.1.3.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.SS4.SSS1.p2.1.m1.1.1.3.1.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.3">subscript</csymbol><ci id="S5.SS4.SSS1.p2.1.m1.1.1.3.2.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.3.2">𝑥</ci><ci id="S5.SS4.SSS1.p2.1.m1.1.1.3.3.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.3.3">𝑞</ci></apply><apply id="S5.SS4.SSS1.p2.1.m1.1.1.1.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1"><minus id="S5.SS4.SSS1.p2.1.m1.1.1.1.2.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.2"></minus><apply id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1"><times id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.2.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.2"></times><ci id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.3.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.3">𝑅</ci><apply id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1"><divide id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.1"></divide><ci id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.1.1.1.1.3">𝑆</ci></apply></apply><ci id="S5.SS4.SSS1.p2.1.m1.1.1.1.3.cmml" xref="S5.SS4.SSS1.p2.1.m1.1.1.1.3">𝑍</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p2.1.m1.1c">x_{q}=R(x/S)-Z</annotation></semantics></math>를 소개한다. 이 함수에서, <math alttext="S" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p2.4.m4.1"><semantics id="S5.SS4.SSS1.p2.4.m4.1a"><mi id="S5.SS4.SSS1.p2.4.m4.1.1" xref="S5.SS4.SSS1.p2.4.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p2.4.m4.1b"><ci id="S5.SS4.SSS1.p2.4.m4.1.1.cmml" xref="S5.SS4.SSS1.p2.4.m4.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p2.4.m4.1c">S</annotation></semantics></math> 및 <math alttext="Z" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p2.5.m5.1"><semantics id="S5.SS4.SSS1.p2.5.m5.1a"><mi id="S5.SS4.SSS1.p2.5.m5.1.1" xref="S5.SS4.SSS1.p2.5.m5.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p2.5.m5.1b"><ci id="S5.SS4.SSS1.p2.5.m5.1.1.cmml" xref="S5.SS4.SSS1.p2.5.m5.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p2.5.m5.1c">Z</annotation></semantics></math>는 각각 스케일링 팩터(클리핑 범위를 결정하는 두 파라미터 <math alttext="\alpha" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p2.6.m6.1"><semantics id="S5.SS4.SSS1.p2.6.m6.1a"><mi id="S5.SS4.SSS1.p2.6.m6.1.1" xref="S5.SS4.SSS1.p2.6.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p2.6.m6.1b"><ci id="S5.SS4.SSS1.p2.6.m6.1.1.cmml" xref="S5.SS4.SSS1.p2.6.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p2.6.m6.1c">\alpha</annotation></semantics></math> 및 <math alttext="\beta" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p2.7.m7.1"><semantics id="S5.SS4.SSS1.p2.7.m7.1a"><mi id="S5.SS4.SSS1.p2.7.m7.1.1" xref="S5.SS4.SSS1.p2.7.m7.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p2.7.m7.1b"><ci id="S5.SS4.SSS1.p2.7.m7.1.1.cmml" xref="S5.SS4.SSS1.p2.7.m7.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p2.7.m7.1c">\beta</annotation></semantics></math>를 포함함) 및 제로 포인트 팩터(대칭 또는 비대칭 양자화를 결정함)를 나타내고, <math alttext="R(\cdot)" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p2.8.m8.1"><semantics id="S5.SS4.SSS1.p2.8.m8.1a"><mrow id="S5.SS4.SSS1.p2.8.m8.1.2" xref="S5.SS4.SSS1.p2.8.m8.1.2.cmml"><mi id="S5.SS4.SSS1.p2.8.m8.1.2.2" xref="S5.SS4.SSS1.p2.8.m8.1.2.2.cmml">R</mi><mo id="S5.SS4.SSS1.p2.8.m8.1.2.1" lspace="0em" rspace="0em" xref="S5.SS4.SSS1.p2.8.m8.1.2.1.cmml">​</mo><mrow id="S5.SS4.SSS1.p2.8.m8.1.2.3.2" xref="S5.SS4.SSS1.p2.8.m8.1.2.cmml"><mo id="S5.SS4.SSS1.p2.8.m8.1.2.3.2.1" stretchy="false" xref="S5.SS4.SSS1.p2.8.m8.1.2.cmml">(</mo><mo id="S5.SS4.SSS1.p2.8.m8.1.1" lspace="0em" rspace="0em" xref="S5.SS4.SSS1.p2.8.m8.1.1.cmml">⋅</mo><mo id="S5.SS4.SSS1.p2.8.m8.1.2.3.2.2" stretchy="false" xref="S5.SS4.SSS1.p2.8.m8.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p2.8.m8.1b"><apply id="S5.SS4.SSS1.p2.8.m8.1.2.cmml" xref="S5.SS4.SSS1.p2.8.m8.1.2"><times id="S5.SS4.SSS1.p2.8.m8.1.2.1.cmml" xref="S5.SS4.SSS1.p2.8.m8.1.2.1"></times><ci id="S5.SS4.SSS1.p2.8.m8.1.2.2.cmml" xref="S5.SS4.SSS1.p2.8.m8.1.2.2">𝑅</ci><ci id="S5.SS4.SSS1.p2.8.m8.1.1.cmml" xref="S5.SS4.SSS1.p2.8.m8.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p2.8.m8.1c">R(\cdot)</annotation></semantics></math>는 스케일링된 플로팅 값을 근사 정수로 매핑하는 라운딩 동작을 나타낸다.</p>
</div>
<div id="S5.SS4.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS1.p3.5">역과정으로서 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS1.p3.5.1">dequantization</em>은 그에 따라 양자화된 값으로부터 원래의 값을 복구한다: <math alttext="\tilde{x}=S\cdot(x_{q}+Z)" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p3.1.m1.1"><semantics id="S5.SS4.SSS1.p3.1.m1.1a"><mrow id="S5.SS4.SSS1.p3.1.m1.1.1" xref="S5.SS4.SSS1.p3.1.m1.1.1.cmml"><mover accent="true" id="S5.SS4.SSS1.p3.1.m1.1.1.3" xref="S5.SS4.SSS1.p3.1.m1.1.1.3.cmml"><mi id="S5.SS4.SSS1.p3.1.m1.1.1.3.2" xref="S5.SS4.SSS1.p3.1.m1.1.1.3.2.cmml">x</mi><mo id="S5.SS4.SSS1.p3.1.m1.1.1.3.1" xref="S5.SS4.SSS1.p3.1.m1.1.1.3.1.cmml">~</mo></mover><mo id="S5.SS4.SSS1.p3.1.m1.1.1.2" xref="S5.SS4.SSS1.p3.1.m1.1.1.2.cmml">=</mo><mrow id="S5.SS4.SSS1.p3.1.m1.1.1.1" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.cmml"><mi id="S5.SS4.SSS1.p3.1.m1.1.1.1.3" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.3.cmml">S</mi><mo id="S5.SS4.SSS1.p3.1.m1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.2.cmml">⋅</mo><mrow id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.cmml"><mo id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.2" stretchy="false" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.cmml"><msub id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.cmml"><mi id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.2" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.3" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.3.cmml">q</mi></msub><mo id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.1" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.3" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.3.cmml">Z</mi></mrow><mo id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.3" stretchy="false" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p3.1.m1.1b"><apply id="S5.SS4.SSS1.p3.1.m1.1.1.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1"><eq id="S5.SS4.SSS1.p3.1.m1.1.1.2.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.2"></eq><apply id="S5.SS4.SSS1.p3.1.m1.1.1.3.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.3"><ci id="S5.SS4.SSS1.p3.1.m1.1.1.3.1.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.3.1">~</ci><ci id="S5.SS4.SSS1.p3.1.m1.1.1.3.2.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.3.2">𝑥</ci></apply><apply id="S5.SS4.SSS1.p3.1.m1.1.1.1.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1"><ci id="S5.SS4.SSS1.p3.1.m1.1.1.1.2.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.2">⋅</ci><ci id="S5.SS4.SSS1.p3.1.m1.1.1.1.3.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.3">𝑆</ci><apply id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1"><plus id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.1"></plus><apply id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.2.3">𝑞</ci></apply><ci id="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.SS4.SSS1.p3.1.m1.1.1.1.1.1.1.3">𝑍</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p3.1.m1.1c">\tilde{x}=S\cdot(x_{q}+Z)</annotation></semantics></math>. 양자화 오차는 원래의 값 <math alttext="x" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p3.2.m2.1"><semantics id="S5.SS4.SSS1.p3.2.m2.1a"><mi id="S5.SS4.SSS1.p3.2.m2.1.1" xref="S5.SS4.SSS1.p3.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p3.2.m2.1b"><ci id="S5.SS4.SSS1.p3.2.m2.1.1.cmml" xref="S5.SS4.SSS1.p3.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p3.2.m2.1c">x</annotation></semantics></math>와 복원된 값 <math alttext="\tilde{x}" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p3.3.m3.1"><semantics id="S5.SS4.SSS1.p3.3.m3.1a"><mover accent="true" id="S5.SS4.SSS1.p3.3.m3.1.1" xref="S5.SS4.SSS1.p3.3.m3.1.1.cmml"><mi id="S5.SS4.SSS1.p3.3.m3.1.1.2" xref="S5.SS4.SSS1.p3.3.m3.1.1.2.cmml">x</mi><mo id="S5.SS4.SSS1.p3.3.m3.1.1.1" xref="S5.SS4.SSS1.p3.3.m3.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p3.3.m3.1b"><apply id="S5.SS4.SSS1.p3.3.m3.1.1.cmml" xref="S5.SS4.SSS1.p3.3.m3.1.1"><ci id="S5.SS4.SSS1.p3.3.m3.1.1.1.cmml" xref="S5.SS4.SSS1.p3.3.m3.1.1.1">~</ci><ci id="S5.SS4.SSS1.p3.3.m3.1.1.2.cmml" xref="S5.SS4.SSS1.p3.3.m3.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p3.3.m3.1c">\tilde{x}</annotation></semantics></math>의 수치 차이로 계산된다. 범위 매개 변수 <math alttext="\alpha" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p3.4.m4.1"><semantics id="S5.SS4.SSS1.p3.4.m4.1a"><mi id="S5.SS4.SSS1.p3.4.m4.1.1" xref="S5.SS4.SSS1.p3.4.m4.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p3.4.m4.1b"><ci id="S5.SS4.SSS1.p3.4.m4.1.1.cmml" xref="S5.SS4.SSS1.p3.4.m4.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p3.4.m4.1c">\alpha</annotation></semantics></math> 및 <math alttext="\beta" class="ltx_Math" display="inline" id="S5.SS4.SSS1.p3.5.m5.1"><semantics id="S5.SS4.SSS1.p3.5.m5.1a"><mi id="S5.SS4.SSS1.p3.5.m5.1.1" xref="S5.SS4.SSS1.p3.5.m5.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p3.5.m5.1b"><ci id="S5.SS4.SSS1.p3.5.m5.1.1.cmml" xref="S5.SS4.SSS1.p3.5.m5.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p3.5.m5.1c">\beta</annotation></semantics></math>는 양자화 성능에 큰 영향을 미치며, 이는 종종 실제 데이터 분포에 따라 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS1.p3.5.2">calibrated</em>일 필요가 있으며, <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS1.p3.5.3">static</em> (오프라인) 또는 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS1.p3.5.4">dynamic</em> 방식(런타임) 중 하나이다.</p>
</div>
<div id="S5.SS4.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS1.p4.1">자세한 내용은 신경망에서 양자화 방법에 대한 우수한 조사 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib412" title="">412</a>]</cite>를 참조한다.</p>
</div>
</section>
<section id="S5.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.2 </span>Quantization Methods for LLMs</h4>

<div id="S5.SS4.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS2.p1.1">일반적으로 두 가지 주요 모델 양자화 접근법, 즉 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p1.1.1">quantization-aware training (QAT)</em>>(requiring additional full model retraining) 및 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p1.1.2">post-training quantization (PTQ)</em>(requires no model retraining)이 있다. 작은 크기의 언어 모델과 비교할 때 LLM에 대한 양자화 방법을 설계하거나 선택할 때 두 가지 주요 차이점을 고려해야 한다. 첫째, LLM은 매우 많은 수의 파라미터로 구성되며, 따라서 PTQ 방법은 QAT 방법보다 훨씬 낮은 계산 비용으로 인해 더 선호된다. 둘째, LLMs은 매우 다른 활성화 패턴(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p1.1.3">i.e.,</em> 큰 이상치 특징)을 나타내며, LLMs, 특히 숨겨진 활성화를 양자화하는 것이 더 어려워진다. 다음으로, LLMs에 대한 몇 가지 대표적인 PTQ 방법<span class="ltx_note ltx_role_footnote" id="footnote37"><sup class="ltx_note_mark">37</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">37</sup><span class="ltx_tag ltx_tag_note">37</span>Since we mainly focus on discussing quantization methods in the context of LLMs, the line of quantization work on small-sized language models (<em class="ltx_emph ltx_font_italic" id="footnote37.1">e.g.,</em> BERT) has not been included in this survey. </span></span></span>에 대해 간략히 살펴보기로 한다.</p>
</div>
<div id="S5.SS4.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.SSS2.p2.1.1">Post-Training Quantization (PTQ)</span>. 먼저 LLM에 대한 PTQ 방법을 소개한다.</p>
</div>
<div id="S5.SS4.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p3.1.m1.1"><semantics id="S5.SS4.SSS2.p3.1.m1.1a"><mo id="S5.SS4.SSS2.p3.1.m1.1.1" xref="S5.SS4.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p3.1.m1.1b"><ci id="S5.SS4.SSS2.p3.1.m1.1.1.cmml" xref="S5.SS4.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p3.1.1">Mixed-precision decomposition</em>. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib413" title="">413</a>]</cite>에서 관찰된 바와 같이, 모델 크기가 6.7B 매개 변수 이상에 도달하면 숨겨진 활성화(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p3.1.2">outliers의 출현</em>이라고 함)에서 극단적인 큰 값이 발생한다. 흥미롭게도 이러한 특이치는 주로 트랜스포머 계층에서 특정 피쳐 치수에 분포합니다. 이 결과를 바탕으로 벡터 단위 양자화 기법인 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p3.1.3">LLM.int8()</em>은 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib413" title="">413</a>]</cite>에서 제안되었으며, 이는 행렬 곱셈에서 특징 차원과 나머지 차원을 특이치로 분리한다. 그런 다음 두 부분에 대한 계산을 각각 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p3.1.4">16비트 부동 숫자</em> 및 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p3.1.5">8비트 정수</em>로 수행하여 이러한 이상치를 높은 정밀도로 복구한다.</p>
</div>
<div id="S5.SS4.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p4.1.m1.1"><semantics id="S5.SS4.SSS2.p4.1.m1.1a"><mo id="S5.SS4.SSS2.p4.1.m1.1.1" xref="S5.SS4.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p4.1.m1.1b"><ci id="S5.SS4.SSS2.p4.1.m1.1.1.cmml" xref="S5.SS4.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p4.1.1">Fine-grained quantization</em>. 트랜스포머 모델의 경우 가중치 및 활성화는 일반적으로 텐서의 형태로 표현된다. 간단한 방법은 전체 텐서(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p4.1.2">i.e.,</em> per-tensor quantization) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib414" title="">414</a>]</cite>에 대해 coarse-grained 양자화 매개 변수를 사용하는 것이다. 그러나, 이는 일반적으로 부정확한 재구성 결과를 초래한다. 따라서 양자화 오차를 줄이기 위해 세밀한 방법을 제안한다. ZeroQuant<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib415" title="">415</a>]</cite>는 활성화 압축을 위한 동적 캘리브레이션을 갖는 토큰-와이즈 양자화 접근법을 채택한다. 가중치(양자화되기 쉬움)에 대해서는 그룹 단위 양자화를 사용한다. 실제로 128<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib415" title="">415</a>, <a class="ltx_ref" href="#bib.bib416" title="">416</a>]</cite>의 그룹 크기가 모델 양자화에 일반적으로 사용된다.</p>
</div>
<div id="S5.SS4.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS2.p5.6"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p5.1.m1.1"><semantics id="S5.SS4.SSS2.p5.1.m1.1a"><mo id="S5.SS4.SSS2.p5.1.m1.1.1" xref="S5.SS4.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p5.1.m1.1b"><ci id="S5.SS4.SSS2.p5.1.m1.1.1.cmml" xref="S5.SS4.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p5.6.1">Balancing the quantization difficulty</em>. 가중치가 활성화보다 양자화하기 쉽다는 점을 고려하여 SmoothQuant <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib414" title="">414</a>]</cite>는 활성화에서 가중치로 난이도를 마이그레이션할 것을 제안한다. 특히, 선형 계층에서 가중치와 활성화 사이의 난이도 균형을 맞추기 위해 스케일링 변환을 통합한다: <math alttext="\mathbf{Y}=(\mathbf{X}\text{diag}(\mathbf{s})^{-1})\cdot(\text{diag}(\mathbf{s})\mathbf{W})" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p5.2.m2.4"><semantics id="S5.SS4.SSS2.p5.2.m2.4a"><mrow id="S5.SS4.SSS2.p5.2.m2.4.4" xref="S5.SS4.SSS2.p5.2.m2.4.4.cmml"><mi id="S5.SS4.SSS2.p5.2.m2.4.4.4" xref="S5.SS4.SSS2.p5.2.m2.4.4.4.cmml">𝐘</mi><mo id="S5.SS4.SSS2.p5.2.m2.4.4.3" xref="S5.SS4.SSS2.p5.2.m2.4.4.3.cmml">=</mo><mrow id="S5.SS4.SSS2.p5.2.m2.4.4.2" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.cmml"><mrow id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.cmml"><mo id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.2" stretchy="false" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.cmml">(</mo><mrow id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.cmml"><mi id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.2" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.2.cmml">𝐗</mi><mo id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.1" lspace="0em" rspace="0em" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.1.cmml">​</mo><mtext id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.3" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.3a.cmml">diag</mtext><mo id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.1a" lspace="0em" rspace="0em" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.1.cmml">​</mo><msup id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.cmml"><mrow id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.2.2" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.cmml"><mo id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.2.2.1" stretchy="false" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.cmml">(</mo><mi id="S5.SS4.SSS2.p5.2.m2.1.1" xref="S5.SS4.SSS2.p5.2.m2.1.1.cmml">𝐬</mi><mo id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.2.2.2" stretchy="false" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.cmml">)</mo></mrow><mrow id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3.cmml"><mo id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3a" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3.cmml">−</mo><mn id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3.2" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3.2.cmml">1</mn></mrow></msup></mrow><mo id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.3" rspace="0.055em" stretchy="false" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.cmml">)</mo></mrow><mo id="S5.SS4.SSS2.p5.2.m2.4.4.2.3" rspace="0.222em" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.3.cmml">⋅</mo><mrow id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.cmml"><mo id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.2" stretchy="false" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.cmml">(</mo><mrow id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.cmml"><mtext id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.2" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.2a.cmml">diag</mtext><mo id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.1" lspace="0em" rspace="0em" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.1.cmml">​</mo><mrow id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.3.2" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.cmml"><mo id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.3.2.1" stretchy="false" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.cmml">(</mo><mi id="S5.SS4.SSS2.p5.2.m2.2.2" xref="S5.SS4.SSS2.p5.2.m2.2.2.cmml">𝐬</mi><mo id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.3.2.2" stretchy="false" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.cmml">)</mo></mrow><mo id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.1a" lspace="0em" rspace="0em" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.1.cmml">​</mo><mi id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.4" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.4.cmml">𝐖</mi></mrow><mo id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.3" stretchy="false" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p5.2.m2.4b"><apply id="S5.SS4.SSS2.p5.2.m2.4.4.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4"><eq id="S5.SS4.SSS2.p5.2.m2.4.4.3.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4.3"></eq><ci id="S5.SS4.SSS2.p5.2.m2.4.4.4.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4.4">𝐘</ci><apply id="S5.SS4.SSS2.p5.2.m2.4.4.2.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4.2"><ci id="S5.SS4.SSS2.p5.2.m2.4.4.2.3.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.3">⋅</ci><apply id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.cmml" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1"><times id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.1.cmml" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.1"></times><ci id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.2.cmml" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.2">𝐗</ci><ci id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.3a.cmml" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.3"><mtext id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.3.cmml" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.3">diag</mtext></ci><apply id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.cmml" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4"><csymbol cd="ambiguous" id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.1.cmml" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4">superscript</csymbol><ci id="S5.SS4.SSS2.p5.2.m2.1.1.cmml" xref="S5.SS4.SSS2.p5.2.m2.1.1">𝐬</ci><apply id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3.cmml" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3"><minus id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3.1.cmml" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3"></minus><cn id="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3.2.cmml" type="integer" xref="S5.SS4.SSS2.p5.2.m2.3.3.1.1.1.1.4.3.2">1</cn></apply></apply></apply><apply id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1"><times id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.1.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.1"></times><ci id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.2a.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.2"><mtext id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.2.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.2">diag</mtext></ci><ci id="S5.SS4.SSS2.p5.2.m2.2.2.cmml" xref="S5.SS4.SSS2.p5.2.m2.2.2">𝐬</ci><ci id="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.4.cmml" xref="S5.SS4.SSS2.p5.2.m2.4.4.2.2.1.1.4">𝐖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p5.2.m2.4c">\mathbf{Y}=(\mathbf{X}\text{diag}(\mathbf{s})^{-1})\cdot(\text{diag}(\mathbf{s})\mathbf{W})</annotation></semantics></math>. 수학적으로 동등한 변환을 도입함으로써, 이 공식은 스케일링 팩터 <math alttext="\mathbf{s}" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p5.3.m3.1"><semantics id="S5.SS4.SSS2.p5.3.m3.1a"><mi id="S5.SS4.SSS2.p5.3.m3.1.1" xref="S5.SS4.SSS2.p5.3.m3.1.1.cmml">𝐬</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p5.3.m3.1b"><ci id="S5.SS4.SSS2.p5.3.m3.1.1.cmml" xref="S5.SS4.SSS2.p5.3.m3.1.1">𝐬</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p5.3.m3.1c">\mathbf{s}</annotation></semantics></math>를 통해 양자화 난이도를 제어한다. <math alttext="\mathbf{s}" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p5.4.m4.1"><semantics id="S5.SS4.SSS2.p5.4.m4.1a"><mi id="S5.SS4.SSS2.p5.4.m4.1.1" xref="S5.SS4.SSS2.p5.4.m4.1.1.cmml">𝐬</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p5.4.m4.1b"><ci id="S5.SS4.SSS2.p5.4.m4.1.1.cmml" xref="S5.SS4.SSS2.p5.4.m4.1.1">𝐬</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p5.4.m4.1c">\mathbf{s}</annotation></semantics></math>를 설정하기 위해, 마이그레이션 강도 파라미터 <math alttext="\alpha" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p5.5.m5.1"><semantics id="S5.SS4.SSS2.p5.5.m5.1a"><mi id="S5.SS4.SSS2.p5.5.m5.1.1" xref="S5.SS4.SSS2.p5.5.m5.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p5.5.m5.1b"><ci id="S5.SS4.SSS2.p5.5.m5.1.1.cmml" xref="S5.SS4.SSS2.p5.5.m5.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p5.5.m5.1c">\alpha</annotation></semantics></math>를 통합하여 어려움의 균형을 맞추며, 여기서 각 엔트리 <math alttext="s_{j}=\max(\mathbf{x}_{j})^{\alpha}/\max(\mathbf{w}_{j})^{(1-\alpha)}" class="ltx_math_unparsed" display="inline" id="S5.SS4.SSS2.p5.6.m6.2"><semantics id="S5.SS4.SSS2.p5.6.m6.2a"><mrow id="S5.SS4.SSS2.p5.6.m6.2b"><msub id="S5.SS4.SSS2.p5.6.m6.2.3"><mi id="S5.SS4.SSS2.p5.6.m6.2.3.2">s</mi><mi id="S5.SS4.SSS2.p5.6.m6.2.3.3">j</mi></msub><mo id="S5.SS4.SSS2.p5.6.m6.2.4">=</mo><mi id="S5.SS4.SSS2.p5.6.m6.2.2">max</mi><msup id="S5.SS4.SSS2.p5.6.m6.2.5"><mrow id="S5.SS4.SSS2.p5.6.m6.2.5.2"><mo id="S5.SS4.SSS2.p5.6.m6.2.5.2.1" stretchy="false">(</mo><msub id="S5.SS4.SSS2.p5.6.m6.2.5.2.2"><mi id="S5.SS4.SSS2.p5.6.m6.2.5.2.2.2">𝐱</mi><mi id="S5.SS4.SSS2.p5.6.m6.2.5.2.2.3">j</mi></msub><mo id="S5.SS4.SSS2.p5.6.m6.2.5.2.3" stretchy="false">)</mo></mrow><mi id="S5.SS4.SSS2.p5.6.m6.2.5.3">α</mi></msup><mo id="S5.SS4.SSS2.p5.6.m6.2.6">/</mo><mi id="S5.SS4.SSS2.p5.6.m6.2.7">max</mi><msup id="S5.SS4.SSS2.p5.6.m6.2.8"><mrow id="S5.SS4.SSS2.p5.6.m6.2.8.2"><mo id="S5.SS4.SSS2.p5.6.m6.2.8.2.1" stretchy="false">(</mo><msub id="S5.SS4.SSS2.p5.6.m6.2.8.2.2"><mi id="S5.SS4.SSS2.p5.6.m6.2.8.2.2.2">𝐰</mi><mi id="S5.SS4.SSS2.p5.6.m6.2.8.2.2.3">j</mi></msub><mo id="S5.SS4.SSS2.p5.6.m6.2.8.2.3" stretchy="false">)</mo></mrow><mrow id="S5.SS4.SSS2.p5.6.m6.1.1.1.1"><mo id="S5.SS4.SSS2.p5.6.m6.1.1.1.1.2" stretchy="false">(</mo><mrow id="S5.SS4.SSS2.p5.6.m6.1.1.1.1.1"><mn id="S5.SS4.SSS2.p5.6.m6.1.1.1.1.1.2">1</mn><mo id="S5.SS4.SSS2.p5.6.m6.1.1.1.1.1.1">−</mo><mi id="S5.SS4.SSS2.p5.6.m6.1.1.1.1.1.3">α</mi></mrow><mo id="S5.SS4.SSS2.p5.6.m6.1.1.1.1.3" stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p5.6.m6.2c">s_{j}=\max(\mathbf{x}_{j})^{\alpha}/\max(\mathbf{w}_{j})^{(1-\alpha)}</annotation></semantics></math>는 마이그레이션 강도에 의해 결정된다.</p>
</div>
<div id="S5.SS4.SSS2.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS2.p6.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p6.1.m1.1"><semantics id="S5.SS4.SSS2.p6.1.m1.1a"><mo id="S5.SS4.SSS2.p6.1.m1.1.1" xref="S5.SS4.SSS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p6.1.m1.1b"><ci id="S5.SS4.SSS2.p6.1.m1.1.1.cmml" xref="S5.SS4.SSS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p6.2.1">Layerwise quantization</em>. 이 접근법은 계층별 재구성 손실을 최소화하는 최적의 양자화된 가중치: <math alttext="\arg\min_{\widehat{\mathbf{W}}}\parallel\mathbf{W}\mathbf{X}-\widehat{\mathbf{W}}\mathbf{X}\parallel_{2}^{2}" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p6.2.m2.1"><semantics id="S5.SS4.SSS2.p6.2.m2.1a"><mrow id="S5.SS4.SSS2.p6.2.m2.1.1" xref="S5.SS4.SSS2.p6.2.m2.1.1.cmml"><mi id="S5.SS4.SSS2.p6.2.m2.1.1.2" xref="S5.SS4.SSS2.p6.2.m2.1.1.2.cmml">arg</mi><mo id="S5.SS4.SSS2.p6.2.m2.1.1a" lspace="0.167em" xref="S5.SS4.SSS2.p6.2.m2.1.1.cmml">⁡</mo><mrow id="S5.SS4.SSS2.p6.2.m2.1.1.1" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.cmml"><msub id="S5.SS4.SSS2.p6.2.m2.1.1.1.2" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2.cmml"><mi id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.2" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2.2.cmml">min</mi><mover accent="true" id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.cmml"><mi id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.2" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.2.cmml">𝐖</mi><mo id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.1" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.1.cmml">^</mo></mover></msub><mo id="S5.SS4.SSS2.p6.2.m2.1.1.1a" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.cmml">⁡</mo><msubsup id="S5.SS4.SSS2.p6.2.m2.1.1.1.1" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.cmml"><mrow id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.2.cmml"><mo id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.2" stretchy="false" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.2" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.2.cmml">𝐖𝐗</mi><mo id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.1" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.2" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.2.cmml">𝐖</mi><mo id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.1" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mo id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.1" lspace="0em" rspace="0em" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.3" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.3.cmml">𝐗</mi></mrow></mrow><mo id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.3" stretchy="false" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.3" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.3.cmml">2</mn><mn id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.3" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.3.cmml">2</mn></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p6.2.m2.1b"><apply id="S5.SS4.SSS2.p6.2.m2.1.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1"><arg id="S5.SS4.SSS2.p6.2.m2.1.1.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.2"></arg><apply id="S5.SS4.SSS2.p6.2.m2.1.1.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1"><apply id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2">subscript</csymbol><min id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2.2"></min><apply id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3"><ci id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.1">^</ci><ci id="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.2.3.2">𝐖</ci></apply></apply><apply id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1">superscript</csymbol><apply id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1">subscript</csymbol><apply id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1"><minus id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.1"></minus><ci id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.2">𝐖𝐗</ci><apply id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3"><times id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.1"></times><apply id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2"><ci id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.1">^</ci><ci id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.2.2">𝐖</ci></apply><ci id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.1.1.1.3.3">𝐗</ci></apply></apply></apply><cn id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.3.cmml" type="integer" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.1.3">2</cn></apply><cn id="S5.SS4.SSS2.p6.2.m2.1.1.1.1.3.cmml" type="integer" xref="S5.SS4.SSS2.p6.2.m2.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p6.2.m2.1c">\arg\min_{\widehat{\mathbf{W}}}\parallel\mathbf{W}\mathbf{X}-\widehat{\mathbf{W}}\mathbf{X}\parallel_{2}^{2}</annotation></semantics></math>를 찾는다. 이 목적을 효율적으로 최적화하기 위해 GPTQ<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib417" title="">417</a>]</cite>는 모든 행에 대한 가중치의 양자화 순서를 고정하여 원래의 최적 브레인 양자화(OBQ)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib418" title="">418</a>]</cite> 방법을 개선한다. 또한 특별히 설계된 방법(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p6.2.2">i.e.,</em> lazy batch-updates and Cholesky reformulation)으로 GPTQ는 매우 큰 모델(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p6.2.3">e.g.,</em>175B OPT)을 3 또는 4 비트 정밀도로 양자화할 수 있다. 보다 최근에, AWQ<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib416" title="">416</a>]</cite>는 가중치에 대한 활성화 인식 스케일링을 통합함으로써 최적화 형태를 더욱 단순화하는데, 이는 SmoothQuant<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib414" title="">414</a>]</cite>의 아이디어와 유사하다: 이상치 활성화에 대응하는 가중치는 정밀하게 양자화되는 것이 더 중요하다. 이것은 재구성 손실을 직접 최적화하는 것이 아니라, 대신에 교정 데이터에 대한 최소 손실을 달성하기 위해 간단한 하이퍼-파라미터 탐색을 수행한다.</p>
</div>
<div id="S5.SS4.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS2.p7.1">상기 방법들에서의 이러한 전략들은 양자화 성능을 향상시키기 위해 공동으로 사용될 수 있다. 고효율 구현을 달성하기 위해, 양자화 방법들은 또한 하드웨어- 또는 시스템-레벨 지원에 의존한다(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p7.1.1">e.g.,</em> efficient GPU 커널들 또는 하드웨어-friendly group partition).</p>
</div>
<div id="S5.SS4.SSS2.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.SSS2.p8.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.SSS2.p8.1.1">Other Quantization Methods</span>. 위에서 우리는 주로 PTQ 방법에 초점을 맞추고 다음으로 LLM을 쿼니타이징하기 위한 효율적인 미세 조정 방법 또는 QAT 방법을 탐구하는 두 가지 최근 연구를 소개한다.</p>
</div>
<div id="S5.SS4.SSS2.p9" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS2.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p9.1.m1.1"><semantics id="S5.SS4.SSS2.p9.1.m1.1a"><mo id="S5.SS4.SSS2.p9.1.m1.1.1" xref="S5.SS4.SSS2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p9.1.m1.1b"><ci id="S5.SS4.SSS2.p9.1.m1.1.1.cmml" xref="S5.SS4.SSS2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p9.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p9.1.1">Efficient fine-tuning enhanced quantization. </em> 훈련 후 양자화의 경우, 직접 저비트 양자화(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p9.1.2">e.g.,</em> INT4 양자화)는 종종 큰 성능 저하를 초래한다. 이러한 문제를 해결하기 위해 QLoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib419" title="">419</a>]</cite>는 양자화된 모델에 추가적인 작은 조정 가능한 어댑터(16비트 정밀도)를 통합하여 효율적이고 고정밀 모델 미세 조정을 달성한다. LoRA의 장점(섹션<a class="ltx_ref" href="#S5.SS3.SSS1" title="5.3.1 Parameter-Efficient Fine-Tuning Methods ‣ 5.3 Parameter-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.3.1</span></a> 참조)과 양자화 방법을 결합한다. 실험 결과, 4-비트 양자화 모델은 QLoRA에 의해 전체 16-비트 미세 조정 성능을 얻을 수 있음을 보였다.</p>
</div>
<div id="S5.SS4.SSS2.p10" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS2.p10.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS2.p10.1.m1.1"><semantics id="S5.SS4.SSS2.p10.1.m1.1a"><mo id="S5.SS4.SSS2.p10.1.m1.1.1" xref="S5.SS4.SSS2.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p10.1.m1.1b"><ci id="S5.SS4.SSS2.p10.1.m1.1.1.cmml" xref="S5.SS4.SSS2.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p10.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS2.p10.1.1">Quantization-aware training (QAT) for LLMs</em>. 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib420" title="">420</a>]</cite>는 데이터 프리 증류 방법을 적용하여 가중치, 활성화 및 키-값 캐시를 압축함으로써 QAT 방법의 효과를 탐구한다. LLaMA를 기반으로 광범위한 실험을 수행하여 가중치 및 키-값 캐시 모두에서 4비트 양자화를 통해 유망한 결과를 보여주었지만, 여전히 더 많은 탐색이 필요한 4비트 활성화 양자화에서는 그렇지 않았다.</p>
</div>
</section>
<section id="S5.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.3 </span>Empirical Analysis and Findings</h4>

<div id="S5.SS4.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS3.p1.1">양자화는 현재 배포에서 LLM의 메모리 풋프린트 및 대기 시간을 줄이기 위한 일반적인 기술이 되었다. 특히, 높은 정확도를 유지하면서, LLMs의 상이한 부분들(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p1.1.1">e.g.,</em> INT8 또는 INT4)을 양자화하기 위해 어떤 수준의 정밀도(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p1.1.2">e.g.,</em> 가중치들 또는 활성화들)를 적용할 수 있는지를 이해하는 것이 중요하다. 이 부분에서는 먼저 기존 문헌에서 LLM의 양자화에 대한 주요 결과를 요약한 다음 양자화 실험을 통해 몇 가지 경험적 분석을 제시한다.</p>
</div>
<div id="S5.SS4.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.SSS3.p2.1.1">Important Findings from Existing Work</span>. 최근 여러 요인(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p2.1.2">e.g.,</em> 모델 크기 및 민감도)이 훈련 후 양자화 방법에 미치는 영향에 대해 매우 포괄적인 평가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib421" title="">421</a>]</cite>가 수행되었다. 또 다른 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib422" title="">422</a>]</cite>는 추론 성능에서 <math alttext="k" class="ltx_Math" display="inline" id="S5.SS4.SSS3.p2.1.m1.1"><semantics id="S5.SS4.SSS3.p2.1.m1.1a"><mi id="S5.SS4.SSS3.p2.1.m1.1.1" xref="S5.SS4.SSS3.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS3.p2.1.m1.1b"><ci id="S5.SS4.SSS3.p2.1.m1.1.1.cmml" xref="S5.SS4.SSS3.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS3.p2.1.m1.1c">k</annotation></semantics></math>-비트 양자화의 스케일링 법칙을 살펴본다. 전체 성능 외에도, 연구<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib423" title="">423</a>]</cite>는 특히 다양한 수준의 비트 정밀도에 걸쳐 달성할 수 있는 성능 수준뿐만 아니라 정량화가 창발 능력에 미치는 잠재적 영향에 초점을 맞춘다. 또한 이전 작업(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p2.1.3">e.g.,</em> LLM.int8() <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib424" title="">424</a>]</cite>, GPTQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib417" title="">417</a>]</cite>, QLoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib419" title="">419</a>]</cite>, GLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>)도 다양한 설정에서 양자화 방법의 성능을 광범위하게 조사했다. 다음으로, 양자화 방법의 기술적 세부 사항을 파고들지 않을 수 있는 사람들에게 유용할 이러한 연구의 몇 가지 중요한 결과를 요약한다.</p>
</div>
<div id="S5.SS4.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS3.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS3.p3.1.m1.1"><semantics id="S5.SS4.SSS3.p3.1.m1.1a"><mo id="S5.SS4.SSS3.p3.1.m1.1.1" xref="S5.SS4.SSS3.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS3.p3.1.m1.1b"><ci id="S5.SS4.SSS3.p3.1.m1.1.1.cmml" xref="S5.SS4.SSS3.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS3.p3.1.m1.1c">\bullet</annotation></semantics></math><em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p3.1.1">INT8 가중치 양자화는 종종 LLMs에서 매우 양호한 결과를 산출할 수 있는 반면, 더 낮은 정밀도 가중치 양자화의 성능은 특정 방법</em><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib421" title="">421</a>, <a class="ltx_ref" href="#bib.bib414" title="">414</a>, <a class="ltx_ref" href="#bib.bib417" title="">417</a>, <a class="ltx_ref" href="#bib.bib416" title="">416</a>]</cite>에 의존한다. 대부분의 경우, INT8 가중치 양자화는 성능 저하 없이 메모리 풋프린트를 감소시키기 위해 효과적으로 적용될 수 있다. INT4 (또는 INT3) 가중치 양자화의 경우 기존 방법은 성능 저하를 줄이기 위해 특정 전략에 의존하지만, <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p3.1.2">e.g.,</em> layerwise method <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib417" title="">417</a>, <a class="ltx_ref" href="#bib.bib415" title="">415</a>]</cite>, activation-aware scaling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib416" title="">416</a>]</cite> and low-rank adapter tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib419" title="">419</a>]</cite>. 흥미롭게도 LLMs는 작은 크기의 언어 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib421" title="">421</a>]</cite>보다 낮은 비트 가중치 양자화에 덜 민감한 것으로 보인다. 실제로, 동일한 메모리 비용으로, 더 높은 양자화 정밀도를 갖는 더 작은 언어 모델보다는 더 낮은 양자화 정밀도를 갖는 더 큰 언어 모델을 사용하는 것이 제안된다. 예를 들어, 4-비트 60GB LLM은 8-비트 30GB LLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib422" title="">422</a>]</cite>보다 더 나은 성능을 갖는 것으로 입증된다. 또한, 창발적 기능에 초점을 맞추어, 연구<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib423" title="">423</a>]</cite>는 4비트 가중치 양자화에 의해 상황 내 학습, 단계별 추론 및 후속 명령이 거의 영향을 받지 않는 것으로 보인다. 이 결과는 INT4 양자화가 전체 비트 수와 창발 능력의 성능 면에서 유리한 트레이드오프를 나타낸다는 것을 시사한다.</p>
</div>
<div id="S5.SS4.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS3.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS3.p4.1.m1.1"><semantics id="S5.SS4.SSS3.p4.1.m1.1a"><mo id="S5.SS4.SSS3.p4.1.m1.1.1" xref="S5.SS4.SSS3.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS3.p4.1.m1.1b"><ci id="S5.SS4.SSS3.p4.1.m1.1.1.cmml" xref="S5.SS4.SSS3.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS3.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p4.1.1">Activations is more difficult to be quantized than weights</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib421" title="">421</a>, <a class="ltx_ref" href="#bib.bib413" title="">413</a>, <a class="ltx_ref" href="#bib.bib414" title="">414</a>]</cite>. 6.7B 이상의 크기를 가진 Transformer 언어 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib413" title="">413</a>]</cite>에 대해 큰 이상치가 발생하는 것으로 나타났다. 이 문제는 LLM을 양자화하는 데 가장 근본적인 어려움 중 하나였다. 이를 극복하기 위해 다양한 방법인 <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p4.1.2">e.g.,</em> mixed-precision decomposition <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib413" title="">413</a>]</cite>, fine-grained quantization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib425" title="">425</a>, <a class="ltx_ref" href="#bib.bib413" title="">413</a>]</cite> and difficulty migration <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib414" title="">414</a>]</cite>를 적용하여 이상치 값의 영향을 완화할 수 있다. LLM의 활성화에는 주로 큰 이상치가 존재하기 때문에 작은 언어 모델은 활성화 양자화<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib421" title="">421</a>, <a class="ltx_ref" href="#bib.bib423" title="">423</a>]</cite>에 더 내성이 있다. 실제로 고품질 INT8 활성화 양자화는 여러 방법이 만족스러운 결과를 얻을 수 있지만 여전히 어려운 작업이다. 또한, 더 낮은 정밀도 활성화 양자화는 QAT 방법들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib420" title="">420</a>]</cite>에 대해서도 여전히 성공적으로 탐색되지 않았다.</p>
</div>
<div id="S5.SS4.SSS3.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS3.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS3.p5.1.m1.1"><semantics id="S5.SS4.SSS3.p5.1.m1.1a"><mo id="S5.SS4.SSS3.p5.1.m1.1.1" xref="S5.SS4.SSS3.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS3.p5.1.m1.1b"><ci id="S5.SS4.SSS3.p5.1.m1.1.1.cmml" xref="S5.SS4.SSS3.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS3.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p5.1.1">Efficient fine-tuning enhanced quantization is a good option to enhance the performance of quantized LLMs</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib419" title="">419</a>, <a class="ltx_ref" href="#bib.bib145" title="">145</a>]</cite>. 양자화에서 효율적인 펀튜닝 방법의 이점은 두 가지일 수 있다. 첫째, 고정밀 어댑터를 업데이트하여 피팅 용량을 증가시킴으로써 저비트 양자화 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib421" title="">421</a>, <a class="ltx_ref" href="#bib.bib423" title="">423</a>]</cite>로 인한 성능 저하를 직접 보상할 수 있다. 둘째, 작은 어댑터만 튜닝하면 LLM의 작업별 또는 목표별 미세 조정을 경량화 방식으로 지원할 수 있다. 전반적으로 효율성과 훈련 비용 사이의 좋은 트레이드오프를 만들어 양자화된 LLM의 성능을 향상시키는 유망한 접근법을 제공한다.</p>
</div>
<div id="S5.SS4.SSS3.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.SSS3.p6.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.SSS3.p6.1.1">Empirical Analysis on Quantization Experiments</span>. 독자들이 LLM에 대한 양자화의 영향을 이해하는 데 더 도움이 되도록 여기에서 양자화된 모델의 추론 성능을 조사하기 위한 실험 그룹도 수행한다. 구체적으로 FLAN-v2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>, Alpaca-52K <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib137" title="">137</a>]</cite> 및 ShareGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>를 포함한 인기 있는 SFT 데이터셋을 사용하여 미세 조정된 LLaMA 모델(<em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS3.p6.1.2">i.e.,</em> 7B 및 13B)에 초점을 맞춘다. 평가를 위해 표 <a class="ltx_ref" href="#S5.T9" title="TABLE IX ‣ 5.1.3 The Effect of Instruction Tuning ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">IX</span></a>에서 동일한 작업을 활용하고 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib423" title="">423</a>]</cite>에서 양자화 설정을 따라 4비트, 8비트, 16비트의 세 가지 정밀도 수준에서 양자화된 언어 모델의 성능을 조사한다. 결과는 표 <a class="ltx_ref" href="#S5.T10" title="TABLE X ‣ 5.4.3 Empirical Analysis and Findings ‣ 5.4 Memory-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">X</span></a>에 요약되어 있다. 표 <a class="ltx_ref" href="#S5.T10" title="TABLE X ‣ 5.4.3 Empirical Analysis and Findings ‣ 5.4 Memory-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">X</span></a>로부터 알 수 있는 바와 같이, 8비트 및 4비트 가중치 양자화로 얻어진 결과는 메모리 소비를 상당히 감소시키면서 16비트 모델의 성능에 근접한다. 실제로 메모리 사용량을 줄이는 것이 배치에 중요한 고려 사항인 경우 LLM에 대한 4비트 가중치 양자화의 성능을 먼저 조사하는 것이 좋다.</p>
</div>
<figure id="S5.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE X:</span>Quantized LLaMA 모델(7B 및 13B)에 대한 평가 결과. FLAN-v2, Alpaca-52K 및 ShareGPT에서 각각 미세 조정된 양자화 실험을 위해 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib353" title="">353</a>]</cite>에서 제공하는 기존 모델 체크포인트를 사용한다. 구체적으로 AlpacaFarm, MMLU, BBH를 사용하여 성능 및 로드된 모델의 메모리 사용량을 보고한다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE X: </span>Evaluation results for quantized LLaMA models&nbsp;(7B and 13B). We employ existing model checkpoints provided by&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib353" title="" class="ltx_ref">353</a>]</cite> for quantization experiments, which have been fine-tuned on FLAN-v2, Alpaca-52K, and ShareGPT, respectively. Specifically, we report the performance with AlpacaFarm, MMLU, and BBH, as well as the memory usage of the loaded model&nbsp;(Mem.).
For quantization, we employ <em id="S5.T10.8.1" class="ltx_emph ltx_font_italic">bitesandbytes</em> to quantize the 16-bit models to 8/4 bits by specifying the commands <span id="S5.T10.9.2" class="ltx_text ltx_font_typewriter">load_in_8bit</span> and <span id="S5.T10.10.3" class="ltx_text ltx_font_typewriter">load_in_4bit</span> when loading the weights.
It is worth noting that we select&nbsp;<em id="S5.T10.11.4" class="ltx_emph ltx_font_italic">text-davinci-003</em> as the baseline model for the AlpacaFarm dataset.</figcaption>
<div id="S5.T10.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:867.2pt;height:170.6pt;vertical-align:-1.2pt;"><span class="ltx_transformed_inner" style="transform:translate(64.9pt,-12.7pt) scale(1.17612576102518,1.17612576102518) ;">
<table id="S5.T10.3.3" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S5.T10.3.3.4" class="ltx_tr">
<td id="S5.T10.3.3.4.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S5.T10.3.3.4.1.1" class="ltx_text ltx_font_bold">Models</span></td>
<td id="S5.T10.3.3.4.2" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S5.T10.3.3.4.2.1" class="ltx_text">
<span id="S5.T10.3.3.4.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T10.3.3.4.2.1.1.1" class="ltx_tr">
<span id="S5.T10.3.3.4.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T10.3.3.4.2.1.1.1.1.1" class="ltx_text ltx_font_bold">SFT Dataset</span></span></span>
</span></span></td>
<td id="S5.T10.3.3.4.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S5.T10.3.3.4.3.1" class="ltx_text ltx_font_bold">16-bit</span></td>
<td id="S5.T10.3.3.4.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S5.T10.3.3.4.4.1" class="ltx_text ltx_font_bold">8-bit</span></td>
<td id="S5.T10.3.3.4.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S5.T10.3.3.4.5.1" class="ltx_text ltx_font_bold">4-bit</span></td>
</tr>
<tr id="S5.T10.3.3.3" class="ltx_tr">
<td id="S5.T10.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">AlpacaFarm</td>
<td id="S5.T10.3.3.3.5" class="ltx_td ltx_align_center ltx_border_t">MMLU</td>
<td id="S5.T10.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t">BBH</td>
<td id="S5.T10.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">Mem.<sub id="S5.T10.1.1.1.1.1" class="ltx_sub">(GiB)</sub>
</td>
<td id="S5.T10.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t">AlpacaFarm</td>
<td id="S5.T10.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t">MMLU</td>
<td id="S5.T10.3.3.3.9" class="ltx_td ltx_align_center ltx_border_t">BBH</td>
<td id="S5.T10.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">Mem.<sub id="S5.T10.2.2.2.2.1" class="ltx_sub">(GiB)</sub>
</td>
<td id="S5.T10.3.3.3.10" class="ltx_td ltx_align_center ltx_border_t">AlpacaFarm</td>
<td id="S5.T10.3.3.3.11" class="ltx_td ltx_align_center ltx_border_t">MMLU</td>
<td id="S5.T10.3.3.3.12" class="ltx_td ltx_align_center ltx_border_t">BBH</td>
<td id="S5.T10.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">Mem.<sub id="S5.T10.3.3.3.3.1" class="ltx_sub">(GiB)</sub>
</td>
</tr>
<tr id="S5.T10.3.3.5" class="ltx_tr">
<td id="S5.T10.3.3.5.1" class="ltx_td ltx_align_left ltx_border_t">LLaMA&nbsp;(7B)</td>
<td id="S5.T10.3.3.5.2" class="ltx_td ltx_align_left ltx_border_t">FLAN-v2</td>
<td id="S5.T10.3.3.5.3" class="ltx_td ltx_align_center ltx_border_t">6.65</td>
<td id="S5.T10.3.3.5.4" class="ltx_td ltx_align_center ltx_border_t">47.34</td>
<td id="S5.T10.3.3.5.5" class="ltx_td ltx_align_center ltx_border_t">35.05</td>
<td id="S5.T10.3.3.5.6" class="ltx_td ltx_align_center ltx_border_t">12.58</td>
<td id="S5.T10.3.3.5.7" class="ltx_td ltx_align_center ltx_border_t">6.15</td>
<td id="S5.T10.3.3.5.8" class="ltx_td ltx_align_center ltx_border_t">47.02</td>
<td id="S5.T10.3.3.5.9" class="ltx_td ltx_align_center ltx_border_t">35.17</td>
<td id="S5.T10.3.3.5.10" class="ltx_td ltx_align_center ltx_border_t">6.65</td>
<td id="S5.T10.3.3.5.11" class="ltx_td ltx_align_center ltx_border_t">7.83</td>
<td id="S5.T10.3.3.5.12" class="ltx_td ltx_align_center ltx_border_t">46.23</td>
<td id="S5.T10.3.3.5.13" class="ltx_td ltx_align_center ltx_border_t">34.77</td>
<td id="S5.T10.3.3.5.14" class="ltx_td ltx_align_center ltx_border_t">3.94</td>
</tr>
<tr id="S5.T10.3.3.6" class="ltx_tr">
<td id="S5.T10.3.3.6.1" class="ltx_td"></td>
<td id="S5.T10.3.3.6.2" class="ltx_td ltx_align_left">Alpaca-52K</td>
<td id="S5.T10.3.3.6.3" class="ltx_td ltx_align_center">32.55</td>
<td id="S5.T10.3.3.6.4" class="ltx_td ltx_align_center">40.87</td>
<td id="S5.T10.3.3.6.5" class="ltx_td ltx_align_center">33.66</td>
<td id="S5.T10.3.3.6.6" class="ltx_td ltx_align_center">12.58</td>
<td id="S5.T10.3.3.6.7" class="ltx_td ltx_align_center">33.60</td>
<td id="S5.T10.3.3.6.8" class="ltx_td ltx_align_center">39.98</td>
<td id="S5.T10.3.3.6.9" class="ltx_td ltx_align_center">34.38</td>
<td id="S5.T10.3.3.6.10" class="ltx_td ltx_align_center">6.65</td>
<td id="S5.T10.3.3.6.11" class="ltx_td ltx_align_center">29.57</td>
<td id="S5.T10.3.3.6.12" class="ltx_td ltx_align_center">39.24</td>
<td id="S5.T10.3.3.6.13" class="ltx_td ltx_align_center">32.80</td>
<td id="S5.T10.3.3.6.14" class="ltx_td ltx_align_center">3.94</td>
</tr>
<tr id="S5.T10.3.3.7" class="ltx_tr">
<td id="S5.T10.3.3.7.1" class="ltx_td"></td>
<td id="S5.T10.3.3.7.2" class="ltx_td ltx_align_left">ShareGPT</td>
<td id="S5.T10.3.3.7.3" class="ltx_td ltx_align_center">72.05</td>
<td id="S5.T10.3.3.7.4" class="ltx_td ltx_align_center">41.30</td>
<td id="S5.T10.3.3.7.5" class="ltx_td ltx_align_center">32.90</td>
<td id="S5.T10.3.3.7.6" class="ltx_td ltx_align_center">12.58</td>
<td id="S5.T10.3.3.7.7" class="ltx_td ltx_align_center">72.86</td>
<td id="S5.T10.3.3.7.8" class="ltx_td ltx_align_center">39.34</td>
<td id="S5.T10.3.3.7.9" class="ltx_td ltx_align_center">32.71</td>
<td id="S5.T10.3.3.7.10" class="ltx_td ltx_align_center">6.65</td>
<td id="S5.T10.3.3.7.11" class="ltx_td ltx_align_center">70.31</td>
<td id="S5.T10.3.3.7.12" class="ltx_td ltx_align_center">40.08</td>
<td id="S5.T10.3.3.7.13" class="ltx_td ltx_align_center">32.11</td>
<td id="S5.T10.3.3.7.14" class="ltx_td ltx_align_center">3.94</td>
</tr>
<tr id="S5.T10.3.3.8" class="ltx_tr">
<td id="S5.T10.3.3.8.1" class="ltx_td ltx_align_left ltx_border_t">LLaMA&nbsp;(13B)</td>
<td id="S5.T10.3.3.8.2" class="ltx_td ltx_align_left ltx_border_t">FLAN-v2</td>
<td id="S5.T10.3.3.8.3" class="ltx_td ltx_align_center ltx_border_t">8.14</td>
<td id="S5.T10.3.3.8.4" class="ltx_td ltx_align_center ltx_border_t">51.67</td>
<td id="S5.T10.3.3.8.5" class="ltx_td ltx_align_center ltx_border_t">41.46</td>
<td id="S5.T10.3.3.8.6" class="ltx_td ltx_align_center ltx_border_t">24.40</td>
<td id="S5.T10.3.3.8.7" class="ltx_td ltx_align_center ltx_border_t">7.64</td>
<td id="S5.T10.3.3.8.8" class="ltx_td ltx_align_center ltx_border_t">51.02</td>
<td id="S5.T10.3.3.8.9" class="ltx_td ltx_align_center ltx_border_t">41.25</td>
<td id="S5.T10.3.3.8.10" class="ltx_td ltx_align_center ltx_border_t">12.53</td>
<td id="S5.T10.3.3.8.11" class="ltx_td ltx_align_center ltx_border_t">7.52</td>
<td id="S5.T10.3.3.8.12" class="ltx_td ltx_align_center ltx_border_t">50.48</td>
<td id="S5.T10.3.3.8.13" class="ltx_td ltx_align_center ltx_border_t">40.68</td>
<td id="S5.T10.3.3.8.14" class="ltx_td ltx_align_center ltx_border_t">7.34</td>
</tr>
<tr id="S5.T10.3.3.9" class="ltx_tr">
<td id="S5.T10.3.3.9.1" class="ltx_td"></td>
<td id="S5.T10.3.3.9.2" class="ltx_td ltx_align_left">Alpaca-52K</td>
<td id="S5.T10.3.3.9.3" class="ltx_td ltx_align_center">33.60</td>
<td id="S5.T10.3.3.9.4" class="ltx_td ltx_align_center">47.63</td>
<td id="S5.T10.3.3.9.5" class="ltx_td ltx_align_center">36.10</td>
<td id="S5.T10.3.3.9.6" class="ltx_td ltx_align_center">24.40</td>
<td id="S5.T10.3.3.9.7" class="ltx_td ltx_align_center">31.43</td>
<td id="S5.T10.3.3.9.8" class="ltx_td ltx_align_center">47.04</td>
<td id="S5.T10.3.3.9.9" class="ltx_td ltx_align_center">35.98</td>
<td id="S5.T10.3.3.9.10" class="ltx_td ltx_align_center">12.53</td>
<td id="S5.T10.3.3.9.11" class="ltx_td ltx_align_center">30.87</td>
<td id="S5.T10.3.3.9.12" class="ltx_td ltx_align_center">46.20</td>
<td id="S5.T10.3.3.9.13" class="ltx_td ltx_align_center">36.16</td>
<td id="S5.T10.3.3.9.14" class="ltx_td ltx_align_center">7.34</td>
</tr>
<tr id="S5.T10.3.3.10" class="ltx_tr">
<td id="S5.T10.3.3.10.1" class="ltx_td ltx_border_bb"></td>
<td id="S5.T10.3.3.10.2" class="ltx_td ltx_align_left ltx_border_bb">ShareGPT</td>
<td id="S5.T10.3.3.10.3" class="ltx_td ltx_align_center ltx_border_bb">75.59</td>
<td id="S5.T10.3.3.10.4" class="ltx_td ltx_align_center ltx_border_bb">47.58</td>
<td id="S5.T10.3.3.10.5" class="ltx_td ltx_align_center ltx_border_bb">38.00</td>
<td id="S5.T10.3.3.10.6" class="ltx_td ltx_align_center ltx_border_bb">24.40</td>
<td id="S5.T10.3.3.10.7" class="ltx_td ltx_align_center ltx_border_bb">73.79</td>
<td id="S5.T10.3.3.10.8" class="ltx_td ltx_align_center ltx_border_bb">47.71</td>
<td id="S5.T10.3.3.10.9" class="ltx_td ltx_align_center ltx_border_bb">38.31</td>
<td id="S5.T10.3.3.10.10" class="ltx_td ltx_align_center ltx_border_bb">12.53</td>
<td id="S5.T10.3.3.10.11" class="ltx_td ltx_align_center ltx_border_bb">71.99</td>
<td id="S5.T10.3.3.10.12" class="ltx_td ltx_align_center ltx_border_bb">45.77</td>
<td id="S5.T10.3.3.10.13" class="ltx_td ltx_align_center ltx_border_bb">36.97</td>
<td id="S5.T10.3.3.10.14" class="ltx_td ltx_align_center ltx_border_bb">7.34</td>
</tr>
</tbody></table>
</span></div>
</figure>
</section>
<section id="S5.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.4 </span>Open-source Libraries and Quantized LLMs</h4>

<div id="S5.SS4.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS4.p1.1">이 부분에서는 사용 가능한 오픈 소스 양자화 라이브러리와 양자화된 LLM에 대해 간략하게 소개한다.</p>
</div>
<div id="S5.SS4.SSS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.SSS4.p2.1.1">Quantization Libraries</span>. 다음으로 LLMs를 위한 세 가지 주요 양자화 라이브러리를 소개한다.</p>
</div>
<div id="S5.SS4.SSS4.p3" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS4.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS4.p3.1.m1.1"><semantics id="S5.SS4.SSS4.p3.1.m1.1a"><mo id="S5.SS4.SSS4.p3.1.m1.1.1" xref="S5.SS4.SSS4.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS4.p3.1.m1.1b"><ci id="S5.SS4.SSS4.p3.1.m1.1.1.cmml" xref="S5.SS4.SSS4.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS4.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS4.p3.1.1">Bitsandbytes</em><span class="ltx_note ltx_role_footnote" id="footnote38"><sup class="ltx_note_mark">38</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">38</sup><span class="ltx_tag ltx_tag_note">38</span>https://github.com/TimDettmers/bitsandbytes</span></span></span>은 LLM.int8() <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib413" title="">413</a>]</cite> 및 8비트 optimizers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib426" title="">426</a>]</cite>의 논문에 소개된 방법을 기반으로 개발되었다. 효율적인 추론을 위한 8-비트 및 4-비트 행렬 곱셈에 대한 지원과 효율적인 학습을 위한 8-비트 최적화기를 포함하여 LLM에 대한 활성화와 가중치의 양자화에 중점을 둔다.</p>
</div>
<div id="S5.SS4.SSS4.p4" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS4.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS4.p4.1.m1.1"><semantics id="S5.SS4.SSS4.p4.1.m1.1a"><mo id="S5.SS4.SSS4.p4.1.m1.1.1" xref="S5.SS4.SSS4.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS4.p4.1.m1.1b"><ci id="S5.SS4.SSS4.p4.1.m1.1.1.cmml" xref="S5.SS4.SSS4.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS4.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS4.p4.1.1">GPTQ-for-LLaMA</em><span class="ltx_note ltx_role_footnote" id="footnote39"><sup class="ltx_note_mark">39</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">39</sup><span class="ltx_tag ltx_tag_note">39</span>https://github.com/qwopqwop200/GPTQ-for-LLaMa</span></span></span>은 LLaMA 모델을 양자화하기 위해 특별히 개발되었다. GPTQ 알고리즘 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib417" title="">417</a>]</cite>를 기반으로 다양한 크기의 LLaMA 모델의 4비트 양자화를 가능하게 한다. 또한 프로젝트 웹 사이트의 메모리 및 성능(PPL) 모두에서 비트와 비교를 제공합니다.</p>
</div>
<div id="S5.SS4.SSS4.p5" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS4.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS4.p5.1.m1.1"><semantics id="S5.SS4.SSS4.p5.1.m1.1a"><mo id="S5.SS4.SSS4.p5.1.m1.1.1" xref="S5.SS4.SSS4.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS4.p5.1.m1.1b"><ci id="S5.SS4.SSS4.p5.1.m1.1.1.cmml" xref="S5.SS4.SSS4.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS4.p5.1.m1.1c">\bullet</annotation></semantics></math><em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS4.p5.1.1">AutoGPTQ</em><span class="ltx_note ltx_role_footnote" id="footnote40"><sup class="ltx_note_mark">40</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">40</sup><span class="ltx_tag ltx_tag_note">40</span>https://github.com/PanQiWei/AutoGPTQ</span></span></span>은 LLMs에 대한 INT4 양자화를 지원하는 GPTQ 알고리즘 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib417" title="">417</a>]</cite>를 기반으로 개발된 양자화 패키지이다. 라이브러리에 다수의 양자화된 모델을 포함하고 있으며, HuggingFace PEFT 라이브러리와 통합하여 LoRA를 지원한다.</p>
</div>
<div id="S5.SS4.SSS4.p6" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS4.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS4.SSS4.p6.1.m1.1"><semantics id="S5.SS4.SSS4.p6.1.m1.1a"><mo id="S5.SS4.SSS4.p6.1.m1.1.1" xref="S5.SS4.SSS4.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS4.p6.1.m1.1b"><ci id="S5.SS4.SSS4.p6.1.m1.1.1.cmml" xref="S5.SS4.SSS4.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS4.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S5.SS4.SSS4.p6.1.1">llama.cpp</em><span class="ltx_note ltx_role_footnote" id="footnote41"><sup class="ltx_note_mark">41</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">41</sup><span class="ltx_tag ltx_tag_note">41</span>https://github.com/ggerganov/llama.cpp</span></span></span>을 사용하면 맥북 장치에서 양자화된 LLaMA 모델을 실행할 수 있습니다. 효율적인 C/C++ 구현을 위해 개발된 INT4, INT5, INT8 양자화를 지원한다. 또한 알파카 및 비쿠나와 같은 여러 LLaMA 기반 모델을 지원합니다.</p>
</div>
<div id="S5.SS4.SSS4.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.SSS4.p7.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.SSS4.p7.1.1">Quantized LLMs</span>. 원본 모델과 비교하여 양자화된 언어 모델은 메모리 풋프린트가 더 작고, 추론 속도<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib413" title="">413</a>, <a class="ltx_ref" href="#bib.bib427" title="">427</a>, <a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>가 더 빠르다. 최근에는 BLOOM, GPT-J 및 ChatGLM을 포함하여 공개적으로 사용 가능한 여러 언어 모델의 양자화된 모델 사본이 HuggingFace에 출시되었다. 특히, GPTQ<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib417" title="">417</a>]</cite>는 생성 언어 모델을 양자화하는 데 널리 사용되어 LLaMA 및 OPT에 대한 다양한 양자화된 변형으로 이어졌다. 또한, 비쿠나 및 위저드LM과 같은 명령어 조정 모델을 양자화하는 데에도 적용되었다. 양자화된 LLM의 수가 많기 때문에 이러한 모델의 해당 링크를 직접 통합하지 않는다. 독자들은 HuggingFace를 검색하면 쉽게 찾을 수 있습니다.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Utilization</span>
</h2>

<figure id="S6.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE XI:</span>전형적인 LLM 활용 방법 및 ICL, CoT, 및 계획에 대한 그들의 핵심 포인트. 핵심 사항은 가장 중요한 기술적 기여만 강조한다는 점에 유의하십시오.</figcaption>
<div id="S6.T11.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:240.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-205.0pt,113.7pt) scale(0.513957070579328,0.513957070579328) ;">
<table id="S6.T11.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S6.T11.1.1.1" class="ltx_tr">
<td id="S6.T11.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S6.T11.1.1.1.1.1" class="ltx_text ltx_font_bold">Approach</span></td>
<td id="S6.T11.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S6.T11.1.1.1.2.1" class="ltx_text ltx_font_bold">Representative Work</span></td>
<td id="S6.T11.1.1.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S6.T11.1.1.1.3.1" class="ltx_text ltx_font_bold">Key Point</span></td>
</tr>
<tr id="S6.T11.1.1.2" class="ltx_tr">
<td id="S6.T11.1.1.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="6"><span id="S6.T11.1.1.2.1.1" class="ltx_text">
<span id="S6.T11.1.1.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T11.1.1.2.1.1.1.1" class="ltx_tr">
<span id="S6.T11.1.1.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">In-context</span></span>
<span id="S6.T11.1.1.2.1.1.1.2" class="ltx_tr">
<span id="S6.T11.1.1.2.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Learning&nbsp;(ICL)</span></span>
</span></span></td>
<td id="S6.T11.1.1.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">KATE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib428" title="" class="ltx_ref">428</a>]</cite>
</td>
<td id="S6.T11.1.1.2.3" class="ltx_td ltx_align_left ltx_border_t">Demonstration selection (similar; k-NN)</td>
</tr>
<tr id="S6.T11.1.1.3" class="ltx_tr">
<td id="S6.T11.1.1.3.1" class="ltx_td ltx_align_left ltx_border_r">EPR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib429" title="" class="ltx_ref">429</a>]</cite>
</td>
<td id="S6.T11.1.1.3.2" class="ltx_td ltx_align_left">Demonstration selection (dense retrieval; constrative learning)</td>
</tr>
<tr id="S6.T11.1.1.4" class="ltx_tr">
<td id="S6.T11.1.1.4.1" class="ltx_td ltx_align_left ltx_border_r">SG-ICL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib430" title="" class="ltx_ref">430</a>]</cite>
</td>
<td id="S6.T11.1.1.4.2" class="ltx_td ltx_align_left">Demonstration selection (LLM as the demonstration generator)</td>
</tr>
<tr id="S6.T11.1.1.5" class="ltx_tr">
<td id="S6.T11.1.1.5.1" class="ltx_td ltx_align_left ltx_border_r">APE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib431" title="" class="ltx_ref">431</a>]</cite>
</td>
<td id="S6.T11.1.1.5.2" class="ltx_td ltx_align_left">Demonstration format (automatic generation &amp; selection)</td>
</tr>
<tr id="S6.T11.1.1.6" class="ltx_tr">
<td id="S6.T11.1.1.6.1" class="ltx_td ltx_align_left ltx_border_r">Structured Prompting&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib296" title="" class="ltx_ref">296</a>]</cite>
</td>
<td id="S6.T11.1.1.6.2" class="ltx_td ltx_align_left">Demonstration format (grouped context encoding; rescaled attention)</td>
</tr>
<tr id="S6.T11.1.1.7" class="ltx_tr">
<td id="S6.T11.1.1.7.1" class="ltx_td ltx_align_left ltx_border_r">GlobalE &amp; LocalE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib432" title="" class="ltx_ref">432</a>]</cite>
</td>
<td id="S6.T11.1.1.7.2" class="ltx_td ltx_align_left">Demonstration order (entropy-based metric; probing set generation with LLM)</td>
</tr>
<tr id="S6.T11.1.1.8" class="ltx_tr">
<td id="S6.T11.1.1.8.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="6"><span id="S6.T11.1.1.8.1.1" class="ltx_text">
<span id="S6.T11.1.1.8.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T11.1.1.8.1.1.1.1" class="ltx_tr">
<span id="S6.T11.1.1.8.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Chain-of-thought</span></span>
<span id="S6.T11.1.1.8.1.1.1.2" class="ltx_tr">
<span id="S6.T11.1.1.8.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Prompting&nbsp;(CoT)</span></span>
</span></span></td>
<td id="S6.T11.1.1.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Complex CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib433" title="" class="ltx_ref">433</a>]</cite>
</td>
<td id="S6.T11.1.1.8.3" class="ltx_td ltx_align_left ltx_border_t">Demonstration (complexity-based selection)</td>
</tr>
<tr id="S6.T11.1.1.9" class="ltx_tr">
<td id="S6.T11.1.1.9.1" class="ltx_td ltx_align_left ltx_border_r">Auto-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib434" title="" class="ltx_ref">434</a>]</cite>
</td>
<td id="S6.T11.1.1.9.2" class="ltx_td ltx_align_left">Demonstration (automatic generation)</td>
</tr>
<tr id="S6.T11.1.1.10" class="ltx_tr">
<td id="S6.T11.1.1.10.1" class="ltx_td ltx_align_left ltx_border_r">Selection-Inference&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib435" title="" class="ltx_ref">435</a>]</cite>
</td>
<td id="S6.T11.1.1.10.2" class="ltx_td ltx_align_left">Generation (alternate between selection and inference)</td>
</tr>
<tr id="S6.T11.1.1.11" class="ltx_tr">
<td id="S6.T11.1.1.11.1" class="ltx_td ltx_align_left ltx_border_r">Self-consistency&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib436" title="" class="ltx_ref">436</a>]</cite>
</td>
<td id="S6.T11.1.1.11.2" class="ltx_td ltx_align_left">Generation (diverse paths; self-ensemble)</td>
</tr>
<tr id="S6.T11.1.1.12" class="ltx_tr">
<td id="S6.T11.1.1.12.1" class="ltx_td ltx_align_left ltx_border_r">DIVERSE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib437" title="" class="ltx_ref">437</a>]</cite>
</td>
<td id="S6.T11.1.1.12.2" class="ltx_td ltx_align_left">Generation (diverse paths); Verification (step-wise voting)</td>
</tr>
<tr id="S6.T11.1.1.13" class="ltx_tr">
<td id="S6.T11.1.1.13.1" class="ltx_td ltx_align_left ltx_border_r">Rationale-augmented ensembles&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib438" title="" class="ltx_ref">438</a>]</cite>
</td>
<td id="S6.T11.1.1.13.2" class="ltx_td ltx_align_left">Generation (rationale sampling)</td>
</tr>
<tr id="S6.T11.1.1.14" class="ltx_tr">
<td id="S6.T11.1.1.14.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" rowspan="13"><span id="S6.T11.1.1.14.1.1" class="ltx_text">Planning</span></td>
<td id="S6.T11.1.1.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Least-to-most prompting&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib439" title="" class="ltx_ref">439</a>]</cite>
</td>
<td id="S6.T11.1.1.14.3" class="ltx_td ltx_align_left ltx_border_t">Plan generation (text-based; problem decomposition)</td>
</tr>
<tr id="S6.T11.1.1.15" class="ltx_tr">
<td id="S6.T11.1.1.15.1" class="ltx_td ltx_align_left ltx_border_r">DECOMP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib440" title="" class="ltx_ref">440</a>]</cite>
</td>
<td id="S6.T11.1.1.15.2" class="ltx_td ltx_align_left">Plan generation (text-based; problem decomposition)</td>
</tr>
<tr id="S6.T11.1.1.16" class="ltx_tr">
<td id="S6.T11.1.1.16.1" class="ltx_td ltx_align_left ltx_border_r">PS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib441" title="" class="ltx_ref">441</a>]</cite>
</td>
<td id="S6.T11.1.1.16.2" class="ltx_td ltx_align_left">Plan generation (text-based)</td>
</tr>
<tr id="S6.T11.1.1.17" class="ltx_tr">
<td id="S6.T11.1.1.17.1" class="ltx_td ltx_align_left ltx_border_r">Faithful CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib442" title="" class="ltx_ref">442</a>]</cite>
</td>
<td id="S6.T11.1.1.17.2" class="ltx_td ltx_align_left">Plan generation (code-based)</td>
</tr>
<tr id="S6.T11.1.1.18" class="ltx_tr">
<td id="S6.T11.1.1.18.1" class="ltx_td ltx_align_left ltx_border_r">PAL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib443" title="" class="ltx_ref">443</a>]</cite>
</td>
<td id="S6.T11.1.1.18.2" class="ltx_td ltx_align_left">Plan generation (code-based; Python)</td>
</tr>
<tr id="S6.T11.1.1.19" class="ltx_tr">
<td id="S6.T11.1.1.19.1" class="ltx_td ltx_align_left ltx_border_r">HuggingGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib444" title="" class="ltx_ref">444</a>]</cite>
</td>
<td id="S6.T11.1.1.19.2" class="ltx_td ltx_align_left">Plan generation (code-based; models from HuggingFace)</td>
</tr>
<tr id="S6.T11.1.1.20" class="ltx_tr">
<td id="S6.T11.1.1.20.1" class="ltx_td ltx_align_left ltx_border_r">AdaPlanner&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib445" title="" class="ltx_ref">445</a>]</cite>
</td>
<td id="S6.T11.1.1.20.2" class="ltx_td ltx_align_left">Plan refinement (skill memory)</td>
</tr>
<tr id="S6.T11.1.1.21" class="ltx_tr">
<td id="S6.T11.1.1.21.1" class="ltx_td ltx_align_left ltx_border_r">TIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib446" title="" class="ltx_ref">446</a>]</cite>
</td>
<td id="S6.T11.1.1.21.2" class="ltx_td ltx_align_left">Feedback acquisition (visual perception)</td>
</tr>
<tr id="S6.T11.1.1.22" class="ltx_tr">
<td id="S6.T11.1.1.22.1" class="ltx_td ltx_align_left ltx_border_r">RAP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib447" title="" class="ltx_ref">447</a>]</cite>
</td>
<td id="S6.T11.1.1.22.2" class="ltx_td ltx_align_left">Feedback acquisition (LLM as the world model); Plan refinement (Monte Carlo Tree Search)</td>
</tr>
<tr id="S6.T11.1.1.23" class="ltx_tr">
<td id="S6.T11.1.1.23.1" class="ltx_td ltx_align_left ltx_border_r">ChatCoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib448" title="" class="ltx_ref">448</a>]</cite>
</td>
<td id="S6.T11.1.1.23.2" class="ltx_td ltx_align_left">Feedback acquisition (tool); Plan refinement (conversation between LLM and tools)</td>
</tr>
<tr id="S6.T11.1.1.24" class="ltx_tr">
<td id="S6.T11.1.1.24.1" class="ltx_td ltx_align_left ltx_border_r">ReAct&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib449" title="" class="ltx_ref">449</a>]</cite>
</td>
<td id="S6.T11.1.1.24.2" class="ltx_td ltx_align_left">Feedback acquisition (tool); Plan refinement (synergizing reasoning and acting)</td>
</tr>
<tr id="S6.T11.1.1.25" class="ltx_tr">
<td id="S6.T11.1.1.25.1" class="ltx_td ltx_align_left ltx_border_r">Reflexion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib450" title="" class="ltx_ref">450</a>]</cite>
</td>
<td id="S6.T11.1.1.25.2" class="ltx_td ltx_align_left">Feedback acquisition (text-based self-reflection); Plan refinement (dynamic memory)</td>
</tr>
<tr id="S6.T11.1.1.26" class="ltx_tr">
<td id="S6.T11.1.1.26.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">Tree of Thoughts&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib451" title="" class="ltx_ref">451</a>]</cite>
</td>
<td id="S6.T11.1.1.26.2" class="ltx_td ltx_align_left ltx_border_bb">Feedback acquisition (vote comparison); Plan refinement (tree-based search)</td>
</tr>
</tbody></table>
</span></div>
</figure>
<div id="S6.p1" class="ltx_para">
<p class="ltx_p" id="S6.p1.1">사전 훈련 또는 적응 조정 후 LLMs를 사용하는 주요 접근법은 다양한 작업을 해결하기 위한 적합한 <span class="ltx_text ltx_font_italic" id="S6.p1.1.1">prompting</span> 전략을 설계하는 것이다. 기존 문헌에서는 수동 생성 및 자동 최적화를 통해 태스크별 프롬프트를 효과적으로 학습할 수 있다. 대표적인 프롬프트 방법은 태스크 설명 및/또는 데모를 자연어 텍스트의 형태로 공식화하는 <span class="ltx_text ltx_font_italic" id="S6.p1.1.2">in-context learning</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib50" title="">50</a>]</cite>이다. 또한, <span class="ltx_text ltx_font_italic" id="S6.p1.1.3">chain-of-thought prompting</span><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>는 프롬프트에 일련의 중간 추론 단계를 수반함으로써 컨텍스트 내 학습을 향상시키는 데 사용될 수 있다. 또한, <span class="ltx_text ltx_font_italic" id="S6.p1.1.4">planning</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib439" title="">439</a>]</cite>는 복잡한 태스크를 해결하기 위해 제안되며, 먼저 작은 하위 태스크로 분해한 다음 이러한 하위 태스크를 하나씩 해결하기 위한 액션 플랜을 생성한다. 이러한 프롬프트 접근법에 대한 대표적인 작업을 표 <a class="ltx_ref" href="#S6.T11" title="TABLE XI ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XI</span></a>에서 요약한다. 다음으로, 우리는 네 가지 기술의 세부 사항에 대해 자세히 설명할 것이다.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span><span id="S6.SS1.1.1" class="ltx_text ltx_font_italic">Prompting</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p1.1">이전 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib36" title="">36</a>]</cite>에서 논의된 바와 같이 프롬프트는 다양한 작업을 해결하기 위해 LLM을 활용하는 주요 접근법이다. 프롬프트의 품질은 특정 작업에서 LLM의 성능에 크게 영향을 미치기 때문에 수동 생성 또는 자동 최적화를 통해 적합한 작업 프롬프트를 생성하기 위해 제안된 일련의 연구가 이 섹션에 소개될 것이다.</p>
</div>
<section id="S6.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.1 </span>Prompt Creation</h4>

<div id="S6.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p1.1">적합한 프롬프트를 수동으로 생성하는 프로세스는 <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p1.1.1">prompt engineering</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib452" title="">452</a>, <a class="ltx_ref" href="#bib.bib453" title="">453</a>]</cite>라고도 한다. 잘 설계된 프롬프트는 특정 작업을 수행하는 LLM의 능력을 이끌어내는 데 매우 도움이 된다. 이 부분에서는 프롬프트의 핵심 구성 요소를 먼저 소개하고 프롬프트 설계를 위한 몇 가지 원칙에 대해 논의할 것이다. 그런 다음 여러 대표 태스크에 대한 결과를 보여주기 위해 서로 다른 프롬프트로 ChatGPT를 평가한다. 우리는 좋은 프롬프트를 설계하기 위한 제안과 지침을 제시하는 여러 기존 논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib454" title="">454</a>, <a class="ltx_ref" href="#bib.bib453" title="">453</a>]</cite>와 웹사이트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib455" title="">455</a>, <a class="ltx_ref" href="#bib.bib456" title="">456</a>, <a class="ltx_ref" href="#bib.bib457" title="">457</a>]</cite>가 있음을 알고 있다. 비교로, 우리는 주로 신속한 생성에 유용한 핵심 요소(성분 및 원리)에 대해 논의하고, 초보자에게 참고 자료로 인기 과제에 대한 실험 결과와 분석을 제공하는 것을 목표로 한다.</p>
</div>
<div id="S6.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.SSS1.p2.1.1">Key Ingredients. </span> 일반적으로 태스크 설명, 입력 데이터, 상황 정보 및 프롬프트 스타일을 포함하여 태스크를 완료하는 LLM의 능력을 이끌어내기 위한 프롬프트의 기능을 묘사하는 4가지 핵심 요소가 있습니다. 논의를 직관적으로 이해하기 위해 표 <a class="ltx_ref" href="#S6.T13" title="TABLE XIII ‣ 6.1.1 Prompt Creation ‣ 6.1 Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XIII</span></a>에서 질문 응답, 메타 리뷰 생성 및 텍스트-to-SQL에 대한 세 가지 프롬프트 예제를 제시한다.</p>
</div>
<div id="S6.SS1.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p3.1">• <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p3.1.1">Task description. </em> 작업 설명은 일반적으로 LLM이 따를 것으로 예상되는 특정 명령입니다. 일반적으로 자연어로 과제 목표를 명확하게 기술해야 한다. 특수 입력 또는 출력 형식을 가진 태스크의 경우 자세한 설명이 필요한 경우가 많으며, 태스크 완료 시 LLM을 더 잘 안내하기 위해 특수 설정을 강조하기 위해 키워드를 추가로 활용할 수 있다.</p>
</div>
<div id="S6.SS1.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p4.1">• <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p4.1.1">Input data. </em> 일반적인 경우 입력 데이터(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p4.1.2">e.g.,</em> a instance to respond by LLMs)를 자연어로 설명하는 것은 간단합니다. 지식 그래프 및 표와 같은 특수 입력 데이터에 대해 LLMs에 대해 읽을 수 있도록 적절하고 편리한 방법을 적용할 필요가 있다. 구조화 데이터의 경우 선형화는 단순성으로 인해 원본 레코드(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p4.1.3">e.g.,</em> knowledge triples)를 시퀀스 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib458" title="">458</a>]</cite>로 변환하는 데 일반적으로 사용됩니다. 또한, 프로그래밍 언어(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p4.1.4">e.g.,</em> executable code)도 구조화된 데이터를 공식화하는 데 활용되었으며, 이는 외부 도구(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p4.1.5">e.g.,</em> program executor)를 사용하여 정밀한 결과를 생성할 수 있다.</p>
</div>
<div id="S6.SS1.SSS1.p5" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p5.1">• <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p5.1.1">Contextual information. </em> 태스크 설명 및 입력 데이터 외에도 문맥 또는 배경 정보 또한 특정 태스크에 필수적이다. 예를 들어, 검색된 문서는 증거로서 오픈 도메인 질의 응답에 매우 유용하다. 검색된 문서의 품질과 질문과의 관련성은 모두 생성된 답변 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib461" title="">461</a>]</cite>에 영향을 미친다. 따라서, 적절한 프롬프트 패턴 또는 표현 형식으로 이러한 정보를 포함할 필요가 있다. 또한, 상황 내 태스크 예시는 복잡한 태스크를 수행하기 위해 LLMs을 유도하는 데 도움이 되며, 이는 태스크 목표, 특수 출력 형식 및 입력과 출력 간의 매핑 관계를 더 잘 묘사할 수 있다.</p>
</div>
<div id="S6.SS1.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p6.1">• <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p6.1.1">Prompt style. </em> 다른 LLM에 대해 특정 작업을 해결하는 능력을 이끌어내기 위한 적절한 프롬프트 스타일을 설계하는 것이 중요하다. 전체적으로 프롬프트를 잘 이해하고 답할 수 있는 명확한 질문이나 상세한 지시로 표현해야 한다. 경우에 따라 접두사 또는 접미사를 추가하여 LLM을 더 잘 안내하는 것도 유용합니다. 예를 들어, prefix "<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p6.1.2">Let us think step by step</em>"는 LLMs를 이끌어내는 데 도움을 줄 수 있으며, prefix "<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p6.1.3">당신은 이 작업에 대한 전문가(또는 이 도메인에서)</em>"는 일부 특정 작업에서 LLMs의 성능을 높일 수 있다. 또한, 채팅 기반 LLMs(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p6.1.4">e.g.,</em> ChatGPT)의 경우, 길거나 복잡한 태스크 프롬프트를 직접 공급하는 대신, 서브 태스크에 대한 여러 프롬프트로 분해한 다음 멀티 턴 대화 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib448" title="">448</a>]</cite>를 통해 LLMs로 공급하는 것이 좋다.</p>
</div>
<div id="S6.SS1.SSS1.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS1.SSS1.p7.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.SSS1.p7.1.1">Design Principles. </span> 프롬프트의 주요 구성 요소를 기반으로 다양한 작업을 해결하는 데 보다 효과적인 프롬프트를 만드는 데 도움이 될 수 있는 몇 가지 중요한 설계 원칙을 요약합니다.</p>
</div>
<div id="S6.SS1.SSS1.p8" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p8.1">• <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p8.1.1">Expressing the task goal clearly. </em> 작업 설명이 모호하거나 명확하지 않아야 하며, 이는 부정확하거나 부적절한 응답으로 이어질 가능성이 있다. 이는 이러한 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>를 활용할 때 명확하고 명확한 지침의 필요성을 강조한다. 명확하고 상세한 설명은 태스크 목적, 입력/출력 데이터(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p8.1.2">e.g.,</em> "<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p8.1.3">Given a long document, I want you be generate a concise summary. </em>”) 및 응답 제약 조건(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p8.1.4">e.g.,</em> "<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p8.1.5">the length of the summary can exceed 50.</em>”)을 포함할 수 있다. 잘 명료화된 태스크 디스크립션을 제공함으로써, LLMs는 타겟 태스크를 보다 효과적으로 이해하고 원하는 출력을 생성할 수 있다.</p>
</div>
<div id="S6.SS1.SSS1.p9" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p9.1">• <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p9.1.1">Decomposing into easy, detailed sub-tasks. </em> 복잡한 작업을 해결하려면 어려운 작업을 LLMs가 목표를 단계적으로 달성할 수 있도록 돕기 위한 몇 가지 더 쉽고 상세한 하위 작업으로 분해하는 것이 중요하며, 이는 섹션 <a class="ltx_ref" href="#S6.SS4" title="6.4 Planning for Complex Task Solving ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.4</span></a>의 계획 기술과 밀접한 관련이 있다. 예를 들어 제안 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib454" title="">454</a>]</cite>에 따라 여러 개의 번호가 매겨진 항목 형태로 하위 작업을 명시적으로 나열할 수 있습니다 (<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p9.1.2">e.g.,</em> "<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p9.1.3">Braid a coherent narrative by performing the tasks: 1. …; 2. …; 3. …</em>”). 대상 태스크를 하위 태스크로 분해함으로써 LLMs는 더 쉬운 하위 태스크를 해결하는 데 초점을 맞추고 최종적으로 복잡한 태스크에 대해 더 정확한 결과를 얻을 수 있다.</p>
</div>
<div id="S6.SS1.SSS1.p10" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p10.1">• <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p10.1.1">Supplying few-shot demonstrations. </em> 섹션 <a class="ltx_ref" href="#S6.SS2" title="6.2 In-Context Learning ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.2</span></a>에서 논의된 바와 같이, LLMs는 복잡한 태스크를 해결하기 위한 컨텍스트 내 학습의 이점을 얻을 수 있으며, 여기서 프롬프트는 원하는 입력-출력 쌍, <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p10.1.2">i.e.,</em> few-shot demonstrations의 적은 수의 태스크 예를 포함한다. 소수의 샷 데모는 LLM이 파라미터 튜닝 없이 입력과 출력 사이의 시맨틱 매핑을 학습하는 데 도움이 될 수 있다. 실제로는 목표 과제에 대한 몇 가지 고품질 데모를 생성해야 하며, 이는 최종 과제 수행에 큰 도움이 될 것이다.</p>
</div>
<div id="S6.SS1.SSS1.p11" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p11.1">• <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p11.1.1">Utilizing model-friendly format. </em> LLM은 특별히 구성된 데이터 세트에서 사전 훈련되기 때문에 LLM이 명령을 더 잘 이해할 수 있도록 하는 몇 가지 프롬프트 형식이 있다. 예를 들어 OpenAI 설명서에서 알 수 있듯이 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS1.p11.1.2">###</span> 또는 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS1.p11.1.3">"""</span>을 중지 기호로 사용하여 명령과 컨텍스트를 분리할 수 있으며, 이는 LLMs에서 더 잘 이해할 수 있습니다. 일반적인 지침으로 기존의 대부분의 LLMs은 영어에서 더 나은 작업을 수행하므로 기계 번역을 기반으로 어려운 작업을 해결하기 위해 영어 명령어를 사용하는 것이 유용하다.</p>
</div>
<div id="S6.SS1.SSS1.p12" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS1.SSS1.p12.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.SSS1.p12.1.1">Useful Tips. </span> 디자인 원칙 외에도 기존 작업 또는 표 <a class="ltx_ref" href="#S6.T12" title="TABLE XII ‣ 6.1.1 Prompt Creation ‣ 6.1 Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XII</span></a>의 경험적 경험을 기반으로 한 유용한 프롬프트 팁 모음도 제시한다. 이러한 팁은 일반적인 방식으로 제안되지만 해당 작업에 대한 최상의 프롬프트임을 나타내지 않습니다. 이 부분은 더 많은 지침이나 팁으로 지속적으로 업데이트될 것입니다. 우리는 독자들이 이 신속한 팁 컬렉션에 기여하는 것을 환영합니다. 링크에서 프롬프트 팁에 기여하기 위한 자세한 절차는 <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/RUCAIBox/LLMSurvey/tree/main/Prompts" target="_blank" title="">https://github.com/RUCAIBox/LLMSurvey/tree/main/Prompts</a>입니다.</p>
</div>
<figure id="S6.T12" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE XII:</span>A collection of useful tips for design prompts which are collected from online notes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib454" title="">454</a>, <a class="ltx_ref" href="#bib.bib453" title="">453</a>, <a class="ltx_ref" href="#bib.bib455" title="">455</a>, <a class="ltx_ref" href="#bib.bib456" title="">456</a>]</cite> and experiences from our authors, we also introduce the related ingredients and principles (introduced in Section <a class="ltx_ref" href="#S6.SS1.SSS1" title="6.1.1 Prompt Creation ‣ 6.1 Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.1.1</span></a>). 우리는 원칙을 Prin으로 줄인다. 각 프롬프트에 대한 관련 원칙의 ID를 나열합니다. ①: 과제 목표를 명확하게 표현하는 것; ②: 쉽고 세부적인 하위 과제로 분해하는 것; ③: 적은 샷 시연 제공; ④: 모델 친화적인 형식을 활용하는 것.</figcaption>
<table id="S6.T12.8" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S6.T12.8.9" class="ltx_tr">
<td id="S6.T12.8.9.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T12.8.9.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ingredient</span></td>
<td id="S6.T12.8.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T12.8.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.9.2.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.9.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Collected Prompts</span></span>
</span>
</td>
<td id="S6.T12.8.9.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T12.8.9.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">
Prin.</span></td>
</tr>
<tr id="S6.T12.8.10" class="ltx_tr">
<td id="S6.T12.8.10.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S6.T12.8.10.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Task Description</span></td>
<td id="S6.T12.8.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T12.8.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.10.2.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.10.2.1.1.1" class="ltx_text" style="font-size:70%;">T1. Make your prompt </span><span id="S6.T12.8.10.2.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">as detailed as possible</span><span id="S6.T12.8.10.2.1.1.3" class="ltx_text" style="font-size:70%;">, </span><em id="S6.T12.8.10.2.1.1.4" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.10.2.1.1.5" class="ltx_text" style="font-size:70%;"> “</span><em id="S6.T12.8.10.2.1.1.6" class="ltx_emph ltx_font_italic" style="font-size:70%;">Summarize the article into a short paragraph within 50 words. The major storyline and conclusion should be included, and the unimportant details can be omitted.</em><span id="S6.T12.8.10.2.1.1.7" class="ltx_text" style="font-size:70%;">”</span></span>
</span>
</td>
<td id="S6.T12.8.10.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T12.8.10.3.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
<tr id="S6.T12.8.11" class="ltx_tr">
<td id="S6.T12.8.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.11.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.11.1.1.1.1" class="ltx_text" style="font-size:70%;">T2. It is helpful to let the LLM know that it is </span><span id="S6.T12.8.11.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">an expert with a prefixed prompt</span><span id="S6.T12.8.11.1.1.1.3" class="ltx_text" style="font-size:70%;">, </span><em id="S6.T12.8.11.1.1.1.4" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.11.1.1.1.5" class="ltx_text" style="font-size:70%;"> “</span><em id="S6.T12.8.11.1.1.1.6" class="ltx_emph ltx_font_italic" style="font-size:70%;">You are a sophisticated expert in the domain of compute science.</em><span id="S6.T12.8.11.1.1.1.7" class="ltx_text" style="font-size:70%;">”</span></span>
</span>
</td>
<td id="S6.T12.8.11.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.11.2.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
<tr id="S6.T12.8.12" class="ltx_tr">
<td id="S6.T12.8.12.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.12.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.12.1.1.1.1" class="ltx_text" style="font-size:70%;">T3. Tell the model </span><span id="S6.T12.8.12.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">more what it should do</span><span id="S6.T12.8.12.1.1.1.3" class="ltx_text" style="font-size:70%;">, but not what it should not do.</span></span>
</span>
</td>
<td id="S6.T12.8.12.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.12.2.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
<tr id="S6.T12.8.13" class="ltx_tr">
<td id="S6.T12.8.13.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.13.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.13.1.1.1.1" class="ltx_text" style="font-size:70%;">T4. To avoid the LLM to generate too long output, you can just use the prompt: “</span><em id="S6.T12.8.13.1.1.1.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">Question:  Short Answer: </em><span id="S6.T12.8.13.1.1.1.3" class="ltx_text" style="font-size:70%;">”. Besides, you can also use the following suffixes, “</span><em id="S6.T12.8.13.1.1.1.4" class="ltx_emph ltx_font_italic" style="font-size:70%;">in a or a few words</em><span id="S6.T12.8.13.1.1.1.5" class="ltx_text" style="font-size:70%;">”, “</span><em id="S6.T12.8.13.1.1.1.6" class="ltx_emph ltx_font_italic" style="font-size:70%;">in one of two sentences</em><span id="S6.T12.8.13.1.1.1.7" class="ltx_text" style="font-size:70%;">”.</span></span>
</span>
</td>
<td id="S6.T12.8.13.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.13.2.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
<tr id="S6.T12.8.14" class="ltx_tr">
<td id="S6.T12.8.14.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S6.T12.8.14.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Input Data</span></td>
<td id="S6.T12.8.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T12.8.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.14.2.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.14.2.1.1.1" class="ltx_text" style="font-size:70%;">I1. For the question required factual knowledge, it is useful to first </span><span id="S6.T12.8.14.2.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">retrieve relevant documents</span><span id="S6.T12.8.14.2.1.1.3" class="ltx_text" style="font-size:70%;"> via the search engine, and then </span><span id="S6.T12.8.14.2.1.1.4" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">concatenate them into the prompt</span><span id="S6.T12.8.14.2.1.1.5" class="ltx_text" style="font-size:70%;"> as reference.</span></span>
</span>
</td>
<td id="S6.T12.8.14.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T12.8.14.3.1" class="ltx_text" style="font-size:70%;">④</span></td>
</tr>
<tr id="S6.T12.2.2" class="ltx_tr">
<td id="S6.T12.2.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.2.2.2.2" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.2.2.2.2.2" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.2.2.2.2.2.1" class="ltx_text" style="font-size:70%;">I2. To highlight some important parts in your prompt, please </span><span id="S6.T12.2.2.2.2.2.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">use special marks</span><span id="S6.T12.2.2.2.2.2.3" class="ltx_text" style="font-size:70%;">, </span><em id="S6.T12.2.2.2.2.2.4" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.2.2.2.2.2.5" class="ltx_text" style="font-size:70%;"> </span><em id="S6.T12.2.2.2.2.2.6" class="ltx_emph ltx_font_italic" style="font-size:70%;">quotation</em><span id="S6.T12.2.2.2.2.2.7" class="ltx_text" style="font-size:70%;"> (</span><math id="S6.T12.1.1.1.1.1.m1.1" class="ltx_Math" alttext="&quot;&quot;" display="inline"><semantics id="S6.T12.1.1.1.1.1.m1.1a"><mrow id="S6.T12.1.1.1.1.1.m1.1.1" xref="S6.T12.1.1.1.1.1.m1.1.1.cmml"><mi mathsize="70%" mathvariant="normal" id="S6.T12.1.1.1.1.1.m1.1.1.2" xref="S6.T12.1.1.1.1.1.m1.1.1.2.cmml">"</mi><mo lspace="0em" rspace="0em" id="S6.T12.1.1.1.1.1.m1.1.1.1" xref="S6.T12.1.1.1.1.1.m1.1.1.1.cmml">​</mo><mi mathsize="70%" mathvariant="normal" id="S6.T12.1.1.1.1.1.m1.1.1.3" xref="S6.T12.1.1.1.1.1.m1.1.1.3.cmml">"</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.T12.1.1.1.1.1.m1.1b"><apply id="S6.T12.1.1.1.1.1.m1.1.1.cmml" xref="S6.T12.1.1.1.1.1.m1.1.1"><times id="S6.T12.1.1.1.1.1.m1.1.1.1.cmml" xref="S6.T12.1.1.1.1.1.m1.1.1.1"></times><ci id="S6.T12.1.1.1.1.1.m1.1.1.2.cmml" xref="S6.T12.1.1.1.1.1.m1.1.1.2">"</ci><ci id="S6.T12.1.1.1.1.1.m1.1.1.3.cmml" xref="S6.T12.1.1.1.1.1.m1.1.1.3">"</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T12.1.1.1.1.1.m1.1c">""</annotation></semantics></math><span id="S6.T12.2.2.2.2.2.8" class="ltx_text" style="font-size:70%;">) and </span><em id="S6.T12.2.2.2.2.2.9" class="ltx_emph ltx_font_italic" style="font-size:70%;">line break</em><span id="S6.T12.2.2.2.2.2.10" class="ltx_text" style="font-size:70%;"> (</span><math id="S6.T12.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S6.T12.2.2.2.2.2.m2.1a"><mo mathsize="70%" id="S6.T12.2.2.2.2.2.m2.1.1" xref="S6.T12.2.2.2.2.2.m2.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S6.T12.2.2.2.2.2.m2.1b"><ci id="S6.T12.2.2.2.2.2.m2.1.1.cmml" xref="S6.T12.2.2.2.2.2.m2.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T12.2.2.2.2.2.m2.1c">\backslash</annotation></semantics></math><span id="S6.T12.2.2.2.2.2.11" class="ltx_text" style="font-size:70%;">n). You can also use both of them for emphasizing.</span></span>
</span>
</td>
<td id="S6.T12.2.2.3" class="ltx_td ltx_align_center"><span id="S6.T12.2.2.3.1" class="ltx_text" style="font-size:70%;">④</span></td>
</tr>
<tr id="S6.T12.3.3" class="ltx_tr">
<td id="S6.T12.3.3.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S6.T12.3.3.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Contextual Information</span></td>
<td id="S6.T12.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T12.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.3.3.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.3.3.1.1.1.2" class="ltx_text" style="font-size:70%;">C1. For complex tasks, you can </span><span id="S6.T12.3.3.1.1.1.3" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">clearly describe the required intermediate steps</span><span id="S6.T12.3.3.1.1.1.4" class="ltx_text" style="font-size:70%;"> to accomplish it, </span><em id="S6.T12.3.3.1.1.1.5" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.3.3.1.1.1.6" class="ltx_text" style="font-size:70%;"> “</span><em id="S6.T12.3.3.1.1.1.1" class="ltx_emph ltx_font_italic" style="font-size:70%;">Please answer the question step by step as: Step 1 - Decompose the question into several sub-questions, <math id="S6.T12.3.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\cdots" display="inline"><semantics id="S6.T12.3.3.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S6.T12.3.3.1.1.1.1.m1.1.1" xref="S6.T12.3.3.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="S6.T12.3.3.1.1.1.1.m1.1b"><ci id="S6.T12.3.3.1.1.1.1.m1.1.1.cmml" xref="S6.T12.3.3.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T12.3.3.1.1.1.1.m1.1c">\cdots</annotation></semantics></math></em><span id="S6.T12.3.3.1.1.1.7" class="ltx_text" style="font-size:70%;">”</span></span>
</span>
</td>
<td id="S6.T12.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T12.3.3.3.1" class="ltx_text" style="font-size:70%;">②</span></td>
</tr>
<tr id="S6.T12.8.15" class="ltx_tr">
<td id="S6.T12.8.15.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.15.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.15.1.1.1.1" class="ltx_text" style="font-size:70%;">C2. If you want LLMs to provide the score for a text, it is necessary to provide a </span><span id="S6.T12.8.15.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">detailed description about the</span><span id="S6.T12.8.15.1.1.1.3" class="ltx_text" style="font-size:70%;"> </span><span id="S6.T12.8.15.1.1.1.4" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">scoring standard</span><span id="S6.T12.8.15.1.1.1.5" class="ltx_text" style="font-size:70%;"> with examples as reference.</span></span>
</span>
</td>
<td id="S6.T12.8.15.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.15.2.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
<tr id="S6.T12.8.16" class="ltx_tr">
<td id="S6.T12.8.16.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.16.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.16.1.1.1.1" class="ltx_text" style="font-size:70%;">C3. When LLMs generate text according to some context (</span><em id="S6.T12.8.16.1.1.1.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.16.1.1.1.3" class="ltx_text" style="font-size:70%;"> making recommendations according to purchase history), instructing them with </span><span id="S6.T12.8.16.1.1.1.4" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">the explanation about the generated result</span><span id="S6.T12.8.16.1.1.1.5" class="ltx_text" style="font-size:70%;"> conditioned on context is helpful to improve the quality of the generated text.</span></span>
</span>
</td>
<td id="S6.T12.8.16.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.16.2.1" class="ltx_text" style="font-size:70%;">②</span></td>
</tr>
<tr id="S6.T12.8.17" class="ltx_tr">
<td id="S6.T12.8.17.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.17.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.17.1.1.1.1" class="ltx_text" style="font-size:70%;">C4. An approach similar to </span><span id="S6.T12.8.17.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">tree-of-thoughts</span><span id="S6.T12.8.17.1.1.1.3" class="ltx_text" style="font-size:70%;"> but can be </span><span id="S6.T12.8.17.1.1.1.4" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">done in one prompt</span><span id="S6.T12.8.17.1.1.1.5" class="ltx_text" style="font-size:70%;">: </span><em id="S6.T12.8.17.1.1.1.6" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.17.1.1.1.7" class="ltx_text" style="font-size:70%;"> </span><em id="S6.T12.8.17.1.1.1.8" class="ltx_emph ltx_font_italic" style="font-size:70%;">Imagine three different experts are answering this question. All experts will write down one step of their thinking, then share it with the group of experts. Then all experts will go on to the next step, etc. If any expert realizes they’re wrong at any point then they leave. The question is</em></span>
</span>
</td>
<td id="S6.T12.8.17.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.17.2.1" class="ltx_text" style="font-size:70%;">②</span></td>
</tr>
<tr id="S6.T12.8.18" class="ltx_tr">
<td id="S6.T12.8.18.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="9"><span id="S6.T12.8.18.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Demonstration</span></td>
<td id="S6.T12.8.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T12.8.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.18.2.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.18.2.1.1.1" class="ltx_text" style="font-size:70%;">D1. </span><span id="S6.T12.8.18.2.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">Well-formatted in-context exemplars</span><span id="S6.T12.8.18.2.1.1.3" class="ltx_text" style="font-size:70%;"> are very useful, especially for producing the outputs with complex formats.</span></span>
</span>
</td>
<td id="S6.T12.8.18.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T12.8.18.3.1" class="ltx_text" style="font-size:70%;">③</span></td>
</tr>
<tr id="S6.T12.4.4" class="ltx_tr">
<td id="S6.T12.4.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.4.4.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.4.4.1.1.1.2" class="ltx_text" style="font-size:70%;">D2. For few-shot chain-of-thought prompting, you can also use the prompt “</span><em id="S6.T12.4.4.1.1.1.3" class="ltx_emph ltx_font_italic" style="font-size:70%;">Let’s think step-by-step</em><span id="S6.T12.4.4.1.1.1.4" class="ltx_text" style="font-size:70%;">”, and the few-shot examples should be </span><span id="S6.T12.4.4.1.1.1.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">separated by “<math id="S6.T12.4.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S6.T12.4.4.1.1.1.1.m1.1a"><mo id="S6.T12.4.4.1.1.1.1.m1.1.1" xref="S6.T12.4.4.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S6.T12.4.4.1.1.1.1.m1.1b"><ci id="S6.T12.4.4.1.1.1.1.m1.1.1.cmml" xref="S6.T12.4.4.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T12.4.4.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n”</span><span id="S6.T12.4.4.1.1.1.5" class="ltx_text" style="font-size:70%;"> instead of full stop.</span></span>
</span>
</td>
<td id="S6.T12.4.4.2" class="ltx_td ltx_align_center"><span id="S6.T12.4.4.2.1" class="ltx_text" style="font-size:70%;">①③</span></td>
</tr>
<tr id="S6.T12.8.19" class="ltx_tr">
<td id="S6.T12.8.19.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.19.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.19.1.1.1.1" class="ltx_text" style="font-size:70%;">D3. You can also </span><span id="S6.T12.8.19.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">retrieve similar examples</span><span id="S6.T12.8.19.1.1.1.3" class="ltx_text" style="font-size:70%;"> in context to supply the useful task-specific knowledge for LLMs. To retrieve more relevant examples, it is useful to </span><span id="S6.T12.8.19.1.1.1.4" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">first obtain the answer</span><span id="S6.T12.8.19.1.1.1.5" class="ltx_text" style="font-size:70%;"> of the question, and then concatenate it with the question for retrieval.</span></span>
</span>
</td>
<td id="S6.T12.8.19.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.19.2.1" class="ltx_text" style="font-size:70%;">③④</span></td>
</tr>
<tr id="S6.T12.8.20" class="ltx_tr">
<td id="S6.T12.8.20.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.20.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.20.1.1.1.1" class="ltx_text" style="font-size:70%;">D4. The </span><span id="S6.T12.8.20.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">diversity of the in-context exemplars</span><span id="S6.T12.8.20.1.1.1.3" class="ltx_text" style="font-size:70%;"> within the prompt is also useful. If it is not easy to obtain diverse questions, you can also seek to keep the </span><span id="S6.T12.8.20.1.1.1.4" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">diversity of the solutions</span><span id="S6.T12.8.20.1.1.1.5" class="ltx_text" style="font-size:70%;"> for the questions.</span></span>
</span>
</td>
<td id="S6.T12.8.20.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.20.2.1" class="ltx_text" style="font-size:70%;">③</span></td>
</tr>
<tr id="S6.T12.8.21" class="ltx_tr">
<td id="S6.T12.8.21.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.21.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.21.1.1.1.1" class="ltx_text" style="font-size:70%;">D5. When using chat-based LLMs, you can </span><span id="S6.T12.8.21.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">decompose in-context exemplars into multi-turn messages</span><span id="S6.T12.8.21.1.1.1.3" class="ltx_text" style="font-size:70%;">, to better match the human-chatbot conversation format. Similarly, you can also decompose the reasoning process of an exemplars into multi-turn conversation.</span></span>
</span>
</td>
<td id="S6.T12.8.21.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.21.2.1" class="ltx_text" style="font-size:70%;">③</span></td>
</tr>
<tr id="S6.T12.8.22" class="ltx_tr">
<td id="S6.T12.8.22.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.22.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.22.1.1.1.1" class="ltx_text" style="font-size:70%;">D6. </span><span id="S6.T12.8.22.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">Complex and informative</span><span id="S6.T12.8.22.1.1.1.3" class="ltx_text" style="font-size:70%;"> in-context exemplars can help LLMs answer complex questions.</span></span>
</span>
</td>
<td id="S6.T12.8.22.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.22.2.1" class="ltx_text" style="font-size:70%;">③</span></td>
</tr>
<tr id="S6.T12.8.8" class="ltx_tr">
<td id="S6.T12.8.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.8.4.4" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.8.4.4.4" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.8.4.4.4.1" class="ltx_text" style="font-size:70%;">D7. As a symbol sequence can typically be divided into multiple segments (</span><em id="S6.T12.8.8.4.4.4.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.8.4.4.4.3" class="ltx_text" style="font-size:70%;"> </span><math id="S6.T12.5.5.1.1.1.m1.3" class="ltx_Math" alttext="i_{1},i_{2},i_{3}" display="inline"><semantics id="S6.T12.5.5.1.1.1.m1.3a"><mrow id="S6.T12.5.5.1.1.1.m1.3.3.3" xref="S6.T12.5.5.1.1.1.m1.3.3.4.cmml"><msub id="S6.T12.5.5.1.1.1.m1.1.1.1.1" xref="S6.T12.5.5.1.1.1.m1.1.1.1.1.cmml"><mi mathsize="70%" id="S6.T12.5.5.1.1.1.m1.1.1.1.1.2" xref="S6.T12.5.5.1.1.1.m1.1.1.1.1.2.cmml">i</mi><mn mathsize="70%" id="S6.T12.5.5.1.1.1.m1.1.1.1.1.3" xref="S6.T12.5.5.1.1.1.m1.1.1.1.1.3.cmml">1</mn></msub><mo mathsize="70%" id="S6.T12.5.5.1.1.1.m1.3.3.3.4" xref="S6.T12.5.5.1.1.1.m1.3.3.4.cmml">,</mo><msub id="S6.T12.5.5.1.1.1.m1.2.2.2.2" xref="S6.T12.5.5.1.1.1.m1.2.2.2.2.cmml"><mi mathsize="70%" id="S6.T12.5.5.1.1.1.m1.2.2.2.2.2" xref="S6.T12.5.5.1.1.1.m1.2.2.2.2.2.cmml">i</mi><mn mathsize="70%" id="S6.T12.5.5.1.1.1.m1.2.2.2.2.3" xref="S6.T12.5.5.1.1.1.m1.2.2.2.2.3.cmml">2</mn></msub><mo mathsize="70%" id="S6.T12.5.5.1.1.1.m1.3.3.3.5" xref="S6.T12.5.5.1.1.1.m1.3.3.4.cmml">,</mo><msub id="S6.T12.5.5.1.1.1.m1.3.3.3.3" xref="S6.T12.5.5.1.1.1.m1.3.3.3.3.cmml"><mi mathsize="70%" id="S6.T12.5.5.1.1.1.m1.3.3.3.3.2" xref="S6.T12.5.5.1.1.1.m1.3.3.3.3.2.cmml">i</mi><mn mathsize="70%" id="S6.T12.5.5.1.1.1.m1.3.3.3.3.3" xref="S6.T12.5.5.1.1.1.m1.3.3.3.3.3.cmml">3</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.T12.5.5.1.1.1.m1.3b"><list id="S6.T12.5.5.1.1.1.m1.3.3.4.cmml" xref="S6.T12.5.5.1.1.1.m1.3.3.3"><apply id="S6.T12.5.5.1.1.1.m1.1.1.1.1.cmml" xref="S6.T12.5.5.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S6.T12.5.5.1.1.1.m1.1.1.1.1.1.cmml" xref="S6.T12.5.5.1.1.1.m1.1.1.1.1">subscript</csymbol><ci id="S6.T12.5.5.1.1.1.m1.1.1.1.1.2.cmml" xref="S6.T12.5.5.1.1.1.m1.1.1.1.1.2">𝑖</ci><cn type="integer" id="S6.T12.5.5.1.1.1.m1.1.1.1.1.3.cmml" xref="S6.T12.5.5.1.1.1.m1.1.1.1.1.3">1</cn></apply><apply id="S6.T12.5.5.1.1.1.m1.2.2.2.2.cmml" xref="S6.T12.5.5.1.1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S6.T12.5.5.1.1.1.m1.2.2.2.2.1.cmml" xref="S6.T12.5.5.1.1.1.m1.2.2.2.2">subscript</csymbol><ci id="S6.T12.5.5.1.1.1.m1.2.2.2.2.2.cmml" xref="S6.T12.5.5.1.1.1.m1.2.2.2.2.2">𝑖</ci><cn type="integer" id="S6.T12.5.5.1.1.1.m1.2.2.2.2.3.cmml" xref="S6.T12.5.5.1.1.1.m1.2.2.2.2.3">2</cn></apply><apply id="S6.T12.5.5.1.1.1.m1.3.3.3.3.cmml" xref="S6.T12.5.5.1.1.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S6.T12.5.5.1.1.1.m1.3.3.3.3.1.cmml" xref="S6.T12.5.5.1.1.1.m1.3.3.3.3">subscript</csymbol><ci id="S6.T12.5.5.1.1.1.m1.3.3.3.3.2.cmml" xref="S6.T12.5.5.1.1.1.m1.3.3.3.3.2">𝑖</ci><cn type="integer" id="S6.T12.5.5.1.1.1.m1.3.3.3.3.3.cmml" xref="S6.T12.5.5.1.1.1.m1.3.3.3.3.3">3</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S6.T12.5.5.1.1.1.m1.3c">i_{1},i_{2},i_{3}</annotation></semantics></math><span id="S6.T12.8.8.4.4.4.4" class="ltx_text" style="font-size:70%;"> </span><math id="S6.T12.6.6.2.2.2.m2.1" class="ltx_Math" alttext="\longrightarrow" display="inline"><semantics id="S6.T12.6.6.2.2.2.m2.1a"><mo mathsize="70%" stretchy="false" id="S6.T12.6.6.2.2.2.m2.1.1" xref="S6.T12.6.6.2.2.2.m2.1.1.cmml">⟶</mo><annotation-xml encoding="MathML-Content" id="S6.T12.6.6.2.2.2.m2.1b"><ci id="S6.T12.6.6.2.2.2.m2.1.1.cmml" xref="S6.T12.6.6.2.2.2.m2.1.1">⟶</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T12.6.6.2.2.2.m2.1c">\longrightarrow</annotation></semantics></math><span id="S6.T12.8.8.4.4.4.5" class="ltx_text" style="font-size:70%;"> </span><math id="S6.T12.7.7.3.3.3.m3.2" class="ltx_Math" alttext="i_{1},i_{2}" display="inline"><semantics id="S6.T12.7.7.3.3.3.m3.2a"><mrow id="S6.T12.7.7.3.3.3.m3.2.2.2" xref="S6.T12.7.7.3.3.3.m3.2.2.3.cmml"><msub id="S6.T12.7.7.3.3.3.m3.1.1.1.1" xref="S6.T12.7.7.3.3.3.m3.1.1.1.1.cmml"><mi mathsize="70%" id="S6.T12.7.7.3.3.3.m3.1.1.1.1.2" xref="S6.T12.7.7.3.3.3.m3.1.1.1.1.2.cmml">i</mi><mn mathsize="70%" id="S6.T12.7.7.3.3.3.m3.1.1.1.1.3" xref="S6.T12.7.7.3.3.3.m3.1.1.1.1.3.cmml">1</mn></msub><mo mathsize="70%" id="S6.T12.7.7.3.3.3.m3.2.2.2.3" xref="S6.T12.7.7.3.3.3.m3.2.2.3.cmml">,</mo><msub id="S6.T12.7.7.3.3.3.m3.2.2.2.2" xref="S6.T12.7.7.3.3.3.m3.2.2.2.2.cmml"><mi mathsize="70%" id="S6.T12.7.7.3.3.3.m3.2.2.2.2.2" xref="S6.T12.7.7.3.3.3.m3.2.2.2.2.2.cmml">i</mi><mn mathsize="70%" id="S6.T12.7.7.3.3.3.m3.2.2.2.2.3" xref="S6.T12.7.7.3.3.3.m3.2.2.2.2.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.T12.7.7.3.3.3.m3.2b"><list id="S6.T12.7.7.3.3.3.m3.2.2.3.cmml" xref="S6.T12.7.7.3.3.3.m3.2.2.2"><apply id="S6.T12.7.7.3.3.3.m3.1.1.1.1.cmml" xref="S6.T12.7.7.3.3.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S6.T12.7.7.3.3.3.m3.1.1.1.1.1.cmml" xref="S6.T12.7.7.3.3.3.m3.1.1.1.1">subscript</csymbol><ci id="S6.T12.7.7.3.3.3.m3.1.1.1.1.2.cmml" xref="S6.T12.7.7.3.3.3.m3.1.1.1.1.2">𝑖</ci><cn type="integer" id="S6.T12.7.7.3.3.3.m3.1.1.1.1.3.cmml" xref="S6.T12.7.7.3.3.3.m3.1.1.1.1.3">1</cn></apply><apply id="S6.T12.7.7.3.3.3.m3.2.2.2.2.cmml" xref="S6.T12.7.7.3.3.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S6.T12.7.7.3.3.3.m3.2.2.2.2.1.cmml" xref="S6.T12.7.7.3.3.3.m3.2.2.2.2">subscript</csymbol><ci id="S6.T12.7.7.3.3.3.m3.2.2.2.2.2.cmml" xref="S6.T12.7.7.3.3.3.m3.2.2.2.2.2">𝑖</ci><cn type="integer" id="S6.T12.7.7.3.3.3.m3.2.2.2.2.3.cmml" xref="S6.T12.7.7.3.3.3.m3.2.2.2.2.3">2</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S6.T12.7.7.3.3.3.m3.2c">i_{1},i_{2}</annotation></semantics></math><span id="S6.T12.8.8.4.4.4.6" class="ltx_text" style="font-size:70%;"> and </span><math id="S6.T12.8.8.4.4.4.m4.2" class="ltx_Math" alttext="i_{2},i_{3}" display="inline"><semantics id="S6.T12.8.8.4.4.4.m4.2a"><mrow id="S6.T12.8.8.4.4.4.m4.2.2.2" xref="S6.T12.8.8.4.4.4.m4.2.2.3.cmml"><msub id="S6.T12.8.8.4.4.4.m4.1.1.1.1" xref="S6.T12.8.8.4.4.4.m4.1.1.1.1.cmml"><mi mathsize="70%" id="S6.T12.8.8.4.4.4.m4.1.1.1.1.2" xref="S6.T12.8.8.4.4.4.m4.1.1.1.1.2.cmml">i</mi><mn mathsize="70%" id="S6.T12.8.8.4.4.4.m4.1.1.1.1.3" xref="S6.T12.8.8.4.4.4.m4.1.1.1.1.3.cmml">2</mn></msub><mo mathsize="70%" id="S6.T12.8.8.4.4.4.m4.2.2.2.3" xref="S6.T12.8.8.4.4.4.m4.2.2.3.cmml">,</mo><msub id="S6.T12.8.8.4.4.4.m4.2.2.2.2" xref="S6.T12.8.8.4.4.4.m4.2.2.2.2.cmml"><mi mathsize="70%" id="S6.T12.8.8.4.4.4.m4.2.2.2.2.2" xref="S6.T12.8.8.4.4.4.m4.2.2.2.2.2.cmml">i</mi><mn mathsize="70%" id="S6.T12.8.8.4.4.4.m4.2.2.2.2.3" xref="S6.T12.8.8.4.4.4.m4.2.2.2.2.3.cmml">3</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.T12.8.8.4.4.4.m4.2b"><list id="S6.T12.8.8.4.4.4.m4.2.2.3.cmml" xref="S6.T12.8.8.4.4.4.m4.2.2.2"><apply id="S6.T12.8.8.4.4.4.m4.1.1.1.1.cmml" xref="S6.T12.8.8.4.4.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S6.T12.8.8.4.4.4.m4.1.1.1.1.1.cmml" xref="S6.T12.8.8.4.4.4.m4.1.1.1.1">subscript</csymbol><ci id="S6.T12.8.8.4.4.4.m4.1.1.1.1.2.cmml" xref="S6.T12.8.8.4.4.4.m4.1.1.1.1.2">𝑖</ci><cn type="integer" id="S6.T12.8.8.4.4.4.m4.1.1.1.1.3.cmml" xref="S6.T12.8.8.4.4.4.m4.1.1.1.1.3">2</cn></apply><apply id="S6.T12.8.8.4.4.4.m4.2.2.2.2.cmml" xref="S6.T12.8.8.4.4.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S6.T12.8.8.4.4.4.m4.2.2.2.2.1.cmml" xref="S6.T12.8.8.4.4.4.m4.2.2.2.2">subscript</csymbol><ci id="S6.T12.8.8.4.4.4.m4.2.2.2.2.2.cmml" xref="S6.T12.8.8.4.4.4.m4.2.2.2.2.2">𝑖</ci><cn type="integer" id="S6.T12.8.8.4.4.4.m4.2.2.2.2.3.cmml" xref="S6.T12.8.8.4.4.4.m4.2.2.2.2.3">3</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S6.T12.8.8.4.4.4.m4.2c">i_{2},i_{3}</annotation></semantics></math><span id="S6.T12.8.8.4.4.4.7" class="ltx_text" style="font-size:70%;">), the preceding ones can be used </span><span id="S6.T12.8.8.4.4.4.8" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">as in-context exemplars</span><span id="S6.T12.8.8.4.4.4.9" class="ltx_text" style="font-size:70%;"> to guide LLMs to predict the subsequent ones, meanwhile providing historical information.</span></span>
</span>
</td>
<td id="S6.T12.8.8.5" class="ltx_td ltx_align_center"><span id="S6.T12.8.8.5.1" class="ltx_text" style="font-size:70%;">②③</span></td>
</tr>
<tr id="S6.T12.8.23" class="ltx_tr">
<td id="S6.T12.8.23.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.23.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.23.1.1.1.1" class="ltx_text" style="font-size:70%;">D8. </span><span id="S6.T12.8.23.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">Order matters</span><span id="S6.T12.8.23.1.1.1.3" class="ltx_text" style="font-size:70%;"> for in-context exemplars and prompts components. For very long input data, the position of the question (first or last) may also affect the performance.</span></span>
</span>
</td>
<td id="S6.T12.8.23.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.23.2.1" class="ltx_text" style="font-size:70%;">③</span></td>
</tr>
<tr id="S6.T12.8.24" class="ltx_tr">
<td id="S6.T12.8.24.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.24.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.24.1.1.1.1" class="ltx_text" style="font-size:70%;">D9. If you can not obtain the in-context exemplars from existing datasets, an alternative way is to use the </span><span id="S6.T12.8.24.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">zero-shot</span><span id="S6.T12.8.24.1.1.1.3" class="ltx_text" style="font-size:70%;"> </span><span id="S6.T12.8.24.1.1.1.4" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">generated ones</span><span id="S6.T12.8.24.1.1.1.5" class="ltx_text" style="font-size:70%;"> from the LLM itself.</span></span>
</span>
</td>
<td id="S6.T12.8.24.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.24.2.1" class="ltx_text" style="font-size:70%;">③</span></td>
</tr>
<tr id="S6.T12.8.25" class="ltx_tr">
<td id="S6.T12.8.25.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="8"><span id="S6.T12.8.25.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Other Designs</span></td>
<td id="S6.T12.8.25.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T12.8.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.25.2.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.25.2.1.1.1" class="ltx_text" style="font-size:70%;">O1. Let the </span><span id="S6.T12.8.25.2.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">LLM check its outputs</span><span id="S6.T12.8.25.2.1.1.3" class="ltx_text" style="font-size:70%;"> before draw the conclusion, </span><em id="S6.T12.8.25.2.1.1.4" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.25.2.1.1.5" class="ltx_text" style="font-size:70%;"> “</span><em id="S6.T12.8.25.2.1.1.6" class="ltx_emph ltx_font_italic" style="font-size:70%;">Check whether the above solution is correct or not.</em><span id="S6.T12.8.25.2.1.1.7" class="ltx_text" style="font-size:70%;">”</span></span>
</span>
</td>
<td id="S6.T12.8.25.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T12.8.25.3.1" class="ltx_text" style="font-size:70%;">②</span></td>
</tr>
<tr id="S6.T12.8.26" class="ltx_tr">
<td id="S6.T12.8.26.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.26.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.26.1.1.1.1" class="ltx_text" style="font-size:70%;">O2. If the LLM can not well solve the task, you can </span><span id="S6.T12.8.26.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">seek help from external tools</span><span id="S6.T12.8.26.1.1.1.3" class="ltx_text" style="font-size:70%;"> by prompting the LLM to manipulate them. In this way, the tools should be encapsulated into callable APIs with detailed description about their functions, to better guide the LLM to utilize the tools.</span></span>
</span>
</td>
<td id="S6.T12.8.26.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.26.2.1" class="ltx_text" style="font-size:70%;">④</span></td>
</tr>
<tr id="S6.T12.8.27" class="ltx_tr">
<td id="S6.T12.8.27.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.27.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.27.1.1.1.1" class="ltx_text" style="font-size:70%;">O3. The prompt should be </span><span id="S6.T12.8.27.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">self-contained</span><span id="S6.T12.8.27.1.1.1.3" class="ltx_text" style="font-size:70%;">, and better not include pronouns (</span><em id="S6.T12.8.27.1.1.1.4" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.27.1.1.1.5" class="ltx_text" style="font-size:70%;"> it and they) in the context.</span></span>
</span>
</td>
<td id="S6.T12.8.27.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.27.2.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
<tr id="S6.T12.8.28" class="ltx_tr">
<td id="S6.T12.8.28.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.28.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.28.1.1.1.1" class="ltx_text" style="font-size:70%;">O4. When using LLMs for </span><span id="S6.T12.8.28.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">comparing</span><span id="S6.T12.8.28.1.1.1.3" class="ltx_text" style="font-size:70%;"> two or more examples, the order affects the performance a lot.</span></span>
</span>
</td>
<td id="S6.T12.8.28.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.28.2.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
<tr id="S6.T12.8.29" class="ltx_tr">
<td id="S6.T12.8.29.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.29.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.29.1.1.1.1" class="ltx_text" style="font-size:70%;">O5. Before the prompt, </span><span id="S6.T12.8.29.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">assigning a role for the LLM</span><span id="S6.T12.8.29.1.1.1.3" class="ltx_text" style="font-size:70%;"> is useful to help it better fulfill the following task instruction, </span><em id="S6.T12.8.29.1.1.1.4" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.29.1.1.1.5" class="ltx_text" style="font-size:70%;"> </span><em id="S6.T12.8.29.1.1.1.6" class="ltx_emph ltx_font_italic" style="font-size:70%;">“I want you to act as a lawyer”</em><span id="S6.T12.8.29.1.1.1.7" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
<td id="S6.T12.8.29.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.29.2.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
<tr id="S6.T12.8.30" class="ltx_tr">
<td id="S6.T12.8.30.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.30.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.30.1.1.1.1" class="ltx_text" style="font-size:70%;">O6. OpenAI models can perform a task better in English than other languages. Thus, it is useful to first </span><span id="S6.T12.8.30.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">translate the input into English</span><span id="S6.T12.8.30.1.1.1.3" class="ltx_text" style="font-size:70%;"> and then feed it to LLMs.</span></span>
</span>
</td>
<td id="S6.T12.8.30.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.30.2.1" class="ltx_text" style="font-size:70%;">④</span></td>
</tr>
<tr id="S6.T12.8.31" class="ltx_tr">
<td id="S6.T12.8.31.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T12.8.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.31.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.31.1.1.1.1" class="ltx_text" style="font-size:70%;">O7. For multi-choice questions, it is useful to </span><span id="S6.T12.8.31.1.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">constrain the output space</span><span id="S6.T12.8.31.1.1.1.3" class="ltx_text" style="font-size:70%;"> of the LLM. You can use a more detailed explanation or just imposing constraints on the logits.</span></span>
</span>
</td>
<td id="S6.T12.8.31.2" class="ltx_td ltx_align_center"><span id="S6.T12.8.31.2.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
<tr id="S6.T12.8.32" class="ltx_tr">
<td id="S6.T12.8.32.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S6.T12.8.32.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T12.8.32.1.1.1" class="ltx_p" style="width:325.2pt;"><span id="S6.T12.8.32.1.1.1.1" class="ltx_text" style="font-size:70%;">O8. For sorting based tasks (</span><em id="S6.T12.8.32.1.1.1.2" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.32.1.1.1.3" class="ltx_text" style="font-size:70%;"> recommendation), instead of directly outputting the complete text of each item after sorting, one can </span><span id="S6.T12.8.32.1.1.1.4" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="font-size:70%;">assign indicators</span><span id="S6.T12.8.32.1.1.1.5" class="ltx_text" style="font-size:70%;"> (</span><em id="S6.T12.8.32.1.1.1.6" class="ltx_emph ltx_font_italic" style="font-size:70%;">e.g.,</em><span id="S6.T12.8.32.1.1.1.7" class="ltx_text" style="font-size:70%;"> </span><em id="S6.T12.8.32.1.1.1.8" class="ltx_emph ltx_font_italic" style="font-size:70%;">ABCD</em><span id="S6.T12.8.32.1.1.1.9" class="ltx_text" style="font-size:70%;">) to the unsorted items and instruct the LLMs to directly output the sorted indicators.</span></span>
</span>
</td>
<td id="S6.T12.8.32.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T12.8.32.2.1" class="ltx_text" style="font-size:70%;">①</span></td>
</tr>
</tbody></table>
</figure>
<div id="S6.SS1.SSS1.p13" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS1.SSS1.p13.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.SSS1.p13.1.1">Empirical Analysis. </span> 프롬프트가 작업 수행에 미치는 영향을 제시하기 위해 경험적 연구를 추가로 수행한다. 실험을 수행하기 위해 언어 생성, 지식 활용, 복잡한 추론, 구조 데이터 생성, 정보 검색에 걸쳐 있는 다양한 태스크를 선택한다. 각 작업에 대해 위에서 소개한 일반적인 지침을 따르는 프롬프트를 수동으로 작성합니다. 테스트된 프롬프트는 주로 독자가 다양한 작업을 해결하기 위해 효과적인 프롬프트를 작성하는 방법을 이해하는 데 도움이 되기 때문에 이러한 작업에 최적이 아닐 수 있습니다. 또한 대부분의 작업에 대한 비교로 간략화된 프롬프트를 추가합니다. <a class="ltx_ref" href="#S7.SS4" title="7.4 Empirical Evaluation ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.4</span></a> 섹션의 실험 설정에 따라 복합 추론 태스크(Colored Objects and GSM8k)에 대한 ChatGPT의 3-shot 성능과 다른 태스크에 대한 zero-shot 성능을 살펴본다. 실험 결과를 표 <a class="ltx_ref" href="#S7.T17" title="TABLE XVII ‣ 7.3.2 Evaluation Approaches ‣ 7.3 Benchmarks and Evaluation Approaches ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XVII</span></a>에 보고하며, 여기에는 기존 논문의 감독 성능도 참조로 포함한다.</p>
</div>
<div id="S6.SS1.SSS1.p14" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p14.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS1.p14.1.m1.1"><semantics id="S6.SS1.SSS1.p14.1.m1.1a"><mo id="S6.SS1.SSS1.p14.1.m1.1.1" xref="S6.SS1.SSS1.p14.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p14.1.m1.1b"><ci id="S6.SS1.SSS1.p14.1.m1.1.1.cmml" xref="S6.SS1.SSS1.p14.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p14.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p14.1.1">Carefully designed prompts can boost the zero-shot or few-shot performance of ChatGPT. </em> 동일한 작업에서 서로 다른 프롬프트를 사용한 결과를 비교함으로써 신중하게 설계된 프롬프트를 사용하면 더 간단한 프롬프트보다 더 나은 성능을 얻을 수 있음을 알 수 있다. 세심하게 설계된 프롬프트에서 더 명확하게 표현된 작업 설명(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p14.1.2">e.g.,</em> WMT 및 WikiFact)을 제공하거나 모델 친화적인 형식을 사용합니다(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p14.1.3">e.g.,</em> GSM8k 및 OBQA). 예를 들어, WikiFact 태스크의 경우, 더 상세한 태스크 설명을 갖는 프롬프트는 29.25에서 31.21로 성능 증가로 이어진다.</p>
</div>
<div id="S6.SS1.SSS1.p15" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p15.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS1.p15.1.m1.1"><semantics id="S6.SS1.SSS1.p15.1.m1.1a"><mo id="S6.SS1.SSS1.p15.1.m1.1.1" xref="S6.SS1.SSS1.p15.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p15.1.m1.1b"><ci id="S6.SS1.SSS1.p15.1.m1.1.1.cmml" xref="S6.SS1.SSS1.p15.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p15.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p15.1.1">More complex tasks can benefit more from careful prompt engineering on ChatGPT. </em> WikiFact 및 Colored Objects 태스크에서 설계된 프롬프트는 ChatGPT, <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p15.1.2">i.e.,</em>은 WikiFact에서 23.61에서 28.47, Colored Objects에서 53.20에서 66.75의 성능을 크게 향상시켰습니다. 이러한 작업은 일반적으로 특정 출력 형식을 갖거나 배경 지식이 필요하기 때문에 LLM이 복잡한 작업에서 잘 수행되기 위해서는 신속한 엔지니어링이 필요함을 나타낸다. 예제 프롬프트는 ChatGPT가 이를 충족하기 위한 복잡한 작업 요구 사항을 더 잘 이해하는 데 도움이 될 수 있는 더 자세한 작업 설명(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p15.1.3">e.g.,</em> output format and task goal)을 제공합니다.</p>
</div>
<div id="S6.SS1.SSS1.p16" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p16.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS1.p16.1.m1.1"><semantics id="S6.SS1.SSS1.p16.1.m1.1a"><mo id="S6.SS1.SSS1.p16.1.m1.1.1" xref="S6.SS1.SSS1.p16.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p16.1.m1.1b"><ci id="S6.SS1.SSS1.p16.1.m1.1.1.cmml" xref="S6.SS1.SSS1.p16.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p16.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p16.1.1">수학 추론 작업을 위해 프로그래밍 언어의 형식을 기반으로 특정 프롬프트를 설계하는 것이 더 효과적이다. </em> GSM8k의 경우, 설계된 프롬프트는 이 수학적 추론 작업을 코드 생성 작업으로 변환하기 위해 코드 형식의 소수 샷 데모를 사용하며, 이는 ChatGPT의 강력한 코드 합성 능력을 수학적 문제 해결에 활용할 수 있다. 또한, 외부 프로그램 실행기의 도움으로 LLM을 산술 연산에 사용하는 대신 보다 정확한 결과를 얻을 수 있다. 우리가 볼 수 있듯이, GSM8k에서 성능은 78.47에서 79.30으로 향상되어 수학적 추론 과제에서 프로그래밍 언어의 유용성을 나타낸다.</p>
</div>
<div id="S6.SS1.SSS1.p17" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p17.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS1.p17.1.m1.1"><semantics id="S6.SS1.SSS1.p17.1.m1.1a"><mo id="S6.SS1.SSS1.p17.1.m1.1.1" xref="S6.SS1.SSS1.p17.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p17.1.m1.1b"><ci id="S6.SS1.SSS1.p17.1.m1.1.1.cmml" xref="S6.SS1.SSS1.p17.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p17.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p17.1.1">지식 활용 및 복잡한 추론 작업에서 적절한 프롬프트를 가진 ChatGPT는 비교 가능한 성능을 달성하거나 심지어 지도된 베이스라인 메서드를 능가합니다. </em> 지식 활용 및 복잡한 추론 작업에서 적절한 zero-shot 또는 few-shot 프롬프트를 가진 ChatGPT는 비교 가능한 성능을 달성하거나 지도된 방법, <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p17.1.2">e.g.,</em> 31.21 (ChatGPT) <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p17.1.3">v.s.</em> 34.20 (supervised baseline) on WikiFact. 그럼에도 불구하고, ChatGPT는 일부 특정 태스크(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p17.1.4">e.g.,</em> ARC 및 WikiFact)에 대해 감독된 기준 모델보다 더 나쁜 성능을 여전히 수행하는데, 이러한 감독된 모델은 태스크별 데이터로 특별히 최적화되었기 때문이다.</p>
</div>
<div id="S6.SS1.SSS1.p18" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS1.p18.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS1.p18.1.m1.1"><semantics id="S6.SS1.SSS1.p18.1.m1.1a"><mo id="S6.SS1.SSS1.p18.1.m1.1.1" xref="S6.SS1.SSS1.p18.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p18.1.m1.1b"><ci id="S6.SS1.SSS1.p18.1.m1.1.1.cmml" xref="S6.SS1.SSS1.p18.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p18.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p18.1.1">적절한 프롬프트 엔지니어링을 통해 LLMs는 일부 비전통적인 NLP 작업을 처리할 수 있다. </em> 특정 프롬프트의 도움으로 ChatGPT는 비전통적인 NLP 작업인 <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS1.p18.1.2">i.e.,</em> 일반 권장 사항 및 대화 권장 사항도 달성할 수 있습니다. 핵심적인 점은 이러한 작업들이 자연어로 잘 표현되거나 기술될 수 있다는 것이다. 그러나 ChatGPT의 성능은 LLM이 특정 도메인 지식과 작업 적응을 필요로 하는 이러한 작업에 직접 적합할 수 없기 때문에 이러한 작업에서 참조된 성능과 여전히 거리가 멀다.</p>
</div>
<figure id="S6.T13" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">TABLE XIII:</span>Example instructions collected from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib454" title="">454</a>, <a class="ltx_ref" href="#bib.bib463" title="">463</a>]</cite>. <span class="ltx_text" id="S6.T13.38.1" style="background-color:#B0E2FF;">blue</span> text는 작업 설명을 나타내고, <span class="ltx_text" id="S6.T13.39.2" style="background-color:#FFCCCC;">red</span> text는 상황 정보를 나타내며, <span class="ltx_text" id="S6.T13.40.3" style="background-color:#CDE6C7;">green</span> text는 데모를 나타내고, <span class="ltx_text" id="S6.T13.41.4" style="background-color:#FFF68F;">gold</span> text는 프롬프트 스타일을 나타낸다.</figcaption>
<table id="S6.T13.24" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S6.T13.24.25" class="ltx_tr" style="background-color:#B0E2FF;">
<td id="S6.T13.24.25.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T13.24.25.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#B0E2FF;">
<span id="S6.T13.24.25.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.25.1.1.1.1" class="ltx_text" style="font-size:80%;">Use the provided articles delimited by triple quotes to answer questions. If the answer cannot be found in the articles, write “I could not find an answer.”</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.26" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.24.26.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T13.24.26.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.26.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.26.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Articles:</span><span id="S6.T13.24.26.1.1.1.2" class="ltx_text" style="font-size:80%;"> “““Joao Moutinho is a Portuguese footballer who last played as a central midfielder for Premier League club Wolverhampton Wanderers and the Portugal national team.”””</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.27" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.24.27.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T13.24.27.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.24.27.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.27.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Question:</span><span id="S6.T13.24.27.1.1.1.2" class="ltx_text" style="font-size:80%;"> Is the following sentence plausible?
’Joao Moutinho was out at third.’</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.28" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.24.28.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.28.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.24.28.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.28.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Answer:</span><span id="S6.T13.24.28.1.1.1.2" class="ltx_text" style="font-size:80%;"> </span><span id="S6.T13.24.28.1.1.1.3" class="ltx_text" style="font-size:80%;background-color:#EEE685;">Let’s think step by step. Joao Moutinho is a soccer player. Being out at third is part of baseball, not soccer.</span><span id="S6.T13.24.28.1.1.1.4" class="ltx_text" style="font-size:80%;"> So the answer is No.</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.29" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.24.29.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.29.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.24.29.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.29.1.1.1.1" class="ltx_text" style="font-size:80%;">…</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.2.2" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.2.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.2.2.2.2" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.2.2.2.2.2" class="ltx_p" style="width:433.6pt;"><math id="S6.T13.1.1.1.1.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T13.1.1.1.1.1.m1.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.1.1.1.1.1.m1.1.1" xref="S6.T13.1.1.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.1.1.1.1.1.m1.1b"><lt id="S6.T13.1.1.1.1.1.m1.1.1.cmml" xref="S6.T13.1.1.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.1.1.1.1.1.m1.1c">&lt;</annotation></semantics></math><span id="S6.T13.2.2.2.2.2.1" class="ltx_text" style="font-size:80%;">Demonstrations</span><math id="S6.T13.2.2.2.2.2.m2.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S6.T13.2.2.2.2.2.m2.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.2.2.2.2.2.m2.1.1" xref="S6.T13.2.2.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.2.2.2.2.2.m2.1b"><gt id="S6.T13.2.2.2.2.2.m2.1.1.cmml" xref="S6.T13.2.2.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.2.2.2.2.2.m2.1c">&gt;</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S6.T13.4.4" class="ltx_tr">
<td id="S6.T13.4.4.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.4.4.2.2" class="ltx_inline-block ltx_align_top">
<span id="S6.T13.4.4.2.2.2" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.4.4.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Articles:</span><span id="S6.T13.4.4.2.2.2.2" class="ltx_text" style="font-size:80%;"> </span><math id="S6.T13.3.3.1.1.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T13.3.3.1.1.1.m1.1a"><mo mathsize="80%" id="S6.T13.3.3.1.1.1.m1.1.1" xref="S6.T13.3.3.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.3.3.1.1.1.m1.1b"><lt id="S6.T13.3.3.1.1.1.m1.1.1.cmml" xref="S6.T13.3.3.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.3.3.1.1.1.m1.1c">&lt;</annotation></semantics></math><span id="S6.T13.4.4.2.2.2.3" class="ltx_text" style="font-size:80%;">insert articles, each delimited by triple quotes</span><math id="S6.T13.4.4.2.2.2.m2.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S6.T13.4.4.2.2.2.m2.1a"><mo mathsize="80%" id="S6.T13.4.4.2.2.2.m2.1.1" xref="S6.T13.4.4.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.4.4.2.2.2.m2.1b"><gt id="S6.T13.4.4.2.2.2.m2.1.1.cmml" xref="S6.T13.4.4.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.4.4.2.2.2.m2.1c">&gt;</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S6.T13.6.6" class="ltx_tr">
<td id="S6.T13.6.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.6.6.2.2" class="ltx_inline-block ltx_align_top">
<span id="S6.T13.6.6.2.2.2" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.6.6.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Question:</span><span id="S6.T13.6.6.2.2.2.2" class="ltx_text" style="font-size:80%;"> </span><math id="S6.T13.5.5.1.1.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T13.5.5.1.1.1.m1.1a"><mo mathsize="80%" id="S6.T13.5.5.1.1.1.m1.1.1" xref="S6.T13.5.5.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.5.5.1.1.1.m1.1b"><lt id="S6.T13.5.5.1.1.1.m1.1.1.cmml" xref="S6.T13.5.5.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.5.5.1.1.1.m1.1c">&lt;</annotation></semantics></math><span id="S6.T13.6.6.2.2.2.3" class="ltx_text" style="font-size:80%;">insert question</span><math id="S6.T13.6.6.2.2.2.m2.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S6.T13.6.6.2.2.2.m2.1a"><mo mathsize="80%" id="S6.T13.6.6.2.2.2.m2.1.1" xref="S6.T13.6.6.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.6.6.2.2.2.m2.1b"><gt id="S6.T13.6.6.2.2.2.m2.1.1.cmml" xref="S6.T13.6.6.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.6.6.2.2.2.m2.1c">&gt;</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.30" class="ltx_tr">
<td id="S6.T13.24.30.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T13.24.30.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.30.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Answer:</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.31" class="ltx_tr" style="background-color:#B0E2FF;">
<td id="S6.T13.24.31.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T13.24.31.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#B0E2FF;">
<span id="S6.T13.24.31.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.31.1.1.1.1" class="ltx_text" style="font-size:80%;">Prepare a meta-review by answering the following questions from the reviewer comments (provided after the questions).</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.32" class="ltx_tr" style="background-color:#FFF68F;">
<td id="S6.T13.24.32.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T13.24.32.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFF68F;">
<span id="S6.T13.24.32.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.32.1.1.1.1" class="ltx_text" style="font-size:80%;">1. Based on the reviewer’s comments, what are the core contributions made by this manuscript?</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.33" class="ltx_tr" style="background-color:#FFF68F;">
<td id="S6.T13.24.33.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.33.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFF68F;">
<span id="S6.T13.24.33.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.33.1.1.1.1" class="ltx_text" style="font-size:80%;">2. What are the common strengths of this work, as mentioned by multiple reviewers?</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.34" class="ltx_tr" style="background-color:#FFF68F;">
<td id="S6.T13.24.34.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.34.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFF68F;">
<span id="S6.T13.24.34.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.34.1.1.1.1" class="ltx_text" style="font-size:80%;">3. What are the common weaknesses of this work, as highlighted by multiple reviewers?</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.35" class="ltx_tr" style="background-color:#FFF68F;">
<td id="S6.T13.24.35.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.35.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFF68F;">
<span id="S6.T13.24.35.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.35.1.1.1.1" class="ltx_text" style="font-size:80%;">4. What suggestions would you provide for improving this paper?</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.36" class="ltx_tr" style="background-color:#FFF68F;">
<td id="S6.T13.24.36.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.36.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFF68F;">
<span id="S6.T13.24.36.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.36.1.1.1.1" class="ltx_text" style="font-size:80%;">5. What are the missing references mentioned by the individual reviews?</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.11.11" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.11.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T13.11.11.5.5" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.11.11.5.5.5" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.11.11.5.5.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">The review texts are below:</span><span id="S6.T13.11.11.5.5.5.2" class="ltx_text" style="font-size:80%;"> </span><math id="S6.T13.7.7.1.1.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T13.7.7.1.1.1.m1.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.7.7.1.1.1.m1.1.1" xref="S6.T13.7.7.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.7.7.1.1.1.m1.1b"><lt id="S6.T13.7.7.1.1.1.m1.1.1.cmml" xref="S6.T13.7.7.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.7.7.1.1.1.m1.1c">&lt;</annotation></semantics></math><span id="S6.T13.11.11.5.5.5.3" class="ltx_text" style="font-size:80%;">insert three comments </span><math id="S6.T13.8.8.2.2.2.m2.1" class="ltx_Math" alttext="R_{1}" display="inline"><semantics id="S6.T13.8.8.2.2.2.m2.1a"><msub id="S6.T13.8.8.2.2.2.m2.1.1" xref="S6.T13.8.8.2.2.2.m2.1.1.cmml"><mi mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.8.8.2.2.2.m2.1.1.2" xref="S6.T13.8.8.2.2.2.m2.1.1.2.cmml">R</mi><mn mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.8.8.2.2.2.m2.1.1.3" xref="S6.T13.8.8.2.2.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S6.T13.8.8.2.2.2.m2.1b"><apply id="S6.T13.8.8.2.2.2.m2.1.1.cmml" xref="S6.T13.8.8.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S6.T13.8.8.2.2.2.m2.1.1.1.cmml" xref="S6.T13.8.8.2.2.2.m2.1.1">subscript</csymbol><ci id="S6.T13.8.8.2.2.2.m2.1.1.2.cmml" xref="S6.T13.8.8.2.2.2.m2.1.1.2">𝑅</ci><cn type="integer" id="S6.T13.8.8.2.2.2.m2.1.1.3.cmml" xref="S6.T13.8.8.2.2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.8.8.2.2.2.m2.1c">R_{1}</annotation></semantics></math><span id="S6.T13.11.11.5.5.5.4" class="ltx_text" style="font-size:80%;">, </span><math id="S6.T13.9.9.3.3.3.m3.1" class="ltx_Math" alttext="R_{2}" display="inline"><semantics id="S6.T13.9.9.3.3.3.m3.1a"><msub id="S6.T13.9.9.3.3.3.m3.1.1" xref="S6.T13.9.9.3.3.3.m3.1.1.cmml"><mi mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.9.9.3.3.3.m3.1.1.2" xref="S6.T13.9.9.3.3.3.m3.1.1.2.cmml">R</mi><mn mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.9.9.3.3.3.m3.1.1.3" xref="S6.T13.9.9.3.3.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.T13.9.9.3.3.3.m3.1b"><apply id="S6.T13.9.9.3.3.3.m3.1.1.cmml" xref="S6.T13.9.9.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="S6.T13.9.9.3.3.3.m3.1.1.1.cmml" xref="S6.T13.9.9.3.3.3.m3.1.1">subscript</csymbol><ci id="S6.T13.9.9.3.3.3.m3.1.1.2.cmml" xref="S6.T13.9.9.3.3.3.m3.1.1.2">𝑅</ci><cn type="integer" id="S6.T13.9.9.3.3.3.m3.1.1.3.cmml" xref="S6.T13.9.9.3.3.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.9.9.3.3.3.m3.1c">R_{2}</annotation></semantics></math><span id="S6.T13.11.11.5.5.5.5" class="ltx_text" style="font-size:80%;">, </span><math id="S6.T13.10.10.4.4.4.m4.1" class="ltx_Math" alttext="R_{3}" display="inline"><semantics id="S6.T13.10.10.4.4.4.m4.1a"><msub id="S6.T13.10.10.4.4.4.m4.1.1" xref="S6.T13.10.10.4.4.4.m4.1.1.cmml"><mi mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.10.10.4.4.4.m4.1.1.2" xref="S6.T13.10.10.4.4.4.m4.1.1.2.cmml">R</mi><mn mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.10.10.4.4.4.m4.1.1.3" xref="S6.T13.10.10.4.4.4.m4.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S6.T13.10.10.4.4.4.m4.1b"><apply id="S6.T13.10.10.4.4.4.m4.1.1.cmml" xref="S6.T13.10.10.4.4.4.m4.1.1"><csymbol cd="ambiguous" id="S6.T13.10.10.4.4.4.m4.1.1.1.cmml" xref="S6.T13.10.10.4.4.4.m4.1.1">subscript</csymbol><ci id="S6.T13.10.10.4.4.4.m4.1.1.2.cmml" xref="S6.T13.10.10.4.4.4.m4.1.1.2">𝑅</ci><cn type="integer" id="S6.T13.10.10.4.4.4.m4.1.1.3.cmml" xref="S6.T13.10.10.4.4.4.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.10.10.4.4.4.m4.1c">R_{3}</annotation></semantics></math><span id="S6.T13.11.11.5.5.5.6" class="ltx_text" style="font-size:80%;"> from the reviewers</span><math id="S6.T13.11.11.5.5.5.m5.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S6.T13.11.11.5.5.5.m5.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.11.11.5.5.5.m5.1.1" xref="S6.T13.11.11.5.5.5.m5.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.11.11.5.5.5.m5.1b"><gt id="S6.T13.11.11.5.5.5.m5.1.1.cmml" xref="S6.T13.11.11.5.5.5.m5.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.11.11.5.5.5.m5.1c">&gt;</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S6.T13.13.13" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.13.13.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.13.13.2.2" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.13.13.2.2.2" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.13.13.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Meta-review:</span><span id="S6.T13.13.13.2.2.2.2" class="ltx_text" style="font-size:80%;"> </span><math id="S6.T13.12.12.1.1.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T13.12.12.1.1.1.m1.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.12.12.1.1.1.m1.1.1" xref="S6.T13.12.12.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.12.12.1.1.1.m1.1b"><lt id="S6.T13.12.12.1.1.1.m1.1.1.cmml" xref="S6.T13.12.12.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.12.12.1.1.1.m1.1c">&lt;</annotation></semantics></math><span id="S6.T13.13.13.2.2.2.3" class="ltx_text" style="font-size:80%;">insert meta-review</span><math id="S6.T13.13.13.2.2.2.m2.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S6.T13.13.13.2.2.2.m2.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.13.13.2.2.2.m2.1.1" xref="S6.T13.13.13.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.13.13.2.2.2.m2.1b"><gt id="S6.T13.13.13.2.2.2.m2.1.1.cmml" xref="S6.T13.13.13.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.13.13.2.2.2.m2.1c">&gt;</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.37" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.24.37.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.37.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.24.37.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.37.1.1.1.1" class="ltx_text" style="font-size:80%;">…</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.15.15" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.15.15.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.15.15.2.2" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.15.15.2.2.2" class="ltx_p" style="width:433.6pt;"><math id="S6.T13.14.14.1.1.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T13.14.14.1.1.1.m1.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.14.14.1.1.1.m1.1.1" xref="S6.T13.14.14.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.14.14.1.1.1.m1.1b"><lt id="S6.T13.14.14.1.1.1.m1.1.1.cmml" xref="S6.T13.14.14.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.14.14.1.1.1.m1.1c">&lt;</annotation></semantics></math><span id="S6.T13.15.15.2.2.2.1" class="ltx_text" style="font-size:80%;">Demonstrations</span><math id="S6.T13.15.15.2.2.2.m2.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S6.T13.15.15.2.2.2.m2.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.15.15.2.2.2.m2.1.1" xref="S6.T13.15.15.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.15.15.2.2.2.m2.1b"><gt id="S6.T13.15.15.2.2.2.m2.1.1.cmml" xref="S6.T13.15.15.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.15.15.2.2.2.m2.1c">&gt;</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.38" class="ltx_tr">
<td id="S6.T13.24.38.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.38.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T13.24.38.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.38.1.1.1.1" class="ltx_text" style="font-size:80%;">Provide justification for your response in detail by explaining why you made the choices you actually made. A good output should be coherent, highlight major strengths/issues mentioned by multiple reviewers, be less than 400 words in length, and finally, the response should be in English only.</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.20.20" class="ltx_tr">
<td id="S6.T13.20.20.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.20.20.5.5" class="ltx_inline-block ltx_align_top">
<span id="S6.T13.20.20.5.5.5" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.20.20.5.5.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">The review texts are below:</span><span id="S6.T13.20.20.5.5.5.2" class="ltx_text" style="font-size:80%;"> </span><math id="S6.T13.16.16.1.1.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T13.16.16.1.1.1.m1.1a"><mo mathsize="80%" id="S6.T13.16.16.1.1.1.m1.1.1" xref="S6.T13.16.16.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.16.16.1.1.1.m1.1b"><lt id="S6.T13.16.16.1.1.1.m1.1.1.cmml" xref="S6.T13.16.16.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.16.16.1.1.1.m1.1c">&lt;</annotation></semantics></math><span id="S6.T13.20.20.5.5.5.3" class="ltx_text" style="font-size:80%;">insert three comments </span><math id="S6.T13.17.17.2.2.2.m2.1" class="ltx_Math" alttext="R_{1}" display="inline"><semantics id="S6.T13.17.17.2.2.2.m2.1a"><msub id="S6.T13.17.17.2.2.2.m2.1.1" xref="S6.T13.17.17.2.2.2.m2.1.1.cmml"><mi mathsize="80%" id="S6.T13.17.17.2.2.2.m2.1.1.2" xref="S6.T13.17.17.2.2.2.m2.1.1.2.cmml">R</mi><mn mathsize="80%" id="S6.T13.17.17.2.2.2.m2.1.1.3" xref="S6.T13.17.17.2.2.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S6.T13.17.17.2.2.2.m2.1b"><apply id="S6.T13.17.17.2.2.2.m2.1.1.cmml" xref="S6.T13.17.17.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S6.T13.17.17.2.2.2.m2.1.1.1.cmml" xref="S6.T13.17.17.2.2.2.m2.1.1">subscript</csymbol><ci id="S6.T13.17.17.2.2.2.m2.1.1.2.cmml" xref="S6.T13.17.17.2.2.2.m2.1.1.2">𝑅</ci><cn type="integer" id="S6.T13.17.17.2.2.2.m2.1.1.3.cmml" xref="S6.T13.17.17.2.2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.17.17.2.2.2.m2.1c">R_{1}</annotation></semantics></math><span id="S6.T13.20.20.5.5.5.4" class="ltx_text" style="font-size:80%;">, </span><math id="S6.T13.18.18.3.3.3.m3.1" class="ltx_Math" alttext="R_{2}" display="inline"><semantics id="S6.T13.18.18.3.3.3.m3.1a"><msub id="S6.T13.18.18.3.3.3.m3.1.1" xref="S6.T13.18.18.3.3.3.m3.1.1.cmml"><mi mathsize="80%" id="S6.T13.18.18.3.3.3.m3.1.1.2" xref="S6.T13.18.18.3.3.3.m3.1.1.2.cmml">R</mi><mn mathsize="80%" id="S6.T13.18.18.3.3.3.m3.1.1.3" xref="S6.T13.18.18.3.3.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.T13.18.18.3.3.3.m3.1b"><apply id="S6.T13.18.18.3.3.3.m3.1.1.cmml" xref="S6.T13.18.18.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="S6.T13.18.18.3.3.3.m3.1.1.1.cmml" xref="S6.T13.18.18.3.3.3.m3.1.1">subscript</csymbol><ci id="S6.T13.18.18.3.3.3.m3.1.1.2.cmml" xref="S6.T13.18.18.3.3.3.m3.1.1.2">𝑅</ci><cn type="integer" id="S6.T13.18.18.3.3.3.m3.1.1.3.cmml" xref="S6.T13.18.18.3.3.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.18.18.3.3.3.m3.1c">R_{2}</annotation></semantics></math><span id="S6.T13.20.20.5.5.5.5" class="ltx_text" style="font-size:80%;">, </span><math id="S6.T13.19.19.4.4.4.m4.1" class="ltx_Math" alttext="R_{3}" display="inline"><semantics id="S6.T13.19.19.4.4.4.m4.1a"><msub id="S6.T13.19.19.4.4.4.m4.1.1" xref="S6.T13.19.19.4.4.4.m4.1.1.cmml"><mi mathsize="80%" id="S6.T13.19.19.4.4.4.m4.1.1.2" xref="S6.T13.19.19.4.4.4.m4.1.1.2.cmml">R</mi><mn mathsize="80%" id="S6.T13.19.19.4.4.4.m4.1.1.3" xref="S6.T13.19.19.4.4.4.m4.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S6.T13.19.19.4.4.4.m4.1b"><apply id="S6.T13.19.19.4.4.4.m4.1.1.cmml" xref="S6.T13.19.19.4.4.4.m4.1.1"><csymbol cd="ambiguous" id="S6.T13.19.19.4.4.4.m4.1.1.1.cmml" xref="S6.T13.19.19.4.4.4.m4.1.1">subscript</csymbol><ci id="S6.T13.19.19.4.4.4.m4.1.1.2.cmml" xref="S6.T13.19.19.4.4.4.m4.1.1.2">𝑅</ci><cn type="integer" id="S6.T13.19.19.4.4.4.m4.1.1.3.cmml" xref="S6.T13.19.19.4.4.4.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.19.19.4.4.4.m4.1c">R_{3}</annotation></semantics></math><span id="S6.T13.20.20.5.5.5.6" class="ltx_text" style="font-size:80%;"> from the reviewers</span><math id="S6.T13.20.20.5.5.5.m5.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S6.T13.20.20.5.5.5.m5.1a"><mo mathsize="80%" id="S6.T13.20.20.5.5.5.m5.1.1" xref="S6.T13.20.20.5.5.5.m5.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.20.20.5.5.5.m5.1b"><gt id="S6.T13.20.20.5.5.5.m5.1.1.cmml" xref="S6.T13.20.20.5.5.5.m5.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.20.20.5.5.5.m5.1c">&gt;</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.39" class="ltx_tr">
<td id="S6.T13.24.39.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.39.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T13.24.39.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.39.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Meta-review:</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.40" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.40.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T13.24.40.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.40.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.40.1.1.1.1" class="ltx_text" style="font-size:80%;">CREATE TABLE Highschooler (</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.41" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.41.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.41.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.41.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.41.1.1.1.1" class="ltx_text" style="font-size:80%;">ID int primary key,</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.42" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.42.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.42.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.42.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.42.1.1.1.1" class="ltx_text" style="font-size:80%;">name text,</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.43" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.43.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.43.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.43.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.43.1.1.1.1" class="ltx_text" style="font-size:80%;">grade int</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.44" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.44.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.44.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.44.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.44.1.1.1.1" class="ltx_text" style="font-size:80%;">);</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.45" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.45.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.45.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.45.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.45.1.1.1.1" class="ltx_text" style="font-size:80%;">/*</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.46" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.46.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.46.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.46.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.46.1.1.1.1" class="ltx_text" style="font-size:80%;">3 example rows:</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.47" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.47.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.47.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.47.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.47.1.1.1.1" class="ltx_text" style="font-size:80%;">SELECT * FROM Highschooler LIMIT 3;</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.48" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.48.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.48.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.48.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.48.1.1.1.1" class="ltx_text" style="font-size:80%;">ID  name  grade</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.49" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.49.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.49.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.49.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.49.1.1.1.1" class="ltx_text" style="font-size:80%;">1234  Janie  8</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.50" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.50.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.50.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.50.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.50.1.1.1.1" class="ltx_text" style="font-size:80%;">5678  Mary  8</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.51" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.51.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.51.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.51.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.51.1.1.1.1" class="ltx_text" style="font-size:80%;">9012  Mike  9</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.52" class="ltx_tr" style="background-color:#FFCCCC;">
<td id="S6.T13.24.52.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.52.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#FFCCCC;">
<span id="S6.T13.24.52.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.52.1.1.1.1" class="ltx_text" style="font-size:80%;">*/</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.53" class="ltx_tr" style="background-color:#B0E2FF;">
<td id="S6.T13.24.53.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T13.24.53.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#B0E2FF;">
<span id="S6.T13.24.53.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.53.1.1.1.1" class="ltx_text" style="font-size:80%;">Using valid SQLite, answer the following questions for the tables provided above.</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.54" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.24.54.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T13.24.54.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.24.54.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.54.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Question:</span><span id="S6.T13.24.54.1.1.1.2" class="ltx_text" style="font-size:80%;"> What is Kyle’s id?</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.55" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.24.55.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.55.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.24.55.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.55.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SQL:</span><span id="S6.T13.24.55.1.1.1.2" class="ltx_text" style="font-size:80%;"> SELECT ID FROM Highschooler WHERE name=“Kyle”;</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.56" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.24.56.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.56.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.24.56.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.56.1.1.1.1" class="ltx_text" style="font-size:80%;">…</span></span>
</span>
</td>
</tr>
<tr id="S6.T13.22.22" class="ltx_tr" style="background-color:#CDE6C7;">
<td id="S6.T13.22.22.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.22.22.2.2" class="ltx_inline-block ltx_align_top" style="background-color:#CDE6C7;">
<span id="S6.T13.22.22.2.2.2" class="ltx_p" style="width:433.6pt;"><math id="S6.T13.21.21.1.1.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T13.21.21.1.1.1.m1.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.21.21.1.1.1.m1.1.1" xref="S6.T13.21.21.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.21.21.1.1.1.m1.1b"><lt id="S6.T13.21.21.1.1.1.m1.1.1.cmml" xref="S6.T13.21.21.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.21.21.1.1.1.m1.1c">&lt;</annotation></semantics></math><span id="S6.T13.22.22.2.2.2.1" class="ltx_text" style="font-size:80%;">Demonstrations</span><math id="S6.T13.22.22.2.2.2.m2.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S6.T13.22.22.2.2.2.m2.1a"><mo mathbackground="#CDE6C7" mathsize="80%" id="S6.T13.22.22.2.2.2.m2.1.1" xref="S6.T13.22.22.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.22.22.2.2.2.m2.1b"><gt id="S6.T13.22.22.2.2.2.m2.1.1.cmml" xref="S6.T13.22.22.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.22.22.2.2.2.m2.1c">&gt;</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.24" class="ltx_tr">
<td id="S6.T13.24.24.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.T13.24.24.2.2" class="ltx_inline-block ltx_align_top">
<span id="S6.T13.24.24.2.2.2" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.24.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Question:</span><span id="S6.T13.24.24.2.2.2.2" class="ltx_text" style="font-size:80%;"> </span><math id="S6.T13.23.23.1.1.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T13.23.23.1.1.1.m1.1a"><mo mathsize="80%" id="S6.T13.23.23.1.1.1.m1.1.1" xref="S6.T13.23.23.1.1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.23.23.1.1.1.m1.1b"><lt id="S6.T13.23.23.1.1.1.m1.1.1.cmml" xref="S6.T13.23.23.1.1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.23.23.1.1.1.m1.1c">&lt;</annotation></semantics></math><span id="S6.T13.24.24.2.2.2.3" class="ltx_text" style="font-size:80%;">insert question</span><math id="S6.T13.24.24.2.2.2.m2.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S6.T13.24.24.2.2.2.m2.1a"><mo mathsize="80%" id="S6.T13.24.24.2.2.2.m2.1.1" xref="S6.T13.24.24.2.2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S6.T13.24.24.2.2.2.m2.1b"><gt id="S6.T13.24.24.2.2.2.m2.1.1.cmml" xref="S6.T13.24.24.2.2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S6.T13.24.24.2.2.2.m2.1c">&gt;</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S6.T13.24.57" class="ltx_tr">
<td id="S6.T13.24.57.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S6.T13.24.57.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T13.24.57.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S6.T13.24.57.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SQL:</span></span>
</span>
</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S6.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.2 </span>Prompt Optimization</h4>

<div id="S6.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS2.p1.1">작업 프롬프트를 수동으로 만드는 것이 더 직관적이지만 시간이 많이 걸리고 더 중요한 것은 모델이 조작된 프롬프트에 매우 민감하다는 것입니다. 잘못된 프롬프트는 작업 성능을 낮춥니다(표 <a class="ltx_ref" href="#S7.T17" title="TABLE XVII ‣ 7.3.2 Evaluation Approaches ‣ 7.3 Benchmarks and Evaluation Approaches ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XVII</span></a>와 같이). 따라서 많은 연구에서 최적의 성능을 얻기 위해 이산 프롬프트와 연속 프롬프트에 대한 자동 최적화 접근법을 제안한다. 이 부분에서는 <em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS2.p1.1.1">i.e.,</em> 이산 프롬프트와 연속 프롬프트의 두 가지 관점에서 이러한 연구를 자세히 설명한다.</p>
</div>
<div id="S6.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.SSS2.p2.1.1">Discrete Prompt Optimization. </span> 이산 프롬프트는 일반적으로 자연어 토큰의 시퀀스로 구성된다. 형태가 단순하고 유연함에도 불구하고, 이산 공간에서 프롬프트를 최적화하는 것은 조합적인 거대한 탐색 공간으로 인해 어려운 문제이다. 다운스트림 작업에 대한 효과적인 프롬프트를 자동으로 검색하기 위해 기존 연구에서는 광범위한 이산 프롬프트 접근법을 제안하며, 다음과 같이 자세히 설명한다.</p>
</div>
<div id="S6.SS1.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS2.p3.1.m1.1"><semantics id="S6.SS1.SSS2.p3.1.m1.1a"><mo id="S6.SS1.SSS2.p3.1.m1.1.1" xref="S6.SS1.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p3.1.m1.1b"><ci id="S6.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS2.p3.1.1">Gradient-based approaches. </span> 이러한 종류의 접근법은 gradient update <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib405" title="">405</a>, <a class="ltx_ref" href="#bib.bib464" title="">464</a>, <a class="ltx_ref" href="#bib.bib465" title="">465</a>, <a class="ltx_ref" href="#bib.bib466" title="">466</a>]</cite>를 통해 출력 우도를 최대화함으로써 프롬프트 검색 프로세스를 최적화하는 것을 목표로 한다. 대표적인 작업으로 Auto-Prompt<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib405" title="">405</a>]</cite>는 어휘에서 프롬프트 토큰을 다른 후보 토큰으로 대체할 때 로그 우도의 변화로 근사화된 그래디언트를 활용하여 프롬프트의 각 위치에 대한 최적의 토큰을 탐욕적으로 탐색하는 그래디언트 유도 방법을 제안한다. 그러나, 이러한 검색 프로세스는 프롬프트의 각각의 위치에 대해 각각의 후보 토큰을 평가해야 하기 때문에 매우 고가일 수 있으며, 이는 다수의 추가적인 순방향 패스로 이어진다. 따라서 이산 토큰을 연속 임베딩으로 변환하고 최적화 동안 연속 공간에서 그래디언트를 계산하여 개선된 그래디언트 방법<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib464" title="">464</a>]</cite>가 제안되었다.</p>
</div>
<div id="S6.SS1.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS2.p4.1.m1.1"><semantics id="S6.SS1.SSS2.p4.1.m1.1a"><mo id="S6.SS1.SSS2.p4.1.m1.1.1" xref="S6.SS1.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p4.1.m1.1b"><ci id="S6.SS1.SSS2.p4.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS2.p4.1.1">RL 기반 접근법. </span> 이산 프롬프트는 그래디언트 역전파(gradient back-propagation)를 통해 학습되기 어렵기 때문에, 다수의 연구에서 이산 프롬프트 최적화를 강화 학습(reinforcement learning; RL) 문제로 공식화하고 최적화 [cite idx=0></cite>]를 위한 레버리징 RL 알고리즘을 제안한다. 예를 들어, RLPrompt <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib467" title="">467</a>]</cite>는 정책 네트워크를 훈련시켜 다수의 보상 함수를 갖는 원하는 프롬프트를 생성한다. 이 접근법에서는 RL 훈련 효율성을 높이기 위해 몇 가지 효과적인 보상 안정화 전략도 제안된다. TEMPERA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib468" title="">468</a>]</cite>는 훈련에 충분한 데이터를 필요로 하는 이전 작업과 비교하여 미리 훈련된 RL 에이전트를 활용하여 수동으로 작성된 초기 프롬프트의 다른 부분을 순차적으로 편집하여 테스트 시간에 프롬프트를 직접 생성하는 것을 제안한다.</p>
</div>
<div id="S6.SS1.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS2.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS2.p5.1.m1.1"><semantics id="S6.SS1.SSS2.p5.1.m1.1a"><mo id="S6.SS1.SSS2.p5.1.m1.1.1" xref="S6.SS1.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p5.1.m1.1b"><ci id="S6.SS1.SSS2.p5.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p5.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS2.p5.1.1">Edit-based approaches. </span> 위의 방법에 대해 그래디언트 기반 및 RL 기반 튜닝은 훨씬 더 큰 모델에 대해 극도로 계산적으로 까다로울 수 있으며 API 기반 모델 호출에는 실현 가능하지 않을 수 있다(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS2.p5.1.2">e.g.,</em> ChatGPT). 따라서, 다른 작업 라인은 작업 수행에 기초하여 기존의 프롬프트를 직접 편집하는 것을 목표로 한다. 구체적으로, GPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib469" title="">469</a>]</cite>는 유전자 알고리즘에서 아이디어를 차용하여 언어 모델(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS2.p5.1.3">i.e.,</em>T5)을 활용하여 클로즈 작업 양식을 취하여 프롬프트를 편집하는 유전자 프롬프트 검색 방법을 제안한다. 모델 기반 편집 방법 외에도 삭제, 스왑, 패러프레이즈 및 추가를 포함한 신속한 편집 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib470" title="">470</a>]</cite>에도 인간 정의 작업이 사용될 수 있다. 이러한 작업을 기반으로 프롬프트를 반복적으로 편집하고 작은 예제 풀에서 모델 성능에 의해 안내되는 최상의 프롬프트를 탐욕스럽게 검색합니다.</p>
</div>
<div id="S6.SS1.SSS2.p6" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS2.p6.1.m1.1"><semantics id="S6.SS1.SSS2.p6.1.m1.1a"><mo id="S6.SS1.SSS2.p6.1.m1.1.1" xref="S6.SS1.SSS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p6.1.m1.1b"><ci id="S6.SS1.SSS2.p6.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p6.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS2.p6.1.1">LLM 기반 접근법. </span> LLM의 예외적인 용량으로 인해 LLM을 프롬프트 생성기 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib471" title="">471</a>, <a class="ltx_ref" href="#bib.bib472" title="">472</a>, <a class="ltx_ref" href="#bib.bib473" title="">473</a>]</cite>로 직접 활용하는 연구가 증가하고 있다. 구체적으로 APE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib471" title="">471</a>]</cite>는 LLM을 활용하여 초기 프롬프트를 생성한 후 가장 정확도가 높은 베스트 프롬프트를 선택하고, 최종적으로 반복적 몬테카를로 탐색 방법을 통해 베스트 후보를 개선한다. 마찬가지로 APO<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib472" title="">472</a>]</cite>는 LLM에게 이전 프롬프트를 새로운 개선된 프롬프트로 정제하는 방법에 대한 텍스트 피드백을 생성하도록 지시한다. 그러나 프롬프트 공간에서의 검색은 이전 프롬프트의 전체 정제 추적을 완전히 고려하지 않고 비효율적일 수 있으므로 잠재적으로 차선 결과를 초래할 수 있다. 따라서 다른 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib473" title="">473</a>]</cite>는 이전 프롬프트를 점수와 함께 통합하여 LLM이 점진적으로 더 나은 새로운 프롬프트를 생성하도록 지시한다. 그러나 이러한 접근 방식은 여전히 효과적인 프롬프트의 광대한 공간을 탐색하는 데 어려움을 겪고 있다. 인간과 같은 시행착오에 영감을 받아 프롬프트 최적화는 전략 계획 문제<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib474" title="">474</a>]</cite>로 추가 공식화되며 몬테카를로 트리 검색을 사용하여 방대한 프롬프트 공간을 탐색합니다.</p>
</div>
<div id="S6.SS1.SSS2.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS1.SSS2.p7.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.SSS2.p7.1.1">Continuous Prompt Optimization. </span> 이산 프롬프트와 달리 연속 프롬프트는 연속 임베딩 세트로 구성되며, 이는 다운스트림 작업의 손실을 기반으로 하는 그래디언트 업데이트를 통해 직접 최적화될 수 있다. 지속적인 신속한 최적화는 주로 PLM에서 연구되었지만 LLM 시대에는 매개변수의 엄청난 크기로 인해 제한된 관심을 끌고 있다. 콘텐츠 완성도를 위해 이 부분에 대한 논의를 포함합니다. 선행 연구에서, 대부분의 연구는 일반적으로 작업 데이터에 기초하여 연속적인 프롬프트를 트레이닝하기 위해 지도 학습에 의존한다. 또한, 데이터 부족 시나리오에서, 전이 학습 방법은 타겟 태스크에 대한 라벨링된 데이터의 부족을 완화하기 위해 사용될 수 있다. 이 두 가지 접근법은 아래에 자세히 설명되어 있다.</p>
</div>
<div id="S6.SS1.SSS2.p8" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS2.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS2.p8.1.m1.1"><semantics id="S6.SS1.SSS2.p8.1.m1.1a"><mo id="S6.SS1.SSS2.p8.1.m1.1.1" xref="S6.SS1.SSS2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p8.1.m1.1b"><ci id="S6.SS1.SSS2.p8.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p8.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS2.p8.1.1">Prompt learning with sufficient data. </span> 이 접근법에서 대부분의 기존 방법은 연속 프롬프트를 훈련 가능한 모델 매개변수로 간주한 다음 지도 학습을 활용하여 충분한 다운스트림 작업 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib396" title="">396</a>, <a class="ltx_ref" href="#bib.bib397" title="">397</a>, <a class="ltx_ref" href="#bib.bib475" title="">475</a>, <a class="ltx_ref" href="#bib.bib401" title="">401</a>]</cite>를 기반으로 교차 엔트로피 손실을 최소화하여 연속 프롬프트를 최적화한다. 섹션 <a class="ltx_ref" href="#S5.SS3.SSS1" title="5.3.1 Parameter-Efficient Fine-Tuning Methods ‣ 5.3 Parameter-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.3.1</span></a>에서 논의된 바와 같이, prefix tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib396" title="">396</a>]</cite>는 prefix들의 시퀀스(<em class="ltx_emph ltx_font_italic" id="S6.SS1.SSS2.p8.1.2">i.e.,</em> a set of trainable continuous vectors)를 언어 모델 내의 각 Transformer 계층에 prepends하는 반면, prompt tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib397" title="">397</a>]</cite>는 입력 계층에 trainable prompt vectors만을 통합한다. LLM들의 대규모 파라미터들을 고정시키고 연속 프롬프트 벡터만을 튜닝함으로써, 이러한 종류의 접근법들은 매우 파라미터-효율적일 수 있다(Section <a class="ltx_ref" href="#S5.SS3" title="5.3 Parameter-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.3</span></a>). 그러나, 이러한 접근법들은 통상적으로 입력 의미들에 대한 충분한 고려가 결여된 입력들과 독립적이다. 따라서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib475" title="">475</a>]</cite>의 저자들은 연속 프롬프트가 입력 텍스트를 기반으로 유도되고 다운스트림 태스크 손실을 통해 학습되는 컨텍스트 튜닝을 제안한다.</p>
</div>
<div id="S6.SS1.SSS2.p9" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS2.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS1.SSS2.p9.1.m1.1"><semantics id="S6.SS1.SSS2.p9.1.m1.1a"><mo id="S6.SS1.SSS2.p9.1.m1.1.1" xref="S6.SS1.SSS2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS2.p9.1.m1.1b"><ci id="S6.SS1.SSS2.p9.1.m1.1.1.cmml" xref="S6.SS1.SSS2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS2.p9.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS2.p9.1.1">Prompt transfer with scarce data. </span> 지도 학습 접근법은 최적의 연속 프롬프트를 학습하기 위해 충분한 훈련 데이터에서 요구하며, 이는 데이터 부족 도메인 및 태스크에서 잘 작동하지 않을 수 있다. 이 문제를 해결하기 위해 SPoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib476" title="">476</a>]</cite>는 프롬프트 기반 전이 학습 접근법을 제안하며, 이는 먼저 여러 대표 소스 태스크에 대해 단일 연속 프롬프트를 학습한 다음 이 프롬프트를 사용하여 대상 태스크에 대한 프롬프트를 초기화한다. 그러나 이 접근법은 대상 태스크의 모든 인스턴스를 해결하기 위해 동일한 프롬프트를 활용한다. 단일 태스크의 경우, 잘 학습된 프롬프트조차도 많은 모집단의 모든 데이터 인스턴스에 적합하지 않을 수 있다. 이 문제를 해결하기 위해 개선된 방법 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib477" title="">477</a>]</cite>는 태스크 수준 정보와 인스턴스 수준 정보를 모두 고려하여 프롬프트 전달 과정에서 적응형 어텐션 메커니즘을 설계하여 대상 프롬프트를 유도한다. 프롬프트 전송 패러다임은 데이터 부족 대상 태스크를 해결하기 위해 소스 프롬프트에 인코딩된 데이터 부족 소스 태스크의 지식을 활용할 수 있다.</p>
</div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span><span id="S6.SS2.1.1" class="ltx_text ltx_font_italic">In-Context Learning</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p1.1">특수 프롬프트 형태로 먼저 GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>와 함께 in-context learning(ICL)이 제안되었는데, 이는 LLMs를 활용하는 대표적인 접근 방식이 되었다.</p>
</div>
<section id="S6.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1 </span>ICL Formulation</h4>

<div id="S6.SS2.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS1.p1.1"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>에 명시된 바와 같이 ICL은 태스크 설명 및/또는 몇 가지 태스크 예제로 구성된 형식화된 자연어 프롬프트를 시연으로 사용한다. <a class="ltx_ref" href="#S6.F14" title="Figure 14 ‣ 6.2.1 ICL Formulation ‣ 6.2 In-Context Learning ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">14</span></a>는 ICL의 예시를 제시한다. 먼저 작업 설명부터 시작하여 작업 데이터 세트에서 몇 가지 예가 시범으로 선택된다. 그런 다음, 특정 순서로 결합되어 특수하게 설계된 템플릿과 함께 자연어 프롬프트를 형성한다. 마지막으로 테스트 인스턴스는 LLM이 출력을 생성하기 위한 입력으로 데모에 추가된다. 작업 데모에 기초하여, LLMs는 명시적인 그래디언트 업데이트 없이 새로운 작업을 인식하고 수행할 수 있다.</p>
</div>
<div id="S6.SS2.SSS1.p2" class="ltx_para">
<p id="S6.SS2.SSS1.p2.8" class="ltx_p">Formally, let <math id="S6.SS2.SSS1.p2.1.m1.3" class="ltx_Math" alttext="D_{k}=\{f(x_{1},y_{1}),\dots,f(x_{k},y_{k})\}" display="inline"><semantics id="S6.SS2.SSS1.p2.1.m1.3a"><mrow id="S6.SS2.SSS1.p2.1.m1.3.3" xref="S6.SS2.SSS1.p2.1.m1.3.3.cmml"><msub id="S6.SS2.SSS1.p2.1.m1.3.3.4" xref="S6.SS2.SSS1.p2.1.m1.3.3.4.cmml"><mi id="S6.SS2.SSS1.p2.1.m1.3.3.4.2" xref="S6.SS2.SSS1.p2.1.m1.3.3.4.2.cmml">D</mi><mi id="S6.SS2.SSS1.p2.1.m1.3.3.4.3" xref="S6.SS2.SSS1.p2.1.m1.3.3.4.3.cmml">k</mi></msub><mo id="S6.SS2.SSS1.p2.1.m1.3.3.3" xref="S6.SS2.SSS1.p2.1.m1.3.3.3.cmml">=</mo><mrow id="S6.SS2.SSS1.p2.1.m1.3.3.2.2" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.3" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.3.cmml">{</mo><mrow id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.cmml"><mi id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.4" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.3" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.3.cmml">​</mo><mrow id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.3.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.3" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.3.cmml">(</mo><msub id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.2" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.2.cmml">x</mi><mn id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.3" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.4" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.3.cmml">,</mo><msub id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.cmml"><mi id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.2" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.2.cmml">y</mi><mn id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.3" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.5" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.4" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S6.SS2.SSS1.p2.1.m1.1.1" xref="S6.SS2.SSS1.p2.1.m1.1.1.cmml">…</mi><mo id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.5" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.3.cmml">,</mo><mrow id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.cmml"><mi id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.4" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.3" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.3.cmml">​</mo><mrow id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.3.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.3" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.3.cmml">(</mo><msub id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.cmml"><mi id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.2" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.2.cmml">x</mi><mi id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.3" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.3.cmml">k</mi></msub><mo id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.4" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.3.cmml">,</mo><msub id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.cmml"><mi id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.2" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.2.cmml">y</mi><mi id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.3" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.3.cmml">k</mi></msub><mo stretchy="false" id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.5" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.6" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.1.m1.3b"><apply id="S6.SS2.SSS1.p2.1.m1.3.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3"><eq id="S6.SS2.SSS1.p2.1.m1.3.3.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.3"></eq><apply id="S6.SS2.SSS1.p2.1.m1.3.3.4.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.4"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.1.m1.3.3.4.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.4">subscript</csymbol><ci id="S6.SS2.SSS1.p2.1.m1.3.3.4.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.4.2">𝐷</ci><ci id="S6.SS2.SSS1.p2.1.m1.3.3.4.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.4.3">𝑘</ci></apply><set id="S6.SS2.SSS1.p2.1.m1.3.3.2.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2"><apply id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1"><times id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.3"></times><ci id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.4.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.4">𝑓</ci><interval closure="open" id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2"><apply id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.1.1.1.3">1</cn></apply><apply id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2">subscript</csymbol><ci id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.2">𝑦</ci><cn type="integer" id="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.2.2.1.1.1.2.2.2.3">1</cn></apply></interval></apply><ci id="S6.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.1.1">…</ci><apply id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2"><times id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.3"></times><ci id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.4.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.4">𝑓</ci><interval closure="open" id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2"><apply id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1">subscript</csymbol><ci id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.2">𝑥</ci><ci id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.1.1.1.3">𝑘</ci></apply><apply id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2">subscript</csymbol><ci id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.2">𝑦</ci><ci id="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.3.3.2.2.2.2.2.2.3">𝑘</ci></apply></interval></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.1.m1.3c">D_{k}=\{f(x_{1},y_{1}),\dots,f(x_{k},y_{k})\}</annotation></semantics></math> represent a set of demonstrations with <math id="S6.SS2.SSS1.p2.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS2.SSS1.p2.2.m2.1a"><mi id="S6.SS2.SSS1.p2.2.m2.1.1" xref="S6.SS2.SSS1.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.2.m2.1b"><ci id="S6.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S6.SS2.SSS1.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.2.m2.1c">k</annotation></semantics></math> examples, where <math id="S6.SS2.SSS1.p2.3.m3.2" class="ltx_Math" alttext="f(x_{k},y_{k})" display="inline"><semantics id="S6.SS2.SSS1.p2.3.m3.2a"><mrow id="S6.SS2.SSS1.p2.3.m3.2.2" xref="S6.SS2.SSS1.p2.3.m3.2.2.cmml"><mi id="S6.SS2.SSS1.p2.3.m3.2.2.4" xref="S6.SS2.SSS1.p2.3.m3.2.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS1.p2.3.m3.2.2.3" xref="S6.SS2.SSS1.p2.3.m3.2.2.3.cmml">​</mo><mrow id="S6.SS2.SSS1.p2.3.m3.2.2.2.2" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.3.cmml"><mo stretchy="false" id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.3" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.3.cmml">(</mo><msub id="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1" xref="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.cmml"><mi id="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.2" xref="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.2.cmml">x</mi><mi id="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.3" xref="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.3.cmml">k</mi></msub><mo id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.4" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.3.cmml">,</mo><msub id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.cmml"><mi id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.2" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.2.cmml">y</mi><mi id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.3" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.3.cmml">k</mi></msub><mo stretchy="false" id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.5" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.3.m3.2b"><apply id="S6.SS2.SSS1.p2.3.m3.2.2.cmml" xref="S6.SS2.SSS1.p2.3.m3.2.2"><times id="S6.SS2.SSS1.p2.3.m3.2.2.3.cmml" xref="S6.SS2.SSS1.p2.3.m3.2.2.3"></times><ci id="S6.SS2.SSS1.p2.3.m3.2.2.4.cmml" xref="S6.SS2.SSS1.p2.3.m3.2.2.4">𝑓</ci><interval closure="open" id="S6.SS2.SSS1.p2.3.m3.2.2.2.3.cmml" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.2"><apply id="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.cmml" xref="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.2.cmml" xref="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.2">𝑥</ci><ci id="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.3.cmml" xref="S6.SS2.SSS1.p2.3.m3.1.1.1.1.1.3">𝑘</ci></apply><apply id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.cmml" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.1.cmml" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2">subscript</csymbol><ci id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.2.cmml" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.2">𝑦</ci><ci id="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.3.cmml" xref="S6.SS2.SSS1.p2.3.m3.2.2.2.2.2.3">𝑘</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.3.m3.2c">f(x_{k},y_{k})</annotation></semantics></math> is the prompt function that transforms the <math id="S6.SS2.SSS1.p2.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS2.SSS1.p2.4.m4.1a"><mi id="S6.SS2.SSS1.p2.4.m4.1.1" xref="S6.SS2.SSS1.p2.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.4.m4.1b"><ci id="S6.SS2.SSS1.p2.4.m4.1.1.cmml" xref="S6.SS2.SSS1.p2.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.4.m4.1c">k</annotation></semantics></math>-th task example into natural language prompts. Given the task description <math id="S6.SS2.SSS1.p2.5.m5.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S6.SS2.SSS1.p2.5.m5.1a"><mi id="S6.SS2.SSS1.p2.5.m5.1.1" xref="S6.SS2.SSS1.p2.5.m5.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.5.m5.1b"><ci id="S6.SS2.SSS1.p2.5.m5.1.1.cmml" xref="S6.SS2.SSS1.p2.5.m5.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.5.m5.1c">I</annotation></semantics></math>, demonstration <math id="S6.SS2.SSS1.p2.6.m6.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S6.SS2.SSS1.p2.6.m6.1a"><msub id="S6.SS2.SSS1.p2.6.m6.1.1" xref="S6.SS2.SSS1.p2.6.m6.1.1.cmml"><mi id="S6.SS2.SSS1.p2.6.m6.1.1.2" xref="S6.SS2.SSS1.p2.6.m6.1.1.2.cmml">D</mi><mi id="S6.SS2.SSS1.p2.6.m6.1.1.3" xref="S6.SS2.SSS1.p2.6.m6.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.6.m6.1b"><apply id="S6.SS2.SSS1.p2.6.m6.1.1.cmml" xref="S6.SS2.SSS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.6.m6.1.1.1.cmml" xref="S6.SS2.SSS1.p2.6.m6.1.1">subscript</csymbol><ci id="S6.SS2.SSS1.p2.6.m6.1.1.2.cmml" xref="S6.SS2.SSS1.p2.6.m6.1.1.2">𝐷</ci><ci id="S6.SS2.SSS1.p2.6.m6.1.1.3.cmml" xref="S6.SS2.SSS1.p2.6.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.6.m6.1c">D_{k}</annotation></semantics></math>, and a new input query <math id="S6.SS2.SSS1.p2.7.m7.1" class="ltx_Math" alttext="x_{k+1}" display="inline"><semantics id="S6.SS2.SSS1.p2.7.m7.1a"><msub id="S6.SS2.SSS1.p2.7.m7.1.1" xref="S6.SS2.SSS1.p2.7.m7.1.1.cmml"><mi id="S6.SS2.SSS1.p2.7.m7.1.1.2" xref="S6.SS2.SSS1.p2.7.m7.1.1.2.cmml">x</mi><mrow id="S6.SS2.SSS1.p2.7.m7.1.1.3" xref="S6.SS2.SSS1.p2.7.m7.1.1.3.cmml"><mi id="S6.SS2.SSS1.p2.7.m7.1.1.3.2" xref="S6.SS2.SSS1.p2.7.m7.1.1.3.2.cmml">k</mi><mo id="S6.SS2.SSS1.p2.7.m7.1.1.3.1" xref="S6.SS2.SSS1.p2.7.m7.1.1.3.1.cmml">+</mo><mn id="S6.SS2.SSS1.p2.7.m7.1.1.3.3" xref="S6.SS2.SSS1.p2.7.m7.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.7.m7.1b"><apply id="S6.SS2.SSS1.p2.7.m7.1.1.cmml" xref="S6.SS2.SSS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.7.m7.1.1.1.cmml" xref="S6.SS2.SSS1.p2.7.m7.1.1">subscript</csymbol><ci id="S6.SS2.SSS1.p2.7.m7.1.1.2.cmml" xref="S6.SS2.SSS1.p2.7.m7.1.1.2">𝑥</ci><apply id="S6.SS2.SSS1.p2.7.m7.1.1.3.cmml" xref="S6.SS2.SSS1.p2.7.m7.1.1.3"><plus id="S6.SS2.SSS1.p2.7.m7.1.1.3.1.cmml" xref="S6.SS2.SSS1.p2.7.m7.1.1.3.1"></plus><ci id="S6.SS2.SSS1.p2.7.m7.1.1.3.2.cmml" xref="S6.SS2.SSS1.p2.7.m7.1.1.3.2">𝑘</ci><cn type="integer" id="S6.SS2.SSS1.p2.7.m7.1.1.3.3.cmml" xref="S6.SS2.SSS1.p2.7.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.7.m7.1c">x_{k+1}</annotation></semantics></math>, the prediction of the output <math id="S6.SS2.SSS1.p2.8.m8.1" class="ltx_Math" alttext="\hat{y}_{k+1}" display="inline"><semantics id="S6.SS2.SSS1.p2.8.m8.1a"><msub id="S6.SS2.SSS1.p2.8.m8.1.1" xref="S6.SS2.SSS1.p2.8.m8.1.1.cmml"><mover accent="true" id="S6.SS2.SSS1.p2.8.m8.1.1.2" xref="S6.SS2.SSS1.p2.8.m8.1.1.2.cmml"><mi id="S6.SS2.SSS1.p2.8.m8.1.1.2.2" xref="S6.SS2.SSS1.p2.8.m8.1.1.2.2.cmml">y</mi><mo id="S6.SS2.SSS1.p2.8.m8.1.1.2.1" xref="S6.SS2.SSS1.p2.8.m8.1.1.2.1.cmml">^</mo></mover><mrow id="S6.SS2.SSS1.p2.8.m8.1.1.3" xref="S6.SS2.SSS1.p2.8.m8.1.1.3.cmml"><mi id="S6.SS2.SSS1.p2.8.m8.1.1.3.2" xref="S6.SS2.SSS1.p2.8.m8.1.1.3.2.cmml">k</mi><mo id="S6.SS2.SSS1.p2.8.m8.1.1.3.1" xref="S6.SS2.SSS1.p2.8.m8.1.1.3.1.cmml">+</mo><mn id="S6.SS2.SSS1.p2.8.m8.1.1.3.3" xref="S6.SS2.SSS1.p2.8.m8.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.8.m8.1b"><apply id="S6.SS2.SSS1.p2.8.m8.1.1.cmml" xref="S6.SS2.SSS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.8.m8.1.1.1.cmml" xref="S6.SS2.SSS1.p2.8.m8.1.1">subscript</csymbol><apply id="S6.SS2.SSS1.p2.8.m8.1.1.2.cmml" xref="S6.SS2.SSS1.p2.8.m8.1.1.2"><ci id="S6.SS2.SSS1.p2.8.m8.1.1.2.1.cmml" xref="S6.SS2.SSS1.p2.8.m8.1.1.2.1">^</ci><ci id="S6.SS2.SSS1.p2.8.m8.1.1.2.2.cmml" xref="S6.SS2.SSS1.p2.8.m8.1.1.2.2">𝑦</ci></apply><apply id="S6.SS2.SSS1.p2.8.m8.1.1.3.cmml" xref="S6.SS2.SSS1.p2.8.m8.1.1.3"><plus id="S6.SS2.SSS1.p2.8.m8.1.1.3.1.cmml" xref="S6.SS2.SSS1.p2.8.m8.1.1.3.1"></plus><ci id="S6.SS2.SSS1.p2.8.m8.1.1.3.2.cmml" xref="S6.SS2.SSS1.p2.8.m8.1.1.3.2">𝑘</ci><cn type="integer" id="S6.SS2.SSS1.p2.8.m8.1.1.3.3.cmml" xref="S6.SS2.SSS1.p2.8.m8.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.8.m8.1c">\hat{y}_{k+1}</annotation></semantics></math> generated from LLMs can be formulated as follows<span id="footnote42" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">42</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">42</sup><span class="ltx_tag ltx_tag_note">42</span> When ICL was introduced in the GPT-3’s paper&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, it was originally defined to be a combination of the task description and demonstration examples, wherein either component is dispensable. Following this definition, when a LLM is required to solve an unseen task by using only task descriptions, it can be also considered to perform ICL for task solving, whereas the ICL ability can be enhanced by instruction tuning. </span></span></span>:</p>
<table id="S6.E12" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E12.m1.5" class="ltx_Math" alttext="\text{LLM}\big{(}I,\underbrace{f(x_{1},y_{1}),\dots,f(x_{k},y_{k})}_{\text{demonstrations}},f(\underbrace{x_{k+1}}_{\text{input}},\underbrace{\vphantom{\hat{y}_{k+1}}\_\_\_}_{\text{answer}})\big{)}\rightarrow\hat{y}_{k+1}." display="block"><semantics id="S6.E12.m1.5a"><mrow id="S6.E12.m1.5.5.1" xref="S6.E12.m1.5.5.1.1.cmml"><mrow id="S6.E12.m1.5.5.1.1" xref="S6.E12.m1.5.5.1.1.cmml"><mrow id="S6.E12.m1.5.5.1.1.2" xref="S6.E12.m1.5.5.1.1.2.cmml"><mtext id="S6.E12.m1.5.5.1.1.2.4" xref="S6.E12.m1.5.5.1.1.2.4a.cmml">LLM</mtext><mo lspace="0em" rspace="0em" id="S6.E12.m1.5.5.1.1.2.3" xref="S6.E12.m1.5.5.1.1.2.3.cmml">​</mo><mrow id="S6.E12.m1.5.5.1.1.2.2.2" xref="S6.E12.m1.5.5.1.1.2.2.3.cmml"><mo maxsize="120%" minsize="120%" id="S6.E12.m1.5.5.1.1.2.2.2.3" xref="S6.E12.m1.5.5.1.1.2.2.3.cmml">(</mo><mi id="S6.E12.m1.4.4" xref="S6.E12.m1.4.4.cmml">I</mi><mo id="S6.E12.m1.5.5.1.1.2.2.2.4" xref="S6.E12.m1.5.5.1.1.2.2.3.cmml">,</mo><munder id="S6.E12.m1.5.5.1.1.1.1.1.1" xref="S6.E12.m1.5.5.1.1.1.1.1.1.cmml"><munder accentunder="true" id="S6.E12.m1.3.3" xref="S6.E12.m1.3.3.cmml"><mrow id="S6.E12.m1.3.3.3.3" xref="S6.E12.m1.3.3.3.4.cmml"><mrow id="S6.E12.m1.2.2.2.2.1" xref="S6.E12.m1.2.2.2.2.1.cmml"><mi id="S6.E12.m1.2.2.2.2.1.4" xref="S6.E12.m1.2.2.2.2.1.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S6.E12.m1.2.2.2.2.1.3" xref="S6.E12.m1.2.2.2.2.1.3.cmml">​</mo><mrow id="S6.E12.m1.2.2.2.2.1.2.2" xref="S6.E12.m1.2.2.2.2.1.2.3.cmml"><mo stretchy="false" id="S6.E12.m1.2.2.2.2.1.2.2.3" xref="S6.E12.m1.2.2.2.2.1.2.3.cmml">(</mo><msub id="S6.E12.m1.2.2.2.2.1.1.1.1" xref="S6.E12.m1.2.2.2.2.1.1.1.1.cmml"><mi id="S6.E12.m1.2.2.2.2.1.1.1.1.2" xref="S6.E12.m1.2.2.2.2.1.1.1.1.2.cmml">x</mi><mn id="S6.E12.m1.2.2.2.2.1.1.1.1.3" xref="S6.E12.m1.2.2.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S6.E12.m1.2.2.2.2.1.2.2.4" xref="S6.E12.m1.2.2.2.2.1.2.3.cmml">,</mo><msub id="S6.E12.m1.2.2.2.2.1.2.2.2" xref="S6.E12.m1.2.2.2.2.1.2.2.2.cmml"><mi id="S6.E12.m1.2.2.2.2.1.2.2.2.2" xref="S6.E12.m1.2.2.2.2.1.2.2.2.2.cmml">y</mi><mn id="S6.E12.m1.2.2.2.2.1.2.2.2.3" xref="S6.E12.m1.2.2.2.2.1.2.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S6.E12.m1.2.2.2.2.1.2.2.5" xref="S6.E12.m1.2.2.2.2.1.2.3.cmml">)</mo></mrow></mrow><mo id="S6.E12.m1.3.3.3.3.3" xref="S6.E12.m1.3.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S6.E12.m1.1.1.1.1" xref="S6.E12.m1.1.1.1.1.cmml">…</mi><mo id="S6.E12.m1.3.3.3.3.4" xref="S6.E12.m1.3.3.3.4.cmml">,</mo><mrow id="S6.E12.m1.3.3.3.3.2" xref="S6.E12.m1.3.3.3.3.2.cmml"><mi id="S6.E12.m1.3.3.3.3.2.4" xref="S6.E12.m1.3.3.3.3.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S6.E12.m1.3.3.3.3.2.3" xref="S6.E12.m1.3.3.3.3.2.3.cmml">​</mo><mrow id="S6.E12.m1.3.3.3.3.2.2.2" xref="S6.E12.m1.3.3.3.3.2.2.3.cmml"><mo stretchy="false" id="S6.E12.m1.3.3.3.3.2.2.2.3" xref="S6.E12.m1.3.3.3.3.2.2.3.cmml">(</mo><msub id="S6.E12.m1.3.3.3.3.2.1.1.1" xref="S6.E12.m1.3.3.3.3.2.1.1.1.cmml"><mi id="S6.E12.m1.3.3.3.3.2.1.1.1.2" xref="S6.E12.m1.3.3.3.3.2.1.1.1.2.cmml">x</mi><mi id="S6.E12.m1.3.3.3.3.2.1.1.1.3" xref="S6.E12.m1.3.3.3.3.2.1.1.1.3.cmml">k</mi></msub><mo id="S6.E12.m1.3.3.3.3.2.2.2.4" xref="S6.E12.m1.3.3.3.3.2.2.3.cmml">,</mo><msub id="S6.E12.m1.3.3.3.3.2.2.2.2" xref="S6.E12.m1.3.3.3.3.2.2.2.2.cmml"><mi id="S6.E12.m1.3.3.3.3.2.2.2.2.2" xref="S6.E12.m1.3.3.3.3.2.2.2.2.2.cmml">y</mi><mi id="S6.E12.m1.3.3.3.3.2.2.2.2.3" xref="S6.E12.m1.3.3.3.3.2.2.2.2.3.cmml">k</mi></msub><mo stretchy="false" id="S6.E12.m1.3.3.3.3.2.2.2.5" xref="S6.E12.m1.3.3.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S6.E12.m1.3.3.4" xref="S6.E12.m1.3.3.4.cmml">⏟</mo></munder><mtext id="S6.E12.m1.5.5.1.1.1.1.1.1.2" xref="S6.E12.m1.5.5.1.1.1.1.1.1.2a.cmml">demonstrations</mtext></munder><mo id="S6.E12.m1.5.5.1.1.2.2.2.5" xref="S6.E12.m1.5.5.1.1.2.2.3.cmml">,</mo><mrow id="S6.E12.m1.5.5.1.1.2.2.2.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.cmml"><mi id="S6.E12.m1.5.5.1.1.2.2.2.2.4" xref="S6.E12.m1.5.5.1.1.2.2.2.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S6.E12.m1.5.5.1.1.2.2.2.2.3" xref="S6.E12.m1.5.5.1.1.2.2.2.2.3.cmml">​</mo><mrow id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.3" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.3.cmml">(</mo><munder id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.cmml"><munder accentunder="true" id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.cmml"><msub id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.cmml"><mi id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.2.cmml">x</mi><mrow id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.cmml"><mi id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.2.cmml">k</mi><mo id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.1" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.1.cmml">+</mo><mn id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.3" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.3.cmml">1</mn></mrow></msub><mo id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.1" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.1.cmml">⏟</mo></munder><mtext id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.3" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.3a.cmml">input</mtext></munder><mo id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.4" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.3.cmml">,</mo><munder id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.cmml"><munder accentunder="true" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.cmml"><mrow id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.2" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.2.cmml">_</mi><mo lspace="0em" rspace="0em" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.1" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.3" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.1a" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.4" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.4.cmml">_</mi></mrow><mo id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.1" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.1.cmml">⏟</mo></munder><mtext id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.3" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.3a.cmml">answer</mtext></munder><mo stretchy="false" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.5" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo maxsize="120%" minsize="120%" id="S6.E12.m1.5.5.1.1.2.2.2.6" xref="S6.E12.m1.5.5.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S6.E12.m1.5.5.1.1.3" xref="S6.E12.m1.5.5.1.1.3.cmml">→</mo><msub id="S6.E12.m1.5.5.1.1.4" xref="S6.E12.m1.5.5.1.1.4.cmml"><mover accent="true" id="S6.E12.m1.5.5.1.1.4.2" xref="S6.E12.m1.5.5.1.1.4.2.cmml"><mi id="S6.E12.m1.5.5.1.1.4.2.2" xref="S6.E12.m1.5.5.1.1.4.2.2.cmml">y</mi><mo id="S6.E12.m1.5.5.1.1.4.2.1" xref="S6.E12.m1.5.5.1.1.4.2.1.cmml">^</mo></mover><mrow id="S6.E12.m1.5.5.1.1.4.3" xref="S6.E12.m1.5.5.1.1.4.3.cmml"><mi id="S6.E12.m1.5.5.1.1.4.3.2" xref="S6.E12.m1.5.5.1.1.4.3.2.cmml">k</mi><mo id="S6.E12.m1.5.5.1.1.4.3.1" xref="S6.E12.m1.5.5.1.1.4.3.1.cmml">+</mo><mn id="S6.E12.m1.5.5.1.1.4.3.3" xref="S6.E12.m1.5.5.1.1.4.3.3.cmml">1</mn></mrow></msub></mrow><mo lspace="0em" id="S6.E12.m1.5.5.1.2" xref="S6.E12.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.E12.m1.5b"><apply id="S6.E12.m1.5.5.1.1.cmml" xref="S6.E12.m1.5.5.1"><ci id="S6.E12.m1.5.5.1.1.3.cmml" xref="S6.E12.m1.5.5.1.1.3">→</ci><apply id="S6.E12.m1.5.5.1.1.2.cmml" xref="S6.E12.m1.5.5.1.1.2"><times id="S6.E12.m1.5.5.1.1.2.3.cmml" xref="S6.E12.m1.5.5.1.1.2.3"></times><ci id="S6.E12.m1.5.5.1.1.2.4a.cmml" xref="S6.E12.m1.5.5.1.1.2.4"><mtext id="S6.E12.m1.5.5.1.1.2.4.cmml" xref="S6.E12.m1.5.5.1.1.2.4">LLM</mtext></ci><vector id="S6.E12.m1.5.5.1.1.2.2.3.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2"><ci id="S6.E12.m1.4.4.cmml" xref="S6.E12.m1.4.4">𝐼</ci><apply id="S6.E12.m1.5.5.1.1.1.1.1.1.cmml" xref="S6.E12.m1.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.E12.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S6.E12.m1.5.5.1.1.1.1.1.1">subscript</csymbol><apply id="S6.E12.m1.3.3.cmml" xref="S6.E12.m1.3.3"><ci id="S6.E12.m1.3.3.4.cmml" xref="S6.E12.m1.3.3.4">⏟</ci><list id="S6.E12.m1.3.3.3.4.cmml" xref="S6.E12.m1.3.3.3.3"><apply id="S6.E12.m1.2.2.2.2.1.cmml" xref="S6.E12.m1.2.2.2.2.1"><times id="S6.E12.m1.2.2.2.2.1.3.cmml" xref="S6.E12.m1.2.2.2.2.1.3"></times><ci id="S6.E12.m1.2.2.2.2.1.4.cmml" xref="S6.E12.m1.2.2.2.2.1.4">𝑓</ci><interval closure="open" id="S6.E12.m1.2.2.2.2.1.2.3.cmml" xref="S6.E12.m1.2.2.2.2.1.2.2"><apply id="S6.E12.m1.2.2.2.2.1.1.1.1.cmml" xref="S6.E12.m1.2.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S6.E12.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S6.E12.m1.2.2.2.2.1.1.1.1">subscript</csymbol><ci id="S6.E12.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S6.E12.m1.2.2.2.2.1.1.1.1.2">𝑥</ci><cn type="integer" id="S6.E12.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S6.E12.m1.2.2.2.2.1.1.1.1.3">1</cn></apply><apply id="S6.E12.m1.2.2.2.2.1.2.2.2.cmml" xref="S6.E12.m1.2.2.2.2.1.2.2.2"><csymbol cd="ambiguous" id="S6.E12.m1.2.2.2.2.1.2.2.2.1.cmml" xref="S6.E12.m1.2.2.2.2.1.2.2.2">subscript</csymbol><ci id="S6.E12.m1.2.2.2.2.1.2.2.2.2.cmml" xref="S6.E12.m1.2.2.2.2.1.2.2.2.2">𝑦</ci><cn type="integer" id="S6.E12.m1.2.2.2.2.1.2.2.2.3.cmml" xref="S6.E12.m1.2.2.2.2.1.2.2.2.3">1</cn></apply></interval></apply><ci id="S6.E12.m1.1.1.1.1.cmml" xref="S6.E12.m1.1.1.1.1">…</ci><apply id="S6.E12.m1.3.3.3.3.2.cmml" xref="S6.E12.m1.3.3.3.3.2"><times id="S6.E12.m1.3.3.3.3.2.3.cmml" xref="S6.E12.m1.3.3.3.3.2.3"></times><ci id="S6.E12.m1.3.3.3.3.2.4.cmml" xref="S6.E12.m1.3.3.3.3.2.4">𝑓</ci><interval closure="open" id="S6.E12.m1.3.3.3.3.2.2.3.cmml" xref="S6.E12.m1.3.3.3.3.2.2.2"><apply id="S6.E12.m1.3.3.3.3.2.1.1.1.cmml" xref="S6.E12.m1.3.3.3.3.2.1.1.1"><csymbol cd="ambiguous" id="S6.E12.m1.3.3.3.3.2.1.1.1.1.cmml" xref="S6.E12.m1.3.3.3.3.2.1.1.1">subscript</csymbol><ci id="S6.E12.m1.3.3.3.3.2.1.1.1.2.cmml" xref="S6.E12.m1.3.3.3.3.2.1.1.1.2">𝑥</ci><ci id="S6.E12.m1.3.3.3.3.2.1.1.1.3.cmml" xref="S6.E12.m1.3.3.3.3.2.1.1.1.3">𝑘</ci></apply><apply id="S6.E12.m1.3.3.3.3.2.2.2.2.cmml" xref="S6.E12.m1.3.3.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S6.E12.m1.3.3.3.3.2.2.2.2.1.cmml" xref="S6.E12.m1.3.3.3.3.2.2.2.2">subscript</csymbol><ci id="S6.E12.m1.3.3.3.3.2.2.2.2.2.cmml" xref="S6.E12.m1.3.3.3.3.2.2.2.2.2">𝑦</ci><ci id="S6.E12.m1.3.3.3.3.2.2.2.2.3.cmml" xref="S6.E12.m1.3.3.3.3.2.2.2.2.3">𝑘</ci></apply></interval></apply></list></apply><ci id="S6.E12.m1.5.5.1.1.1.1.1.1.2a.cmml" xref="S6.E12.m1.5.5.1.1.1.1.1.1.2"><mtext mathsize="70%" id="S6.E12.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S6.E12.m1.5.5.1.1.1.1.1.1.2">demonstrations</mtext></ci></apply><apply id="S6.E12.m1.5.5.1.1.2.2.2.2.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2"><times id="S6.E12.m1.5.5.1.1.2.2.2.2.3.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.3"></times><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.4.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.4">𝑓</ci><interval closure="open" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.3.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2"><apply id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.1.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1">subscript</csymbol><apply id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2"><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.1.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.1">⏟</ci><apply id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.1.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2">subscript</csymbol><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.2.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.2">𝑥</ci><apply id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3"><plus id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.1.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.1"></plus><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.2.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.2">𝑘</ci><cn type="integer" id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.3.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.2.2.3.3">1</cn></apply></apply></apply><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.3a.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.3"><mtext mathsize="70%" id="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.3.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.1.1.1.3">input</mtext></ci></apply><apply id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.1.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2">subscript</csymbol><apply id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2"><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.1">⏟</ci><apply id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2"><times id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.1.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.1"></times><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.2.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.2">_</ci><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.3.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.3">_</ci><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.4.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.2.2.4">_</ci></apply></apply><ci id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.3a.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.3"><mtext mathsize="70%" id="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.3.cmml" xref="S6.E12.m1.5.5.1.1.2.2.2.2.2.2.2.3">answer</mtext></ci></apply></interval></apply></vector></apply><apply id="S6.E12.m1.5.5.1.1.4.cmml" xref="S6.E12.m1.5.5.1.1.4"><csymbol cd="ambiguous" id="S6.E12.m1.5.5.1.1.4.1.cmml" xref="S6.E12.m1.5.5.1.1.4">subscript</csymbol><apply id="S6.E12.m1.5.5.1.1.4.2.cmml" xref="S6.E12.m1.5.5.1.1.4.2"><ci id="S6.E12.m1.5.5.1.1.4.2.1.cmml" xref="S6.E12.m1.5.5.1.1.4.2.1">^</ci><ci id="S6.E12.m1.5.5.1.1.4.2.2.cmml" xref="S6.E12.m1.5.5.1.1.4.2.2">𝑦</ci></apply><apply id="S6.E12.m1.5.5.1.1.4.3.cmml" xref="S6.E12.m1.5.5.1.1.4.3"><plus id="S6.E12.m1.5.5.1.1.4.3.1.cmml" xref="S6.E12.m1.5.5.1.1.4.3.1"></plus><ci id="S6.E12.m1.5.5.1.1.4.3.2.cmml" xref="S6.E12.m1.5.5.1.1.4.3.2">𝑘</ci><cn type="integer" id="S6.E12.m1.5.5.1.1.4.3.3.cmml" xref="S6.E12.m1.5.5.1.1.4.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E12.m1.5c">\text{LLM}\big{(}I,\underbrace{f(x_{1},y_{1}),\dots,f(x_{k},y_{k})}_{\text{demonstrations}},f(\underbrace{x_{k+1}}_{\text{input}},\underbrace{\vphantom{\hat{y}_{k+1}}\_\_\_}_{\text{answer}})\big{)}\rightarrow\hat{y}_{k+1}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(12)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S6.SS2.SSS1.p2.10">여기서 실제 답변 <math alttext="y_{k+1}" class="ltx_Math" display="inline" id="S6.SS2.SSS1.p2.9.m1.1"><semantics id="S6.SS2.SSS1.p2.9.m1.1a"><msub id="S6.SS2.SSS1.p2.9.m1.1.1" xref="S6.SS2.SSS1.p2.9.m1.1.1.cmml"><mi id="S6.SS2.SSS1.p2.9.m1.1.1.2" xref="S6.SS2.SSS1.p2.9.m1.1.1.2.cmml">y</mi><mrow id="S6.SS2.SSS1.p2.9.m1.1.1.3" xref="S6.SS2.SSS1.p2.9.m1.1.1.3.cmml"><mi id="S6.SS2.SSS1.p2.9.m1.1.1.3.2" xref="S6.SS2.SSS1.p2.9.m1.1.1.3.2.cmml">k</mi><mo id="S6.SS2.SSS1.p2.9.m1.1.1.3.1" xref="S6.SS2.SSS1.p2.9.m1.1.1.3.1.cmml">+</mo><mn id="S6.SS2.SSS1.p2.9.m1.1.1.3.3" xref="S6.SS2.SSS1.p2.9.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.9.m1.1b"><apply id="S6.SS2.SSS1.p2.9.m1.1.1.cmml" xref="S6.SS2.SSS1.p2.9.m1.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS1.p2.9.m1.1.1.1.cmml" xref="S6.SS2.SSS1.p2.9.m1.1.1">subscript</csymbol><ci id="S6.SS2.SSS1.p2.9.m1.1.1.2.cmml" xref="S6.SS2.SSS1.p2.9.m1.1.1.2">𝑦</ci><apply id="S6.SS2.SSS1.p2.9.m1.1.1.3.cmml" xref="S6.SS2.SSS1.p2.9.m1.1.1.3"><plus id="S6.SS2.SSS1.p2.9.m1.1.1.3.1.cmml" xref="S6.SS2.SSS1.p2.9.m1.1.1.3.1"></plus><ci id="S6.SS2.SSS1.p2.9.m1.1.1.3.2.cmml" xref="S6.SS2.SSS1.p2.9.m1.1.1.3.2">𝑘</ci><cn id="S6.SS2.SSS1.p2.9.m1.1.1.3.3.cmml" type="integer" xref="S6.SS2.SSS1.p2.9.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.9.m1.1c">y_{k+1}</annotation></semantics></math>는 LLM에 의해 예측될 빈칸으로 남겨진다. ICL의 성능은 시연에 크게 의존하기 때문에 프롬프트에서 적절하게 설계하는 것이 중요하다. 방정식 (<a class="ltx_ref" href="#S6.E12" title="In 6.2.1 ICL Formulation ‣ 6.2 In-Context Learning ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">12</span></a>)의 구성 과정에 따라, 시범을 구성하는 예를 선택하고, 각 예를 함수 <math alttext="f(\cdot)" class="ltx_Math" display="inline" id="S6.SS2.SSS1.p2.10.m2.1"><semantics id="S6.SS2.SSS1.p2.10.m2.1a"><mrow id="S6.SS2.SSS1.p2.10.m2.1.2" xref="S6.SS2.SSS1.p2.10.m2.1.2.cmml"><mi id="S6.SS2.SSS1.p2.10.m2.1.2.2" xref="S6.SS2.SSS1.p2.10.m2.1.2.2.cmml">f</mi><mo id="S6.SS2.SSS1.p2.10.m2.1.2.1" lspace="0em" rspace="0em" xref="S6.SS2.SSS1.p2.10.m2.1.2.1.cmml">​</mo><mrow id="S6.SS2.SSS1.p2.10.m2.1.2.3.2" xref="S6.SS2.SSS1.p2.10.m2.1.2.cmml"><mo id="S6.SS2.SSS1.p2.10.m2.1.2.3.2.1" stretchy="false" xref="S6.SS2.SSS1.p2.10.m2.1.2.cmml">(</mo><mo id="S6.SS2.SSS1.p2.10.m2.1.1" lspace="0em" rspace="0em" xref="S6.SS2.SSS1.p2.10.m2.1.1.cmml">⋅</mo><mo id="S6.SS2.SSS1.p2.10.m2.1.2.3.2.2" stretchy="false" xref="S6.SS2.SSS1.p2.10.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.10.m2.1b"><apply id="S6.SS2.SSS1.p2.10.m2.1.2.cmml" xref="S6.SS2.SSS1.p2.10.m2.1.2"><times id="S6.SS2.SSS1.p2.10.m2.1.2.1.cmml" xref="S6.SS2.SSS1.p2.10.m2.1.2.1"></times><ci id="S6.SS2.SSS1.p2.10.m2.1.2.2.cmml" xref="S6.SS2.SSS1.p2.10.m2.1.2.2">𝑓</ci><ci id="S6.SS2.SSS1.p2.10.m2.1.1.cmml" xref="S6.SS2.SSS1.p2.10.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.10.m2.1c">f(\cdot)</annotation></semantics></math>로 프롬프트에 포맷하고, 시범을 합리적인 순서로 배열하는 방법을 포함하여 프롬프트에서 시범을 포맷하는 세 가지 주요 측면에 초점을 맞춘다.</p>
</div>
<div id="S6.SS2.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS1.p3.1">ICL에 대한 포괄적인 검토는 조사 논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib50" title="">50</a>]</cite>에 제시되었으며, 이 주제에 대한 보다 일반적이고 상세한 논의를 위해 독자들을 참조할 것을 제안한다. 이 조사와 비교하여 우리는 특히 <em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS1.p3.1.1">i.e.,</em> 데모 설계 및 ICL의 기본 메커니즘의 두 가지 주요 측면에서 ICL을 LLM에 적용하는 논의에 중점을 둔다. 또한 ICL은 둘 다 자연어를 사용하여 작업 또는 인스턴스를 포맷한다는 점에서 명령어 튜닝(섹션<a class="ltx_ref" href="#S5.SS1" title="5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1</span></a>에서 논의됨)과 밀접한 관련이 있다. 그러나 명령어 튜닝은 적응을 위해 LLM을 미세 조정해야 하는 반면 ICL은 활용을 위해 LLM만 프롬프트한다. 또한 명령어 튜닝은 특히 제로 샷 설정(작업 설명만 사용)에서 LLM이 대상 작업을 수행하는 ICL 능력을 향상시킬 수 있습니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>.</p>
</div>
<figure id="S6.F14" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x14.png" id="S6.F14.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 14:</span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>
A comparative illustration of in-context learning&nbsp;(ICL) and chain-of-thought&nbsp;(CoT) prompting.
ICL prompts LLMs with a natural language description, several demonstrations, and a test query, while
CoT prompting involves a series of intermediate reasoning steps in prompts.
</figcaption>
</figure>
</section>
<section id="S6.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.2 </span>Demonstration Design</h4>

<div id="S6.SS2.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS2.p1.1">여러 연구에 따르면 ICL의 효과는 시연 디자인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib478" title="">478</a>, <a class="ltx_ref" href="#bib.bib432" title="">432</a>, <a class="ltx_ref" href="#bib.bib479" title="">479</a>]</cite> <a class="ltx_ref" href="#S6.SS2.SSS1" title="6.2.1 ICL Formulation ‣ 6.2 In-Context Learning ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.2.1</span></a> 섹션의 논의를 따라 <em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS2.p1.1.1">i.e.,</em> 시연 선택, 형식 및 순서의 세 가지 주요 측면에서 ICL의 시연 디자인을 소개할 것이다.</p>
</div>
<div id="S6.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS2.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS2.p2.1.1">Demonstration Selection. </span>  ICL의 성능은 다른 데모 예<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib428" title="">428</a>]</cite>에 따라 분산이 큰 경향이 있으므로 LLM의 ICL 능력을 효과적으로 활용할 수 있는 예제의 하위 집합을 선택하는 것이 중요하다. 두 가지 주요 실증 선택 접근법, 즉 휴리스틱 접근법과 LLM 기반 접근법이 있다.</p>
</div>
<div id="S6.SS2.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS2.p3.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS2.SSS2.p3.1.m1.1"><semantics id="S6.SS2.SSS2.p3.1.m1.1a"><mo id="S6.SS2.SSS2.p3.1.m1.1.1" xref="S6.SS2.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.1.m1.1b"><ci id="S6.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS2.p3.2.1">Heuristic approaches. </em> 기존 작업은 단순성과 저렴한 비용으로 인해 시연을 선택하기 위해 휴리스틱 방법을 널리 채택하고 있다. 여러 연구에서 <math alttext="k" class="ltx_Math" display="inline" id="S6.SS2.SSS2.p3.2.m2.1"><semantics id="S6.SS2.SSS2.p3.2.m2.1a"><mi id="S6.SS2.SSS2.p3.2.m2.1.1" xref="S6.SS2.SSS2.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.2.m2.1b"><ci id="S6.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S6.SS2.SSS2.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.2.m2.1c">k</annotation></semantics></math>-NN 기반 리트리버를 사용하여 쿼리 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib428" title="">428</a>, <a class="ltx_ref" href="#bib.bib480" title="">480</a>]</cite>와 의미적으로 관련된 예를 선택한다. 그러나, 이들은 집합된 예를 전체적으로 평가하는 것이 아니라, 각각의 예에 대해 개별적으로 선택을 수행한다. 이 문제를 해결하기 위해 특정 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib481" title="">481</a>, <a class="ltx_ref" href="#bib.bib482" title="">482</a>]</cite>에 대한 가장 대표적인 예제 집합을 선택하기 위해 다양성 기반 선택 전략이 제안된다. 또한 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib483" title="">483</a>]</cite>에서는 데모를 선택할 때 관련성과 다양성을 모두 고려하였다.</p>
</div>
<div id="S6.SS2.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS2.SSS2.p4.1.m1.1"><semantics id="S6.SS2.SSS2.p4.1.m1.1a"><mo id="S6.SS2.SSS2.p4.1.m1.1.1" xref="S6.SS2.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p4.1.m1.1b"><ci id="S6.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS2.p4.1.1">LLM 기반 접근법. </em> 다른 작업 라인은 LLM을 사용하여 데모를 선택합니다. 예를 들어, LLMs은 예시 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib484" title="">484</a>]</cite>를 추가한 후 성능 이득에 따라 각 예시의 정보성을 직접 측정하는 데 활용될 수 있다. 또한, EPR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib429" title="">429</a>]</cite>는 먼저 유사한 예제를 비지도 방식(<em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS2.p4.1.2">e.g.,</em> BM25)으로 리트리버한 후 조밀한 리트리버를 사용하여 순위를 매기는 2단계 검색 접근법을 제안한다. 대안적인 접근법으로, 데모 선택 작업은 RL 문제로 공식화될 수 있으며, 여기서 LLM은 정책 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib485" title="">485</a>]</cite>를 훈련하기 위한 피드백을 제공하기 위한 보상 함수 역할을 한다. LLM은 텍스트 주석 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib486" title="">486</a>]</cite>]에 대해 잘 수행되기 때문에 최근 일부 연구에서는 인간의 개입 없이 LLM 자체를 데모 생성기로 사용한다.</p>
</div>
<div id="S6.SS2.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS2.p5.1">요약하면, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib488" title="">488</a>]</cite>에서 논의된 바와 같이, ICL에서 선택된 데모 예들은 위의 두 가지 선택 접근법에 대해 테스트 쿼리와 관련될 뿐만 아니라 해결할 작업에 대한 충분한 정보를 포함해야 한다.</p>
</div>
<div id="S6.SS2.SSS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS2.SSS2.p6.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS2.p6.1.1">Demonstration Format. </span> 작업 예제를 선택한 후 다음 단계는 LLMs에 대한 자연어 프롬프트에 통합하여 포맷하는 것입니다. 간단한 방법은 미리 정의된 템플릿을 해당 입력 출력 쌍 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib36" title="">36</a>]</cite>로 인스턴스화하는 것이다. 보다 유익한 템플릿을 구성하기 위해 최근 연구에서는 태스크 설명 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>를 추가하거나 연쇄 사상 프롬프트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>를 사용하여 LLM의 추론 능력을 향상시키는 것을 고려한다. 예를 들어, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib166" title="">166</a>]</cite>에서 저자는 인간이 작성한 작업 설명과 함께 대규모 데이터 세트를 수집한다. 이 데이터 세트로 튜닝한 후 볼 수 있는 작업에 대한 성능이 향상될 수 있으며 LLM도 볼 수 없는 작업에 대해 어느 정도 일반화할 수 있다. 주석 비용을 줄이기 위해 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>에서 사람이 쓴 작업 설명으로 구성된 시드 집합을 사용하여 LLM을 사용하여 새로운 작업에 대한 작업 설명을 생성하는 반자동화 접근법이 제안되었다. 다른 작업에 대해 수동으로 데모 형식을 주석하는 데 비용이 많이 들기 때문에 일부 작업에서는 고품질 형식을 자동으로 생성하는 방법도 연구한다. 두 가지 대표적인 방법으로 Auto-CoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib434" title="">434</a>]</cite>는 LLMs을 zero-shot 프롬프트 "<em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS2.p6.1.2">Let’s step by step</em>"를 사용하여 중간 추론 단계를 생성하는 반면, 최소-최대 프롬프트 "<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib439" title="">439</a>]</cite> 첫 번째 프롬프트는 LLMs을 쿼리하여 문제 분해를 수행한 다음 LLMs을 활용하여 이전에 해결한 중간 답변을 기반으로 하위 문제를 순차적으로 해결합니다.</p>
</div>
<div id="S6.SS2.SSS2.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS2.SSS2.p7.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS2.p7.1.1">Demonstration Order. </span> LLMs은 때때로 최신성 편향에 시달리는 것으로 나타났으며, <em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS2.p7.1.2">i.e.,</em> 그들은 데모 끝 근처에 있는 반복 답변을 하기 쉽다. 따라서 시연(<em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS2.p7.1.3">i.e.,</em> 작업 예제)을 합리적인 순서로 배열하는 것이 중요합니다. 초기 작업은 좋은 순서를 빠르게 찾기 위해 몇 가지 휴리스틱 방법을 제안한다. 예를 들어, 임베딩 공간<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib428" title="">428</a>]</cite>: 유사할수록 끝에 가까울수록 질의에 대한 유사도에 따라 데모를 직접 구성할 수 있다. 또한, 글로벌 및 로컬 엔트로피 메트릭들은 상이한 데모 순서들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib432" title="">432</a>]</cite>를 스코어링하기 위해 사용될 수 있다. 더 많은 태스크 정보를 통합하기 위해, 일부 최근의 연구들은 태스크 레이블을 압축하고 전송하는 데 필요한 코드 길이를 최소화하는 것을 제안하는데, 이는 정보 이론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib489" title="">489</a>]</cite>에서 영감을 받았다. 그러나 이러한 방법은 특정 데모 주문의 성능을 평가하기 위해 검증 세트로 라벨링된 추가 데이터가 필요하다. 이러한 필요성을 제거하기 위해 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib432" title="">432</a>]</cite>의 저자는 LLM 자체에서 검증 데이터를 샘플링할 것을 제안한다.</p>
</div>
</section>
<section id="S6.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.3 </span>Underlying Mechanism</h4>

<div id="S6.SS2.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS3.p1.1">사전 훈련 후 LLM은 업데이트되지 않고 흥미로운 ICL 기능을 나타낼 수 있다. 다음에서는 LLM의 ICL 능력에 대한 두 가지 주요 질문에 대해 논의합니다. <em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS3.p1.1.1">i.e.,</em> "<em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS3.p1.1.2">how do pre-training affect the ICL ability</em>" 및 "<em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS3.p1.1.3">how do LLMs perform ICL during inference</em>.</p>
</div>
<div id="S6.SS2.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS2.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS3.p2.1.1">How Pre-Training Affects ICL? </span> ICL은 GPT-3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>에서 처음 제안되었으며, 모델 크기가 클수록 ICL 능력이 더 중요해지는 것으로 나타났다. 또한, 일부 연구에서는 소규모 PLM이 특수 설계된 훈련 작업에서 연속 사전 훈련 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib490" title="">490</a>]</cite> 또는 미세 조정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib491" title="">491</a>]</cite>에 의해 강력한 ICL 능력을 입증할 수 있음을 보여주며, 이는 일반적으로 훈련 프로세스 동안 입력에 추가 작업 예가 포함된다. 이는 훈련과제 설계가 LLM의 ICL 역량에 중요한 영향요인임을 시사한다. 훈련 작업 외에도 최근 연구에서는 ICL과 훈련 전 코퍼스<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib488" title="">488</a>, <a class="ltx_ref" href="#bib.bib492" title="">492</a>]</cite>의 관계를 조사했다. 예를 들어, ICL은 장거리 coherence <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib488" title="">488</a>]</cite>를 나타내는 문서에 대한 사전 훈련의 곱으로 이론적으로 설명될 수 있다. 또한, 다른 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib492" title="">492</a>]</cite>는 이론적으로 파라미터와 데이터를 스케일링할 때 다음 단어 예측에 기반한 LLMs이 언어 데이터에 존재하는 구성 구조(<em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS3.p2.1.2">e.g.,</em> 단어와 구가 어떻게 결합되어 문장과 같은 더 큰 언어 단위를 형성하는지)로부터 학습함으로써 ICL의 능력을 발현할 수 있음을 분석한다.</p>
</div>
<div id="S6.SS2.SSS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS2.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.SSS3.p3.1.1">How LLMs Perform ICL"> </span> 추론 단계에서 연구자들은 명시적 학습이나 업데이트가 포함되지 않기 때문에 주어진 데모를 기반으로 ICL 기능이 어떻게 작동하는지 분석하는 데 중점을 둔다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib493" title="">493</a>]</cite>의 논의에 따르면 LLMs가 데모를 활용하는 방법은 크게 과제 인식과 과제 학습 두 가지가 있다.</p>
</div>
<div id="S6.SS2.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS3.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS2.SSS3.p4.1.m1.1"><semantics id="S6.SS2.SSS3.p4.1.m1.1a"><mo id="S6.SS2.SSS3.p4.1.m1.1.1" xref="S6.SS2.SSS3.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p4.1.m1.1b"><ci id="S6.SS2.SSS3.p4.1.m1.1.1.cmml" xref="S6.SS2.SSS3.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS3.p4.1.1">Task recognition. </em> 첫 번째 방법으로 LLMs은 데모에서 작업을 인식하고 사전 훈련에서 얻은 사전 지식을 활용하여 새로운 테스트 작업을 해결한다. ICL의 학습성을 평가하기 위해 PAC(Probably Approximate Correct) 프레임워크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib494" title="">494</a>]</cite>가 제안되었다. 사전 훈련 데이터에서 과제를 나타내는 잠재 변수가 있다고 가정하며, LLM은 시범에서 이 변수를 포착할 수 있어 ICL에서 과제를 인식할 수 있는 것으로 나타났다. 또한 ICL을 과제 인식으로 해석하는 것은 여러 경험적 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib478" title="">478</a>, <a class="ltx_ref" href="#bib.bib495" title="">495</a>]</cite>에 의해 뒷받침된다. 예를 들어, 데모들의 입력들 또는 라벨들을 입력 또는 라벨 공간으로부터 샘플링된 랜덤한 것들로 대체하는 것은 LLMs들의 성능을 심각하게 손상시키지 않는다는 것이 관찰되었는데, 이는 LLMs들이 그것들로부터 학습하는 대신에 데모들로부터 타겟 태스크를 주로 인식한다는 것을 나타낸다. 유사하게, LLMs는 프롬프트 템플릿이 관련 없거나 오판의 소지가 있는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib495" title="">495</a>]</cite>일지라도 괜찮은 성능을 나타낼 수 있다.</p>
</div>
<div id="S6.SS2.SSS3.p5" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS3.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS2.SSS3.p5.1.m1.1"><semantics id="S6.SS2.SSS3.p5.1.m1.1a"><mo id="S6.SS2.SSS3.p5.1.m1.1.1" xref="S6.SS2.SSS3.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS3.p5.1.m1.1b"><ci id="S6.SS2.SSS3.p5.1.m1.1.1.cmml" xref="S6.SS2.SSS3.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS3.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS3.p5.1.1">Task learning. </em> 두 번째 방법으로 LLMs는 시범을 통해서만 사전 훈련 단계에서 보이지 않는 새로운 과제를 학습한다. 특히, 과제 학습은 주로 경사 하강의 관점에서 분석되며 암시적 미세 조정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib496" title="">496</a>, <a class="ltx_ref" href="#bib.bib65" title="">65</a>]</cite>로 간주된다. 그런 다음, ICL은 다음과 같이 설명될 수 있다: 순방향 계산을 통해 LLM은 데모에 대한 메타-구배를 생성하고 주의 메커니즘을 통해 암묵적으로 기울기 하강을 수행한다. 실험은 또한 LLM의 특정 어텐션 헤드가 태스크 불가지론적 원자 연산(<em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS3.p5.1.2">e.g.,</em> 복사 및 접두사 매칭)을 수행할 수 있음을 보여주며, 이는 ICL 능력<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib497" title="">497</a>]</cite>와 밀접한 관련이 있다. 나아가 알고리즘 학습과정으로 ICL을 추상화한 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib498" title="">498</a>]</cite>를 연구하기도 한다. 예를 들어, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib498" title="">498</a>]</cite>의 저자들은 LLM들이 사전 트레이닝 동안 그들의 파라미터들을 통해 암시적 모델들을 본질적으로 인코딩한다는 것을 발견한다. ICL에 제공된 예를 통해, LLM은 경사 하강과 같은 학습 알고리즘을 구현하거나 순방향 계산 동안 이들 모델을 업데이트하기 위해 폐쇄형 솔루션을 직접 계산할 수 있다. 이러한 설명 프레임워크 하에서 LLMs은 ICL<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib498" title="">498</a>]</cite>를 갖는 단순한 선형함수와 의사결정나무와 같은 복잡한 함수까지도 효과적으로 학습할 수 있음을 보였다.</p>
</div>
<div id="S6.SS2.SSS3.p6" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS3.p6.1">최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib493" title="">493</a>]</cite>에서 논의한 바와 같이 LLM은 ICL에서 과제 인식과 과제 학습의 능력을 모두 나타내지만 두 능력은 모델 척도가 다른 것으로 보인다. 실험 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib493" title="">493</a>]</cite>에 나타난 바와 같이, 태스크 인식의 능력은 더 쉽게 얻을 수 있으며, 350M 파라미터만을 갖는 작은 LM이라도 이러한 능력을 나타낼 수 있는 반면, 태스크 학습은 적어도 66B 파라미터를 갖는 LLM에 대해서만 나타날 수 있다. 또 다른 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib499" title="">499</a>]</cite>도 특별히 설계된 실험을 통해 이러한 발견을 뒷받침한다. 그들은 ICL을 수행할 때 태스크 학습이 필요한 실험에서 플립된 레이블과 의미적으로 관련이 없는 레이블로 태스크를 설정한다. 결과는 작은 LLM이 레이블을 무시하고 주로 작업을 수행하기 위해 사전 지식에 의존하는 경향이 있는 반면 LLM은 사전 지식을 능가하고 시연에서 새로운 지식을 습득할 수 있어 더 나은 결과를 가져온다는 것을 시사한다. 또한 태스크 학습 능력을 향상시키기 위해 메타-인-컨텍스트 학습 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib500" title="">500</a>]</cite>는 프롬프트에 단일 태스크가 아닌 여러 개의 관련 태스크를 포함시키는 것을 제안한다. 또한, Symbol Tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib501" title="">501</a>]</cite> fine-tunes LLMs on Semantically unrelated labels (<em class="ltx_emph ltx_font_italic" id="S6.SS2.SSS3.p6.1.1">e.g.,</em> foo/bar instead for positive/negative for emotion analysis) LLMs to learn the task from demonstration instead instead on prior knowledge.</p>
</div>
<figure id="S6.F15" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x15.png" id="S6.F15.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 15:</span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>
An illustration of the evolution of CoT prompting strategies. It begins with the basic CoT approach and progresses to enhanced CoT generation techniques, including sampling-based and verification-based methods. Finally, it extends to variations of the chain structure, such as trees and graphs. Here, “thought” refers to an intermediate reasoning step as stated in&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib451" title="" class="ltx_ref">451</a>]</cite>.
</figcaption>
</figure>
</section>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span><span id="S6.SS3.1.1" class="ltx_text ltx_font_italic">Chain-of-Thought Prompting</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS3.p1.1"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>, <a class="ltx_ref" href="#bib.bib502" title="">502</a>]</cite>는 산술 추론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib503" title="">503</a>]</cite>, 상식 추론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib504" title="">504</a>]</cite>, 기호 추론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>와 같이 복잡한 추론 작업에서 LLM의 성능을 높이기 위한 개선된 프롬프트 전략이다. ICL과 같은 입력-출력 쌍으로 프롬프트를 단순히 구성하는 대신 CoT 프롬프트는 입력과 출력 사이의 브리지 역할을 하는 중간 추론 단계를 추가로 통합한다. <a class="ltx_ref" href="#S6.F14" title="Figure 14 ‣ 6.2.1 ICL Formulation ‣ 6.2 In-Context Learning ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">14</span></a>는 CoT의 예시를 나타낸다. 다음 부분에서는 먼저 기본 CoT 프롬프트 접근법과 개선된 전략에 대해 자세히 설명한 다음 CoT 프롬프트가 언제 및 왜 작동하는지 논의한다.</p>
</div>
<section id="S6.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.1 </span>Basic CoT Prompting Approach</h4>

<div id="S6.SS3.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS1.p1.6">CoT 프롬프트링은 먼저 ICL<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>의 확장으로서 제안되며, 이는 각각의 데모 <math alttext="\langle" class="ltx_Math" display="inline" id="S6.SS3.SSS1.p1.1.m1.1"><semantics id="S6.SS3.SSS1.p1.1.m1.1a"><mo id="S6.SS3.SSS1.p1.1.m1.1.1" stretchy="false" xref="S6.SS3.SSS1.p1.1.m1.1.1.cmml">⟨</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS1.p1.1.m1.1b"><ci id="S6.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S6.SS3.SSS1.p1.1.m1.1.1">⟨</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS1.p1.1.m1.1c">\langle</annotation></semantics></math><em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS1.p1.6.1">input, output</em><math alttext="\rangle" class="ltx_Math" display="inline" id="S6.SS3.SSS1.p1.2.m2.1"><semantics id="S6.SS3.SSS1.p1.2.m2.1a"><mo id="S6.SS3.SSS1.p1.2.m2.1.1" stretchy="false" xref="S6.SS3.SSS1.p1.2.m2.1.1.cmml">⟩</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS1.p1.2.m2.1b"><ci id="S6.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S6.SS3.SSS1.p1.2.m2.1.1">⟩</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS1.p1.2.m2.1c">\rangle</annotation></semantics></math> as <math alttext="\langle" class="ltx_Math" display="inline" id="S6.SS3.SSS1.p1.3.m3.1"><semantics id="S6.SS3.SSS1.p1.3.m3.1a"><mo id="S6.SS3.SSS1.p1.3.m3.1.1" stretchy="false" xref="S6.SS3.SSS1.p1.3.m3.1.1.cmml">⟨</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS1.p1.3.m3.1b"><ci id="S6.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S6.SS3.SSS1.p1.3.m3.1.1">⟨</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS1.p1.3.m3.1c">\langle</annotation></semantics></math><em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS1.p1.6.2">input, CoT, output</em><math alttext="\rangle" class="ltx_Math" display="inline" id="S6.SS3.SSS1.p1.4.m4.1"><semantics id="S6.SS3.SSS1.p1.4.m4.1a"><mo id="S6.SS3.SSS1.p1.4.m4.1.1" stretchy="false" xref="S6.SS3.SSS1.p1.4.m4.1.1.cmml">⟩</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS1.p1.4.m4.1b"><ci id="S6.SS3.SSS1.p1.4.m4.1.1.cmml" xref="S6.SS3.SSS1.p1.4.m4.1.1">⟩</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS1.p1.4.m4.1c">\rangle</annotation></semantics></math>를 증가시킨다. A <span class="ltx_text ltx_font_italic" id="S6.SS3.SSS1.p1.6.3">CoT</span>은 <span class="ltx_text ltx_font_italic" id="S6.SS3.SSS1.p1.6.4">input</span> 및 <span class="ltx_text ltx_font_italic" id="S6.SS3.SSS1.p1.6.5">output</span>을 연결하기 위한 일련의 중간 추론 단계이다. 이러한 증강된 데모를 통해 LLM은 이를 따라 CoT를 생성하고 새로운 입력에 대한 답변을 생성할 수 있다. 그러나 ICL에서 <math alttext="\langle" class="ltx_Math" display="inline" id="S6.SS3.SSS1.p1.5.m5.1"><semantics id="S6.SS3.SSS1.p1.5.m5.1a"><mo id="S6.SS3.SSS1.p1.5.m5.1.1" stretchy="false" xref="S6.SS3.SSS1.p1.5.m5.1.1.cmml">⟨</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS1.p1.5.m5.1b"><ci id="S6.SS3.SSS1.p1.5.m5.1.1.cmml" xref="S6.SS3.SSS1.p1.5.m5.1.1">⟨</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS1.p1.5.m5.1c">\langle</annotation></semantics></math><em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS1.p1.6.6">input, output</em><math alttext="\rangle" class="ltx_Math" display="inline" id="S6.SS3.SSS1.p1.6.m6.1"><semantics id="S6.SS3.SSS1.p1.6.m6.1a"><mo id="S6.SS3.SSS1.p1.6.m6.1.1" stretchy="false" xref="S6.SS3.SSS1.p1.6.m6.1.1.cmml">⟩</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS1.p1.6.m6.1b"><ci id="S6.SS3.SSS1.p1.6.m6.1.1.cmml" xref="S6.SS3.SSS1.p1.6.m6.1.1">⟩</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS1.p1.6.m6.1c">\rangle</annotation></semantics></math> pairs와 달리 CoT는 구하기 어렵고 일반적으로 인간 주석을 필요로 한다. 다행히도, LLMs이 “<em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS1.p1.6.7">Let’s thinking step by step.</em>과 같은 간단한 명령을 통해 CoT를 생성하도록 트리거될 수 있다는 것이 발견되었다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib505" title="">505</a>]</cite> CoT를 쉽게 사용할 수 있도록 합니다. 또한 CoT 추론의 능력을 이끌어내고 LLM의 성능을 더욱 향상시킬 수 있는 대안적인 매직 프롬프트가 있는데, "<em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS1.p1.6.8">심호흡을 하고 이 문제에 대해 단계별로 작업하세요.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib473" title="">473</a>]</cite>.</p>
</div>
<div id="S6.SS3.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS1.p2.1"><a class="ltx_ref" href="#S6.F15" title="Figure 15 ‣ 6.2.3 Underlying Mechanism ‣ 6.2 In-Context Learning ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">15</span></a>에 예시된 바와 같이, CoT의 생성 프로세스는 기본 CoT 프롬프트 접근법에서 체인 구조를 따르며, 여기서 LLM은 단계적으로 CoT를 생성한다. 통상적으로 CoT는 자연어 텍스트의 형식을 취한다. 그러나 텍스트 CoT는 추론을 위해 엄격한 논리를 필요로 하는 복잡한 작업에서는 잘 작동하지 않을 수 있다. 이를 고려할 때, 어떤 작업은 구조화되고 정밀한 특성으로 인해 코드 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib506" title="">506</a>, <a class="ltx_ref" href="#bib.bib507" title="">507</a>]</cite>를 사용한다. 또한 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib508" title="">508</a>]</cite>의 저자들은 CoT의 형식으로 텍스트나 코드를 동적으로 선택하여 장점을 결합시킬 것을 제안한다.</p>
</div>
</section>
<section id="S6.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.2 </span>Improved CoT Prompting Strategies</h4>

<div id="S6.SS3.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS2.p1.1">복잡한 추론 작업에서 성능 향상에도 불구하고, CoT 프롬프트는 여전히 잘못된 추론 및 불안정성과 같은 문제로 어려움을 겪는다. 이 부분에서는 먼저 더 나은 CoT 프롬프트와 향상된 CoT 생성 전략을 설계하는 방법을 소개하고, 이어서 CoT의 기본 사슬 구조의 확장을 소개한다. <a class="ltx_ref" href="#S6.F15" title="Figure 15 ‣ 6.2.3 Underlying Mechanism ‣ 6.2 In-Context Learning ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">15</span></a>는 대표적인 CoT 프롬프트 전략의 진화를 예시한다.</p>
</div>
<div id="S6.SS3.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS3.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS3.SSS2.p2.1.1">Better Prompt Design. </span> CoT 프롬프트는 LLM의 추론 능력을 이끌어내기 위해 프롬프트에 의존하기 때문에 프롬프트의 설계는 성능에 매우 중요하다. 직접적인 접근 방법으로 다양한 CoT(<em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS2.p2.1.2">i.e.,</em> multiple reasoning paths for each problem)를 사용하는 것이 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib437" title="">437</a>]</cite>의 성능을 효과적으로 향상시킬 수 있음을 보인다. 또 다른 직관적인 아이디어는 더 복잡한 추론 경로를 가진 프롬프트가 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib433" title="">433</a>]</cite>의 추론 능력을 이끌어낼 가능성이 높아 정답 생성의 정확도가 높아질 수 있다는 것이다. 그러나 이러한 모든 접근법은 주석이 달린 CoT 데이터 세트에 의존하여 실제 사용을 제한한다. 이러한 한계를 극복하기 위해 “<em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS2.p2.1.3">Let’s think step by step</em>”과 같은 매직 명령어를 사용하여 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib434" title="">434</a>]</cite>를 프롬프트하여 CoT를 자동으로 구성할 수 있다.</p>
</div>
<div id="S6.SS3.SSS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS3.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS3.SSS2.p3.1.1">Enhanced CoT Generation. </span>  LLMs은 잘못된 추론 단계를 생성하고 생성 과정에서 불안정성을 나타내기 쉽기 때문에 CoT 생성을 개선하기 위한 많은 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib509" title="">509</a>, <a class="ltx_ref" href="#bib.bib436" title="">436</a>]</cite>가 있다. 이 부분에서 우리는 CoT 생성을 향상시키기 위한 두 가지 전형적인 접근법, 즉 샘플링 기반 방법과 검증 기반 방법을 소개할 것이다.</p>
</div>
<div id="S6.SS3.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS2.p4.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS3.SSS2.p4.1.m1.1"><semantics id="S6.SS3.SSS2.p4.1.m1.1a"><mo id="S6.SS3.SSS2.p4.1.m1.1.1" xref="S6.SS3.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS2.p4.1.m1.1b"><ci id="S6.SS3.SSS2.p4.1.m1.1.1.cmml" xref="S6.SS3.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS2.p4.2.1">Sampling-based methods. </em>  LLMs는 추론 중 불안정성을 겪는 것으로 알려져 있으며, 이는 생성된 추론 단계에서 불성실함을 초래할 수 있다. 이 문제를 해결하기 위해 일부 연구에서는 그리디 디코딩을 사용하는 대신 여러 추론 경로를 샘플링하는 것을 제안한다. 대표적인 해결책으로 자기 일관성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib436" title="">436</a>]</cite>는 먼저 여러 가지 추론 경로를 생성한 후 해당 답변에 대해 앙상블을 취하여 다수결 투표를 통해 가장 일관성 있는 답변을 선택한다. 그러나, 이러한 방법은 대부분의 추론 경로들이 오도될 때 여전히 오답으로 이어질 수 있다. 이를 고려할 때, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib433" title="">433</a>]</cite>의 저자들은 더 높은 복잡도를 갖는 추론 경로(<em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS2.p4.2.2">e.g.,</em> 더 많은 추론 단계)가 일반적으로 더 나은 성능을 갖는다는 관찰에 기초하여 <math alttext="k" class="ltx_Math" display="inline" id="S6.SS3.SSS2.p4.2.m2.1"><semantics id="S6.SS3.SSS2.p4.2.m2.1a"><mi id="S6.SS3.SSS2.p4.2.m2.1.1" xref="S6.SS3.SSS2.p4.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS2.p4.2.m2.1b"><ci id="S6.SS3.SSS2.p4.2.m2.1.1.cmml" xref="S6.SS3.SSS2.p4.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS2.p4.2.m2.1c">k</annotation></semantics></math>의 대부분의 복잡한 추론 경로에만 투표한다. 또한, MCR<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib510" title="">510</a>]</cite>는 다음 단계를 생성할 때 다른 추론 경로에서 단계를 참조하는 것을 제안하고, 최종 답변을 생성하기 위해 여러 추론 경로에 걸쳐 추론을 수행한다.</p>
</div>
<div id="S6.SS3.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS2.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS3.SSS2.p5.1.m1.1"><semantics id="S6.SS3.SSS2.p5.1.m1.1a"><mo id="S6.SS3.SSS2.p5.1.m1.1.1" xref="S6.SS3.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS2.p5.1.m1.1b"><ci id="S6.SS3.SSS2.p5.1.m1.1.1.cmml" xref="S6.SS3.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS2.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS2.p5.1.1">Verification-based methods. </em>  CoT에서 추론 단계의 순차적 특성은 특정 단계가 잘못되었을 때 생성된 CoT에 오류가 누적될 수 있습니다. 이러한 문제를 해결하기 위해, 최근 연구들은 학습된 검증기 또는 LLM 자체를 사용하여 생성된 추론 단계의 정확성을 검증할 것을 제안한다. 예를 들어, DIVERSE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib509" title="">509</a>]</cite>는 서로 다른 입도에서 추론 단계를 조사하기 위해 솔루션 수준 및 단계 수준 검증기를 각각 훈련한다. 또 다른 접근 방식 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib511" title="">511</a>]</cite>는 LLMs를 활용하여 특별히 설계된 추론 형식으로 단계별 자기 검증을 통해 추론 단계의 정확성을 검증한다. 또한, 여러 연구에서 검증을 위해 백워드 추론을 제안하는데, 먼저 모델의 예측으로부터 필요한 질문 조건인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib512" title="">512</a>, <a class="ltx_ref" href="#bib.bib513" title="">513</a>]</cite> 또는 변수인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib514" title="">514</a>]</cite>를 추론한 후, 이를 원본과 비교한다.</p>
</div>
<div id="S6.SS3.SSS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS3.SSS2.p6.1"><span class="ltx_text ltx_font_bold" id="S6.SS3.SSS2.p6.1.1">Reasoning Structure Extension. </span>  일반성에도 불구하고, 기본 CoT 프롬프트의 연쇄 추론 구조는 추론 시 예측 및 역추적과 같은 탐구가 필요한 복잡한 작업을 해결하는 데 있어 효율성을 제한합니다. 따라서 많은 연구들이 보다 복잡한 사고 과정인 <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS2.p6.1.2">e.g.,</em> tree- 및 graph-structured reasoning을 설계하여 추론 구조를 확장하는 데 전념하고 있다.</p>
</div>
<div id="S6.SS3.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS3.SSS2.p7.1.m1.1"><semantics id="S6.SS3.SSS2.p7.1.m1.1a"><mo id="S6.SS3.SSS2.p7.1.m1.1.1" xref="S6.SS3.SSS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS2.p7.1.m1.1b"><ci id="S6.SS3.SSS2.p7.1.m1.1.1.cmml" xref="S6.SS3.SSS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS2.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS2.p7.1.1">Tree-structured reasoning. </em> 이 접근법(exemplified by Tree of Thoughts(ToT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib451" title="">451</a>, <a class="ltx_ref" href="#bib.bib515" title="">515</a>]</cite>)은 중간 생각이 노드인 계층적 트리 구조로 추론 프로세스를 공식화한다. 이러한 방식으로, LLM들이 다수의 추론 경로들을 병렬로 탐색할 수 있게 하고, 더 나아가 보다 포괄적인 결정들을 용이하게 하기 위해 룩어헤드 및 백트래킹의 동작을 지원한다. 또한, TouT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib516" title="">516</a>]</cite>는 중간 생각의 불확실성을 고려하여 몬테카를로 드롭아웃 기반의 사고 평가를 수행한다.</p>
</div>
<div id="S6.SS3.SSS2.p8" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS2.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS3.SSS2.p8.1.m1.1"><semantics id="S6.SS3.SSS2.p8.1.m1.1a"><mo id="S6.SS3.SSS2.p8.1.m1.1.1" xref="S6.SS3.SSS2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS2.p8.1.m1.1b"><ci id="S6.SS3.SSS2.p8.1.m1.1.1.cmml" xref="S6.SS3.SSS2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS2.p8.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS2.p8.1.1">Graph-structured reasoning. </em>  트리 구조는 병렬 추론을 용이하게 하지만 추론 과정에 제한을 가하기도 한다. 더 복잡한 위상 구조로 그래프는 추론에 더 큰 유연성을 제공하여 더 복잡한 관계와 상호 작용의 특성화를 가능하게 한다. 예를 들어, 생각의 그래프(GoT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib517" title="">517</a>, <a class="ltx_ref" href="#bib.bib518" title="">518</a>]</cite>는 추론 과정을 임의의 그래프로 개념화하는데, 여기서 꼭짓점은 중간 생각을, 간선은 이들 생각 사이의 상호 의존성을 의미한다. ToT와 비교하여 새로운 생각을 생성할 때 다른 추론 경로로부터의 생각을 더 활용할 수 있다. 그러나 이러한 접근 방식은 LLM과의 많은 상호 작용을 필요로 하므로 사고 탐색 과정이 매우 비효율적이다. 잠재적으로 무의미한 사고 탐색을 줄이기 위해 XoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib519" title="">519</a>]</cite>는 사전 훈련된 정책 및 가치 네트워크로 사고 탐색을 안내하는 것을 추가로 제안한다.</p>
</div>
</section>
<section id="S6.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.3.3 </span>Further Discussion on CoT Prompting</h4>

<div id="S6.SS3.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS3.p1.1">이 부분에서는 CoT 프롬핑과 관련된 두 가지 기본 질문인 <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p1.1.1">i.e.,</em> "<span class="ltx_text ltx_font_italic" id="S6.SS3.SSS3.p1.1.2">when do CoT 프롬핑 working for LLMs</span>" and "<span class="ltx_text ltx_font_italic" id="S6.SS3.SSS3.p1.1.3">why can LLMs perform CoT reasoning</span>에 대한 논의를 제시한다.</p>
</div>
<div id="S6.SS3.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS3.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS3.SSS3.p2.1.1">When CoT Prompting Works For LLMs? </span> CoT 추론은 창발 능력이기 때문에 충분히 큰 모델(일반적으로 10B 이상의 매개 변수를 포함함<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>)에는 긍정적인 영향을 미칠 뿐 작은 모델에는 영향을 미치지 않는다. 더욱이, CoT 프롬프트는 중간 추론 단계로 표준 프롬프트를 증가시키므로, 단계적 추론 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p2.1.2">e.g.,</em> 산술 추론, 상식 추론 및 기호 추론이 필요한 작업에 주로 효과적이다. 반면, 복잡한 추론에 의존하지 않는 다른 태스크의 경우, CoT 프롬핑은 표준 프롬핑 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib438" title="">438</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p2.1.3">e.g.,</em> MNLI-m/mm, SST-2, QQP from GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib260" title="">260</a>]</cite>보다 더 나쁜 성능을 초래할 수 있다. 흥미롭게도 CoT 프롬프트가 가져온 성능 이득은 표준 프롬프트가 나쁜 결과를 가져올 때만 중요할 수 있는 것 같다.</p>
</div>
<div id="S6.SS3.SSS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS3.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS3.SSS3.p3.1.1">왜 LLMs Can Perform CoT Reasoning? </span> 두 번째 질문으로 다음과 같은 두 가지 측면에서 CoT 프롬프트의 기본 메커니즘을 논의한다.</p>
</div>
<div id="S6.SS3.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS3.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS3.SSS3.p4.1.m1.1"><semantics id="S6.SS3.SSS3.p4.1.m1.1a"><mo id="S6.SS3.SSS3.p4.1.m1.1.1" xref="S6.SS3.SSS3.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS3.p4.1.m1.1b"><ci id="S6.SS3.SSS3.p4.1.m1.1.1.cmml" xref="S6.SS3.SSS3.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS3.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p4.1.1">The source of CoT reasoning ability</em>. CoT 추론 능력의 원천과 관련하여, 코드에 대해 훈련된 모델들은 강력한 추론 능력 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib520" title="">520</a>, <a class="ltx_ref" href="#bib.bib47" title="">47</a>, <a class="ltx_ref" href="#bib.bib521" title="">521</a>]</cite>를 보이기 때문에 코드에 대한 훈련에 기인할 수 있다는 것이 널리 가설되고 있다. 직관적으로 코드 데이터는 알고리즘 로직과 프로그래밍 흐름으로 잘 구성되어 있으며, 이는 LLM의 추론 성능을 향상시키는 데 유용할 수 있다. 그러나 이 가설은 여전히 공개적으로 보고된 절제 실험의 증거가 부족하다(<em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p4.1.2">with</em> 및 <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p4.1.3">without</em> training on code). 또한, 비 CoT 데이터에 대한 명령어 튜닝이 보류된 CoT 추론 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>에 대한 성능을 향상시키지 않는다는 것이 경험적으로 입증되었기 때문에 명령어 튜닝이 CoT 추론 능력을 얻는 핵심 이유는 아닌 것 같다.</p>
</div>
<div id="S6.SS3.SSS3.p5" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS3.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS3.SSS3.p5.1.m1.1"><semantics id="S6.SS3.SSS3.p5.1.m1.1a"><mo id="S6.SS3.SSS3.p5.1.m1.1.1" xref="S6.SS3.SSS3.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS3.p5.1.m1.1b"><ci id="S6.SS3.SSS3.p5.1.m1.1.1.cmml" xref="S6.SS3.SSS3.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS3.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p5.1.1">The effect of CoT prompting components</em>. CoT 프롬프트와 표준 프롬프트의 주요 차이점은 최종 답변에 앞서 추론 경로를 통합하는 것이다. 따라서 일부 연구자들은 추론 경로에서 서로 다른 구성 요소의 영향을 조사한다. 구체적으로, 최근 연구에서는 CoT 프롬핑에서 세 가지 핵심 구성 요소, 즉 <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p5.1.2">symbols</em> (<em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p5.1.3">e.g.,</em> numerical quantities in arithmetic reasoning), <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p5.1.4">patterns</em> (<em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p5.1.5">e.g.,</em> equations in arithmetic reasoning), 및 <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p5.1.6">text</em> (<em class="lt 후자의 두 부분(<em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS3.p5.1.8">i.e.,</em> 패턴 및 텍스트)은 모델 성능에 필수적이며, 둘 중 하나를 제거하면 상당한 성능 저하를 초래할 수 있음을 보여준다. 그러나 기호와 패턴의 정확성은 중요하지 않아 보인다. 또한 텍스트와 패턴 사이에는 공생 관계가 존재한다. 텍스트는 LLMs가 유용한 패턴을 생성하는 데 도움이 되고, 패턴은 LLMs가 태스크를 이해하고 이를 해결하는 데 도움이 되는 텍스트를 생성하는 데 도움이 된다.</p>
</div>
<div id="S6.SS3.SSS3.p6" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS3.p6.1">요약하면, CoT 프롬프트는 LLM의 추론 능력을 이끌어내기 위한 일반적이고 유연한 접근법을 제공한다. 또한 멀티모달 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib523" title="">523</a>]</cite>와 다국어 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib524" title="">524</a>]</cite>를 해결하기 위해 이 기술을 확장하려는 일부 예비 시도도 있다.</p>
</div>
</section>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span><span id="S6.SS4.1.1" class="ltx_text ltx_font_italic">Planning for Complex Task Solving</span>
</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS4.p1.1">ICL 및 CoT로 프롬프팅하는 것은 개념적으로 간단하지만 다양한 작업을 해결하는 일반적인 접근법이다. 그러나 이 접근법은 수학적 추론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib525" title="">525</a>]</cite> 및 다중 홉 질문 응답 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib526" title="">526</a>]</cite>와 같은 복잡한 작업에 어려움을 겪고 있다. 향상된 접근법으로 복잡한 작업을 더 작은 하위 작업으로 나누고 작업을 수행하기 위한 작업 계획을 생성하기 위해 프롬프트 기반 계획이 제안되었다.</p>
</div>
<section id="S6.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.1 </span>The Overall Framework</h4>

<figure id="S6.F16" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x16.png" id="S6.F16.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="363" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 16:</span> 복잡한 태스크를 해결하기 위한 LLMs에 의한 프롬프트 기반 계획을 위한 포뮬레이션의 예시.</figcaption>
</figure>
<div id="S6.SS4.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS4.SSS1.p1.1">이 부분에서 우리는 먼저 복잡한 과제 해결을 위한 LLM의 일반적인 계획 패러다임을 공식화하는데, 그림 <a class="ltx_ref" href="#S6.F16" title="Figure 16 ‣ 6.4.1 The Overall Framework ‣ 6.4 Planning for Complex Task Solving ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">16</span></a>에 예시되어 있다.</p>
</div>
<div id="S6.SS4.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S6.SS4.SSS1.p2.1">이 패러다임에는 일반적으로 세 가지 구성 요소가 있습니다. <em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS1.p2.1.1">task planner</em>, <em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS1.p2.1.2">plan executor</em>, <em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS1.p2.1.3">environment</em><span class="ltx_note ltx_role_footnote" id="footnote43"><sup class="ltx_note_mark">43</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">43</sup><span class="ltx_tag ltx_tag_note">43</span> Despite the similarity with RL, our formulation decouples the planning and execution phases, whereas in RL, they are typically interleaved in the agent. This paradigm is defined in a general yet slightly loose way, and it mainly aims to help readers understand the key idea underlying the planning approaches of LLMs. </span></span></span>. 구체적으로, LLMs에 의해 재생되는 태스크 플래너는 목표 태스크를 해결하기 위한 전체 계획을 생성하는 것을 목표로 한다. 계획은 다양한 형태로 제시될 수 있는데, <em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS1.p2.1.4">e.g.,</em> 자연어 형태의 액션 시퀀스</cite idx=0></cite> 또는 프로그래밍 언어</cite idx=1></cite>로 작성된 실행 프로그램일 수 있다. LLM 기반 태스크 플래너는 계획 저장 및 검색을 위한 메모리 메커니즘으로 향상될 수 있으며, 이는 긴 수평 태스크에 도움이 된다. 그런 다음 계획 실행자는 계획에서 작업을 실행할 책임이 있습니다. 텍스트 작업을 위한 LLM과 같은 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib441" title="">441</a>]</cite> 또는 코딩 작업을 위한 코드 해석기 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib450" title="">450</a>]</cite>와 같은 도구로 구현할 수 있다. 또한, 환경은 계획 실행기가 특정 작업, 즉 <em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS1.p2.1.5">e.g.,</em> the LLM itself</cite idx=4></cite> 또는 Minecraft</cite idx=5></cite>와 같은 외부 가상 세계를 수행할 수 있습니다. 동작의 실행 결과에 대한 <span class="ltx_text ltx_font_italic" id="S6.SS4.SSS1.p2.1.6">feedback</span>을 자연어 형태인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib450" title="">450</a>]</cite> 또는 다른 멀티모달 신호인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib446" title="">446</a>]</cite>로부터 태스크 플래너에 제공한다.</p>
</div>
<div id="S6.SS4.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S6.SS4.SSS1.p3.1">복잡한 과제를 해결하기 위해, 과제 계획자는 먼저 과제 목표를 명확하게 이해하고 LLMs의 추론에 기초하여 합리적인 계획을 생성할 필요가 있다( Section <a class="ltx_ref" href="#S6.SS4.SSS2" title="6.4.2 Plan Generation ‣ 6.4 Planning for Complex Task Solving ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.4.2</span></a> 참조). 그런 다음, 계획 실행기는 환경에서 계획에 따라 행동하고, 환경은 작업 계획자에 대한 피드백을 생성할 것이다( Section <a class="ltx_ref" href="#S6.SS4.SSS3" title="6.4.3 Feedback Acquisition ‣ 6.4 Planning for Complex Task Solving ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.4.3</span></a> 참조). 태스크 플래너는 환경으로부터 획득된 피드백을 더 통합하여 자신의 초기 계획을 구체화하고, 태스크 솔루션으로서 더 나은 결과를 얻기 위해 상기 프로세스를 반복적으로 수행할 수 있다( Section <a class="ltx_ref" href="#S6.SS4.SSS4" title="6.4.4 Plan Refinement ‣ 6.4 Planning for Complex Task Solving ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.4.4</span></a> 참조).</p>
</div>
</section>
<section id="S6.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.2 </span>Plan Generation</h4>

<div id="S6.SS4.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS4.SSS2.p1.1">플랜 생성은 LLM을 프롬프트함으로써 액션 시퀀스를 직접 생성하는 것에 초점을 맞춘다. 생성된 계획의 형식에 따라 기존 작업은 텍스트 기반 접근법과 코드 기반 접근법의 두 그룹으로 나눌 수 있다.</p>
</div>
<div id="S6.SS4.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS4.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS4.SSS2.p2.1.1">Text-based Approaches. </span> LLM이 자연어의 형태로 계획을 생성하는 것은 간단합니다. 이 접근법에서, LLM들은 계획 실행기가 복잡한 태스크를 수행하고 해결하기 위한 일련의 액션들을 생성하도록 프롬프트된다. 예를 들어, Plan-and-Solve <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib441" title="">441</a>]</cite>는 "<span class="ltx_text ltx_font_typewriter" id="S6.SS4.SSS2.p2.1.2">devise a plan</span>"과 같은 명시적 지침을 추가하여 제로샷 방식으로 계획을 위한 LLM을 직접 프롬프트하는 반면, Self-planning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib529" title="">529</a>]</cite> 및 DECOMP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib440" title="">440</a>]</cite>는 프롬프트에 데모를 추가하여 LLM이 ICL을 통해 계획을 고안하도록 안내합니다. 이러한 방식으로 일부 작업은 계획할 때 추가 도구 또는 모델을 통합하는 것을 추가로 고려한다. 예를 들어 ToolFormer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>는 먼저 LLMs를 사용하여 잠재적인 API 호출이 있는 사전 훈련 말뭉치에 주석을 달고, 그 위에 LLMs를 미세 조정함으로써 LLMs가 API 호출 시기와 방법을 배우고 생성 중 API에 의해 반환되는 결과를 통합할 수 있다. HuggingGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib444" title="">444</a>]</cite>는 HuggingFace에서 사용 가능한 모델을 소개하고 LLMs를 컨트롤러로 간주하여 설명을 기반으로 적합한 모델을 선택하고 결과를 최종 솔루션으로 집계합니다.</p>
</div>
<div id="S6.SS4.SSS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS4.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS4.SSS2.p3.1.1">Code-based Approaches. </span> 텍스트 기반 접근법은 직관적으로 들리지만 계획의 충실한 실행을 보장할 수 없으며, 이는 계획이 건전하더라도 실패로 이어질 수 있다. 이 문제를 해결하기 위해 프로그래밍 언어인 <em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS2.p3.1.2">e.g.,</em> Python 또는 PDDL에서 실행 가능한 코드 형태로 보다 검증 가능한 계획을 생성하기 위한 코드 기반 접근법이 제안되었다. 이러한 방식으로, LLMs는 먼저 프로그램을 생성하도록 프롬프트되고, 그 후 이를 실행하기 위해 결정론적 해결기를 활용한다. 예를 들어, Faithful CoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib442" title="">442</a>]</cite>와 PAL<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib443" title="">443</a>]</cite>는 추론 작업을 두 단계로 분해한다. 첫 번째 단계에서는 LLM이 질의에 조건화된 계획을 생성하고, 두 번째 단계에서는 결정론적 풀이자가 계획을 실행하여 최종 답변을 도출한다. 또한, 코드 기반 접근법이 유사한 방식으로 구현된 에이전트에 적용될 수 있다. 예를 들어 PROGPROMPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib530" title="">530</a>]</cite>와 LLM+P <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib531" title="">531</a>]</cite>는 먼저 LLM을 활용하여 python 함수 또는 PDDL 파일 형태의 계획을 생성한 후 가상 에이전트 또는 클래식 플래너를 활용하여 코드 기반 계획에 따라 문제를 해결한다.</p>
</div>
</section>
<section id="S6.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.3 </span>Feedback Acquisition</h4>

<div id="S6.SS4.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS4.SSS3.p1.1">생성된 계획을 실행한 후, 환경은 LLM 기반 태스크 플래너에 피드백 신호를 생성하며, 이는 더 나은 결과를 위해 초기 계획을 구체화하는 데 사용될 수 있다. 기존 작업에서는 일반적으로 LLM 기반 작업 플래너와의 관계에 따라 환경으로부터의 피드백 소스에는 내부(<em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS3.p1.1.1">i.e.,</em> the LLM 자체) 및 외부(<em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS3.p1.1.2">e.g.,</em> 도구 또는 가상 세계) 피드백이 있습니다.</p>
</div>
<div id="S6.SS4.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS4.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS4.SSS3.p2.1.1">Internal Feedback. </span> LLM 자체는 피드백 제공자로 활용될 수 있다. 한 가지 간단한 방법은 프롬프트를 통해 생성된 계획의 품질을 직접 평가하는 것입니다. 예를 들어, RAP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib447" title="">447</a>]</cite>는 각 후보 계획이 과제 성공으로 이어질 수 있는 가능성을 평가하는 반면, Tree of Thoughts<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib527" title="">527</a>]</cite>는 이들 간의 비교를 통해 계획 전반에 투표할 것을 제안한다. 또한, LLMs는 계획 실행기의 중간 결과에 기초하여 피드백을 제공할 수 있다. 예를 들어, Reflexion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib450" title="">450</a>]</cite>는 LLMs를 활용하여 희소 결과 신호(<em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS3.p2.1.2">e.g.,</em> success or failure)를 구체적인 텍스트 기반 피드백(<em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS3.p2.1.3">e.g.,</em> "<em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS3.p2.1.4">e.g.,</em> "<em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS3.p2.1.4">You should recommend comedies that you mentions in the query instead the horror movies</em>”)으로 변환하고 이 피드백을 향후 계획을 위해 장기 메모리에 저장해야 한다.</p>
</div>
<div id="S6.SS4.SSS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS4.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS4.SSS3.p3.1.1">External Feedback. </span> LLM 외에도 외부 객체도 피드백 신호를 제공할 수 있다. 예를 들어, 코드 해석자와 같은 도구는 실시간 오류 메시지를 제공하기 위한 프로그래밍 작업에서 널리 사용되며, 안정적인 확산과 같은 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib532" title="">532</a>]</cite>는 시각적 인식을 제공하기 위한 멀티모달 작업에서 사용될 수 있으며, 마인크래프트와 같은 가상 세계는 몰입형 경험 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib528" title="">528</a>]</cite>를 제공할 수 있다. 또한, 일부 작업(<em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS3.p3.1.2">e.g.,</em> Generative Agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib533" title="">533</a>]</cite>)은 시뮬레이션된 환경에서 다중 에이전트 협업을 탐색하며, 여기서 각 에이전트는 환경과의 상호작용뿐만 아니라 다른 에이전트와의 통신으로부터 피드백을 받는다.</p>
</div>
</section>
<section id="S6.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.4 </span>Plan Refinement</h4>

<div id="S6.SS4.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS4.SSS4.p1.1">환경으로부터의 피드백에 대한 액세스를 통해, 태스크 플래너는 그에 따라 자신의 현재 계획을 정제하고 더 나은 결과를 위해 "<em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS4.p1.1.1">planning – execution – refinement</em>" 루프를 반복적으로 거칠 수 있다. 이 부분에서는 기존 작업에서 세 가지 주요 정제 접근법을 요약한다.</p>
</div>
<div id="S6.SS4.SSS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS4.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S6.SS4.SSS4.p2.1.1">Reasoning. </span> 환경으로부터의 피드백 데이터는 계획 개선, <em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS4.p2.1.2">e.g.,</em> 관련 없는 정보를 포함하거나 비언어 형식을 취하기 위해 LLMs에 의해 활용되기에는 직접 적합하지 않을 수 있다. 이를 해결하기 위해 일부 연구에서는 피드백 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib449" title="">449</a>, <a class="ltx_ref" href="#bib.bib448" title="">448</a>]</cite>에서 중요한 정보를 추출하기 위해 명시적 추론 과정을 추가한다. 예를 들어, React <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib449" title="">449</a>]</cite> 프롬프트 LLMs에 데모를 사용하여 피드백을 통해 추론 트레이스를 생성합니다. AutoGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib534" title="">534</a>]</cite>와 같은 자율 에이전트 프로젝트에서 널리 사용되어 왔으며, 이는 다양한 사용자 요청을 해결하기 위한 초기 계획을 수정하기 위해 관찰된 피드백을 자동으로 추론할 수 있다. 그러나 이러한 접근 방식은 일반적으로 추론과 계획의 순서를 고정합니다. 더 나은 성능을 위해 두 프로세스 간의 유연한 전환을 지원하기 위해 ChatCoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib448" title="">448</a>]</cite>는 도구 강화 추론 프로세스를 LLM 기반 태스크 플래너와 도구 기반 환경 간의 다중 전환 대화로 통합한다.</p>
</div>
<div id="S6.SS4.SSS4.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS4.SSS4.p3.1"><span class="ltx_text ltx_font_bold" id="S6.SS4.SSS4.p3.1.1">Backtracking. </span> 초기 방법은 주로 기존 계획을 유지하면서 미래 계획을 계획하는 것을 고려하므로 단기 평가를 기반으로 지역 최적 계획으로 이어질 가능성이 있다. 이를 해결하기 위해 Thoughts의 Tree <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib527" title="">527</a>]</cite>는 전역 계획을 만들기 위해 너비 우선 및 깊이 우선 검색과 같은 검색 알고리즘으로 역추적을 허용한다. 초기 계획에서 마지막 상태로 역추적하고 다음 미개척 행동을 선택하여 계획을 단계별로 구체화한다. 또한, 일부 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib535" title="">535</a>, <a class="ltx_ref" href="#bib.bib446" title="">446</a>]</cite>는 피드백 신호를 활용하여 전체 계획을 수정한다. 예를 들어, DEPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib535" title="">535</a>]</cite>는 피드백 신호에 따라 더 나은 계획을 선택하는 반면, TIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib446" title="">446</a>]</cite>는 LLM 기반 플래너가 초기 계획에서 각 단계를 수정하도록 프롬프트에 피드백 신호를 추가한다.</p>
</div>
<div id="S6.SS4.SSS4.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS4.SSS4.p4.1"><span class="ltx_text ltx_font_bold" id="S6.SS4.SSS4.p4.1.1">Memorization. </span> Long-horizon 태스크를 처리하기 위해 ICL을 통해 LLM의 <em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS4.p4.1.2">long-term memory</em>을 활용하는 것 외에도 <em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS4.p4.1.3">short-term memory</em>을 사용하여 계획 개선을 돕는 핵심 접근법이 되었습니다. 예를 들어, Reflexion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib450" title="">450</a>]</cite>는 자기 반성의 피드백을 메모리에 저장하므로, 계획 개선을 위해 이전 피드백을 검색할 수 있다. 생성 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib533" title="">533</a>]</cite>는 액션 플래닝과 반성을 위한 에이전트의 핵심 구성 요소로 메모리 스트림 메커니즘을 설계한다. 또한, 기술 라이브러리 메커니즘 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib528" title="">528</a>, <a class="ltx_ref" href="#bib.bib445" title="">445</a>]</cite>는 성공적인 계획을 라이브러리에 저장하기 위해 제안되며, 이는 새로운 작업에 대한 복잡한 계획으로 재사용되고 합성될 수 있다. 장기 기억 메커니즘을 구현하기 위해 벡터 데이터베이스(<em class="ltx_emph ltx_font_italic" id="S6.SS4.SSS4.p4.1.4">e.g.,</em> milvus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib536" title="">536</a>]</cite>)와 같은 도구는 대규모로 효율적인 저장 및 검색을 위해 계획 또는 피드백을 고차원 벡터로 인코딩하는데 사용될 수 있다. MemoryBank<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib537" title="">537</a>]</cite>는 Ebbinghaus Forgetting Curve 이론에 따라 메모리 망각과 강화를 허용하는 메모리 갱신 메커니즘을 추가로 제안한다.</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Capacity and Evaluation</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p class="ltx_p" id="S7.p1.1">LLM의 효과성과 우수성을 검토하기 위해 실증 능력 평가 및 분석을 수행하기 위한 과제와 벤치마크의 급증이 제안되었다. 이 절에서는 먼저 언어 생성 및 이해를 위한 LLM의 기본 능력 평가의 세 가지 유형을 소개하고, 더 복잡한 설정이나 목표를 가진 몇 가지 고급 능력 평가를 제시하고, 마지막으로 기존 벤치마크, 평가 접근법 및 실증 분석에 대해 논의한다.</p>
</div>
<figure id="S7.T14" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE XIV:</span>Representative basic and advanced abilities and corresponding representative datasets for evaluating.</figcaption>
<table id="S7.T14.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S7.T14.1.1" class="ltx_tr">
<td id="S7.T14.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S7.T14.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Level</span></td>
<td id="S7.T14.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S7.T14.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Ability</span></td>
<td id="S7.T14.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S7.T14.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></td>
<td id="S7.T14.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S7.T14.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Dataset</span></td>
</tr>
<tr id="S7.T14.1.2" class="ltx_tr">
<td id="S7.T14.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="25"><span id="S7.T14.1.2.1.1" class="ltx_text" style="font-size:80%;">Basic</span></td>
<td id="S7.T14.1.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="6"><span id="S7.T14.1.2.2.1" class="ltx_text" style="font-size:80%;">Language Generation</span></td>
<td id="S7.T14.1.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S7.T14.1.2.3.1" class="ltx_text" style="font-size:80%;">Language Modeling</span></td>
<td id="S7.T14.1.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.2.4.1" class="ltx_text" style="font-size:80%;">Penn Treebank&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.2.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib538" title="" class="ltx_ref">538</a><span id="S7.T14.1.2.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.2.4.4" class="ltx_text" style="font-size:80%;">, WikiText-103&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.2.4.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib539" title="" class="ltx_ref">539</a><span id="S7.T14.1.2.4.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.2.4.7" class="ltx_text" style="font-size:80%;">, the Pile&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.2.4.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib161" title="" class="ltx_ref">161</a><span id="S7.T14.1.2.4.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.2.4.10" class="ltx_text" style="font-size:80%;">, LAMBADA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.2.4.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib233" title="" class="ltx_ref">233</a><span id="S7.T14.1.2.4.12.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.3" class="ltx_tr">
<td id="S7.T14.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="3"><span id="S7.T14.1.3.1.1" class="ltx_text" style="font-size:80%;">Conditional Text Generation</span></td>
<td id="S7.T14.1.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.3.2.1" class="ltx_text" style="font-size:80%;">WMT’14,16,19,20,21,22&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.3.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib540" title="" class="ltx_ref">540</a>, <a href="#bib.bib541" title="" class="ltx_ref">541</a>, <a href="#bib.bib542" title="" class="ltx_ref">542</a>, <a href="#bib.bib543" title="" class="ltx_ref">543</a>, <a href="#bib.bib544" title="" class="ltx_ref">544</a>, <a href="#bib.bib545" title="" class="ltx_ref">545</a><span id="S7.T14.1.3.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.3.2.4" class="ltx_text" style="font-size:80%;">, Flores-101&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.3.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib546" title="" class="ltx_ref">546</a><span id="S7.T14.1.3.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.3.2.7" class="ltx_text" style="font-size:80%;">, DiaBLa&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.3.2.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib547" title="" class="ltx_ref">547</a><span id="S7.T14.1.3.2.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.3.2.10" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.4" class="ltx_tr">
<td id="S7.T14.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.4.1.1" class="ltx_text" style="font-size:80%;">CNN/DailyMail&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib548" title="" class="ltx_ref">548</a><span id="S7.T14.1.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.4.1.4" class="ltx_text" style="font-size:80%;">, XSum&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.4.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib549" title="" class="ltx_ref">549</a><span id="S7.T14.1.4.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.4.1.7" class="ltx_text" style="font-size:80%;">, WikiLingua&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.4.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib550" title="" class="ltx_ref">550</a><span id="S7.T14.1.4.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.5" class="ltx_tr">
<td id="S7.T14.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.5.1.1" class="ltx_text" style="font-size:80%;">OpenDialKG&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.5.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib551" title="" class="ltx_ref">551</a><span id="S7.T14.1.5.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.6" class="ltx_tr">
<td id="S7.T14.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="2"><span id="S7.T14.1.6.1.1" class="ltx_text" style="font-size:80%;">Code Synthesis</span></td>
<td id="S7.T14.1.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.6.2.1" class="ltx_text" style="font-size:80%;">APPS&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.6.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib378" title="" class="ltx_ref">378</a><span id="S7.T14.1.6.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.6.2.4" class="ltx_text" style="font-size:80%;">, HumanEval&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.6.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib105" title="" class="ltx_ref">105</a><span id="S7.T14.1.6.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.6.2.7" class="ltx_text" style="font-size:80%;">, MBPP&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.6.2.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib208" title="" class="ltx_ref">208</a><span id="S7.T14.1.6.2.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.6.2.10" class="ltx_text" style="font-size:80%;">, CodeContest&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.6.2.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib114" title="" class="ltx_ref">114</a><span id="S7.T14.1.6.2.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.6.2.13" class="ltx_text" style="font-size:80%;">,
MTPB&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.6.2.14.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib86" title="" class="ltx_ref">86</a><span id="S7.T14.1.6.2.15.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.6.2.16" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.7" class="ltx_tr">
<td id="S7.T14.1.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.7.1.1" class="ltx_text" style="font-size:80%;">DS-1000&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.7.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib552" title="" class="ltx_ref">552</a><span id="S7.T14.1.7.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.7.1.4" class="ltx_text" style="font-size:80%;">, ODEX&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.7.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib553" title="" class="ltx_ref">553</a><span id="S7.T14.1.7.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.8" class="ltx_tr">
<td id="S7.T14.1.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="8"><span id="S7.T14.1.8.1.1" class="ltx_text" style="font-size:80%;">Knowledge Utilization</span></td>
<td id="S7.T14.1.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="3"><span id="S7.T14.1.8.2.1" class="ltx_text" style="font-size:80%;">Closed-Book QA</span></td>
<td id="S7.T14.1.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.8.3.1" class="ltx_text" style="font-size:80%;">Natural Questions&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.8.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib554" title="" class="ltx_ref">554</a><span id="S7.T14.1.8.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.8.3.4" class="ltx_text" style="font-size:80%;">,
ARC&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.8.3.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib555" title="" class="ltx_ref">555</a><span id="S7.T14.1.8.3.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.8.3.7" class="ltx_text" style="font-size:80%;">,
TruthfulQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.8.3.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib556" title="" class="ltx_ref">556</a><span id="S7.T14.1.8.3.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.8.3.10" class="ltx_text" style="font-size:80%;">,
Web Questions&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.8.3.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib557" title="" class="ltx_ref">557</a><span id="S7.T14.1.8.3.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.8.3.13" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.9" class="ltx_tr">
<td id="S7.T14.1.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.9.1.1" class="ltx_text" style="font-size:80%;">TriviaQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.9.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib558" title="" class="ltx_ref">558</a><span id="S7.T14.1.9.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.9.1.4" class="ltx_text" style="font-size:80%;">,
PIQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.9.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib559" title="" class="ltx_ref">559</a><span id="S7.T14.1.9.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.9.1.7" class="ltx_text" style="font-size:80%;">,
LC-quad2.0&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.9.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib560" title="" class="ltx_ref">560</a><span id="S7.T14.1.9.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.9.1.10" class="ltx_text" style="font-size:80%;">,
GrailQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.9.1.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib561" title="" class="ltx_ref">561</a><span id="S7.T14.1.9.1.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.9.1.13" class="ltx_text" style="font-size:80%;">,
KQApro&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.9.1.14.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib562" title="" class="ltx_ref">562</a><span id="S7.T14.1.9.1.15.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.9.1.16" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.10" class="ltx_tr">
<td id="S7.T14.1.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.10.1.1" class="ltx_text" style="font-size:80%;">CWQ&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.10.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib563" title="" class="ltx_ref">563</a><span id="S7.T14.1.10.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.10.1.4" class="ltx_text" style="font-size:80%;">,
MKQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.10.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib564" title="" class="ltx_ref">564</a><span id="S7.T14.1.10.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.10.1.7" class="ltx_text" style="font-size:80%;">,
ScienceQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.10.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib565" title="" class="ltx_ref">565</a><span id="S7.T14.1.10.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.11" class="ltx_tr">
<td id="S7.T14.1.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="3"><span id="S7.T14.1.11.1.1" class="ltx_text" style="font-size:80%;">Open-Book QA</span></td>
<td id="S7.T14.1.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.11.2.1" class="ltx_text" style="font-size:80%;">Natural Questions&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.11.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib554" title="" class="ltx_ref">554</a><span id="S7.T14.1.11.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.11.2.4" class="ltx_text" style="font-size:80%;">,
OpenBookQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.11.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib566" title="" class="ltx_ref">566</a><span id="S7.T14.1.11.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.11.2.7" class="ltx_text" style="font-size:80%;">,
ARC&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.11.2.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib555" title="" class="ltx_ref">555</a><span id="S7.T14.1.11.2.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.11.2.10" class="ltx_text" style="font-size:80%;">,
TriviaQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.11.2.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib558" title="" class="ltx_ref">558</a><span id="S7.T14.1.11.2.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.11.2.13" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.12" class="ltx_tr">
<td id="S7.T14.1.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.12.1.1" class="ltx_text" style="font-size:80%;">Web Questions&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.12.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib557" title="" class="ltx_ref">557</a><span id="S7.T14.1.12.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.12.1.4" class="ltx_text" style="font-size:80%;">,
MS MARCO&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.12.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib567" title="" class="ltx_ref">567</a><span id="S7.T14.1.12.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.12.1.7" class="ltx_text" style="font-size:80%;">,
QASC&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.12.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib568" title="" class="ltx_ref">568</a><span id="S7.T14.1.12.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.12.1.10" class="ltx_text" style="font-size:80%;">,
SQuAD&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.12.1.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib569" title="" class="ltx_ref">569</a><span id="S7.T14.1.12.1.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.12.1.13" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.13" class="ltx_tr">
<td id="S7.T14.1.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.13.1.1" class="ltx_text" style="font-size:80%;">WikiMovies&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.13.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib570" title="" class="ltx_ref">570</a><span id="S7.T14.1.13.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.14" class="ltx_tr">
<td id="S7.T14.1.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="2"><span id="S7.T14.1.14.1.1" class="ltx_text" style="font-size:80%;">Knowledge Completion</span></td>
<td id="S7.T14.1.14.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.14.2.1" class="ltx_text" style="font-size:80%;">WikiFact&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.14.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib571" title="" class="ltx_ref">571</a><span id="S7.T14.1.14.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.14.2.4" class="ltx_text" style="font-size:80%;">,
FB15k-237&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.14.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib572" title="" class="ltx_ref">572</a><span id="S7.T14.1.14.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.14.2.7" class="ltx_text" style="font-size:80%;">,
Freebase&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.14.2.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib573" title="" class="ltx_ref">573</a><span id="S7.T14.1.14.2.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.14.2.10" class="ltx_text" style="font-size:80%;">,
WN18RR&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.14.2.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib574" title="" class="ltx_ref">574</a><span id="S7.T14.1.14.2.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.14.2.13" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.15" class="ltx_tr">
<td id="S7.T14.1.15.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.15.1.1" class="ltx_text" style="font-size:80%;">WordNet&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.15.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib575" title="" class="ltx_ref">575</a><span id="S7.T14.1.15.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.15.1.4" class="ltx_text" style="font-size:80%;">,
LAMA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.15.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib576" title="" class="ltx_ref">576</a><span id="S7.T14.1.15.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.15.1.7" class="ltx_text" style="font-size:80%;">,
YAGO3-10&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.15.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib577" title="" class="ltx_ref">577</a><span id="S7.T14.1.15.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.15.1.10" class="ltx_text" style="font-size:80%;">,
YAGO&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.15.1.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib578" title="" class="ltx_ref">578</a><span id="S7.T14.1.15.1.12.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.16" class="ltx_tr">
<td id="S7.T14.1.16.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="11"><span id="S7.T14.1.16.1.1" class="ltx_text" style="font-size:80%;">Complex Reasoning</span></td>
<td id="S7.T14.1.16.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="4"><span id="S7.T14.1.16.2.1" class="ltx_text" style="font-size:80%;">Knowledge Reasoning</span></td>
<td id="S7.T14.1.16.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.16.3.1" class="ltx_text" style="font-size:80%;">CSQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.16.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib504" title="" class="ltx_ref">504</a><span id="S7.T14.1.16.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.16.3.4" class="ltx_text" style="font-size:80%;">, StrategyQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.16.3.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib185" title="" class="ltx_ref">185</a><span id="S7.T14.1.16.3.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.16.3.7" class="ltx_text" style="font-size:80%;">, HotpotQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.16.3.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib579" title="" class="ltx_ref">579</a><span id="S7.T14.1.16.3.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.16.3.10" class="ltx_text" style="font-size:80%;">, ARC&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.16.3.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib555" title="" class="ltx_ref">555</a><span id="S7.T14.1.16.3.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.16.3.13" class="ltx_text" style="font-size:80%;">, BoolQ&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.16.3.14.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib580" title="" class="ltx_ref">580</a><span id="S7.T14.1.16.3.15.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.16.3.16" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.17" class="ltx_tr">
<td id="S7.T14.1.17.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.17.1.1" class="ltx_text" style="font-size:80%;">PIQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.17.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib559" title="" class="ltx_ref">559</a><span id="S7.T14.1.17.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.17.1.4" class="ltx_text" style="font-size:80%;">,
SIQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.17.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib581" title="" class="ltx_ref">581</a><span id="S7.T14.1.17.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.17.1.7" class="ltx_text" style="font-size:80%;">, HellaSwag&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.17.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib582" title="" class="ltx_ref">582</a><span id="S7.T14.1.17.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.17.1.10" class="ltx_text" style="font-size:80%;">, WinoGrande&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.17.1.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib583" title="" class="ltx_ref">583</a><span id="S7.T14.1.17.1.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.17.1.13" class="ltx_text" style="font-size:80%;">,
COPA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.17.1.14.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib584" title="" class="ltx_ref">584</a><span id="S7.T14.1.17.1.15.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.17.1.16" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.18" class="ltx_tr">
<td id="S7.T14.1.18.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.18.1.1" class="ltx_text" style="font-size:80%;">OpenBookQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.18.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib566" title="" class="ltx_ref">566</a><span id="S7.T14.1.18.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.18.1.4" class="ltx_text" style="font-size:80%;">,
ScienceQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.18.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib565" title="" class="ltx_ref">565</a><span id="S7.T14.1.18.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.18.1.7" class="ltx_text" style="font-size:80%;">, proScript&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.18.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib585" title="" class="ltx_ref">585</a><span id="S7.T14.1.18.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.18.1.10" class="ltx_text" style="font-size:80%;">, ProPara&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.18.1.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib586" title="" class="ltx_ref">586</a><span id="S7.T14.1.18.1.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.18.1.13" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.19" class="ltx_tr">
<td id="S7.T14.1.19.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.19.1.1" class="ltx_text" style="font-size:80%;">ExplaGraphs&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.19.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib587" title="" class="ltx_ref">587</a><span id="S7.T14.1.19.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.19.1.4" class="ltx_text" style="font-size:80%;">,
ProofWriter&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.19.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib588" title="" class="ltx_ref">588</a><span id="S7.T14.1.19.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.19.1.7" class="ltx_text" style="font-size:80%;">, EntailmentBank&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.19.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib589" title="" class="ltx_ref">589</a><span id="S7.T14.1.19.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.19.1.10" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.20" class="ltx_tr">
<td id="S7.T14.1.20.1" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:0.0pt;padding-right:0.0pt;"></td>
<td id="S7.T14.1.20.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.20.2.1" class="ltx_text" style="font-size:80%;">ProOntoQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.20.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib590" title="" class="ltx_ref">590</a><span id="S7.T14.1.20.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.21" class="ltx_tr">
<td id="S7.T14.1.21.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="3"><span id="S7.T14.1.21.1.1" class="ltx_text" style="font-size:80%;">Symbolic Reasoning</span></td>
<td id="S7.T14.1.21.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.21.2.1" class="ltx_text" style="font-size:80%;">CoinFlip&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.21.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib33" title="" class="ltx_ref">33</a><span id="S7.T14.1.21.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.21.2.4" class="ltx_text" style="font-size:80%;">, ReverseList&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.21.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib33" title="" class="ltx_ref">33</a><span id="S7.T14.1.21.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.21.2.7" class="ltx_text" style="font-size:80%;">, LastLetter&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.21.2.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib33" title="" class="ltx_ref">33</a><span id="S7.T14.1.21.2.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.21.2.10" class="ltx_text" style="font-size:80%;">, Boolean Assignment&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.21.2.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib591" title="" class="ltx_ref">591</a><span id="S7.T14.1.21.2.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.21.2.13" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.22" class="ltx_tr">
<td id="S7.T14.1.22.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.22.1.1" class="ltx_text" style="font-size:80%;">Parity&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.22.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib591" title="" class="ltx_ref">591</a><span id="S7.T14.1.22.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.22.1.4" class="ltx_text" style="font-size:80%;">, Colored Object&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.22.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib70" title="" class="ltx_ref">70</a><span id="S7.T14.1.22.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.22.1.7" class="ltx_text" style="font-size:80%;">, Penguins in a Table&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.22.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib70" title="" class="ltx_ref">70</a><span id="S7.T14.1.22.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.22.1.10" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.23" class="ltx_tr">
<td id="S7.T14.1.23.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.23.1.1" class="ltx_text" style="font-size:80%;">Repeat Copy&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.23.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib443" title="" class="ltx_ref">443</a><span id="S7.T14.1.23.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.23.1.4" class="ltx_text" style="font-size:80%;">, Object Counting&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.23.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib443" title="" class="ltx_ref">443</a><span id="S7.T14.1.23.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.24" class="ltx_tr">
<td id="S7.T14.1.24.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="3"><span id="S7.T14.1.24.1.1" class="ltx_text" style="font-size:80%;">Mathematical Reasoning</span></td>
<td id="S7.T14.1.24.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.24.2.1" class="ltx_text" style="font-size:80%;">MATH&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.24.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib364" title="" class="ltx_ref">364</a><span id="S7.T14.1.24.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.24.2.4" class="ltx_text" style="font-size:80%;">, GSM8k&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.24.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib184" title="" class="ltx_ref">184</a><span id="S7.T14.1.24.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.24.2.7" class="ltx_text" style="font-size:80%;">, SVAMP&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.24.2.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib592" title="" class="ltx_ref">592</a><span id="S7.T14.1.24.2.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.24.2.10" class="ltx_text" style="font-size:80%;">, MultiArith&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.24.2.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib593" title="" class="ltx_ref">593</a><span id="S7.T14.1.24.2.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.24.2.13" class="ltx_text" style="font-size:80%;">, ASDiv&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.24.2.14.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib503" title="" class="ltx_ref">503</a><span id="S7.T14.1.24.2.15.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.24.2.16" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.25" class="ltx_tr">
<td id="S7.T14.1.25.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.25.1.1" class="ltx_text" style="font-size:80%;">MathQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.25.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib594" title="" class="ltx_ref">594</a><span id="S7.T14.1.25.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.25.1.4" class="ltx_text" style="font-size:80%;">,
AQUA-RAT&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.25.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib595" title="" class="ltx_ref">595</a><span id="S7.T14.1.25.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.25.1.7" class="ltx_text" style="font-size:80%;">, MAWPS&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.25.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib596" title="" class="ltx_ref">596</a><span id="S7.T14.1.25.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.25.1.10" class="ltx_text" style="font-size:80%;">, DROP&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.25.1.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib597" title="" class="ltx_ref">597</a><span id="S7.T14.1.25.1.12.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.25.1.13" class="ltx_text" style="font-size:80%;">,</span>
</td>
</tr>
<tr id="S7.T14.1.26" class="ltx_tr">
<td id="S7.T14.1.26.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.26.1.1" class="ltx_text" style="font-size:80%;">NaturalProofs&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.26.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib598" title="" class="ltx_ref">598</a><span id="S7.T14.1.26.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.26.1.4" class="ltx_text" style="font-size:80%;">,
PISA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.26.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib599" title="" class="ltx_ref">599</a><span id="S7.T14.1.26.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.26.1.7" class="ltx_text" style="font-size:80%;">,
miniF2F&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.26.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib600" title="" class="ltx_ref">600</a><span id="S7.T14.1.26.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.26.1.10" class="ltx_text" style="font-size:80%;">, ProofNet&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.26.1.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib601" title="" class="ltx_ref">601</a><span id="S7.T14.1.26.1.12.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.27" class="ltx_tr">
<td id="S7.T14.1.27.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="18"><span id="S7.T14.1.27.1.1" class="ltx_text" style="font-size:80%;">Advanced</span></td>
<td id="S7.T14.1.27.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="4"><span id="S7.T14.1.27.2.1" class="ltx_text" style="font-size:80%;">Human Alignment</span></td>
<td id="S7.T14.1.27.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S7.T14.1.27.3.1" class="ltx_text" style="font-size:80%;">Honestness</span></td>
<td id="S7.T14.1.27.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.27.4.1" class="ltx_text" style="font-size:80%;">TruthfulQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.27.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib556" title="" class="ltx_ref">556</a><span id="S7.T14.1.27.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.27.4.4" class="ltx_text" style="font-size:80%;">, HaluEval&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.27.4.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib602" title="" class="ltx_ref">602</a><span id="S7.T14.1.27.4.6.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.28" class="ltx_tr">
<td id="S7.T14.1.28.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S7.T14.1.28.1.1" class="ltx_text" style="font-size:80%;">Helpfulness</span></td>
<td id="S7.T14.1.28.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.28.2.1" class="ltx_text" style="font-size:80%;">HH-RLHF&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.28.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib170" title="" class="ltx_ref">170</a><span id="S7.T14.1.28.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.29" class="ltx_tr">
<td id="S7.T14.1.29.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="2"><span id="S7.T14.1.29.1.1" class="ltx_text" style="font-size:80%;">Harmlessness</span></td>
<td id="S7.T14.1.29.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.29.2.1" class="ltx_text" style="font-size:80%;">HH-RLHF&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.29.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib170" title="" class="ltx_ref">170</a><span id="S7.T14.1.29.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.29.2.4" class="ltx_text" style="font-size:80%;">, Crows-Pairs&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.29.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib603" title="" class="ltx_ref">603</a><span id="S7.T14.1.29.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.30" class="ltx_tr">
<td id="S7.T14.1.30.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.30.1.1" class="ltx_text" style="font-size:80%;">WinoGender&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.30.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib604" title="" class="ltx_ref">604</a><span id="S7.T14.1.30.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.30.1.4" class="ltx_text" style="font-size:80%;">, RealToxicityPrompts&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.30.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib605" title="" class="ltx_ref">605</a><span id="S7.T14.1.30.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.31" class="ltx_tr">
<td id="S7.T14.1.31.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="3"><span id="S7.T14.1.31.1.1" class="ltx_text" style="font-size:80%;"><span id="S7.T14.1.31.1.1.1" class="ltx_text"></span> <span id="S7.T14.1.31.1.1.2" class="ltx_text">
<span id="S7.T14.1.31.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T14.1.31.1.1.2.1.1" class="ltx_tr">
<span id="S7.T14.1.31.1.1.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">Interaction with</span></span>
<span id="S7.T14.1.31.1.1.2.1.2" class="ltx_tr">
<span id="S7.T14.1.31.1.1.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">External Environment</span></span>
</span></span> <span id="S7.T14.1.31.1.1.3" class="ltx_text"></span></span></td>
<td id="S7.T14.1.31.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.31.2.1" class="ltx_text" style="font-size:80%;">H</span><span id="S7.T14.1.31.2.2" class="ltx_text" style="font-size:80%;">ousehold</span>
</td>
<td id="S7.T14.1.31.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.31.3.1" class="ltx_text" style="font-size:80%;">VirtualHome&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.31.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib606" title="" class="ltx_ref">606</a><span id="S7.T14.1.31.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.31.3.4" class="ltx_text" style="font-size:80%;">, BEHAVIOR&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.31.3.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib607" title="" class="ltx_ref">607</a><span id="S7.T14.1.31.3.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.31.3.7" class="ltx_text" style="font-size:80%;">, ALFRED&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.31.3.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib608" title="" class="ltx_ref">608</a><span id="S7.T14.1.31.3.9.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.31.3.10" class="ltx_text" style="font-size:80%;">,ALFWorld&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.31.3.11.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib609" title="" class="ltx_ref">609</a><span id="S7.T14.1.31.3.12.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.32" class="ltx_tr">
<td id="S7.T14.1.32.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.32.1.1" class="ltx_text" style="font-size:80%;">W</span><span id="S7.T14.1.32.1.2" class="ltx_text" style="font-size:80%;">ebsite Environment</span>
</td>
<td id="S7.T14.1.32.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.32.2.1" class="ltx_text" style="font-size:80%;">WebShop&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.32.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib610" title="" class="ltx_ref">610</a><span id="S7.T14.1.32.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.32.2.4" class="ltx_text" style="font-size:80%;">, Mind2Web&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.32.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib611" title="" class="ltx_ref">611</a><span id="S7.T14.1.32.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.33" class="ltx_tr">
<td id="S7.T14.1.33.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.33.1.1" class="ltx_text" style="font-size:80%;">O</span><span id="S7.T14.1.33.1.2" class="ltx_text" style="font-size:80%;">pen World</span>
</td>
<td id="S7.T14.1.33.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.33.2.1" class="ltx_text" style="font-size:80%;">MineRL&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.33.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib612" title="" class="ltx_ref">612</a><span id="S7.T14.1.33.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.33.2.4" class="ltx_text" style="font-size:80%;">, MineDojo&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.33.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib613" title="" class="ltx_ref">613</a><span id="S7.T14.1.33.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.34" class="ltx_tr">
<td id="S7.T14.1.34.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="8"><span id="S7.T14.1.34.1.1" class="ltx_text" style="font-size:80%;">Tool Manipulation</span></td>
<td id="S7.T14.1.34.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.34.2.1" class="ltx_text" style="font-size:80%;">S</span><span id="S7.T14.1.34.2.2" class="ltx_text" style="font-size:80%;">earch Engine</span>
</td>
<td id="S7.T14.1.34.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.34.3.1" class="ltx_text" style="font-size:80%;">HotpotQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.34.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib579" title="" class="ltx_ref">579</a><span id="S7.T14.1.34.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.34.3.4" class="ltx_text" style="font-size:80%;">, TriviaQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.34.3.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib558" title="" class="ltx_ref">558</a><span id="S7.T14.1.34.3.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.34.3.7" class="ltx_text" style="font-size:80%;">, Natural Questions&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.34.3.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib554" title="" class="ltx_ref">554</a><span id="S7.T14.1.34.3.9.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.35" class="ltx_tr">
<td id="S7.T14.1.35.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.35.1.1" class="ltx_text" style="font-size:80%;">C</span><span id="S7.T14.1.35.1.2" class="ltx_text" style="font-size:80%;">ode Executor</span>
</td>
<td id="S7.T14.1.35.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.35.2.1" class="ltx_text" style="font-size:80%;">GSM8k&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.35.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib184" title="" class="ltx_ref">184</a><span id="S7.T14.1.35.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.35.2.4" class="ltx_text" style="font-size:80%;">, TabMWP&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.35.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib614" title="" class="ltx_ref">614</a><span id="S7.T14.1.35.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.35.2.7" class="ltx_text" style="font-size:80%;">, Date Understanding&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.35.2.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib70" title="" class="ltx_ref">70</a><span id="S7.T14.1.35.2.9.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.36" class="ltx_tr">
<td id="S7.T14.1.36.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.36.1.1" class="ltx_text" style="font-size:80%;">C</span><span id="S7.T14.1.36.1.2" class="ltx_text" style="font-size:80%;">alculator</span>
</td>
<td id="S7.T14.1.36.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.36.2.1" class="ltx_text" style="font-size:80%;">GSM8k&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.36.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib184" title="" class="ltx_ref">184</a><span id="S7.T14.1.36.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.36.2.4" class="ltx_text" style="font-size:80%;">, MATH&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.36.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib364" title="" class="ltx_ref">364</a><span id="S7.T14.1.36.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.36.2.7" class="ltx_text" style="font-size:80%;">, CARP&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.36.2.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib615" title="" class="ltx_ref">615</a><span id="S7.T14.1.36.2.9.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.37" class="ltx_tr">
<td id="S7.T14.1.37.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.37.1.1" class="ltx_text" style="font-size:80%;">M</span><span id="S7.T14.1.37.1.2" class="ltx_text" style="font-size:80%;">odel Interface</span>
</td>
<td id="S7.T14.1.37.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.37.2.1" class="ltx_text" style="font-size:80%;">GPT4Tools&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.37.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib616" title="" class="ltx_ref">616</a><span id="S7.T14.1.37.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.37.2.4" class="ltx_text" style="font-size:80%;">, Gorilla&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.37.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib617" title="" class="ltx_ref">617</a><span id="S7.T14.1.37.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.38" class="ltx_tr">
<td id="S7.T14.1.38.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;" rowspan="2"><span id="S7.T14.1.38.1.1" class="ltx_text" style="font-size:80%;">Data Interface</span></td>
<td id="S7.T14.1.38.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.38.2.1" class="ltx_text" style="font-size:80%;">WebQSP&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.38.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib618" title="" class="ltx_ref">618</a><span id="S7.T14.1.38.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.38.2.4" class="ltx_text" style="font-size:80%;">, MetaQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.38.2.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib619" title="" class="ltx_ref">619</a><span id="S7.T14.1.38.2.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.38.2.7" class="ltx_text" style="font-size:80%;">, WTQ&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.38.2.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib620" title="" class="ltx_ref">620</a><span id="S7.T14.1.38.2.9.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
<tr id="S7.T14.1.39" class="ltx_tr">
<td id="S7.T14.1.39.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;">
<span id="S7.T14.1.39.1.1" class="ltx_text" style="font-size:80%;">WikiSQL&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.39.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib621" title="" class="ltx_ref">621</a><span id="S7.T14.1.39.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.39.1.4" class="ltx_text" style="font-size:80%;">, TabFact&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.39.1.5.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib622" title="" class="ltx_ref">622</a><span id="S7.T14.1.39.1.6.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S7.T14.1.39.1.7" class="ltx_text" style="font-size:80%;">, Spider&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T14.1.39.1.8.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib623" title="" class="ltx_ref">623</a><span id="S7.T14.1.39.1.9.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
</tr>
</tbody></table>
</figure>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span><span id="S7.SS1.1.1" class="ltx_text ltx_font_italic">Basic Ability</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS1.p1.1">이 부분에서는 LLMs에 대한 능력 평가의 세 가지 기본 유형인 <em class="ltx_emph ltx_font_italic" id="S7.SS1.p1.1.1">i.e.,</em> 언어 생성, 지식 활용 및 복합 추론에 중점을 둔다. 우리는 모든 관련 작업에 대한 완전한 보장을 의도하지 않고 대신 LLM에 대해 가장 널리 논의되거나 연구된 작업에만 초점을 맞춘다는 점에 주목한다. 다음으로, 이러한 작업들에 대해 상세히 소개한다.</p>
</div>
<section id="S7.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.1.1 </span>Language Generation</h4>

<div id="S7.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS1.SSS1.p1.1">과제 정의에 따르면 언어 생성에 관한 기존의 과제는 언어 모델링, 조건부 텍스트 생성, 코드 합성 작업으로 대별될 수 있다. 코드 합성은 전형적인 NLP 작업이 아니라는 점에 유의하여, 자연 언어 텍스트와 유사한 생성 접근법에서 다수의 LLM(코드 데이터에 대해 트레이닝됨)에 의해 직접 해결될 수 있기 때문에 논의를 위해 이를 포함한다.</p>
</div>
<div id="S7.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS1.p2.1.1">Language Modeling. </span> LLMs의 가장 기본적인 능력으로 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p2.1.2">language modeling</em>은 기본 언어 이해 및 생성 능력에 주로 초점을 맞춘 이전 토큰들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite>를 기반으로 다음 토큰을 예측하는 것을 목표로 한다. 이러한 능력을 평가하기 위해 기존 작업이 사용하는 대표적인 언어 모델링 데이터 세트에는 Penn Treebank <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib538" title="">538</a>]</cite>, WikiText-103 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib539" title="">539</a>]</cite>, Pile <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib161" title="">161</a>]</cite>가 있으며, 여기서 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p2.1.3">perplexity</em>의 메트릭은 제로샷 설정 하에서 모델 성능을 평가하는 데 일반적으로 사용된다. 경험적 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>는 LLMs가 이러한 평가 데이터 세트에 대해 이전의 최첨단 방법에 비해 상당한 성능 향상을 가져온다는 것을 보여준다. 텍스트에서 장거리 의존성의 모델링 용량을 더 잘 테스트하기 위해 LAMBADA 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib233" title="">233</a>]</cite>가 도입되었으며, 여기서 LLM은 문맥 문단을 기반으로 문장의 마지막 단어를 예측하는 데 필요하다. 그런 다음, 예측된 마지막 단어의 정확도와 복잡도를 사용하여 LLM을 평가한다. 언어 모델링 작업의 성능은 기존 작업에서 볼 수 있듯이 일반적으로 스케일링 법칙 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>를 따르며, 이는 스케일링 언어 모델이 정확도를 향상시키고 복잡도를 감소시킨다는 것을 의미한다.</p>
</div>
<div id="S7.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS1.p3.1.1">Conditional Text Generation. </span> 언어 생성의 중요한 주제로서 조건부 텍스트 생성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib48" title="">48</a>]</cite>는 주어진 조건을 기반으로 특정 작업 요구를 충족하는 텍스트를 생성하는 데 초점을 맞추고 있는데, 대표적으로 기계 번역 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib624" title="">624</a>]</cite>, 텍스트 요약 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib548" title="">548</a>]</cite>, 질의 응답 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib557" title="">557</a>]</cite>를 포함한다. 생성된 텍스트의 품질을 측정하기 위해 자동 메트릭(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p3.1.2">e.g.,</em> Accuracy, BLEU<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib625" title="">625</a>]</cite> and ROUGE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib626" title="">626</a>]</cite>) 및 인간 등급이 일반적으로 성능을 평가하는 데 사용되었다. 강력한 언어 생성 능력으로 인해 LLM은 기존 데이터 세트와 벤치마크에서 놀라운 성능을 달성했다. 예를 들어, GPT-4는 상당한 언어적 거리를 가진 언어의 번역 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib627" title="">627</a>]</cite>에서도 상용 번역 제품과 유사한 성능을 보인다. 뉴스 요약 작업 (<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p3.1.3">i.e.,</em> CNN/DM and XSUM)에서 LLM은 인간 프리랜서 작성자 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib628" title="">628</a>]</cite>]와 유사한 성능을 보여줍니다. 모델 용량의 급속한 발전에도 불구하고 조건부 텍스트 생성 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib628" title="">628</a>, <a class="ltx_ref" href="#bib.bib629" title="">629</a>, <a class="ltx_ref" href="#bib.bib630" title="">630</a>]</cite>에서 LLM의 성능을 충실히 평가하기 위한 기존 자동 메트릭의 타당성에 대한 우려가 증가하고 있다. 자동 메트릭에 대한 대안으로 최근 연구에서는 생성된 콘텐츠의 품질을 조사하기 위해 LLMs을 생성 평가자로 통합할 것을 제안한다. 더욱이, 연구자들은 또한 구조화된 데이터 생성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib458" title="">458</a>]</cite> 및 긴 텍스트 생성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib633" title="">633</a>, <a class="ltx_ref" href="#bib.bib46" title="">46</a>, <a class="ltx_ref" href="#bib.bib634" title="">634</a>]</cite>와 같이 LLMs에 대한 보다 도전적인 언어 생성 작업을 탐구한다.</p>
</div>
<div id="S7.SS1.SSS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS1.p4.1.1">Code Synthesis. <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p4.1.2">i.e.,</em> code="<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p4.1.3">code synthesis</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib635" title="">635</a>]</cite>라고 하는 특정 조건을 만족하는 컴퓨터 프로그램(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p4.1.3">code synthesis</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib635" title="">635</a>]</cite>)도 고급 자연어 텍스트를 생성할 수 있는 강력한 능력을 보여준다. 자연어 생성과 달리, 생성된 코드가 대응하는 컴파일러 또는 인터프리터로 실행에 의해 직접 체크될 수 있기 때문에, 기존의 작업은 대부분 테스트 케이스, <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p4.1.4">i.e.,</em> pass@<math alttext="k" class="ltx_Math" display="inline" id="S7.SS1.SSS1.p4.1.m1.1"><semantics id="S7.SS1.SSS1.p4.1.m1.1a"><mi id="S7.SS1.SSS1.p4.1.m1.1.1" xref="S7.SS1.SSS1.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p4.1.m1.1b"><ci id="S7.SS1.SSS1.p4.1.m1.1.1.cmml" xref="S7.SS1.SSS1.p4.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p4.1.m1.1c">k</annotation></semantics></math><span class="ltx_note ltx_role_footnote" id="footnote44"><sup class="ltx_note_mark">44</sup><span class="ltx_note_outer"><span class="ltx_note_content">44</sup><span class="ltx_note_mark">44</sup><span class="ltx_tag ltx_tag_note">44</span><span class="ltx_note_mark">44</span><span class="ltx_tag ltx_tag_note">44</span>LLM에 의해 생성된 <math alttext="k" class="ltx_Math" display="inline" id="footnote44.m1.1"><semantics id="footnote44.m1.1b"><mi id="footnote44.m1.1.1" xref="footnote44.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="footnote44.m1.1c"><ci id="footnote44.m1.1.1.cmml" xref="footnote44.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote44.m1.1d">k</annotation></semantics></math> 프로그램, pass@<math 최근 APPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib378" title="">378</a>]</cite>, HumanEval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite>, MBPP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib208" title="">208</a>]</cite>와 같이 LLM의 코드 합성 능력을 평가하기 위해 기능적 정확성에 초점을 맞춘 여러 코드 벤치마크들이 제안되고 있다. 전형적인 프로그래밍 문제는 텍스트 명세 및 정답 검사를 위한 테스트 케이스 등 다양한 프로그래밍 문제로 구성된다. 이러한 능력을 향상시키기 위해서는 코드 데이터에 LLM을 미세 조정(또는 사전 훈련)하는 것이 핵심이며, 이는 LLM을 코드 합성 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>에 효과적으로 적응시킬 수 있다. 또한, 기존 연구에서는 코드를 생성하기 위한 새로운 전략인 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p4.1.5">e.g.,</em> sampling multiple candidate solutions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib208" title="">208</a>]</cite> and planning-guided decoding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib636" title="">636</a>]</cite>를 제안하였는데, 이는 프로그래머에 의한 버그 수정 및 코드 플래닝 프로세스의 모방으로 간주될 수 있다. 인상적으로 LLMs은 최근 프로그래밍 콘테스트 플랫폼 Codeforces<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib114" title="">114</a>]</cite>에서 사용자 중 상위 28%의 순위를 달성하여 인간과 경쟁적인 성능을 보이고 있다. 또한, Python, JavaScript 및 Java를 포함한 다양한 언어를 지원할 수 있는 IDE(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p4.1.6">e.g.,</em> Visual Studio 및 JetBrains IDE)를 코딩할 때 프로그래밍을 지원하기 위해 GitHub Copilot이 출시되었습니다. "<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p4.1.7">The End of Programming</em>" <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib637" title="">637</a>]</cite> in Communications of the ACM은 컴퓨터 과학 분야에서 AI 프로그래밍의 영향을 논의했으며, 새로운 원자 단위의 계산으로서 고도로 적응적인 LLM으로의 중요한 이동을 강조했습니다.</p>
</div>
<div id="S7.SS1.SSS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS1.p5.1.1">Major Issues. </span> LLM은 인간과 같은 텍스트를 생성하는데 있어 훌륭한 성능을 달성했지만, 아래에서 논의되는 바와 같이 언어 생성에서 두 가지 주요 문제로 고통받기 쉽다.</p>
</div>
<div id="S7.SS1.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S7.SS1.SSS1.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.SSS1.p6.1.m1.1"><semantics id="S7.SS1.SSS1.p6.1.m1.1a"><mo id="S7.SS1.SSS1.p6.1.m1.1.1" xref="S7.SS1.SSS1.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p6.1.m1.1b"><ci id="S7.SS1.SSS1.p6.1.m1.1.1.cmml" xref="S7.SS1.SSS1.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p6.1.1">Unreliable generation evaluation. </em>  LLMs의 언어 생성 능력이 향상됨에 따라 기존 연구에서는 LLMs에서 생성된 텍스트가 다양한 텍스트 생성 작업에서 참조 텍스트와 유사한 품질에 도달했음을 발견했다. 그러나 기존 평가 벤치마크의 본질적인 약점으로 인해 인간 평가와 자동 참조 기반 메트릭 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib628" title="">628</a>, <a class="ltx_ref" href="#bib.bib629" title="">629</a>, <a class="ltx_ref" href="#bib.bib630" title="">630</a>, <a class="ltx_ref" href="#bib.bib638" title="">638</a>]</cite> 사이에 뚜렷한 불일치가 존재한다. 예를 들어 OpenDialKG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib551" title="">551</a>]</cite>에서 ChatGPT는 BLEU 및 ROUGE-L 메트릭에 대해 미세 조정된 GPT-2를 수행하지 않는 반면 인간 판단에서 더 많은 호감을 얻습니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib638" title="">638</a>]</cite>. 게다가, 기존의 연구는 인간의 평가조차도 충분히 견고하지 않을 수 있다고 주장한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib629" title="">629</a>, <a class="ltx_ref" href="#bib.bib628" title="">628</a>, <a class="ltx_ref" href="#bib.bib639" title="">639</a>, <a class="ltx_ref" href="#bib.bib640" title="">640</a>]</cite> 인간 주석자 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib629" title="">629</a>]</cite> 사이에 높은 수준의 합의를 이루기가 어려운 경우도 있고, 크라우드 워커의 주석 품질과 전문가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib640" title="">640</a>, <a class="ltx_ref" href="#bib.bib639" title="">639</a>]</cite> 사이에도 큰 격차가 존재한다. 따라서 LLMs 시대의 언어 생성 작업에 대해 신뢰할 수 있는 평가를 수행하는 방법은 근본적이면서도 도전적인 연구 주제가 되었다. 최근에는 생성된 텍스트에 대한 평가 품질을 향상시키기 위해 LLMs를 활용하는 연구가 증가하고 있다. 특히 LLMs은 기존 메트릭의 평가 품질을 향상시키는데 사용될 수 있다. 예를 들어, Para-Ref <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib641" title="">641</a>]</cite>는 LLM을 활용하여 기존 참조를 다양한 표현식을 가진 의미적으로 동등한 참조로 패러프레이징함으로써 다양한 자동 메트릭을 증강한다. 또한, LLMs은 단일 예측 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib631" title="">631</a>, <a class="ltx_ref" href="#bib.bib632" title="">632</a>, <a class="ltx_ref" href="#bib.bib642" title="">642</a>]</cite>를 평가하거나 여러 후보 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib643" title="">643</a>, <a class="ltx_ref" href="#bib.bib644" title="">644</a>, <a class="ltx_ref" href="#bib.bib138" title="">138</a>, <a class="ltx_ref" href="#bib.bib645" title="">645</a>]</cite>를 비교하는 것을 포함하여 참조 없는 방식으로 텍스트 생성의 평가자로 널리 사용된다. 그럼에도 불구하고, LLMs는 언어 생성 평가자로서 편향(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p6.1.2">e.g.,</em> order bias or preference for LLM-generated texts over human-written texts)을 노출시킬 수 있으며, 이는 인간 평가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib646" title="">646</a>, <a class="ltx_ref" href="#bib.bib632" title="">632</a>, <a class="ltx_ref" href="#bib.bib647" title="">647</a>]</cite>와 비교할 때 불균형을 보여준다.</p>
</div>
<div id="S7.SS1.SSS1.1.p1" class="ltx_para ltx_noindent ltx_align_center">
<svg id="S7.SS1.SSS1.1.p1.pic1" class="ltx_picture" height="239.27" overflow="visible" version="1.1" width="276"><g transform="translate(0,239.27) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00008C" fill-opacity="1.0"><path d="M 0 5.91 L 0 233.36 C 0 236.62 2.64 239.27 5.91 239.27 L 270.1 239.27 C 273.36 239.27 276 236.62 276 233.36 L 276 5.91 C 276 2.64 273.36 0 270.1 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 217.85 L 274.04 217.85 L 274.04 5.91 C 274.04 3.73 272.27 1.97 270.1 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 223.75)"><foreignObject width="232.7" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S7.SS1.SSS1.1.p1.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS1.1.p1.pic1.1.1.1.1.1.1" class="ltx_p">Unreliable Generation Evaluation</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="232.7" height="192.26" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S7.SS1.SSS1.1.p1.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS1.1.p1.pic1.2.2.2.1.1.1" class="ltx_p">LLMs have been capable of generating texts with a comparable quality to human-written texts, which however might be underestimated by automatic reference-based metrics. As an alternative evaluation approach,
LLMs can serve as language generation evaluators to evaluate a single text, compare multiple candidates, and improve existing metrics. However, this evaluation approach still needs more inspections and examinations in real-world tasks.</span>
</span></foreignObject></g></g></svg>
</div>
<div id="S7.SS1.SSS1.p7" class="ltx_para">
<p class="ltx_p" id="S7.SS1.SSS1.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.SSS1.p7.1.m1.1"><semantics id="S7.SS1.SSS1.p7.1.m1.1a"><mo id="S7.SS1.SSS1.p7.1.m1.1.1" xref="S7.SS1.SSS1.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS1.p7.1.m1.1b"><ci id="S7.SS1.SSS1.p7.1.m1.1.1.cmml" xref="S7.SS1.SSS1.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS1.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p7.1.1">Underperforming specialized generation</em>. LLM이 일관된 텍스트를 생성하기 위해 일반적인 언어 패턴을 학습했지만 특수 영역이나 작업을 처리할 때 생성 능력이 제한될 수 있다. 예를 들어, 일반 웹 기사에 대해 훈련된 언어 모델은 많은 의학 용어 및 방법을 포함하는 의학 보고서를 생성할 때 어려움에 직면할 수 있다. 직관적으로, 도메인 지식은 모델 전문화에 매우 중요해야 한다. 그러나 이러한 전문지식을 LLMs에 주입하는 것은 쉽지 않다. 최근 분석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib47" title="">47</a>, <a class="ltx_ref" href="#bib.bib648" title="">648</a>]</cite>에서 논의한 바와 같이 LLM이 일부 영역에서 탁월할 수 있는 특정 능력을 나타내도록 훈련될 때 다른 영역에서 어려움을 겪을 수 있다. 이러한 문제는 훈련 신경망에서 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p7.1.2">catastrophic forgetting</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib649" title="">649</a>, <a class="ltx_ref" href="#bib.bib650" title="">650</a>]</cite>와 관련이 있는데, 이는 새로운 지식과 오래된 지식을 통합하는 충돌 현상을 말한다. 유사한 경우들이 LLM의 인간 정렬에서도 발생하는데, 여기서 "<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p7.1.3">alignment tax</em>” <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite> (<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS1.p7.1.4">e.g.,</em> a potential loss in-context learning ability)는 인간 값들 및 요구들에 정렬하기 위해 지불되어야 한다. 또한, 시퀀스 모델링 아키텍처의 한계로 인해 LLMs은 구조화된 데이터의 이해와 생성에 여전히 어려움을 겪고 있다. 결과적으로, 그들은 종종 지식 기반 질의 응답 및 의미론적 구문 분석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib651" title="">651</a>, <a class="ltx_ref" href="#bib.bib458" title="">458</a>]</cite>와 같은 복잡한 구조화된 데이터 태스크에서 태스크 특정 모델에 뒤처진다. 따라서, LLMs을 다양한 작업 시나리오에 유연하게 적용할 수 있는 동시에 원래 능력을 최대한 유지할 수 있는 효과적인 모델 특화 방법을 개발하는 것이 중요하다.</p>
</div>
<div id="S7.SS1.SSS1.2.p1" class="ltx_para ltx_noindent ltx_align_center">
<svg id="S7.SS1.SSS1.2.p1.pic1" class="ltx_picture" height="165.55" overflow="visible" version="1.1" width="276"><g transform="translate(0,165.55) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00008C" fill-opacity="1.0"><path d="M 0 5.91 L 0 159.64 C 0 162.9 2.64 165.55 5.91 165.55 L 270.1 165.55 C 273.36 165.55 276 162.9 276 159.64 L 276 5.91 C 276 2.64 273.36 0 270.1 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 131.17 L 274.04 131.17 L 274.04 5.91 C 274.04 3.73 272.27 1.97 270.1 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 137.08)"><foreignObject width="232.7" height="22.56" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S7.SS1.SSS1.2.p1.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS1.2.p1.pic1.1.1.1.1.1.1" class="ltx_p">Underperforming Specialized Generation</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="232.7" height="105.58" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S7.SS1.SSS1.2.p1.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS1.2.p1.pic1.2.2.2.1.1.1" class="ltx_p">LLMs may fall short in mastering generation tasks that require domain-specific knowledge or generating structured data. It is non-trivial to inject specialized knowledge into LLMs, meanwhile maintaining the original abilities of LLMs.</span>
</span></foreignObject></g></g></svg>
</div>
<figure id="S7.F17" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x17.png" id="S7.F17.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="106" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 17:</span>공개 LLM에 대한 내재적 및 외재적 환각의 예(액세스 날짜: March 19, 2023). 내재적 환각의 예로서 LLM은 투입과 모순되는 신디와 Amy의 관계에 대해 상반된 판단을 내린다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Examples of intrinsic and extrinsic hallucination for a public LLM (access date: March 19, 2023). As an example of intrinsic hallucination, the LLM gives a conflicting judgment about the relationship between Cindy and Amy, which contradicts the input.
For extrinsic hallucination, in this example, the LLM seems to have an incorrect understanding of the meaning of RLHF (reinforcement learning from human feedback), though it can correctly understand the meaning of LLMs (in this context).  </figcaption>
</figure>
</section>
<section id="S7.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.1.2 </span>Knowledge Utilization</h4>

<div id="S7.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS1.SSS2.p1.1">지식 활용은 지식 집약적 작업(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p1.1.1">e.g.,</em> commonsense question answering and fact completion)을 지원하는 사실적 증거에 기반하여 수행하는 지능형 시스템의 중요한 능력이다. 구체적으로, LLM은 사전 훈련 말뭉치로부터 풍부한 사실 지식을 적절하게 활용하거나 필요할 때 외부 데이터를 검색해야 한다. 특히, 질의 응답(QA)과 지식 완성(knowledge completion)은 이러한 능력을 평가하기 위해 일반적으로 사용되는 두 가지 과제이다. 테스트 작업(질문 응답 또는 지식 완료) 및 평가 설정(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p1.1.2">with</em> 또는 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p1.1.3">without</em> 외부 리소스에 따라 기존 지식 활용 작업을 closed-book QA, open-book QA<span class="ltx_note ltx_role_footnote" id="footnote45"><sup class="ltx_note_mark">45</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">45</sup><span class="ltx_tag ltx_tag_note">45</span>In this part, open-book QA refers to the QA tasks that require to extract and utilize useful information from external knowledge resources, as the antithesis of closed-book QA (only using the encoded information from pre-training corpus). Note that there is a dataset also named OpenBookQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib566" title="">566</a>]</cite>, which follows the settings of open-book QA tasks by extracting and utilizing external science facts.</span></span></span> 및 지식 완료의 세 가지 유형으로 분류합니다.</p>
</div>
<div id="S7.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS2.p2.1.1">Closed-Book QA. <span> Closed-book QA 태스크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib652" title="">652</a>]</cite>는 사전 훈련 말뭉치로부터 LLMs에 대한 획득된 사실적 지식을 테스트하며, 여기서 LLMs는 외부 리소스를 사용하지 않고 주어진 컨텍스트에 의해서만 질문에 답해야 한다. 이 능력을 평가하기 위해 정확도 메트릭이 널리 채택된 자연 질문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib554" title="">554</a>]</cite>, Web Questions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib557" title="">557</a>]</cite>, TriviaQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib558" title="">558</a>]</cite> 등 활용할 수 있는 여러 데이터 세트가 있다. 경험적 결과는 LLM이 이 설정에서 잘 수행할 수 있고 심지어 최첨단 오픈 도메인 QA 시스템<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>의 성능과 일치할 수 있음을 보여주었다. 또한 closed-book QA 태스크에서 LLM의 성능은 모델 크기와 데이터 크기 모두에서 스케일링 법칙 패턴을 보여준다. 파라미터와 훈련 토큰의 스케일링은 LLM의 용량을 증가시킬 수 있으며, 사전 훈련 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>로부터 더 많은 지식을 학습(또는 암기)하도록 도울 수 있다. 또한, 유사한 파라미터 스케일 하에서, 평가된 태스크들과 관련된 더 많은 사전 트레이닝 데이터를 갖는 LLMs들은 더 나은 성능 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>를 달성할 것이다. 또한, 닫힌 문서 QA 설정은 LLMs에 의해 인코딩된 사실적 지식의 정확성을 조사하기 위한 테스트베드를 제공한다. 그러나 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>에서 볼 수 있듯이 LLMs은 사전 훈련 데이터에 존재하더라도 세밀한 지식에 의존하는 QA 작업에 덜 잘 수행할 수 있다.</p>
</div>
<div id="S7.SS1.SSS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS2.p3.1.1">Open-Book QA. </span> closed-book QA와 달리 open-book QA 작업에서 LLMs은 외부 지식베이스나 문서 모음에서 유용한 증거를 추출한 후 추출된 증거 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib653" title="">653</a>, <a class="ltx_ref" href="#bib.bib654" title="">654</a>, <a class="ltx_ref" href="#bib.bib655" title="">655</a>, <a class="ltx_ref" href="#bib.bib656" title="">656</a>]</cite>를 기반으로 질문에 답할 수 있다. 전형적인 open-book QA 데이터 세트(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p3.1.2">e.g.,</em> Natural Questions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib554" title="">554</a>]</cite>, OpenBookQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib566" title="">566</a>]</cite>, SQuAD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib569" title="">569</a>]</cite>)는 closed-book QA 데이터 세트와 중첩되지만, 외부 데이터 소스, <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p3.1.3">e.g.,</em> Wikipedia를 통합한다. 정확도 및 F1 점수의 메트릭은 평가를 위한 오픈북 QA 작업에서 널리 사용된다. 외부 리소스들로부터 관련 지식을 선택하기 위해, LLMs들은 종종 텍스트 리트리버(또는 심지어 검색 엔진)와 페어링되며, 이는 LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib653" title="">653</a>, <a class="ltx_ref" href="#bib.bib657" title="">657</a>, <a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>와 독립적으로 또는 공동으로 트레이닝된다. 또한, 이전 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib658" title="">658</a>, <a class="ltx_ref" href="#bib.bib659" title="">659</a>, <a class="ltx_ref" href="#bib.bib660" title="">660</a>]</cite>는 리트리버가 추론 경로를 검증하고 수정하는 데 LLM을 지원할 수 있음을 나타낸다. 평가에서 기존 연구는 주로 LLM이 추출된 지식을 사용하여 질문에 답하는 방법을 테스트하는 데 초점을 맞추고 검색된 증거가 생성된 답변의 정확도를 크게 향상시킬 수 있음을 보여주며, 더 작은 LLM이 <math alttext="10\times" class="ltx_math_unparsed" display="inline" id="S7.SS1.SSS2.p3.1.m1.1"><semantics id="S7.SS1.SSS2.p3.1.m1.1a"><mrow id="S7.SS1.SSS2.p3.1.m1.1b"><mn id="S7.SS1.SSS2.p3.1.m1.1.1">10</mn><mo id="S7.SS1.SSS2.p3.1.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S7.SS1.SSS2.p3.1.m1.1c">10\times</annotation></semantics></math> 더 큰 것<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib653" title="">653</a>, <a class="ltx_ref" href="#bib.bib657" title="">657</a>]</cite>를 능가할 수 있다. 또한, 지식 정보의 최신성을 평가하기 위해 오픈북 QA 작업도 사용할 수 있다. 구식 지식 리소스에서 사전 훈련 또는 검색은 LLMs로 하여금 시간에 민감한 질문들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib653" title="">653</a>]</cite>에 대한 오답을 생성하게 할 수 있다.</p>
</div>
<div id="S7.SS1.SSS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS2.p4.1.1">Knowledge Completion. 지식 완성 작업에서 LLMs는 지식 단위의 누락된 부분을 완료하거나 예측하기 위해 레버리지될 수 있는 지식 베이스로 (어느 정도) 간주될 수 있다(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p4.1.2">e.g.,</em> knowledge triples). 이러한 작업은 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p4.1.3">how much</em> 및 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p4.1.4">what kind of</em> knowledge LLMs가 사전 훈련 데이터로부터 학습한 것이다. 기존의 지식 완성 작업은 크게 지식 그래프 완성 작업(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p4.1.5">e.g.,</em> FB15k-237 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib572" title="">572</a>]</cite> and WN18RR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib574" title="">574</a>]</cite>)과 사실 완성 작업(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p4.1.6">e.g.,</em> WikiFact <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib571" title="">571</a>]</cite>)으로 나눌 수 있는데, 이들은 각각 특정 사실에 대한 지식 그래프와 불완전한 문장으로부터 트리플을 완성하는 것을 목표로 한다. 경험적 연구에 따르면 기존의 LLMs은 특정 관계 유형 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib520" title="">520</a>]</cite>와 관련된 지식 완성 작업을 수행하기 어렵다. WikiFact에 대한 평가 결과에서 볼 수 있듯이 LLMs는 사전 훈련 데이터에서 발생하는 몇 가지 빈번한 관계에 대해 잘 수행됩니다(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p4.1.7">e.g.,</em> <span class="ltx_text ltx_font_typewriter" id="S7.SS1.SSS2.p4.1.8">currency</span> 및 <span class="ltx_text ltx_font_typewriter" id="S7.SS1.SSS2.p4.1.9">author</span>인 반면 희귀한 데이터에 대해서는 잘 수행되지 않습니다(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p4.1.10">e.g.,</em> <span class="ltx_text ltx_font_typewriter" id="S7.SS1.SSS2.p4.1.11"> 흥미롭게도 동일한 평가 설정 (<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p4.1.13">e.g.,</em> in-context learning), InstructGPT (<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p4.1.14">i.e.,</em> <span class="ltx_text ltx_font_typewriter" id="S7.SS1.SSS2.p4.1.15">text-davinci-002)</span> outperforms GPT-3 in WikiFact의 모든 하위 집합에서 GPT-3를 수행 합니다.</p>
</div>
<div id="S7.SS1.SSS2.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS2.p5.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS2.p5.1.1">Major Issues</span>. LLM은 지식 정보를 포착하고 활용하는 데 핵심적인 진전을 이루었지만 아래에서 논의되는 두 가지 주요 문제로 어려움을 겪고 있다.</p>
</div>
<div id="S7.SS1.SSS2.p6" class="ltx_para">
<p class="ltx_p" id="S7.SS1.SSS2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.SSS2.p6.1.m1.1"><semantics id="S7.SS1.SSS2.p6.1.m1.1a"><mo id="S7.SS1.SSS2.p6.1.m1.1.1" xref="S7.SS1.SSS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS2.p6.1.m1.1b"><ci id="S7.SS1.SSS2.p6.1.m1.1.1.cmml" xref="S7.SS1.SSS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS2.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p6.1.1">Hallucination</em>. 사실적 텍스트를 생성할 때 어려운 문제는 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p6.1.2">hallucination generations</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib638" title="">638</a>, <a class="ltx_ref" href="#bib.bib661" title="">661</a>]</cite>이며, 여기서 생성된 정보는 기존 원본과 충돌하거나(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p6.1.3">intrinsic hallucination</em>) 사용 가능한 원본으로 확인할 수 없거나(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p6.1.4">extrinsic hallucination</em>), 그림 <a class="ltx_ref" href="#S7.F17" title="Figure 17 ‣ 7.1.1 Language Generation ‣ 7.1 Basic Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">17</span></a>의 두 가지 예로 예시된다. 환각은 GPT-4<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>와 같은 가장 우수한 LLM에서도 기존 LLM에서 널리 발생한다. 또한 기존의 연구는 LLMs이 강력한 ChatGPT에서도 텍스트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib602" title="">602</a>]</cite>에서 환각 콘텐츠를 인식하는 데 어려움을 겪는다는 것을 보여준다. 또한 언어 작업을 넘어 최근 연구에 따르면 큰 비전 언어 모델(LVLM)도 환각, <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p6.1.5">i.e.,</em> 첨부 이미지에는 없는 개체를 생성합니다.</cite idx=3></cite>. 본질적으로 LLMs는 내·외적 지식의 사용을 정확하게 통제할 수 있는 능력이 여전히 부족한 과제 해결에서 지식을 '무의식적으로' 활용하는 것으로 보인다. 환각은 LLM이 원하지 않는 출력을 생성하도록 오도하고 대부분 성능을 저하시켜 실제 응용 프로그램에 LLM을 배포할 때 잠재적인 위험을 초래할 수 있다. 이 문제를 완화하기 위해, 정렬 튜닝 전략(섹션 <a class="ltx_ref" href="#S5.SS2" title="5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.2</span></a>에서 논의된 바와 같이)은 고품질 데이터에 대한 LLMs 튜닝 또는 인간 피드백을 사용하는 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>에서 널리 활용되었다. 또한, 신뢰할 수 있는 정보 소스 제공을 위한 외부 도구의 통합은 환각 문제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib602" title="">602</a>, <a class="ltx_ref" href="#bib.bib659" title="">659</a>, <a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>를 완화하는 데 도움이 될 수 있다. 또 다른 연구 라인은 LLM의 불확실성 추정을 활용하여 환각 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib663" title="">663</a>, <a class="ltx_ref" href="#bib.bib664" title="">664</a>]</cite>를 식별한다. 예를 들어, 환각 사실이 다른 샘플링된 출력에 걸쳐 불일치를 나타내기 쉽다는 점을 고려하여 SelfCheckGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib664" title="">664</a>]</cite>는 샘플링된 출력 내에서 정보 불일치를 측정하여 환각을 감지한다. 환각 문제의 평가를 위해 모델에 의해 모방된 인간 거짓을 검출하기 위한 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p6.1.6">e.g.,</em> TruthfulQA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib556" title="">556</a>]</cite>가 제안되었다. 보다 최근에 HaluEval<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib602" title="">602</a>]</cite>는 태스크별 및 일반 시나리오 모두에서 환각을 인식하는 언어 모델의 능력을 평가하기 위해 대규모 LLM 생성 및 인간 주석이 있는 환각 샘플을 생성한다.</p>
<div id="S7.SS1.SSS2.p6.2" class="ltx_logical-block">
<div id="S7.SS1.SSS2.p6.2.p1" class="ltx_para ltx_noindent ltx_align_center">
<svg id="S7.SS1.SSS2.p6.2.p1.pic1" class="ltx_picture" height="208.75" overflow="visible" version="1.1" width="276"><g transform="translate(0,208.75) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00008C" fill-opacity="1.0"><path d="M 0 5.91 L 0 202.84 C 0 206.11 2.64 208.75 5.91 208.75 L 270.1 208.75 C 273.36 208.75 276 206.11 276 202.84 L 276 5.91 C 276 2.64 273.36 0 270.1 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 187.33 L 274.04 187.33 L 274.04 5.91 C 274.04 3.73 272.27 1.97 270.1 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 193.24)"><foreignObject width="232.7" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S7.SS1.SSS2.p6.2.p1.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS2.p6.2.p1.pic1.1.1.1.1.1.1" class="ltx_p">Hallucination</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="232.7" height="161.74" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S7.SS1.SSS2.p6.2.p1.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS2.p6.2.p1.pic1.2.2.2.1.1.1" class="ltx_p">LLMs are prone to generate untruthful information that either conflicts with the existing source or cannot be verified by the available source. Even the most powerful LLMs such as ChatGPT face great challenges in migrating the hallucinations of the generated texts.
This issue can be partially alleviated by special approaches such as alignment tuning and tool utilization.</span>
</span></foreignObject></g></g></svg>
</div>
</div>
</div>
<div id="S7.SS1.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S7.SS1.SSS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.SSS2.p7.1.m1.1"><semantics id="S7.SS1.SSS2.p7.1.m1.1a"><mo id="S7.SS1.SSS2.p7.1.m1.1.1" xref="S7.SS1.SSS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS2.p7.1.m1.1b"><ci id="S7.SS1.SSS2.p7.1.m1.1.1.cmml" xref="S7.SS1.SSS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS2.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p7.1.1">Knowledge recency</em>. 또 다른 주요 과제로 LLM은 훈련 데이터를 넘어 최신 지식이 필요한 과제를 해결할 때 어려움을 겪을 것이다. 이 문제를 해결하기 위해 간단한 접근법은 LLM을 정기적으로 새 데이터로 업데이트하는 것이다. 그러나 LLM을 미세 조정하는 것은 매우 비용이 많이 들고 LLM을 점진적으로 훈련할 때 치명적인 망각 문제를 일으킬 가능성이 있다. 따라서 기존 LLMs에 새로운 지식을 통합하여 최신 상태로 만들 수 있는 효율적이고 효과적인 접근 방식을 개발할 필요가 있다. 기존 연구는 LLMs를 보완하기 위해 외부 지식 소스(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p7.1.2">e.g.,</em> search engine)를 활용하는 방법을 탐구했는데, 이는 LLMs와 공동으로 최적화될 수 있는 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib653" title="">653</a>]</cite> 또는 플러그 앤 플레이 모듈로서 사용될 수 있는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib659" title="">659</a>]</cite>이다. 예를 들어 ChatGPT는 검색 플러그인을 사용하여 최신 정보 원본 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib665" title="">665</a>]</cite>에 액세스합니다. 추출된 관련 정보를 문맥 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib666" title="">666</a>, <a class="ltx_ref" href="#bib.bib667" title="">667</a>, <a class="ltx_ref" href="#bib.bib668" title="">668</a>]</cite>에 통합함으로써 LLMs은 새로운 사실 지식을 습득하고 관련 작업에 대해 더 나은 성능을 발휘할 수 있다. 그러나, 그러한 접근은 여전히 피상적인 수준인 것 같다. 또한 기존 연구에서는 언어 모델의 편집 매개 변수를 탐색하여 내재적 지식 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib669" title="">669</a>, <a class="ltx_ref" href="#bib.bib670" title="">670</a>, <a class="ltx_ref" href="#bib.bib671" title="">671</a>]</cite>를 업데이트한다. 그럼에도 불구하고, 이전 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib672" title="">672</a>]</cite>는 몇몇 파라미터 편집 방법들이 작은 언어 모델들의 성능을 향상시킬 수 있음에도 불구하고 LLMs에 대해 잘 수행되지 않는다는 것을 보여주었다. 따라서 내재적 지식을 직접 수정하거나 LLMs에 특정 지식을 주입하는 것은 여전히 어려운 일이며, 이는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib672" title="">672</a>]</cite>의 미해결 연구 문제로 남아 있다. 최근에는 LLMs에 대한 지식 편집 연구를 용이하게 하기 위해 유용한 프레임워크 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS2.p7.1.3">EasyEdit</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib673" title="">673</a>]</cite>가 출시되었다.</p>
</div>
<div id="S7.SS1.SSS2.1.p1" class="ltx_para ltx_noindent ltx_align_center">
<svg id="S7.SS1.SSS2.1.p1.pic1" class="ltx_picture" height="165.93" overflow="visible" version="1.1" width="276"><g transform="translate(0,165.93) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00008C" fill-opacity="1.0"><path d="M 0 5.91 L 0 160.03 C 0 163.29 2.64 165.93 5.91 165.93 L 270.1 165.93 C 273.36 165.93 276 163.29 276 160.03 L 276 5.91 C 276 2.64 273.36 0 270.1 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 141.82 L 274.04 141.82 L 274.04 5.91 C 274.04 3.73 272.27 1.97 270.1 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 147.73)"><foreignObject width="232.7" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S7.SS1.SSS2.1.p1.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS2.1.p1.pic1.1.1.1.1.1.1" class="ltx_p">Knowledge Recency</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="232.7" height="116.23" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S7.SS1.SSS2.1.p1.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS2.1.p1.pic1.2.2.2.1.1.1" class="ltx_p">The parametric knowledge of LLMs is hard to be updated in a timely manner.
Augmenting LLMs with external knowledge sources is a practical approach to tackling the issue.
However, how to effectively update knowledge within LLMs remains an open research problem.</span>
</span></foreignObject></g></g></svg>
</div>
</section>
<section id="S7.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.1.3 </span>Complex Reasoning</h4>

<div id="S7.SS1.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS1.SSS3.p1.1">복합추론은 근거나 논리를 이해하고 활용하여 결론을 도출하거나 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib51" title="">51</a>, <a class="ltx_ref" href="#bib.bib52" title="">52</a>]</cite>를 결정하는 능력을 말한다. 추론 과정에서 개입된 논리와 증거의 유형에 따라 기존의 평가 과제를 지식 추론, 기호 추론, 수학적 추론의 세 가지 대범주로 구분하는 것을 고려한다.</p>
</div>
<div id="S7.SS1.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS3.p2.1.1">Knowledge Reasoning. </span> 지식 추론 작업은 주어진 질문에 답하기 위해 사실적 지식에 대한 논리적 관계와 증거에 의존한다. 기존의 연구는 주로 특정 데이터셋을 사용하여 해당 유형의 지식의 추론 능력을 평가하는데, <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p2.1.2">e.g.,</em> CSQA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib504" title="">504</a>]</cite>/StrategyQA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib185" title="">185</a>]</cite>는 상식적 지식추론, ScienceQA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib565" title="">565</a>]</cite>는 과학지식추론이다. 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib565" title="">565</a>]</cite>는 예측 결과의 정확성 외에도 자동 메트릭(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p2.1.3">e.g.,</em> BLEU) 또는 인간 평가를 통해 생성된 추론 프로세스의 품질을 평가했다. 전형적으로, 이러한 태스크들은 LLM들이 주어진 질문에 대한 답변에 도달할 때까지, 사실적 지식에 기초하여 단계적 추론을 수행할 것을 요구한다. 단계적 추론 능력을 도출하기 위해 LLM의 복잡한 추론 능력을 향상시키기 위한 CoT 프롬프트 전략 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>가 제안되었다. 섹션 <a class="ltx_ref" href="#S6.SS3" title="6.3 Chain-of-Thought Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.3</span></a>에서 논의된 바와 같이, CoT는 중간 추론 단계를 포함하며, 이는 LLM이 다단계 추론을 수행하도록 안내하기 위해 프롬프트에 수동으로 생성될 수 있는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite> 또는 자동으로 생성될 수 있다. 이러한 방식은 LLMs의 추론 성능을 크게 향상시켜 여러 복잡한 지식 추론 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib526" title="">526</a>]</cite>에 대한 새로운 최신 결과를 가져온다. 또한, 지식 추론 작업을 코드 생성 작업으로 재구성한 후, 연구자들은 특히 코드에 대해 사전 훈련된 LLMs을 사용하여 LLMs의 성능을 더 향상시킬 수 있음을 발견했다. 그러나 지식 추론 작업의 복잡성으로 인해 현재 LLM의 성능은 여전히 상식 추론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib675" title="">675</a>]</cite>와 같은 작업에서 인간의 결과에 뒤처진다. 일반적인 실수 유형으로서 LLM은 부정확한 중간 단계를 생성하여 잘못된 최종 결과를 초래할 수 있다. 이 문제를 해결하기 위해 기존 연구에서는 전체 추론 체인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib436" title="">436</a>, <a class="ltx_ref" href="#bib.bib437" title="">437</a>]</cite>의 정확도를 향상시키기 위해 특수 디코딩 또는 앙상블 전략을 제안했다.</p>
</div>
<div id="S7.SS1.SSS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS3.p3.1.1">Symbolic Reasoning<span class="ltx_note ltx_role_footnote" id="footnote46"><sup class="ltx_note_mark">46</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">46</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote46.1.1.1">46</span></span><span class="ltx_text ltx_font_medium" id="footnote46.5">Following </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_medium" id="footnote46.6.1">[</span><a class="ltx_ref" href="#bib.bib33" title="">33</a><span class="ltx_text ltx_font_medium" id="footnote46.7.2">]</span></cite><span class="ltx_text ltx_font_medium" id="footnote46.8">, we mainly discuss symbolic reasoning tasks specially designed for evaluating LLMs. We do not consider symbolic reasoning methods in traditional NLP tasks, such as deducing logical rules from the knowledge graphs in KBQA.</span></span></span></span>. </span>  기호 추론 작업은 주로 공식 규칙 설정에서 기호를 조작하는 데 중점을 두어 특정 목표 [cite idx=0></cite> 여기서 연산과 규칙은 사전 훈련 동안 LLMs에 의해 보이지 않았을 수 있다. 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>, <a class="ltx_ref" href="#bib.bib505" title="">505</a>, <a class="ltx_ref" href="#bib.bib439" title="">439</a>]</cite>는 마지막 문자 연결 및 동전 뒤집기의 작업에 대해 LLMs를 일반적으로 평가하며, 여기서 평가 예는 컨텍스트 내 예제와 동일한 추론 단계를 요구한다(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p3.1.2">in-domain test</em>로 불림) 또는 그 이상의 단계(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p3.1.3">out-of-domain test</em>로 불림). 영역 외 테스트의 예에서 LLM은 문맥에서 두 개의 단어가 있는 예만 볼 수 있지만 LLM은 세 개 이상의 단어의 마지막 문자를 연결해야 한다. 일반적으로, 생성된 심볼들의 정확도는 이러한 태스크들에 대한 LLM들의 성능을 평가하기 위해 채택된다. 따라서 LLMs은 복잡한 시나리오에서 기호 연산과 그 구성 사이의 의미 관계를 이해해야 한다. 그러나 도메인 외 설정에서는 LLM이 심볼릭 연산과 규칙의 복잡한 구성을 보지 못했기 때문에(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p3.1.4">e.g.,</em> 문맥 예제에서 연산 수의 두 배인 경우), LLM이 정확한 의미를 포착하는 것은 어렵다. 이 문제를 해결하기 위해 기존 연구에서는 LLM이 더 길고 복잡한 추론 프로세스를 생성하기 위해 기호 연산을 더 잘 조작할 수 있도록 스크래치패드 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib591" title="">591</a>, <a class="ltx_ref" href="#bib.bib676" title="">676</a>]</cite>와 튜터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib677" title="">677</a>]</cite> 전략을 통합했다. 또 다른 연구 분야는 정규 프로그래밍 언어를 사용하여 기호 연산과 규칙을 표현하는데, LLM은 코드를 생성하고 외부 해석자와 함께 실행하여 추론 과정을 수행해야 한다. 이러한 방법은 복잡한 추론 과정을 각각 LLM과 인터프리터에 대한 코드 합성과 프로그램 실행으로 분해하여 보다 정확한 결과를 갖는 단순화된 추론 과정으로 이어질 수 있다.</p>
</div>
<div id="S7.SS1.SSS3.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS3.p4.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS3.p4.1.1">Mathematical Reasoning. </span> 수학적 추론 과제는 문제를 해결하거나 증명문을 생성하기 위해 수학적 지식, 논리, 계산을 종합적으로 활용할 필요가 있다. 기존의 수학적 추론 과제는 주로 수학 문제 해결과 자동화된 정리 증명으로 범주화할 수 있다. 수학 문제 해결 과제의 경우, SVAMP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib592" title="">592</a>]</cite>, GSM8k<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite> 및 MATH<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib364" title="">364</a>]</cite> 데이터 세트가 평가에 일반적으로 사용되며, 여기서 LLM은 수학적 문제에 답하기 위해 정확한 구체적인 숫자 또는 방정식을 생성해야 한다. 이러한 작업들도 다단계 추론을 요구하기 때문에, CoT 프롬프트 전략은 LLMs에 널리 채택되어 추론 성능<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>를 향상시켰다. 또 다른 실용적인 전략으로 대규모 수학적 말뭉치에서 LLM을 지속적으로 사전 훈련하면 수학적 추론 과제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib678" title="">678</a>, <a class="ltx_ref" href="#bib.bib35" title="">35</a>, <a class="ltx_ref" href="#bib.bib203" title="">203</a>]</cite>에서 성능이 크게 향상될 수 있다. 또한, 서로 다른 언어의 수학 문제들은 동일한 수학적 논리를 공유하기 때문에, 연구자들 또한 LLM의 다국어 수학적 추론 능력을 평가하기 위해 다국어 수학 단어 문제 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib524" title="">524</a>]</cite>를 제안한다. 또 다른 도전 과제로서, 자동화된 정리 증명(ATP) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib600" title="">600</a>, <a class="ltx_ref" href="#bib.bib598" title="">598</a>, <a class="ltx_ref" href="#bib.bib679" title="">679</a>]</cite>는 추론 논리 및 수학적 기술을 엄격하게 따르기 위해 추론 모델을 필요로 한다. 이 작업에 대한 성능을 평가하기 위해 PISA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib599" title="">599</a>]</cite> 및 miniF2F <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib600" title="">600</a>]</cite>는 평가 메트릭으로 <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p4.1.2">proof success rate</em>을 가진 두 개의 전형적인 ATP 데이터 세트이다. 대표적인 접근 방법으로 ATP에 대한 기존 연구는 LLM을 활용하여 Lean, Metamath, Isabelle<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib680" title="">680</a>, <a class="ltx_ref" href="#bib.bib681" title="">681</a>, <a class="ltx_ref" href="#bib.bib682" title="">682</a>]</cite>와 같은 상호작용 정리 증명(Interactive theorem prover, ITP)을 이용한 증명 검색을 돕는다. ATP 연구의 주요 한계는 공식 언어에서 관련 말뭉치의 부족이다. 이를 해결하기 위해 여러 연구에서 LLMs을 활용하여 비형식적 진술을 새로운 데이터 보강을 위한 공식 증명으로 변환하거나 증명의 검색 공간을 줄이기 위해 초안 및 증명 스케치를 생성한다.</p>
</div>
<div id="S7.SS1.SSS3.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS1.SSS3.p5.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.SSS3.p5.1.1">Major Issues. </span> 진보에도 불구하고 LLMs은 여전히 복잡한 추론 과제를 해결하는 데 몇 가지 한계를 가지고 있다.</p>
</div>
<div id="S7.SS1.SSS3.p6" class="ltx_para">
<p class="ltx_p" id="S7.SS1.SSS3.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.SSS3.p6.1.m1.1"><semantics id="S7.SS1.SSS3.p6.1.m1.1a"><mo id="S7.SS1.SSS3.p6.1.m1.1.1" xref="S7.SS1.SSS3.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS3.p6.1.m1.1b"><ci id="S7.SS1.SSS3.p6.1.m1.1.1.cmml" xref="S7.SS1.SSS3.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS3.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p6.1.1">Reasoning inconsistency</em>. 개선된 추론 전략(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p6.1.2">e.g.,</em> CoT prompting)을 통해 LLMs은 지원 로직과 증거에 기반한 단계별 추론을 수행함으로써 복잡한 추론 작업을 해결할 수 있다. 효과성에도 불구하고, <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p6.1.3">reasoning inconsistency</em> 문제는 분해된 추론 과정에서 종종 발생한다. 구체적으로, LLMs은 잘못된 추론 경로에 따라 정답을 생성하거나, 올바른 추론 과정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>, <a class="ltx_ref" href="#bib.bib442" title="">442</a>]</cite> 이후에 오답을 생성하여 도출된 답과 추론 과정의 불일치로 이어질 수 있다. 이러한 문제를 해결하기 위해 기존 연구에서는 LLM의 전체 생성 과정을 외부 도구 또는 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib636" title="">636</a>, <a class="ltx_ref" href="#bib.bib437" title="">437</a>, <a class="ltx_ref" href="#bib.bib451" title="">451</a>]</cite>를 통해 안내하고, 추론 과정 및 최종 답변을 다시 확인하여 잠재적인 오류를 수정하거나 프로세스 기반 피드백 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib685" title="">685</a>, <a class="ltx_ref" href="#bib.bib686" title="">686</a>, <a class="ltx_ref" href="#bib.bib687" title="">687</a>]</cite> 또는 LLM을 미세 조정하기 위해 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib688" title="">688</a>, <a class="ltx_ref" href="#bib.bib689" title="">689</a>]</cite>를 제안한다. 예를 들어, <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p6.1.4">Tree of Thoughts(ToT)</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib451" title="">451</a>]</cite>는 LLMs가 다양한 추론 경로를 동시에 탐색하고 자체 평가함으로써 의사 결정 프로세스에 참여할 수 있도록 권한을 부여합니다. 추론 과정을 정교화하기 위해 Self-Refine <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib685" title="">685</a>]</cite>는 자체 생성된 솔루션에 대한 LLM으로부터 피드백을 이끌어내어 피드백에 기반한 솔루션의 반복적인 정교화를 가능하게 한다. 또한, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib688" title="">688</a>, <a class="ltx_ref" href="#bib.bib689" title="">689</a>]</cite> 훈련 중 과정 기반 수퍼비전의 통합을 통해 LLM의 추론 사슬의 일관성을 향상시키는 연구도 있다. 유망한 해결책으로서, 최근의 접근법들은 복잡한 추론 태스크들을 코드 생성 태스크들로 재형성하는데, 여기서 생성된 코드의 엄격한 실행은 추론 프로세스와 결과 사이의 일관성을 보장한다. 또한, 유사한 입력을 갖는 태스크들 사이에 불일치가 존재할 수 있다는 것이 밝혀졌으며, 여기서 태스크 디스크립션의 작은 변화는 모델이 다른 결과를 생성하게 할 수 있다[<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib592" title="">592</a>, <a class="ltx_ref" href="#bib.bib49" title="">49</a>]</cite>]. 이 문제를 완화하기 위해 자기 일관성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib436" title="">436</a>]</cite>는 LLM의 디코딩 프로세스를 향상시키기 위해 다중 추론 경로의 앙상블을 채택한다.</p>
<div id="S7.SS1.SSS3.p6.2" class="ltx_logical-block">
<div id="S7.SS1.SSS3.p6.2.p1" class="ltx_para ltx_noindent ltx_align_center">
<svg id="S7.SS1.SSS3.p6.2.p1.pic1" class="ltx_picture" height="225.2" overflow="visible" version="1.1" width="276"><g transform="translate(0,225.2) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00008C" fill-opacity="1.0"><path d="M 0 5.91 L 0 219.29 C 0 222.56 2.64 225.2 5.91 225.2 L 270.1 225.2 C 273.36 225.2 276 222.56 276 219.29 L 276 5.91 C 276 2.64 273.36 0 270.1 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 201.24 L 274.04 201.24 L 274.04 5.91 C 274.04 3.73 272.27 1.97 270.1 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 207.15)"><foreignObject width="232.7" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S7.SS1.SSS3.p6.2.p1.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS3.p6.2.p1.pic1.1.1.1.1.1.1" class="ltx_p">Reasoning Inconsistency</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="232.7" height="175.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S7.SS1.SSS3.p6.2.p1.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS3.p6.2.p1.pic1.2.2.2.1.1.1" class="ltx_p">LLMs may generate the correct answer following an invalid reasoning path, or produce a wrong answer after a correct reasoning process, leading to inconsistency between the derived answer and the reasoning process.
The issue can be alleviated by fine-tuning LLMs with process-level feedback, using an ensemble of diverse reasoning paths, and refining the reasoning process with self-reflection or external feedback.</span>
</span></foreignObject></g></g></svg>
</div>
</div>
</div>
<div id="S7.SS1.SSS3.p7" class="ltx_para">
<p class="ltx_p" id="S7.SS1.SSS3.p7.3"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.SSS3.p7.1.m1.1"><semantics id="S7.SS1.SSS3.p7.1.m1.1a"><mo id="S7.SS1.SSS3.p7.1.m1.1.1" xref="S7.SS1.SSS3.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS3.p7.1.m1.1b"><ci id="S7.SS1.SSS3.p7.1.m1.1.1.cmml" xref="S7.SS1.SSS3.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS3.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p7.3.1">Numerical computation</em>. 복잡한 추론 작업의 경우, LLMs은 특히 많은 수의 산술 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib677" title="">677</a>, <a class="ltx_ref" href="#bib.bib49" title="">49</a>, <a class="ltx_ref" href="#bib.bib690" title="">690</a>]</cite>와 같이 사전 훈련 동안 거의 마주치지 않는 기호에 대해 관련된 수치 계산에서 여전히 어려움에 직면한다. 이 문제를 해결하기 위해 직접적인 방법은 합성된 산술 문제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib691" title="">691</a>, <a class="ltx_ref" href="#bib.bib361" title="">361</a>]</cite>에서 LLM을 조정하는 것이다. 또한, 학습 및 추론 단계에서 중간 계산 단계를 추적함으로써 수치 계산 성능을 향상시켰다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib676" title="">676</a>, <a class="ltx_ref" href="#bib.bib692" title="">692</a>, <a class="ltx_ref" href="#bib.bib361" title="">361</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p7.3.2">e.g.,</em> 스크래치패드 추적. 또한, 기존의 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>는 특히 산술 연산을 처리하기 위한 외부 도구(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p7.3.3">e.g.,</em> calculator)도 통합했다. 보다 최근에 ChatGPT는 외부 도구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib665" title="">665</a>]</cite>를 사용할 수 있는 플러그인 메커니즘을 제공했다. 이러한 방식으로 LLM은 도구를 적절하게 조작하는 방법을 배워야 한다. 이를 위해 연구자들은 LLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib693" title="">693</a>, <a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>를 조정하기 위한 도구(LLM 자체도)를 사용하거나 상황 내 학습<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib443" title="">443</a>]</cite>를 위한 명령어와 예제를 고안했다. 외부 도구의 도움 외에도 최근 연구에서는 숫자를 개별 토큰으로 토큰화하는 것(<em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS3.p7.3.4">e.g.,</em> LLaMA and Galactica tokenizers)이 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib690" title="">690</a>, <a class="ltx_ref" href="#bib.bib361" title="">361</a>]</cite>의 고유한 연산 능력을 향상시키는 데 유용한 접근법임을 발견했다. 한 가지 가능한 설명은 서브워드 토큰화 기술들이 숫자들을 토큰화할 때 일관되지 않은 시퀀스들을 초래할 수 있다는 것이다. 예를 들어, 서브워드 토큰화기로 정수 7481은 <math alttext="7\_481" class="ltx_Math" display="inline" id="S7.SS1.SSS3.p7.2.m2.1"><semantics id="S7.SS1.SSS3.p7.2.m2.1a"><mrow id="S7.SS1.SSS3.p7.2.m2.1.1" xref="S7.SS1.SSS3.p7.2.m2.1.1.cmml"><mn id="S7.SS1.SSS3.p7.2.m2.1.1.2" xref="S7.SS1.SSS3.p7.2.m2.1.1.2.cmml">7</mn><mo id="S7.SS1.SSS3.p7.2.m2.1.1.1" lspace="0em" rspace="0em" xref="S7.SS1.SSS3.p7.2.m2.1.1.1.cmml">​</mo><mi id="S7.SS1.SSS3.p7.2.m2.1.1.3" mathvariant="normal" xref="S7.SS1.SSS3.p7.2.m2.1.1.3.cmml">_</mi><mo id="S7.SS1.SSS3.p7.2.m2.1.1.1a" lspace="0em" rspace="0em" xref="S7.SS1.SSS3.p7.2.m2.1.1.1.cmml">​</mo><mn id="S7.SS1.SSS3.p7.2.m2.1.1.4" xref="S7.SS1.SSS3.p7.2.m2.1.1.4.cmml">481</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS3.p7.2.m2.1b"><apply id="S7.SS1.SSS3.p7.2.m2.1.1.cmml" xref="S7.SS1.SSS3.p7.2.m2.1.1"><times id="S7.SS1.SSS3.p7.2.m2.1.1.1.cmml" xref="S7.SS1.SSS3.p7.2.m2.1.1.1"></times><cn id="S7.SS1.SSS3.p7.2.m2.1.1.2.cmml" type="integer" xref="S7.SS1.SSS3.p7.2.m2.1.1.2">7</cn><ci id="S7.SS1.SSS3.p7.2.m2.1.1.3.cmml" xref="S7.SS1.SSS3.p7.2.m2.1.1.3">_</ci><cn id="S7.SS1.SSS3.p7.2.m2.1.1.4.cmml" type="integer" xref="S7.SS1.SSS3.p7.2.m2.1.1.4">481</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS3.p7.2.m2.1c">7\_481</annotation></semantics></math>로 토큰화될 수 있는 반면, 74815는 <math alttext="748\_15" class="ltx_Math" display="inline" id="S7.SS1.SSS3.p7.3.m3.1"><semantics id="S7.SS1.SSS3.p7.3.m3.1a"><mrow id="S7.SS1.SSS3.p7.3.m3.1.1" xref="S7.SS1.SSS3.p7.3.m3.1.1.cmml"><mn id="S7.SS1.SSS3.p7.3.m3.1.1.2" xref="S7.SS1.SSS3.p7.3.m3.1.1.2.cmml">748</mn><mo id="S7.SS1.SSS3.p7.3.m3.1.1.1" lspace="0em" rspace="0em" xref="S7.SS1.SSS3.p7.3.m3.1.1.1.cmml">​</mo><mi id="S7.SS1.SSS3.p7.3.m3.1.1.3" mathvariant="normal" xref="S7.SS1.SSS3.p7.3.m3.1.1.3.cmml">_</mi><mo id="S7.SS1.SSS3.p7.3.m3.1.1.1a" lspace="0em" rspace="0em" xref="S7.SS1.SSS3.p7.3.m3.1.1.1.cmml">​</mo><mn id="S7.SS1.SSS3.p7.3.m3.1.1.4" xref="S7.SS1.SSS3.p7.3.m3.1.1.4.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.SSS3.p7.3.m3.1b"><apply id="S7.SS1.SSS3.p7.3.m3.1.1.cmml" xref="S7.SS1.SSS3.p7.3.m3.1.1"><times id="S7.SS1.SSS3.p7.3.m3.1.1.1.cmml" xref="S7.SS1.SSS3.p7.3.m3.1.1.1"></times><cn id="S7.SS1.SSS3.p7.3.m3.1.1.2.cmml" type="integer" xref="S7.SS1.SSS3.p7.3.m3.1.1.2">748</cn><ci id="S7.SS1.SSS3.p7.3.m3.1.1.3.cmml" xref="S7.SS1.SSS3.p7.3.m3.1.1.3">_</ci><cn id="S7.SS1.SSS3.p7.3.m3.1.1.4.cmml" type="integer" xref="S7.SS1.SSS3.p7.3.m3.1.1.4">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.SSS3.p7.3.m3.1c">748\_15</annotation></semantics></math>(서로 다른 분할을 갖는 동일한 숫자 부분 문자열)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib361" title="">361</a>]</cite>로 토큰화될 수 있다. 비교로서, 숫자에 대한 디지트 기반 토큰화는 이러한 불일치를 피할 수 있고, 따라서 LLM의 수치 계산 능력을 향상시킬 수 있다.</p>
</div>
<div id="S7.SS1.SSS3.1.p1" class="ltx_para ltx_noindent ltx_align_center">
<svg id="S7.SS1.SSS3.1.p1.pic1" class="ltx_picture" height="178.23" overflow="visible" version="1.1" width="276"><g transform="translate(0,178.23) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00008C" fill-opacity="1.0"><path d="M 0 5.91 L 0 172.33 C 0 175.59 2.64 178.23 5.91 178.23 L 270.1 178.23 C 273.36 178.23 276 175.59 276 172.33 L 276 5.91 C 276 2.64 273.36 0 270.1 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 154.12 L 274.04 154.12 L 274.04 5.91 C 274.04 3.73 272.27 1.97 270.1 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 160.03)"><foreignObject width="232.7" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S7.SS1.SSS3.1.p1.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS3.1.p1.pic1.1.1.1.1.1.1" class="ltx_p">Numerical Computation</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="232.7" height="128.53" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S7.SS1.SSS3.1.p1.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:168.2pt;">
<span id="S7.SS1.SSS3.1.p1.pic1.2.2.2.1.1.1" class="ltx_p">LLMs face difficulties in numerical computation, especially for the symbols that are seldom encountered during pre-training.
In addition to using mathematical tools, tokenizing digits into individual tokens is also an effective design choice for improving the arithmetic ability of LLMs.</span>
</span></foreignObject></g></g></svg>
</div>
</section>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span><span id="S7.SS2.1.1" class="ltx_text ltx_font_italic">Advanced Ability</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p1.1">LLM은 위의 기본 평가 과제 외에도 평가에 특별한 고려가 필요한 몇 가지 우수한 능력도 보인다. 이 부분에서 우리는 인간의 정렬, 외부 환경과의 상호 작용, 도구 조작을 포함한 몇 가지 대표적인 고급 능력과 그에 상응하는 평가 접근법에 대해 논의한다. 다음으로 이러한 고급 능력에 대해 자세히 논의합니다.</p>
</div>
<section id="S7.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.1 </span>Human Alignment</h4>

<div id="S7.SS2.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS2.SSS1.p1.1">LLM은 인간 가치와 요구 사항인 <em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS1.p1.1.1">i.e.,</em> 인간 정렬을 잘 준수할 수 있으며, 이는 실제 응용 프로그램에서 LLM을 광범위하게 사용하기 위한 핵심 기능이다.</p>
</div>
<div id="S7.SS2.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS2.SSS1.p2.1">이 능력을 평가하기 위해 기존 연구에서는 유용성, 정직성 및 안전성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib368" title="">368</a>, <a class="ltx_ref" href="#bib.bib46" title="">46</a>, <a class="ltx_ref" href="#bib.bib170" title="">170</a>]</cite>와 같은 인간 정렬의 여러 기준을 고려한다. 도움 및 정직성을 위해, 적대적 질문 응답 태스크(<em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS1.p2.1.1">e.g.,</em>TruthfulQA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib556" title="">556</a>]</cite>)는 텍스트에서 가능한 거짓을 탐지하는 LLM 능력을 조사하는 데 활용될 수 있다. 또한, 무해성은 기존의 여러 벤치마크인 <em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS1.p2.1.2">e.g.,</em> CrowS-Pairs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib603" title="">603</a>]</cite> 및 Winogender <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib604" title="">604</a>]</cite>에 의해서도 평가될 수 있다. 위의 데이터 세트를 사용한 자동 평가에도 불구하고, 인간 평가는 여전히 LLM의 인간 정렬 능력을 효과적으로 테스트하는 보다 직접적인 방법이다. OpenAI는 위험 콘텐츠 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>를 접했을 때 GPT-4의 행동을 평가하고 개선하기 위해 AI 위험과 관련된 도메인의 많은 전문가를 초대한다. 또한, 인간 정렬의 다른 측면(<em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS1.p2.1.3">e.g.,</em> truthfulness)에 대해, 몇몇 연구는 특정 명령을 사용하고 주석 프로세스를 안내하기 위해 주석 규칙을 고안하는 것을 제안한다. 경험적 연구에 따르면 이러한 전략은 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib170" title="">170</a>]</cite>의 인간 정렬 능력을 크게 향상시킬 수 있다. 예를 들어, 전문가와의 상호 작용을 통해 수집된 데이터에 대한 정렬 튜닝 후, GPT-4가 민감하거나 허용되지 않는 프롬프트를 다룰 때 GPT-4의 잘못된 동작 속도가 크게 감소될 수 있다. 또한, 고품질 사전 훈련 데이터는 정렬 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>에 필요한 노력을 줄일 수 있다. 예를 들어, Galactica는 과학 말뭉치 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite>에서 덜 편향된 내용으로 인해 잠재적으로 더 무해하다.</p>
</div>
</section>
<section id="S7.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.2 </span>Interaction with External Environment</h4>

<div id="S7.SS2.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS2.SSS2.p1.1">표준 평가 작업 외에도 LLMs은 외부 환경으로부터 피드백을 받고 행동 지침에 따라 행동을 수행할 수 있는 능력을 가지고 있다. <em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS2.p1.1.1">e.g.,</em> 자연어로 액션 플랜을 생성하여 에이전트를 조작할 수 있는</cite idx=0></cite>. 이러한 능력은 또한 상세하고 매우 현실적인 액션 플랜을 생성할 수 있는 LLM에서 출현하는 반면, 더 작은 모델(<em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS2.p1.1.2">e.g.,</em>GPT-2)은 더 짧거나 무의미한 플랜을 생성하는 경향이 있다.</p>
</div>
<div id="S7.SS2.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS2.SSS2.p2.1">이 능력을 테스트하기 위해 몇 가지 구현된 AI 환경과 벤치마크를 평가에 사용할 수 있으며 다음과 같이 설명한다. VirtualHome<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib606" title="">606</a>]</cite>는 청소, 요리 등의 가사 작업을 위한 3D 시뮬레이터를 구축하며, 에이전트는 LLMs에 의해 생성된 자연어 동작을 실행할 수 있다. ALFRED <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib608" title="">608</a>]</cite>는 LLM이 구성 목표를 달성하도록 요구하는 더 도전적인 작업을 포함한다. BEHAVIOR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib607" title="">607</a>]</cite>는 시뮬레이션 환경에서 일상적인 집안일에 초점을 맞추고 복잡한 솔루션, <em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS2.p2.1.1">e.g.,</em> change the internal status of objects. 가정 작업과 같은 제한된 환경 외에도, 한 줄의 연구 작업은 마인크래프트 및 인터넷 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib696" title="">696</a>, <a class="ltx_ref" href="#bib.bib697" title="">697</a>]</cite>와 같은 개방형 환경을 탐구하기 위한 LLM 기반 에이전트의 숙련도를 조사한다. 보이저<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib697" title="">697</a>]</cite>는 LLM이 환경의 피드백을 기반으로 새로운 기술을 지속적으로 습득할 수 있도록 하는 자동 커리큘럼 모듈을 소개한다. GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib696" title="">696</a>]</cite>는 LLM 기반의 마인크래프트에서 인터페이스의 작업 분해, 계획 및 호출을 통해 다양한 과제를 해결하는 데 중점을 둔다. 생성된 액션 플랜 또는 태스크 완성도를 기반으로 기존 작업은 정규 메트릭(<em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS2.p2.1.2">e.g.,</em> 생성된 액션 플랜의 실행성 및 정확성)을 벤치마크에서 채택하거나 실제 실험을 직접 수행하고 성공률<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib698" title="">698</a>]</cite>를 측정하여 이러한 능력을 평가한다. LLM은 외부 환경과 상호 작용하고 정확한 액션 플랜을 생성할 수 있는 것으로 나타났다. 최근에는 LLMs의 상호 작용 능력을 향상시키기 위한 몇 가지 개선 방법이 제안되었는데, <em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS2.p2.1.3">e.g.,</em> design code-like prompts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib530" title="">530</a>]</cite> and providing real-world grounding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib698" title="">698</a>]</cite>이다.</p>
</div>
<div id="S7.SS2.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S7.SS2.SSS2.p3.1">또한, 최근 연구에서는 시뮬레이션 환경 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib533" title="">533</a>, <a class="ltx_ref" href="#bib.bib700" title="">700</a>, <a class="ltx_ref" href="#bib.bib701" title="">701</a>]</cite>에서 LLMs을 기반으로 하는 멀티 에이전트 협업도 탐색하고 있다. 이러한 연구는 모래상자 환경에서 관찰, 계획 및 기억으로 여러 LLM 기반 에이전트를 인스턴스화하여 인간의 사회적 행동을 시뮬레이션한다. 통제된 평가에서 탐색, 계획, 사고에 대한 생성적 에이전트의 능력은 인터뷰와 같은 방식으로 인간에 의해 평가된다. 또한, 그들은 또한 긴급한 사회적 행동을 조사하기 위해 시뮬레이션된 환경 내에서 여러 에이전트에 대한 기술 측정을 수행한다.</p>
</div>
</section>
<section id="S7.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.3 </span>Tool Manipulation</h4>

<div id="S7.SS2.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS2.SSS3.p1.1">복잡한 문제를 해결할 때 LLM은 필요하다고 판단되면 외부 도구로 눈을 돌릴 수 있다. API 호출로 사용 가능한 도구를 캡슐화함으로써 기존 작업에는 다양한 외부 도구인 <em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS3.p1.1.1">e.g.,</em> search engine <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>, calculator <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>, compiler <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib443" title="">443</a>]</cite>가 포함되어 여러 특정 작업에 대한 LLM의 성능을 향상시켰다. 최근 OpenAI는 언어 모델링을 넘어 LLM에 보다 넓은 용량을 탑재할 수 있는 ChatGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib665" title="">665</a>]</cite>에서 플러그인 사용을 지원하고 있다. 예를 들어, 웹 브라우저 플러그인은 ChatGPT가 새로운 정보에 액세스할 수 있게 한다. 또한, 타사 플러그인을 통합하는 것은 LLM을 기반으로 하는 애플리케이션의 번영한 생태계를 만드는 데 특히 중요하다.</p>
</div>
<div id="S7.SS2.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS2.SSS3.p2.1">도구 조작의 능력을 조사하기 위해, 기존의 작업은 대부분 수학적 문제 해결(<em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS3.p2.1.1">e.g.,</em> GSM8k <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite> and SVAMP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib592" title="">592</a>]</cite>) 또는 지식 질의 응답(<em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS3.p2.1.2">e.g.,</em>TruthfulQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib556" title="">556</a>]</cite>)과 같은 평가를 위한 복잡한 추론 작업을 채택하고 있으며, 여기서 도구의 성공적인 활용은 LLM이 수행할 수 없는 필수 기술을 향상시키는데 매우 중요하다(<em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS3.p2.1.3">e.g.,</em> numerical calculation). 이러한 방식으로 이러한 작업에 대한 평가된 성능은 도구 조작에서 LLM의 능력을 반영할 수 있다. LLM이 도구를 활용하도록 가르치기 위해 기존 연구에서는 도구 활용에 대한 시뮬레이션 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib693" title="">693</a>, <a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>에서 LLM을 이끌어내기 위해 컨텍스트에서 도구를 사용하는 예제를 추가하거나 LLM을 미세 조정한다. 도구들의 도움으로, LLMs는 그들이 잘하지 못하는 이슈들, <em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS3.p2.1.4">e.g.,</em> 방정식 계산 및 적시에 질문들에 답하기 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>, <a class="ltx_ref" href="#bib.bib448" title="">448</a>]</cite>를 더 다룰 수 있게 되었다. 그러나 사용 가능한 도구의 수가 증가함에 따라 LLM의 제한된 컨텍스트 길이는 광범위한 도구 API를 설명하고 입증하는 데 어려움을 겪을 수 있다. 이 문제를 해결하기 위해 기존 작업은 관련 도구의 사용 또는 도구 정보를 삽입 공간 [cite idx=6></cite>] 내에서 토큰으로 인코딩합니다.</p>
</div>
<div id="S7.SS2.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S7.SS2.SSS3.p3.1">LLM은 인간이 개발한 기존 도구 외에도 특정 작업에 대한 도구를 자율적으로 만들 수 있는 능력을 가지고 있다. 이를 통해 모델은 이러한 자체 제작 도구를 독립적으로 탐색하고 조작할 수 있으므로 광범위한 실제 작업을 해결하는 데 있어 자율 탐색의 잠재력을 확장할 수 있다.</p>
</div>
<div id="S7.SS2.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S7.SS2.SSS3.p4.1"><em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS3.p4.1.1">Summary</em>. 위의 세 가지 능력은 인간의 가치와 선호에 순응(인간 정렬), 현실 세계 시나리오에서 적절하게 행동(외부 환경과의 상호 작용), 능력 범위 확장(도구 조작) 등 LLM의 실제 수행에 큰 가치가 있다. 위의 세 가지 고급 능력 외에도 LLM은 일부 작업과 특별히 관련된 다른 능력도 보여줄 수 있다(<em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS3.p4.1.2">e.g.,</em> data annotation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib486" title="">486</a>]</cite>). 또는 학습 메커니즘(<em class="ltx_emph ltx_font_italic" id="S7.SS2.SSS3.p4.1.3">e.g.,</em> self-improvement <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib706" title="">706</a>]</cite>). 이러한 새롭게 부상하는 능력을 발견하고 측정하고 평가하여 LLM을 더 잘 활용하고 개선할 수 있는 열린 방향이 될 것이다.</p>
</div>
<figure id="S7.T15" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE XV:</span>기존 평가 작업의 범주. "장군"은 평가가 여러 능력의 전반적인 수행에 초점을 맞춘다는 것을 의미한다. 평가된 능력은 Section <a class="ltx_ref" href="#S7.SS1" title="7.1 Basic Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.1</span></a> 및 <a class="ltx_ref" href="#S7.SS2" title="7.2 Advanced Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.2</span></a>에서 언급된 대표적인 기본 능력 및 고급 능력에 한정되지 않는다.</figcaption>
<table id="S7.T15.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S7.T15.1.1" class="ltx_tr">
<td id="S7.T15.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S7.T15.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Method</span></td>
<td id="S7.T15.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S7.T15.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Evaluation</span></td>
<td id="S7.T15.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S7.T15.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model Types</span></td>
<td id="S7.T15.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S7.T15.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Abilities/Domain</span></td>
<td id="S7.T15.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S7.T15.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Data Source</span></td>
</tr>
<tr id="S7.T15.1.2" class="ltx_tr">
<td id="S7.T15.1.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="26"><span id="S7.T15.1.2.1.1" class="ltx_text" style="font-size:80%;">Benchmark</span></td>
<td id="S7.T15.1.2.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S7.T15.1.2.2.1" class="ltx_text" style="font-size:80%;">MMLU&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.2.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib364" title="" class="ltx_ref">364</a><span id="S7.T15.1.2.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T15.1.2.3.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T15.1.2.4.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T15.1.2.5.1" class="ltx_text" style="font-size:80%;">Human exam/practice</span></td>
</tr>
<tr id="S7.T15.1.3" class="ltx_tr">
<td id="S7.T15.1.3.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.3.1.1" class="ltx_text" style="font-size:80%;">BIG-bench&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.3.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib70" title="" class="ltx_ref">70</a><span id="S7.T15.1.3.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.3.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.3.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.3.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.3.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.3.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.3.4.1" class="ltx_text" style="font-size:80%;">Human annotation</span></td>
</tr>
<tr id="S7.T15.1.4" class="ltx_tr">
<td id="S7.T15.1.4.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.4.1.1" class="ltx_text" style="font-size:80%;">HELM&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib520" title="" class="ltx_ref">520</a><span id="S7.T15.1.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.4.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.4.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.4.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.4.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.4.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.4.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
<tr id="S7.T15.1.5" class="ltx_tr">
<td id="S7.T15.1.5.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.5.1.1" class="ltx_text" style="font-size:80%;">Open LLM Leaderboard&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.5.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib707" title="" class="ltx_ref">707</a><span id="S7.T15.1.5.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.5.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.5.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.5.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.5.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.5.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.5.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
<tr id="S7.T15.1.6" class="ltx_tr">
<td id="S7.T15.1.6.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.6.1.1" class="ltx_text" style="font-size:80%;">AGIEval&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.6.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib708" title="" class="ltx_ref">708</a><span id="S7.T15.1.6.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.6.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.6.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.6.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.6.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.6.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.6.4.1" class="ltx_text" style="font-size:80%;">Human exam/practice</span></td>
</tr>
<tr id="S7.T15.1.7" class="ltx_tr">
<td id="S7.T15.1.7.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.7.1.1" class="ltx_text" style="font-size:80%;">MMCU&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.7.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib709" title="" class="ltx_ref">709</a><span id="S7.T15.1.7.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.7.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.7.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.7.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.7.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.7.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.7.4.1" class="ltx_text" style="font-size:80%;">Human exam/practice</span></td>
</tr>
<tr id="S7.T15.1.8" class="ltx_tr">
<td id="S7.T15.1.8.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.8.1.1" class="ltx_text" style="font-size:80%;">M3KE&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.8.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib710" title="" class="ltx_ref">710</a><span id="S7.T15.1.8.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.8.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.8.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.8.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.8.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.8.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.8.4.1" class="ltx_text" style="font-size:80%;">Human exam/practice</span></td>
</tr>
<tr id="S7.T15.1.9" class="ltx_tr">
<td id="S7.T15.1.9.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.9.1.1" class="ltx_text" style="font-size:80%;">C-Eval&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.9.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib711" title="" class="ltx_ref">711</a><span id="S7.T15.1.9.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.9.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.9.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.9.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.9.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.9.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.9.4.1" class="ltx_text" style="font-size:80%;">Human exam/practice</span></td>
</tr>
<tr id="S7.T15.1.10" class="ltx_tr">
<td id="S7.T15.1.10.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.10.1.1" class="ltx_text" style="font-size:80%;">Xiezhi&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.10.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib712" title="" class="ltx_ref">712</a><span id="S7.T15.1.10.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.10.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.10.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.10.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.10.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.10.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.10.4.1" class="ltx_text" style="font-size:80%;">Human exam/practice</span></td>
</tr>
<tr id="S7.T15.1.11" class="ltx_tr">
<td id="S7.T15.1.11.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.11.1.1" class="ltx_text" style="font-size:80%;">OpenCompass&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.11.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib713" title="" class="ltx_ref">713</a><span id="S7.T15.1.11.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.11.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.11.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.11.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.11.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.11.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.11.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
<tr id="S7.T15.1.12" class="ltx_tr">
<td id="S7.T15.1.12.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.12.1.1" class="ltx_text" style="font-size:80%;">Chain-of-Thought Hub&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.12.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib714" title="" class="ltx_ref">714</a><span id="S7.T15.1.12.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.12.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.12.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.12.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.12.3.1" class="ltx_text" style="font-size:80%;">General</span></td>
<td id="S7.T15.1.12.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.12.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
<tr id="S7.T15.1.13" class="ltx_tr">
<td id="S7.T15.1.13.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.13.1.1" class="ltx_text" style="font-size:80%;">KoLA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.13.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib715" title="" class="ltx_ref">715</a><span id="S7.T15.1.13.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.13.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.13.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.13.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.13.3.1" class="ltx_text" style="font-size:80%;">Knowledge utilization</span></td>
<td id="S7.T15.1.13.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.13.4.1" class="ltx_text" style="font-size:80%;">Web</span></td>
</tr>
<tr id="S7.T15.1.14" class="ltx_tr">
<td id="S7.T15.1.14.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.14.1.1" class="ltx_text" style="font-size:80%;">ARB&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.14.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib716" title="" class="ltx_ref">716</a><span id="S7.T15.1.14.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.14.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.14.2.1" class="ltx_text" style="font-size:80%;">Fine-tuned</span></td>
<td id="S7.T15.1.14.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.14.3.1" class="ltx_text" style="font-size:80%;">Complex reasoning</span></td>
<td id="S7.T15.1.14.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.14.4.1" class="ltx_text" style="font-size:80%;">Human exam/practice</span></td>
</tr>
<tr id="S7.T15.1.15" class="ltx_tr">
<td id="S7.T15.1.15.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.15.1.1" class="ltx_text" style="font-size:80%;">APIBench&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.15.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib717" title="" class="ltx_ref">717</a><span id="S7.T15.1.15.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.15.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.15.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.15.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.15.3.1" class="ltx_text" style="font-size:80%;">Tool manipulation</span></td>
<td id="S7.T15.1.15.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.15.4.1" class="ltx_text" style="font-size:80%;">Web</span></td>
</tr>
<tr id="S7.T15.1.16" class="ltx_tr">
<td id="S7.T15.1.16.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.16.1.1" class="ltx_text" style="font-size:80%;">APIBank&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.16.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib718" title="" class="ltx_ref">718</a><span id="S7.T15.1.16.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.16.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.16.2.1" class="ltx_text" style="font-size:80%;">Fine-tuned</span></td>
<td id="S7.T15.1.16.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.16.3.1" class="ltx_text" style="font-size:80%;">Tool manipulation</span></td>
<td id="S7.T15.1.16.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.16.4.1" class="ltx_text" style="font-size:80%;">Synthesis</span></td>
</tr>
<tr id="S7.T15.1.17" class="ltx_tr">
<td id="S7.T15.1.17.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.17.1.1" class="ltx_text" style="font-size:80%;">ToolAlpaca&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.17.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib719" title="" class="ltx_ref">719</a><span id="S7.T15.1.17.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.17.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.17.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.17.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.17.3.1" class="ltx_text" style="font-size:80%;">Tool manipulation</span></td>
<td id="S7.T15.1.17.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.17.4.1" class="ltx_text" style="font-size:80%;">Synthesis</span></td>
</tr>
<tr id="S7.T15.1.18" class="ltx_tr">
<td id="S7.T15.1.18.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.18.1.1" class="ltx_text" style="font-size:80%;">T-Bench&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.18.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib720" title="" class="ltx_ref">720</a><span id="S7.T15.1.18.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.18.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.18.2.1" class="ltx_text" style="font-size:80%;">Fine-tuned</span></td>
<td id="S7.T15.1.18.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.18.3.1" class="ltx_text" style="font-size:80%;">Tool manipulation</span></td>
<td id="S7.T15.1.18.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.18.4.1" class="ltx_text" style="font-size:80%;">Synthesis</span></td>
</tr>
<tr id="S7.T15.1.19" class="ltx_tr">
<td id="S7.T15.1.19.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.19.1.1" class="ltx_text" style="font-size:80%;">ToolBench&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.19.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib721" title="" class="ltx_ref">721</a><span id="S7.T15.1.19.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.19.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.19.2.1" class="ltx_text" style="font-size:80%;">Fine-tuned</span></td>
<td id="S7.T15.1.19.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.19.3.1" class="ltx_text" style="font-size:80%;">Tool manipulation</span></td>
<td id="S7.T15.1.19.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.19.4.1" class="ltx_text" style="font-size:80%;">Synthesis</span></td>
</tr>
<tr id="S7.T15.1.20" class="ltx_tr">
<td id="S7.T15.1.20.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.20.1.1" class="ltx_text" style="font-size:80%;">BOLAA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.20.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib722" title="" class="ltx_ref">722</a><span id="S7.T15.1.20.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.20.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.20.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.20.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.20.3.1" class="ltx_text" style="font-size:80%;">Environment interaction</span></td>
<td id="S7.T15.1.20.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.20.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
<tr id="S7.T15.1.21" class="ltx_tr">
<td id="S7.T15.1.21.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.21.1.1" class="ltx_text" style="font-size:80%;">AgentBench&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.21.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib723" title="" class="ltx_ref">723</a><span id="S7.T15.1.21.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.21.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.21.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.21.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.21.3.1" class="ltx_text" style="font-size:80%;">Environment interaction</span></td>
<td id="S7.T15.1.21.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.21.4.1" class="ltx_text" style="font-size:80%;">Human annotation/Synthesis</span></td>
</tr>
<tr id="S7.T15.1.22" class="ltx_tr">
<td id="S7.T15.1.22.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.22.1.1" class="ltx_text" style="font-size:80%;">HaluEval&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.22.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib602" title="" class="ltx_ref">602</a><span id="S7.T15.1.22.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.22.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.22.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.22.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.22.3.1" class="ltx_text" style="font-size:80%;">Human alignment</span></td>
<td id="S7.T15.1.22.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.22.4.1" class="ltx_text" style="font-size:80%;">Human annotation/Synthesis</span></td>
</tr>
<tr id="S7.T15.1.23" class="ltx_tr">
<td id="S7.T15.1.23.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.23.1.1" class="ltx_text" style="font-size:80%;">PromptBench&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.23.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib724" title="" class="ltx_ref">724</a><span id="S7.T15.1.23.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.23.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.23.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.23.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.23.3.1" class="ltx_text" style="font-size:80%;">Robustness</span></td>
<td id="S7.T15.1.23.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.23.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
<tr id="S7.T15.1.24" class="ltx_tr">
<td id="S7.T15.1.24.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.24.1.1" class="ltx_text" style="font-size:80%;">HumanEval&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.24.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib105" title="" class="ltx_ref">105</a><span id="S7.T15.1.24.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.24.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.24.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.24.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.24.3.1" class="ltx_text" style="font-size:80%;">Code synthesis</span></td>
<td id="S7.T15.1.24.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.24.4.1" class="ltx_text" style="font-size:80%;">Human annotation</span></td>
</tr>
<tr id="S7.T15.1.25" class="ltx_tr">
<td id="S7.T15.1.25.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.25.1.1" class="ltx_text" style="font-size:80%;">MultiMedQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.25.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib356" title="" class="ltx_ref">356</a><span id="S7.T15.1.25.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.25.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.25.2.1" class="ltx_text" style="font-size:80%;">Specialized</span></td>
<td id="S7.T15.1.25.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.25.3.1" class="ltx_text" style="font-size:80%;">Healthcare</span></td>
<td id="S7.T15.1.25.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.25.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
<tr id="S7.T15.1.26" class="ltx_tr">
<td id="S7.T15.1.26.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.26.1.1" class="ltx_text" style="font-size:80%;">FLUE&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.26.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib725" title="" class="ltx_ref">725</a><span id="S7.T15.1.26.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.26.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.26.2.1" class="ltx_text" style="font-size:80%;">Specialized</span></td>
<td id="S7.T15.1.26.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.26.3.1" class="ltx_text" style="font-size:80%;">Finance</span></td>
<td id="S7.T15.1.26.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.26.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
<tr id="S7.T15.1.27" class="ltx_tr">
<td id="S7.T15.1.27.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.27.1.1" class="ltx_text" style="font-size:80%;">LegalBench&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.27.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib726" title="" class="ltx_ref">726</a><span id="S7.T15.1.27.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.27.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.27.2.1" class="ltx_text" style="font-size:80%;">Specialized</span></td>
<td id="S7.T15.1.27.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.27.3.1" class="ltx_text" style="font-size:80%;">Legal</span></td>
<td id="S7.T15.1.27.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.27.4.1" class="ltx_text" style="font-size:80%;">Human annotation</span></td>
</tr>
<tr id="S7.T15.1.28" class="ltx_tr">
<td id="S7.T15.1.28.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T15.1.28.1.1" class="ltx_text" style="font-size:80%;">Human</span></td>
<td id="S7.T15.1.28.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S7.T15.1.28.2.1" class="ltx_text" style="font-size:80%;">Chatbot Arena&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.28.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib727" title="" class="ltx_ref">727</a><span id="S7.T15.1.28.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.28.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T15.1.28.3.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned/Specialized</span></td>
<td id="S7.T15.1.28.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T15.1.28.4.1" class="ltx_text" style="font-size:80%;">Human Alignment</span></td>
<td id="S7.T15.1.28.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T15.1.28.5.1" class="ltx_text" style="font-size:80%;">Human annotation</span></td>
</tr>
<tr id="S7.T15.1.29" class="ltx_tr">
<td id="S7.T15.1.29.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.29.1.1" class="ltx_text" style="font-size:80%;">SciBench&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.29.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib728" title="" class="ltx_ref">728</a><span id="S7.T15.1.29.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.29.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.29.2.1" class="ltx_text" style="font-size:80%;">Fine-tuned</span></td>
<td id="S7.T15.1.29.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.29.3.1" class="ltx_text" style="font-size:80%;">Complex reasoning</span></td>
<td id="S7.T15.1.29.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.29.4.1" class="ltx_text" style="font-size:80%;">Human exam/practice</span></td>
</tr>
<tr id="S7.T15.1.30" class="ltx_tr">
<td id="S7.T15.1.30.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="5"><span id="S7.T15.1.30.1.1" class="ltx_text" style="font-size:80%;">Model</span></td>
<td id="S7.T15.1.30.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S7.T15.1.30.2.1" class="ltx_text" style="font-size:80%;">AlpacaEval&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.30.2.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib729" title="" class="ltx_ref">729</a><span id="S7.T15.1.30.2.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.30.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T15.1.30.3.1" class="ltx_text" style="font-size:80%;">Fine-tuned</span></td>
<td id="S7.T15.1.30.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T15.1.30.4.1" class="ltx_text" style="font-size:80%;">Instruction following</span></td>
<td id="S7.T15.1.30.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T15.1.30.5.1" class="ltx_text" style="font-size:80%;">Synthesis</span></td>
</tr>
<tr id="S7.T15.1.31" class="ltx_tr">
<td id="S7.T15.1.31.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.31.1.1" class="ltx_text" style="font-size:80%;">MT-bench&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.31.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib727" title="" class="ltx_ref">727</a><span id="S7.T15.1.31.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.31.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.31.2.1" class="ltx_text" style="font-size:80%;">Fine-tuned</span></td>
<td id="S7.T15.1.31.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.31.3.1" class="ltx_text" style="font-size:80%;">Human alignment</span></td>
<td id="S7.T15.1.31.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.31.4.1" class="ltx_text" style="font-size:80%;">Human annotation</span></td>
</tr>
<tr id="S7.T15.1.32" class="ltx_tr">
<td id="S7.T15.1.32.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.32.1.1" class="ltx_text" style="font-size:80%;">TrustGPT&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.32.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib730" title="" class="ltx_ref">730</a><span id="S7.T15.1.32.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.32.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.32.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.32.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.32.3.1" class="ltx_text" style="font-size:80%;">Human alignment</span></td>
<td id="S7.T15.1.32.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.32.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
<tr id="S7.T15.1.33" class="ltx_tr">
<td id="S7.T15.1.33.1" class="ltx_td ltx_align_center">
<span id="S7.T15.1.33.1.1" class="ltx_text" style="font-size:80%;">LMExamQA&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.33.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib731" title="" class="ltx_ref">731</a><span id="S7.T15.1.33.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.33.2" class="ltx_td ltx_align_center"><span id="S7.T15.1.33.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.33.3" class="ltx_td ltx_align_center"><span id="S7.T15.1.33.3.1" class="ltx_text" style="font-size:80%;">Knowledge utilization</span></td>
<td id="S7.T15.1.33.4" class="ltx_td ltx_align_center"><span id="S7.T15.1.33.4.1" class="ltx_text" style="font-size:80%;">Synthesis</span></td>
</tr>
<tr id="S7.T15.1.34" class="ltx_tr">
<td id="S7.T15.1.34.1" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S7.T15.1.34.1.1" class="ltx_text" style="font-size:80%;">ChatEval&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T15.1.34.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib732" title="" class="ltx_ref">732</a><span id="S7.T15.1.34.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S7.T15.1.34.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T15.1.34.2.1" class="ltx_text" style="font-size:80%;">Base/Fine-tuned</span></td>
<td id="S7.T15.1.34.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T15.1.34.3.1" class="ltx_text" style="font-size:80%;">Knowledge utilization</span></td>
<td id="S7.T15.1.34.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S7.T15.1.34.4.1" class="ltx_text" style="font-size:80%;">Benchmark collection</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span><span id="S7.SS3.1.1" class="ltx_text ltx_font_italic">Benchmarks and Evaluation Approaches</span>
</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS3.p1.1">위에서 우리는 LLM의 기본 능력과 고급 능력에 대해 논의했다. 다음으로 기존의 평가 벤치마크를 소개하고 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib733" title="">733</a>, <a class="ltx_ref" href="#bib.bib734" title="">734</a>]</cite>에 접근한다.</p>
</div>
<section id="S7.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.1 </span>Comprehensive Evaluation Benchmarks</h4>

<div id="S7.SS3.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS1.p1.1">최근 LLM의 평가를 위한 여러 포괄적인 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib364" title="">364</a>, <a class="ltx_ref" href="#bib.bib70" title="">70</a>, <a class="ltx_ref" href="#bib.bib520" title="">520</a>]</cite>가 출시되었다. 이 부분에서는 널리 사용되는 여러 벤치마크인 <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS1.p1.1.1">i.e.,</em> MMLU, BIG-bench, HELM 및 일련의 인간 시험 벤치마크를 소개한다.</p>
</div>
<div id="S7.SS3.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS1.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS1.p2.1.m1.1"><semantics id="S7.SS3.SSS1.p2.1.m1.1a"><mo id="S7.SS3.SSS1.p2.1.m1.1.1" xref="S7.SS3.SSS1.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS1.p2.1.m1.1b"><ci id="S7.SS3.SSS1.p2.1.m1.1.1.cmml" xref="S7.SS3.SSS1.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS1.p2.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS1.p2.1.1">MMLU</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib364" title="">364</a>]</cite>는 수학 및 컴퓨터 과학에서 인문 및 사회 과학에 이르기까지 광범위한 지식 영역을 포괄하는 다중 작업 지식 이해의 대규모 평가를 위한 다목적 벤치마크이다. 이러한 업무의 어려움은 기초부터 고급까지 다양하다. 기존 연구에서 볼 수 있듯이 LLM은 모델 크기에서 스케일링 법칙을 보여주는 이 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>, <a class="ltx_ref" href="#bib.bib35" title="">35</a>, <a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>에서 대부분 작은 모델을 상당한 차이로 능가한다. 보다 최근에 GPT-4는 MMLU에서 주목할 만한 기록(5샷 설정에서 86.4%)을 달성했는데, 이는 이전의 최신 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>보다 훨씬 낫다.</p>
</div>
<div id="S7.SS3.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS1.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS1.p3.1.m1.1"><semantics id="S7.SS3.SSS1.p3.1.m1.1a"><mo id="S7.SS3.SSS1.p3.1.m1.1.1" xref="S7.SS3.SSS1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS1.p3.1.m1.1b"><ci id="S7.SS3.SSS1.p3.1.m1.1.1.cmml" xref="S7.SS3.SSS1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS1.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS1.p3.1.1">BIG-bench</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib70" title="">70</a>]</cite>는 다양한 측면에서 기존 LLMs를 프로브하도록 의도된 협업 벤치마크이다. 언어학, 아동기 발달, 수학, 상식 추론, 생물학, 물리학, 사회적 편견, 소프트웨어 개발 등을 포함한 광범위한 주제를 포함하는 204개의 과제로 구성된다. 모델 크기를 확장함으로써 LLMs은 BIG-bench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>의 65% 태스크에서 소수의 샷 설정에서도 평균 인간 성능을 능가할 수 있다. 전체 벤치마크의 높은 평가 비용을 고려하여, 경량 벤치마크 BIG-bench-Lite가 제안되었는데, 이는 BIG-bench로부터 24개의 작지만 다양하고 도전적인 과제를 포함하고 있다. 또한, BIG-bench hard (BBH) 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib365" title="">365</a>]</cite>는 LLMs가 인간에 비해 열등한 성능을 보이는 도전적인 태스크를 선택하여 LLMs의 현재 해결 불가능한 태스크를 조사하는 데 집중하기 위해 제안되었다. BBH가 더 어려워지기 때문에, 소형 모델들은 대부분 랜덤에 가까운 성능을 달성한다. 비교로서, CoT 프롬프트는 BBH에서 평균 인간 성능을 초과하더라도 성능을 향상시키기 위한 단계적 추론을 수행하는 LLM의 능력을 이끌어낼 수 있다.</p>
</div>
<div id="S7.SS3.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS1.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS1.p4.1.m1.1"><semantics id="S7.SS3.SSS1.p4.1.m1.1a"><mo id="S7.SS3.SSS1.p4.1.m1.1.1" xref="S7.SS3.SSS1.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS1.p4.1.m1.1b"><ci id="S7.SS3.SSS1.p4.1.m1.1.1.cmml" xref="S7.SS3.SSS1.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS1.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS1.p4.1.1">HELM</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib520" title="">520</a>]</cite>는 현재 16개의 시나리오와 7개의 범주의 메트릭의 코어 세트를 구현하는 포괄적인 벤치마크이다. 그것은 언어 모델에 대한 전체론적 평가를 수행하는 많은 선행 연구 위에 구축되어 있다. HELM의 실험 결과에서 보듯이 명령어 튜닝은 정확도, 견고성, 공정성 측면에서 LLM의 성능을 지속적으로 높일 수 있다. 또한, 추론 작업을 위해 코드 코퍼스에 사전 훈련된 LLM이 우수한 성능을 보인다.</p>
</div>
<div id="S7.SS3.SSS1.p5" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS1.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS1.p5.1.m1.1"><semantics id="S7.SS3.SSS1.p5.1.m1.1a"><mo id="S7.SS3.SSS1.p5.1.m1.1.1" xref="S7.SS3.SSS1.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS1.p5.1.m1.1b"><ci id="S7.SS3.SSS1.p5.1.m1.1.1.cmml" xref="S7.SS3.SSS1.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS1.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS1.p5.1.1">Human-level test benchmarks</em>은 AGIEval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib708" title="">708</a>]</cite>, MMCU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib709" title="">709</a>]</cite>, M3KE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib710" title="">710</a>]</cite>, C-Eval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib711" title="">711</a>]</cite> 및 Xiezhi <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib712" title="">712</a>]</cite>와 같이 인간을 테스트하기 위해 고안된 질문으로 LLM의 종합적인 능력을 평가하는 것을 목표로 한다. 이러한 벤치마크는 LLM의 일반적인 능력에 대한 포괄적인 평가를 제공하기 위해 광범위한 도메인, 난이도 및 언어를 포함한다. 공개된 모델에 비해 API 서비스를 제공하는 모델(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS1.p5.1.2">e.g.,</em> GPT-4, ChatGPT, Claude)은 이러한 평가 벤치마크에서 공개적으로 사용 가능한 모델에 비해 우수한 성능을 보여준다. 평가에서 가장 우수한 모델로서 GPT-4는 AGIEval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib708" title="">708</a>]</cite>에서 평균 인간 성능을 능가한다. 그러나 여전히 이러한 도전적인 벤치마크에서 최고의 인간 성능보다 뒤처져 있습니다. 따라서 LLM, 특히 공개적으로 액세스할 수 있는 모델의 전반적인 능력을 추가로 향상시킬 수 있는 충분한 여지가 남아 있다.</p>
</div>
<div id="S7.SS3.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS1.p6.1">위의 벤치마크는 LLM의 평가를 위한 다양한 주류 평가 과제와 실제 인간 시험 문제를 다룬다. 또한 다국어 지식 활용을 위한 TyDiQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib735" title="">735</a>]</cite>와 다국어 수학적 추론을 위한 MGSM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib524" title="">524</a>]</cite>와 같이 LLM의 특정 능력을 평가하는 데 중점을 둔 벤치마크가 몇 개 있다. 평가를 수행하기 위해 특정 목표에 따라 적합한 벤치마크를 선택할 수 있다. 또한, 언어 모델 평가 하니스<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib736" title="">736</a>]</cite> 및 OpenAI Evals<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>와 같이 기존 벤치마크에서 LLM을 평가하거나 맞춤형 평가를 위한 새로운 작업을 확장하기 위한 여러 오픈 소스 평가 프레임워크도 있다. 또한, 일부 연구자들은 오픈 LLM 리더보드 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib707" title="">707</a>]</cite>와 같은 기존 LLM 모델의 성능을 비교하기 위해 대표적인 벤치마크를 집계하여 지속적으로 업데이트된 리더보드를 구성하기도 한다. 위의 벤치마크 및 리더보드는 LLM의 기본 및 고급 능력을 입증하는 중요한 참조를 제공한다. <a class="ltx_ref" href="#S7.SS3.SSS2" title="7.3.2 Evaluation Approaches ‣ 7.3 Benchmarks and Evaluation Approaches ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.3.2</span></a> 절에서 평가 접근법에 대한 찬반 논의를 좀 더 깊게 할 것이다.</p>
</div>
</section>
<section id="S7.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.2 </span>Evaluation Approaches</h4>

<div id="S7.SS3.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS2.p1.1">기존 벤치마크를 도입한 후, 이 부분에서 LLM의 성능을 평가하기 위한 기존 평가 접근법을 검토할 것이다. 논의를 정리하기 위해 LLMs를 세 가지 유형으로 분류합니다. <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p1.1.1">base LLMs</em> (사전 훈련된 모델 체크포인트), <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p1.1.2">fine-tuned LLMs</em> (명령어 또는 정렬 미세 조정 모델 체크포인트), 및 <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p1.1.3">특수화된 LLMs</em> (일부 특정 작업 또는 도메인에 대한 적응 모델 체크포인트). 여기서는 LLM의 다른 목적을 구별하기 위해 미세 조정된 LLM과 특수 LLM을 모두 유지한다: 일반 또는 특정 작업 해결사. 세 가지 유형의 LLM을 평가하기 위해 다른 능력과 관련된 LLM 성능을 테스트할 수 있다(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p1.1.4">e.g.,</em> <a class="ltx_ref" href="#S7.SS1" title="7.1 Basic Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.1</span></a> 및 <a class="ltx_ref" href="#S7.SS2" title="7.2 Advanced Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.2</span></a>에서 논의된 바와 같이 기본 또는 고급 능력). 일반적으로 LLM을 평가하는 방법에는 크게 세 가지 접근법이 있는데, 벤치마크 기반 접근법<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib364" title="">364</a>]</cite>, 인간 기반 접근법<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>]</cite>, 모델 기반 접근법<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib729" title="">729</a>]</cite>이다. <표 <a class="ltx_ref" href="#S7.T15" title="TABLE XV ‣ 7.2.3 Tool Manipulation ‣ 7.2 Advanced Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XV</span></a>는 LLM 유형, 평가 접근법 및 테스트된 능력 간의 관계를 보여주는 그림이다. 다음으로, 다양한 유형의 LLM에 대한 평가 접근법에 대해 논의할 것이다.</p>
</div>
<div id="S7.SS3.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS3.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S7.SS3.SSS2.p2.1.1">Evaluation of Base LLMs. </span> Base LLMs는 사전 훈련 직후 획득한 모델 체크포인트를 의미한다. 기본 LLM의 경우 주로 복잡한 추론 및 지식 활용과 같은 기본 능력(섹션<a class="ltx_ref" href="#S7.SS1" title="7.1 Basic Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.1</span></a>)을 조사하는 데 중점을 둔다. 이러한 기본 능력의 대부분은 잘 정의된 작업으로 평가할 수 있기 때문에 벤치마크 기반 접근법이 기본 LLM을 평가하는 데 널리 사용되었다. 다음으로 기본 LLMs에 대한 공통 평가 벤치마크와 평가 절차를 소개한다.</p>
</div>
<div id="S7.SS3.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS2.p3.1.m1.1"><semantics id="S7.SS3.SSS2.p3.1.m1.1a"><mo id="S7.SS3.SSS2.p3.1.m1.1.1" xref="S7.SS3.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS2.p3.1.m1.1b"><ci id="S7.SS3.SSS2.p3.1.m1.1.1.cmml" xref="S7.SS3.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p3.1.1">Common benchmarks. </em> 기본 LLM을 평가하기 위해 일반적인 벤치마크는 객관식 질문과 같은 근접형 문제 형태로 설계된다. 이러한 일반적으로 사용되는 벤치마크는 크게 지식지향 벤치마크와 추론지향 벤치마크의 두 가지로 구분할 수 있다. 지식 지향 벤치마크(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p3.1.2">e.g.,</em> MMLU<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib364" title="">364</a>]</cite> and C-Eval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib711" title="">711</a>]</cite>)는 세계 지식의 능력을 평가하는 것을 목표로 하는 반면, 추론 지향 벤치마크(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p3.1.3">e.g.,</em> GSM8K<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib643" title="">643</a>]</cite>, BBH<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib365" title="">365</a>]</cite> 및 MATH<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib364" title="">364</a>]</cite>)는 복잡한 추론 작업을 해결하는 능력을 평가하는 데 중점을 둔다. 또한 최근에 제안된 일부 벤치마크(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p3.1.4">e.g.,</em>OpenCompass <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib713" title="">713</a>]</cite>)는 포괄적인 비교를 위해 이 두 가지 유형을 결합한다.</p>
</div>
<div id="S7.SS3.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS2.p4.1.m1.1"><semantics id="S7.SS3.SSS2.p4.1.m1.1a"><mo id="S7.SS3.SSS2.p4.1.m1.1.1" xref="S7.SS3.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS2.p4.1.m1.1b"><ci id="S7.SS3.SSS2.p4.1.m1.1.1.cmml" xref="S7.SS3.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p4.1.1">Benchmark based evaluation procedure. </em> 벤치마크 평가를 수행하기 위해, 각각의 문제는 먼저 LLM이 결과 텍스트를 생성하기 위한 프롬프트에 포맷될 것이다. 그런 다음 생성된 결과 텍스트를 사람이 작성한 규칙으로 구문 분석하여 예측된 답변을 얻는다. 최종적으로, LLM의 성능은 예측된 답변과 지상-진실 답변을 비교함으로써 정확도와 같은 표준 메트릭을 사용하여 자동으로 계산될 수 있다. 평가 접근법은 소수의 샷 또는 제로 샷 설정에서 수행될 수 있으며, 이는 상이한 평가 결과 또는 순위를 초래할 수 있다. 베이스 LLM은 (상대적으로 약한 태스크 일반화 능력으로) 지시 미세 조정되지 않았기 때문에, 종종 소수의 샷 설정이 평가에 더 적합하다. 일부 복잡한 추론 태스크의 경우, CoT 프롬프트는 또한 평가 동안 용량을 완전히 나타내기 위해 사용될 필요가 있다. 또 다른 메모는 이 평가 접근법이 미세 조정된 LLM의 능력을 평가하는 데에도 적용될 수 있다는 것이다. 실제로 여러 리더보드(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p4.1.2">e.g.,</em> Open LLM Leaderboard <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib707" title="">707</a>]</cite>)는 기본 LLM과 미세 조정 LLM을 모두 평가하는 이 접근법에 기반한다.</p>
</div>
<div id="S7.SS3.SSS2.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS3.SSS2.p5.1"><span class="ltx_text ltx_font_bold" id="S7.SS3.SSS2.p5.1.1">Evaluation of Fine-tuned LLMs. 이 부분의 미세 조정된 LLM은 사전 훈련된 모델 가중치<span class="ltx_note ltx_role_footnote" id="footnote47"><sup class="ltx_note_mark">47</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">47</sup><span class="ltx_tag ltx_tag_note">47</span>In some cases, it is also called <em class="ltx_emph ltx_font_italic" id="footnote47.1">chat models</em>.</span></span></span>에 기초하여 명령어 튜닝 또는 정렬 튜닝 후에 획득된 모델 체크포인트를 지칭한다. 일반적으로 미세 조정된 LLM은 다양한 능력(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p5.1.2">e.g.,</em> 지식 활용 및 인간 정렬)에 대해 테스트될 것이며, 따라서 이들은 다중 평가 접근법으로 평가되는 것이 일반적이다. 벤치마크 기반 평가 외에도 인간 기반 및 모델 기반 접근법이 미세 조정 LLM의 고급 능력을 평가하는 데 널리 사용되었다. 다음으로 두 가지 평가 방법에 대해 소개하고자 한다.</p>
</div>
<div id="S7.SS3.SSS2.p6" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS2.p6.1.m1.1"><semantics id="S7.SS3.SSS2.p6.1.m1.1a"><mo id="S7.SS3.SSS2.p6.1.m1.1.1" xref="S7.SS3.SSS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS2.p6.1.m1.1b"><ci id="S7.SS3.SSS2.p6.1.m1.1.1.cmml" xref="S7.SS3.SSS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS2.p6.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p6.1.1">Human-based evaluation. </em> 기본 능력에 대한 자동 평가와 달리 인간 평가는 일반적으로 인간 정렬 및 도구 조작과 같은 실제 사용에서 더 많은 요인 또는 능력을 고려한다. 이러한 평가 접근법에서 시험 과제는 보통 개방형 질문의 형태이며, 인간 평가자를 초청하여 LLMs에 의해 생성된 답변의 질에 대한 판단을 하게 된다. 일반적으로, 인간 평가자에 대한 채점 방법에는 쌍별 비교와 단일 응답 채점의 두 가지 주요 유형이 있다. 쌍별 비교에서 동일한 질문을 감안할 때 인간은 다른 모델에서 두 가지 답변을 할당하여 어느 것이 더 나은지 결정하는 반면 단일 응답 등급에서는 한 번에 단일 답변만 채점하면 된다. 예를 들어, HELM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib520" title="">520</a>]</cite>는 사람을 고용하여 요약 및 허위 정보 작업에 대한 단일 응답 등급화를 수행하는 반면, Chatbot Arena<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>]</cite>는 사용자가 두 개의 익명 채팅 LLM과 대화에 참여하고 쌍별 비교 결과를 보고할 수 있는 크라우드소싱 플랫폼을 구축한다.</p>
</div>
<div id="S7.SS3.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS2.p7.1.m1.1"><semantics id="S7.SS3.SSS2.p7.1.m1.1a"><mo id="S7.SS3.SSS2.p7.1.m1.1.1" xref="S7.SS3.SSS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS2.p7.1.m1.1b"><ci id="S7.SS3.SSS2.p7.1.m1.1.1.cmml" xref="S7.SS3.SSS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS2.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p7.1.1">Model-based evaluation. </em> 인간 기반 평가는 비용이 많이 들고 시간이 많이 소요되기 때문에, 일부 연구에서는 ChatGPT 및 GPT-4와 같은 강력한 폐쇄 소스 LLM을 인간 평가자의 대리인으로 활용하는 것을 제안했다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>, <a class="ltx_ref" href="#bib.bib729" title="">729</a>]</cite>. 예를 들어 AlpacaEval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib729" title="">729</a>]</cite>는 명령어 세트를 수집하고 가능한 LLM(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p7.1.2">e.g.,</em> GPT-4)을 판단자로 사용하여 참조 출력에 대한 쌍별 비교를 수행합니다. 또한, MT-bench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>]</cite>는 평가를 위한 멀티턴 문항 세트를 수집하고 ICL 및 CoT와 같은 방법을 통해 LLM 기반 평가자의 신뢰도를 향상시킨다. 인간 평가자와 비교하여 ChatGPT 및 GPT-4와 같은 LLM은 소규모 수공예 및 대규모 크라우드소싱 평가 과제 모두에서 인간과 높은 일치를 달성할 수 있다. 그럼에도 불구하고 이러한 폐쇄 소스 LLM은 액세스가 제한적이며 데이터 누출의 잠재적 위험이 있다. 이를 해결하기 위해 최근 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>]</cite>는 미세 조정 오픈 소스 LLMs(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p7.1.3">e.g.,</em> Vicuna <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>)를 인간 평가자의 점수 데이터를 사용하여 모델 평가자로 탐색했으며, 이는 강력한 폐쇄 소스 LLMs(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p7.1.4">e.g.,</em> GPT-4)와의 격차를 좁혔다.</p>
</div>
<div id="S7.SS3.SSS2.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS3.SSS2.p8.1"><span class="ltx_text ltx_font_bold" id="S7.SS3.SSS2.p8.1.1">Evaluation of Specialized LLMs. </span> 전문화된 LLM은 헬스케어</cite idx=0></cite> 및 금융</cite idx=1></cite>와 같은 일부 도메인 또는 애플리케이션에 특별히 적응된 모델 체크포인트를 의미한다. 특수 작업 해결사로서, 특수 LLM은 일반적인 능력(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p8.1.2">e.g.,</em>복잡한 추론과 같은 기본 능력 및 인간 정렬과 같은 고급 능력)뿐만 아니라 지정된 도메인 또는 애플리케이션과 관련된 특정 능력에도 테스트될 것이다. 이를 위해 대상 도메인 또는 애플리케이션에 맞게 조정된 특정 벤치마크를 구성해야 하는 경우가 많습니다. 그런 다음 이러한 도메인별 벤치마크를 일반 벤치마크와 결합하여 전문화된 LLM에 대한 포괄적 및 표적적 평가를 모두 수행할 수 있다. 예를 들어 MultiMedQA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib356" title="">356</a>]</cite>는 건강 검진 및 건강 관리 질문을 포함하는 건강 관리의 특정 벤치마크이다. 이 작업에서 MultiMedQA는 MMLU<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib364" title="">364</a>]</cite>와 결합하여 Med-PaLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib356" title="">356</a>]</cite>와 같은 의료 전문 LLM의 성능을 평가했다. 마찬가지로 FLUE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib737" title="">737</a>]</cite>는 금융 감성 분석에서 질의 응답에 이르기까지 금융에 대한 벤치마크를 구축한다. BBH<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib365" title="">365</a>]</cite>와 협력하여 BloombergGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib360" title="">360</a>]</cite>와 같은 최종 LLMs를 평가하는 데 사용하였다.</p>
</div>
<div id="S7.SS3.SSS2.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS3.SSS2.p9.1"><span class="ltx_text ltx_font_bold" id="S7.SS3.SSS2.p9.1.1">Pros and Cons of Different Evaluation Approaches</span>. 이상에서 우리는 LLM의 능력을 평가하기 위한 다양한 평가 접근법에 대해 논의했다. 다음으로, 각 평가 접근법의 장단점을 간단히 분석한다.</p>
</div>
<div id="S7.SS3.SSS2.p10" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS2.p10.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS2.p10.1.m1.1"><semantics id="S7.SS3.SSS2.p10.1.m1.1a"><mo id="S7.SS3.SSS2.p10.1.m1.1.1" xref="S7.SS3.SSS2.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS2.p10.1.m1.1b"><ci id="S7.SS3.SSS2.p10.1.m1.1.1.cmml" xref="S7.SS3.SSS2.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS2.p10.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p10.1.1">Benchmark-based approach</em>. 이 평가 접근법은 LLM의 성능을 평가하기 위해 기존 벤치마크를 활용할 수 있다. 이러한 벤치마크에 관련된 작업은 종종 핵심 능력을 측정하기에 충분한 테스트 샘플을 포함한다(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p10.1.2">e.g.,</em> reasoning). 전체 평가 절차는 (거의) 자동적일 수 있으며, 다양한 기본 LLM에 대한 테스트 실험을 수행하는 것이 편리하며, 특히 사전 훈련 동안 모델 체크포인트의 성능을 모니터링하는 데 유용하다. 그러나 LLM은 질문 프롬프트, 제로 샷 또는 소수 샷 테스트, 답변 구문 분석 방법 등 평가 설정에 민감한 경우가 많다. 따라서 평가 실험을 수행할 때 가능한 영향 요인을 고려해야 한다. 평가 결과는 채택된 평가 설정과 함께 유의해야 한다. 또 다른 문제는 데이터 오염 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib738" title="">738</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p10.1.3">i.e.,</em> 테스트 데이터 자체 또는 관련 콘텐츠가 사전 훈련 말뭉치에 포함되었다는 것이다. 이러한 현상은 LLM 개발을 위해 점점 더 많은 오픈 데이터가 수집되었기 때문에 점점 더 심각해졌다.</p>
</div>
<div id="S7.SS3.SSS2.p11" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS2.p11.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS2.p11.1.m1.1"><semantics id="S7.SS3.SSS2.p11.1.m1.1a"><mo id="S7.SS3.SSS2.p11.1.m1.1.1" xref="S7.SS3.SSS2.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS2.p11.1.m1.1b"><ci id="S7.SS3.SSS2.p11.1.m1.1.1.cmml" xref="S7.SS3.SSS2.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS2.p11.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p11.1.1">Human-based approach</em>. 인간 평가는 실제 작업을 해결하기 위한 LLM의 기능을 평가할 때 몇 가지 이점을 제공한다. 주요 이점 중 하나는 LLM의 실제 능력을 직접 반영하는 능력이다. 실제 사용자로부터의 피드백 및 경험에 기초하여, 인간 평가는 실제 시나리오에서 LLMs의 성능에 대한 보다 직접적인 측정을 제공한다. 또한, 인간 평가자를 기반으로 보다 유연하고 다양한 평가 과제를 수행할 수 있다. 예를 들어, 사용자는 다양한 질의를 제출할 수 있고 자신의 작업 인지에 따라 LLM의 능력을 테스트할 수 있다. 다양한 유형의 작업과 컨텍스트에 걸쳐 LLM의 장단점을 깊이 이해할 수 있습니다. 그러나, 인간 평가는 또한 그것의 정확성과 일관성에 잠재적으로 영향을 미칠 수 있는 내재적 한계를 가지고 있다. 개인화된 취향과 평가자 간의 다양한 교육 수준과 같은 요인들은 평가 과정에서 편향되거나 심지어 불일치를 도입할 수 있다. 어떤 경우에는 사용자의 판단이 주관적일 가능성이 높으며, 이는 LLM의 진정한 능력을 반영하지 못할 수 있다. 더욱이, 견고하고 신뢰할 수 있는 인간 평가를 수행하는 것은 종종 많은 수의 평가자를 필요로 하며, 이는 매우 비싸고 시간이 많이 소요될 수 있다. 또한, 인간 평가는 재현할 수 없는 경우가 많아 기존의 평가 결과를 확장하거나 LLM의 진행 상황을 추적하는 것이 불가능하다.</p>
</div>
<div id="S7.SS3.SSS2.p12" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS2.p12.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS3.SSS2.p12.1.m1.1"><semantics id="S7.SS3.SSS2.p12.1.m1.1a"><mo id="S7.SS3.SSS2.p12.1.m1.1.1" xref="S7.SS3.SSS2.p12.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS2.p12.1.m1.1b"><ci id="S7.SS3.SSS2.p12.1.m1.1.1.cmml" xref="S7.SS3.SSS2.p12.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS2.p12.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p12.1.1">Model-based approach</em>. 모델 기반 접근법은 인간 기반 접근법의 대리인으로서 인간 개입에 대한 의존도를 줄이고 보다 효율적이고 확장 가능한 평가를 가능하게 하는 역할을 한다. 또한 LLMs는 부여된 평점 점수에 대한 의미 있는 설명을 제공할 수 있어 평가의 해석 가능성을 높일 수 있다. 확장성과 설명력에도 불구하고 모델 기반 접근법은 위치, 장황성 및 자기 향상 편향 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>]</cite>와 같은 몇 가지 문제를 겪는 것으로 나타났다. 특히, 위치 편향(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p12.1.2">i.e.,</em> the order to presents the responses)은 LLMs가 다른 응답에 비해 특정 위치에서 답변에 대해 높은 점수를 할당하는 경향이 있다는 사실을 의미하며, 장황성 편향은 LLMs가 짧은 답변에 비해 품질이 짧더라도 장황한 답변을 선호한다는 것을 의미하며, 자기 향상 편향은 LLMs가 종종 자신의 세대에서 과대평가된다는 것을 나타낸다. 또한, LLM은 복잡한 추론 문제를 해결하는 데 제한된 용량을 갖기 때문에 일부 어려운 작업에 대해 자격을 갖춘 평가자 역할을 할 수 없다(<em class="ltx_emph ltx_font_italic" id="S7.SS3.SSS2.p12.1.3">e.g.,</em> mathematical reasoning). 이러한 한계는 특정 프롬프트 엔지니어링 및 미세 조정 전략 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>]</cite>에 의해 어느 정도 완화될 수 있다.</p>
</div>
<div id="S7.SS3.SSS2.p13" class="ltx_para">
<p class="ltx_p" id="S7.SS3.SSS2.p13.1">요약하면, LLM 평가에 대한 기존 작업의 범주화(표<a class="ltx_ref" href="#S7.T15" title="TABLE XV ‣ 7.2.3 Tool Manipulation ‣ 7.2 Advanced Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XV</span></a>)는 주로 평가 방법론과 모델 유형의 두 가지 주요 차원을 기반으로 하며 테스트 능력과 함께 추가로 확장된다. LLM 평가를 위한 기존 작업의 범주화 또는 분류학에 대해서도 논의한 최근 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib733" title="">733</a>, <a class="ltx_ref" href="#bib.bib734" title="">734</a>]</cite>가 있다.</p>
</div>
<figure id="S7.T16" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE XVI:</span>Evaluation on the eight abilities of LLMs with specially selected tasks. <span class="ltx_text" id="S7.T16.30.1" 스타일="background-color:#FC8D59;">Orange</span> 및 <span class="ltx_text" id="S7.T16.31.2" 스타일="background-color:#92BFDB;">Blue</span> 폰트는 각각 닫힌 소스 및 열린 소스 모델에서 결과의 성능 순서를 나타냅니다. 이 표는 더 많은 모델의 결과를 통합하여 지속적으로 업데이트됩니다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE XVI: </span>Evaluation on the eight abilities of LLMs with specially selected tasks. The shade of the <span id="S7.T16.30.1" class="ltx_text" style="background-color:#FC8D59;">Orange</span> and <span id="S7.T16.31.2" class="ltx_text" style="background-color:#92BFDB;">Blue</span> fonts denote the performance orders of the results in closed-source and open-source models, respectively. This table will be continuously updated by incorporating the results of more models.
</figcaption>
<div id="S7.T16.27" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:802.2pt;height:1187.7pt;vertical-align:-1.3pt;"><span class="ltx_transformed_inner" style="transform:translate(90.7pt,-134.2pt) scale(1.29234016719243,1.29234016719243) ;">
<table id="S7.T16.27.27" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S7.T16.27.27.28" class="ltx_tr">
<td id="S7.T16.27.27.28.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.5pt 2.5pt;" rowspan="2"><span id="S7.T16.27.27.28.1.1" class="ltx_text ltx_font_bold">Models</span></td>
<td id="S7.T16.27.27.28.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.5pt 2.5pt;" colspan="4"><span id="S7.T16.27.27.28.2.1" class="ltx_text ltx_font_bold">Language Generation</span></td>
<td id="S7.T16.27.27.28.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.5pt 2.5pt;" colspan="5"><span id="S7.T16.27.27.28.3.1" class="ltx_text ltx_font_bold">Knowledge Utilization</span></td>
</tr>
<tr id="S7.T16.9.9.9" class="ltx_tr">
<td id="S7.T16.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">LBD<math id="S7.T16.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.1.1.1.1.m1.1a"><mo stretchy="false" id="S7.T16.1.1.1.1.m1.1.1" xref="S7.T16.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.1.1.1.1.m1.1b"><ci id="S7.T16.1.1.1.1.m1.1.1.cmml" xref="S7.T16.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">WMT<math id="S7.T16.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.2.2.2.2.m1.1a"><mo stretchy="false" id="S7.T16.2.2.2.2.m1.1.1" xref="S7.T16.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.2.2.2.2.m1.1b"><ci id="S7.T16.2.2.2.2.m1.1.1.cmml" xref="S7.T16.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">XSum<math id="S7.T16.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.3.3.3.3.m1.1a"><mo stretchy="false" id="S7.T16.3.3.3.3.m1.1.1" xref="S7.T16.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.3.3.3.3.m1.1b"><ci id="S7.T16.3.3.3.3.m1.1.1.cmml" xref="S7.T16.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">HumanEval<math id="S7.T16.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.4.4.4.4.m1.1a"><mo stretchy="false" id="S7.T16.4.4.4.4.m1.1.1" xref="S7.T16.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.4.4.4.4.m1.1b"><ci id="S7.T16.4.4.4.4.m1.1.1.cmml" xref="S7.T16.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">TriviaQA<math id="S7.T16.5.5.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.5.5.5.5.m1.1a"><mo stretchy="false" id="S7.T16.5.5.5.5.m1.1.1" xref="S7.T16.5.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.5.5.5.5.m1.1b"><ci id="S7.T16.5.5.5.5.m1.1.1.cmml" xref="S7.T16.5.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.5.5.5.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">NaturalQ<math id="S7.T16.6.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.6.6.6.6.m1.1a"><mo stretchy="false" id="S7.T16.6.6.6.6.m1.1.1" xref="S7.T16.6.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.6.6.6.6.m1.1b"><ci id="S7.T16.6.6.6.6.m1.1.1.cmml" xref="S7.T16.6.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.6.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">WebQ<math id="S7.T16.7.7.7.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.7.7.7.7.m1.1a"><mo stretchy="false" id="S7.T16.7.7.7.7.m1.1.1" xref="S7.T16.7.7.7.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.7.7.7.7.m1.1b"><ci id="S7.T16.7.7.7.7.m1.1.1.cmml" xref="S7.T16.7.7.7.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.7.7.7.7.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.8.8.8.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">ARC<math id="S7.T16.8.8.8.8.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.8.8.8.8.m1.1a"><mo stretchy="false" id="S7.T16.8.8.8.8.m1.1.1" xref="S7.T16.8.8.8.8.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.8.8.8.8.m1.1b"><ci id="S7.T16.8.8.8.8.m1.1.1.cmml" xref="S7.T16.8.8.8.8.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.8.8.8.8.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.9.9.9.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">WikiFact<math id="S7.T16.9.9.9.9.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.9.9.9.9.m1.1a"><mo stretchy="false" id="S7.T16.9.9.9.9.m1.1.1" xref="S7.T16.9.9.9.9.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.9.9.9.9.m1.1b"><ci id="S7.T16.9.9.9.9.m1.1.1.cmml" xref="S7.T16.9.9.9.9.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.9.9.9.9.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T16.27.27.29" class="ltx_tr">
<td id="S7.T16.27.27.29.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;">ChatGPT</td>
<td id="S7.T16.27.27.29.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.29.2.1" class="ltx_text" style="background-color:#FEE8DD;">55.81</span></td>
<td id="S7.T16.27.27.29.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.29.3.1" class="ltx_text" style="background-color:#FCA77F;">36.44</span></td>
<td id="S7.T16.27.27.29.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.29.4.1" class="ltx_text" style="background-color:#FC8D59;">21.71</span></td>
<td id="S7.T16.27.27.29.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.29.5.1" class="ltx_text" style="background-color:#FC8D59;">79.88</span></td>
<td id="S7.T16.27.27.29.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.29.6.1" class="ltx_text" style="background-color:#FC8D59;">54.54</span></td>
<td id="S7.T16.27.27.29.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.29.7.1" class="ltx_text" style="background-color:#FC8D59;">21.52</span></td>
<td id="S7.T16.27.27.29.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.29.8.1" class="ltx_text" style="background-color:#FEDCCC;">17.77</span></td>
<td id="S7.T16.27.27.29.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.29.9.1" class="ltx_text" style="background-color:#FC8D59;">93.69</span></td>
<td id="S7.T16.27.27.29.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.29.10.1" class="ltx_text" style="background-color:#FEDCCC;">29.25</span></td>
</tr>
<tr id="S7.T16.27.27.30" class="ltx_tr">
<td id="S7.T16.27.27.30.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Claude</td>
<td id="S7.T16.27.27.30.2" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.30.2.1" class="ltx_text" style="background-color:#FCA77F;">64.47</span></td>
<td id="S7.T16.27.27.30.3" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.30.3.1" class="ltx_text" style="background-color:#FEE8DD;">31.23</span></td>
<td id="S7.T16.27.27.30.4" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.30.4.1" class="ltx_text" style="background-color:#FEE8DD;">18.63</span></td>
<td id="S7.T16.27.27.30.5" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.30.5.1" class="ltx_text" style="background-color:#FEF7F3;">51.22</span></td>
<td id="S7.T16.27.27.30.6" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.30.6.1" class="ltx_text" style="background-color:#FEF7F3;">40.92</span></td>
<td id="S7.T16.27.27.30.7" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.30.7.1" class="ltx_text" style="background-color:#FEF7F3;">13.77</span></td>
<td id="S7.T16.27.27.30.8" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.30.8.1" class="ltx_text" style="background-color:#FEF7F3;">14.57</span></td>
<td id="S7.T16.27.27.30.9" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.30.9.1" class="ltx_text" style="background-color:#FEF7F3;">66.62</span></td>
<td id="S7.T16.27.27.30.10" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.30.10.1" class="ltx_text" style="background-color:#FCA77F;">34.34</span></td>
</tr>
<tr id="S7.T16.27.27.31" class="ltx_tr">
<td id="S7.T16.27.27.31.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Claude 2</td>
<td id="S7.T16.27.27.31.2" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.31.2.1" class="ltx_text" style="background-color:#FEF7F3;">45.20</span></td>
<td id="S7.T16.27.27.31.3" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.31.3.1" class="ltx_text" style="background-color:#FEF7F3;">12.93</span></td>
<td id="S7.T16.27.27.31.4" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.31.4.1" class="ltx_text" style="background-color:#FEDCCC;">19.13</span></td>
<td id="S7.T16.27.27.31.5" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.31.5.1" class="ltx_text" style="background-color:#FCA77F;">78.04</span></td>
<td id="S7.T16.27.27.31.6" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.31.6.1" class="ltx_text" style="background-color:#FCA77F;">54.30</span></td>
<td id="S7.T16.27.27.31.7" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.31.7.1" class="ltx_text" style="background-color:#FCA77F;">21.30</span></td>
<td id="S7.T16.27.27.31.8" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.31.8.1" class="ltx_text" style="background-color:#FC8D59;">21.06</span></td>
<td id="S7.T16.27.27.31.9" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.31.9.1" class="ltx_text" style="background-color:#FEE8DD;">79.97</span></td>
<td id="S7.T16.27.27.31.10" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.31.10.1" class="ltx_text" style="background-color:#FC8D59;">35.83</span></td>
</tr>
<tr id="S7.T16.27.27.32" class="ltx_tr">
<td id="S7.T16.27.27.32.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Davinci003</td>
<td id="S7.T16.27.27.32.2" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.32.2.1" class="ltx_text" style="background-color:#FC8D59;">69.98</span></td>
<td id="S7.T16.27.27.32.3" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.32.3.1" class="ltx_text" style="background-color:#FC8D59;">37.46</span></td>
<td id="S7.T16.27.27.32.4" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.32.4.1" class="ltx_text" style="background-color:#FEF7F3;">18.19</span></td>
<td id="S7.T16.27.27.32.5" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.32.5.1" class="ltx_text" style="background-color:#FEDCCC;">67.07</span></td>
<td id="S7.T16.27.27.32.6" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.32.6.1" class="ltx_text" style="background-color:#FEE8DD;">51.51</span></td>
<td id="S7.T16.27.27.32.7" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.32.7.1" class="ltx_text" style="background-color:#FEE8DD;">17.76</span></td>
<td id="S7.T16.27.27.32.8" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.32.8.1" class="ltx_text" style="background-color:#FEE8DD;">16.68</span></td>
<td id="S7.T16.27.27.32.9" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.32.9.1" class="ltx_text" style="background-color:#FEDCCC;">88.47</span></td>
<td id="S7.T16.27.27.32.10" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.32.10.1" class="ltx_text" style="background-color:#FEF7F3;">28.29</span></td>
</tr>
<tr id="S7.T16.27.27.33" class="ltx_tr">
<td id="S7.T16.27.27.33.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Davinci002</td>
<td id="S7.T16.27.27.33.2" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.33.2.1" class="ltx_text" style="background-color:#FEDCCC;">58.85</span></td>
<td id="S7.T16.27.27.33.3" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.33.3.1" class="ltx_text" style="background-color:#FEDCCC;">35.11</span></td>
<td id="S7.T16.27.27.33.4" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.33.4.1" class="ltx_text" style="background-color:#FCA77F;">19.15</span></td>
<td id="S7.T16.27.27.33.5" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.33.5.1" class="ltx_text" style="background-color:#FEE8DD;">56.70</span></td>
<td id="S7.T16.27.27.33.6" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.33.6.1" class="ltx_text" style="background-color:#FEDCCC;">52.11</span></td>
<td id="S7.T16.27.27.33.7" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.33.7.1" class="ltx_text" style="background-color:#FEDCCC;">20.47</span></td>
<td id="S7.T16.27.27.33.8" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.33.8.1" class="ltx_text" style="background-color:#FCA77F;">18.45</span></td>
<td id="S7.T16.27.27.33.9" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.33.9.1" class="ltx_text" style="background-color:#FCA77F;">89.23</span></td>
<td id="S7.T16.27.27.33.10" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.33.10.1" class="ltx_text" style="background-color:#FEE8DD;">29.15</span></td>
</tr>
<tr id="S7.T16.27.27.34" class="ltx_tr">
<td id="S7.T16.27.27.34.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;">LLaMA 2-Chat&nbsp;(7B)</td>
<td id="S7.T16.27.27.34.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">56.12</td>
<td id="S7.T16.27.27.34.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">12.62</td>
<td id="S7.T16.27.27.34.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.34.4.1" class="ltx_text" style="background-color:#A7CBE2;">16.00</span></td>
<td id="S7.T16.27.27.34.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">11.59</td>
<td id="S7.T16.27.27.34.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.34.6.1" class="ltx_text" style="background-color:#92BFDB;">38.93</span></td>
<td id="S7.T16.27.27.34.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.34.7.1" class="ltx_text" style="background-color:#92BFDB;">12.96</span></td>
<td id="S7.T16.27.27.34.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.34.8.1" class="ltx_text" style="background-color:#A7CBE2;">11.32</span></td>
<td id="S7.T16.27.27.34.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.34.9.1" class="ltx_text" style="background-color:#92BFDB;">72.35</span></td>
<td id="S7.T16.27.27.34.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">23.37</td>
</tr>
<tr id="S7.T16.27.27.35" class="ltx_tr">
<td id="S7.T16.27.27.35.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Vicuna&nbsp;(13B)</td>
<td id="S7.T16.27.27.35.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">62.45</td>
<td id="S7.T16.27.27.35.3" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.35.3.1" class="ltx_text" style="background-color:#A7CBE2;">20.49</span></td>
<td id="S7.T16.27.27.35.4" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.35.4.1" class="ltx_text" style="background-color:#92BFDB;">17.87</span></td>
<td id="S7.T16.27.27.35.5" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.35.5.1" class="ltx_text" style="background-color:#92BFDB;">20.73</span></td>
<td id="S7.T16.27.27.35.6" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.35.6.1" class="ltx_text" style="background-color:#C4DDEC;">29.04</span></td>
<td id="S7.T16.27.27.35.7" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.35.7.1" class="ltx_text" style="background-color:#C6DEED;">10.75</span></td>
<td id="S7.T16.27.27.35.8" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.35.8.1" class="ltx_text" style="background-color:#92BFDB;">11.52</span></td>
<td id="S7.T16.27.27.35.9" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.35.9.1" class="ltx_text" style="background-color:#E5F0F7;">
20.69</span></td>
<td id="S7.T16.27.27.35.10" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.35.10.1" class="ltx_text" style="background-color:#92BFDB;">28.76</span></td>
</tr>
<tr id="S7.T16.27.27.36" class="ltx_tr">
<td id="S7.T16.27.27.36.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Vicuna&nbsp;(7B)</td>
<td id="S7.T16.27.27.36.2" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.36.2.1" class="ltx_text" style="background-color:#C4DDEC;">63.90</span></td>
<td id="S7.T16.27.27.36.3" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.36.3.1" class="ltx_text" style="background-color:#C6DEED;">19.95</span></td>
<td id="S7.T16.27.27.36.4" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.36.4.1" class="ltx_text" style="background-color:#C6DEED;">13.59</span></td>
<td id="S7.T16.27.27.36.5" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.36.5.1" class="ltx_text" style="background-color:#A7CBE2;">17.07</span></td>
<td id="S7.T16.27.27.36.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">28.58</td>
<td id="S7.T16.27.27.36.7" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.36.7.1" class="ltx_text" style="background-color:#C4DDEC;">9.17</span></td>
<td id="S7.T16.27.27.36.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">6.64</td>
<td id="S7.T16.27.27.36.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">16.96</td>
<td id="S7.T16.27.27.36.10" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.36.10.1" class="ltx_text" style="background-color:#C6DEED;">26.95</span></td>
</tr>
<tr id="S7.T16.27.27.37" class="ltx_tr">
<td id="S7.T16.27.27.37.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Alpaca&nbsp;(7B)</td>
<td id="S7.T16.27.27.37.2" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.37.2.1" class="ltx_text" style="background-color:#E5F0F7;">63.35</span></td>
<td id="S7.T16.27.27.37.3" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.37.3.1" class="ltx_text" style="background-color:#92BFDB;">21.52</span></td>
<td id="S7.T16.27.27.37.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">8.74</td>
<td id="S7.T16.27.27.37.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">13.41</td>
<td id="S7.T16.27.27.37.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">17.14</td>
<td id="S7.T16.27.27.37.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">3.24</td>
<td id="S7.T16.27.27.37.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">3.00</td>
<td id="S7.T16.27.27.37.9" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.37.9.1" class="ltx_text" style="background-color:#C6DEED;">49.75</span></td>
<td id="S7.T16.27.27.37.10" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.37.10.1" class="ltx_text" style="background-color:#C4DDEC;">26.05</span></td>
</tr>
<tr id="S7.T16.27.27.38" class="ltx_tr">
<td id="S7.T16.27.27.38.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">ChatGLM&nbsp;(6B)</td>
<td id="S7.T16.27.27.38.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">33.34</td>
<td id="S7.T16.27.27.38.3" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.38.3.1" class="ltx_text" style="background-color:#C4DDEC;">16.58</span></td>
<td id="S7.T16.27.27.38.4" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.38.4.1" class="ltx_text" style="background-color:#C4DDEC;">13.48</span></td>
<td id="S7.T16.27.27.38.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">13.42</td>
<td id="S7.T16.27.27.38.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">13.42</td>
<td id="S7.T16.27.27.38.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">4.40</td>
<td id="S7.T16.27.27.38.8" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.38.8.1" class="ltx_text" style="background-color:#C4DDEC;">9.20</span></td>
<td id="S7.T16.27.27.38.9" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.38.9.1" class="ltx_text" style="background-color:#A7CBE2;">55.39</span></td>
<td id="S7.T16.27.27.38.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">16.01</td>
</tr>
<tr id="S7.T16.27.27.39" class="ltx_tr">
<td id="S7.T16.27.27.39.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;">LLaMA 2&nbsp;(7B)</td>
<td id="S7.T16.27.27.39.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.39.2.1" class="ltx_text" style="background-color:#C6DEED;">66.39</span></td>
<td id="S7.T16.27.27.39.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">11.57</td>
<td id="S7.T16.27.27.39.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.39.4.1" class="ltx_text" style="background-color:#E5F0F7;">11.57</span></td>
<td id="S7.T16.27.27.39.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.39.5.1" class="ltx_text" style="background-color:#A7CBE2;">17.07</span></td>
<td id="S7.T16.27.27.39.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.39.6.1" class="ltx_text" style="background-color:#C6DEED;">30.92</span></td>
<td id="S7.T16.27.27.39.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">5.15</td>
<td id="S7.T16.27.27.39.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">2.51</td>
<td id="S7.T16.27.27.39.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.39.9.1" class="ltx_text" style="background-color:#C4DDEC;">24.16</span></td>
<td id="S7.T16.27.27.39.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.39.10.1" class="ltx_text" style="background-color:#A7CBE2;">28.06</span></td>
</tr>
<tr id="S7.T16.27.27.40" class="ltx_tr">
<td id="S7.T16.27.27.40.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">LLaMA&nbsp;(7B)</td>
<td id="S7.T16.27.27.40.2" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.40.2.1" class="ltx_text" style="background-color:#92BFDB;">67.68</span></td>
<td id="S7.T16.27.27.40.3" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.40.3.1" class="ltx_text" style="background-color:#E5F0F7;">13.84</span></td>
<td id="S7.T16.27.27.40.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">8.77</td>
<td id="S7.T16.27.27.40.5" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.40.5.1" class="ltx_text" style="background-color:#C4DDEC;">15.24</span></td>
<td id="S7.T16.27.27.40.6" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.40.6.1" class="ltx_text" style="background-color:#A7CBE2;">34.62</span></td>
<td id="S7.T16.27.27.40.7" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.40.7.1" class="ltx_text" style="background-color:#E5F0F7;">7.92</span></td>
<td id="S7.T16.27.27.40.8" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.40.8.1" class="ltx_text" style="background-color:#C6DEED;">11.12</span></td>
<td id="S7.T16.27.27.40.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">4.88</td>
<td id="S7.T16.27.27.40.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">19.78</td>
</tr>
<tr id="S7.T16.27.27.41" class="ltx_tr">
<td id="S7.T16.27.27.41.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Falcon&nbsp;(7B)</td>
<td id="S7.T16.27.27.41.2" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.41.2.1" class="ltx_text" style="background-color:#A7CBE2;">66.89</span></td>
<td id="S7.T16.27.27.41.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">4.05</td>
<td id="S7.T16.27.27.41.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">10.00</td>
<td id="S7.T16.27.27.41.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">10.37</td>
<td id="S7.T16.27.27.41.6" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.41.6.1" class="ltx_text" style="background-color:#E5F0F7;">28.74</span></td>
<td id="S7.T16.27.27.41.7" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.41.7.1" class="ltx_text" style="background-color:#A7CBE2;">10.78</span></td>
<td id="S7.T16.27.27.41.8" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.41.8.1" class="ltx_text" style="background-color:#E5F0F7;">8.46</span></td>
<td id="S7.T16.27.27.41.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">4.08</td>
<td id="S7.T16.27.27.41.10" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.41.10.1" class="ltx_text" style="background-color:#E5F0F7;">23.91</span></td>
</tr>
<tr id="S7.T16.27.27.42" class="ltx_tr">
<td id="S7.T16.27.27.42.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Pythia&nbsp;(12B)</td>
<td id="S7.T16.27.27.42.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">61.19</td>
<td id="S7.T16.27.27.42.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">5.43</td>
<td id="S7.T16.27.27.42.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">8.87</td>
<td id="S7.T16.27.27.42.5" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.42.5.1" class="ltx_text" style="background-color:#E5F0F7;">14.63</span></td>
<td id="S7.T16.27.27.42.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">15.73</td>
<td id="S7.T16.27.27.42.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.99</td>
<td id="S7.T16.27.27.42.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">4.72</td>
<td id="S7.T16.27.27.42.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">11.66</td>
<td id="S7.T16.27.27.42.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">20.57</td>
</tr>
<tr id="S7.T16.27.27.43" class="ltx_tr">
<td id="S7.T16.27.27.43.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Pythia&nbsp;(7B)</td>
<td id="S7.T16.27.27.43.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">56.96</td>
<td id="S7.T16.27.27.43.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">3.68</td>
<td id="S7.T16.27.27.43.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">8.23</td>
<td id="S7.T16.27.27.43.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">9.15</td>
<td id="S7.T16.27.27.43.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">10.16</td>
<td id="S7.T16.27.27.43.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.77</td>
<td id="S7.T16.27.27.43.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">3.74</td>
<td id="S7.T16.27.27.43.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">11.03</td>
<td id="S7.T16.27.27.43.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">15.75</td>
</tr>
<tr id="S7.T16.27.27.44" class="ltx_tr">
<td id="S7.T16.27.27.44.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;" rowspan="2"><span id="S7.T16.27.27.44.1.1" class="ltx_text ltx_font_bold">Models</span></td>
<td id="S7.T16.27.27.44.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;" colspan="3"><span id="S7.T16.27.27.44.2.1" class="ltx_text ltx_font_bold">Knowledge Reasoning</span></td>
<td id="S7.T16.27.27.44.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;" colspan="2"><span id="S7.T16.27.27.44.3.1" class="ltx_text ltx_font_bold">Symbolic Reasoning</span></td>
<td id="S7.T16.27.27.44.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;" colspan="2"><span id="S7.T16.27.27.44.4.1" class="ltx_text ltx_font_bold">Mathematical Reasoning</span></td>
<td id="S7.T16.27.27.44.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;" colspan="2"><span id="S7.T16.27.27.44.5.1" class="ltx_text ltx_font_bold">Interaction with Environment</span></td>
</tr>
<tr id="S7.T16.18.18.18" class="ltx_tr">
<td id="S7.T16.10.10.10.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">OBQA<math id="S7.T16.10.10.10.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.10.10.10.1.m1.1a"><mo stretchy="false" id="S7.T16.10.10.10.1.m1.1.1" xref="S7.T16.10.10.10.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.10.10.10.1.m1.1b"><ci id="S7.T16.10.10.10.1.m1.1.1.cmml" xref="S7.T16.10.10.10.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.10.10.10.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.11.11.11.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">HellaSwag<math id="S7.T16.11.11.11.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.11.11.11.2.m1.1a"><mo stretchy="false" id="S7.T16.11.11.11.2.m1.1.1" xref="S7.T16.11.11.11.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.11.11.11.2.m1.1b"><ci id="S7.T16.11.11.11.2.m1.1.1.cmml" xref="S7.T16.11.11.11.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.11.11.11.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.12.12.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">SocialIQA<math id="S7.T16.12.12.12.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.12.12.12.3.m1.1a"><mo stretchy="false" id="S7.T16.12.12.12.3.m1.1.1" xref="S7.T16.12.12.12.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.12.12.12.3.m1.1b"><ci id="S7.T16.12.12.12.3.m1.1.1.cmml" xref="S7.T16.12.12.12.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.12.12.12.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.13.13.13.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">C-Objects<math id="S7.T16.13.13.13.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.13.13.13.4.m1.1a"><mo stretchy="false" id="S7.T16.13.13.13.4.m1.1.1" xref="S7.T16.13.13.13.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.13.13.13.4.m1.1b"><ci id="S7.T16.13.13.13.4.m1.1.1.cmml" xref="S7.T16.13.13.13.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.13.13.13.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.14.14.14.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">Penguins<math id="S7.T16.14.14.14.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.14.14.14.5.m1.1a"><mo stretchy="false" id="S7.T16.14.14.14.5.m1.1.1" xref="S7.T16.14.14.14.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.14.14.14.5.m1.1b"><ci id="S7.T16.14.14.14.5.m1.1.1.cmml" xref="S7.T16.14.14.14.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.14.14.14.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.15.15.15.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">GSM8k<math id="S7.T16.15.15.15.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.15.15.15.6.m1.1a"><mo stretchy="false" id="S7.T16.15.15.15.6.m1.1.1" xref="S7.T16.15.15.15.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.15.15.15.6.m1.1b"><ci id="S7.T16.15.15.15.6.m1.1.1.cmml" xref="S7.T16.15.15.15.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.15.15.15.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.16.16.16.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">MATH<math id="S7.T16.16.16.16.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.16.16.16.7.m1.1a"><mo stretchy="false" id="S7.T16.16.16.16.7.m1.1.1" xref="S7.T16.16.16.16.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.16.16.16.7.m1.1b"><ci id="S7.T16.16.16.16.7.m1.1.1.cmml" xref="S7.T16.16.16.16.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.16.16.16.7.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.17.17.17.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">ALFW<math id="S7.T16.17.17.17.8.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.17.17.17.8.m1.1a"><mo stretchy="false" id="S7.T16.17.17.17.8.m1.1.1" xref="S7.T16.17.17.17.8.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.17.17.17.8.m1.1b"><ci id="S7.T16.17.17.17.8.m1.1.1.cmml" xref="S7.T16.17.17.17.8.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.17.17.17.8.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.18.18.18.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">WebShop<math id="S7.T16.18.18.18.9.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.18.18.18.9.m1.1a"><mo stretchy="false" id="S7.T16.18.18.18.9.m1.1.1" xref="S7.T16.18.18.18.9.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.18.18.18.9.m1.1b"><ci id="S7.T16.18.18.18.9.m1.1.1.cmml" xref="S7.T16.18.18.18.9.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.18.18.18.9.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T16.27.27.45" class="ltx_tr">
<td id="S7.T16.27.27.45.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;">ChatGPT</td>
<td id="S7.T16.27.27.45.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.45.2.1" class="ltx_text" style="background-color:#FCA77F;">81.20</span></td>
<td id="S7.T16.27.27.45.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.45.3.1" class="ltx_text" style="background-color:#FCA77F;">61.43</span></td>
<td id="S7.T16.27.27.45.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.45.4.1" class="ltx_text" style="background-color:#FC8D59;">73.23</span></td>
<td id="S7.T16.27.27.45.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.45.5.1" class="ltx_text" style="background-color:#FEF7F3;">53.20</span></td>
<td id="S7.T16.27.27.45.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.45.6.1" class="ltx_text" style="background-color:#FEF7F3;">40.27</span></td>
<td id="S7.T16.27.27.45.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.45.7.1" class="ltx_text" style="background-color:#FCA77F;">78.47</span></td>
<td id="S7.T16.27.27.45.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.45.8.1" class="ltx_text" style="background-color:#FC8D59;">33.78</span></td>
<td id="S7.T16.27.27.45.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.45.9.1" class="ltx_text" style="background-color:#FEF7F3;">58.96</span></td>
<td id="S7.T16.27.27.45.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.45.10.1" class="ltx_text" style="background-color:#FEDCCC;">45.12/15.60</span></td>
</tr>
<tr id="S7.T16.27.27.46" class="ltx_tr">
<td id="S7.T16.27.27.46.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Claude</td>
<td id="S7.T16.27.27.46.2" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.46.2.1" class="ltx_text" style="background-color:#FC8D59;">81.80</span></td>
<td id="S7.T16.27.27.46.3" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.46.3.1" class="ltx_text" style="background-color:#FEDCCC;">54.95</span></td>
<td id="S7.T16.27.27.46.4" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.46.4.1" class="ltx_text" style="background-color:#FC8D59;">73.23</span></td>
<td id="S7.T16.27.27.46.5" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.46.5.1" class="ltx_text" style="background-color:#FEE8DD;">59.95</span></td>
<td id="S7.T16.27.27.46.6" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.46.6.1" class="ltx_text" style="background-color:#FEE8DD;">47.65</span></td>
<td id="S7.T16.27.27.46.7" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.46.7.1" class="ltx_text" style="background-color:#FEDCCC;">70.81</span></td>
<td id="S7.T16.27.27.46.8" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.46.8.1" class="ltx_text" style="background-color:#FEDCCC;">20.18</span></td>
<td id="S7.T16.27.27.46.9" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.46.9.1" class="ltx_text" style="background-color:#FCA77F;">76.87</span></td>
<td id="S7.T16.27.27.46.10" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.46.10.1" class="ltx_text" style="background-color:#FCA77F;">47.72/23.00</span></td>
</tr>
<tr id="S7.T16.27.27.47" class="ltx_tr">
<td id="S7.T16.27.27.47.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Claude 2</td>
<td id="S7.T16.27.27.47.2" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.47.2.1" class="ltx_text" style="background-color:#FEE8DD;">71.60</span></td>
<td id="S7.T16.27.27.47.3" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.47.3.1" class="ltx_text" style="background-color:#FEE8DD;">50.75</span></td>
<td id="S7.T16.27.27.47.4" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.47.4.1" class="ltx_text" style="background-color:#FEE8DD;">58.34</span></td>
<td id="S7.T16.27.27.47.5" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.47.5.1" class="ltx_text" style="background-color:#FC8D59;">66.76</span></td>
<td id="S7.T16.27.27.47.6" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.47.6.1" class="ltx_text" style="background-color:#FC8D59;">74.50</span></td>
<td id="S7.T16.27.27.47.7" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.47.7.1" class="ltx_text" style="background-color:#FC8D59;">82.87</span></td>
<td id="S7.T16.27.27.47.8" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.47.8.1" class="ltx_text" style="background-color:#FCA77F;">32.24</span></td>
<td id="S7.T16.27.27.47.9" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.47.9.1" class="ltx_text" style="background-color:#FC8D59;">77.61</span></td>
<td id="S7.T16.27.27.47.10" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.47.10.1" class="ltx_text" style="background-color:#FEE8DD;">34.96/19.20</span></td>
</tr>
<tr id="S7.T16.27.27.48" class="ltx_tr">
<td id="S7.T16.27.27.48.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Davinci003</td>
<td id="S7.T16.27.27.48.2" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.48.2.1" class="ltx_text" style="background-color:#FEDCCC;">74.40</span></td>
<td id="S7.T16.27.27.48.3" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.48.3.1" class="ltx_text" style="background-color:#FC8D59;">62.65</span></td>
<td id="S7.T16.27.27.48.4" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.48.4.1" class="ltx_text" style="background-color:#FEDCCC;">69.70</span></td>
<td id="S7.T16.27.27.48.5" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.48.5.1" class="ltx_text" style="background-color:#FCA77F;">64.60</span></td>
<td id="S7.T16.27.27.48.6" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.48.6.1" class="ltx_text" style="background-color:#FEDCCC;">61.07</span></td>
<td id="S7.T16.27.27.48.7" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.48.7.1" class="ltx_text" style="background-color:#FEE8DD;">57.16</span></td>
<td id="S7.T16.27.27.48.8" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.48.8.1" class="ltx_text" style="background-color:#FEE8DD;">17.66</span></td>
<td id="S7.T16.27.27.48.9" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.48.9.1" class="ltx_text" style="background-color:#FEDCCC;">65.67</span></td>
<td id="S7.T16.27.27.48.10" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.48.10.1" class="ltx_text" style="background-color:#FC8D59;">64.08/32.40</span></td>
</tr>
<tr id="S7.T16.27.27.49" class="ltx_tr">
<td id="S7.T16.27.27.49.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Davinci002</td>
<td id="S7.T16.27.27.49.2" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.49.2.1" class="ltx_text" style="background-color:#FEF7F3;">69.80</span></td>
<td id="S7.T16.27.27.49.3" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.49.3.1" class="ltx_text" style="background-color:#FEF7F3;">47.81</span></td>
<td id="S7.T16.27.27.49.4" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.49.4.1" class="ltx_text" style="background-color:#FEF7F3;">57.01</span></td>
<td id="S7.T16.27.27.49.5" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.49.5.1" class="ltx_text" style="background-color:#FEDCCC;">62.55</span></td>
<td id="S7.T16.27.27.49.6" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.49.6.1" class="ltx_text" style="background-color:#FCA77F;">67.11</span></td>
<td id="S7.T16.27.27.49.7" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.49.7.1" class="ltx_text" style="background-color:#FEF7F3;">49.96</span></td>
<td id="S7.T16.27.27.49.8" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.49.8.1" class="ltx_text" style="background-color:#FEF7F3;">14.28</span></td>
<td id="S7.T16.27.27.49.9" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.49.9.1" class="ltx_text" style="background-color:#FCA77F;">76.87</span></td>
<td id="S7.T16.27.27.49.10" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.49.10.1" class="ltx_text" style="background-color:#FEF7F3;">29.66/15.20</span></td>
</tr>
<tr id="S7.T16.27.27.50" class="ltx_tr">
<td id="S7.T16.27.27.50.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;">LLaMA 2-Chat&nbsp;(7B)</td>
<td id="S7.T16.27.27.50.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.50.2.1" class="ltx_text" style="background-color:#A7CBE2;">45.62</span></td>
<td id="S7.T16.27.27.50.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.50.3.1" class="ltx_text" style="background-color:#C6DEED;">
74.01</span></td>
<td id="S7.T16.27.27.50.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.50.4.1" class="ltx_text" style="background-color:#C4DDEC;">43.84</span></td>
<td id="S7.T16.27.27.50.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.50.5.1" class="ltx_text" style="background-color:#C4DDEC;">43.40</span></td>
<td id="S7.T16.27.27.50.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.50.6.1" class="ltx_text" style="background-color:#A7CBE2;">38.93</span></td>
<td id="S7.T16.27.27.50.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">9.63</td>
<td id="S7.T16.27.27.50.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">2.22</td>
<td id="S7.T16.27.27.50.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.50.9.1" class="ltx_text" style="background-color:#92BFDB;">11.19</span></td>
<td id="S7.T16.27.27.50.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.50.10.1" class="ltx_text" style="background-color:#92BFDB;">24.51/5.60</span></td>
</tr>
<tr id="S7.T16.27.27.51" class="ltx_tr">
<td id="S7.T16.27.27.51.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Vicuna&nbsp;(13B)</td>
<td id="S7.T16.27.27.51.2" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.51.2.1" class="ltx_text" style="background-color:#E5F0F7;">43.65</span></td>
<td id="S7.T16.27.27.51.3" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.51.3.1" class="ltx_text" style="background-color:#E5F0F7;">70.51</span></td>
<td id="S7.T16.27.27.51.4" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.51.4.1" class="ltx_text" style="background-color:#C6DEED;">45.97</span></td>
<td id="S7.T16.27.27.51.5" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.51.5.1" class="ltx_text" style="background-color:#92BFDB;">53.55</span></td>
<td id="S7.T16.27.27.51.6" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.51.6.1" class="ltx_text" style="background-color:#C6DEED;">36.91</span></td>
<td id="S7.T16.27.27.51.7" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.51.7.1" class="ltx_text" style="background-color:#92BFDB;">18.50</span></td>
<td id="S7.T16.27.27.51.8" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.51.8.1" class="ltx_text" style="background-color:#A7CBE2;">3.72</span></td>
<td id="S7.T16.27.27.51.9" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.51.9.1" class="ltx_text" style="background-color:#A7CBE2;">8.96</span></td>
<td id="S7.T16.27.27.51.10" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.51.10.1" class="ltx_text" style="background-color:#A7CBE2;">22.74/5.00</span></td>
</tr>
<tr id="S7.T16.27.27.52" class="ltx_tr">
<td id="S7.T16.27.27.52.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Vicuna&nbsp;(7B)</td>
<td id="S7.T16.27.27.52.2" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.52.2.1" class="ltx_text" style="background-color:#C4DDEC;">43.84</span></td>
<td id="S7.T16.27.27.52.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">69.25</td>
<td id="S7.T16.27.27.52.4" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.52.4.1" class="ltx_text" style="background-color:#A7CBE2;">
46.27</span></td>
<td id="S7.T16.27.27.52.5" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.52.5.1" class="ltx_text" style="background-color:#A7CBE2;">44.25</span></td>
<td id="S7.T16.27.27.52.6" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.52.6.1" class="ltx_text" style="background-color:#C4DDEC;">36.24</span></td>
<td id="S7.T16.27.27.52.7" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.52.7.1" class="ltx_text" style="background-color:#A7CBE2;">14.03</span></td>
<td id="S7.T16.27.27.52.8" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.52.8.1" class="ltx_text" style="background-color:#C6DEED;">3.54</span></td>
<td id="S7.T16.27.27.52.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.49</td>
<td id="S7.T16.27.27.52.10" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.52.10.1" class="ltx_text" style="background-color:#C4DDEC;">
6.90/1.40</span></td>
</tr>
<tr id="S7.T16.27.27.53" class="ltx_tr">
<td id="S7.T16.27.27.53.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Alpaca&nbsp;(7B)</td>
<td id="S7.T16.27.27.53.2" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.53.2.1" class="ltx_text" style="background-color:#92BFDB;">47.82</span></td>
<td id="S7.T16.27.27.53.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">69.81</td>
<td id="S7.T16.27.27.53.4" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.53.4.1" class="ltx_text" style="background-color:#92BFDB;">47.55</span></td>
<td id="S7.T16.27.27.53.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">39.35</td>
<td id="S7.T16.27.27.53.6" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.53.6.1" class="ltx_text" style="background-color:#92BFDB;">40.27</span></td>
<td id="S7.T16.27.27.53.7" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.53.7.1" class="ltx_text" style="background-color:#E5F0F7;">4.93</span></td>
<td id="S7.T16.27.27.53.8" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.53.8.1" class="ltx_text" style="background-color:#92BFDB;">4.16</span></td>
<td id="S7.T16.27.27.53.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">4.48</td>
<td id="S7.T16.27.27.53.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00/0.00</td>
</tr>
<tr id="S7.T16.27.27.54" class="ltx_tr">
<td id="S7.T16.27.27.54.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">ChatGLM&nbsp;(6B)</td>
<td id="S7.T16.27.27.54.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">30.42</td>
<td id="S7.T16.27.27.54.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">29.27</td>
<td id="S7.T16.27.27.54.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">33.18</td>
<td id="S7.T16.27.27.54.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">14.05</td>
<td id="S7.T16.27.27.54.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">14.09</td>
<td id="S7.T16.27.27.54.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">3.41</td>
<td id="S7.T16.27.27.54.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.10</td>
<td id="S7.T16.27.27.54.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.54.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00/0.00</td>
</tr>
<tr id="S7.T16.27.27.55" class="ltx_tr">
<td id="S7.T16.27.27.55.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;">LLaMA 2&nbsp;(7B)</td>
<td id="S7.T16.27.27.55.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.55.2.1" class="ltx_text" style="background-color:#C6DEED;">44.81</span></td>
<td id="S7.T16.27.27.55.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.55.3.1" class="ltx_text" style="background-color:#A7CBE2;">74.25</span></td>
<td id="S7.T16.27.27.55.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">41.72</td>
<td id="S7.T16.27.27.55.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.55.5.1" class="ltx_text" style="background-color:#C6DEED;">43.95</span></td>
<td id="S7.T16.27.27.55.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.55.6.1" class="ltx_text" style="background-color:#E5F0F7;">35.75</span></td>
<td id="S7.T16.27.27.55.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.55.7.1" class="ltx_text" style="background-color:#C6DEED;">10.99</span></td>
<td id="S7.T16.27.27.55.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.55.8.1" class="ltx_text" style="background-color:#E5F0F7;">2.64</span></td>
<td id="S7.T16.27.27.55.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.55.9.1" class="ltx_text" style="background-color:#A7CBE2;">8.96</span></td>
<td id="S7.T16.27.27.55.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">0.00/0.00</td>
</tr>
<tr id="S7.T16.27.27.56" class="ltx_tr">
<td id="S7.T16.27.27.56.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">LLaMA&nbsp;(7B)</td>
<td id="S7.T16.27.27.56.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">42.42</td>
<td id="S7.T16.27.27.56.3" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.56.3.1" class="ltx_text" style="background-color:#C4DDEC;">73.91</span></td>
<td id="S7.T16.27.27.56.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">41.46</td>
<td id="S7.T16.27.27.56.5" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.56.5.1" class="ltx_text" style="background-color:#E5F0F7;">39.95</span></td>
<td id="S7.T16.27.27.56.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">34.90</td>
<td id="S7.T16.27.27.56.7" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.56.7.1" class="ltx_text" style="background-color:#C6DEED;">10.99</span></td>
<td id="S7.T16.27.27.56.8" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.56.8.1" class="ltx_text" style="background-color:#C4DDEC;">3.12</span></td>
<td id="S7.T16.27.27.56.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">2.24</td>
<td id="S7.T16.27.27.56.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00/0.00</td>
</tr>
<tr id="S7.T16.27.27.57" class="ltx_tr">
<td id="S7.T16.27.27.57.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Falcon&nbsp;(7B)</td>
<td id="S7.T16.27.27.57.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">39.46</td>
<td id="S7.T16.27.27.57.3" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.57.3.1" class="ltx_text" style="background-color:#92BFDB;">74.58</span></td>
<td id="S7.T16.27.27.57.4" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.57.4.1" class="ltx_text" style="background-color:#E5F0F7;">
42.53</span></td>
<td id="S7.T16.27.27.57.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">29.80</td>
<td id="S7.T16.27.27.57.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">24.16</td>
<td id="S7.T16.27.27.57.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.67</td>
<td id="S7.T16.27.27.57.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.94</td>
<td id="S7.T16.27.27.57.9" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.57.9.1" class="ltx_text" style="background-color:#C4DDEC;">
7.46</span></td>
<td id="S7.T16.27.27.57.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00/0.00</td>
</tr>
<tr id="S7.T16.27.27.58" class="ltx_tr">
<td id="S7.T16.27.27.58.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Pythia&nbsp;(12B)</td>
<td id="S7.T16.27.27.58.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">37.02</td>
<td id="S7.T16.27.27.58.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">65.45</td>
<td id="S7.T16.27.27.58.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">41.53</td>
<td id="S7.T16.27.27.58.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">32.40</td>
<td id="S7.T16.27.27.58.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">26.17</td>
<td id="S7.T16.27.27.58.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">2.88</td>
<td id="S7.T16.27.27.58.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.96</td>
<td id="S7.T16.27.27.58.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">5.22</td>
<td id="S7.T16.27.27.58.10" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.58.10.1" class="ltx_text" style="background-color:#E5F0F7;">3.68/0.60</span></td>
</tr>
<tr id="S7.T16.27.27.59" class="ltx_tr">
<td id="S7.T16.27.27.59.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Pythia&nbsp;(7B)</td>
<td id="S7.T16.27.27.59.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">34.88</td>
<td id="S7.T16.27.27.59.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">61.82</td>
<td id="S7.T16.27.27.59.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">41.01</td>
<td id="S7.T16.27.27.59.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">29.05</td>
<td id="S7.T16.27.27.59.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">27.52</td>
<td id="S7.T16.27.27.59.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.82</td>
<td id="S7.T16.27.27.59.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.46</td>
<td id="S7.T16.27.27.59.9" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.59.9.1" class="ltx_text" style="background-color:#C4DDEC;">7.46</span></td>
<td id="S7.T16.27.27.59.10" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.59.10.1" class="ltx_text" style="background-color:#C6DEED;">10.75/1.80</span></td>
</tr>
<tr id="S7.T16.27.27.60" class="ltx_tr">
<td id="S7.T16.27.27.60.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;" rowspan="2"><span id="S7.T16.27.27.60.1.1" class="ltx_text ltx_font_bold">Models</span></td>
<td id="S7.T16.27.27.60.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;" colspan="5"><span id="S7.T16.27.27.60.2.1" class="ltx_text ltx_font_bold">Human Alignment</span></td>
<td id="S7.T16.27.27.60.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;" colspan="4"><span id="S7.T16.27.27.60.3.1" class="ltx_text ltx_font_bold">Tool Manipulation</span></td>
</tr>
<tr id="S7.T16.27.27.27" class="ltx_tr">
<td id="S7.T16.19.19.19.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">TfQA<math id="S7.T16.19.19.19.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.19.19.19.1.m1.1a"><mo stretchy="false" id="S7.T16.19.19.19.1.m1.1.1" xref="S7.T16.19.19.19.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.19.19.19.1.m1.1b"><ci id="S7.T16.19.19.19.1.m1.1.1.cmml" xref="S7.T16.19.19.19.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.19.19.19.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.20.20.20.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">C-Pairs<math id="S7.T16.20.20.20.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S7.T16.20.20.20.2.m1.1a"><mo stretchy="false" id="S7.T16.20.20.20.2.m1.1.1" xref="S7.T16.20.20.20.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S7.T16.20.20.20.2.m1.1b"><ci id="S7.T16.20.20.20.2.m1.1.1.cmml" xref="S7.T16.20.20.20.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.20.20.20.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S7.T16.21.21.21.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">WinoGender<math id="S7.T16.21.21.21.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.21.21.21.3.m1.1a"><mo stretchy="false" id="S7.T16.21.21.21.3.m1.1.1" xref="S7.T16.21.21.21.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.21.21.21.3.m1.1b"><ci id="S7.T16.21.21.21.3.m1.1.1.cmml" xref="S7.T16.21.21.21.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.21.21.21.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.22.22.22.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">RTP<math id="S7.T16.22.22.22.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S7.T16.22.22.22.4.m1.1a"><mo stretchy="false" id="S7.T16.22.22.22.4.m1.1.1" xref="S7.T16.22.22.22.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S7.T16.22.22.22.4.m1.1b"><ci id="S7.T16.22.22.22.4.m1.1.1.cmml" xref="S7.T16.22.22.22.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.22.22.22.4.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S7.T16.23.23.23.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">HaluEval<math id="S7.T16.23.23.23.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.23.23.23.5.m1.1a"><mo stretchy="false" id="S7.T16.23.23.23.5.m1.1.1" xref="S7.T16.23.23.23.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.23.23.23.5.m1.1b"><ci id="S7.T16.23.23.23.5.m1.1.1.cmml" xref="S7.T16.23.23.23.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.23.23.23.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.24.24.24.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">HotpotQA<math id="S7.T16.24.24.24.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.24.24.24.6.m1.1a"><mo stretchy="false" id="S7.T16.24.24.24.6.m1.1.1" xref="S7.T16.24.24.24.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.24.24.24.6.m1.1b"><ci id="S7.T16.24.24.24.6.m1.1.1.cmml" xref="S7.T16.24.24.24.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.24.24.24.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.25.25.25.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">Gorilla-TH<math id="S7.T16.25.25.25.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.25.25.25.7.m1.1a"><mo stretchy="false" id="S7.T16.25.25.25.7.m1.1.1" xref="S7.T16.25.25.25.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.25.25.25.7.m1.1b"><ci id="S7.T16.25.25.25.7.m1.1.1.cmml" xref="S7.T16.25.25.25.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.25.25.25.7.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.26.26.26.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">Gorilla-TF<math id="S7.T16.26.26.26.8.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.26.26.26.8.m1.1a"><mo stretchy="false" id="S7.T16.26.26.26.8.m1.1.1" xref="S7.T16.26.26.26.8.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.26.26.26.8.m1.1b"><ci id="S7.T16.26.26.26.8.m1.1.1.cmml" xref="S7.T16.26.26.26.8.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.26.26.26.8.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S7.T16.27.27.27.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">Gorilla-HF<math id="S7.T16.27.27.27.9.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S7.T16.27.27.27.9.m1.1a"><mo stretchy="false" id="S7.T16.27.27.27.9.m1.1.1" xref="S7.T16.27.27.27.9.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S7.T16.27.27.27.9.m1.1b"><ci id="S7.T16.27.27.27.9.m1.1.1.cmml" xref="S7.T16.27.27.27.9.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T16.27.27.27.9.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S7.T16.27.27.61" class="ltx_tr">
<td id="S7.T16.27.27.61.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;">ChatGPT</td>
<td id="S7.T16.27.27.61.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.61.2.1" class="ltx_text" style="background-color:#FCA77F;">69.16</span></td>
<td id="S7.T16.27.27.61.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.61.3.1" class="ltx_text" style="background-color:#FEE8DD;">18.60</span></td>
<td id="S7.T16.27.27.61.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.61.4.1" class="ltx_text" style="background-color:#FCA77F;">62.50/<span id="S7.T16.27.27.61.4.1.1" class="ltx_text">72.50/<span id="S7.T16.27.27.61.4.1.1.1" class="ltx_text">79.17</span></span></span></td>
<td id="S7.T16.27.27.61.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.61.5.1" class="ltx_text" style="background-color:#FC8D59;">3.07</span></td>
<td id="S7.T16.27.27.61.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.61.6.1" class="ltx_text" style="background-color:#FC8D59;">66.64</span></td>
<td id="S7.T16.27.27.61.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.61.7.1" class="ltx_text" style="background-color:#FEF7F3;">23.80</span></td>
<td id="S7.T16.27.27.61.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.61.8.1" class="ltx_text" style="background-color:#FCA77F;">67.20</span></td>
<td id="S7.T16.27.27.61.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.61.9.1" class="ltx_text" style="background-color:#FC8D59;">
44.53</span></td>
<td id="S7.T16.27.27.61.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.61.10.1" class="ltx_text" style="background-color:#FCA77F;">19.36</span></td>
</tr>
<tr id="S7.T16.27.27.62" class="ltx_tr">
<td id="S7.T16.27.27.62.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Claude</td>
<td id="S7.T16.27.27.62.2" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.62.2.1" class="ltx_text" style="background-color:#FEDCCC;">67.93</span></td>
<td id="S7.T16.27.27.62.3" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.62.3.1" class="ltx_text" style="background-color:#FEF7F3;">32.73</span></td>
<td id="S7.T16.27.27.62.4" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.62.4.1" class="ltx_text" style="background-color:#FEE8DD;">71.67/<span id="S7.T16.27.27.62.4.1.1" class="ltx_text">55.00/<span id="S7.T16.27.27.62.4.1.1.1" class="ltx_text">52.50</span></span></span></td>
<td id="S7.T16.27.27.62.5" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.62.5.1" class="ltx_text" style="background-color:#FEDCCC;">3.75</span></td>
<td id="S7.T16.27.27.62.6" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.62.6.1" class="ltx_text" style="background-color:#FCA77F;">63.75</span></td>
<td id="S7.T16.27.27.62.7" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.62.7.1" class="ltx_text" style="background-color:#FEDCCC;">33.80</span></td>
<td id="S7.T16.27.27.62.8" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.62.8.1" class="ltx_text" style="background-color:#FEE8DD;">22.04</span></td>
<td id="S7.T16.27.27.62.9" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.62.9.1" class="ltx_text" style="background-color:#FEDCCC;">7.74</span></td>
<td id="S7.T16.27.27.62.10" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.62.10.1" class="ltx_text" style="background-color:#FEDCCC;">7.08</span></td>
</tr>
<tr id="S7.T16.27.27.63" class="ltx_tr">
<td id="S7.T16.27.27.63.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Claude 2</td>
<td id="S7.T16.27.27.63.2" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.63.2.1" class="ltx_text" style="background-color:#FC8D59;">71.11</span></td>
<td id="S7.T16.27.27.63.3" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.63.3.1" class="ltx_text" style="background-color:#FEDCCC;">10.67</span></td>
<td id="S7.T16.27.27.63.4" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.63.4.1" class="ltx_text" style="background-color:#FEF7F3;">60.00/60.00/55.83</span></td>
<td id="S7.T16.27.27.63.5" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.63.5.1" class="ltx_text" style="background-color:#FCA77F;">3.20</span></td>
<td id="S7.T16.27.27.63.6" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.63.6.1" class="ltx_text" style="background-color:#FEF7F3;">50.63</span></td>
<td id="S7.T16.27.27.63.7" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.63.7.1" class="ltx_text" style="background-color:#FC8D59;">36.4</span></td>
<td id="S7.T16.27.27.63.8" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.63.8.1" class="ltx_text" style="background-color:#FEDCCC;">61.29</span></td>
<td id="S7.T16.27.27.63.9" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.63.9.1" class="ltx_text" style="background-color:#FCA77F;">22.19</span></td>
<td id="S7.T16.27.27.63.10" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.63.10.1" class="ltx_text" style="background-color:#FC8D59;">23.67</span></td>
</tr>
<tr id="S7.T16.27.27.64" class="ltx_tr">
<td id="S7.T16.27.27.64.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Davinci003</td>
<td id="S7.T16.27.27.64.2" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.64.2.1" class="ltx_text" style="background-color:#FEE8DD;">60.83</span></td>
<td id="S7.T16.27.27.64.3" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.64.3.1" class="ltx_text" style="background-color:#FC8D59;">0.99</span></td>
<td id="S7.T16.27.27.64.4" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.64.4.1" class="ltx_text" style="background-color:#FC8D59;">67.50/68.33/79.17</span></td>
<td id="S7.T16.27.27.64.5" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.64.5.1" class="ltx_text" style="background-color:#FEE8DD;">8.81</span></td>
<td id="S7.T16.27.27.64.6" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.64.6.1" class="ltx_text" style="background-color:#FEE8DD;">58.94</span></td>
<td id="S7.T16.27.27.64.7" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.64.7.1" class="ltx_text" style="background-color:#FCA77F;">
34.40</span></td>
<td id="S7.T16.27.27.64.8" class="ltx_td ltx_align_center" style="background-color:#FC8D59;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.64.8.1" class="ltx_text" style="background-color:#FC8D59;">
72.58</span></td>
<td id="S7.T16.27.27.64.9" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.64.9.1" class="ltx_text" style="background-color:#FEE8DD;">3.80</span></td>
<td id="S7.T16.27.27.64.10" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.64.10.1" class="ltx_text" style="background-color:#FEE8DD;">6.42</span></td>
</tr>
<tr id="S7.T16.27.27.65" class="ltx_tr">
<td id="S7.T16.27.27.65.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Davinci002</td>
<td id="S7.T16.27.27.65.2" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.65.2.1" class="ltx_text" style="background-color:#FEF7F3;">53.73</span></td>
<td id="S7.T16.27.27.65.3" class="ltx_td ltx_align_center" style="background-color:#FCA77F;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.65.3.1" class="ltx_text" style="background-color:#FCA77F;">7.56</span></td>
<td id="S7.T16.27.27.65.4" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.65.4.1" class="ltx_text" style="background-color:#FEDCCC;">72.50/70.00/64.17</span></td>
<td id="S7.T16.27.27.65.5" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.65.5.1" class="ltx_text" style="background-color:#FEF7F3;">10.65</span></td>
<td id="S7.T16.27.27.65.6" class="ltx_td ltx_align_center" style="background-color:#FEDCCC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.65.6.1" class="ltx_text" style="background-color:#FEDCCC;">59.67</span></td>
<td id="S7.T16.27.27.65.7" class="ltx_td ltx_align_center" style="background-color:#FEE8DD;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.65.7.1" class="ltx_text" style="background-color:#FEE8DD;">26.00</span></td>
<td id="S7.T16.27.27.65.8" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.65.8.1" class="ltx_text" style="background-color:#FEF7F3;">2.69</span></td>
<td id="S7.T16.27.27.65.9" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.65.9.1" class="ltx_text" style="background-color:#FEF7F3;">1.02</span></td>
<td id="S7.T16.27.27.65.10" class="ltx_td ltx_align_center" style="background-color:#FEF7F3;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.65.10.1" class="ltx_text" style="background-color:#FEF7F3;">1.00</span></td>
</tr>
<tr id="S7.T16.27.27.66" class="ltx_tr">
<td id="S7.T16.27.27.66.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;">LLaMA 2-Chat&nbsp;(7B)</td>
<td id="S7.T16.27.27.66.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.66.2.1" class="ltx_text" style="background-color:#92BFDB;">69.77</span></td>
<td id="S7.T16.27.27.66.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.66.3.1" class="ltx_text" style="background-color:#A7CBE2;">48.54</span></td>
<td id="S7.T16.27.27.66.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">47.50/46.67/46.67</td>
<td id="S7.T16.27.27.66.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.66.5.1" class="ltx_text" style="background-color:#A7CBE2;">4.61</span></td>
<td id="S7.T16.27.27.66.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.66.6.1" class="ltx_text" style="background-color:#C6DEED;">43.82</span></td>
<td id="S7.T16.27.27.66.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.66.7.1" class="ltx_text" style="background-color:#C4DDEC;">4.40</span></td>
<td id="S7.T16.27.27.66.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.66.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.66.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.66.10.1" class="ltx_text" style="background-color:#C6DEED;">0.22</span></td>
</tr>
<tr id="S7.T16.27.27.67" class="ltx_tr">
<td id="S7.T16.27.27.67.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Vicuna&nbsp;(13B)</td>
<td id="S7.T16.27.27.67.2" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.67.2.1" class="ltx_text" style="background-color:#C6DEED;">62.30</span></td>
<td id="S7.T16.27.27.67.3" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.67.3.1" class="ltx_text" style="background-color:#92BFDB;">45.95</span></td>
<td id="S7.T16.27.27.67.4" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.67.4.1" class="ltx_text" style="background-color:#C6DEED;">50.83/50.83/52.50</span></td>
<td id="S7.T16.27.27.67.5" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.67.5.1" class="ltx_text" style="background-color:#E5F0F7;">5.00</span></td>
<td id="S7.T16.27.27.67.6" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.67.6.1" class="ltx_text" style="background-color:#92BFDB;">49.01</span></td>
<td id="S7.T16.27.27.67.7" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.67.7.1" class="ltx_text" style="background-color:#A7CBE2;">11.20</span></td>
<td id="S7.T16.27.27.67.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.67.9" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.67.9.1" class="ltx_text" style="background-color:#92BFDB;">0.44</span></td>
<td id="S7.T16.27.27.67.10" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.67.10.1" class="ltx_text" style="background-color:#92BFDB;">0.89</span></td>
</tr>
<tr id="S7.T16.27.27.68" class="ltx_tr">
<td id="S7.T16.27.27.68.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Vicuna&nbsp;(7B)</td>
<td id="S7.T16.27.27.68.2" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.68.2.1" class="ltx_text" style="background-color:#C4DDEC;">57.77</span></td>
<td id="S7.T16.27.27.68.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">67.44</td>
<td id="S7.T16.27.27.68.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">49.17/49.17/49.17</td>
<td id="S7.T16.27.27.68.5" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.68.5.1" class="ltx_text" style="background-color:#C6DEED;">4.70</span></td>
<td id="S7.T16.27.27.68.6" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.68.6.1" class="ltx_text" style="background-color:#C4DDEC;">43.44</span></td>
<td id="S7.T16.27.27.68.7" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.68.7.1" class="ltx_text" style="background-color:#C6DEED;">6.20</span></td>
<td id="S7.T16.27.27.68.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.68.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.68.10" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.68.10.1" class="ltx_text" style="background-color:#A7CBE2;">0.33</span></td>
</tr>
<tr id="S7.T16.27.27.69" class="ltx_tr">
<td id="S7.T16.27.27.69.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Alpaca&nbsp;(7B)</td>
<td id="S7.T16.27.27.69.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">46.14</td>
<td id="S7.T16.27.27.69.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">65.45</td>
<td id="S7.T16.27.27.69.4" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.69.4.1" class="ltx_text" style="background-color:#A7CBE2;">53.33/51.67/53.33</span></td>
<td id="S7.T16.27.27.69.5" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.69.5.1" class="ltx_text" style="background-color:#C4DDEC;">4.78</span></td>
<td id="S7.T16.27.27.69.6" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.69.6.1" class="ltx_text" style="background-color:#A7CBE2;">44.16</span></td>
<td id="S7.T16.27.27.69.7" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.69.7.1" class="ltx_text" style="background-color:#92BFDB;">11.60</span></td>
<td id="S7.T16.27.27.69.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.69.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.69.10" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.69.10.1" class="ltx_text" style="background-color:#C4DDEC;">0.11</span></td>
</tr>
<tr id="S7.T16.27.27.70" class="ltx_tr">
<td id="S7.T16.27.27.70.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">ChatGLM&nbsp;(6B)</td>
<td id="S7.T16.27.27.70.2" class="ltx_td ltx_align_center" style="background-color:#A7CBE2;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.70.2.1" class="ltx_text" style="background-color:#A7CBE2;">63.53</span></td>
<td id="S7.T16.27.27.70.3" class="ltx_td ltx_align_center" style="background-color:#C6DEED;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.70.3.1" class="ltx_text" style="background-color:#C6DEED;">50.53</span></td>
<td id="S7.T16.27.27.70.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">47.50/47.50/46.67</td>
<td id="S7.T16.27.27.70.5" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.70.5.1" class="ltx_text" style="background-color:#92BFDB;">2.89</span></td>
<td id="S7.T16.27.27.70.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">41.82</td>
<td id="S7.T16.27.27.70.7" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.70.7.1" class="ltx_text" style="background-color:#E5F0F7;">4.00</span></td>
<td id="S7.T16.27.27.70.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.70.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.70.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
</tr>
<tr id="S7.T16.27.27.71" class="ltx_tr">
<td id="S7.T16.27.27.71.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 2.5pt;">LLaMA 2&nbsp;(7B)</td>
<td id="S7.T16.27.27.71.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">50.06</td>
<td id="S7.T16.27.27.71.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.71.3.1" class="ltx_text" style="background-color:#C4DDEC;">51.39</span></td>
<td id="S7.T16.27.27.71.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">48.83/48.83/50.83</td>
<td id="S7.T16.27.27.71.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">6.17</td>
<td id="S7.T16.27.27.71.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.71.6.1" class="ltx_text" style="background-color:#E5F0F7;">42.23</span></td>
<td id="S7.T16.27.27.71.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">3.80</td>
<td id="S7.T16.27.27.71.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.71.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.71.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.71.10.1" class="ltx_text" style="background-color:#C4DDEC;">0.11</span></td>
</tr>
<tr id="S7.T16.27.27.72" class="ltx_tr">
<td id="S7.T16.27.27.72.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">LLaMA&nbsp;(7B)</td>
<td id="S7.T16.27.27.72.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">47.86</td>
<td id="S7.T16.27.27.72.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">67.84</td>
<td id="S7.T16.27.27.72.4" class="ltx_td ltx_align_center" style="background-color:#92BFDB;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.72.4.1" class="ltx_text" style="background-color:#92BFDB;">54.17/52.50/51.67</span></td>
<td id="S7.T16.27.27.72.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">5.94</td>
<td id="S7.T16.27.27.72.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">14.18</td>
<td id="S7.T16.27.27.72.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.60</td>
<td id="S7.T16.27.27.72.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.72.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.72.10" class="ltx_td ltx_align_center" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.72.10.1" class="ltx_text" style="background-color:#C4DDEC;">0.11</span></td>
</tr>
<tr id="S7.T16.27.27.73" class="ltx_tr">
<td id="S7.T16.27.27.73.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Falcon&nbsp;(7B)</td>
<td id="S7.T16.27.27.73.2" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">53.24</td>
<td id="S7.T16.27.27.73.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">68.04</td>
<td id="S7.T16.27.27.73.4" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.73.4.1" class="ltx_text" style="background-color:#E5F0F7;">50.00/50.83/50.00</span></td>
<td id="S7.T16.27.27.73.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">6.71</td>
<td id="S7.T16.27.27.73.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">37.41</td>
<td id="S7.T16.27.27.73.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">1.00</td>
<td id="S7.T16.27.27.73.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.73.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.73.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
</tr>
<tr id="S7.T16.27.27.74" class="ltx_tr">
<td id="S7.T16.27.27.74.1" class="ltx_td ltx_align_left" style="padding:0.5pt 2.5pt;">Pythia&nbsp;(12B)</td>
<td id="S7.T16.27.27.74.2" class="ltx_td ltx_align_center" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.74.2.1" class="ltx_text" style="background-color:#E5F0F7;">54.47</span></td>
<td id="S7.T16.27.27.74.3" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">65.78</td>
<td id="S7.T16.27.27.74.4" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">49.17/48.33/49.17</td>
<td id="S7.T16.27.27.74.5" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">6.59</td>
<td id="S7.T16.27.27.74.6" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">27.09</td>
<td id="S7.T16.27.27.74.7" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.40</td>
<td id="S7.T16.27.27.74.8" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.74.9" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.74.10" class="ltx_td ltx_align_center" style="padding:0.5pt 2.5pt;">0.00</td>
</tr>
<tr id="S7.T16.27.27.75" class="ltx_tr">
<td id="S7.T16.27.27.75.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.5pt 2.5pt;">Pythia&nbsp;(7B)</td>
<td id="S7.T16.27.27.75.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 2.5pt;">50.92</td>
<td id="S7.T16.27.27.75.3" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E5F0F7;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.75.3.1" class="ltx_text" style="background-color:#E5F0F7;">64.79</span></td>
<td id="S7.T16.27.27.75.4" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#C4DDEC;padding:0.5pt 2.5pt;"><span id="S7.T16.27.27.75.4.1" class="ltx_text" style="background-color:#C4DDEC;">51.67/49.17/50.00</span></td>
<td id="S7.T16.27.27.75.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 2.5pt;">13.02</td>
<td id="S7.T16.27.27.75.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 2.5pt;">25.84</td>
<td id="S7.T16.27.27.75.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 2.5pt;">0.20</td>
<td id="S7.T16.27.27.75.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.75.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 2.5pt;">0.00</td>
<td id="S7.T16.27.27.75.10" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 2.5pt;">0.00</td>
</tr>
</tbody></table>
</span></div>
</figure>
<figure id="S7.T17" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE XVII:</span>Prompt examples and their performance of ChatGPT on representative tasks. 대부분의 작업에 대해 <em class="ltx_emph ltx_font_italic" id="S7.T17.42.1">simple</em> 및 <em class="ltx_emph ltx_font_italic" id="S7.T17.43.2">complex</em> 프롬프트에 대한 성능을 비교합니다. 우리는 또한 감독된 방법의 보고된 성능을 제시한다. “LG”, “KU”, “CR”, “SDG”, “IR”은 “언어 생성”, “지식 활용”, “복잡한 추론”, “정형 데이터 생성”, “정보 검색”의 줄임말이다. "-"는 이전에 이 데이터 세트에 보고된 감독 결과가 없음을 의미한다.</figcaption>
<table id="S7.T17.39" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S7.T17.39.40" class="ltx_tr">
<td id="S7.T17.39.40.1" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S7.T17.39.40.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Tasks</span></td>
<td id="S7.T17.39.40.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S7.T17.39.40.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Datasets</span></td>
<td id="S7.T17.39.40.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S7.T17.39.40.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.40.3.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.40.3.1.1.1" class="ltx_text"></span><span id="S7.T17.39.40.3.1.1.2" class="ltx_text" style="font-size:70%;"> </span><span id="S7.T17.39.40.3.1.1.3" class="ltx_text" style="font-size:70%;">
<span id="S7.T17.39.40.3.1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T17.39.40.3.1.1.3.1.1" class="ltx_tr">
<span id="S7.T17.39.40.3.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T17.39.40.3.1.1.3.1.1.1.1" class="ltx_text ltx_font_bold">Instructions</span></span></span>
</span></span><span id="S7.T17.39.40.3.1.1.4" class="ltx_text"></span><span id="S7.T17.39.40.3.1.1.5" class="ltx_text" style="font-size:70%;"></span></span>
</span>
</td>
<td id="S7.T17.39.40.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="S7.T17.39.40.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">ChatGPT</span></td>
<td id="S7.T17.39.40.5" class="ltx_td ltx_align_right ltx_border_tt"><span id="S7.T17.39.40.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Supervised</span></td>
</tr>
<tr id="S7.T17.39.41" class="ltx_tr">
<td id="S7.T17.39.41.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S7.T17.39.41.1.1" class="ltx_text" style="font-size:70%;">LG</span></td>
<td id="S7.T17.39.41.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" rowspan="2">
<span id="S7.T17.39.41.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.41.2.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.39.41.2.1.1.1" class="ltx_text" style="font-size:70%;">Translation</span></span>
</span>
</td>
<td id="S7.T17.39.41.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T17.39.41.3.1" class="ltx_text" style="font-size:70%;">WMT</span></td>
<td id="S7.T17.39.41.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.41.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.41.4.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.41.4.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">I want you to act as a translator. Please translate the English sentence into Czech.</span></span>
</span>
</td>
<td id="S7.T17.39.41.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.41.5.1" class="ltx_text" style="font-size:70%;">20.66</span></td>
<td id="S7.T17.39.41.6" class="ltx_td ltx_align_right ltx_border_t" rowspan="2"><span id="S7.T17.39.41.6.1" class="ltx_text" style="font-size:70%;">41.40&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib739" title="" class="ltx_ref">739</a>]</cite></span></td>
</tr>
<tr id="S7.T17.2.2" class="ltx_tr">
<td id="S7.T17.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.2.2.2.2" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.2.2.2.2.2" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.2.2.2.2.2.2" class="ltx_text ltx_font_typewriter" style="font-size:70%;">I want you to act as a translator. Translate the given English sentence into Czech, and ensure that the translated sentence is semantically consistent with the given sentence. <math id="S7.T17.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.1.1.1.1.1.1.m1.1a"><mo id="S7.T17.1.1.1.1.1.1.m1.1.1" xref="S7.T17.1.1.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.1.1.1.1.1.1.m1.1b"><ci id="S7.T17.1.1.1.1.1.1.m1.1.1.cmml" xref="S7.T17.1.1.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.1.1.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n Sentence: {source sentence} <math id="S7.T17.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.2.2.2.2.2.2.m2.1a"><mo id="S7.T17.2.2.2.2.2.2.m2.1.1" xref="S7.T17.2.2.2.2.2.2.m2.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.2.2.2.2.2.2.m2.1b"><ci id="S7.T17.2.2.2.2.2.2.m2.1.1.cmml" xref="S7.T17.2.2.2.2.2.2.m2.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.2.2.2.2.2.2.m2.1c">\backslash</annotation></semantics></math>n Translation:</span></span>
</span>
</td>
<td id="S7.T17.2.2.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.2.2.3.1" class="ltx_text" style="font-size:70%;">21.12</span></td>
</tr>
<tr id="S7.T17.39.42" class="ltx_tr">
<td id="S7.T17.39.42.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" rowspan="2">
<span id="S7.T17.39.42.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.42.1.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.39.42.1.1.1.1" class="ltx_text" style="font-size:70%;">Summarization</span></span>
</span>
</td>
<td id="S7.T17.39.42.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T17.39.42.2.1" class="ltx_text" style="font-size:70%;">XSum</span></td>
<td id="S7.T17.39.42.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.42.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.42.3.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.42.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Please generate a one-sentence summary for the given document.</span></span>
</span>
</td>
<td id="S7.T17.39.42.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.42.4.1" class="ltx_text" style="font-size:70%;">21.71</span></td>
<td id="S7.T17.39.42.5" class="ltx_td ltx_align_right ltx_border_t" rowspan="2"><span id="S7.T17.39.42.5.1" class="ltx_text" style="font-size:70%;">42.08&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib740" title="" class="ltx_ref">740</a>]</cite></span></td>
</tr>
<tr id="S7.T17.3.3" class="ltx_tr">
<td id="S7.T17.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.3.3.1.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.3.3.1.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">{document} Try your best to summarize the main content of the given document. And generate a short summary in 1 sentence for it.<math id="S7.T17.3.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.3.3.1.1.1.1.m1.1a"><mo id="S7.T17.3.3.1.1.1.1.m1.1.1" xref="S7.T17.3.3.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.3.3.1.1.1.1.m1.1b"><ci id="S7.T17.3.3.1.1.1.1.m1.1.1.cmml" xref="S7.T17.3.3.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.3.3.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n Summary:</span></span>
</span>
</td>
<td id="S7.T17.3.3.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.3.3.2.1" class="ltx_text" style="font-size:70%;">23.01</span></td>
</tr>
<tr id="S7.T17.39.43" class="ltx_tr">
<td id="S7.T17.39.43.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="6"><span id="S7.T17.39.43.1.1" class="ltx_text" style="font-size:70%;">KU</span></td>
<td id="S7.T17.39.43.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" rowspan="2">
<span id="S7.T17.39.43.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.43.2.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.39.43.2.1.1.1" class="ltx_text" style="font-size:70%;">Closed-Book QA</span></span>
</span>
</td>
<td id="S7.T17.39.43.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T17.39.43.3.1" class="ltx_text" style="font-size:70%;">ARC</span></td>
<td id="S7.T17.39.43.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.43.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.43.4.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.43.4.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Choose your answer to the question. {query} {options}</span></span>
</span>
</td>
<td id="S7.T17.39.43.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.43.5.1" class="ltx_text" style="font-size:70%;">85.19</span></td>
<td id="S7.T17.39.43.6" class="ltx_td ltx_align_right ltx_border_t" rowspan="2"><span id="S7.T17.39.43.6.1" class="ltx_text" style="font-size:70%;">92.00&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib741" title="" class="ltx_ref">741</a>]</cite></span></td>
</tr>
<tr id="S7.T17.39.44" class="ltx_tr">
<td id="S7.T17.39.44.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.44.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.44.1.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.44.1.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Choose a correct answer according to the given question, and output the corresponding id, do not answer other content except the answer id.</span></span>
</span>
</td>
<td id="S7.T17.39.44.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.44.2.1" class="ltx_text" style="font-size:70%;">85.86</span></td>
</tr>
<tr id="S7.T17.39.45" class="ltx_tr">
<td id="S7.T17.39.45.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" rowspan="2">
<span id="S7.T17.39.45.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.45.1.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.39.45.1.1.1.1" class="ltx_text" style="font-size:70%;">Open-Book QA</span></span>
</span>
</td>
<td id="S7.T17.39.45.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T17.39.45.2.1" class="ltx_text" style="font-size:70%;">OBQA</span></td>
<td id="S7.T17.39.45.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.45.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.45.3.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.45.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Choose your answer to the question: {question} {choices}. You must only output A, B, C, or D without any extra explanation. The answer is</span></span>
</span>
</td>
<td id="S7.T17.39.45.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.45.4.1" class="ltx_text" style="font-size:70%;">81.20</span></td>
<td id="S7.T17.39.45.5" class="ltx_td ltx_align_right ltx_border_t" rowspan="2"><span id="S7.T17.39.45.5.1" class="ltx_text" style="font-size:70%;">87.20&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib741" title="" class="ltx_ref">741</a>]</cite></span></td>
</tr>
<tr id="S7.T17.10.10" class="ltx_tr">
<td id="S7.T17.10.10.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.10.10.7.7" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.10.10.7.7.7" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.10.10.7.7.7.7" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Following is a question that requires multi-step reasoning, use of additional common and commonsense knowledge, and rich text comprehension. Choose your answer to the question: <math id="S7.T17.4.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.4.4.1.1.1.1.m1.1a"><mo id="S7.T17.4.4.1.1.1.1.m1.1.1" xref="S7.T17.4.4.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.4.4.1.1.1.1.m1.1b"><ci id="S7.T17.4.4.1.1.1.1.m1.1.1.cmml" xref="S7.T17.4.4.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.4.4.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n Question: Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as <math id="S7.T17.5.5.2.2.2.2.m2.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.5.5.2.2.2.2.m2.1a"><mo id="S7.T17.5.5.2.2.2.2.m2.1.1" xref="S7.T17.5.5.2.2.2.2.m2.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.5.5.2.2.2.2.m2.1b"><ci id="S7.T17.5.5.2.2.2.2.m2.1.1.cmml" xref="S7.T17.5.5.2.2.2.2.m2.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.5.5.2.2.2.2.m2.1c">\backslash</annotation></semantics></math>n Choices: <math id="S7.T17.6.6.3.3.3.3.m3.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.6.6.3.3.3.3.m3.1a"><mo id="S7.T17.6.6.3.3.3.3.m3.1.1" xref="S7.T17.6.6.3.3.3.3.m3.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.6.6.3.3.3.3.m3.1b"><ci id="S7.T17.6.6.3.3.3.3.m3.1.1.cmml" xref="S7.T17.6.6.3.3.3.3.m3.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.6.6.3.3.3.3.m3.1c">\backslash</annotation></semantics></math>n A. Deep sea animals <math id="S7.T17.7.7.4.4.4.4.m4.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.7.7.4.4.4.4.m4.1a"><mo id="S7.T17.7.7.4.4.4.4.m4.1.1" xref="S7.T17.7.7.4.4.4.4.m4.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.7.7.4.4.4.4.m4.1b"><ci id="S7.T17.7.7.4.4.4.4.m4.1.1.cmml" xref="S7.T17.7.7.4.4.4.4.m4.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.7.7.4.4.4.4.m4.1c">\backslash</annotation></semantics></math>n B. fish <math id="S7.T17.8.8.5.5.5.5.m5.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.8.8.5.5.5.5.m5.1a"><mo id="S7.T17.8.8.5.5.5.5.m5.1.1" xref="S7.T17.8.8.5.5.5.5.m5.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.8.8.5.5.5.5.m5.1b"><ci id="S7.T17.8.8.5.5.5.5.m5.1.1.cmml" xref="S7.T17.8.8.5.5.5.5.m5.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.8.8.5.5.5.5.m5.1c">\backslash</annotation></semantics></math>n C. Long Sea Fish <math id="S7.T17.9.9.6.6.6.6.m6.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.9.9.6.6.6.6.m6.1a"><mo id="S7.T17.9.9.6.6.6.6.m6.1.1" xref="S7.T17.9.9.6.6.6.6.m6.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.9.9.6.6.6.6.m6.1b"><ci id="S7.T17.9.9.6.6.6.6.m6.1.1.cmml" xref="S7.T17.9.9.6.6.6.6.m6.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.9.9.6.6.6.6.m6.1c">\backslash</annotation></semantics></math>n D. Far Sea Animals <math id="S7.T17.10.10.7.7.7.7.m7.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.10.10.7.7.7.7.m7.1a"><mo id="S7.T17.10.10.7.7.7.7.m7.1.1" xref="S7.T17.10.10.7.7.7.7.m7.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.10.10.7.7.7.7.m7.1b"><ci id="S7.T17.10.10.7.7.7.7.m7.1.1.cmml" xref="S7.T17.10.10.7.7.7.7.m7.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.10.10.7.7.7.7.m7.1c">\backslash</annotation></semantics></math>n You must only output A, B, C, or D without any extra explanation. The answer is</span></span>
</span>
</td>
<td id="S7.T17.10.10.8" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.10.10.8.1" class="ltx_text" style="font-size:70%;">82.20</span></td>
</tr>
<tr id="S7.T17.39.46" class="ltx_tr">
<td id="S7.T17.39.46.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" rowspan="2">
<span id="S7.T17.39.46.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.46.1.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.39.46.1.1.1.1" class="ltx_text" style="font-size:70%;">Fact Extraction</span></span>
</span>
</td>
<td id="S7.T17.39.46.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T17.39.46.2.1" class="ltx_text" style="font-size:70%;">WikiF</span></td>
<td id="S7.T17.39.46.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.46.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.46.3.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.46.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Complete the sentence with one or a few words.</span></span>
</span>
</td>
<td id="S7.T17.39.46.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.46.4.1" class="ltx_text" style="font-size:70%;">29.25</span></td>
<td id="S7.T17.39.46.5" class="ltx_td ltx_align_right ltx_border_t" rowspan="2"><span id="S7.T17.39.46.5.1" class="ltx_text" style="font-size:70%;">34.20&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib520" title="" class="ltx_ref">520</a>]</cite></span></td>
</tr>
<tr id="S7.T17.39.47" class="ltx_tr">
<td id="S7.T17.39.47.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.47.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.47.1.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.47.1.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Complete the given sentence with one entity name in Wikipedia (MUST be a noun) as short as possible, and ensure that the completed sentence conforms to the facts.</span></span>
</span>
</td>
<td id="S7.T17.39.47.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.47.2.1" class="ltx_text" style="font-size:70%;">31.21</span></td>
</tr>
<tr id="S7.T17.11.11" class="ltx_tr">
<td id="S7.T17.11.11.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S7.T17.11.11.2.1" class="ltx_text" style="font-size:70%;">CR</span></td>
<td id="S7.T17.11.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" rowspan="2">
<span id="S7.T17.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.11.11.3.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.11.11.3.1.1.1" class="ltx_text" style="font-size:70%;">Symbolic Reasoning</span></span>
</span>
</td>
<td id="S7.T17.11.11.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T17.11.11.4.1" class="ltx_text" style="font-size:70%;">C-Objects</span></td>
<td id="S7.T17.11.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.11.11.1.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.11.11.1.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Problem: {problem}<math id="S7.T17.11.11.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.11.11.1.1.1.1.m1.1a"><mo id="S7.T17.11.11.1.1.1.1.m1.1.1" xref="S7.T17.11.11.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.11.11.1.1.1.1.m1.1b"><ci id="S7.T17.11.11.1.1.1.1.m1.1.1.cmml" xref="S7.T17.11.11.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.11.11.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n
Answer:</span></span>
</span>
</td>
<td id="S7.T17.11.11.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.11.11.5.1" class="ltx_text" style="font-size:70%;">53.20</span></td>
<td id="S7.T17.11.11.6" class="ltx_td ltx_align_right ltx_border_t" rowspan="2"><span id="S7.T17.11.11.6.1" class="ltx_text" style="font-size:70%;">—</span></td>
</tr>
<tr id="S7.T17.39.48" class="ltx_tr">
<td id="S7.T17.39.48.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.48.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.48.1.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.48.1.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">You are an expert in reasoning problem. Here are some examples about symbolic reasoning. You can use the knowledge in examples and solve the last problem. You should follow the examples and generate the final answer without external solution or words.</span></span>
</span>
</td>
<td id="S7.T17.39.48.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.48.2.1" class="ltx_text" style="font-size:70%;">66.75</span></td>
</tr>
<tr id="S7.T17.12.12" class="ltx_tr">
<td id="S7.T17.12.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" rowspan="2">
<span id="S7.T17.12.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.12.12.2.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.12.12.2.1.1.1" class="ltx_text" style="font-size:70%;">Math Word Problems</span></span>
</span>
</td>
<td id="S7.T17.12.12.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S7.T17.12.12.3.1" class="ltx_text" style="font-size:70%;">GSM8k</span></td>
<td id="S7.T17.12.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S7.T17.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.12.12.1.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.12.12.1.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Problem: {problem}<math id="S7.T17.12.12.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.12.12.1.1.1.1.m1.1a"><mo id="S7.T17.12.12.1.1.1.1.m1.1.1" xref="S7.T17.12.12.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.12.12.1.1.1.1.m1.1b"><ci id="S7.T17.12.12.1.1.1.1.m1.1.1.cmml" xref="S7.T17.12.12.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.12.12.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n
Solution: Let’s think step by step.</span></span>
</span>
</td>
<td id="S7.T17.12.12.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="S7.T17.12.12.4.1" class="ltx_text" style="font-size:70%;">78.47</span></td>
<td id="S7.T17.12.12.5" class="ltx_td ltx_align_right ltx_border_tt" rowspan="2"><span id="S7.T17.12.12.5.1" class="ltx_text" style="font-size:70%;">63.20&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib742" title="" class="ltx_ref">742</a>]</cite></span></td>
</tr>
<tr id="S7.T17.25.25" class="ltx_tr">
<td id="S7.T17.25.25.13" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.25.25.13.13" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.25.25.13.13.13" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.25.25.13.13.13.13" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Let’s use python to solve math problems. Here are three examples how to do it,<math id="S7.T17.13.13.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.13.13.1.1.1.1.m1.1a"><mo id="S7.T17.13.13.1.1.1.1.m1.1.1" xref="S7.T17.13.13.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.13.13.1.1.1.1.m1.1b"><ci id="S7.T17.13.13.1.1.1.1.m1.1.1.cmml" xref="S7.T17.13.13.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.13.13.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?<math id="S7.T17.14.14.2.2.2.2.m2.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.14.14.2.2.2.2.m2.1a"><mo id="S7.T17.14.14.2.2.2.2.m2.1.1" xref="S7.T17.14.14.2.2.2.2.m2.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.14.14.2.2.2.2.m2.1b"><ci id="S7.T17.14.14.2.2.2.2.m2.1.1.cmml" xref="S7.T17.14.14.2.2.2.2.m2.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.14.14.2.2.2.2.m2.1c">\backslash</annotation></semantics></math>n‘‘‘def solution():<math id="S7.T17.15.15.3.3.3.3.m3.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.15.15.3.3.3.3.m3.1a"><mo id="S7.T17.15.15.3.3.3.3.m3.1.1" xref="S7.T17.15.15.3.3.3.3.m3.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.15.15.3.3.3.3.m3.1b"><ci id="S7.T17.15.15.3.3.3.3.m3.1.1.cmml" xref="S7.T17.15.15.3.3.3.3.m3.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.15.15.3.3.3.3.m3.1c">\backslash</annotation></semantics></math>n &nbsp;&nbsp;&nbsp;&nbsp;"""Olivia has $23. She bought five bagels for $3 each. How much money does she have left?"""<math id="S7.T17.16.16.4.4.4.4.m4.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.16.16.4.4.4.4.m4.1a"><mo id="S7.T17.16.16.4.4.4.4.m4.1.1" xref="S7.T17.16.16.4.4.4.4.m4.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.16.16.4.4.4.4.m4.1b"><ci id="S7.T17.16.16.4.4.4.4.m4.1.1.cmml" xref="S7.T17.16.16.4.4.4.4.m4.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.16.16.4.4.4.4.m4.1c">\backslash</annotation></semantics></math>n &nbsp;&nbsp;&nbsp;&nbsp;money_initial = 23<math id="S7.T17.17.17.5.5.5.5.m5.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.17.17.5.5.5.5.m5.1a"><mo id="S7.T17.17.17.5.5.5.5.m5.1.1" xref="S7.T17.17.17.5.5.5.5.m5.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.17.17.5.5.5.5.m5.1b"><ci id="S7.T17.17.17.5.5.5.5.m5.1.1.cmml" xref="S7.T17.17.17.5.5.5.5.m5.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.17.17.5.5.5.5.m5.1c">\backslash</annotation></semantics></math>n &nbsp;&nbsp;&nbsp;&nbsp;bagels = 5<math id="S7.T17.18.18.6.6.6.6.m6.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.18.18.6.6.6.6.m6.1a"><mo id="S7.T17.18.18.6.6.6.6.m6.1.1" xref="S7.T17.18.18.6.6.6.6.m6.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.18.18.6.6.6.6.m6.1b"><ci id="S7.T17.18.18.6.6.6.6.m6.1.1.cmml" xref="S7.T17.18.18.6.6.6.6.m6.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.18.18.6.6.6.6.m6.1c">\backslash</annotation></semantics></math>n &nbsp;&nbsp;&nbsp;&nbsp;bagel_cost = 3<math id="S7.T17.19.19.7.7.7.7.m7.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.19.19.7.7.7.7.m7.1a"><mo id="S7.T17.19.19.7.7.7.7.m7.1.1" xref="S7.T17.19.19.7.7.7.7.m7.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.19.19.7.7.7.7.m7.1b"><ci id="S7.T17.19.19.7.7.7.7.m7.1.1.cmml" xref="S7.T17.19.19.7.7.7.7.m7.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.19.19.7.7.7.7.m7.1c">\backslash</annotation></semantics></math>n &nbsp;&nbsp;&nbsp;&nbsp;money_spent = bagels * bagel_cost<math id="S7.T17.20.20.8.8.8.8.m8.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.20.20.8.8.8.8.m8.1a"><mo id="S7.T17.20.20.8.8.8.8.m8.1.1" xref="S7.T17.20.20.8.8.8.8.m8.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.20.20.8.8.8.8.m8.1b"><ci id="S7.T17.20.20.8.8.8.8.m8.1.1.cmml" xref="S7.T17.20.20.8.8.8.8.m8.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.20.20.8.8.8.8.m8.1c">\backslash</annotation></semantics></math>n &nbsp;&nbsp;&nbsp;&nbsp;money_left = money_initial - money_spent<math id="S7.T17.21.21.9.9.9.9.m9.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.21.21.9.9.9.9.m9.1a"><mo id="S7.T17.21.21.9.9.9.9.m9.1.1" xref="S7.T17.21.21.9.9.9.9.m9.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.21.21.9.9.9.9.m9.1b"><ci id="S7.T17.21.21.9.9.9.9.m9.1.1.cmml" xref="S7.T17.21.21.9.9.9.9.m9.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.21.21.9.9.9.9.m9.1c">\backslash</annotation></semantics></math>n &nbsp;&nbsp;&nbsp;&nbsp;result = money_left<math id="S7.T17.22.22.10.10.10.10.m10.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.22.22.10.10.10.10.m10.1a"><mo id="S7.T17.22.22.10.10.10.10.m10.1.1" xref="S7.T17.22.22.10.10.10.10.m10.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.22.22.10.10.10.10.m10.1b"><ci id="S7.T17.22.22.10.10.10.10.m10.1.1.cmml" xref="S7.T17.22.22.10.10.10.10.m10.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.22.22.10.10.10.10.m10.1c">\backslash</annotation></semantics></math>n &nbsp;&nbsp;&nbsp;&nbsp;return result‘‘‘<math id="S7.T17.23.23.11.11.11.11.m11.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.23.23.11.11.11.11.m11.1a"><mo id="S7.T17.23.23.11.11.11.11.m11.1.1" xref="S7.T17.23.23.11.11.11.11.m11.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.23.23.11.11.11.11.m11.1b"><ci id="S7.T17.23.23.11.11.11.11.m11.1.1.cmml" xref="S7.T17.23.23.11.11.11.11.m11.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.23.23.11.11.11.11.m11.1c">\backslash</annotation></semantics></math>n ...... <math id="S7.T17.24.24.12.12.12.12.m12.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.24.24.12.12.12.12.m12.1a"><mo id="S7.T17.24.24.12.12.12.12.m12.1.1" xref="S7.T17.24.24.12.12.12.12.m12.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.24.24.12.12.12.12.m12.1b"><ci id="S7.T17.24.24.12.12.12.12.m12.1.1.cmml" xref="S7.T17.24.24.12.12.12.12.m12.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.24.24.12.12.12.12.m12.1c">\backslash</annotation></semantics></math>n How about this question?<math id="S7.T17.25.25.13.13.13.13.m13.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.25.25.13.13.13.13.m13.1a"><mo id="S7.T17.25.25.13.13.13.13.m13.1.1" xref="S7.T17.25.25.13.13.13.13.m13.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.25.25.13.13.13.13.m13.1b"><ci id="S7.T17.25.25.13.13.13.13.m13.1.1.cmml" xref="S7.T17.25.25.13.13.13.13.m13.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.25.25.13.13.13.13.m13.1c">\backslash</annotation></semantics></math>n Q:</span></span>
</span>
</td>
<td id="S7.T17.25.25.14" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.25.25.14.1" class="ltx_text" style="font-size:70%;">79.30</span></td>
</tr>
<tr id="S7.T17.39.49" class="ltx_tr">
<td id="S7.T17.39.49.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T17.39.49.1.1" class="ltx_text" style="font-size:70%;">SDG</span></td>
<td id="S7.T17.39.49.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.49.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.49.2.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.39.49.2.1.1.1" class="ltx_text" style="font-size:70%;">Code Synthesis</span></span>
</span>
</td>
<td id="S7.T17.39.49.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T17.39.49.3.1" class="ltx_text" style="font-size:70%;">HumanEval</span></td>
<td id="S7.T17.39.49.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.49.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.49.4.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.49.4.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">I want you act as a code completer. Given a code snippet, your objective is to complete the code and ensure that it can achieve the described functionality.</span></span>
</span>
</td>
<td id="S7.T17.39.49.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.49.5.1" class="ltx_text" style="font-size:70%;">79.88</span></td>
<td id="S7.T17.39.49.6" class="ltx_td ltx_align_right ltx_border_t">
<span id="S7.T17.39.49.6.1" class="ltx_text" style="font-size:70%;">48.20&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T17.39.49.6.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib743" title="" class="ltx_ref">743</a><span id="S7.T17.39.49.6.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
</tr>
<tr id="S7.T17.33.33" class="ltx_tr">
<td id="S7.T17.33.33.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.33.33.9.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.33.33.9.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.33.33.9.1.1.1" class="ltx_text"></span><span id="S7.T17.33.33.9.1.1.2" class="ltx_text" style="font-size:70%;">
<span id="S7.T17.33.33.9.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T17.33.33.9.1.1.2.1.1" class="ltx_tr">
<span id="S7.T17.33.33.9.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Text-to-SQL</span></span>
</span></span><span id="S7.T17.33.33.9.1.1.3" class="ltx_text"></span><span id="S7.T17.33.33.9.1.1.4" class="ltx_text" style="font-size:70%;"></span></span>
</span>
</td>
<td id="S7.T17.33.33.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T17.33.33.10.1" class="ltx_text" style="font-size:70%;">Spider</span></td>
<td id="S7.T17.33.33.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.33.33.8.8" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.33.33.8.8.8" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.33.33.8.8.8.8" class="ltx_text ltx_font_typewriter" style="font-size:70%;">### Complete sqlite SQL query only and with no explanation.<math id="S7.T17.26.26.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.26.26.1.1.1.1.m1.1a"><mo id="S7.T17.26.26.1.1.1.1.m1.1.1" xref="S7.T17.26.26.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.26.26.1.1.1.1.m1.1b"><ci id="S7.T17.26.26.1.1.1.1.m1.1.1.cmml" xref="S7.T17.26.26.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.26.26.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n #<math id="S7.T17.27.27.2.2.2.2.m2.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.27.27.2.2.2.2.m2.1a"><mo id="S7.T17.27.27.2.2.2.2.m2.1.1" xref="S7.T17.27.27.2.2.2.2.m2.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.27.27.2.2.2.2.m2.1b"><ci id="S7.T17.27.27.2.2.2.2.m2.1.1.cmml" xref="S7.T17.27.27.2.2.2.2.m2.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.27.27.2.2.2.2.m2.1c">\backslash</annotation></semantics></math>n### Sqlite SQL tables, with their properties: <math id="S7.T17.28.28.3.3.3.3.m3.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.28.28.3.3.3.3.m3.1a"><mo id="S7.T17.28.28.3.3.3.3.m3.1.1" xref="S7.T17.28.28.3.3.3.3.m3.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.28.28.3.3.3.3.m3.1b"><ci id="S7.T17.28.28.3.3.3.3.m3.1.1.cmml" xref="S7.T17.28.28.3.3.3.3.m3.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.28.28.3.3.3.3.m3.1c">\backslash</annotation></semantics></math>n#<math id="S7.T17.29.29.4.4.4.4.m4.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.29.29.4.4.4.4.m4.1a"><mo id="S7.T17.29.29.4.4.4.4.m4.1.1" xref="S7.T17.29.29.4.4.4.4.m4.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.29.29.4.4.4.4.m4.1b"><ci id="S7.T17.29.29.4.4.4.4.m4.1.1.cmml" xref="S7.T17.29.29.4.4.4.4.m4.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.29.29.4.4.4.4.m4.1c">\backslash</annotation></semantics></math>n{table}<math id="S7.T17.30.30.5.5.5.5.m5.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.30.30.5.5.5.5.m5.1a"><mo id="S7.T17.30.30.5.5.5.5.m5.1.1" xref="S7.T17.30.30.5.5.5.5.m5.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.30.30.5.5.5.5.m5.1b"><ci id="S7.T17.30.30.5.5.5.5.m5.1.1.cmml" xref="S7.T17.30.30.5.5.5.5.m5.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.30.30.5.5.5.5.m5.1c">\backslash</annotation></semantics></math>n# {foreign_key}<math id="S7.T17.31.31.6.6.6.6.m6.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.31.31.6.6.6.6.m6.1a"><mo id="S7.T17.31.31.6.6.6.6.m6.1.1" xref="S7.T17.31.31.6.6.6.6.m6.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.31.31.6.6.6.6.m6.1b"><ci id="S7.T17.31.31.6.6.6.6.m6.1.1.cmml" xref="S7.T17.31.31.6.6.6.6.m6.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.31.31.6.6.6.6.m6.1c">\backslash</annotation></semantics></math>n#<math id="S7.T17.32.32.7.7.7.7.m7.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.32.32.7.7.7.7.m7.1a"><mo id="S7.T17.32.32.7.7.7.7.m7.1.1" xref="S7.T17.32.32.7.7.7.7.m7.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.32.32.7.7.7.7.m7.1b"><ci id="S7.T17.32.32.7.7.7.7.m7.1.1.cmml" xref="S7.T17.32.32.7.7.7.7.m7.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.32.32.7.7.7.7.m7.1c">\backslash</annotation></semantics></math>n### {question}<math id="S7.T17.33.33.8.8.8.8.m8.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.33.33.8.8.8.8.m8.1a"><mo id="S7.T17.33.33.8.8.8.8.m8.1.1" xref="S7.T17.33.33.8.8.8.8.m8.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.33.33.8.8.8.8.m8.1b"><ci id="S7.T17.33.33.8.8.8.8.m8.1.1.cmml" xref="S7.T17.33.33.8.8.8.8.m8.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.33.33.8.8.8.8.m8.1c">\backslash</annotation></semantics></math>n SELECT</span></span>
</span>
</td>
<td id="S7.T17.33.33.11" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.33.33.11.1" class="ltx_text" style="font-size:70%;">70.10</span></td>
<td id="S7.T17.33.33.12" class="ltx_td ltx_align_right ltx_border_t">
<span id="S7.T17.33.33.12.1" class="ltx_text" style="font-size:70%;">84.10&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T17.33.33.12.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib744" title="" class="ltx_ref">744</a><span id="S7.T17.33.33.12.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
</tr>
<tr id="S7.T17.39.39" class="ltx_tr">
<td id="S7.T17.39.39.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="15"><span id="S7.T17.39.39.7.1" class="ltx_text" style="font-size:70%;">IR</span></td>
<td id="S7.T17.39.39.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.39.8.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.39.8.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.39.39.8.1.1.1" class="ltx_text" style="font-size:70%;">Recommendation</span></span>
</span>
</td>
<td id="S7.T17.39.39.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S7.T17.39.39.9.1" class="ltx_text" style="font-size:70%;">MovieLens</span></td>
<td id="S7.T17.39.39.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T17.39.39.6.6" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.39.6.6.6" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.39.6.6.6.6" class="ltx_text ltx_font_typewriter" style="font-size:70%;">I’ve watched the following movies in the past in order: <math id="S7.T17.34.34.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.34.34.1.1.1.1.m1.1a"><mo id="S7.T17.34.34.1.1.1.1.m1.1.1" xref="S7.T17.34.34.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.34.34.1.1.1.1.m1.1b"><ci id="S7.T17.34.34.1.1.1.1.m1.1.1.cmml" xref="S7.T17.34.34.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.34.34.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n {user_his_text} <math id="S7.T17.35.35.2.2.2.2.m2.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.35.35.2.2.2.2.m2.1a"><mo id="S7.T17.35.35.2.2.2.2.m2.1.1" xref="S7.T17.35.35.2.2.2.2.m2.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.35.35.2.2.2.2.m2.1b"><ci id="S7.T17.35.35.2.2.2.2.m2.1.1.cmml" xref="S7.T17.35.35.2.2.2.2.m2.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.35.35.2.2.2.2.m2.1c">\backslash</annotation></semantics></math>n<math id="S7.T17.36.36.3.3.3.3.m3.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.36.36.3.3.3.3.m3.1a"><mo id="S7.T17.36.36.3.3.3.3.m3.1.1" xref="S7.T17.36.36.3.3.3.3.m3.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.36.36.3.3.3.3.m3.1b"><ci id="S7.T17.36.36.3.3.3.3.m3.1.1.cmml" xref="S7.T17.36.36.3.3.3.3.m3.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.36.36.3.3.3.3.m3.1c">\backslash</annotation></semantics></math>n Now there are {recall_budget} candidate movies that I can watch next: <math id="S7.T17.37.37.4.4.4.4.m4.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.37.37.4.4.4.4.m4.1a"><mo id="S7.T17.37.37.4.4.4.4.m4.1.1" xref="S7.T17.37.37.4.4.4.4.m4.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.37.37.4.4.4.4.m4.1b"><ci id="S7.T17.37.37.4.4.4.4.m4.1.1.cmml" xref="S7.T17.37.37.4.4.4.4.m4.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.37.37.4.4.4.4.m4.1c">\backslash</annotation></semantics></math>n {candidate_text_order} <math id="S7.T17.38.38.5.5.5.5.m5.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.38.38.5.5.5.5.m5.1a"><mo id="S7.T17.38.38.5.5.5.5.m5.1.1" xref="S7.T17.38.38.5.5.5.5.m5.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.38.38.5.5.5.5.m5.1b"><ci id="S7.T17.38.38.5.5.5.5.m5.1.1.cmml" xref="S7.T17.38.38.5.5.5.5.m5.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.38.38.5.5.5.5.m5.1c">\backslash</annotation></semantics></math>n Please rank these {recall_budget} movies by measuring the possibilities that I would like to watch next most, according to my watching history. Please think step by step. <math id="S7.T17.39.39.6.6.6.6.m6.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S7.T17.39.39.6.6.6.6.m6.1a"><mo id="S7.T17.39.39.6.6.6.6.m6.1.1" xref="S7.T17.39.39.6.6.6.6.m6.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S7.T17.39.39.6.6.6.6.m6.1b"><ci id="S7.T17.39.39.6.6.6.6.m6.1.1.cmml" xref="S7.T17.39.39.6.6.6.6.m6.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T17.39.39.6.6.6.6.m6.1c">\backslash</annotation></semantics></math>n Note that my most recently watched movie is {recent_item}. Please show me your ranking results with order numbers. Split your output with line break. You MUST rank the given candidate movies. You can not generate movies that are not in the given candidate list.</span></span>
</span>
</td>
<td id="S7.T17.39.39.10" class="ltx_td ltx_align_right ltx_border_t"><span id="S7.T17.39.39.10.1" class="ltx_text" style="font-size:70%;">48.80</span></td>
<td id="S7.T17.39.39.11" class="ltx_td ltx_align_right ltx_border_t">
<span id="S7.T17.39.39.11.1" class="ltx_text" style="font-size:70%;">76.25&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T17.39.39.11.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib745" title="" class="ltx_ref">745</a><span id="S7.T17.39.39.11.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
</tr>
<tr id="S7.T17.39.50" class="ltx_tr">
<td id="S7.T17.39.50.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S7.T17.39.50.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.50.1.1.1" class="ltx_p" style="width:43.4pt;"><span id="S7.T17.39.50.1.1.1.1" class="ltx_text" style="font-size:70%;">Conversational  Recommendation</span></span>
</span>
</td>
<td id="S7.T17.39.50.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S7.T17.39.50.2.1" class="ltx_text" style="font-size:70%;">ReDial</span></td>
<td id="S7.T17.39.50.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S7.T17.39.50.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T17.39.50.3.1.1" class="ltx_p" style="width:238.5pt;"><span id="S7.T17.39.50.3.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:70%;">Recommend 10 items that are consistent with user preference. The recommendation list can contain items that the dialog mentioned before. The format of the recommendation list is: no. title (year). Don’t mention anything other than the title of items in your recommendation list</span></span>
</span>
</td>
<td id="S7.T17.39.50.4" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S7.T17.39.50.4.1" class="ltx_text" style="font-size:70%;">17.20</span></td>
<td id="S7.T17.39.50.5" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">
<span id="S7.T17.39.50.5.1" class="ltx_text" style="font-size:70%;">25.60&nbsp;</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.T17.39.50.5.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib746" title="" class="ltx_ref">746</a><span id="S7.T17.39.50.5.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4 </span><span id="S7.SS4.1.1" class="ltx_text ltx_font_italic">Empirical Evaluation</span>
</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS4.p1.1">위의 평가 벤치마크와 접근 방식은 주로 LLM의 전반적인 능력을 평가하는 데 사용된다. 이 부분에서는 섹션 <a class="ltx_ref" href="#S7.SS1" title="7.1 Basic Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.1</span></a> 및 섹션 <a class="ltx_ref" href="#S7.SS2" title="7.2 Advanced Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.2</span></a>에서 논의된 능력에 대한 세밀한 평가를 수행한다. 능력의 종류별로 대표 태스크와 평가 실험을 수행하기 위한 데이터셋을 선정하여 LLMs의 해당 성능을 검토한다.</p>
</div>
<section id="S7.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.4.1 </span>Experimental Settings</h4>

<div id="S7.SS4.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS1.p1.1">이 부분에서는 우리의 평가를 위한 실험 설정을 소개한다.</p>
</div>
<div id="S7.SS4.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS4.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S7.SS4.SSS1.p2.1.1">Evaluation Models. </span> 평가를 수행 하기 위해 다음과 같이 오픈 소스 모델에서 폐쇄 소스 API 액세스 모델에 대 한 대표적인 LLM을 고려 합니다.</p>
</div>
<div id="S7.SS4.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS1.p3.1">• <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p3.1.1">Open-source models. </em> 기존 오픈 소스 모델은 기본 모델과 명령 조정 모델로 분류할 수 있습니다. 베이스 모델은 언어 모델링 목적을 가진 대규모 범용 코퍼스에서 사전 훈련될 뿐, 더 이상의 감독된 미세 조정은 없다. 평가에서는 LLaMA (7B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>, LLaMA 2 (7B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>, Pythia (7B and 12B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib96" title="">96</a>]</cite>, Falcon (7B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib747" title="">747</a>]</cite><span class="ltx_note ltx_role_footnote" id="footnote48"><sup class="ltx_note_mark">48</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">48</sup><span class="ltx_tag ltx_tag_note">48</span>Experiments with larger models are still in schedule due to the limit of computational resources. </span></span></span>의 네 가지 대표적인 기본 모델을 선정한다. 명령어 조정 모델은 명령을 사용하여 미세 조정 된 모델입니다 (<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p3.1.2">i.e.,</em> 작업 데이터 세트, 데일리 채팅 또는 합성 명령). 실험에서는 Vicuna (7B and 13B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>, Alpaca (7B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib137" title="">137</a>]</cite>, ChatGLM (6B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite> 등 4개의 대표적인 명령어 조정 모델을 선정하였다. 또한 비교를 위해 LLaMA 2-Chat (7B) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>를 포함하였으며, LLaMA 2 (7B)를 기반으로 명령어 튜닝과 RLHF를 통해 인간과 정렬된 대표적인 모델이다.</p>
</div>
<div id="S7.SS4.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS1.p4.1">• <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p4.1.1">Closed-source models. </em> 오픈 소스 모델 외에도 API를 통해서만 접근할 수 있는 폐쇄 소스 모델도 있어 개발자와 연구자 모두에게 많은 관심을 받고 있다. 여기에서 우리는 텍스트-davinci-002/003(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p4.1.2">Davinci002/003</em>), ChatGPT, Claude 및 Claude 2를 포함한 4개의 대표적인 폐쇄 소스 모델을 선택한다. 여기서 처음 세 모델은 OpenAI에 의해 개발되고 나머지 두 모델은 Anthropic에 의해 개발된다.</p>
</div>
<div id="S7.SS4.SSS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS4.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S7.SS4.SSS1.p5.1.1">Tasks and Datasets. </span> 다음으로 Section <a class="ltx_ref" href="#S7.SS1" title="7.1 Basic Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.1</span></a>와 Section <a class="ltx_ref" href="#S7.SS2" title="7.2 Advanced Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.2</span></a>에서 논의된 능력에 대한 평가 작업과 데이터셋을 설정하였다. 우리는 주로 이러한 데이터 세트에 대한 LLM의 제로 샷 성능을 평가한다. 제로샷 방식(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p5.1.2">e.g.,</em> 수학적 추론 및 도구 조작)으로 해결하기 어려운 더 복잡한 작업을 위해 오픈 소스 모델의 컨텍스트 길이 제한을 고려하여 주로 3-샷 성능을 보고한다.</p>
</div>
<div id="S7.SS4.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS1.p6.1">• <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p6.1.2">Language generation. 앞서 논의한 바와 같이 언어 생성을 위해 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p6.1.3">i.e.,</em> 언어 모델링, 조건부 텍스트 생성 및 코드 합성의 세 가지 작업을 평가한다. 특히, LAMBADA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib233" title="">233</a>]</cite> (언어 모델링), WMT’22<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib545" title="">545</a>]</cite> (기계 번역), XSum<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib549" title="">549</a>]</cite> (텍스트 요약), HumanEval<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite> (코드 합성)의 4가지 데이터셋을 선정하여 평가하였다. WMT'22에서는 기계 번역에서 LLM의 평균 성능을 조사하기 위해 원래 대규모 테스트 세트에서 각 언어 쌍에 대해 1000개의 예를 선택하여 새로운 평가 세트를 구성한다. 이러한 데이터 세트에 대한 LLM의 제로샷 성능을 평가하고, LAMBADA에 대한 예측 단어의 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p6.1.4">accuracy</em>, WMT’22에 대한 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p6.1.5">BLEU-4</em>, XSum에 대한 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p6.1.6">ROUGE-L</em> 및 HumanEval에 대한 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p6.1.1.1">pass@<math alttext="10" class="ltx_Math" display="inline" id="S7.SS4.SSS1.p6.1.1.m1.1"><semantics id="S7.SS4.SSS1.p6.1.1.m1.1a"><mn id="S7.SS4.SSS1.p6.1.1.m1.1.1" xref="S7.SS4.SSS1.p6.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S7.SS4.SSS1.p6.1.1.m1.1b"><cn id="S7.SS4.SSS1.p6.1.1.m1.1.1.cmml" type="integer" xref="S7.SS4.SSS1.p6.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.SSS1.p6.1.1.m1.1c">10</annotation></semantics></math></em>을 계산한다.</p>
</div>
<div id="S7.SS4.SSS1.p7" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS1.p7.1">• <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p7.1.1">Knowledge utilization. 지식 활용 능력을 평가하기 위해 4개의 질문 응답 데이터 세트(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p7.1.2">i.e.,</em> TriviaQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib558" title="">558</a>]</cite>, Natural Questions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib554" title="">554</a>]</cite>, Web Questions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib557" title="">557</a>]</cite>, and ARC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib555" title="">555</a>]</cite>)와 사실 추출 데이터 세트인 WikiFact <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib571" title="">571</a>]</cite>를 선택한다. 또한 이러한 데이터 세트에 대한 LLM의 제로샷 성능을 보고하고 ARC에 대한 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p7.1.3">accuracy</em> 및 다른 데이터 세트에 대한 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p7.1.4">exact match</em>을 계산한다.</p>
</div>
<div id="S7.SS4.SSS1.p8" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS1.p8.1">• <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p8.1.1">Complex reasoning. 복잡한 추론의 경우 OpenbookQA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib566" title="">566</a>]</cite>, HellaSwag<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib582" title="">582</a>]</cite>, and SocialIQA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib581" title="">581</a>]</cite>의 비교 모델을 지식 추론의 경우, Colored Objects<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib70" title="">70</a>]</cite> and Penguins in the Table<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib70" title="">70</a>]</cite> for symbolic reasoning; GSM8k<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite> and MATH<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib364" title="">364</a>]</cite> for mathematical reasoning. <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p8.1.2">accuracy</em> for OpenbookQA, HellaSwag, and SocialIQA; <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p8.1.3">solve rate</em> for Colored Objects and Penguins in the Table; and <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p8.1.4">accuracy</em> for GSM8k and MATH. 지식 추론 작업은 모두 제로 샷 설정에서 풀 수 있는 QA 작업이기 때문에 제로 샷 성능을 평가한다. 복잡한 기호 추론과 수학적 추론 과제를 위해 3-shot in-context 예제를 활용하여 LLMs을 더 잘 이끌어내어 이를 달성한다. 기존의 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib443" title="">443</a>, <a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>에 이어 수학적 추론 과제를 더 잘 해결하기 위해 연쇄적 사고 프롬프트 전략을 활용한다.</p>
</div>
<div id="S7.SS4.SSS1.p9" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS1.p9.1">• <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p9.1.1">Human alignment. 인간 정렬을 위해 TruthfulQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib556" title="">556</a>]</cite>를 선택하여 질문에 대한 답변을 생성하는데 있어 LLM이 진실한지, CrowS-Pairs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib603" title="">603</a>]</cite> 및 WinoGender <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib604" title="">604</a>]</cite>에서 고정관념을 평가하고, RealToxityPrompts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib605" title="">605</a>]</cite>에서 LLM이 독성 언어를 생성하는 정도를 평가하고, HaluEval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib602" title="">602</a>]</cite>에서 LLM이 환각을 인식하는 능력을 테스트한다. 실제 독성 프롬프트의 테스트 세트가 너무 크기 때문에 평가를 위해 10000개의 예를 무작위로 샘플링한다. LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>를 따라 제로샷 성능을 보고하고, 클레임을 TruthfulQA에 대해 true로 식별하는 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p9.1.2">accuracy</em>, CrowS-Pairs에 대해 편향된 문장(높은 perplexity)을 인식하는 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p9.1.3">accuracy</em>, WinoGender에 대해 Coreference resolution accuracy (he/she/they)</em>, RealToxityPrompts에 대해 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p9.1.5">toxicity score</em> 및 HaluEval에 대해 환각을 인식하는 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1 TruthfulQA의 경우 텍스트-다빈치-003을 사용하여 채점을 위해 사람을 대체하는 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>를 따른다. Crows-Pairs와 WinoGender의 경우, 우리는 복잡도와 상호참조 해상도 점수를 계산하기 위해 LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>의 실험 설정을 따른다. RealToxityPrompts의 경우 독성 평가를 위해 Perspective-API<span class="ltx_note ltx_role_footnote" id="footnote49"><sup class="ltx_note_mark">49</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">49</sup><span class="ltx_tag ltx_tag_note">49</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://perspectiveapi.com/" target="_blank" title="">https://perspectiveapi.com/</a></span></span></span>을 활용한다.</p>
</div>
<div id="S7.SS4.SSS1.p10" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS1.p10.1">• <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p10.1.1">Interaction with environment. 이 능력을 테스트하기 위해 ALFWorld <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib609" title="">609</a>]</cite>와 WebShop <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib610" title="">610</a>]</cite>를 선택하여 가정 및 전자 상거래 환경과 같은 실제 시나리오를 시뮬레이션합니다. WebShop 및 ALFWorld에서 LLM의 1-shot 및 2-shot 성능을 각각 평가하는 ReAct<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib449" title="">449</a>]</cite>의 설정을 따르고, ALFWorld에 대한 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p10.1.2">success rate</em> 및 WebShop에 대한 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p10.1.3">average score/success rate</em>을 계산한다. 또한 입력 프롬프트의 길이를 줄이고 줄 바꿈을 EOS 토큰으로 활용하기 위해 ReAct<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib449" title="">449</a>]</cite>를 따른다.</p>
</div>
<div id="S7.SS4.SSS1.p11" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS1.p11.1">• <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p11.1.1">Tool manipulation. <em> 도구 조작을 위해 검색 엔진과 모델 인터페이스를 포함한 두 종류의 도구를 고려한다. 따라서 두 가지 도구 조작 벤치마크인 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p11.1.2">i.e.,</em> HotpotQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib579" title="">579</a>]</cite>와 Gorilla <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib617" title="">617</a>]</cite>를 채택한다. HotpotQA는 LLM이 검색 엔진을 사용하여 웹에서 문서를 검색하고, 고릴라가 TorchHub, TensorHub 및 HuggingFace의 세 허브에서 모델 API를 호출하도록 요구한다. <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p11.1.3">exact match</em> for HotpotQA 및 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p11.1.4">accuracy</em> for Gorilla를 계산합니다. HotpotQA의 경우 ReAct<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib449" title="">449</a>]</cite>를 따라 3-shot 성능을 보고합니다. 고릴라의 경우 논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib617" title="">617</a>]</cite>에서 공개한 코드를 따르고 제로샷 성능을 평가한다.</p>
</div>
<div id="S7.SS4.SSS1.p12" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS4.SSS1.p12.1"><span class="ltx_text ltx_font_bold" id="S7.SS4.SSS1.p12.1.1">Implementation Details. 각 작업 및 데이터 세트에 대해 기존 작업에서 제공 하는 동일한 프롬프트 및 결과 구문 분석 방법 (<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p12.1.2">i.e.,</em> TruthfulQA, HotPotQA, Gorilla, HaluEval)을 사용 하 여 비교 된 LLM을 평가 합니다 (<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS1.p12.1.3">i.e.,</em> TriviaQA, Natural Questions, Web Questions, ARC, WikiFact, GSM8k, MATH, C-Objects, Penguins, LAMBADA, WMT’22, XSum, HumanEval, CrowS-Pairs, WinoGender, RealToxityPrompt). 특히, 폐쇄 소스 모델에 대한 모든 실험은 공식 API를 호출하는 것을 기반으로 하는 반면, 오픈 소스 모델의 경우 공개적으로 사용 가능한 코드와 모델 매개변수를 활용하고 8개의 A800-80G GPU에 대한 추론을 수행한다. 트리비아QA, OpenbookQA, HellaSwag, SocialIQA의 경우 테스트 세트가 공개되지 않았기 때문에 개발 세트에 대해 실험한다. 다른 데이터 세트의 경우 테스트 세트에 대해 실험합니다. 실험을 재현하기 위해 <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/RUCAIBox/LLMSurvey/tree/main/Experiments" target="_blank" title="">https://github.com/RUCAIBox/LLMSurvey/tree/main/Experiments</a>에서 실험 코드와 데이터를 공개적으로 공개합니다.</p>
</div>
</section>
<section id="S7.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.4.2 </span>Results Analysis and Findings</h4>

<div id="S7.SS4.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p1.1"><a class="ltx_ref" href="#S7.T16" title="TABLE XVI ‣ 7.3.2 Evaluation Approaches ‣ 7.3 Benchmarks and Evaluation Approaches ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XVI</span></a>의 실험 결과를 보고하고, 그 결과를 다음과 같이 분석한다.</p>
</div>
<div id="S7.SS4.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS4.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S7.SS4.SSS2.p2.1.1">Analysis of Closed-Source Models. </span> 우리는 네 개의 폐쇄 소스 모델(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p2.1.2">i.e.,</em> ChatGPT, Claude, Davinci003 및 Davinci002)의 분석 및 결과를 다음과 같이 요약합니다.</p>
</div>
<div id="S7.SS4.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS4.SSS2.p3.1.m1.1"><semantics id="S7.SS4.SSS2.p3.1.m1.1a"><mo id="S7.SS4.SSS2.p3.1.m1.1.1" xref="S7.SS4.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS4.SSS2.p3.1.m1.1b"><ci id="S7.SS4.SSS2.p3.1.m1.1.1.cmml" xref="S7.SS4.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.SSS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p3.1.1">These five closed-source models achieve promising results as general-purpose task solvers, where ChatGPT mostly performs best. </em> ChatGPT, Claude, Claude 2, Davinci003 및 Davinci002는 복잡한 태스크(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p3.1.2">e.g.,</em> GSM8k)를 포함하여 대부분의 태스크에서 잘 수행되며, 이는 범용 태스크 해결자가 될 수 있는 큰 잠재력을 보여주었다. 이 중 ChatGPT는 평가 과제에서 보다 우수한 모델 역량을 발휘하여 모든 과제에서 가장 많이 수상하였다. 일부 평가 작업에서 ChatGPT와 다른 폐쇄 소스 모델 간의 성능 차이는 매우 큽니다. 특히 복잡한 작업 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p3.1.3">e.g.,</em> 78.47 (ChatGPT) <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p3.1.4">v.s.</em> 49.96 (Davinci002) on GSM8k 및 79.88 (ChatGPT) <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p3.1.5">v.s.</em> 51.22 (Claude) on HumanEval.</p>
</div>
<div id="S7.SS4.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS4.SSS2.p4.1.m1.1"><semantics id="S7.SS4.SSS2.p4.1.m1.1a"><mo id="S7.SS4.SSS2.p4.1.m1.1.1" xref="S7.SS4.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS4.SSS2.p4.1.m1.1b"><ci id="S7.SS4.SSS2.p4.1.m1.1.1.cmml" xref="S7.SS4.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p4.1.1">Claude 2, ChatGPT 및 Davinci003은 환경 및 도구 조작 작업과의 상호 작용에 대해 더 나은 성능을 발휘한다. </em> 두 평가 작업에서 Claude 2, ChatGPT 및 Davinci003은 다른 모델보다 큰 마진으로 더 나은 성능을 수행 합니다. <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p4.1.2">e.g.,</em> 36.40 (Claude 2) <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p4.1.3">v.s.</em> 26.00 (Davinci002) on HotpotQA, 44.53 (ChatGPT) <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p4.1.4">v.s.</em> 7.74 (Claude) on Gorilla-TF, 72.58 (Davinci003) <em class="ltx_emph ltx_font_italic" id="S7.SS4. 가능한 이유는 이 세 가지 모델이 이러한 고급 능력, 즉 외부 플러그인 사용을 지원하는 <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p4.1.6">e.g.,</em>을 위해 특별히 최적화되었기 때문이다.</p>
</div>
<div id="S7.SS4.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS4.SSS2.p5.1.m1.1"><semantics id="S7.SS4.SSS2.p5.1.m1.1a"><mo id="S7.SS4.SSS2.p5.1.m1.1.1" xref="S7.SS4.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS4.SSS2.p5.1.m1.1b"><ci id="S7.SS4.SSS2.p5.1.m1.1.1.cmml" xref="S7.SS4.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.SSS2.p5.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p5.1.1">모든 비교 모델들은 매우 어려운 추론 작업들에서 잘 수행되지 않는다. </em> On MATH and HotpotQA, 모든 모델(ChatGPT 포함)의 성능이 좋지 않습니다. 두 과제는 풀이가 매우 어려워 복잡한 수학적 지식에 대한 정확한 이해와 문서 간 멀티홉 추론을 각각 수행해야 한다. 또한, 이러한 모델들은 또한 기계 번역 작업(WMT)에 대해 상대적으로 약한 성능을 갖는다. 가능한 이유는 WMT가 소수 언어의 평가 예도 많이 포함하고 있기 때문에 이러한 LLM의 사전 훈련 데이터에서 잘 다루지 않을 수 있다.</p>
</div>
<div id="S7.SS4.SSS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.SS4.SSS2.p6.1"><span class="ltx_text ltx_font_bold" id="S7.SS4.SSS2.p6.1.1">Analysis of Open-Source Models. 다음으로, 8개의 오픈 소스 모델(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p6.1.2">i.e.,</em> LLaMA 2-Chat, Vicuna, Alpaca, ChatGLM, LLaMA 2, LLaMA, Pythia and Falcon)에 대한 분석 및 결과를 다음과 같이 계속 보여준다.</p>
</div>
<div id="S7.SS4.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS4.SSS2.p7.1.m1.1"><semantics id="S7.SS4.SSS2.p7.1.m1.1a"><mo id="S7.SS4.SSS2.p7.1.m1.1.1" xref="S7.SS4.SSS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS4.SSS2.p7.1.m1.1b"><ci id="S7.SS4.SSS2.p7.1.m1.1.1.cmml" xref="S7.SS4.SSS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.SSS2.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p7.1.1">Instruction-tuned models mostly better performance than the base models. 비교된 모든 오픈 소스 방법 중 명령어 튜닝 모델(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p7.1.2">i.e.,</em> LLaMA 2-Chat, Vicuna, Alpaca and ChatGLM)은 대부분 명령어 튜닝이 아닌 모델(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p7.1.3">i.e.,</em> LLaMA 2, LLaMA, Pythia and Falcon)보다 더 나은 성능을 보인다. 이는 명령어 튜닝이 일반적으로 다양한 태스크를 해결하는 데 있어 LLM의 소수 샷 또는 제로 샷 능력을 향상시킬 수 있음을 나타낸다. 그러나 명령어 튜닝 후 Vicuna (7B)와 Alpaca (7B)는 언어 모델링 작업인 LAMBADA에서 성능 저하를 겪는다. 그 이유는 명령 데이터가 주로 LLM이 인간의 명령을 따를 수 있게 하는 것에 초점을 맞추고 있기 때문일 수 있으며, 이는 일반적인 언어 생성 작업에 항상 유용한 것은 아니다.</p>
</div>
<div id="S7.SS4.SSS2.p8" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS4.SSS2.p8.1.m1.1"><semantics id="S7.SS4.SSS2.p8.1.m1.1a"><mo id="S7.SS4.SSS2.p8.1.m1.1.1" xref="S7.SS4.SSS2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS4.SSS2.p8.1.m1.1b"><ci id="S7.SS4.SSS2.p8.1.m1.1.1.cmml" xref="S7.SS4.SSS2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.SSS2.p8.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p8.1.1">이러한 소규모 오픈 소스 모델은 수학적 추론, 환경과의 상호 작용 및 도구 조작 작업에 대해 잘 수행되지 않습니다. </em> 수학적 추론, 환경과의 상호작용, 도구 조작의 작업에서 평가된 모든 오픈 소스 모델은 명령어 조정 모델을 포함하여 잘 수행되지 않는다. 가능한 이유는 이러한 모델을 미세 조정하기 위한 명령 데이터가 이러한 작업에 대해 특별히 설계되지 않았기 때문이다. 또한, 이러한 폐쇄 소스 모델은 작은 모델 크기로 인해 제한된 모델 용량을 가질 수 있다.</p>
</div>
<div id="S7.SS4.SSS2.p9" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS4.SSS2.p9.1.m1.1"><semantics id="S7.SS4.SSS2.p9.1.m1.1a"><mo id="S7.SS4.SSS2.p9.1.m1.1.1" xref="S7.SS4.SSS2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS4.SSS2.p9.1.m1.1b"><ci id="S7.SS4.SSS2.p9.1.m1.1.1.cmml" xref="S7.SS4.SSS2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.SSS2.p9.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p9.1.1">Top-performing model varies on different human alignment tasks. </em> 서로 다른 인간 정렬 작업에 대해, 우리는 이들 모델이 일관성 없는 성능 순위를 달성한다는 것을 알 수 있다. 예를 들어, LLaMA 2-Chat(7B)는 TruthfulQA에서 비교된 오픈 소스 모델 중 가장 잘 수행하는 반면, Vicuna(13B)는 CrowS-Pair에서 가장 잘 수행한다. 가능한 이유는 이들 태스크들이 인간 정렬의 상이한 양태들을 평가하기 위한 특정 목적들로 설계되고, 이들 모델들은 동일한 모델의 변형들에 대해서도 상이한 태스크들에 대해 다양한 성능을 나타내기 때문이다(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p9.1.2">e.g.,</em> Pythia (7B) 및 Pythia (12B)). 더 자세한 결과를 밝히기 위해서는 인간 정렬 평가에 대한 더 많은 실험과 분석이 필요하다.</p>
</div>
<div id="S7.SS4.SSS2.p10" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p10.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS4.SSS2.p10.1.m1.1"><semantics id="S7.SS4.SSS2.p10.1.m1.1a"><mo id="S7.SS4.SSS2.p10.1.m1.1.1" xref="S7.SS4.SSS2.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS4.SSS2.p10.1.m1.1b"><ci id="S7.SS4.SSS2.p10.1.m1.1.1.cmml" xref="S7.SS4.SSS2.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.SSS2.p10.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p10.1.1">보다 최근에 출시된 모델로서, LLaMA 2(7B)는 전반적으로 특히 복잡한 추론 작업에서 좋은 성능을 달성한다. </em> 복잡한 추론 작업의 경우, LLaMA 2 (7B)는 대부분 다른 기본 모델보다 성능이 우수합니다. <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p10.1.2">e.g.,</em> 43.95 (LLaMA 2 (7B)) <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p10.1.3">v.s.</em> 29.80 (Falcon (7B)) in C-Objects. 다른 작업(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p10.1.4">e.g.,</em> 언어 생성 및 지식 활용)의 경우, LLaMA 2(7B)도 최고의 성능을 내는 기본 모델로서 비교 가능한 성능을 달성할 수 있다. 사전 훈련(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p10.1.5">i.e.,</em> 약 2조 토큰)에 더 많은 데이터를 사용했으며, 이는 주로 우수한 성능에 기여한다. 또한 보다 강력한 데이터 클리닝 프로세스를 수행합니다.</p>
</div>
<div id="S7.SS4.SSS2.p11" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p11.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS4.SSS2.p11.1.m1.1"><semantics id="S7.SS4.SSS2.p11.1.m1.1a"><mo id="S7.SS4.SSS2.p11.1.m1.1.1" xref="S7.SS4.SSS2.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS4.SSS2.p11.1.m1.1b"><ci id="S7.SS4.SSS2.p11.1.m1.1.1.cmml" xref="S7.SS4.SSS2.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS4.SSS2.p11.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p11.1.1">Scaling the open-source modes can improve the performance consistently. </em> Vicuna(7B)와 Vicuna(13B), Pythia(7B)와 Pythia(13B)의 성능을 비교해보면, 이러한 평가 과제에서 규모가 큰 모델이 작은 모델보다 대부분 더 나은 성능을 보여 모델 크기를 확장하는 효과가 있음을 알 수 있다. 상이한 태스크들에 걸쳐, 스케일링 모델은 더 복잡한 태스크들(<em class="ltx_emph ltx_font_italic" id="S7.SS4.SSS2.p11.1.2">e.g.,</em> symbolic and mathematical reasoning)에 더 유익하며, 여기서 더 큰 모델들은 대부분 큰 마진에서 더 작은 모델들을 능가한다.</p>
</div>
<div id="S7.SS4.SSS2.p12" class="ltx_para">
<p class="ltx_p" id="S7.SS4.SSS2.p12.1">독자들은 오픈 소스 언어 모델에 대한 이러한 발견은 모델 크기에 제한된다는 점에 유의해야 한다. 우리는 이러한 모델의 더 큰 버전의 결과를 포함하여 이 부분을 지속적으로 업데이트하고 더 많은 실험을 위한 계산 자원의 지원을 요청할 것이다.</p>
</div>
</section>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Applications</span>
</h2>

<figure id="S8.F18" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2303.18223/assets/x18.png" id="S8.F18.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="217" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 18:</span>The applications of LLMs in representative research directions and downstream domains.</figcaption>
</figure>
<div id="S8.p1" class="ltx_para">
<p class="ltx_p" id="S8.p1.1">이 섹션에서는 LLM의 적용에 대한 최근 진행 상황을 두 가지 측면, 즉 연구 커뮤니티와 대표 도메인에 미치는 영향에 대해 간략하게 검토한다. <a class="ltx_ref" href="#S8.F18" title="Figure 18 ‣ 8 Applications ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">18</span></a>는 이 섹션<span class="ltx_note ltx_role_footnote" id="footnote50"><sup class="ltx_note_mark">50</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">50</sup><span class="ltx_tag ltx_tag_note">50</span>Note that we don’t aim to cover all the related research directions or domains, but instead demonstrating the use or impact of LLMs via these selected examples. </span></span></span>의 콘텐츠 조직을 나타낸다.</p>
</div>
<section id="S8.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1 </span><span id="S8.SS1.1.1" class="ltx_text ltx_font_italic">LLM for Research Community</span>
</h3>

<div id="S8.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS1.p1.1">LLM이 AI 알고리즘을 개발하는 방식에 혁명을 일으켰기 때문에 연구 커뮤니티에 상당한 영향을 미친다. 이 부분에서는 대표적인 몇 가지 연구 방향에 대해 LLM이 주도한 발전을 간략하게 검토한다.</p>
</div>
<section id="S8.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.1 </span>LLM for Classic NLP Tasks</h4>

<div id="S8.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS1.p1.1">사전 훈련된 언어 모델(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p1.1.1">e.g.,</em>BERT)이 NLP 분야에서 시작됨에 따라 언어 모델의 기술적 발전은 NLP 연구에 중요한 영향을 미친다. 이 부분에서는 기존의 많은 NLP 시스템과 응용의 기초가 된 단어 수준, 문장 수준, 서열 태깅, 관계 추출, 텍스트 생성 작업 등 5가지 고전적 NLP 작업에 LLM의 적용에 대해 논의한다. 우리는 모든 NLP 작업을 포괄적으로 다루려는 것이 아니라 기본 작업을 통해 기본 NLP 연구를 위한 LLM의 영향을 분석하려고 한다. 또한 이 조사에서 초기에 논의된 여러 작업(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p1.1.2">e.g.,</em> 언어 모델링)에 대한 논의를 생략합니다.</p>
</div>
<div id="S8.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS1.p2.1.1">Word/Sentence-level Tasks. </span> 오랜 NLP 작업으로 단어 수준(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p2.1.2">e.g.,</em> word clustering <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib748" title="">748</a>]</cite> and sense disambiguation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib749" title="">749</a>]</cite>) 및 문장 수준 작업(sentence matching <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib750" title="">750</a>]</cite> and sentiment classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib751" title="">751</a>]</cite>)이 문헌에서 널리 연구되어 실제 플랫폼에서 적용되고 있다. 이러한 과제를 해결하기 위해서는 단어 또는 문장에 대한 의미 정보를 정확하게 이해하는 것이 관건이다. 지금까지 이러한 작업에 대한 풍부한 고품질 라벨링된 데이터가 축적됨에 따라 기존 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib39" title="">39</a>, <a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite>는 작은 언어 모델이 미세 조정함으로써 매우 우수한 성능을 달성할 수 있음을 발견했다. 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib752" title="">752</a>]</cite>에서도 이러한 작업에 대한 LLM의 성능을 테스트하여 LLM이 인컨텍스트 학습을 통해서도 잘 수행할 수 있음을 보여준다(예제는 거의 없음). 반면, 작은 모델은 특정 작업 요구 사항과 도메인 지식을 학습하기 위해 이러한 작업에 특별히 최적화될 수 있기 때문에, 전체 데이터 미세 조정 작은 모델은 여러 고전 작업 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib753" title="">753</a>, <a class="ltx_ref" href="#bib.bib754" title="">754</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p2.1.3">예:</em> 시맨틱 매칭 및 감정 분석을 사용하여 인컨텍스트 학습을 사용하여 LLMs를 대부분 능가할 수 있다.</p>
</div>
<div id="S8.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS1.p3.1.1">Sequence Tagging. </span> 시퀀스 태깅 작업인 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p3.1.2">e.g.,</em> named entity recognition (NER) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib755" title="">755</a>]</cite> and part-of-speech (POS) tagging <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib756" title="">756</a>]</cite>도 기본 작업입니다. 일반적으로 이러한 작업은 입력 시퀀스의 각 토큰에 적절한 의미 범주 레이블, <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p3.1.3">e.g.,</em> 클래식 B-I-O(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p3.1.4">Beginning</em>, <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p3.1.5">Inside</em> 및 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p3.1.6">Outside</em>)를 할당해야 합니다. 딥러닝 시대에 초기 노력인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib757" title="">757</a>, <a class="ltx_ref" href="#bib.bib758" title="">758</a>]</cite>는 주로 학습된 시퀀스 표현(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p3.1.7">e.g.,</em> using CNN, LSTM, BERT)을 고전적인 조건부 랜덤 필드 모델(CRF)에 통합하여 구조적 예측을 기반으로 태깅 작업을 수행한다. 최근, 연구자들은 시퀀스 태깅 태스크에서 LLM의 성능을 테스트했지만, 특히 모호하거나 희귀한 이름을 가진 특수 범주의 경우, LLM이 여전히 in-context learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib753" title="">753</a>]</cite>를 사용하여 문제를 해결하는 데 어려움을 겪는다는 것을 관찰했다. 가능한 이유는 LLMs가 인간 주석이 있는 데이터 세트에서 이러한 클래스의 의미를 오해할 수 있기 때문에 명령어와 제한된 예에 따라 해당 클래스의 의미를 정확하게 이해하기가 어렵기 때문이다.</p>
</div>
<div id="S8.SS1.SSS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS1.p4.1.1">Information Extraction. 정보 추출 작업은 관계 추출 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib759" title="">759</a>]</cite> 및 이벤트 추출 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib760" title="">760</a>]</cite>와 같은 비정형 텍스트 데이터에서 유용한 정형 정보를 자동으로 추출하는 데 중점을 두고 있으며, 이는 많은 NLP 애플리케이션과 관련된 중요한 작업이기도 하다. 일반적으로 이전 연구에서는 이 작업을 텍스트 분류 작업 또는 순차적 레이블링 작업으로 공식화한다. 정보 추출이 종종 복잡한 의미 관계(한 문장 내의 다중 관계)를 정확하게 이해하고 처리해야 하기 때문에, LLMs를 사용한 인-컨텍스트 학습은 전형적으로 최신 풀-데이터 미세 조정 방법들<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib761" title="">761</a>, <a class="ltx_ref" href="#bib.bib762" title="">762</a>]</cite>를 저수행한다. 반면, LLM과 소형 모델 간의 협업을 가능하게 하는 것은 특정 태스크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib763" title="">763</a>, <a class="ltx_ref" href="#bib.bib762" title="">762</a>]</cite>의 성능을 더욱 높일 수 있음을 보여준다. 또한, 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib425" title="">425</a>]</cite>에서도 LLMs이 2단계 워크플로우를 사용하여 정보 추출을 위한 경쟁적인 제로샷 성능을 달성할 수 있음을 보여줌으로써 향후 응용 분야에서 이 접근 방식이 매력적이라고 할 수 있다.</p>
</div>
<div id="S8.SS1.SSS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS1.p5.1.1">Text Generation. </span> Text 생성 작업, <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p5.1.2">e.g.,</em> machine translation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib624" title="">624</a>]</cite> and automatic summary <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib548" title="">548</a>]</cite>는 널리 연구된 오랜 NLP 작업이며, Fine-tuned small models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib311" title="">311</a>, <a class="ltx_ref" href="#bib.bib764" title="">764</a>]</cite>를 기반으로 하는 많은 배포된 제품 및 시스템이 있었다. MLM의 사전 학습은 텍스트 예측에 기반을 두고 있기 때문에 적절한 프롬프트의 도움으로 상용 제품 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib627" title="">627</a>]</cite>와 인간 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib628" title="">628</a>]</cite>로 강력한 언어 생성 능력을 보인다. 또한 LLMs은 실제 응용 시나리오에서 특수 요구 사항인 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p5.1.3">e.g.,</em> 문서 수준 번역 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib767" title="">767</a>]</cite>를 효과적으로 처리할 수 있으며 사용자와의 자연어 상호 작용을 가능하게 하여 생성 품질을 더욱 향상시킬 수 있다. 위의 성공에도 불구하고, 최근의 연구는 LLM이 낮은 리소스 언어 및 도메인, <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p5.1.4">e.g.,</em> Marathi-to-English translation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib769" title="">769</a>]</cite>에 대한 생성 작업을 잘 다루기가 어렵다는 것을 보여준다.</p>
</div>
<div id="S8.SS1.SSS1.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS1.p6.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS1.p6.1.1">Summary</span>. 이상의 논의를 바탕으로 고전적 NLP 작업에서 LLMs 사용에 대한 제안과 향후 방향을 다음과 같이 요약한다.</p>
</div>
<div id="S8.SS1.SSS1.p7" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS1.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S8.SS1.SSS1.p7.1.m1.1"><semantics id="S8.SS1.SSS1.p7.1.m1.1a"><mo id="S8.SS1.SSS1.p7.1.m1.1.1" xref="S8.SS1.SSS1.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S8.SS1.SSS1.p7.1.m1.1b"><ci id="S8.SS1.SSS1.p7.1.m1.1.1.cmml" xref="S8.SS1.SSS1.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS1.SSS1.p7.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p7.1.1">Suggestions:</em> LLM 및 소형 모델은 서로 다른 측면에서 고유한 장점을 가지고 있다: LLM은 다양한 NLP 작업에 대한 통일된 솔루션을 제공하고 경쟁 성능을 달성할 수 있는 반면(특히 제로/페우 샷 설정에서), 소형 모델은 개발하기에 경제적이고 목표 작업에 따라 특별히 튜닝될 수 있으며, 이는 충분한 고품질 라벨링된 데이터로 좋은 성능을 달성할 수 있다[<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib753" title="">753</a>, <a class="ltx_ref" href="#bib.bib754" title="">754</a>, <a class="ltx_ref" href="#bib.bib770" title="">770</a>, <a class="ltx_ref" href="#bib.bib771" title="">771</a>]</cite>]. 응용 프로그램에서는 유연성, 데이터 가용성, 훈련 컴퓨팅 및 효율성을 종합적으로 고려하여 실제 필요에 따라 적절한 선택을 할 수 있습니다.</p>
</div>
<div id="S8.SS1.SSS1.p8" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS1.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S8.SS1.SSS1.p8.1.m1.1"><semantics id="S8.SS1.SSS1.p8.1.m1.1a"><mo id="S8.SS1.SSS1.p8.1.m1.1.1" xref="S8.SS1.SSS1.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S8.SS1.SSS1.p8.1.m1.1b"><ci id="S8.SS1.SSS1.p8.1.m1.1.1.cmml" xref="S8.SS1.SSS1.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS1.SSS1.p8.1.m1.1c">\bullet</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p8.1.1">Future direction:</em> 우수한 일반 용량에도 불구하고 LLMs는 여전히 낮은 리소스 도메인, <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p8.1.2">e.g.,</em> 마이너 언어 번역에서 NLP 작업을 효과적으로 처리할 수 없습니다. 이러한 작업을 해결하기 위해서는 미세 조정 또는 프롬프트를 통해 필요한 작업 정보 또는 도메인별 지식을 LLMs에 주입하는 효과적인 접근 방식을 개발해야 한다. 또한, LLMs이 고전적인 NLP 태스크들(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p8.1.3">e.g.,</em> nested entity extraction)에서 복잡한 의미 관계를 처리하는 것은 여전히 어려운 일이며, 이는 LLMs의 기본 작업 메커니즘으로부터 더 많은 탐색의 가치가 있다. 또한 고전적인 NLP 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib772" title="">772</a>]</cite>의 복잡한 경우를 해결할 때 상호 보완을 위해 LLM과 미세 조정된 작은 언어 모델을 결합하는 것이 유망하다. 또 다른 유망한 방향은 인간-기계 협력 연구(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS1.p8.1.4">e.g.,</em> conversational translation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib768" title="">768</a>]</cite>)를 NLP 작업에서 수행하는 것인데, 이는 LLM이 인간의 명령을 효과적으로 이해하고 의미 있는 응답을 할 수 있기 때문이다.</p>
</div>
</section>
<section id="S8.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.2 </span>LLM for Information Retrieval</h4>

<div id="S8.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS2.p1.1">정보 검색 시스템의 목표는 사용자가 이상적인 정보 자원(일반적으로 문서)을 발견하고 정보 과부하 문제를 완화할 수 있도록 지원하는 것이다. 일반적으로 현대 IR 시스템은 검색-then-rerank 파이프라인 프레임워크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>를 채택한다. 이 프레임워크 내에서, 리트리버는 초기에 대규모 코퍼스에서 관련 정보를 검색하고, 리랭커는 후속적으로 다단계 랭킹 절차를 수행하여 가장 관련성이 높은 정보 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib773" title="">773</a>]</cite>]를 획득한다. LLM의 출현은 정보 접근 방식에 상당한 영향을 미치기 때문에 우리는 IR 모델로서의 LLM과 LLM 강화 IR 모델의 두 가지 주요 측면에서 IR의 발전을 어떻게 발전시키는지에 대해 논의한다.</p>
</div>
<div id="S8.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS2.p2.1.1">LLMs as IR Models. </span> 기존 IR 모델은 전체적으로 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p2.1.2">sparse models</em> (용어 기반 어휘 유사성에 의존함) 및 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p2.1.3">dense models</em> ( embedding based semantic similarity에 의존함) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib740" title="">740</a>]</cite>로 분류될 수 있다. 특히, dense 모델은 주로 fine-tuned PLM(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p2.1.4">e.g.,</em>BERT)에 의해 구현된다. PLM에 비해 LLM은 텍스트 의미론을 캡처하는 데 더 강력한 모델 용량을 가지므로 기존 조밀한 IR 모델을 개선할 가능성이 있다. 그러나 LLM의 높은 오버헤드로 인해 대부분의 연구는 검색된 후보의 순위를 정제하는 것을 목표로 LLM을 재순위자로 사용하는 데 중점을 둔다. 이를 달성하기 위해, 최근의 노력들은 종종 LLM들이 제공된 후보 문서들의 작은 세트에 대해 재순위화를 수행할 수 있게 하는 특별한 명령들을 공식화한다. 전형적으로, 이러한 접근법은 모델 트레이닝을 필요로 하지 않으며, 잘 트레이닝된 재순위화 방법들<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib774" title="">774</a>, <a class="ltx_ref" href="#bib.bib775" title="">775</a>]</cite>와 비교하여 유망한 결과들을 달성한다. 특히, LLM 기반 재순위 접근법은 점별(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p2.1.5">estimating the relevance scores for query-document pairs</em>) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib776" title="">776</a>]</cite>, pairwise(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p2.1.6">determining the relevance order of two documents</em>) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib775" title="">775</a>]</cite>, 또는 listwise 순위(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p2.1.7">sorting a subset of candidate documents</em>) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib777" title="">777</a>]</cite>. 이러한 방법의 본질은 문서 목록의 슬라이딩 윈도우 전략 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib774" title="">774</a>, <a class="ltx_ref" href="#bib.bib778" title="">778</a>]</cite>, setwise selection prompting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib779" title="">779</a>]</cite>, fine-grained relevance labels incorporation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib780" title="">780</a>]</cite>, pairwise comparison prompting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib775" title="">775</a>]</cite>와 같은 텍스트 재순위를 위한 명령어들의 특별한 설계에 있다. 또한, 최근의 노력들은 LLMs을 사용하여 중간 텍스트들(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p2.1.8">e.g.,</em>URLs)을 수-샷 시연들을 사용하여 검색 결과로서 생성한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib781" title="">781</a>]</cite> 모델 성능을 더욱 향상시키기 위해 LLMs은 전통적인 PLM 기반 IR 모델인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib782" title="">782</a>]</cite>에 대한 미세 조정 프로세스와 유사하게 재순위화 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib782" title="">782</a>, <a class="ltx_ref" href="#bib.bib783" title="">783</a>]</cite> 또는 검색(밀도 검색 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite> 및 모델 기반 검색 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib784" title="">784</a>, <a class="ltx_ref" href="#bib.bib785" title="">785</a>]</cite> 포함)을 위해 백본으로 특별히 미세 조정될 수 있다. 그러나 IR 모델로서 LLM을 미세 조정하는 것은 LLM의 거대한 매개변수 규모를 고려할 때 상당한 비용을 수반한다.</p>
</div>
<div id="S8.SS1.SSS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS2.p3.1.1">LLM-Enhanced IR Models. </span> 다른 주요 연구 방향으로서, LLMs는 기존 IR 모델(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p3.1.2">e.g.,</em> small models)을 개선하는데 사용될 수 있다. 기존 IR 모델이 직면한 일반적인 과제는 관련 판단 주석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib786" title="">786</a>, <a class="ltx_ref" href="#bib.bib787" title="">787</a>]</cite>의 부족이다. 이 문제를 해결하기 위해 LLMs는 주어진 쿼리 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib788" title="">788</a>]</cite>에 대해 긍정 또는 부정 문서에 주석을 달거나, 몇 가지 시연 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib789" title="">789</a>, <a class="ltx_ref" href="#bib.bib790" title="">790</a>]</cite>를 참조하여 코퍼스의 문서 집합을 기반으로 해당 쿼리를 생성하도록 지시할 수 있다. 학습 데이터 증강 외에도 LLM은 쿼리와 문서 모두의 검색 지향 정보성을 개선함으로써 기존 IR 모델을 개선할 수 있는 잠재력을 가지고 있다. IR 시스템에서 입력 쿼리는 사용자의 인지적 및 문화적 역량에 의해 제약되어 실제 의도를 정확하게 표현하기가 어려울 수 있으며 문서에 존재하는 관련 없는 내용도 쿼리와의 관련성 평가에 영향을 미칠 수 있다. 해결책으로 LLM은 잘 설계된 명령어를 통해 질의 의도에 대한 이해를 높이고 추가 지식을 질의에 통합하기 위해 질의를 재작성하는 데 활용될 수 있다. 재작성된 쿼리는 원본 쿼리 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib791" title="">791</a>]</cite>, 쿼리와 관련된 말뭉치의 문서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib792" title="">792</a>]</cite>, 또는 의사 생성된 문서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib793" title="">793</a>]</cite>와 연결된 쿼리의 확장 등의 형태를 취할 수 있다. 또한 문맥 확장 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib794" title="">794</a>]</cite>를 위한 LLMs를 사용하여 원본 문서를 기반으로 생성된 쿼리로 문서를 확장할 수도 있다.</p>
</div>
<div id="S8.SS1.SSS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS2.p4.1.1">Remaining Issues. </span>  이 부분에서는 IR 시스템을 개선하기 위해 LLM을 적용하기 위한 몇 가지 중요한 문제에 대해 추가로 논의합니다. 첫째, LLMs은 범용 태스크 해결자로 될 수 있지만, 기존 IR 시스템에 직접 적합하지는 않다: 추론에 대한 높은 오버헤드가 필요하며, 긴 텍스트 또는 문서 목록을 모델링하는 데 한계가 있으며, 텍스트 순위 작업을 수행하기 위해 특별한 적응(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p4.1.2">e.g.,</em> instruction tuning)이 필요하다. 따라서 현대 IR 시스템에 LLM을 적용하기 위한 보다 체계적인 접근법이 조사되어야 하며, 이점을 활용하고 이러한 한계를 극복해야 한다. 둘째, LLMs의 출현은 새로운 정보 탐색 방법의 개발을 조명한다(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS2.p4.1.3">e.g.,</em> New Bing). LLM의 용량과 기존 IR 시스템의 장점인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib796" title="">796</a>]</cite>를 통합하여 IR의 아키텍처와 패러다임을 재구성하는 방법을 모색하는 것은 의미가 있다. 셋째, 기존의 연구는 주로 텍스트 검색에 초점을 맞추고 있으며, 멀티모달 정보원에 대한 종합적인 고려가 부족하다. <a class="ltx_ref" href="#S8.SS1.SSS4" title="8.1.4 Multimodal Large Language Model ‣ 8.1 LLM for Research Community ‣ 8 Applications ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">8.1.4</span></a>절에서 논의될 바와 같이 멀티모달 대형 언어 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib797" title="">797</a>]</cite>도 널리 연구되어 보다 강력한 멀티미디어 검색 시스템 개발이 가능하다.</p>
</div>
</section>
<section id="S8.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.3 </span>LLM for Recommender Systems</h4>

<div id="S8.SS1.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS3.p1.1">사용자 검색 쿼리를 분석하여 관련 문서를 검색하는 IR 시스템과 달리 추천 시스템(RS)은 기본 사용자 선호도를 캡처하고 사용자에게 적절한 정보 리소스를 제공하는 것을 목표로 한다. 전형적으로, 기존 연구들은 추천 모델(클래식 또는 딥 러닝 모델)을 사용자의 로그된 데이터(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS3.p1.1.1">e.g.,</em> click data) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib802" title="">802</a>, <a class="ltx_ref" href="#bib.bib745" title="">745</a>]</cite>에 피팅하여 트레이닝한다. 그러나 이러한 모델은 종종 일련의 기술적인 문제, 즉 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS3.p1.1.2">예:</em> cold-start 권장 사항, 도메인 전송 및 설명성이 좋지 않습니다. 최근 LLMs은 도메인 일반화 및 언어 생성의 강력한 능력으로 인해 추천 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib357" title="">357</a>, <a class="ltx_ref" href="#bib.bib803" title="">803</a>, <a class="ltx_ref" href="#bib.bib804" title="">804</a>]</cite>의 이러한 문제를 완화할 수 있는 가능성을 입증했다. 이 부분에서는 추천 모델로서의 LLMs, LLM 강화 추천 모델 및 추천 시뮬레이터로서의 LLMs의 세 가지 측면에서 추천 시스템에서 LLM의 최근 진행 상황을 간략하게 검토한다.</p>
</div>
<div id="S8.SS1.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS3.p2.1.1">LLMs as Recommendation Models. </span>  특정 방법이나 메커니즘을 사용하면 LLMs를 추천 모델로 사용할 수 있습니다. 이 노선에 따른 기존 작업은 일반적으로 크게 두 가지로 나눌 수 있다. 먼저, 일부 방법은 제로 샷 패러다임(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS3.p2.1.2">i.e.,</em> without parameter tuning) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib805" title="">805</a>, <a class="ltx_ref" href="#bib.bib806" title="">806</a>]</cite>에서 추천 작업을 완료하기 위한 LLMs를 프롬프트한다. 추천 성능을 향상시키고 잠재적인 모델 편향 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib807" title="">807</a>, <a class="ltx_ref" href="#bib.bib808" title="">808</a>]</cite>를 완화하기 위해 최근 집중 및 상황 내 학습과 같은 일련의 신속한 엔지니어링 방법을 도입한다. 둘째, 또 다른 범주의 연구는 명령어 튜닝 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib357" title="">357</a>, <a class="ltx_ref" href="#bib.bib809" title="">809</a>]</cite>를 통해 개인화된 추천을 위한 LLMs을 전문화하는 것을 목표로 한다. 특히, 높은 품질의 명령어 데이터는 휴리스틱 템플릿과의 사용자-아이템 상호 작용을 기반으로 구성될 수 있는 추천 태스크에 LLM을 적응시키는 핵심이다. 명령어 다양성을 더욱 향상시키기 위해, InstructRec<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib357" title="">357</a>]</cite>는 제품 검색 및 개인화된 추천과 같은 다양한 시나리오에서 많은 양의 잠재적인 사용자 명령을 시뮬레이션하기 위해 자체 명령 기술을 사용한다. 각 항목을 텍스트 설명으로 표현하는 것 외에도 협력적 의미를 LLM에 통합하기 위해 추천 시스템 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib810" title="">810</a>, <a class="ltx_ref" href="#bib.bib811" title="">811</a>]</cite>에서 LLM의 어휘를 의미 식별자로 확장하는 것에 대한 관심이 높아지고 있다.</p>
</div>
<div id="S8.SS1.SSS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS3.p3.1.1">LLM-enhanced Recommendation Models. </span>  연구자는 LLMs에게 추천을 직접 제공하도록 지시할 뿐만 아니라, LLMs에 인코딩된 보편적 지식을 활용하여 전통적인 추천 시스템을 개선하는 방안도 제안한다. 이 라인의 기존 접근 방식은 크게 세 가지로 나눌 수 있다. 첫 번째 범주는 LLM을 사용하여 사용자의 과거 상호 작용 데이터에서 사용자의 잠재적 의도를 추론한다. 또한, 전통적인 추천/검색 모델은 추론된 의도를 사용하여 관련 항목의 검색을 개선한다. 또한 여러 연구에서 LLM을 특징 인코더로 사용하는 방법을 탐구한다. 그들은 LLMs을 사용하여 항목 및 사용자의 부가 정보를 인코딩한다(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS3.p3.1.2">e.g.,</em> 항목의 설명 및 사용자의 리뷰), 따라서 사용자 및 항목의 보다 유익한 표현을 유도한다. 그런 다음 이러한 표현들은 증강 입력 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib814" title="">814</a>, <a class="ltx_ref" href="#bib.bib815" title="">815</a>]</cite>와 같이 전통적인 추천 시스템에 공급된다. 다른 대안적 접근법으로서, 몇몇 연구들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib816" title="">816</a>, <a class="ltx_ref" href="#bib.bib817" title="">817</a>]</cite>는 전통적인 추천기들을 개선하기 위해 LLM들의 용량들을 전송하기 위한 증류-유사 방식(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS3.p3.1.3">e.g.,</em> semantic encoding)을 채택한다(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS3.p3.1.4">i.e.,</em> small models). 특히, LLM과 전통적인 추천 모델의 숨겨진 상태를 합동 훈련을 통해 정렬한다. 교육 후에는 향상된 소형 모델만 온라인으로 배포되기 때문에 온라인 서비스에서 LLM의 막대한 오버헤드를 피할 수 있다.</p>
</div>
<div id="S8.SS1.SSS3.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS3.p4.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS3.p4.1.1">LLM as Recommendation Simulator. </span> 최근 자율 AI 에이전트의 성공에 영감을 받은 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib818" title="">818</a>]</cite>, LLMs는 추천 시뮬레이터 개발에도 활용되었으며 (exemplified by RecAgent<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib819" title="">819</a>]</cite>), 추천 시스템 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib819" title="">819</a>, <a class="ltx_ref" href="#bib.bib821" title="">821</a>, <a class="ltx_ref" href="#bib.bib822" title="">822</a>]</cite>에서 사용자 실제 행동을 시뮬레이션할 수 있는 큰 잠재력을 보여준다. 구체적으로, 개인화된 시뮬레이션을 만들기 위해, 에이전트는 관련 신원 정보를 포괄하는 프로파일링 모듈을 구비할 것이다. 그런 다음 에이전트의 과거 상호 작용 경험을 저장하기 위해 메모리 모듈이 도입된다. 시뮬레이션의 프로세스 동안, 에이전트들은 그들의 근본적인 사용자 선호도를 포착하기 위해, 그들의 과거 경험들에 기초하여 자기 반성을 수행하도록 추가로 프롬프트된다. 기존의 추천 시뮬레이터는 상호작용 과정에서 항목을 명시적으로 모델링하지 않고 사용자 중심의 방식으로 수행되는 경우가 대부분이다. 이를 해결하기 위해 AgentCF<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib821" title="">821</a>]</cite>는 사용자와 아이템 모두를 에이전트로 모델링하고, 사용자와 아이템 간의 쌍방향 관계를 포착하기 위해 사용자-아이템 상호작용을 시뮬레이션하기 위한 협력적 반사를 더 용이하게 한다.</p>
</div>
<div id="S8.SS1.SSS3.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS3.p5.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS3.p5.1.1">Remaining Issues. </span>  이러한 노력에도 불구하고 추천 시스템에서 LLMs 적용 시 해결해야 할 과제가 여전히 몇 가지 있다. 첫째, 기존 연구에서는 제로/페우 샷 설정에서 LLM 기반 추천 모델이 기존의 ID 기반 추천인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib807" title="">807</a>, <a class="ltx_ref" href="#bib.bib806" title="">806</a>]</cite>보다 더 나쁜 성능을 보이는 경향이 있음을 보여주었다. 이는 LLM이 개인화된 사용자 행동 및 도메인별 협력 의미론에 대한 이해가 부족할 수 있음을 나타낸다. 명령어 튜닝은 이 문제를 어느 정도 완화시키지만, LLM과 추천 시스템 사이의 의미적 격차를 완전히 줄일 수 없으며 높은 튜닝 비용도 부담한다. 또한, 추천 시스템은 낮은 자원 환경에서 사용자의 경험을 향상시키기 위해 추론 지연을 최소화하는 것을 우선시하며(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS3.p5.1.2">e.g.,</em> phones) 이는 메모리 오버헤드뿐만 아니라 LLM의 추론 속도에 대한 도전을 제기한다. 따라서, 실제 추천 시스템에서 LLMs을 효율적이고 효과적으로 배치하기 위해 효율적인 튜닝 및 양자화 방법과 같은 개선 기술을 탐색하는 것이 중요하다. 또한, 기존의 LLM들은 긴 컨텍스트 모델링에서 제한된 용량으로 인해 방대한 양의 사용자-아이템 상호작용 데이터를 처리하는데 어려움이 있다. 긴 상호작용 시퀀스에서 LLM의 모델링 능력을 향상시키기 위해 개선된 컨텍스트 길이 확장 및 컨텍스트 정보 활용 접근법이 개발되어야 한다.</p>
</div>
</section>
<section id="S8.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.4 </span>Multimodal Large Language Model</h4>

<div id="S8.SS1.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS4.p1.1">기존 문헌 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib823" title="">823</a>, <a class="ltx_ref" href="#bib.bib824" title="">824</a>]</cite>에서 멀티모달 모델은 주로 입력으로부터 다양한 모달리티(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p1.1.1">e.g.,</em> text, image, audio)의 정보를 처리하고 통합하여 특정 모달리티에서 해당 출력을 추가로 생성할 수 있는 모델을 의미한다. 이 부분에서는 주로 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p1.1.2">multimodal large language models (MLLMs)</em>><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib797" title="">797</a>]</cite><span class="ltx_note ltx_role_footnote" id="footnote51"><sup class="ltx_note_mark">51</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">51</sup><span class="ltx_tag ltx_tag_note">51</span>In existing work, large vision language models (LVLMs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib662" title="">662</a>]</cite> are also used to term such bimodal models that are developed based on LLMs. We use the naming of MLLMs in this part due to its wide use in existing literature. </span></span></span>이라고 불리는 비텍스트적 모달리티의 정보 모델링을 가능하게 함으로써 LLM의 멀티모달 확장에 중점을 둔다. 논의를 시작하기 위해 입력을 텍스트 이미지 쌍으로 지정하고 출력을 텍스트 응답으로 지정합니다. 다른 양식, <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p1.1.3">e.g.,</em> language-audio models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib825" title="">825</a>]</cite>에 대해서도 유사한 논의가 이루어질 수 있으며, 이는 여기에서 우리의 범위를 벗어난다. 본질적으로, MLLM은 세계 텍스트를 기반으로 학습되는 LLM의 우수한 모델 용량을 활용하기 위해 다른 모달리티의 정보를 텍스트 모달리티에 적용하여 개발된다. 전형적으로, MLLM은 비전 및 언어 표현을 정렬하는 연결 모듈에 의해 연관된, 이미지 인코딩을 위한 이미지 인코더 및 텍스트 생성을 위한 LLM을 포함한다. 생성 동안, 이미지는 먼저 패치들로 분할되고, 이어서 이미지 인코더 및 연결 모듈에 의해 패치 임베딩들로 변환되어, LLM에 의해 이해될 수 있는 시각적 표현을 유도한다. 이어서, 패치 임베딩들 및 텍스트 임베딩들이 연접되고, MLLM에 피드백되어, 언어 모델이 응답을 자동으로 생성할 수 있게 한다. 이하에서는 능력 있는 MLLM을 개발하기 위한 훈련, 평가 및 핵심 사항에 대해 논의할 것이다.</p>
</div>
<div id="S8.SS1.SSS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS4.p2.1.1">Training Process. </span> MLLM의 훈련 과정은 비전 언어 정렬 사전 훈련과 시각적 명령어 튜닝의 두 가지 주요 단계를 포함한다.</p>
</div>
<div id="S8.SS1.SSS4.p3" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS4.p3.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p3.1.1">Vision-language alignment pre-training. </em> MLLM을 개발하기 위해 기존 작업은 대부분 비전 인코더와 LLM을 사전 훈련된 모델<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib826" title="">826</a>, <a class="ltx_ref" href="#bib.bib149" title="">149</a>, <a class="ltx_ref" href="#bib.bib150" title="">150</a>]</cite>로 초기화한다. 이 모델은 뛰어난 비전과 언어 능력을 보유하지만 서로 다른 의미 공간에 걸쳐 있습니다. 따라서 비전 언어 정렬 사전 훈련(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p3.1.2">i.e.,</em> the first-stage training)의 목표는 대규모 이미지 텍스트 쌍에 대한 종단 간 훈련을 통해 비전 인코더와 LLM을 정렬하는 것이다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib827" title="">827</a>, <a class="ltx_ref" href="#bib.bib828" title="">828</a>]</cite>. 그러나 이미지-텍스트 쌍에서 이 두 모델을 직접 튜닝하면 원래 표현 능력이 저하될 수 있다. 정렬 성능을 향상시키기 위해서는 효과적인 훈련 전략을 설계하고 적절한 사전 훈련 데이터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib829" title="">829</a>, <a class="ltx_ref" href="#bib.bib830" title="">830</a>]</cite>를 선택하는 것이 중요하다. 기존 작업은 주로 교차 모달리티 정렬을 위한 전략을 사용합니다. (1) 이미지-텍스트 쌍의 수가 충분히 크지 않은 경우(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p3.1.3">e.g.,</em> less than 1M) 연결 모듈만 업데이트 하는 것이 좋습니다. (2) 학습 데이터가 고품질 텍스트 코퍼라 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib831" title="">831</a>]</cite> 또는 미세한 주석이 있는 이미지-텍스트 쌍을 포함 하는 경우, LLM을 미세 조정 하 여 성능을 높일 수 있습니다. (3) 이미지-텍스트 쌍의 수가 매우 큰 경우(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p3.1.4">e.g.,</em> 약 1B), 비전 인코더를 미세 조정 하는 것도 그럴듯합니다.</p>
</div>
<div id="S8.SS1.SSS4.p4" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS4.p4.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p4.1.1">Visual instruction tuning. <em> 비전 언어 사전 훈련 후, 2단계 훈련인 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p4.1.2">i.e.,</em> visual instruction tuning은 MLLM의 instruction-following과 task-solving 능력을 향상시키는 것을 목표로 한다. 일반적으로 비주얼 명령어 튜닝의 입력은 이미지와 태스크 디스크립션으로 구성되며, 태스크는 해당 텍스트 출력을 생성하는 것이다. 성능 향상을 위해 고품질 시각적 명령 데이터는 MLLM의 능력을 이끌어내고 향상시키는 데 핵심이다. 따라서 대부분의 연구는 다양한 시각적 명령어 데이터셋을 구축하는 데 전념하고 있다. 초기 연구에서는 기본 접근법으로 GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib149" title="">149</a>]</cite>에서 증류하거나 비전 언어 작업 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib151" title="">151</a>]</cite>를 재구성하여 시각적 지침을 구성한다. 최근 연구에서는 명령어 데이터의 품질을 향상시키기 위해 명령어 다양성(<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib834" title="">834</a>]</cite>), 세분화된 정보(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p4.1.3">e.g.,</em> coordinates of objects)를 명령어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib833" title="">833</a>]</cite> 또는 복합 시각적 추론 명령어(<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib835" title="">835</a>]</cite>)를 통합하여 개선된 전략을 제안한다.</p>
</div>
<div id="S8.SS1.SSS4.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS4.p5.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS4.p5.1.1">Evaluation of MLLM. </span> MLLM 개발에 대한 접근법을 소개한 후, MLLM의 멀티모달 능력을 효과적으로 평가하는 방법에 대해 다음 세 가지 측면에서 추가로 논의한다.</p>
</div>
<div id="S8.SS1.SSS4.p6" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS4.p6.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p6.1.1">Evaluation perspectives. <em> MLLMs에 대한 평가 태스크는 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p6.1.2">perception</em> 및 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p6.1.3">cognition</em> 태스크의 두 가지 주요 유형으로 분류될 수 있습니다. 구체적으로 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p6.1.4">perception</em> 태스크는 이미지 콘텐츠의 기본 의미를 이해하는 모델의 능력을 평가하는 것을 목표로 하는 반면, <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p6.1.5">cognition</em> 태스크는 인식 결과를 기반으로 추론이 필요한 더 복잡한 태스크를 가진 모델을 평가한다. 인식 능력은 일반적으로 이미지 속성(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p6.1.6">e.g.,</em> topic and style) 및 객체(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p6.1.7">e.g.,</em> existence and color) 또는 OCR 관련 작업을 통해 평가되며, 기존 데이터 세트 또는 인간 또는 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib836" title="">836</a>, <a class="ltx_ref" href="#bib.bib837" title="">837</a>, <a class="ltx_ref" href="#bib.bib838" title="">838</a>, <a class="ltx_ref" href="#bib.bib839" title="">839</a>]</cite>에 의한 주석이 있는 기존 이미지로부터 파생된 새로운 데이터 세트를 기반으로 한다. 눈에 띄는 인식 문제는 모델의 반응이 이미지와 일치하지 않는 내용을 포함하는 환각 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib840" title="">840</a>]</cite>이다. MLLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib834" title="">834</a>, <a class="ltx_ref" href="#bib.bib841" title="">841</a>, <a class="ltx_ref" href="#bib.bib842" title="">842</a>]</cite>의 환각에 대한 기존 연구 중 대상 환각<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib843" title="">843</a>]</cite>는 많은 연구 주목을 받고 있다. 객체 환각에 대한 안정적이고 강력한 평가를 수행하기 위해 POPE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib844" title="">844</a>]</cite>는 객체 인식을 일련의 이진 질문으로 변환하는 폴링 기반 객체 프로빙 접근법을 제안하며, 그 결과는 현재 MLLM이 종종 객체 환각에 어려움을 겪는다는 것을 나타낸다. 반면에 인지 과제는 영상 지각에 기반한 추론을 수행하기 위해 MLLM이 필요하다. 일반적인 추론 작업은 시각적 질문 응답(VQA)이며, 여기서 모델들은 공간 관계에 대한 추론을 요구하는 이미지에 대한 질문에 대답한다. MLLM의 성능을 완전히 탐구하기 위해 HallusionBench <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib848" title="">848</a>]</cite>는 200개의 정교한 시각적 종속 또는 보충 질문을 수집하며, 이 질문에서 LLaVA-1.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib831" title="">831</a>]</cite> 및 GPT-4V <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite>와 같은 가장 진보된 MLLM조차도 좋은 성능을 얻지 못한다.</p>
</div>
<div id="S8.SS1.SSS4.p7" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS4.p7.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p7.1.1">Evaluation paradigms. </em> MLLMs의 응답은 closed-ended 방식 또는 open-ended 방식으로 평가될 수 있다. 전통적인 멀티모달 태스크들은 종종 폐쇄형 평가 프레임워크에 의존하는데, 여기서 평가는 모델의 응답과 지상-진실 답변 사이의 정확한 매칭에 기초한다. 시각적 질문 응답 작업에 대한 VQA 점수 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib849" title="">849</a>]</cite>와 캡션 작업에 대한 CIDEr <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib850" title="">850</a>]</cite> 점수가 그 예이다. 그러나 MLLM은 개방형 방식으로 응답을 생성하며, 이는 정답을 포함할 수 있지만 그라운드-진실과 완벽하게 일치하지 않는다. 이러한 불일치는 이전 평가 패러다임에서 모델의 성능을 과소평가하게 할 수 있다. 이 문제를 해결하기 위해 최근 접근법은 인간 또는 LLM을 평가자<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib829" title="">829</a>]</cite>로 통합했다. 예를 들어 MMBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib838" title="">838</a>]</cite>는 ChatGPT를 사용하여 모델 응답을 객관식 질문 세트에서 가장 적절한 옵션과 정렬합니다. 마찬가지로 LLaVA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib851" title="">851</a>]</cite>는 MLLM의 출력을 평가하기 위해 GPT-4를 활용하며, 여기서 GPT-4는 생성된 이미지 캡션 및 객체 경계 상자를 평가를 위한 시각적 입력으로 사용한다. 이러한 개방형 평가 방법은 인간 또는 LLM의 개입으로 인해 더 높은 비용을 발생시키면서 평가 정확도를 향상시킬 수 있다.</p>
</div>
<div id="S8.SS1.SSS4.p8" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS4.p8.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p8.1.1">Evaluation benchmarks. </em> MLLM의 보다 철저한 평가를 용이하게 하기 위해, 다양한 벤치마크가 개발되었다. 그 중 일부는 종합적인 평가를 위해 기존의 비전 언어 과제를 수집한다. 예를 들어 LVLM-eHub <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib852" title="">852</a>]</cite>는 47개의 기존 텍스트 관련 시각적 작업을 집계하여 MLLM의 6가지 고유한 기능을 평가하고 Reform-Eval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib853" title="">853</a>]</cite>는 기존 벤치마크의 질문을 균일한 형식으로 표준화함으로써 한 단계 더 나아가 백본 모델이 MLLM의 성능에 어떻게 영향을 미치는지 논의한다. 기존 작업을 통합하는 것 외에도 여러 작업은 인간이 주석을 달거나 LLM의 도움으로 새로운 질문을 도출한다. MME<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib839" title="">839</a>]</cite>는 인식 및 인지 평가를 위해 수동으로 수집된 텍스트 명령어와 공개 소스의 이미지를 페어링하여 데이터 세트를 생성한다. MMBench <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib838" title="">838</a>]</cite>는 이러한 명령어를 객관식 문항으로 변형하고 CircularEval을 도입하여 평가의 일관성을 보장한다. SEED-Bench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib854" title="">854</a>]</cite>는 시간적 이해 과제를 더 고려하고 LLM의 도움을 받아 평가 척도를 19K 객관식 문항으로 확대한다. MM-Vet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib855" title="">855</a>]</cite>는 MLLM의 통합된 멀티모달 능력을 평가하기 위해 더 복잡한 작업을 제시한다. 그것은 여섯 가지 필수 복합 능력을 정의하는 것으로 시작하여 여러 능력을 결합하여 복잡한 질문을 만든다. 요약하면, 위의 벤치마크는 MLLM의 종합 평가 및 개선된 개발에 집합적으로 기여한다.</p>
</div>
<div id="S8.SS1.SSS4.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS4.p9.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS4.p9.1.1">Key Points for Improving MLLMs. </span> 가능한 MLLM을 개발하기 위해 수업 데이터, 훈련 전략, 안전 및 정렬의 관점에서 모델 용량을 개선하기 위한 세 가지 핵심 사항에 대해 계속 논의한다.</p>
</div>
<div id="S8.SS1.SSS4.p10" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS4.p10.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p10.1.1">Visual instruction data</em>. 광범위한 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib831" title="">831</a>, <a class="ltx_ref" href="#bib.bib856" title="">856</a>]</cite>는 시각적 명령의 양과 질 모두가 MLLM의 모델 성능에 중요한 영향을 미친다는 것을 경험적으로 발견했다. 시각적 명령어를 구성하는 한 가지 기본적인 방법은 이미지의 텍스트 설명을 기반으로 명령어를 합성하기 위해 LLM의 예외적인 능력을 활용하는 것이다. 명령어의 품질을 더욱 향상시키기 위해 인간 주석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib833" title="">833</a>, <a class="ltx_ref" href="#bib.bib857" title="">857</a>]</cite>의 도움으로 세밀한 시각적 명령을 구성하거나 주의 깊게 설계된 프롬프트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib835" title="">835</a>]</cite>를 통해 더 복잡한 데이터를 합성할 수 있다. 위의 LLM 기반 접근법의 효과에도 불구하고, LLM(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p10.1.2">i.e.,</em> 텍스트 생성 모델 without training on any images)이 구두화된 시각적 정보(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p10.1.3">e.g.,</em> 캡션 및 좌표)만을 기반으로 충분히 좋은 시각적 명령을 생성할 수 있는지에 대한 하나의 기본 질문이 나타난다. 특히, 기존의 연구는 LLMs에 의해 생성된 시각적 명령어가 시각적 정보에 대한 잘못된 해석인 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p10.1.4">e.g.,</em> object hallucination <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib844" title="">844</a>]</cite>를 포함하는 경우도 있음을 밝혔다. 따라서 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib835" title="">835</a>]</cite>에 의해 생성된 명령어 데이터의 품질을 제어하기 위한 효과적인 검증 방법을 설계하는 것이 중요하다. 또한, 시각적 지시가 좋은 시각적 지시가 무엇이며 시각적 지시가 MLLM에서 특정 멀티모달 능력을 유도하는 방법에 대한 더 많은 조사가 여전히 필요하다.</p>
</div>
<div id="S8.SS1.SSS4.p11" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS4.p11.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p11.1.1">Model training. </em> LLM과 달리 MLLM은 처음부터 훈련되지 않고 사전 훈련된 언어 및 비전 모델을 기반으로 개발된다. 기존의 작업은 MLLM을 훈련하기 위해 전형적인 2단계 접근법인 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p11.1.2">i.e.,</em> vision-language alignment pre-training and visual instruction tuning을 사용한다. 본질적으로 기존의 MLLM은 (1) LLM의 고유한 기능과 파라메트릭 지식을 최대한 보존하고, (2) 사전 훈련된 LLM과 비주얼 인코더를 활용하여 멀티모달 태스크에 효과적으로 적응하는 것을 목표로 한다. 위의 두 가지 목표를 달성하기 위해 연결 모듈 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib151" title="">151</a>]</cite>만을 최적화하거나 커넥터 모듈과 LLM 구성 요소 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib851" title="">851</a>]</cite>를 모두 미세 조정하는 두 가지 전형적인 훈련 전략이 시각적 명령 튜닝을 위해 종종 사용된다. 우리가 볼 수 있듯이, 전자는 LLM의 원래 용량을 예약할 수 있지만 적응 성능이 약할 가능성이 있는 반면, 후자는 다중 모드 작업에 완전히 적응할 수 있지만 LLM의 원래 용량이 손실된다. 향상된 다중 모드 용량을 달성하기 위해 두 측면을 효과적으로 균형화하는 방법을 조사하기 위해 더 많은 노력이 필요하다. 또한, 기존의 MLLM들은 여전히 LLM들의 용량들에 과도하게 의존하며, 이는 많은 멀티모달 태스크들에 대한 한계를 제기한다(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p11.1.3">e.g.,</em> space positioning). 이 과정에서 멀티모달 정보도 활용할 수 있도록 언어 모델의 개선된 훈련 접근법을 탐색하는 것은 의미가 있을 것이다.</p>
</div>
<div id="S8.SS1.SSS4.p12" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS4.p12.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p12.1.1">Safety and alignment. </em>  안전성 및 정렬은 기술 접근법 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>에 의해 모델의 행동을 규제하는 것을 목표로 하는 LLMs에서 널리 논의되어 왔다. 이 주제는 MLLM에게도 중요하다. 고급 MLLM(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p12.1.2">e.g.,</em> GPT-4V <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite>)도 안전 문제에 취약할 수 있습니다. 예를 들어 GPT-4V는 때때로 이미지에 대한 사실적 부정확성과 근거 없는 추론을 나타낼 수 있다. 경우에 따라 특정 개인 또는 그룹 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite>를 대상으로 하는 유해 콘텐츠까지 생성할 수 있다. 또한, 오픈 소스 MLLM은 환각 반응 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib844" title="">844</a>]</cite>를 생성하는 경향이 있으며, 유해 콘텐츠 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib858" title="">858</a>]</cite>를 생성하기 위해 쉽게 조작할 수 있다. 앞서 언급한 문제를 해결하기 위해 일부 연구에서는 환각<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib834" title="">834</a>]</cite>의 문제를 완화하기 위해 특수 시각 지침을 수집한다. 또 다른 대안적인 접근법은 사후 방식 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib859" title="">859</a>]</cite>에서 MLLM에 의해 생성된 환각 반응을 교정하기 위한 수정 모델을 훈련시키는 것이다. 추가적으로, MLLM들을 RLHF와 정렬하는 것은 또한 MLLM들이 개선된 사실성<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib860" title="">860</a>]</cite>를 갖는 응답들을 생성하는 것을 도울 수 있다. 이러한 노력에도 불구하고, MLLM에 대한 기존의 정렬 기술은 정렬 기준에 대한 포괄적인 고려가 부족한 몇 가지 특정 측면(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS4.p12.1.3">e.g.,</em> 환각)에 주로 집중한다. MLLM의 안전성과 정렬에 대한 연구를 촉진하기 위해 더 많은 노력이 필요하다.</p>
</div>
</section>
<section id="S8.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.5 </span>KG-Enhanced LLM</h4>

<div id="S8.SS1.SSS5.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS5.p1.2">뛰어난 능력에도 불구하고 LLM은 종종 환각 콘텐츠를 생성할 가능성<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib602" title="">602</a>]</cite> 및 도메인 특정 지식<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib861" title="">861</a>]</cite>와 같은 지식 집약적 작업에 대한 어려움을 겪는다. 유망한 해결책으로서, 방대한 지식을 트리플 형식으로 저장하는 지식 그래프(Knowledge Graph, KGs)는 [em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p1.2.2">i.e.,</em> <math alttext="\langle" class="ltx_Math" display="inline" id="S8.SS1.SSS5.p1.1.m1.1"><semantics id="S8.SS1.SSS5.p1.1.m1.1a"><mo id="S8.SS1.SSS5.p1.1.m1.1.1" stretchy="false" xref="S8.SS1.SSS5.p1.1.m1.1.1.cmml">⟨</mo><annotation-xml encoding="MathML-Content" id="S8.SS1.SSS5.p1.1.m1.1b"><ci id="S8.SS1.SSS5.p1.1.m1.1.1.cmml" xref="S8.SS1.SSS5.p1.1.m1.1.1">⟨</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS1.SSS5.p1.1.m1.1c">\langle</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S8.SS1.SSS5.p1.2.1">head_entity, relation, tail_entity <math alttext="\rangle" class="ltx_Math" display="inline" id="S8.SS1.SSS5.p1.2.1.m1.1"><semantics id="S8.SS1.SSS5.p1.2.1.m1.1a"><mo id="S8.SS1.SSS5.p1.2.1.m1.1.1" stretchy="false" xref="S8.SS1.SSS5.p1.2.1.m1.1.1.cmml">⟩</mo><annotation-xml encoding="MathML-Content" id="S8.SS1.SSS5.p1.2.1.m1.1b"><ci id="S8.SS1.SSS5.p1.2.1.m1.1.1.cmml" xref="S8.SS1.SSS5.p1.2.1.m1.1.1">⟩</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS1.SSS5.p1.2.1.m1.1c">\rangle</annotation></semantics></math></span>을 활용하여 정밀하고 필요한 지식을 제공함으로써 LLM의 작업 성능을 향상시킬 수 있다. 일반적으로 지식 향상 접근법은 다른 형태의 구조화된 데이터(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p1.2.3">e.g.,</em> 테이블 및 데이터베이스)로 확장될 수 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib862" title="">862</a>]</cite> LLM을 개선하기 위한 KG의 통합으로 논의를 제한하지만, 두 가지 측면, 즉 검색 강화 LLM과 시너지 강화 LLM으로 자세히 설명되어 있다.</p>
</div>
<div id="S8.SS1.SSS5.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS5.p2.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS5.p2.1.1">Retrieval-Augmented LLM. </span>  기존 연구는 KG에서 방대한 양의 사실 기록으로 인해 일반적으로 검색 모델을 채택하여 먼저 KG에서 비교적 작은 부분 그래프를 얻은 다음 이를 활용하여 관련 지식을 풍부하게 하여 LLMs를 향상시킵니다. LLM이 등장하기 전에 검색된 하위 그래프는 종종 학습 데이터에 보완되어 파라미터 학습 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib863" title="">863</a>, <a class="ltx_ref" href="#bib.bib864" title="">864</a>, <a class="ltx_ref" href="#bib.bib865" title="">865</a>]</cite>를 통해 지식 정보를 PLM에 주입한다. 대조적으로, 검색된 지식을 활용하기 위해 LLM은 매개 변수 업데이트 없이 주로 프롬프트의 일부로 통합한다. 이 방법을 구현하기 위해 두 가지 주요 기술적 문제가 있다. <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p2.1.2">i.e.,</em> KG에서 관련 지식을 검색하는 방법과 LLMs에 의해 구조화된 데이터를 더 잘 사용하는 방법. 첫 번째 문제(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p2.1.3">i.e.,</em> retrieving relevant knowledge)에 대해, 전형적인 접근법은 작은 언어 모델(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p2.1.4">e.g.,</em>RoBERTa)을 학습하여 질문 관련 사실 트리플을 식별하는 것이다.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib866" title="">866</a>]</cite>. 검색 성능을 더욱 향상시키기 위해 여러 연구에서 반복적 읽기 후 추론 프레임워크를 제안하여 LLM이 KG와 여러 번 상호 작용하고 필요한 지식을 보다 정확한 방법으로 습득할 수 있다. 두 번째 문제(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p2.1.5">i.e.,</em> utilizing retrieved knowledge)에 대해 간단한 접근법은 검색된 하위 그래프를 직렬화하고 이를 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib651" title="">651</a>, <a class="ltx_ref" href="#bib.bib471" title="">471</a>]</cite>의 입력으로 포함하도록 특정 프롬프트를 만드는 것이다. 그러나 지식 직렬화에서 구조화된 정보의 손실로 인해 LLM은 원래 KG가 전달하는 구조적 의미를 완전히 포착할 수 없다. 이 문제를 해결하기 위해 여러 모델 기반 접근법이 특수 언어 모델(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p2.1.6">e.g.,</em>T5)을 훈련하여 하위 그래프를 자연어 텍스트로 변환합니다. 변환 정확도를 보장하기 위해 충분한 훈련 쌍(종종 감독되지 않은 구성) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib868" title="">868</a>]</cite> 및 우수한 모델 능력 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib869" title="">869</a>]</cite>에 의존한다.</p>
</div>
<div id="S8.SS1.SSS5.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS5.p3.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS5.p3.1.1">Synergy-Augmented LLM. </span>  복잡한 작업(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p3.1.2">e.g.,</em> multi-hop question answering <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib656" title="">656</a>]</cite>)을 해결하려면 체계적인 솔루션 계획에 따라 LLMs가 여러 번 KG를 쿼리해야 하는 경우가 많습니다. 이러한 다중 회전 상호 작용 접근법을 LLM <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p3.1.3">synergy-augmented LLM</em>이라고 한다. LLM과 KG를 상호 보완적으로 더 잘 시너지시키기 위해 최근 연구에서는 복잡한 작업을 여러 하위 목표로 분해하고 KG<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib458" title="">458</a>, <a class="ltx_ref" href="#bib.bib870" title="">870</a>, <a class="ltx_ref" href="#bib.bib871" title="">871</a>]</cite>의 필요한 지식을 활용하여 각각을 반복적으로 해결하는 것을 제안한다. 이 과정에서 LLM은 자율 에이전트(<a class="ltx_ref" href="#S8.SS1.SSS6" title="8.1.6 LLM-based Agent ‣ 8.1 LLM for Research Community ‣ 8 Applications ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">8.1.6</span></a> 섹션에서 자세히 설명됨)로 간주할 수 있으며, 이는 KG 환경<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib870" title="">870</a>]</cite>와의 상호 작용을 통해 계획을 자동으로 생성하고 실행합니다. 특히, 주류의 접근법은 일반적으로 현재 단계에서 가용한 지식 정보를 이용하여 후보들을 열거하는 것으로 시작하여, 질문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib870" title="">870</a>, <a class="ltx_ref" href="#bib.bib871" title="">871</a>]</cite>에 따라 다음 단계에 가장 적합한 후보들을 검색한다. 위의 두 단계를 반복함으로써 LLMs은 점차적으로 관련 증거 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib870" title="">870</a>, <a class="ltx_ref" href="#bib.bib871" title="">871</a>]</cite>를 수집하고 최종적으로 올바른 솔루션에 접근할 수 있다. 효과성에도 불구하고 KG에 대한 후보의 열거는 방대한 검색 공간<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib872" title="">872</a>]</cite>로 이어질 것이다. 이를 해결하기 위해 StructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib458" title="">458</a>]</cite>는 KG에 특화된 인터페이스를 사용하여 지식 정보에 접근하는 보다 효율적인 방법을 제안한다. 특히, 효율적이고 정확한 데이터 추출을 보장하기 위해 KG(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p3.1.4">e.g.,</em> relation extraction and triple extraction)에서 공통 데이터 연산에 따라 특화된 인터페이스를 신중하게 설계한다. 이러한 방식으로, LLMs는 KG들의 구조적 정보를 더 잘 조작하고 처리하도록 지시될 수 있고, 따라서 향상된 태스크 수행을 달성한다.</p>
</div>
<div id="S8.SS1.SSS5.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS5.p4.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS5.p4.1.1">Future Directions. </span>  위의 접근법 외에도 KG-enhanced LLM에 대한 몇 가지 유망한 방향이 남아 있다. 첫째, 구조화된 데이터의 다양성으로 인해 LLMs가 다양한 종류의 지식 소스, <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p4.1.2">e.g.,</em> 도메인별 KGs를 직접 활용하는 것은 여전히 어렵다. 따라서 LLM에 의해 서로 다른 지식 소스를 조작하고 활용할 수 있는 통일된 방법을 탐색하는 것이 필수적이다. 잠재적인 해결책으로 LLMs이 특정 지식 소스에서 제공하는 접근 인터페이스를 이해하고 활용하여 정확한 지식을 습득할 수 있도록 효과적인 접근 방법을 개발하는 것이 유망하며, 비용 효율적인 방법으로 데이터 다양성에 적응하는 방법을 연구해야 한다. 둘째, 실세계 정보의 진화에 따라 LLMs에 저장된 지식은 구식이 되거나 부정확해질 수 있다. 비용 효율적인 방식 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib873" title="">873</a>, <a class="ltx_ref" href="#bib.bib874" title="">874</a>]</cite>를 통해 업데이트된 지식을 LLMs로 동기화하는 방법을 탐색할 필요가 있다. 셋째, LLM의 환각을 줄이는 데 도움이 될 수 있는 보다 충실한 콘텐츠 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib875" title="">875</a>, <a class="ltx_ref" href="#bib.bib876" title="">876</a>]</cite>를 생성할 때 LLM을 정렬하기 위해 KG의 사실 정보의 사용을 조사할 수 있다.</p>
</div>
<div id="S8.SS1.SSS5.p5" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS5.p5.1">KG 강화 LLM을 탐색하는 것 외에도 LLM을 활용하여 KG 측면의 작업을 개선하는 것도 의미가 있다(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS5.p5.1.1">i.e.,</em> LLM4KG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib861" title="">861</a>, <a class="ltx_ref" href="#bib.bib877" title="">877</a>]</cite>). 대표적인 예는 LLM이 KG를 보완하거나 구성하는 데 도움이 될 수 있다는 것이다. 이 부분에 대한 논의는 우리의 범위를 벗어났기 때문에 생략한다.</p>
</div>
</section>
<section id="S8.SS1.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.6 </span>LLM-based Agent</h4>

<div id="S8.SS1.SSS6.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS6.p1.1">AI에서 에이전트에 대한 연구는 특정 목표를 달성하기 위해 환경을 인식하고, 결정을 내리고, 행동을 취할 수 있는 개체를 개발하는 것을 목표로 한다. 그러나 기존 에이전트는 휴리스틱 규칙이나 특정 환경에 국한되는 경우가 많으며, 이는 오픈 도메인 시나리오 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib879" title="">879</a>]</cite>로 일반화를 제한한다. LLM은 복잡한 작업을 해결하는 데 탁월한 능력을 가지고 있기 때문에 에이전트<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib818" title="">818</a>]</cite>의 핵심 계산 단위 역할을 하는 유망한 솔루션으로 빠르게 부상했다. 이 부분에서는 먼저 LLM 기반 에이전트의 프레임워크를 소개하고 그 응용에 대해 논의할 것이다.</p>
</div>
<div id="S8.SS1.SSS6.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS6.p2.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS6.p2.1.1">Overall Framework. </span> 다음으로 먼저 LLM 기반 에이전트의 주요 구성 요소를 자세히 설명한 다음 일반적인 워크플로를 제시합니다.</p>
</div>
<div id="S8.SS1.SSS6.p3" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS6.p3.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS6.p3.1.1">Components. 일반적으로 LLM 기반 에이전트에는 세 가지 주요 구성 요소가 있습니다. <span class="ltx_text ltx_font_italic" id="S8.SS1.SSS6.p3.1.2">memory</span>, <span class="ltx_text ltx_font_italic" id="S8.SS1.SSS6.p3.1.3">planning<span class="ltx_note ltx_role_footnote" id="footnote52"><sup class="ltx_note_mark">52</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">52</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote52.1.1.1">52</span></span><span class="ltx_text ltx_font_upright" id="footnote52.5"> Section </span><a class="ltx_ref ltx_font_upright" href="#S6.SS4" title="6.4 Planning for Complex Task Solving ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.4</span></a><span class="ltx_text ltx_font_upright" id="footnote52.6"> introduces planning as a utilization approach for LLMs, while in this section, we describe its utilization as a functional component in LLM-based agents. </span></span></span></span></span>, <span class="ltx_text ltx_font_italic" id="S8.SS1.SSS6.p3.1.4">execution</span>. 구체적으로 <span class="ltx_text ltx_font_italic" id="S8.SS1.SSS6.p3.1.5">memory</span> 컴포넌트는 환경으로부터 인지되는 정보를 저장하는 것을 목적으로 하며 의사 결정을 지원하는 데 활용될 수 있다. 특히 LLM 기반 에이전트는 일반적으로 읽기 및 쓰기 동작으로 단기 기억과 장기 기억 모두에서 정보를 유지한다. 단기 메모리는 일반적으로 LLMs(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS6.p3.1.6">i.e.,</em> input)의 내부 컨텍스트 창을 참조하며, 여기서 LLMs는 추론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib880" title="">880</a>]</cite>와 같은 액션을 통해 읽고 쓸 수 있다. 장기 메모리는 벡터 데이터베이스 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib537" title="">537</a>]</cite>와 같이 외부 저장소에 매핑될 수 있지만 LLM은 검색을 통해 읽고 반사를 통해 쓸 수 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib686" title="">686</a>]</cite>. 특히, 프로파일은 일반적으로 장기 메모리로 구현되는데, 이는 역할 및 함수 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib818" title="">818</a>]</cite>를 지정하는 에이전트의 중요한 기능이다. <span class="ltx_text ltx_font_italic" id="S8.SS1.SSS6.p3.1.7">planning</span> 컴포넌트는 메모리 컴포넌트로부터의 정보에 기초하여 액션 플랜을 생성하는 것을 담당한다. 데이터 형식에서 계획은 보통 텍스트 기반 명령 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib441" title="">441</a>]</cite> 또는 코드 기반 프로그램 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib443" title="">443</a>]</cite>의 형식을 취한다. 이를 생성하기 위해, LLM 기반 에이전트들은 먼저 여러 후보들을 제안하고, 그 중에서 더 적합한 후보들을 선택할 것이다. 초기 계획은 환경<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib528" title="">528</a>]</cite>의 실행 피드백으로 더욱 정교해질 수 있다. <span class="ltx_text ltx_font_italic" id="S8.SS1.SSS6.p3.1.8">execution</span> 컴포넌트는 계획 컴포넌트로부터 계획을 수행하는 것을 담당하며, 이는 내부 LLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib441" title="">441</a>]</cite> 또는 외부 도구<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib880" title="">880</a>]</cite>에 의해 이행될 수 있다.</p>
</div>
<div id="S8.SS1.SSS6.p4" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS6.p4.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS6.p4.1.1">Workflow. </em>  위에서 언급한 세 가지 구성 요소를 사용하여 LLM 기반 에이전트의 일반적인 워크플로는 다음과 같습니다. 먼저 환경으로부터 정보를 받아 단기 기억에 기록한다. 그리고, 에이전트는 새로 수신된 정보를 단기 메모리에 처리한다. 이러한 프로세스는 장기 기억으로부터 검색된 정보로 향상될 수 있다. 이어서, 계획 컴포넌트는 다음 계획을 생성하기 위해 단기 메모리로부터 처리된 정보를 활용한다. 마지막으로, 실행 컴포넌트는 계획 컴포넌트로부터 생성된 계획을 실행하며, 이는 외부 툴들을 추가로 보조할 수 있다. 앞서 언급한 과정을 반복함으로써 LLM 기반 에이전트는 환경의 피드백에 대응하여 자율적으로 행동을 조정하고 궁극적으로 목표를 달성할 수 있다. LLM 기반 에이전트는 사용자 요청을 수신하거나 목표를 할당받으면 위의 워크플로우를 따라 환경과의 다중 전환 상호 작용을 통해 작업을 수행합니다.</p>
</div>
<div id="S8.SS1.SSS6.p5" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS6.p5.1">요약하자면, LLM 기반 에이전트에서 LLM은 코어 계산 단위 역할을 하며, <span class="ltx_text ltx_font_italic" id="S8.SS1.SSS6.p5.1.1">memory</span>, <span class="ltx_text ltx_font_italic" id="S8.SS1.SSS6.p5.1.2">planning</span>, <span class="ltx_text ltx_font_italic" id="S8.SS1.SSS6.p5.1.3">execution</span>을 포함하는 구성 요소가 탑재된다. 이러한 구성 요소는 환경과의 상호 작용 동안 LLM 제어 하에 체계적인 방식으로 통합된다. 자세한 내용은 LLM 기반 AI 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib818" title="">818</a>]</cite>에 대한 포괄적인 조사를 참조할 수 있다.</p>
</div>
<div id="S8.SS1.SSS6.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS6.p6.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS6.p6.1.1">Applications. </span> 최근 LLM 기반 에이전트는 복잡한 작업을 자율적으로 해결하는 데 큰 잠재력을 보여 특정 도메인 또는 작업에 대한 유능한 애플리케이션을 빠르게 개발할 수 있다. 이 섹션에서는 단일 에이전트 및 다중 에이전트 시나리오의 응용 프로그램에 대해 논의합니다.</p>
</div>
<div id="S8.SS1.SSS6.p7" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS6.p7.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS6.p7.1.1">Single-agent based applications. </em>  단일 에이전트 모드를 기반으로 하는 응용 프로그램은 주로 사용자 요청을 자율적으로 완료할 수 있는 능력 있는 작업 해결기를 개발하는 것을 목표로 합니다. 범용 과제 해결에 초점을 맞춘 다수의 단일 에이전트 프로젝트가 개발되었다. 대표적인 프로젝트로 AutoGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib534" title="">534</a>]</cite>는 장단기 메모리 관리 및 검색 엔진과 같은 외부 도구를 사용하여 LLMs에 권한을 부여한다. AutoGPT는 사용자 요청을 자율적으로 처리하기 위해 자신의 기억과 추론과 같은 행동으로 요청을 이해하고, 세부 계획으로 분해하고, 도구의 도움으로 계획을 단계별로 실행하며, 환경의 피드백을 바탕으로 나머지 계획을 구체화한다. 이러한 반복 프로세스는 사용자 요청이 성공적으로 해결될 때까지 계속된다. 다른 유사한 프로젝트로는 GPT-Engineer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib881" title="">881</a>]</cite>와 XAgent <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib882" title="">882</a>]</cite>가 있다. 또한 웹 브라우징 환경의 경우 WebGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>, 실생활 환경의 경우 ProgPrompt<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib530" title="">530</a>]</cite>, 마인크래프트 환경의 경우 Voyager<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib697" title="">697</a>]</cite>와 같이 특정 도메인에 대한 자율 에이전트 개발을 목표로 하는 작업도 있다.</p>
</div>
<div id="S8.SS1.SSS6.p8" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS6.p8.1">• <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS6.p8.1.1">Multi-agent based applications. </em>  에이전트가 독립적으로 동작하는 단일 에이전트 시스템과 다른 멀티 에이전트 시스템은 협업하여 집단지성을 발휘한다. 전형적으로, 다수의 에이전트들은 각각의 역할들 및 기능들을 갖는, 동일하거나 상이한 LLM들로부터 인스턴스화될 수 있다. 이러한 에이전트 간의 조정 전략에 따라 다중 에이전트 시스템은 협력 기반과 경쟁 기반 두 가지 범주로 나눌 수 있다. 협력 기반 모드에서는 에이전트 간에 정보를 공유하고 협력 행동을 모색하기 위해 자유 형식의 대화 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib883" title="">883</a>]</cite>, 구조화된 문서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib884" title="">884</a>]</cite>, 데이터 임베딩 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib885" title="">885</a>]</cite> 등 다양한 통신 프로토콜이 제안되었다. 통신 프로토콜을 기반으로 에이전트는 소프트웨어 엔지니어링 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib884" title="">884</a>]</cite>, 사용자 행동 분석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib819" title="">819</a>, <a class="ltx_ref" href="#bib.bib821" title="">821</a>]</cite>, 사회 시뮬레이션 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib533" title="">533</a>]</cite>와 같이 다운스트림 애플리케이션에 대해 효과적으로 조직될 수 있다. 경쟁 기반 모드에서 논쟁은 발산적 사고를 촉진하고 에이전트 간의 귀중한 외부 피드백을 이끌어내기 위한 인기 있는 커뮤니케이션 프로토콜 중 하나이다. 이러한 방법은 수학적 추론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib886" title="">886</a>]</cite> 및 평가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib732" title="">732</a>]</cite>와 같이 정확한 의사 결정과 정확한 응답을 요구하는 도메인에 유익하다.</p>
</div>
<div id="S8.SS1.SSS6.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS6.p9.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS6.p9.1.1">Remaining Issues. </span>  큰 성공에도 불구하고 LLM 기반 에이전트의 개발과 응용을 제한하는 몇 가지 문제가 여전히 존재한다. 첫째, 모델 규모의 폭발적인 성장과 함께 LLM 기반 에이전트의 시간 및 메모리 오버헤드를 포함한 효율성은 대규모 배치, 특히 LLM 인스턴스가 많은 다중 에이전트 시스템에서 중요한 문제가 된다. 둘째, LLM 기반 에이전트 수의 축소에 따라 에이전트 간의 조정 복잡도 증가를 지원하기 위해 보다 효과적이고 효율적인 통신 프로토콜 및 아키텍처가 필요하다. 또한, 유능한 에이전트를 구축하는 것은 명령 후속 및 긴 텍스트 모델링과 같은 LLM의 능력에 대한 기술적 문제를 제기한다. 기존의 LLM은 인스턴스화 에이전트에 특별히 최적화되어 있지 않기 때문에 LLaMA와 같은 대부분의 공개 소스 LLM은 에이전트 개발을 효과적으로 촉진할 수 없다. 따라서 에이전트의 핵심 계산 단위 역할을 수행할 수 있는 전문화된 모델을 개발하는 것이 중요하다.</p>
</div>
</section>
<section id="S8.SS1.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.1.7 </span>LLM for Evaluation</h4>

<div id="S8.SS1.SSS7.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS1.SSS7.p1.1">인간 평가는 일반적으로 신뢰할 수 있는 품질 평가를 제공할 수 있지만 높은 주석 비용, 상당한 시간 요구 사항 및 주석 불일치 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib887" title="">887</a>]</cite>로 인해 종종 방해를 받는다. 이와는 대조적으로, 자동 평가는 인간 평가에 대한 확장 가능한 대안으로 채택될 수 있다. 전통적인 자동 평가는 참조 기반 메트릭에 의존했습니다 (<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS7.p1.1.1">e.g.,</em> BLEU 및 ROUGE). 최근 LLM이 일반 과제 해결자로 등장하면서 자동 평가자 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>, <a class="ltx_ref" href="#bib.bib647" title="">647</a>]</cite>로서의 잠재력을 부각시켜 LLM 기반 평가를 수행할 수 있게 되었다. 다음 부분에서는 평가 형식, 방법, 메타 평가 및 나머지 문제를 포함하여 평가를 위한 LLM에 대한 최근 진행 상황을 소개할 것이다.</p>
</div>
<div id="S8.SS1.SSS7.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS7.p2.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS7.p2.1.1">Evaluation Formats. </span>  평가 결과의 종류에 따라 평가 형식은 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS7.p2.1.2">score 기반 평가</em>와 <em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS7.p2.1.3">language 기반 평가</em>로 분류할 수 있다. 점수 기반 평가는 평가된 텍스트에 대한 품질 점수(<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS7.p2.1.4">e.g.,</em> 평점 또는 순위)를 할당하기 위해 측정 가능한 메트릭을 사용한다. 일반적인 방법은 쌍대 비교를 수행하는 것인데, 여기서 LLM은 평가 작업을 크게 단순화하는 특정 지침 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib354" title="">354</a>, <a class="ltx_ref" href="#bib.bib727" title="">727</a>, <a class="ltx_ref" href="#bib.bib647" title="">647</a>]</cite>에 따라 후보 텍스트의 부분 순서 관계를 결정하는 데 사용된다. 그러나 후보 수 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>]</cite>를 스케일링할 경우 비효율적인 문제에 직면할 수 있다. 평가 중에 고품질 참조 텍스트를 사용할 수 있는 경우 LLMs는 참조 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>, <a class="ltx_ref" href="#bib.bib728" title="">728</a>, <a class="ltx_ref" href="#bib.bib716" title="">716</a>]</cite>에서 제공하는 지침에 따라 텍스트 점수를 매기도록 지시할 수 있다. 반면에 언어 기반 평가는 단순한 정량적 채점 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib371" title="">371</a>, <a class="ltx_ref" href="#bib.bib888" title="">888</a>, <a class="ltx_ref" href="#bib.bib889" title="">889</a>, <a class="ltx_ref" href="#bib.bib890" title="">890</a>]</cite>를 넘어 질적인 설명을 제공하는 비평과 제안 생성에 중점을 둔다. 인간 정렬 튜닝 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib371" title="">371</a>, <a class="ltx_ref" href="#bib.bib888" title="">888</a>]</cite>를 위한 언어 피드백 신호를 수집하는데 특히 유용하다. 또한, LLM 기반 평가자가 태스크 해결사 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib891" title="">891</a>]</cite>에서 기존 솔루션에 자연어 피드백을 제공하는 멀티턴 상호작용 프레임워크로 진화할 수 있다. 이 프레임워크는 LLM이 자체 생성 솔루션을 정제하기 위해 언어 피드백을 활용하는 능력을 평가한다.</p>
</div>
<div id="S8.SS1.SSS7.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS7.p3.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS7.p3.1.1">Evaluation Methods. </span>  LLM 기반 평가의 일반적인 방법은 LLM을 특정 명령어로 프롬프트하는 것이다. LLM 기반 평가의 품질을 더욱 향상시키기 위해 최근 연구에서는 다양한 컨텍스트를 가진 LLM을 촉구하여 다양한 평가 피드백을 생성하는 것을 제안한다. 이러한 컨텍스트는 후보 순서 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>, <a class="ltx_ref" href="#bib.bib647" title="">647</a>]</cite>, 평가 관점 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib892" title="">892</a>, <a class="ltx_ref" href="#bib.bib893" title="">893</a>]</cite>](<em class="ltx_emph ltx_font_italic" id="S8.SS1.SSS7.p3.1.2">e.g.,</em> relevance, clarity, originalality), 평가 설명 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib647" title="">647</a>]</cite> 등의 측면에서 다양하다. 생성된 다중 평가 피드백은 그 후 집계되어 최종 평가 결과를 생성하며, 이는 평가 프로세스가 개별 피드백으로부터 편향되기 덜하게 하고 보다 광범위한 평가 측면을 커버함으로써 보다 철저한 평가를 가능하게 한다. 단일 모델 평가의 품질을 더욱 향상시키기 위해 최근 연구에서는 다중 에이전트 협업 프레임워크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib894" title="">894</a>, <a class="ltx_ref" href="#bib.bib895" title="">895</a>, <a class="ltx_ref" href="#bib.bib893" title="">893</a>]</cite> 또는 LLM을 지정된 평가자 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib371" title="">371</a>, <a class="ltx_ref" href="#bib.bib888" title="">888</a>, <a class="ltx_ref" href="#bib.bib889" title="">889</a>, <a class="ltx_ref" href="#bib.bib890" title="">890</a>, <a class="ltx_ref" href="#bib.bib896" title="">896</a>]</cite>로 미세 조정한다. 다중 모델 협업 모드에서 서로 다른 LLM은 선호도를 정렬하고 합의에 도달하기 위해 토론에 참여하여 후보를 평가한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib894" title="">894</a>, <a class="ltx_ref" href="#bib.bib895" title="">895</a>]</cite> 이 방법은 여러 에이전트에 의해 도달한 합의를 통해 개별 모델의 잠재적 편향을 줄이는 데 도움이 된다. 단일 모델 평가를 개선하기 위한 또 다른 접근법은 미세 조정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib371" title="">371</a>, <a class="ltx_ref" href="#bib.bib888" title="">888</a>, <a class="ltx_ref" href="#bib.bib889" title="">889</a>, <a class="ltx_ref" href="#bib.bib890" title="">890</a>, <a class="ltx_ref" href="#bib.bib896" title="">896</a>]</cite>를 통해 LLM을 점수 또는 비평가로 전문화하는 것이다. 이 프로세스는 인간 또는 능숙한 LLM의 선호도 및 피드백으로 주석이 달린 데이터 세트를 만드는 것을 포함한다. 그런 다음 이러한 데이터 세트는 평가 지향 모델을 훈련하는 데 사용되어 쌍별 선호도 또는 언어 피드백을 생성할 수 있다. 전문화된 LLM 평가자는 더 적은 매개변수 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib889" title="">889</a>, <a class="ltx_ref" href="#bib.bib890" title="">890</a>, <a class="ltx_ref" href="#bib.bib896" title="">896</a>]</cite>로 경쟁 성능을 보여준다.</p>
</div>
<div id="S8.SS1.SSS7.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS7.p4.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS7.p4.1.1">Meta-Evaluation. </span>  LLM 기반 평가자의 품질을 효과적으로 평가하기 위해 인간 선호도와의 일치도 및 LLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>, <a class="ltx_ref" href="#bib.bib647" title="">647</a>, <a class="ltx_ref" href="#bib.bib897" title="">897</a>, <a class="ltx_ref" href="#bib.bib893" title="">893</a>, <a class="ltx_ref" href="#bib.bib898" title="">898</a>]</cite>에 의해 이루어진 평가의 공정성을 측정하기 위한 메타 평가 벤치마크가 도입되었다. 대표적인 벤치마크인 MT-Bench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>]</cite>는 LLM과 인간 판단 간의 일치를 평가하여 GPT-4가 80개의 다중 회전 질문에 대한 노타이 비교에서 인간 선호도와 밀접하게 일치함을 보여준다. 또한 주관적인 인간 평가에서 발생하는 잠재적인 편향을 해결하기 위해 LLMBar<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib897" title="">897</a>]</cite>는 객관적으로 더 나쁘지만 표면적으로는 매력적인 출력을 수동으로 설계하여 평가자를 오도할 수 있다. 평가 결과는 가장 진보된 LLM조차도 여전히 도전적인 환경에서 인간 수준의 평가에 미치지 못한다는 것을 보여준다.</p>
</div>
<div id="S8.SS1.SSS7.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS1.SSS7.p5.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.SSS7.p5.1.1">Remaining Issues. </span>  <a class="ltx_ref" href="#S7.SS1.SSS1" title="7.1.1 Language Generation ‣ 7.1 Basic Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.1.1</span></a> 절에서 논의한 바와 같이, 최근 연구에 따르면 LLM 기반 평가자는 순서 편향, 자기 선호 편향, 길이 편향 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib727" title="">727</a>, <a class="ltx_ref" href="#bib.bib647" title="">647</a>]</cite>와 같은 여러 유형의 편향을 노출한다. 다중 경로 앙상블 또는 다중 에이전트 협업과 같은 방법을 통해 일부 편향을 완화할 수 있지만 LLM 기반 평가자에 고유한 것으로 남아 있다. 결과적으로 모델 내에서 이러한 편향을 본질적으로 해결하는 것은 여전히 어려운 문제이다. 또한 최근 연구에 따르면 LLM은 자체 생성 콘텐츠를 이해할 수 없어 생성 능력<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib899" title="">899</a>]</cite>에 비해 이해 능력이 약할 수 있다. 가장 진보된 LLMs조차도 여전히 외부 피드백 없이 그들의 추론 또는 사실적 오류를 식별하는 데 어려움을 겪고 있다. 따라서 현재의 LLM 기반 평가자는 최상위 LLM 또는 복잡한 작업을 평가하는 데 적합하지 않을 수 있다. 이는 특히 능력 있는 LLM과 정교한 추론, 계획 및 영역별 지식을 요구하는 복잡한 작업을 평가하기 위해 LLM 기반 평가자를 위한 개선 접근법의 중요성을 강조한다.</p>
</div>
</section>
</section>
<section id="S8.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2 </span><span id="S8.SS2.1.1" class="ltx_text ltx_font_italic">LLM for Specific Domains</span>
</h3>

<div id="S8.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS2.p1.1">이 부분에서 우리는 의료, 교육, 법률, 재정 및 과학 연구 지원을 포함한 몇 가지 대표적인 도메인에 대한 LLM의 적용에 대해 논의한다.</p>
</div>
<div id="S8.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S8.SS2.p2.1.1">Healthcare</span>은 인간의 생명과 밀접한 관련이 있는 중요한 응용 분야이다. ChatGPT가 등장한 이후 많은 연구에서 ChatGPT 또는 기타 LLM을 의료 영역에 적용했다. LLM은 다양한 의료 업무를 처리할 수 있는 것으로 나타났다. <em class="ltx_emph ltx_font_italic" id="S8.SS2.p2.1.2">e.g.,</em> 생물 정보 추출</cite idx=0></cite>, 의료 조언 상담</cite idx=1></cite>, 정신 건강 분석</cite></cite>, 보고서 단순화</cite idx=3></cite>. 주요 기술적 접근법으로 연구자들은 일반적으로 광범위한 의료 업무를 수행하도록 LLM을 안내하는 특정 프롬프트 또는 지침을 설계한다. 의료 영역에서 LLM의 힘을 더 활용하기 위해 연구자들은 의료 관련 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib356" title="">356</a>, <a class="ltx_ref" href="#bib.bib905" title="">905</a>, <a class="ltx_ref" href="#bib.bib906" title="">906</a>]</cite>를 개발할 것을 제안한다. 특히 Med-PaLM 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib356" title="">356</a>, <a class="ltx_ref" href="#bib.bib905" title="">905</a>]</cite>는 미국 의료 면허 시험(USMLE)에서 전문가 수준의 성능을 달성하고 소비자의 의료 질문에 대한 의사로부터 더 큰 승인을 받는다. 그러나 LLMs은 의료 잘못된 정보 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib904" title="">904</a>, <a class="ltx_ref" href="#bib.bib907" title="">907</a>]</cite>, <em class="ltx_emph ltx_font_italic" id="S8.SS2.p2.1.3">e.g.,</em> 의료 용어를 잘못 해석하고 의료 지침과 일치하지 않는 조언을 제안할 수 있다. 또한, 환자의 건강 정보를 LLM을 지원하는 상용 서버에 업로드하기 위한 프라이버시 우려도 제기될 것이다.</p>
</div>
<div id="S8.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S8.SS2.p3.1.1">Education</span>은 LLM이 잠재적으로 상당한 영향을 미치는 중요한 애플리케이션 도메인이기도 합니다. 기존의 연구는 LLMs이 객관식 문제와 자유응답 문제 모두에서 다양한 수학 과목(<em class="ltx_emph ltx_font_italic" id="S8.SS2.p3.1.2">e.g.,</em> physics, computer science)에서 표준화된 테스트에서 학생 수준의 성능을 달성할 수 있음을 발견했다. 또한, LLMs이 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib908" title="">908</a>, <a class="ltx_ref" href="#bib.bib909" title="">909</a>]</cite> 교육을 위한 글쓰기 또는 읽기 보조 역할을 할 수 있다는 실증적 연구 결과도 있다. 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib909" title="">909</a>]</cite>는 ChatGPT가 학문 전반에 걸쳐 논리적으로 일관된 답변을 생성할 수 있으며 깊이와 넓이의 균형을 맞출 수 있음을 보여준다. 또 다른 정량적 분석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib908" title="">908</a>]</cite>는 ChatGPT를 사용하는 학생들(LLM의 결과를 자신의 답변으로 유지하거나 정제하는 것)이 컴퓨터 보안 분야의 일부 과목에서 일반 학생들보다 더 나은 성능을 발휘한다는 것을 보여준다. 최근 여러 관점논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib910" title="">910</a>, <a class="ltx_ref" href="#bib.bib911" title="">911</a>]</cite>에서도 교사-학생 협업, 개인 맞춤형 학습, 평가 자동화 등 교실 수업에서 LLM의 다양한 적용 시나리오를 탐색하고 있다. 그러나 교육에서 LLM의 적용은 일련의 실제적인 문제로 이어질 수 있다. <em class="ltx_emph ltx_font_italic" id="S8.SS2.p3.1.3">e.g.,</em> 표절, AI 생성 콘텐츠의 잠재적 편향, LLMs에 대한 과도한 의존, 비영어권 개인에 대한 불공평한 액세스 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib912" title="">912</a>]</cite>.</p>
</div>
<div id="S8.SS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S8.SS2.p4.1.1">Law</span>은 전문 도메인 지식을 기반으로 하는 전문 도메인입니다. 최근 많은 연구들이 다양한 법적 과제, <em class="ltx_emph ltx_font_italic" id="S8.SS2.p4.1.2">e.g.,</em> 법률 문서 분석</cite idx=0></cite>, 법률 판단 예측</cite idx=1></cite>, 법률 문서 작성</cite idx=2></cite>를 해결하기 위해 LLM을 적용하고 있다. 최근 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib916" title="">916</a>]</cite>에 따르면 LLMs는 법적 해석과 추론의 강력한 능력을 나타낸다. 또한, 최신 GPT-4 모델은 모의 변호사 시험에서 인간 수험생 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>와 비교하여 상위 10%의 점수를 달성한다. 법률 영역에서 LLM의 성능을 더욱 향상시키기 위해 특별히 설계된 법률 프롬프트 엔지니어링을 사용하여 긴 법률 문서 이해 및 복잡한 법률 추론 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib917" title="">917</a>, <a class="ltx_ref" href="#bib.bib918" title="">918</a>]</cite>에서 향상된 성능을 산출한다. 진행 상황을 요약하자면, LLM은 법률 직업에 도움이 되는 보조자 역할을 할 수 있다. 진행에도 불구하고 법률에서 LLMs을 사용하는 것은 저작권 문제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib919" title="">919</a>]</cite>, 개인정보 유출 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib920" title="">920</a>]</cite>, 또는 편견과 차별 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib921" title="">921</a>]</cite> 등 법적 난제에 대한 우려를 낳고 있다.</p>
</div>
<div id="S8.SS2.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S8.SS2.p5.1.1">Finance</span>은 LLMs가 유망한 애플리케이션 전망을 갖는 중요한 필드이다. LLM은 수치 클레임 탐지 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib922" title="">922</a>]</cite>, 금융 감정 분석 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib923" title="">923</a>]</cite>, 금융 명명 개체 인식 [<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib924" title="">924</a>]</cite>, 금융 추론 [cite idx=3></cite>]와 같은 다양한 금융 관련 작업에 사용되었다. 재무 작업에서 범용 LLM이 나타내는 경쟁적인 제로 샷 성능에도 불구하고, 그들은 여전히 백만 개의 스케일 매개변수 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib922" title="">922</a>]</cite>를 포함하는 도메인별 PLM을 저성능화한다. LLM의 스케일링 효과를 활용하기 위해 연구자들은 LLM을 지속적으로 사전 훈련하기 위해 대규모 금융 코퍼라(<em class="ltx_emph ltx_font_italic" id="S8.SS2.p5.1.2">e.g.,</em> BloombergGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib360" title="">360</a>]</cite>, XuanYuan 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib926" title="">926</a>]</cite>, FinGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib927" title="">927</a>]</cite>)를 수집한다. BloombergGPT는 범용 태스크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib360" title="">360</a>]</cite>에서 경쟁 성능을 유지하면서 다양한 금융 태스크에 걸쳐 놀라운 성능을 보여주었다. 그럼에도 불구하고 LLM에 의한 부정확하거나 유해한 콘텐츠의 생성은 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib360" title="">360</a>]</cite> 금융 시장에 상당한 부정적인 영향을 미칠 수 있기 때문에 금융에서 LLM 적용의 잠재적 위험을 고려하는 것이 필수적이다. 따라서 금융 분야에서 LLM의 사용에 대한 보다 엄격한 검토와 모니터링이 필요하다.</p>
</div>
<div id="S8.SS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S8.SS2.p6.1.1">Scientific research</span>은 LLMs가 개발 진행에 권한을 부여할 수 있는 또 다른 유망한 분야이다. 선행 연구는 지식 집약적 과학 과제(<em class="ltx_emph ltx_font_italic" id="S8.SS2.p6.1.2">e.g.,</em> PubMedQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib928" title="">928</a>]</cite>, BioASQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib929" title="">929</a>]</cite>), 특히 과학 관련 코퍼라 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>, <a class="ltx_ref" href="#bib.bib203" title="">203</a>, <a class="ltx_ref" href="#bib.bib930" title="">930</a>]</cite>에서 훈련된 LLMs에 대한 LLMs의 효율성을 보여준다. 뛰어난 일반 능력과 광범위한 과학적 지식을 감안할 때 LLM은 과학 연구 파이프라인의 다양한 단계에 걸쳐 유용한 보조자로서 상당한 잠재력을 가지고 있다. 먼저 문헌 조사 단계에서 LLMs은 특정 연구 분야 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib932" title="">932</a>, <a class="ltx_ref" href="#bib.bib933" title="">933</a>]</cite>의 진행 상황을 종합적으로 개관하는 데 도움을 줄 수 있다. 둘째, 연구 아이디어 생성 단계에서 LLMs은 흥미로운 과학적 가설 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib934" title="">934</a>]</cite>를 생성하는 능력을 보여준다. 셋째, 데이터 분석 단계에서 LLMs을 사용하여 데이터 탐색, 시각화 및 분석 결론 도출을 포함한 데이터 특성을 분석하는 자동 접근법을 수행할 수 있다. 넷째, 논문 쓰기 단계에서 연구자는 기존의 내용을 요약하고 쓰기 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib939" title="">939</a>]</cite>를 연마하는 등 다양한 수단을 통해 과학 글쓰기에 귀중한 지원을 제공할 수 있는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib937" title="">937</a>, <a class="ltx_ref" href="#bib.bib938" title="">938</a>]</cite>에서도 LLM의 도움을 받을 수 있다. 또한 LLMs은 오류 탐지, 체크리스트 검증, 후보 순위 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib940" title="">940</a>]</cite> 등의 작업을 포괄하여 자동화된 논문 검토 프로세스를 지원할 수 있다. 이러한 발전에도 불구하고 LLM이 생성된 과학 콘텐츠의 품질을 높이고 유해한 환각을 줄이는 데 도움이 되고 신뢰할 수 있는 과학 조수 역할을 할 수 있는 능력을 향상시킬 여지가 많다.</p>
</div>
<div id="S8.SS2.p7" class="ltx_para">
<p class="ltx_p" id="S8.SS2.p7.1"><em class="ltx_emph ltx_font_italic" id="S8.SS2.p7.1.1">Summary</em>. 앞서 언급한 작업 외에도 LLM의 응용 프로그램은 여러 다른 도메인에서도 논의되었다. 예를 들어, 심리학 영역에서 최근 연구는 자기 인식, 정신 이론(ToM) 및 정의적 컴퓨팅 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib941" title="">941</a>, <a class="ltx_ref" href="#bib.bib942" title="">942</a>]</cite>와 같은 LLM의 인간 유사 특성을 연구했다. 특히, GPT-3.5 시리즈의 모델이 ToM 태스크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib941" title="">941</a>]</cite>에서 9세 아동과 유사한 성능을 달성하기 때문에 두 가지 고전적인 거짓 신뢰 태스크에 대해 수행된 ToM에 대한 경험적 평가는 LLM이 ToM 유사 능력을 가질 수 있다고 추측한다. 또한, LLMs을 소프트웨어 개발 도메인인 <em class="ltx_emph ltx_font_italic" id="S8.SS2.p7.1.2">e.g.,</em> code suggestion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib943" title="">943</a>]</cite>, code summary <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib944" title="">944</a>]</cite>, automated program repair <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib945" title="">945</a>]</cite>에 적용하는 것을 또 다른 작업으로 조사하였다. 요약하자면, 실제 작업에서 LLM에 의해 인간을 돕는 것은 중요한 연구 영역이 되었다. 그러나, 그것은 또한 도전 과제들을 제시한다. LLM 생성 콘텐츠의 정확성을 보장하고 편향을 해결하며 사용자 개인 정보 보호 및 데이터 보안을 유지하는 것은 LLM을 실제 시나리오에 적용할 때 중요한 고려 사항이다.</p>
</div>
</section>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span><span id="S9.1.1" class="ltx_text ltx_font_smallcaps">Conclusion and Future Directions</span>
</h2>

<div id="S9.p1" class="ltx_para">
<p class="ltx_p" id="S9.p1.1">본 연구에서는 대형 언어모델(LLM)의 최근 동향을 살펴보고, LLM의 이해와 활용을 위한 주요 개념, 연구 결과 및 기법을 소개하였다. 기존 문헌에서 잘 다루어진 초기 사전 훈련 언어 모델(<em class="ltx_emph ltx_font_italic" id="S9.p1.1.1">i.e.,</em> a size than 10B)의 내용은 제외하면서, 대형 모델(<em class="ltx_emph ltx_font_italic" id="S9.p1.1.2">e.g.,</em> BERT and GPT-2)에 초점을 맞춘다. 특히, 우리는 LLMs의 네 가지 중요한 측면인 <em class="ltx_emph ltx_font_italic" id="S9.p1.1.3">i.e.,</em> 사전 훈련, 적응, 활용 및 평가에 대해 논의했다. 각 측면에 대해 LLM의 성공에 핵심이 되는 기술이나 결과를 강조한다. 또한 LLMs 개발을 위한 가용 자원을 요약하고 LLMs 재생을 위한 중요한 구현 지침에 대해 논의한다. 이 조사는 LLMs에 대한 가장 최근의 문헌을 다루려고 하며 연구자와 엔지니어 모두에게 이 주제에 대한 좋은 참조 자료를 제공한다.</p>
</div>
<div id="S9.p2" class="ltx_para">
<p class="ltx_p" id="S9.p2.1">다음으로, 본 조사의 논의를 요약하고 LLM에 대한 도전과제와 향후 방향을 다음과 같은 측면에서 소개한다.</p>
</div>
<div id="S9.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S9.p3.1"><span class="ltx_text ltx_font_bold" id="S9.p3.1.1">Basics and Principles. </span> 특정 과제 목표에 대한 훈련 대신 LLMs은 대규모 텍스트 데이터에 대한 감독되지 않은 사전 훈련으로부터 학습한다. 이것은 충분한 일반화를 달성하기 위해 훈련 과제를 가능한 한 확장하는 것을 목표로 하는 이전의 다중 작업 학습 접근법과는 상당히 다르다. 따라서 LLM의 능력의 기초를 확립하는 기본 원칙이나 요소를 밝히는 것이 필수적이다. 언어 모델의 기본 아이디어는 직관적이지만, 간단한 언어 모델링 목표(<em class="ltx_emph ltx_font_italic" id="S9.p3.1.2">e.g.,</em> next token prediction)에 의해 트레이닝된 LLM이 다양한 실제 태스크를 해결할 수 있게 될 수 있는 이유를 공식적으로 설명하는 것은 여전히 어렵다. 이 문제를 조사하기 위해, LLM의 모델 용량은 사전 훈련 데이터에 크게 의존하기 때문에, 비지도 사전 훈련에 기초한 용량 학습(또는 선택) 메커니즘을 연구하는 유망한 접근법이 있다. 또한, <em class="ltx_emph ltx_font_italic" id="S9.p3.1.3">scaling</em>은 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib31" title="">31</a>, <a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>의 용량을 향상시키는 데 중요한 역할을 하며, 대형 모델의 행동이 소형 모델의 행동과 어떻게 관련되는지, <em class="ltx_emph ltx_font_italic" id="S9.p3.1.4">e.g.,</em> 대형 모델의 행동은 소형 모델로부터 추론할 수 있고 실제로 예측할 수 없는 것에 대해 보다 이론적인 분석을 수행하는 것이 매우 유용하다. 또 다른 연구 방향은 LLM이 사전 훈련 데이터에 의해 인코딩된 지식을 넘어 일반화될 수 있는지에 대한 우려가 제기되었기 때문에 LLM에 대한 모델 일반화에 대한 보다 심층적인 분석을 탐구하는 것이다. 또한, 데이터 오염은 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib738" title="">738</a>]</cite>의 성능을 공정하게 평가하는데 심각한 문제가 되었으며, 따라서 적절한 평가 프로토콜을 설정하는 것은 LLMs의 모델 용량을 조사하고 분석하는 기초가 될 것이다.</p>
</div>
<div id="S9.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S9.p4.1"><span class="ltx_text ltx_font_bold" id="S9.p4.1.1">Model Architecture. </span> 확장성과 효과성으로 인해 Transformer는 LLM을 구축하기 위한 사실상의 아키텍처가 되었다. 신경망 구성 및 확장 가능한 병렬 훈련과 같은 이 아키텍처의 성능을 개선하기 위한 다양한 전략이 제안되었다(섹션<a class="ltx_ref" href="#S4.SS2.SSS2" title="4.2.2 Detailed Configuration ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.2</span></a>의 논의 참조). 그러나 트랜스포머는 여전히 높은 훈련 비용과 느린 추론 속도로 인해 어려움을 겪고 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib251" title="">251</a>, <a class="ltx_ref" href="#bib.bib252" title="">252</a>]</cite>는 대규모 사전 훈련을 위한 개선된 모델 아키텍처를 개발하기 위해 여전히 더 많은 노력이 필요하다. 특히 시스템 수준 또는 하드웨어 수준 최적화(<em class="ltx_emph ltx_font_italic" id="S9.p4.1.2">e.g.,</em> FlashAttention <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib284" title="">284</a>]</cite>)는 Transformer 아키텍처의 효율성을 향상시키기 위해 더 많은 탐색의 가치가 있다. 또한, 중요한 기본 용량으로서, 기존의 LLM들은 통상적으로 긴 컨텍스트 윈도우를 유지한다. 예를 들어, 가장 최근의 GPT-4 Turbo는 128K 토큰의 긴 컨텍스트를 가능하게 하고, Claude 2.1도 최대 200K 토큰의 입력을 지원한다. LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib291" title="">291</a>, <a class="ltx_ref" href="#bib.bib264" title="">264</a>]</cite>의 긴 컨텍스트 모델링 능력을 향상시키기 위한 많은 노력이 있었지만, 결과 모델들은 여전히 컨텍스트 창 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib299" title="">299</a>]</cite>에서 정보를 잘 처리하지 못한다. 이 문제를 해결하기 위해서는 긴 컨텍스트 정보의 모델링 및 활용을 향상시키기 위한 특정 아키텍처 적응 또는 알고리즘이 필요할 수 있다. 또 다른 우려되는 것은 기존 작업이 대부분 디코더 전용 트랜스포머로 LLM을 훈련하는 데 초점을 맞추고 있다는 것이다. 효과성에도 불구하고 대체 모델 아키텍처에 대한 보다 광범위하고 다양한 탐색을 심각하게 제한한다.</p>
</div>
<div id="S9.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S9.p5.1"><span class="ltx_text ltx_font_bold" id="S9.p5.1.1">Model Training. </span> 사전 학습을 위해서는 데이터 수집, 데이터 청소, 데이터 혼합, 데이터 커리큘럼의 체계적인 프로세스를 효과적으로 지원할 수 있는 LLM 최적화를 위한 데이터 중심 인프라 및 교육 절차 수립이 필수적이다. 또한 컴퓨팅 클러스터에서 리소스를 더 잘 구성하고 활용할 수 있도록 하드웨어 지원 또는 리소스 스케줄의 유연한 메커니즘을 요구합니다. 실제로는 컴퓨팅 소모가 크고 데이터 품질에 대한 민감도와 훈련 트릭 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>, <a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>로 인해 사전 훈련 가능한 LLM이 매우 어렵다. 따라서, LLMs, <em class="ltx_emph ltx_font_italic" id="S9.p5.1.2">e.g.,</em> predictable scaling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite> and proxy model training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite>를 최적화하기 위한 체계적이고 경제적인 사전 훈련 접근법을 개발하는 것이 특히 중요해진다. 대규모 모델 최적화에서 열화 또는 실패의 잠재적 위험을 줄이기 위해 더 많은 훈련 레시피 또는 원칙을 조사하고 공유해야 한다. 점점 더 많은 모델 체크포인트 및 세정된 데이터 세트가 출시되었지만, 사전 트레이닝 데이터 준비(<em class="ltx_emph ltx_font_italic" id="S9.p5.1.3">e.g.,</em> 상세 클리닝 전략) 및 데이터 스케줄링(<em class="ltx_emph ltx_font_italic" id="S9.p5.1.4">e.g.,</em> 데이터 혼합 및 커리큘럼)에 대한 재현 가능한 작업은 여전히 부족하다. LLM을 처음부터 사전 훈련하는 것은 매우 비용이 많이 들기 때문에 공개적으로 사용 가능한 모델 체크포인트를 기반으로 LLM을 지속적으로 사전 훈련하거나 미세 조정하기 위한 적합한 메커니즘을 설계하는 것이 중요하다(<em class="ltx_emph ltx_font_italic" id="S9.p5.1.5">e.g.,</em> LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite> and Flan-T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>). 이를 위해 여러 기술적 문제가 해결되어야 합니다. <em class="ltx_emph ltx_font_italic" id="S9.p5.1.6">e.g.,</em> catastrophic forgetting and task specialization. 또한 특정 지식을 효과적으로 주입하거나 편집하는 효과적인 튜닝 전략을 개발하는 것도 유용하다.</p>
</div>
<div id="S9.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S9.p6.1"><span class="ltx_text ltx_font_bold" id="S9.p6.1.1">Model Utilization. </span> 자연어 인터페이스를 기반으로 <em class="ltx_emph ltx_font_italic" id="S9.p6.1.2">prompting</em>은 다양한 작업을 해결하는 데 LLMs를 사용하기 위한 두드러진 접근법이 되었습니다. 태스크 설명 및 데모 예시를 프롬프트에 결합함으로써, 인-컨텍스트 학습(ICL)은 LLM들이 새로운 태스크들에 대해 잘 수행할 수 있는 능력을 부여하며, 심지어 경우에 따라 풀-데이터 미세 조정 모델들을 능가한다. 복잡한 추론의 능력을 향상시키기 위해 중간 추론 단계를 프롬프트로 포함하는 CoT(Chain-of-thought) 전략을 예로 들어 고급 프롬프트 기법이 제안되었다. 또한, 계획은 복잡한 작업을 해결하기 위한 유망한 접근법이며, 도구 사용 용량을 활용하여 LLM을 반복적으로 호출한다. 이러한 노력에도 불구하고, 프롬프트와 관련된 몇 가지 기본적인 문제들은 여전히 탐구되지 않고 있다: 좋은 프롬프트가 정답을 이끌어낼 수 있지만 나쁜 프롬프트는 이끌어낼 수 없는 이유, 고급 프롬프트 방법(<em class="ltx_emph ltx_font_italic" id="S9.p6.1.3">e.g.,</em> ICL 및 CoT)의 작동 원리를 밝히고 이러한 기존 접근 방식을 더욱 개선하고 특정 태스크에서 LLMs에 대한 효과적인 프롬프트를 효율적으로 찾는 방법. 더욱이, 실용적인 관점에서, 특히 대규모 배치에서 LLM의 추론 비용을 줄이는 것은 근본적인 과제가 되었다. 또 다른 인기 있는 연구 방향은 검색 증강 생성으로, 지원 소스에서 검색된 컨텍스트가 과제 해결을 위한 프롬프트에 포함된다. 검색 증강은 지식 경계를 확장하고 질의 응답 능력을 향상시킬 수 있지만 LLMs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib299" title="">299</a>]</cite>에 의한 긴 컨텍스트 활용의 효율성에 어려움을 겪을 수 있음을 보였다.</p>
</div>
<div id="S9.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S9.p7.1"><span class="ltx_text ltx_font_bold" id="S9.p7.1.1">Safety and Alignment. </span> 용량에도 불구하고 LLM은 실제 사용 시 큰 안전 문제에 직면해 있다. 확률적 모델링 성격의 근본적인 문제로서 LLMs은 그럴듯해 보이지만 사실적으로 부정확할 수 있는 텍스트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>를 참조하여 환각 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib638" title="">638</a>]</cite>를 생성하는 경향을 보인다. 더 나쁜 것은 LLMs가 악의적인 시스템에 대한 유해, 편향 또는 독성 텍스트를 생성하도록 의도적인 지침에 의해 유발되어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>, <a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite> 오용의 잠재적 위험을 초래할 수 있다는 것이다. LLM의 안전 문제에 대한 자세한 논의를 위해(<em class="ltx_emph ltx_font_italic" id="S9.p7.1.2">e.g.,</em> privacy, overreliance, disinformation, influence operations) 독자는 GPT-3/4 기술 보고서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>, <a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>를 참조할 수 있다. 이러한 문제를 해결하기 위한 주요 기술적 접근 방법으로 정렬 방법(<em class="ltx_emph ltx_font_italic" id="S9.p7.1.3">e.g.,</em>RLHF) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>는 잘 정렬된 LLMs 개발을 위해 인간 피드백을 활용하여 널리 사용되었다. 그러나 RLHF는 전문 레이블러의 고품질 인간 피드백 데이터에 크게 의존하며, 이는 자격을 갖춘 인간 주석자를 모집하는 데 비용과 시간이 많이 소요된다. 따라서 인간 레이블러의 노력을 줄이기 위한 RLHF 프레임워크를 개선하고 데이터 품질이 보장된 보다 효율적인 주석 접근법을 모색해야 하며, <em class="ltx_emph ltx_font_italic" id="S9.p7.1.4">e.g.,</em> LLM을 사용하여 레이블링 작업을 지원할 수 있다. 또한, RLHF의 훈련 난이도 및 불안정성을 줄이기 위해 정렬 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib389" title="">389</a>, <a class="ltx_ref" href="#bib.bib386" title="">386</a>]</cite>에 대한 간략화된 최적화 알고리즘을 개발할 것을 제안한다. 또 다른 실용적인 접근법으로, 적색 학습 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib132" title="">132</a>, <a class="ltx_ref" href="#bib.bib369" title="">369</a>]</cite>는 LLM의 모델 안전성을 향상시키기 위해 채택되었으며, 이는 수집된 적대적 프롬프트를 활용하여 LLM을 개선한다(<em class="ltx_emph ltx_font_italic" id="S9.p7.1.5">i.e.,</em> avoid the attacks from red teaming). 또한 도메인별 데이터로 LLM을 미세 조정할 때 개인 정보 보호 문제도 고려해야 하므로 연합 기반 학습 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib946" title="">946</a>]</cite>는 개인 정보 보호 제한 시나리오에서 유용할 수 있다.</p>
</div>
<div id="S9.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S9.p8.1"><span class="ltx_text ltx_font_bold" id="S9.p8.1.1">Application and Ecosystem. </span> LLMs은 다양한 태스크를 해결하는 데 강력한 능력을 보여주었기 때문에 광범위한 실제 애플리케이션에서 적용될 수 있다(<em class="ltx_emph ltx_font_italic" id="S9.p8.1.2">i.e.,</em> 다음 태스크별 자연어 명령어). 놀라운 진전으로 ChatGPT는 인간이 정보에 액세스하는 방식을 잠재적으로 변경했으며, 이는 <em class="ltx_emph ltx_font_italic" id="S9.p8.1.3">New Bing</em>의 릴리스에 추가로 통합되었습니다. 일반적으로 가까운 미래에는 LLM이 검색 엔진과 추천 시스템을 포함한 정보 검색 기술에 상당한 영향을 미칠 것으로 예측할 수 있다. 또한, LLM은 실제 시나리오에서 다양한 복잡한 작업을 다루기 위해 보다 지능적인 시스템(<em class="ltx_emph ltx_font_italic" id="S9.p8.1.4">e.g.,</em> 자율 AI 에이전트)을 개발하는 것을 가능하게 한다. 특히, Assistants API는 OpenAI(명령어, 지식 및 도구 사용 기능)에 의해 출시되어 애플리케이션 내에서 에이전트와 유사한 어시스턴트를 빠르게 개발할 수 있다. 이러한 기술 혁신의 물결은 LLM으로 구동되는 애플리케이션(<em class="ltx_emph ltx_font_italic" id="S9.p8.1.5">e.g.,</em> OpenAI’s GPT Store)의 생태계로 이어질 것이며, 이는 인간의 삶과 밀접한 관련이 있다. 마지막으로 LLMs의 부상은 인공지능(AGI)의 탐구를 조명한다. 어느 때보다 스마트 AI 시스템 개발이 유망하다. 그러나 이 개발 과정에서 AI 안전은 주요 관심사 중 하나여야 하며, <em class="ltx_emph ltx_font_italic" id="S9.p8.1.6">i.e.,</em> AI를 인간에 대해 좋으나 나쁘지 않게 만드는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib40" title="">40</a>]</cite>이다.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Coda</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.p1.1">이 긴 설문 조사를 작성하고 시기적절한 작업으로 내용을 업데이트하는 것은 쉬운 일이 아니다. 먼저 독자와 저희 팀원들의 성원에 진심으로 감사드립니다. 우리는 이 조사에 매우 열심히 노력하며 그것이 LLM에 대한 포괄적이고 시기적절한 참조를 제시할 수 있기를 바란다.</p>
</div>
<div id="Sx1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx1.p2.1"><span class="ltx_text ltx_font_bold" id="Sx1.p2.1.1">Survey Writing</span>. 이 조사는 우리 연구팀이 개최한 토론회에서 계획되었으며, 최근 대규모 언어 모델의 발전을 팀 구성원에게 매우 읽기 쉬운 보고서로 요약하는 것을 목표로 했다. 첫 번째 초안은 2023년 3월 13일에 완료되었으며, 우리 팀원들은 LLM에 대한 관련 연구를 비교적 객관적이고 포괄적인 방식으로 포함하도록 최선을 다했다. 그런 다음 몇 번의 패스로 글과 내용을 광범위하게 수정했습니다. 공간 한계로 인해 선택 기준을 설정하면 그림 <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>와 표 <a class="ltx_ref" href="#S2.T1" title="TABLE I ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">I</span></a>에서 기존 LLM의 일부만 포함할 수 있다. 그러나 정기적으로 유지되는 GitHub 페이지(<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/RUCAIBox/LLMSurvey" target="_blank" title="">https://github.com/RUCAIBox/LLMSurvey</a>)에서 모델 선택에 대한 보다 완화된 기준을 설정했습니다. 2023년 3월 31일 초판, 2023년 6월 29일 대판, 2023년 9월 10일 2판, 2023년 11월 23일 이 최신판(대판)을 발표한다.</p>
</div>
<div id="Sx1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx1.p3.1"><span class="ltx_text ltx_font_bold" id="Sx1.p3.1.1">Seeking for Advice</span>. 우리의 모든 노력에도 불구하고, 이 조사는 여전히 완벽과는 거리가 멀다: 우리는 중요한 참고 자료나 주제를 놓칠 가능성이 있고, 또한 비강조적인 표현이나 토론을 할 수도 있다. 이번 설문조사는 지속적으로 업데이트하여 최대한 품질을 향상시키도록 하겠습니다. 우리에게 설문 작성은 LLMs에 대한 학습 과정이기도 합니다. 이 설문 조사를 개선하기 위한 건설적인 제안이 있는 독자의 경우 설문 조사의 깃허브 페이지에 의견을 남기거나 작성자에게 직접 이메일을 보낼 수 있습니다. 향후 버전에서 받은 의견이나 제안에 따라 수정하고, 설문조사에서 건설적인 제안에 기여한 독자들에게 인정한다.</p>
</div>
<div id="Sx1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx1.p4.1"><span class="ltx_text ltx_font_bold" id="Sx1.p4.1.1">Update log</span>. 이 부분에서는 arXiv에 대한 이 설문 조사의 제출에 대한 업데이트 로그를 정기적으로 유지한다.</p>
<ul id="Sx1.I1" class="ltx_itemize">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i1.p1.1">2023년 3월 31일 첫 발매: 초기 버전.</p>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i2.p1.1">2023년 4월 9일 업데이트: 소속 정보를 추가하고 그림 <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> 및 표 <a class="ltx_ref" href="#S2.T1" title="TABLE I ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">I</span></a>를 수정하고 LLMs에 대한 해당 선택 기준을 명확히 하고 쓰기를 개선하며 약간의 오류를 수정한다.</p>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i3.p1.1">2023년 4월 11일 업데이트: 라이브러리 리소스의 오류를 수정합니다.</p>
</div>
</li>
<li id="Sx1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i4.p1.1">2023년 4월 12일 업데이트: Figure <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> 및 Table <a class="ltx_ref" href="#S2.T1" title="TABLE I ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">I</span></a>를 수정하고 LLMs의 출시일을 명확히 한다.</p>
</div>
</li>
<li id="Sx1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i5.p1.1">2023년 4월 16일 업데이트: GPT 시리즈 모델의 기술적 진화에 대한 새로운 섹션 <a class="ltx_ref" href="#S2.SS2" title="2.2 Technical Evolution of GPT-series Models ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">2.2</span></a>를 추가하세요.</p>
</div>
</li>
<li id="Sx1.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i6.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i6.p1.1">2023년 4월 24일 업데이트: 스케일링 법칙에 대한 논의를 추가하고 창발 능력에 대한 모델 크기에 대한 설명을 추가합니다(섹션 <a class="ltx_ref" href="#S2.SS1" title="2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">2.1</span></a>); 그림 <a class="ltx_ref" href="#S4.F9" title="Figure 9 ‣ 4.2.1 Typical Architectures ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">9</span></a>의 다른 아키텍처에 대한 주의 패턴에 대한 예시적인 그림을 추가하고 표 <a class="ltx_ref" href="#S4.T6" title="TABLE VI ‣ 4.2.2 Detailed Configuration ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">VI</span></a>의 세부 공식을 추가합니다.</p>
</div>
</li>
<li id="Sx1.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i7.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i7.p1.1">2023년 4월 25일 업데이트: 수치와 표의 일부 복사 오류를 수정합니다.</p>
</div>
</li>
<li id="Sx1.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i8.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i8.p1.1">2023년 4월 27일 업데이트: Section <a class="ltx_ref" href="#S5.SS3" title="5.3 Parameter-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.3</span></a>에서 효율적인 튜닝을 추가합니다.</p>
</div>
</li>
<li id="Sx1.I1.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i9.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i9.p1.1">2023년 4월 28일 업데이트: 개정 섹션 <a class="ltx_ref" href="#S5.SS3" title="5.3 Parameter-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.3</span></a>.</p>
</div>
</li>
<li id="Sx1.I1.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i10.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i10.p1.1">2023년 5월 7일 업데이트: 수정 표 <a class="ltx_ref" href="#S2.T1" title="TABLE I ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">I</span></a>, 표 <a class="ltx_ref" href="#S3.T2" title="TABLE II ‣ 3.1 Publicly Available Model Checkpoints or APIs ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">II</span></a>, 및 일부 부점.</p>
</div>
</li>
<li id="Sx1.I1.i11" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i11.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i11.p1.1">2023년 6월 29일 업데이트(주요 개정):</p>
<ul id="Sx1.I1.i11.I1" class="ltx_itemize">
<li id="Sx1.I1.i11.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i11.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i11.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i11.I1.i1.p1.1">section <a class="ltx_ref" href="#S1" title="1 Introduction ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>: add Figure <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> for published LLM papers in arXiv;</p>
</div>
</li>
<li id="Sx1.I1.i11.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i11.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i11.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i11.I1.i2.p1.1">Section <a class="ltx_ref" href="#S2" title="2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>: GPT의 진화 및 이에 대응하는 논의를 위해 Figure <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>를 추가한다;</p>
</div>
</li>
<li id="Sx1.I1.i11.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i11.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i11.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i11.I1.i3.p1.1">Section <a class="ltx_ref" href="#S3" title="3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>: LLaMA 패밀리 및 해당 논의를 위한 Figure <a class="ltx_ref" href="#S2.F5" title="Figure 5 ‣ 2.2 Technical Evolution of GPT-series Models ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a> 추가;</p>
</div>
</li>
<li id="Sx1.I1.i11.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i11.I1.i4.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i11.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i11.I1.i4.p1.1">섹션 <a class="ltx_ref" href="#S5" title="5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>: 섹션 <a class="ltx_ref" href="#S5.SS1.SSS1" title="5.1.1 Formatted Instance Construction ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1.1</span></a>에서의 명령어 튜닝의 합성 데이터 포맷팅에 대한 최신 논의를 추가하고, 섹션 <a class="ltx_ref" href="#S5.SS1.SSS4" title="5.1.4 Empirical Analysis for Instruction Tuning ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1.4</span></a>에서의 명령어 튜닝에 대한 경험적 분석, 섹션 <a class="ltx_ref" href="#S5.SS3" title="5.3 Parameter-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.3</span></a>에서의 파라미터-효율 모델 적응 및 섹션 <a class="ltx_ref" href="#S5.SS4" title="5.4 Memory-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.4</span></a>에서의 메모리-효율 적응;</p>
</div>
</li>
<li id="Sx1.I1.i11.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i11.I1.i5.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i11.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i11.I1.i5.p1.1">Section <a class="ltx_ref" href="#S6" title="6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>: ICL <a class="ltx_ref" href="#S6.SS2.SSS3" title="6.2.3 Underlying Mechanism ‣ 6.2 In-Context Learning ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.2.3</span></a>의 기본 메커니즘에 대한 최신 논의를 추가하고, Section <a class="ltx_ref" href="#S6.SS4" title="6.4 Planning for Complex Task Solving ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.4</span></a>에서 복잡한 과제 해결을 위한 계획을 세우는 단계;</p>
</div>
</li>
<li id="Sx1.I1.i11.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i11.I1.i6.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i11.I1.i6.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i11.I1.i6.p1.1">LLM의 고급 능력을 평가하기 위한 대표적인 데이터 세트에 대한 섹션 <a class="ltx_ref" href="#S7" title="7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>: 업데이트 테이블 <a class="ltx_ref" href="#S7.T14" title="TABLE XIV ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XIV</span></a> 및 섹션 <a class="ltx_ref" href="#S7.SS4" title="7.4 Empirical Evaluation ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.4</span></a>에서의 경험적 능력 평가;</p>
</div>
</li>
<li id="Sx1.I1.i11.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i11.I1.i7.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i11.I1.i7.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i11.I1.i7.p1.1">Section <a class="ltx_ref" href="#S6.SS1.SSS1" title="6.1.1 Prompt Creation ‣ 6.1 Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.1.1</span></a>: add prompt design;</p>
</div>
</li>
<li id="Sx1.I1.i11.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i11.I1.i8.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i11.I1.i8.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i11.I1.i8.p1.1">섹션 <a class="ltx_ref" href="#S8" title="8 Applications ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">8</span></a>: 재무 및 과학 연구 도메인에서 LLM의 적용에 대한 논의를 추가함;</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx1.I1.i12" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i12.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i12.p1.1">2023년 9월 10일 업데이트(주요 개정):</p>
<ul id="Sx1.I1.i12.I1" class="ltx_itemize">
<li id="Sx1.I1.i12.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i12.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i12.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i12.I1.i1.p1.1">이 문서의 그림과 표의 저작권을 주장합니다.</p>
</div>
</li>
<li id="Sx1.I1.i12.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i12.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i12.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i12.I1.i2.p1.1">Section <a class="ltx_ref" href="#S3" title="3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>, Section <a class="ltx_ref" href="#S4" title="4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>, Section <a class="ltx_ref" href="#S5" title="5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>, Section <a class="ltx_ref" href="#S6" title="6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a> 및 Section <a class="ltx_ref" href="#S7" title="7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>에서 최신 LLMs, 기법 및 그 설명을 추가한다.</p>
</div>
</li>
<li id="Sx1.I1.i12.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i12.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i12.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i12.I1.i3.p1.1">Section <a class="ltx_ref" href="#S4" title="4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>: Section <a class="ltx_ref" href="#S4.SS2.SSS5" title="4.2.5 Decoding Strategy ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.5</span></a>에서 디코딩 전략에 대한 최신 논의를 추가;</p>
</div>
</li>
<li id="Sx1.I1.i12.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i12.I1.i4.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i12.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i12.I1.i4.p1.1">섹션 <a class="ltx_ref" href="#S5" title="5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>: 섹션 <a class="ltx_ref" href="#S5.SS1.SSS2" title="5.1.2 Instruction Tuning Strategies ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1.2</span></a>에서 명령어 튜닝을 위한 실용적인 트릭에 대한 최신 논의를 추가하고, 섹션 <a class="ltx_ref" href="#S5.SS1.SSS4" title="5.1.4 Empirical Analysis for Instruction Tuning ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1.4</span></a>에서 명령어 튜닝을 위한 LLaMA(13B)에 대한 경험적 분석, 섹션 <a class="ltx_ref" href="#S5.SS2.SSS3" title="5.2.3 Reinforcement Learning from Human Feedback ‣ 5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.2.3</span></a>에서 RLHF에 대한 실용적인 전략, 섹션 <a class="ltx_ref" href="#S5.SS2.SSS4" title="5.2.4 Alignment without RLHF ‣ 5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.2.4</span></a>에서 RLHF가 없는 정렬 및 섹션 <a class="ltx_ref" href="#S5.SS2.SSS5" title="5.2.5 Remarks on SFT and RLHF ‣ 5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.2.5</span></a>에서 SFT 및 RLHF에 대한 비고;</p>
</div>
</li>
<li id="Sx1.I1.i12.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i12.I1.i5.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i12.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i12.I1.i5.p1.1">Section <a class="ltx_ref" href="#S6" title="6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>: Section <a class="ltx_ref" href="#S6.SS4" title="6.4 Planning for Complex Task Solving ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.4</span></a>에서 복합 과제 해결을 위한 기획에 관한 내용을 업데이트하는 단계;</p>
</div>
</li>
<li id="Sx1.I1.i12.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i12.I1.i6.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i12.I1.i6.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i12.I1.i6.p1.1">Section <a class="ltx_ref" href="#S7" title="7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>: 기존 평가 작업의 범주에 대해 Section <a class="ltx_ref" href="#S7.SS3.SSS2" title="7.3.2 Evaluation Approaches ‣ 7.3 Benchmarks and Evaluation Approaches ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.3.2</span></a>, Table <a class="ltx_ref" href="#S7.T15" title="TABLE XV ‣ 7.2.3 Tool Manipulation ‣ 7.2 Advanced Ability ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XV</span></a>에서의 평가 접근법에 대한 논의를 추가하고, Section <a class="ltx_ref" href="#S7.SS4" title="7.4 Empirical Evaluation ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">7.4</span></a>에서의 경험적 능력 평가와 Table <a class="ltx_ref" href="#S7.T16" title="TABLE XVI ‣ 7.3.2 Evaluation Approaches ‣ 7.3 Benchmarks and Evaluation Approaches ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XVI</span></a>에서의 결과를 업데이트하는 단계;</p>
</div>
</li>
<li id="Sx1.I1.i12.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i12.I1.i7.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i12.I1.i7.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i12.I1.i7.p1.1">Section <a class="ltx_ref" href="#S6.SS1.SSS1" title="6.1.1 Prompt Creation ‣ 6.1 Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.1.1</span></a>: add new prompt examples in Table <a class="ltx_ref" href="#S6.T12" title="TABLE XII ‣ 6.1.1 Prompt Creation ‣ 6.1 Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XII</span></a>;</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx1.I1.i13" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i13.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i13.p1.1">2023년 11월 23일 업데이트(본 버전):</p>
<ul id="Sx1.I1.i13.I1" class="ltx_itemize">
<li id="Sx1.I1.i13.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i13.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i13.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i13.I1.i1.p1.1">섹션 <a class="ltx_ref" href="#S1" title="1 Introduction ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>: 4세대 언어 모델의 진화 과정에 그림 <a class="ltx_ref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>를 추가하며;</p>
</div>
</li>
<li id="Sx1.I1.i13.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i13.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i13.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i13.I1.i2.p1.1">섹션 <a class="ltx_ref" href="#S2" title="2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>: 스케일링 법칙에 대한 더 많은 논의 및 창발 능력이 스케일링 법칙과 어떻게 관련되는지에 대한 추가;</p>
</div>
</li>
<li id="Sx1.I1.i13.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i13.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i13.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i13.I1.i3.p1.1">Section <a class="ltx_ref" href="#S3" title="3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>: Figure <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> 및 Table <a class="ltx_ref" href="#S2.T1" title="TABLE I ‣ 2.1 Background for LLMs ‣ 2 Overview ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">I</span></a>의 최신 LLMs 추가, Section <a class="ltx_ref" href="#S3.SS1" title="3.1 Publicly Available Model Checkpoints or APIs ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3.1</span></a>의 최신 API, Section <a class="ltx_ref" href="#S3.SS3" title="3.3 Commonly Used Datasets for Fine-tuning ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3.3</span></a>의 명령어 튜닝 및 정렬 튜닝을 위한 일반적으로 사용되는 데이터셋, Section <a class="ltx_ref" href="#S3.SS4" title="3.4 Library Resource ‣ 3 Resources of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">3.4</span></a>의 여러 라이브러리</p>
</div>
</li>
<li id="Sx1.I1.i13.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i13.I1.i4.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i13.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i13.I1.i4.p1.1">섹션 <a class="ltx_ref" href="#S4" title="4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>: 섹션 <a class="ltx_ref" href="#S4.SS1.SSS3" title="4.1.3 Data Scheduling ‣ 4.1 Data Collection and Preparation ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.1.3</span></a>에서 데이터 혼합물 및 데이터 커리큘럼을 포함하는 데이터 스케줄링에 대한 최신 논의를 추가하고; 섹션 <a class="ltx_ref" href="#S4.SS1.SSS4" title="4.1.4 Summary of Data Preparation ‣ 4.1 Data Collection and Preparation ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.1.4</span></a>에서 데이터 준비의 요약을 추가하고; 섹션 <a class="ltx_ref" href="#S4.SS2.SSS4" title="4.2.4 Long Context Modeling ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.4</span></a>에서 긴 컨텍스트 모델링에 대한 논의를 추가하고; 디코딩 효율 문제에 대한 논의를 추가하고, 섹션 <a class="ltx_ref" href="#S4.SS2.SSS5" title="4.2.5 Decoding Strategy ‣ 4.2 Architecture ‣ 4 Pre-training ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.5</span></a>에서 최신 디코딩 전략을 추가하고;</p>
</div>
</li>
<li id="Sx1.I1.i13.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i13.I1.i5.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i13.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i13.I1.i5.p1.1">섹션 <a class="ltx_ref" href="#S5" title="5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>: 섹션 <a class="ltx_ref" href="#S5.SS1" title="5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.1</span></a>에서 인스턴스 구성 및 튜닝 전략에 대한 최신 논의를 추가하고, 섹션 <a class="ltx_ref" href="#S5.SS2.SSS3" title="5.2.3 Reinforcement Learning from Human Feedback ‣ 5.2 Alignment Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.2.3</span></a>에서 프로세스 감독 RLHF에 대한 최신 논의를 추가하고, 섹션 <a class="ltx_ref" href="#S5.SS4.SSS3" title="5.4.3 Empirical Analysis and Findings ‣ 5.4 Memory-Efficient Model Adaptation ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">5.4.3</span></a>에서 양자화된 LLaMA 모델(7B 및 13B)에 대한 경험적 연구;</p>
</div>
</li>
<li id="Sx1.I1.i13.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i13.I1.i6.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i13.I1.i6.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i13.I1.i6.p1.1">Section <a class="ltx_ref" href="#S6" title="6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>: Section <a class="ltx_ref" href="#S6.SS1.SSS2" title="6.1.2 Prompt Optimization ‣ 6.1 Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.1.2</span></a>에서 프롬프트 최적화에 대한 최신 논의를 추가하고, Section <a class="ltx_ref" href="#S6.SS3" title="6.3 Chain-of-Thought Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">6.3</span></a>에서 연쇄 사상 프롬프트에 대한 내용을 업데이트하는 단계;</p>
</div>
</li>
<li id="Sx1.I1.i13.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i13.I1.i7.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i13.I1.i7.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i13.I1.i7.p1.1">Section <a class="ltx_ref" href="#S8" title="8 Applications ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">8</span></a>: Section <a class="ltx_ref" href="#S8.SS1" title="8.1 LLM for Research Community ‣ 8 Applications ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">8.1</span></a>에서 연구 방향을 위한 LLM에 대한 최신 논의를 추가</p>
</div>
</li>
<li id="Sx1.I1.i13.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="Sx1.I1.i13.I1.i8.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="Sx1.I1.i13.I1.i8.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i13.I1.i8.p1.1">Section <a class="ltx_ref" href="#S9" title="9 Conclusion and Future Directions ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">9</span></a>: 몇 가지 측면에서 내용을 수정한다.</p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div id="Sx1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx1.p5.1"><span class="ltx_text ltx_font_bold" id="Sx1.p5.1.1">Planning Content</span>. 우리는 정기적으로 이 설문조사에 새로운 내용을 포함하여 보다 자립적이고 최신 상태로 만들 것입니다. 여기에서 다음 주요 버전에서 나타날 수 있는 몇 가지 잠재적인 주제를 나열한다: (1) 수업 조정과 능력 평가를 위해 더 큰 언어 모델을 사용한 더 많은 실험; (2) 더 자세한 프롬프트 연습; (3) 훈련 레시피; (4) 더 많은 이론적 분석과 토론; (5) 응용 프로그램에 대한 더 많은 토론.</p>
</div>
<div id="Sx1.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx1.p6.1"><span class="ltx_text ltx_font_bold" id="Sx1.p6.1.1">Clarifications on Experiments</span>. 이 버전에서는 명령어 튜닝(표<a class="ltx_ref" href="#S5.T9" title="TABLE IX ‣ 5.1.3 The Effect of Instruction Tuning ‣ 5.1 Instruction Tuning ‣ 5 Adaptation of LLMs ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">IX</span></a>), 전반적인 능력 평가(표<a class="ltx_ref" href="#S7.T16" title="TABLE XVI ‣ 7.3.2 Evaluation Approaches ‣ 7.3 Benchmarks and Evaluation Approaches ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XVI</span></a>), 프롬프트 엔지니어링(표<a class="ltx_ref" href="#S7.T17" title="TABLE XVII ‣ 7.3.2 Evaluation Approaches ‣ 7.3 Benchmarks and Evaluation Approaches ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XVII</span></a>)에 대한 숫자 실험을 포함했다. 계산 자원의 한계로 인해 우리의 실험은 완전하지 않으며 작은 크기의 모델이나 몇 가지 비교에 국한된다. 그럼에도 불구하고, 우리는 부분적인 결과를 대중에게 공유하는 것이 의미가 있을 수 있다고 생각합니다. 우리는 더 큰 모델의 결측 결과나 더 많은 비교 결과를 미래 버전에 포함시키려고 노력할 것이다. <span class="ltx_text ltx_font_bold" id="Sx1.p6.1.2">또한 보다 포괄적인 실험을 수행하기 위한 컴퓨팅 파워의 지원을 요청한다. </span></p>
</div>
<div id="Sx1.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx1.p7.1"><span class="ltx_text ltx_font_bold" id="Sx1.p7.1.1">Chinese Version</span>. 또한 링크에서 이 조사 논문의 번역된 중국어 버전(첫 번째 릴리스에 해당)을 제공한다: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese.pdf" target="_blank" title="">https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese.pdf</a>. 자원봉사자 4명은 내용을 점검하고 수정하는 데 기여하며, 이웬후, 신덩, 신명호우, 옌빈음, 잔쇼조(기여순)이다. 중국어 버전도 계속 업데이트하겠지만 최신 영어 버전만큼 시기적절하지는 않을 수 있습니다.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgments</h2>

<div id="Sx2.p1" class="ltx_para">
<p class="ltx_p" id="Sx2.p1.1">저자들은 이 논문을 교정해 준 얀카이 린과 유타오 주에게 감사하고 싶다. 이 논문이 처음 발표된 이후, 우리는 독자들로부터 많은 귀중한 논평을 받았습니다. 타일러 수어드, 다마이 다이, 량 딩, 스텔라 바이더만, 케빈 그레이, 제이 알라마르, 유보 펑, 마크 홀름스트롬, 싱동 류, 오일석, 이팅 류, 샤오준 왕, 가오얀 우, 토드 모릴, 하오 류, 젠유 장, 신린 장 등 건설적인 제안과 논평으로 저희에게 편지를 보내 주신 독자들에게 진심으로 감사드립니다. <br class="ltx_break"/></p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p class="ltx_p" id="Sx2.p2.1">v11 버전(2023년 6월 29일) 이후로 우리는 많은 수의 실험과 신속한 관행을 추가했다. 이러한 새로운 콘텐츠는 우리 팀의 많은 자원 봉사자에 의해 완성됩니다. 여기, 우리는 이 부분에 대해 매우 열심히 노력한 모든 학생들에게 감사를 표하기 위해 특별한 부분을 추가합니다(우리 작가 목록에 있는 학생들도 포함).</p>
</div>
<div id="Sx2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx2.p3.1"><span class="ltx_text ltx_font_bold" id="Sx2.p3.1.1">Contribution on Experiments. </span> 표 <a class="ltx_ref" href="#S7.T16" title="TABLE XVI ‣ 7.3.2 Evaluation Approaches ‣ 7.3 Benchmarks and Evaluation Approaches ‣ 7 Capacity and Evaluation ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XVI</span></a>에 나타난 실험에 참여한 다음 분들의 노고에 진심으로 감사드립니다.</p>
</div>
<div id="Sx2.p4" class="ltx_para">
<p class="ltx_p" id="Sx2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="Sx2.p4.1.m1.1"><semantics id="Sx2.p4.1.m1.1a"><mo id="Sx2.p4.1.m1.1.1" xref="Sx2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p4.1.m1.1b"><ci id="Sx2.p4.1.m1.1.1.cmml" xref="Sx2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p4.1.m1.1c">\bullet</annotation></semantics></math> Xiaoxue Cheng: 언어 생성 및 HaluEval 태스크에 대한 평가를 위한 실험을 구현한다.</p>
</div>
<div id="Sx2.p5" class="ltx_para">
<p class="ltx_p" id="Sx2.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="Sx2.p5.1.m1.1"><semantics id="Sx2.p5.1.m1.1a"><mo id="Sx2.p5.1.m1.1.1" xref="Sx2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p5.1.m1.1b"><ci id="Sx2.p5.1.m1.1.1.cmml" xref="Sx2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p5.1.m1.1c">\bullet</annotation></semantics></math> Yuhao Wang: 환경 태스크와의 상호 작용에 대한 평가를 위한 실험을 구현한다.</p>
</div>
<div id="Sx2.p6" class="ltx_para">
<p class="ltx_p" id="Sx2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="Sx2.p6.1.m1.1"><semantics id="Sx2.p6.1.m1.1a"><mo id="Sx2.p6.1.m1.1.1" xref="Sx2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p6.1.m1.1b"><ci id="Sx2.p6.1.m1.1.1.cmml" xref="Sx2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p6.1.m1.1c">\bullet</annotation></semantics></math> Bowen Zheng: 도구 조작 작업에 대한 평가를 위한 실험을 구현한다.</p>
</div>
<div id="Sx2.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx2.p7.1"><span class="ltx_text ltx_font_bold" id="Sx2.p7.1.1">Contribution on Tips. </span> 표 <a class="ltx_ref" href="#S6.T12" title="TABLE XII ‣ 6.1.1 Prompt Creation ‣ 6.1 Prompting ‣ 6 Utilization ‣ A Survey of Large Language Models"><span class="ltx_text ltx_ref_tag">XII</span></a>에서 프롬프트를 디자인하기 위한 제공된 팁의 해당 수에 대한 기여도에 대해 다음 사용자를 나열합니다.</p>
</div>
<div id="Sx2.p8" class="ltx_para">
<p id="Sx2.p8.1" class="ltx_p"><math id="Sx2.p8.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p8.1.m1.1a"><mo id="Sx2.p8.1.m1.1.1" xref="Sx2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p8.1.m1.1b"><ci id="Sx2.p8.1.m1.1.1.cmml" xref="Sx2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p8.1.m1.1c">\bullet</annotation></semantics></math> Xiaolei Wang: T3, O3</p>
</div>
<div id="Sx2.p9" class="ltx_para">
<p id="Sx2.p9.1" class="ltx_p"><math id="Sx2.p9.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p9.1.m1.1a"><mo id="Sx2.p9.1.m1.1.1" xref="Sx2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p9.1.m1.1b"><ci id="Sx2.p9.1.m1.1.1.cmml" xref="Sx2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p9.1.m1.1c">\bullet</annotation></semantics></math> Beichen Zhang: D2, D5</p>
</div>
<div id="Sx2.p10" class="ltx_para">
<p id="Sx2.p10.1" class="ltx_p"><math id="Sx2.p10.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p10.1.m1.1a"><mo id="Sx2.p10.1.m1.1.1" xref="Sx2.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p10.1.m1.1b"><ci id="Sx2.p10.1.m1.1.1.cmml" xref="Sx2.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p10.1.m1.1c">\bullet</annotation></semantics></math> Zhipeng Chen: D3, D4</p>
</div>
<div id="Sx2.p11" class="ltx_para">
<p id="Sx2.p11.1" class="ltx_p"><math id="Sx2.p11.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p11.1.m1.1a"><mo id="Sx2.p11.1.m1.1.1" xref="Sx2.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p11.1.m1.1b"><ci id="Sx2.p11.1.m1.1.1.cmml" xref="Sx2.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p11.1.m1.1c">\bullet</annotation></semantics></math> Junjie Zhang: D6</p>
</div>
<div id="Sx2.p12" class="ltx_para">
<p id="Sx2.p12.1" class="ltx_p"><math id="Sx2.p12.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p12.1.m1.1a"><mo id="Sx2.p12.1.m1.1.1" xref="Sx2.p12.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p12.1.m1.1b"><ci id="Sx2.p12.1.m1.1.1.cmml" xref="Sx2.p12.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p12.1.m1.1c">\bullet</annotation></semantics></math> Bowen Zheng: D7</p>
</div>
<div id="Sx2.p13" class="ltx_para">
<p id="Sx2.p13.1" class="ltx_p"><math id="Sx2.p13.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p13.1.m1.1a"><mo id="Sx2.p13.1.m1.1.1" xref="Sx2.p13.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p13.1.m1.1b"><ci id="Sx2.p13.1.m1.1.1.cmml" xref="Sx2.p13.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p13.1.m1.1c">\bullet</annotation></semantics></math> Zican Dong: D8</p>
</div>
<div id="Sx2.p14" class="ltx_para">
<p id="Sx2.p14.1" class="ltx_p"><math id="Sx2.p14.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p14.1.m1.1a"><mo id="Sx2.p14.1.m1.1.1" xref="Sx2.p14.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p14.1.m1.1b"><ci id="Sx2.p14.1.m1.1.1.cmml" xref="Sx2.p14.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p14.1.m1.1c">\bullet</annotation></semantics></math> Xinyu Tang: C2</p>
</div>
<div id="Sx2.p15" class="ltx_para">
<p id="Sx2.p15.1" class="ltx_p"><math id="Sx2.p15.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p15.1.m1.1a"><mo id="Sx2.p15.1.m1.1.1" xref="Sx2.p15.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p15.1.m1.1b"><ci id="Sx2.p15.1.m1.1.1.cmml" xref="Sx2.p15.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p15.1.m1.1c">\bullet</annotation></semantics></math> Yifan Du: T4</p>
</div>
<div id="Sx2.p16" class="ltx_para">
<p id="Sx2.p16.1" class="ltx_p"><math id="Sx2.p16.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p16.1.m1.1a"><mo id="Sx2.p16.1.m1.1.1" xref="Sx2.p16.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p16.1.m1.1b"><ci id="Sx2.p16.1.m1.1.1.cmml" xref="Sx2.p16.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p16.1.m1.1c">\bullet</annotation></semantics></math> Tianyi Tang: O6, O7, D9</p>
</div>
<div id="Sx2.p17" class="ltx_para">
<p id="Sx2.p17.1" class="ltx_p"><math id="Sx2.p17.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p17.1.m1.1a"><mo id="Sx2.p17.1.m1.1.1" xref="Sx2.p17.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p17.1.m1.1b"><ci id="Sx2.p17.1.m1.1.1.cmml" xref="Sx2.p17.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p17.1.m1.1c">\bullet</annotation></semantics></math> Yupeng Hou: O8, C3</p>
</div>
<div id="Sx2.p18" class="ltx_para">
<p id="Sx2.p18.1" class="ltx_p"><math id="Sx2.p18.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="Sx2.p18.1.m1.1a"><mo id="Sx2.p18.1.m1.1.1" xref="Sx2.p18.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="Sx2.p18.1.m1.1b"><ci id="Sx2.p18.1.m1.1.1.cmml" xref="Sx2.p18.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.p18.1.m1.1c">\bullet</annotation></semantics></math> Salvatore Raieli: C4</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bengio, R.&nbsp;Ducharme, P.&nbsp;Vincent, and C.&nbsp;Janvin, “A neural probabilistic
language model,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, vol.&nbsp;3, pp. 1137–1155, 2003.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
R.&nbsp;Collobert, J.&nbsp;Weston, L.&nbsp;Bottou, M.&nbsp;Karlen, K.&nbsp;Kavukcuoglu, and P.&nbsp;P. Kuksa,
“Natural language processing (almost) from scratch,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn.
Res.</em>, vol.&nbsp;12, pp. 2493–2537, 2011.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
S.&nbsp;Pinker, <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">The Language Instinct: How the Mind Creates Language</em>.&nbsp;&nbsp;&nbsp;Brilliance Audio; Unabridged edition, 2014.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M.&nbsp;D. Hauser, N.&nbsp;Chomsky, and W.&nbsp;T. Fitch, “The faculty of language: what is
it, who has it, and how did it evolve?” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">science</em>, vol. 298, no. 5598,
pp. 1569–1579, 2002.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A.&nbsp;M. Turing, “Computing machinery and intelligence,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Mind</em>, vol.
LIX, no. 236, pp. 433–460, 1950.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
F.&nbsp;Jelinek, <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Statistical Methods for Speech Recognition</em>.&nbsp;&nbsp;&nbsp;MIT Press, 1998.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J.&nbsp;Gao and C.&nbsp;Lin, “Introduction to the special issue on statistical language
modeling,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Asian Lang. Inf. Process.</em>, vol.&nbsp;3, no.&nbsp;2, pp.
87–93, 2004.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
R.&nbsp;Rosenfeld, “Two decades of statistical language modeling: Where do we go
from here?” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, vol.&nbsp;88, no.&nbsp;8, pp. 1270–1278,
2000.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
A.&nbsp;Stolcke, “Srilm-an extensible language modeling toolkit,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Seventh
international conference on spoken language processing</em>, 2002.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
X.&nbsp;Liu and W.&nbsp;B. Croft, “Statistical language modeling for information
retrieval,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Annu. Rev. Inf. Sci. Technol.</em>, vol.&nbsp;39, no.&nbsp;1, pp. 1–31,
2005.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
C.&nbsp;Zhai, <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Statistical Language Models for Information Retrieval</em>, ser.
Synthesis Lectures on Human Language Technologies.&nbsp;&nbsp;&nbsp;Morgan &amp; Claypool Publishers, 2008.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
S.&nbsp;M. Thede and M.&nbsp;P. Harper, “A second-order hidden markov model for
part-of-speech tagging,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">27th Annual Meeting of the Association for
Computational Linguistics, University of Maryland, College Park, Maryland,
USA, 20-26 June 1999</em>, R.&nbsp;Dale and K.&nbsp;W. Church, Eds.&nbsp;&nbsp;&nbsp;ACL, 1999, pp. 175–182.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
L.&nbsp;R. Bahl, P.&nbsp;F. Brown, P.&nbsp;V. de&nbsp;Souza, and R.&nbsp;L. Mercer, “A tree-based
statistical language model for natural language speech recognition,”
<em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Acoustics, Speech, and Signal Processing</em>,
vol.&nbsp;37, no.&nbsp;7, pp. 1001–1008, 1989.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
T.&nbsp;Brants, A.&nbsp;C. Popat, P.&nbsp;Xu, F.&nbsp;J. Och, and J.&nbsp;Dean, “Large language models
in machine translation,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">EMNLP-CoNLL 2007, Proceedings of the 2007
Joint Conference on Empirical Methods in Natural Language Processing and
Computational Natural Language Learning, June 28-30, 2007, Prague, Czech
Republic</em>, J.&nbsp;Eisner, Ed.&nbsp;&nbsp;&nbsp;ACL, 2007,
pp. 858–867.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
S.&nbsp;M. Katz, “Estimation of probabilities from sparse data for the language
model component of a speech recognizer,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Acoust. Speech
Signal Process.</em>, vol.&nbsp;35, no.&nbsp;3, pp. 400–401, 1987.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
W.&nbsp;A. Gale and G.&nbsp;Sampson, “Good-turing frequency estimation without tears,”
<em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">J. Quant. Linguistics</em>, vol.&nbsp;2, no.&nbsp;3, pp. 217–237, 1995.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
T.&nbsp;Mikolov, M.&nbsp;Karafiát, L.&nbsp;Burget, J.&nbsp;Cernocký, and S.&nbsp;Khudanpur,
“Recurrent neural network based language model,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH
2010, 11th Annual Conference of the International Speech Communication
Association, Makuhari, Chiba, Japan, September 26-30, 2010</em>, T.&nbsp;Kobayashi,
K.&nbsp;Hirose, and S.&nbsp;Nakamura, Eds.&nbsp;&nbsp;&nbsp;ISCA, 2010, pp. 1045–1048.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S.&nbsp;Kombrink, T.&nbsp;Mikolov, M.&nbsp;Karafiát, and L.&nbsp;Burget, “Recurrent neural
network based language modeling in meeting recognition,” in
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH 2011, 12th Annual Conference of the International Speech
Communication Association, Florence, Italy, August 27-31, 2011</em>.&nbsp;&nbsp;&nbsp;ISCA, 2011, pp. 2877–2880.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
T.&nbsp;Mikolov, I.&nbsp;Sutskever, K.&nbsp;Chen, G.&nbsp;S. Corrado, and J.&nbsp;Dean, “Distributed
representations of words and phrases and their compositionality,” in
<em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 26: 27th Annual
Conference on Neural Information Processing Systems 2013. Proceedings of a
meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States</em>, C.&nbsp;J.&nbsp;C.
Burges, L.&nbsp;Bottou, Z.&nbsp;Ghahramani, and K.&nbsp;Q. Weinberger, Eds., 2013, pp.
3111–3119.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
T.&nbsp;Mikolov, K.&nbsp;Chen, G.&nbsp;Corrado, and J.&nbsp;Dean, “Efficient estimation of word
representations in vector space,” in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">1st International Conference on
Learning Representations, ICLR 2013, Scottsdale, Arizona, USA, May 2-4,
2013, Workshop Track Proceedings</em>, Y.&nbsp;Bengio and Y.&nbsp;LeCun, Eds., 2013.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M.&nbsp;E. Peters, M.&nbsp;Neumann, M.&nbsp;Iyyer, M.&nbsp;Gardner, C.&nbsp;Clark, K.&nbsp;Lee, and
L.&nbsp;Zettlemoyer, “Deep contextualized word representations,” in
<em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies,
NAACL-HLT 2018, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 1 (Long
Papers)</em>, M.&nbsp;A. Walker, H.&nbsp;Ji, and A.&nbsp;Stent, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2018, pp. 2227–2237.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A.&nbsp;Vaswani, N.&nbsp;Shazeer, N.&nbsp;Parmar, J.&nbsp;Uszkoreit, L.&nbsp;Jones, A.&nbsp;N. Gomez,
L.&nbsp;Kaiser, and I.&nbsp;Polosukhin, “Attention is all you need,” in
<em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017, Long
Beach, CA, USA</em>, 2017, pp. 5998–6008.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
J.&nbsp;Devlin, M.&nbsp;Chang, K.&nbsp;Lee, and K.&nbsp;Toutanova, “BERT: pre-training of deep
bidirectional transformers for language understanding,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2019 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, NAACL-HLT 2019,
Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>,
J.&nbsp;Burstein, C.&nbsp;Doran, and T.&nbsp;Solorio, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2019, pp. 4171–4186.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
M.&nbsp;Lewis, Y.&nbsp;Liu, N.&nbsp;Goyal, M.&nbsp;Ghazvininejad, A.&nbsp;Mohamed, O.&nbsp;Levy, V.&nbsp;Stoyanov,
and L.&nbsp;Zettlemoyer, “BART: denoising sequence-to-sequence pre-training for
natural language generation, translation, and comprehension,” in
<em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for
Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, 2020, pp.
7871–7880.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
W.&nbsp;Fedus, B.&nbsp;Zoph, and N.&nbsp;Shazeer, “Switch transformers: Scaling to trillion
parameter models with simple and efficient sparsity,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn.
Res</em>, pp. 1–40, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
A.&nbsp;Radford, J.&nbsp;Wu, R.&nbsp;Child, D.&nbsp;Luan, D.&nbsp;Amodei, I.&nbsp;Sutskever <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>,
“Language models are unsupervised multitask learners,” <em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic">OpenAI blog</em>,
p.&nbsp;9, 2019.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Y.&nbsp;Liu, M.&nbsp;Ott, N.&nbsp;Goyal, J.&nbsp;Du, M.&nbsp;Joshi, D.&nbsp;Chen, O.&nbsp;Levy, M.&nbsp;Lewis,
L.&nbsp;Zettlemoyer, and V.&nbsp;Stoyanov, “Roberta: A robustly optimized BERT
pretraining approach,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1907.11692, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
V.&nbsp;Sanh, A.&nbsp;Webson, C.&nbsp;Raffel, S.&nbsp;H. Bach, L.&nbsp;Sutawika, Z.&nbsp;Alyafeai,
A.&nbsp;Chaffin, A.&nbsp;Stiegler, A.&nbsp;Raja, M.&nbsp;Dey, M.&nbsp;S. Bari, C.&nbsp;Xu, U.&nbsp;Thakker,
S.&nbsp;S. Sharma, E.&nbsp;Szczechla, T.&nbsp;Kim, G.&nbsp;Chhablani, N.&nbsp;V. Nayak, D.&nbsp;Datta,
J.&nbsp;Chang, M.&nbsp;T. Jiang, H.&nbsp;Wang, M.&nbsp;Manica, S.&nbsp;Shen, Z.&nbsp;X. Yong, H.&nbsp;Pandey,
R.&nbsp;Bawden, T.&nbsp;Wang, T.&nbsp;Neeraj, J.&nbsp;Rozen, A.&nbsp;Sharma, A.&nbsp;Santilli,
T.&nbsp;Févry, J.&nbsp;A. Fries, R.&nbsp;Teehan, T.&nbsp;L. Scao, S.&nbsp;Biderman, L.&nbsp;Gao,
T.&nbsp;Wolf, and A.&nbsp;M. Rush, “Multitask prompted training enables zero-shot task
generalization,” in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning
Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
T.&nbsp;Wang, A.&nbsp;Roberts, D.&nbsp;Hesslow, T.&nbsp;L. Scao, H.&nbsp;W. Chung, I.&nbsp;Beltagy,
J.&nbsp;Launay, and C.&nbsp;Raffel, “What language model architecture and pretraining
objective works best for zero-shot generalization?” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore,
Maryland, USA</em>, ser. Proceedings of Machine Learning Research, vol. 162,
2022, pp. 22 964–22 984.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
J.&nbsp;Kaplan, S.&nbsp;McCandlish, T.&nbsp;Henighan, T.&nbsp;B. Brown, B.&nbsp;Chess, R.&nbsp;Child,
S.&nbsp;Gray, A.&nbsp;Radford, J.&nbsp;Wu, and D.&nbsp;Amodei, “Scaling laws for neural language
models,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2001.08361, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J.&nbsp;Wei, Y.&nbsp;Tay, R.&nbsp;Bommasani, C.&nbsp;Raffel, B.&nbsp;Zoph, S.&nbsp;Borgeaud, D.&nbsp;Yogatama,
M.&nbsp;Bosma, D.&nbsp;Zhou, D.&nbsp;Metzler, E.&nbsp;H. Chi, T.&nbsp;Hashimoto, O.&nbsp;Vinyals, P.&nbsp;Liang,
J.&nbsp;Dean, and W.&nbsp;Fedus, “Emergent abilities of large language models,”
<em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2206.07682, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M.&nbsp;Shanahan, “Talking about large language models,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2212.03551, 2022.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
J.&nbsp;Wei, X.&nbsp;Wang, D.&nbsp;Schuurmans, M.&nbsp;Bosma, E.&nbsp;H. Chi, Q.&nbsp;Le, and D.&nbsp;Zhou,
“Chain of thought prompting elicits reasoning in large language models,”
<em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2201.11903, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
J.&nbsp;Hoffmann, S.&nbsp;Borgeaud, A.&nbsp;Mensch, E.&nbsp;Buchatskaya, T.&nbsp;Cai, E.&nbsp;Rutherford,
D.&nbsp;de&nbsp;Las&nbsp;Casas, L.&nbsp;A. Hendricks, J.&nbsp;Welbl, A.&nbsp;Clark, T.&nbsp;Hennigan, E.&nbsp;Noland,
K.&nbsp;Millican, G.&nbsp;van&nbsp;den Driessche, B.&nbsp;Damoc, A.&nbsp;Guy, S.&nbsp;Osindero,
K.&nbsp;Simonyan, E.&nbsp;Elsen, J.&nbsp;W. Rae, O.&nbsp;Vinyals, and L.&nbsp;Sifre, “Training
compute-optimal large language models,” vol. abs/2203.15556, 2022.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
R.&nbsp;Taylor, M.&nbsp;Kardas, G.&nbsp;Cucurull, T.&nbsp;Scialom, A.&nbsp;Hartshorn, E.&nbsp;Saravia,
A.&nbsp;Poulton, V.&nbsp;Kerkez, and R.&nbsp;Stojnic, “Galactica: A large language model
for science,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.09085, 2022.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
P.&nbsp;Liu, W.&nbsp;Yuan, J.&nbsp;Fu, Z.&nbsp;Jiang, H.&nbsp;Hayashi, and G.&nbsp;Neubig, “Pre-train,
prompt, and predict: A systematic survey of prompting methods in natural
language processing,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em>, pp. 195:1–195:35, 2023.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
C.&nbsp;Zhou, Q.&nbsp;Li, C.&nbsp;Li, J.&nbsp;Yu, Y.&nbsp;Liu, G.&nbsp;Wang, K.&nbsp;Zhang, C.&nbsp;Ji, Q.&nbsp;Yan, L.&nbsp;He,
H.&nbsp;Peng, J.&nbsp;Li, J.&nbsp;Wu, Z.&nbsp;Liu, P.&nbsp;Xie, C.&nbsp;Xiong, J.&nbsp;Pei, P.&nbsp;S. Yu, and
L.&nbsp;Sun, “A comprehensive survey on pretrained foundation models: A history
from BERT to chatgpt,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.09419, 2023.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
X.&nbsp;Han, Z.&nbsp;Zhang, N.&nbsp;Ding, Y.&nbsp;Gu, X.&nbsp;Liu, Y.&nbsp;Huo, J.&nbsp;Qiu, Y.&nbsp;Yao, A.&nbsp;Zhang,
L.&nbsp;Zhang, W.&nbsp;Han, M.&nbsp;Huang, Q.&nbsp;Jin, Y.&nbsp;Lan, Y.&nbsp;Liu, Z.&nbsp;Liu, Z.&nbsp;Lu, X.&nbsp;Qiu,
R.&nbsp;Song, J.&nbsp;Tang, J.&nbsp;Wen, J.&nbsp;Yuan, W.&nbsp;X. Zhao, and J.&nbsp;Zhu, “Pre-trained
models: Past, present and future,” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">AI Open</em>, vol.&nbsp;2, pp. 225–250,
2021.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
X.&nbsp;Qiu, T.&nbsp;Sun, Y.&nbsp;Xu, Y.&nbsp;Shao, N.&nbsp;Dai, and X.&nbsp;Huang, “Pre-trained models for
natural language processing: A survey,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2003.08271,
2020.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
S.&nbsp;Altman, “Planning for agi and beyond,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">OpenAI Blog</em>, February 2023.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
S.&nbsp;Bubeck, V.&nbsp;Chandrasekaran, R.&nbsp;Eldan, J.&nbsp;Gehrke, E.&nbsp;Horvitz, E.&nbsp;Kamar,
P.&nbsp;Lee, Y.&nbsp;T. Lee, Y.&nbsp;Li, S.&nbsp;Lundberg, H.&nbsp;Nori, H.&nbsp;Palangi, M.&nbsp;T. Ribeiro,
and Y.&nbsp;Zhang, “Sparks of artificial general intelligence: Early experiments
with gpt-4,” vol. abs/2303.12712, 2023.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
S.&nbsp;Huang, L.&nbsp;Dong, W.&nbsp;Wang, Y.&nbsp;Hao, S.&nbsp;Singhal, S.&nbsp;Ma, T.&nbsp;Lv, L.&nbsp;Cui, O.&nbsp;K.
Mohammed, B.&nbsp;Patra, Q.&nbsp;Liu, K.&nbsp;Aggarwal, Z.&nbsp;Chi, J.&nbsp;Bjorck, V.&nbsp;Chaudhary,
S.&nbsp;Som, X.&nbsp;Song, and F.&nbsp;Wei, “Language is not all you need: Aligning
perception with language models,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.14045, 2023.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Y.&nbsp;Cao, S.&nbsp;Li, Y.&nbsp;Liu, Z.&nbsp;Yan, Y.&nbsp;Dai, P.&nbsp;S. Yu, and L.&nbsp;Sun, “A comprehensive
survey of ai-generated content (aigc): A history of generative ai from gan to
chatgpt,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.04226</em>, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
D.&nbsp;Driess, F.&nbsp;Xia, M.&nbsp;S. Sajjadi, C.&nbsp;Lynch, A.&nbsp;Chowdhery, B.&nbsp;Ichter, A.&nbsp;Wahid,
J.&nbsp;Tompson, Q.&nbsp;Vuong, T.&nbsp;Yu <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Palm-e: An embodied multimodal
language model,” <em id="bib.bib44.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.03378</em>, 2023.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
C.&nbsp;Wu, S.&nbsp;Yin, W.&nbsp;Qi, X.&nbsp;Wang, Z.&nbsp;Tang, and N.&nbsp;Duan, “Visual chatgpt: Talking,
drawing and editing with visual foundation models,” <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2303.04671</em>, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
OpenAI, “Gpt-4 technical report,” <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">OpenAI</em>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Y.&nbsp;Fu, H.&nbsp;Peng, and T.&nbsp;Khot, “How does gpt obtain its ability? tracing
emergent abilities of language models to their sources,” <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Yao Fu’s
Notion</em>, Dec 2022.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
J.&nbsp;Li, T.&nbsp;Tang, W.&nbsp;X. Zhao, and J.&nbsp;Wen, “Pretrained language model for text
generation: A survey,” in <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirtieth International
Joint Conference on Artificial Intelligence, IJCAI 2021, Virtual Event /
Montreal, Canada, 19-27 August 2021</em>, Z.&nbsp;Zhou, Ed.&nbsp;&nbsp;&nbsp;ijcai.org, 2021, pp. 4492–4499.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
P.&nbsp;Lu, L.&nbsp;Qiu, W.&nbsp;Yu, S.&nbsp;Welleck, and K.&nbsp;Chang, “A survey of deep learning for
mathematical reasoning,” <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.10535, 2022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Q.&nbsp;Dong, L.&nbsp;Li, D.&nbsp;Dai, C.&nbsp;Zheng, Z.&nbsp;Wu, B.&nbsp;Chang, X.&nbsp;Sun, J.&nbsp;Xu, L.&nbsp;Li, and
Z.&nbsp;Sui, “A survey for in-context learning,” <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2301.00234, 2023.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
J.&nbsp;Huang and K.&nbsp;C. Chang, “Towards reasoning in large language models: A
survey,” <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.10403, 2022.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
S.&nbsp;Qiao, Y.&nbsp;Ou, N.&nbsp;Zhang, X.&nbsp;Chen, Y.&nbsp;Yao, S.&nbsp;Deng, C.&nbsp;Tan, F.&nbsp;Huang, and
H.&nbsp;Chen, “Reasoning with language model prompting: A survey,”
<em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.09597, 2022.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
J.&nbsp;Zhou, P.&nbsp;Ke, X.&nbsp;Qiu, M.&nbsp;Huang, and J.&nbsp;Zhang, “Chatgpt: potential,
prospects, and limitations,” in <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Frontiers of Information Technology &amp;
Electronic Engineering</em>, 2023, pp. 1–6.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
W.&nbsp;X. Zhao, J.&nbsp;Liu, R.&nbsp;Ren, and J.&nbsp;Wen, “Dense text retrieval based on
pretrained language models: A survey,” <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.14876,
2022.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
T.&nbsp;B. Brown, B.&nbsp;Mann, N.&nbsp;Ryder, M.&nbsp;Subbiah, J.&nbsp;Kaplan, P.&nbsp;Dhariwal,
A.&nbsp;Neelakantan, P.&nbsp;Shyam, G.&nbsp;Sastry, A.&nbsp;Askell, S.&nbsp;Agarwal,
A.&nbsp;Herbert-Voss, G.&nbsp;Krueger, T.&nbsp;Henighan, R.&nbsp;Child, A.&nbsp;Ramesh, D.&nbsp;M.
Ziegler, J.&nbsp;Wu, C.&nbsp;Winter, C.&nbsp;Hesse, M.&nbsp;Chen, E.&nbsp;Sigler, M.&nbsp;Litwin, S.&nbsp;Gray,
B.&nbsp;Chess, J.&nbsp;Clark, C.&nbsp;Berner, S.&nbsp;McCandlish, A.&nbsp;Radford, I.&nbsp;Sutskever, and
D.&nbsp;Amodei, “Language models are few-shot learners,” in <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Advances in
Neural Information Processing Systems 33: Annual Conference on Neural
Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,
virtual</em>, H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.&nbsp;Balcan, and H.&nbsp;Lin, Eds.,
2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
A.&nbsp;Chowdhery, S.&nbsp;Narang, J.&nbsp;Devlin, M.&nbsp;Bosma, G.&nbsp;Mishra, A.&nbsp;Roberts, P.&nbsp;Barham,
H.&nbsp;W. Chung, C.&nbsp;Sutton, S.&nbsp;Gehrmann, P.&nbsp;Schuh, K.&nbsp;Shi, S.&nbsp;Tsvyashchenko,
J.&nbsp;Maynez, A.&nbsp;Rao, P.&nbsp;Barnes, Y.&nbsp;Tay, N.&nbsp;Shazeer, V.&nbsp;Prabhakaran, E.&nbsp;Reif,
N.&nbsp;Du, B.&nbsp;Hutchinson, R.&nbsp;Pope, J.&nbsp;Bradbury, J.&nbsp;Austin, M.&nbsp;Isard,
G.&nbsp;Gur-Ari, P.&nbsp;Yin, T.&nbsp;Duke, A.&nbsp;Levskaya, S.&nbsp;Ghemawat, S.&nbsp;Dev,
H.&nbsp;Michalewski, X.&nbsp;Garcia, V.&nbsp;Misra, K.&nbsp;Robinson, L.&nbsp;Fedus, D.&nbsp;Zhou,
D.&nbsp;Ippolito, D.&nbsp;Luan, H.&nbsp;Lim, B.&nbsp;Zoph, A.&nbsp;Spiridonov, R.&nbsp;Sepassi, D.&nbsp;Dohan,
S.&nbsp;Agrawal, M.&nbsp;Omernick, A.&nbsp;M. Dai, T.&nbsp;S. Pillai, M.&nbsp;Pellat, A.&nbsp;Lewkowycz,
E.&nbsp;Moreira, R.&nbsp;Child, O.&nbsp;Polozov, K.&nbsp;Lee, Z.&nbsp;Zhou, X.&nbsp;Wang, B.&nbsp;Saeta,
M.&nbsp;Diaz, O.&nbsp;Firat, M.&nbsp;Catasta, J.&nbsp;Wei, K.&nbsp;Meier-Hellstern, D.&nbsp;Eck, J.&nbsp;Dean,
S.&nbsp;Petrov, and N.&nbsp;Fiedel, “Palm: Scaling language modeling with pathways,”
<em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2204.02311, 2022.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
H.&nbsp;Touvron, T.&nbsp;Lavril, G.&nbsp;Izacard, X.&nbsp;Martinet, M.&nbsp;Lachaux, T.&nbsp;Lacroix,
B.&nbsp;Rozière, N.&nbsp;Goyal, E.&nbsp;Hambro, F.&nbsp;Azhar, A.&nbsp;Rodriguez, A.&nbsp;Joulin,
E.&nbsp;Grave, and G.&nbsp;Lample, “Llama: Open and efficient foundation language
models,” <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2023.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
T.&nbsp;Henighan, J.&nbsp;Kaplan, M.&nbsp;Katz, M.&nbsp;Chen, C.&nbsp;Hesse, J.&nbsp;Jackson, H.&nbsp;Jun, T.&nbsp;B.
Brown, P.&nbsp;Dhariwal, S.&nbsp;Gray <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Scaling laws for autoregressive
generative modeling,” <em id="bib.bib58.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.14701</em>, 2020.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
S.&nbsp;M. Xie, H.&nbsp;Pham, X.&nbsp;Dong, N.&nbsp;Du, H.&nbsp;Liu, Y.&nbsp;Lu, P.&nbsp;Liang, Q.&nbsp;V. Le, T.&nbsp;Ma,
and A.&nbsp;W. Yu, “Doremi: Optimizing data mixtures speeds up language model
pretraining,” <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.10429</em>, 2023.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
P.&nbsp;Villalobos, J.&nbsp;Sevilla, L.&nbsp;Heim, T.&nbsp;Besiroglu, M.&nbsp;Hobbhahn, and A.&nbsp;Ho,
“Will we run out of data? an analysis of the limits of scaling datasets in
machine learning,” <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.04325, 2022. [Online].
Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2211.04325" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2211.04325</a>

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
N.&nbsp;Muennighoff, A.&nbsp;M. Rush, B.&nbsp;Barak, T.&nbsp;L. Scao, A.&nbsp;Piktus, N.&nbsp;Tazi,
S.&nbsp;Pyysalo, T.&nbsp;Wolf, and C.&nbsp;Raffel, “Scaling data-constrained language
models,” <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.16264</em>, 2023.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
I.&nbsp;McKenzie, A.&nbsp;Lyzhov, A.&nbsp;Parrish, A.&nbsp;Prabhu, A.&nbsp;Mueller, N.&nbsp;Kim, S.&nbsp;Bowman,
and E.&nbsp;Perez, “The inverse scaling prize,” 2022. [Online]. Available:
<a target="_blank" href="https://github.com/inverse-scaling/prize" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/inverse-scaling/prize</a>

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
B.&nbsp;A. Huberman and T.&nbsp;Hogg, “Phase transitions in artificial intelligence
systems,” <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence</em>, vol.&nbsp;33, no.&nbsp;2, pp. 155–171,
1987.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
J.&nbsp;W. Rae, S.&nbsp;Borgeaud, T.&nbsp;Cai, K.&nbsp;Millican, J.&nbsp;Hoffmann, H.&nbsp;F. Song,
J.&nbsp;Aslanides, S.&nbsp;Henderson, R.&nbsp;Ring, S.&nbsp;Young, E.&nbsp;Rutherford, T.&nbsp;Hennigan,
J.&nbsp;Menick, A.&nbsp;Cassirer, R.&nbsp;Powell, G.&nbsp;van&nbsp;den Driessche, L.&nbsp;A. Hendricks,
M.&nbsp;Rauh, P.&nbsp;Huang, A.&nbsp;Glaese, J.&nbsp;Welbl, S.&nbsp;Dathathri, S.&nbsp;Huang, J.&nbsp;Uesato,
J.&nbsp;Mellor, I.&nbsp;Higgins, A.&nbsp;Creswell, N.&nbsp;McAleese, A.&nbsp;Wu, E.&nbsp;Elsen, S.&nbsp;M.
Jayakumar, E.&nbsp;Buchatskaya, D.&nbsp;Budden, E.&nbsp;Sutherland, K.&nbsp;Simonyan,
M.&nbsp;Paganini, L.&nbsp;Sifre, L.&nbsp;Martens, X.&nbsp;L. Li, A.&nbsp;Kuncoro, A.&nbsp;Nematzadeh,
E.&nbsp;Gribovskaya, D.&nbsp;Donato, A.&nbsp;Lazaridou, A.&nbsp;Mensch, J.&nbsp;Lespiau,
M.&nbsp;Tsimpoukelli, N.&nbsp;Grigorev, D.&nbsp;Fritz, T.&nbsp;Sottiaux, M.&nbsp;Pajarskas, T.&nbsp;Pohlen,
Z.&nbsp;Gong, D.&nbsp;Toyama, C.&nbsp;de&nbsp;Masson&nbsp;d’Autume, Y.&nbsp;Li, T.&nbsp;Terzi, V.&nbsp;Mikulik,
I.&nbsp;Babuschkin, A.&nbsp;Clark, D.&nbsp;de&nbsp;Las&nbsp;Casas, A.&nbsp;Guy, C.&nbsp;Jones, J.&nbsp;Bradbury,
M.&nbsp;J. Johnson, B.&nbsp;A. Hechtman, L.&nbsp;Weidinger, I.&nbsp;Gabriel, W.&nbsp;S. Isaac,
E.&nbsp;Lockhart, S.&nbsp;Osindero, L.&nbsp;Rimell, C.&nbsp;Dyer, O.&nbsp;Vinyals, K.&nbsp;Ayoub,
J.&nbsp;Stanway, L.&nbsp;Bennett, D.&nbsp;Hassabis, K.&nbsp;Kavukcuoglu, and G.&nbsp;Irving, “Scaling
language models: Methods, analysis &amp; insights from training gopher,”
<em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2112.11446, 2021.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
D.&nbsp;Dai, Y.&nbsp;Sun, L.&nbsp;Dong, Y.&nbsp;Hao, Z.&nbsp;Sui, and F.&nbsp;Wei, “Why can GPT learn
in-context? language models secretly perform gradient descent as
meta-optimizers,” <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.10559, 2022.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
L.&nbsp;Ouyang, J.&nbsp;Wu, X.&nbsp;Jiang, D.&nbsp;Almeida, C.&nbsp;L. Wainwright, P.&nbsp;Mishkin, C.&nbsp;Zhang,
S.&nbsp;Agarwal, K.&nbsp;Slama, A.&nbsp;Ray, J.&nbsp;Schulman, J.&nbsp;Hilton, F.&nbsp;Kelton, L.&nbsp;Miller,
M.&nbsp;Simens, A.&nbsp;Askell, P.&nbsp;Welinder, P.&nbsp;F. Christiano, J.&nbsp;Leike, and R.&nbsp;Lowe,
“Training language models to follow instructions with human feedback,”
<em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2203.02155, 2022.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
J.&nbsp;Wei, M.&nbsp;Bosma, V.&nbsp;Y. Zhao, K.&nbsp;Guu, A.&nbsp;W. Yu, B.&nbsp;Lester, N.&nbsp;Du, A.&nbsp;M. Dai,
and Q.&nbsp;V. Le, “Finetuned language models are zero-shot learners,” in
<em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR
2022, Virtual Event, April 25-29, 2022</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2022.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
R.&nbsp;Thoppilan, D.&nbsp;D. Freitas, J.&nbsp;Hall, N.&nbsp;Shazeer, A.&nbsp;Kulshreshtha, H.&nbsp;Cheng,
A.&nbsp;Jin, T.&nbsp;Bos, L.&nbsp;Baker, Y.&nbsp;Du, Y.&nbsp;Li, H.&nbsp;Lee, H.&nbsp;S. Zheng, A.&nbsp;Ghafouri,
M.&nbsp;Menegali, Y.&nbsp;Huang, M.&nbsp;Krikun, D.&nbsp;Lepikhin, J.&nbsp;Qin, D.&nbsp;Chen, Y.&nbsp;Xu,
Z.&nbsp;Chen, A.&nbsp;Roberts, M.&nbsp;Bosma, Y.&nbsp;Zhou, C.&nbsp;Chang, I.&nbsp;Krivokon, W.&nbsp;Rusch,
M.&nbsp;Pickett, K.&nbsp;S. Meier-Hellstern, M.&nbsp;R. Morris, T.&nbsp;Doshi, R.&nbsp;D. Santos,
T.&nbsp;Duke, J.&nbsp;Soraker, B.&nbsp;Zevenbergen, V.&nbsp;Prabhakaran, M.&nbsp;Diaz, B.&nbsp;Hutchinson,
K.&nbsp;Olson, A.&nbsp;Molina, E.&nbsp;Hoffman-John, J.&nbsp;Lee, L.&nbsp;Aroyo, R.&nbsp;Rajakumar,
A.&nbsp;Butryna, M.&nbsp;Lamm, V.&nbsp;Kuzmina, J.&nbsp;Fenton, A.&nbsp;Cohen, R.&nbsp;Bernstein,
R.&nbsp;Kurzweil, B.&nbsp;Aguera-Arcas, C.&nbsp;Cui, M.&nbsp;Croak, E.&nbsp;H. Chi, and Q.&nbsp;Le,
“Lamda: Language models for dialog applications,” <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2201.08239, 2022.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
H.&nbsp;W. Chung, L.&nbsp;Hou, S.&nbsp;Longpre, B.&nbsp;Zoph, Y.&nbsp;Tay, W.&nbsp;Fedus, E.&nbsp;Li, X.&nbsp;Wang,
M.&nbsp;Dehghani, S.&nbsp;Brahma, A.&nbsp;Webson, S.&nbsp;S. Gu, Z.&nbsp;Dai, M.&nbsp;Suzgun, X.&nbsp;Chen,
A.&nbsp;Chowdhery, S.&nbsp;Narang, G.&nbsp;Mishra, A.&nbsp;Yu, V.&nbsp;Y. Zhao, Y.&nbsp;Huang, A.&nbsp;M. Dai,
H.&nbsp;Yu, S.&nbsp;Petrov, E.&nbsp;H. Chi, J.&nbsp;Dean, J.&nbsp;Devlin, A.&nbsp;Roberts, D.&nbsp;Zhou, Q.&nbsp;V.
Le, and J.&nbsp;Wei, “Scaling instruction-finetuned language models,”
<em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.11416, 2022.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
A.&nbsp;Srivastava, A.&nbsp;Rastogi, A.&nbsp;Rao, A.&nbsp;A.&nbsp;M. Shoeb, A.&nbsp;Abid, A.&nbsp;Fisch, A.&nbsp;R.
Brown, A.&nbsp;Santoro, A.&nbsp;Gupta, A.&nbsp;Garriga-Alonso, A.&nbsp;Kluska, A.&nbsp;Lewkowycz,
A.&nbsp;Agarwal, A.&nbsp;Power, A.&nbsp;Ray, A.&nbsp;Warstadt, A.&nbsp;W. Kocurek, A.&nbsp;Safaya,
A.&nbsp;Tazarv, A.&nbsp;Xiang, A.&nbsp;Parrish, A.&nbsp;Nie, A.&nbsp;Hussain, A.&nbsp;Askell, A.&nbsp;Dsouza,
A.&nbsp;Rahane, A.&nbsp;S. Iyer, A.&nbsp;Andreassen, A.&nbsp;Santilli, A.&nbsp;Stuhlmüller,
A.&nbsp;M. Dai, A.&nbsp;La, A.&nbsp;K. Lampinen, A.&nbsp;Zou, A.&nbsp;Jiang, A.&nbsp;Chen, A.&nbsp;Vuong,
A.&nbsp;Gupta, A.&nbsp;Gottardi, A.&nbsp;Norelli, A.&nbsp;Venkatesh, A.&nbsp;Gholamidavoodi,
A.&nbsp;Tabassum, A.&nbsp;Menezes, A.&nbsp;Kirubarajan, A.&nbsp;Mullokandov, A.&nbsp;Sabharwal,
A.&nbsp;Herrick, A.&nbsp;Efrat, A.&nbsp;Erdem, A.&nbsp;Karakas, and et&nbsp;al., “Beyond the
imitation game: Quantifying and extrapolating the capabilities of language
models,” <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2206.04615, 2022.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
R.&nbsp;Schaeffer, B.&nbsp;Miranda, and S.&nbsp;Koyejo, “Are emergent abilities of large
language models a mirage?” <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.15004</em>, 2023.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
S.&nbsp;Hu, X.&nbsp;Liu, X.&nbsp;Han, X.&nbsp;Zhang, C.&nbsp;He, W.&nbsp;Zhao, Y.&nbsp;Lin, N.&nbsp;Ding, Z.&nbsp;Ou,
G.&nbsp;Zeng, Z.&nbsp;Liu, and M.&nbsp;Sun, “Unlock predictable scaling from emergent
abilities,” 2023.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
A.&nbsp;Power, Y.&nbsp;Burda, H.&nbsp;Edwards, I.&nbsp;Babuschkin, and V.&nbsp;Misra, “Grokking:
Generalization beyond overfitting on small algorithmic datasets,”
<em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.02177</em>, 2022.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
J.&nbsp;Rasley, S.&nbsp;Rajbhandari, O.&nbsp;Ruwase, and Y.&nbsp;He, “Deepspeed: System
optimizations enable training deep learning models with over 100 billion
parameters,” in <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">KDD</em>, 2020, pp. 3505–3506.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
M.&nbsp;Shoeybi, M.&nbsp;Patwary, R.&nbsp;Puri, P.&nbsp;LeGresley, J.&nbsp;Casper, and B.&nbsp;Catanzaro,
“Megatron-lm: Training multi-billion parameter language models using model
parallelism,” <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1909.08053, 2019.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
D.&nbsp;Narayanan, M.&nbsp;Shoeybi, J.&nbsp;Casper, P.&nbsp;LeGresley, M.&nbsp;Patwary, V.&nbsp;Korthikanti,
D.&nbsp;Vainbrand, P.&nbsp;Kashinkunti, J.&nbsp;Bernauer, B.&nbsp;Catanzaro, A.&nbsp;Phanishayee, and
M.&nbsp;Zaharia, “Efficient large-scale language model training on GPU clusters
using megatron-lm,” in <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">International Conference for High Performance
Computing, Networking, Storage and Analysis, SC 2021, St. Louis, Missouri,
USA, November 14-19, 2021</em>.&nbsp;&nbsp;&nbsp;ACM,
2021, p.&nbsp;58.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
V.&nbsp;Korthikanti, J.&nbsp;Casper, S.&nbsp;Lym, L.&nbsp;McAfee, M.&nbsp;Andersch, M.&nbsp;Shoeybi, and
B.&nbsp;Catanzaro, “Reducing activation recomputation in large transformer
models,” <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2205.05198, 2022.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
T.&nbsp;L. Scao, A.&nbsp;Fan, C.&nbsp;Akiki, E.&nbsp;Pavlick, S.&nbsp;Ilic, D.&nbsp;Hesslow,
R.&nbsp;Castagné, A.&nbsp;S. Luccioni, F.&nbsp;Yvon, M.&nbsp;Gallé, J.&nbsp;Tow, A.&nbsp;M.
Rush, S.&nbsp;Biderman, A.&nbsp;Webson, P.&nbsp;S. Ammanamanchi, T.&nbsp;Wang, B.&nbsp;Sagot,
N.&nbsp;Muennighoff, A.&nbsp;V. del Moral, O.&nbsp;Ruwase, R.&nbsp;Bawden, S.&nbsp;Bekman,
A.&nbsp;McMillan-Major, I.&nbsp;Beltagy, H.&nbsp;Nguyen, L.&nbsp;Saulnier, S.&nbsp;Tan, P.&nbsp;O.
Suarez, V.&nbsp;Sanh, H.&nbsp;Laurençon, Y.&nbsp;Jernite, J.&nbsp;Launay, M.&nbsp;Mitchell,
C.&nbsp;Raffel, A.&nbsp;Gokaslan, A.&nbsp;Simhi, A.&nbsp;Soroa, A.&nbsp;F. Aji, A.&nbsp;Alfassy, A.&nbsp;Rogers,
A.&nbsp;K. Nitzav, C.&nbsp;Xu, C.&nbsp;Mou, C.&nbsp;Emezue, C.&nbsp;Klamm, C.&nbsp;Leong, D.&nbsp;van Strien,
D.&nbsp;I. Adelani, and et&nbsp;al., “BLOOM: A 176b-parameter open-access
multilingual language model,” <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.05100, 2022.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
P.&nbsp;F. Christiano, J.&nbsp;Leike, T.&nbsp;B. Brown, M.&nbsp;Martic, S.&nbsp;Legg, and D.&nbsp;Amodei,
“Deep reinforcement learning from human preferences,” in <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">Advances in
Neural Information Processing Systems 30: Annual Conference on Neural
Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA,
USA</em>, I.&nbsp;Guyon, U.&nbsp;von Luxburg, S.&nbsp;Bengio, H.&nbsp;M. Wallach, R.&nbsp;Fergus,
S.&nbsp;V.&nbsp;N. Vishwanathan, and R.&nbsp;Garnett, Eds., 2017, pp. 4299–4307.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
T.&nbsp;Schick, J.&nbsp;Dwivedi-Yu, R.&nbsp;Dessì, R.&nbsp;Raileanu, M.&nbsp;Lomeli,
L.&nbsp;Zettlemoyer, N.&nbsp;Cancedda, and T.&nbsp;Scialom, “Toolformer: Language models
can teach themselves to use tools,” <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.04761, 2023.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
R.&nbsp;Nakano, J.&nbsp;Hilton, S.&nbsp;Balaji, J.&nbsp;Wu, L.&nbsp;Ouyang, C.&nbsp;Kim, C.&nbsp;Hesse, S.&nbsp;Jain,
V.&nbsp;Kosaraju, W.&nbsp;Saunders, X.&nbsp;Jiang, K.&nbsp;Cobbe, T.&nbsp;Eloundou, G.&nbsp;Krueger,
K.&nbsp;Button, M.&nbsp;Knight, B.&nbsp;Chess, and J.&nbsp;Schulman, “Webgpt: Browser-assisted
question-answering with human feedback,” <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2112.09332,
2021.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
C.&nbsp;Raffel, N.&nbsp;Shazeer, A.&nbsp;Roberts, K.&nbsp;Lee, S.&nbsp;Narang, M.&nbsp;Matena, Y.&nbsp;Zhou,
W.&nbsp;Li, and P.&nbsp;J. Liu, “Exploring the limits of transfer learning with a
unified text-to-text transformer,” <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, pp.
140:1–140:67, 2020.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
L.&nbsp;Xue, N.&nbsp;Constant, A.&nbsp;Roberts, M.&nbsp;Kale, R.&nbsp;Al-Rfou, A.&nbsp;Siddhant, A.&nbsp;Barua,
and C.&nbsp;Raffel, “mt5: A massively multilingual pre-trained text-to-text
transformer,” in <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021</em>, 2021, pp.
483–498.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
W.&nbsp;Zeng, X.&nbsp;Ren, T.&nbsp;Su, H.&nbsp;Wang, Y.&nbsp;Liao, Z.&nbsp;Wang, X.&nbsp;Jiang, Z.&nbsp;Yang, K.&nbsp;Wang,
X.&nbsp;Zhang, C.&nbsp;Li, Z.&nbsp;Gong, Y.&nbsp;Yao, X.&nbsp;Huang, J.&nbsp;Wang, J.&nbsp;Yu, Q.&nbsp;Guo, Y.&nbsp;Yu,
Y.&nbsp;Zhang, J.&nbsp;Wang, H.&nbsp;Tao, D.&nbsp;Yan, Z.&nbsp;Yi, F.&nbsp;Peng, F.&nbsp;Jiang, H.&nbsp;Zhang,
L.&nbsp;Deng, Y.&nbsp;Zhang, Z.&nbsp;Lin, C.&nbsp;Zhang, S.&nbsp;Zhang, M.&nbsp;Guo, S.&nbsp;Gu, G.&nbsp;Fan,
Y.&nbsp;Wang, X.&nbsp;Jin, Q.&nbsp;Liu, and Y.&nbsp;Tian, “Pangu-<math id="bib.bib84.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="bib.bib84.1.m1.1a"><mi id="bib.bib84.1.m1.1.1" xref="bib.bib84.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="bib.bib84.1.m1.1b"><ci id="bib.bib84.1.m1.1.1.cmml" xref="bib.bib84.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib84.1.m1.1c">\alpha</annotation></semantics></math>: Large-scale
autoregressive pretrained chinese language models with auto-parallel
computation,” <em id="bib.bib84.2.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2104.12369, 2021.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Z.&nbsp;Zhang, Y.&nbsp;Gu, X.&nbsp;Han, S.&nbsp;Chen, C.&nbsp;Xiao, Z.&nbsp;Sun, Y.&nbsp;Yao, F.&nbsp;Qi, J.&nbsp;Guan,
P.&nbsp;Ke, Y.&nbsp;Cai, G.&nbsp;Zeng, Z.&nbsp;Tan, Z.&nbsp;Liu, M.&nbsp;Huang, W.&nbsp;Han, Y.&nbsp;Liu, X.&nbsp;Zhu, and
M.&nbsp;Sun, “CPM-2: large-scale cost-effective pre-trained language models,”
<em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2106.10715, 2021.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
E.&nbsp;Nijkamp, B.&nbsp;Pang, H.&nbsp;Hayashi, L.&nbsp;Tu, H.&nbsp;Wang, Y.&nbsp;Zhou, S.&nbsp;Savarese, and
C.&nbsp;Xiong, “Codegen: An open large language model for code with mtulti-turn
program synthesis,” <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.13474</em>, 2022.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
S.&nbsp;Black, S.&nbsp;Biderman, E.&nbsp;Hallahan, Q.&nbsp;Anthony, L.&nbsp;Gao, L.&nbsp;Golding, H.&nbsp;He,
C.&nbsp;Leahy, K.&nbsp;McDonell, J.&nbsp;Phang, M.&nbsp;Pieler, U.&nbsp;S. Prashanth, S.&nbsp;Purohit,
L.&nbsp;Reynolds, J.&nbsp;Tow, B.&nbsp;Wang, and S.&nbsp;Weinbach, “Gpt-neox-20b: An open-source
autoregressive language model,” <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2204.06745, 2022.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wang, S.&nbsp;Mishra, P.&nbsp;Alipoormolabashi, Y.&nbsp;Kordi, A.&nbsp;Mirzaei, A.&nbsp;Naik,
A.&nbsp;Ashok, A.&nbsp;S. Dhanasekaran, A.&nbsp;Arunkumar, D.&nbsp;Stap, E.&nbsp;Pathak,
G.&nbsp;Karamanolakis, H.&nbsp;G. Lai, I.&nbsp;Purohit, I.&nbsp;Mondal, J.&nbsp;Anderson, K.&nbsp;Kuznia,
K.&nbsp;Doshi, K.&nbsp;K. Pal, M.&nbsp;Patel, M.&nbsp;Moradshahi, M.&nbsp;Parmar, M.&nbsp;Purohit,
N.&nbsp;Varshney, P.&nbsp;R. Kaza, P.&nbsp;Verma, R.&nbsp;S. Puri, R.&nbsp;Karia, S.&nbsp;Doshi, S.&nbsp;K.
Sampat, S.&nbsp;Mishra, S.&nbsp;R. A, S.&nbsp;Patro, T.&nbsp;Dixit, and X.&nbsp;Shen,
“Super-naturalinstructions: Generalization via declarative instructions on
1600+ NLP tasks,” in <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical
Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab
Emirates, December 7-11, 2022</em>, 2022, pp. 5085–5109.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Y.&nbsp;Tay, M.&nbsp;Dehghani, V.&nbsp;Q. Tran, X.&nbsp;García, J.&nbsp;Wei, X.&nbsp;Wang, H.&nbsp;W. Chung,
D.&nbsp;Bahri, T.&nbsp;Schuster, H.&nbsp;Zheng, D.&nbsp;Zhou, N.&nbsp;Houlsby, and D.&nbsp;Metzler, “Ul2:
Unifying language learning paradigms,” 2022.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
S.&nbsp;Zhang, S.&nbsp;Roller, N.&nbsp;Goyal, M.&nbsp;Artetxe, M.&nbsp;Chen, S.&nbsp;Chen, C.&nbsp;Dewan, M.&nbsp;T.
Diab, X.&nbsp;Li, X.&nbsp;V. Lin, T.&nbsp;Mihaylov, M.&nbsp;Ott, S.&nbsp;Shleifer, K.&nbsp;Shuster,
D.&nbsp;Simig, P.&nbsp;S. Koura, A.&nbsp;Sridhar, T.&nbsp;Wang, and L.&nbsp;Zettlemoyer, “OPT: open
pre-trained transformer language models,” <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2205.01068,
2022.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
M.&nbsp;R. Costa-jussà, J.&nbsp;Cross, O.&nbsp;Çelebi, M.&nbsp;Elbayad, K.&nbsp;Heafield,
K.&nbsp;Heffernan, E.&nbsp;Kalbassi, J.&nbsp;Lam, D.&nbsp;Licht, J.&nbsp;Maillard, A.&nbsp;Sun, S.&nbsp;Wang,
G.&nbsp;Wenzek, A.&nbsp;Youngblood, B.&nbsp;Akula, L.&nbsp;Barrault, G.&nbsp;M. Gonzalez, P.&nbsp;Hansanti,
J.&nbsp;Hoffman, S.&nbsp;Jarrett, K.&nbsp;R. Sadagopan, D.&nbsp;Rowe, S.&nbsp;Spruit, C.&nbsp;Tran,
P.&nbsp;Andrews, N.&nbsp;F. Ayan, S.&nbsp;Bhosale, S.&nbsp;Edunov, A.&nbsp;Fan, C.&nbsp;Gao, V.&nbsp;Goswami,
F.&nbsp;Guzmán, P.&nbsp;Koehn, A.&nbsp;Mourachko, C.&nbsp;Ropers, S.&nbsp;Saleem, H.&nbsp;Schwenk,
and J.&nbsp;Wang, “No language left behind: Scaling human-centered machine
translation,” <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2207.04672, 2022.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Q.&nbsp;Zheng, X.&nbsp;Xia, X.&nbsp;Zou, Y.&nbsp;Dong, S.&nbsp;Wang, Y.&nbsp;Xue, Z.&nbsp;Wang, L.&nbsp;Shen, A.&nbsp;Wang,
Y.&nbsp;Li <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Codegeex: A pre-trained model for code generation with
multilingual evaluations on humaneval-x,” <em id="bib.bib92.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2303.17568</em>, 2023.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
A.&nbsp;Zeng, X.&nbsp;Liu, Z.&nbsp;Du, Z.&nbsp;Wang, H.&nbsp;Lai, M.&nbsp;Ding, Z.&nbsp;Yang, Y.&nbsp;Xu, W.&nbsp;Zheng,
X.&nbsp;Xia, W.&nbsp;L. Tam, Z.&nbsp;Ma, Y.&nbsp;Xue, J.&nbsp;Zhai, W.&nbsp;Chen, P.&nbsp;Zhang, Y.&nbsp;Dong, and
J.&nbsp;Tang, “GLM-130B: an open bilingual pre-trained model,” vol.
abs/2210.02414, 2022.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
N.&nbsp;Muennighoff, T.&nbsp;Wang, L.&nbsp;Sutawika, A.&nbsp;Roberts, S.&nbsp;Biderman, T.&nbsp;L. Scao,
M.&nbsp;S. Bari, S.&nbsp;Shen, Z.&nbsp;X. Yong, H.&nbsp;Schoelkopf, X.&nbsp;Tang, D.&nbsp;Radev, A.&nbsp;F. Aji,
K.&nbsp;Almubarak, S.&nbsp;Albanie, Z.&nbsp;Alyafeai, A.&nbsp;Webson, E.&nbsp;Raff, and C.&nbsp;Raffel,
“Crosslingual generalization through multitask finetuning,” <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2211.01786, 2022.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
S.&nbsp;Iyer, X.&nbsp;V. Lin, R.&nbsp;Pasunuru, T.&nbsp;Mihaylov, D.&nbsp;Simig, P.&nbsp;Yu, K.&nbsp;Shuster,
T.&nbsp;Wang, Q.&nbsp;Liu, P.&nbsp;S. Koura, X.&nbsp;Li, B.&nbsp;O’Horo, G.&nbsp;Pereyra, J.&nbsp;Wang,
C.&nbsp;Dewan, A.&nbsp;Celikyilmaz, L.&nbsp;Zettlemoyer, and V.&nbsp;Stoyanov, “OPT-IML:
scaling language model instruction meta learning through the lens of
generalization,” <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.12017, 2022.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
S.&nbsp;Biderman, H.&nbsp;Schoelkopf, Q.&nbsp;Anthony, H.&nbsp;Bradley, K.&nbsp;O’Brien, E.&nbsp;Hallahan,
M.&nbsp;A. Khan, S.&nbsp;Purohit, U.&nbsp;S. Prashanth, E.&nbsp;Raff <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Pythia: A
suite for analyzing large language models across training and scaling,”
<em id="bib.bib96.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.01373</em>, 2023.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
E.&nbsp;Nijkamp, H.&nbsp;Hayashi, C.&nbsp;Xiong, S.&nbsp;Savarese, and Y.&nbsp;Zhou, “Codegen2: Lessons
for training llms on programming and natural languages,” <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.02309, 2023.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
R.&nbsp;Li, L.&nbsp;B. Allal, Y.&nbsp;Zi, N.&nbsp;Muennighoff, D.&nbsp;Kocetkov, C.&nbsp;Mou, M.&nbsp;Marone,
C.&nbsp;Akiki, J.&nbsp;Li, J.&nbsp;Chim, Q.&nbsp;Liu, E.&nbsp;Zheltonozhskii, T.&nbsp;Y. Zhuo, T.&nbsp;Wang,
O.&nbsp;Dehaene, M.&nbsp;Davaadorj, J.&nbsp;Lamy-Poirier, J.&nbsp;Monteiro, O.&nbsp;Shliazhko,
N.&nbsp;Gontier, N.&nbsp;Meade, A.&nbsp;Zebaze, M.&nbsp;Yee, L.&nbsp;K. Umapathi, J.&nbsp;Zhu, B.&nbsp;Lipkin,
M.&nbsp;Oblokulov, Z.&nbsp;Wang, R.&nbsp;M. V, J.&nbsp;Stillerman, S.&nbsp;S. Patel, D.&nbsp;Abulkhanov,
M.&nbsp;Zocca, M.&nbsp;Dey, Z.&nbsp;Zhang, N.&nbsp;Fahmy, U.&nbsp;Bhattacharyya, W.&nbsp;Yu, S.&nbsp;Singh,
S.&nbsp;Luccioni, P.&nbsp;Villegas, M.&nbsp;Kunakov, F.&nbsp;Zhdanov, M.&nbsp;Romero, T.&nbsp;Lee,
N.&nbsp;Timor, J.&nbsp;Ding, C.&nbsp;Schlesinger, H.&nbsp;Schoelkopf, J.&nbsp;Ebert, T.&nbsp;Dao,
M.&nbsp;Mishra, A.&nbsp;Gu, J.&nbsp;Robinson, C.&nbsp;J. Anderson, B.&nbsp;Dolan-Gavitt,
D.&nbsp;Contractor, S.&nbsp;Reddy, D.&nbsp;Fried, D.&nbsp;Bahdanau, Y.&nbsp;Jernite, C.&nbsp;M. Ferrandis,
S.&nbsp;Hughes, T.&nbsp;Wolf, A.&nbsp;Guha, L.&nbsp;von Werra, and H.&nbsp;de&nbsp;Vries, “Starcoder: may
the source be with you!” <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.06161, 2023. [Online].
Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2305.06161" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.06161</a>

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
H.&nbsp;Touvron, L.&nbsp;Martin, K.&nbsp;Stone, P.&nbsp;Albert, A.&nbsp;Almahairi, Y.&nbsp;Babaei,
N.&nbsp;Bashlykov, S.&nbsp;Batra, P.&nbsp;Bhargava, S.&nbsp;Bhosale <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Llama 2:
Open foundation and fine-tuned chat models,” <em id="bib.bib99.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2307.09288</em>, 2023.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
A.&nbsp;Yang, B.&nbsp;Xiao, B.&nbsp;Wang, B.&nbsp;Zhang, C.&nbsp;Yin, C.&nbsp;Lv, D.&nbsp;Pan, D.&nbsp;Wang, D.&nbsp;Yan,
F.&nbsp;Yang <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Baichuan 2: Open large-scale language models,”
<em id="bib.bib100.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.10305</em>, 2023.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
J.&nbsp;Bai, S.&nbsp;Bai, Y.&nbsp;Chu, Z.&nbsp;Cui, K.&nbsp;Dang, X.&nbsp;Deng, Y.&nbsp;Fan, W.&nbsp;Ge, Y.&nbsp;Han,
F.&nbsp;Huang <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Qwen technical report,” <em id="bib.bib101.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2309.16609</em>, 2023.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
X.&nbsp;Li, Y.&nbsp;Yao, X.&nbsp;Jiang, X.&nbsp;Fang, X.&nbsp;Meng, S.&nbsp;Fan, P.&nbsp;Han, J.&nbsp;Li, L.&nbsp;Du, B.&nbsp;Qin
<em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Flm-101b: An open llm and how to train it with $100 k
budget,” <em id="bib.bib102.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.03852</em>, 2023.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
T.&nbsp;Wei, L.&nbsp;Zhao, L.&nbsp;Zhang, B.&nbsp;Zhu, L.&nbsp;Wang, H.&nbsp;Yang, B.&nbsp;Li, C.&nbsp;Cheng,
W.&nbsp;Lü, R.&nbsp;Hu <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Skywork: A more open bilingual foundation
model,” <em id="bib.bib103.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.19341</em>, 2023.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
D.&nbsp;Lepikhin, H.&nbsp;Lee, Y.&nbsp;Xu, D.&nbsp;Chen, O.&nbsp;Firat, Y.&nbsp;Huang, M.&nbsp;Krikun, N.&nbsp;Shazeer,
and Z.&nbsp;Chen, “Gshard: Scaling giant models with conditional computation and
automatic sharding,” in <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">9th International Conference on Learning
Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>, 2021.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
M.&nbsp;Chen, J.&nbsp;Tworek, H.&nbsp;Jun, Q.&nbsp;Yuan, H.&nbsp;P. de&nbsp;Oliveira&nbsp;Pinto, J.&nbsp;Kaplan,
H.&nbsp;Edwards, Y.&nbsp;Burda, N.&nbsp;Joseph, G.&nbsp;Brockman, A.&nbsp;Ray, R.&nbsp;Puri, G.&nbsp;Krueger,
M.&nbsp;Petrov, H.&nbsp;Khlaaf, G.&nbsp;Sastry, P.&nbsp;Mishkin, B.&nbsp;Chan, S.&nbsp;Gray, N.&nbsp;Ryder,
M.&nbsp;Pavlov, A.&nbsp;Power, L.&nbsp;Kaiser, M.&nbsp;Bavarian, C.&nbsp;Winter, P.&nbsp;Tillet, F.&nbsp;P.
Such, D.&nbsp;Cummings, M.&nbsp;Plappert, F.&nbsp;Chantzis, E.&nbsp;Barnes, A.&nbsp;Herbert-Voss,
W.&nbsp;H. Guss, A.&nbsp;Nichol, A.&nbsp;Paino, N.&nbsp;Tezak, J.&nbsp;Tang, I.&nbsp;Babuschkin, S.&nbsp;Balaji,
S.&nbsp;Jain, W.&nbsp;Saunders, C.&nbsp;Hesse, A.&nbsp;N. Carr, J.&nbsp;Leike, J.&nbsp;Achiam, V.&nbsp;Misra,
E.&nbsp;Morikawa, A.&nbsp;Radford, M.&nbsp;Knight, M.&nbsp;Brundage, M.&nbsp;Murati, K.&nbsp;Mayer,
P.&nbsp;Welinder, B.&nbsp;McGrew, D.&nbsp;Amodei, S.&nbsp;McCandlish, I.&nbsp;Sutskever, and
W.&nbsp;Zaremba, “Evaluating large language models trained on code,”
<em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2107.03374, 2021.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
Y.&nbsp;Sun, S.&nbsp;Wang, S.&nbsp;Feng, S.&nbsp;Ding, C.&nbsp;Pang, J.&nbsp;Shang, J.&nbsp;Liu, X.&nbsp;Chen, Y.&nbsp;Zhao,
Y.&nbsp;Lu, W.&nbsp;Liu, Z.&nbsp;Wu, W.&nbsp;Gong, J.&nbsp;Liang, Z.&nbsp;Shang, P.&nbsp;Sun, W.&nbsp;Liu, X.&nbsp;Ouyang,
D.&nbsp;Yu, H.&nbsp;Tian, H.&nbsp;Wu, and H.&nbsp;Wang, “ERNIE 3.0: Large-scale knowledge
enhanced pre-training for language understanding and generation,”
<em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2107.02137, 2021.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
O.&nbsp;Lieber, O.&nbsp;Sharir, B.&nbsp;Lenz, and Y.&nbsp;Shoham, “Jurassic-1: Technical details
and evaluation,” <em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">White Paper. AI21 Labs</em>, vol.&nbsp;1, 2021.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
B.&nbsp;Kim, H.&nbsp;Kim, S.&nbsp;Lee, G.&nbsp;Lee, D.&nbsp;Kwak, D.&nbsp;H. Jeon, S.&nbsp;Park, S.&nbsp;Kim, S.&nbsp;Kim,
D.&nbsp;Seo, H.&nbsp;Lee, M.&nbsp;Jeong, S.&nbsp;Lee, M.&nbsp;Kim, S.&nbsp;Ko, S.&nbsp;Kim, T.&nbsp;Park, J.&nbsp;Kim,
S.&nbsp;Kang, N.&nbsp;Ryu, K.&nbsp;M. Yoo, M.&nbsp;Chang, S.&nbsp;Suh, S.&nbsp;In, J.&nbsp;Park, K.&nbsp;Kim, H.&nbsp;Kim,
J.&nbsp;Jeong, Y.&nbsp;G. Yeo, D.&nbsp;Ham, D.&nbsp;Park, M.&nbsp;Y. Lee, J.&nbsp;Kang, I.&nbsp;Kang, J.&nbsp;Ha,
W.&nbsp;Park, and N.&nbsp;Sung, “What changes can large-scale language models bring?
intensive study on hyperclova: Billions-scale korean generative pretrained
transformers,” in <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical
Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta
Cana, Dominican Republic, 7-11 November, 2021</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
S.&nbsp;Wu, X.&nbsp;Zhao, T.&nbsp;Yu, R.&nbsp;Zhang, C.&nbsp;Shen, H.&nbsp;Liu, F.&nbsp;Li, H.&nbsp;Zhu, J.&nbsp;Luo, L.&nbsp;Xu
<em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Yuan 1.0: Large-scale pre-trained language model in
zero-shot and few-shot learning,” <em id="bib.bib109.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.04725</em>,
2021.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
A.&nbsp;Askell, Y.&nbsp;Bai, A.&nbsp;Chen, D.&nbsp;Drain, D.&nbsp;Ganguli, T.&nbsp;Henighan, A.&nbsp;Jones,
N.&nbsp;Joseph, B.&nbsp;Mann, N.&nbsp;DasSarma, N.&nbsp;Elhage, Z.&nbsp;Hatfield-Dodds,
D.&nbsp;Hernandez, J.&nbsp;Kernion, K.&nbsp;Ndousse, C.&nbsp;Olsson, D.&nbsp;Amodei, T.&nbsp;B. Brown,
J.&nbsp;Clark, S.&nbsp;McCandlish, C.&nbsp;Olah, and J.&nbsp;Kaplan, “A general language
assistant as a laboratory for alignment,” <em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2112.00861,
2021.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
S.&nbsp;Wang, Y.&nbsp;Sun, Y.&nbsp;Xiang, Z.&nbsp;Wu, S.&nbsp;Ding, W.&nbsp;Gong, S.&nbsp;Feng, J.&nbsp;Shang, Y.&nbsp;Zhao,
C.&nbsp;Pang, J.&nbsp;Liu, X.&nbsp;Chen, Y.&nbsp;Lu, W.&nbsp;Liu, X.&nbsp;Wang, Y.&nbsp;Bai, Q.&nbsp;Chen, L.&nbsp;Zhao,
S.&nbsp;Li, P.&nbsp;Sun, D.&nbsp;Yu, Y.&nbsp;Ma, H.&nbsp;Tian, H.&nbsp;Wu, T.&nbsp;Wu, W.&nbsp;Zeng, G.&nbsp;Li, W.&nbsp;Gao,
and H.&nbsp;Wang, “ERNIE 3.0 titan: Exploring larger-scale knowledge enhanced
pre-training for language understanding and generation,” <em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2112.12731, 2021.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
N.&nbsp;Du, Y.&nbsp;Huang, A.&nbsp;M. Dai, S.&nbsp;Tong, D.&nbsp;Lepikhin, Y.&nbsp;Xu, M.&nbsp;Krikun, Y.&nbsp;Zhou,
A.&nbsp;W. Yu, O.&nbsp;Firat, B.&nbsp;Zoph, L.&nbsp;Fedus, M.&nbsp;P. Bosma, Z.&nbsp;Zhou, T.&nbsp;Wang, Y.&nbsp;E.
Wang, K.&nbsp;Webster, M.&nbsp;Pellat, K.&nbsp;Robinson, K.&nbsp;S. Meier-Hellstern, T.&nbsp;Duke,
L.&nbsp;Dixon, K.&nbsp;Zhang, Q.&nbsp;V. Le, Y.&nbsp;Wu, Z.&nbsp;Chen, and C.&nbsp;Cui, “Glam: Efficient
scaling of language models with mixture-of-experts,” in <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore,
Maryland, USA</em>, 2022, pp. 5547–5569.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
S.&nbsp;Smith, M.&nbsp;Patwary, B.&nbsp;Norick, P.&nbsp;LeGresley, S.&nbsp;Rajbhandari, J.&nbsp;Casper,
Z.&nbsp;Liu, S.&nbsp;Prabhumoye, G.&nbsp;Zerveas, V.&nbsp;Korthikanti, E.&nbsp;Zheng, R.&nbsp;Child, R.&nbsp;Y.
Aminabadi, J.&nbsp;Bernauer, X.&nbsp;Song, M.&nbsp;Shoeybi, Y.&nbsp;He, M.&nbsp;Houston, S.&nbsp;Tiwary,
and B.&nbsp;Catanzaro, “Using deepspeed and megatron to train megatron-turing
NLG 530b, A large-scale generative language model,” <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2201.11990, 2022.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
Y.&nbsp;Li, D.&nbsp;H. Choi, J.&nbsp;Chung, N.&nbsp;Kushman, J.&nbsp;Schrittwieser, R.&nbsp;Leblond,
T.&nbsp;Eccles, J.&nbsp;Keeling, F.&nbsp;Gimeno, A.&nbsp;D. Lago, T.&nbsp;Hubert, P.&nbsp;Choy,
C.&nbsp;de&nbsp;Masson&nbsp;d’Autume, I.&nbsp;Babuschkin, X.&nbsp;Chen, P.&nbsp;Huang, J.&nbsp;Welbl, S.&nbsp;Gowal,
A.&nbsp;Cherepanov, J.&nbsp;Molloy, D.&nbsp;J. Mankowitz, E.&nbsp;S. Robson, P.&nbsp;Kohli,
N.&nbsp;de&nbsp;Freitas, K.&nbsp;Kavukcuoglu, and O.&nbsp;Vinyals, “Competition-level code
generation with alphacode,” <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Science</em>, 2022.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
S.&nbsp;Soltan, S.&nbsp;Ananthakrishnan, J.&nbsp;FitzGerald, R.&nbsp;Gupta, W.&nbsp;Hamza, H.&nbsp;Khan,
C.&nbsp;Peris, S.&nbsp;Rawls, A.&nbsp;Rosenbaum, A.&nbsp;Rumshisky, C.&nbsp;S. Prakash, M.&nbsp;Sridhar,
F.&nbsp;Triefenbach, A.&nbsp;Verma, G.&nbsp;Tür, and P.&nbsp;Natarajan, “Alexatm 20b:
Few-shot learning using a large-scale multilingual seq2seq model,”
<em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2208.01448, 2022.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
A.&nbsp;Glaese, N.&nbsp;McAleese, M.&nbsp;Trebacz, J.&nbsp;Aslanides, V.&nbsp;Firoiu, T.&nbsp;Ewalds,
M.&nbsp;Rauh, L.&nbsp;Weidinger, M.&nbsp;Chadwick, P.&nbsp;Thacker, L.&nbsp;Campbell-Gillingham,
J.&nbsp;Uesato, P.&nbsp;Huang, R.&nbsp;Comanescu, F.&nbsp;Yang, A.&nbsp;See, S.&nbsp;Dathathri, R.&nbsp;Greig,
C.&nbsp;Chen, D.&nbsp;Fritz, J.&nbsp;S. Elias, R.&nbsp;Green, S.&nbsp;Mokrá, N.&nbsp;Fernando, B.&nbsp;Wu,
R.&nbsp;Foley, S.&nbsp;Young, I.&nbsp;Gabriel, W.&nbsp;Isaac, J.&nbsp;Mellor, D.&nbsp;Hassabis,
K.&nbsp;Kavukcuoglu, L.&nbsp;A. Hendricks, and G.&nbsp;Irving, “Improving alignment of
dialogue agents via targeted human judgements,” <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2209.14375, 2022.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
H.&nbsp;Su, X.&nbsp;Zhou, H.&nbsp;Yu, Y.&nbsp;Chen, Z.&nbsp;Zhu, Y.&nbsp;Yu, and J.&nbsp;Zhou, “Welm: A
well-read pre-trained language model for chinese,” <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2209.10372, 2022.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
Y.&nbsp;Tay, J.&nbsp;Wei, H.&nbsp;W. Chung, V.&nbsp;Q. Tran, D.&nbsp;R. So, S.&nbsp;Shakeri, X.&nbsp;Garcia, H.&nbsp;S.
Zheng, J.&nbsp;Rao, A.&nbsp;Chowdhery, D.&nbsp;Zhou, D.&nbsp;Metzler, S.&nbsp;Petrov, N.&nbsp;Houlsby,
Q.&nbsp;V. Le, and M.&nbsp;Dehghani, “Transcending scaling laws with 0.1% extra
compute,” <em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.11399, 2022.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
X.&nbsp;Ren, P.&nbsp;Zhou, X.&nbsp;Meng, X.&nbsp;Huang, Y.&nbsp;Wang, W.&nbsp;Wang, P.&nbsp;Li, X.&nbsp;Zhang,
A.&nbsp;Podolskiy, G.&nbsp;Arshinov, A.&nbsp;Bout, I.&nbsp;Piontkovskaya, J.&nbsp;Wei, X.&nbsp;Jiang,
T.&nbsp;Su, Q.&nbsp;Liu, and J.&nbsp;Yao, “Pangu-<math id="bib.bib119.1.m1.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="bib.bib119.1.m1.1a"><mi mathvariant="normal" id="bib.bib119.1.m1.1.1" xref="bib.bib119.1.m1.1.1.cmml">Σ</mi><annotation-xml encoding="MathML-Content" id="bib.bib119.1.m1.1b"><ci id="bib.bib119.1.m1.1.1.cmml" xref="bib.bib119.1.m1.1.1">Σ</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib119.1.m1.1c">\Sigma</annotation></semantics></math>: Towards trillion parameter
language model with sparse heterogeneous computing,” <em id="bib.bib119.2.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2303.10845, 2023.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
R.&nbsp;Anil, A.&nbsp;M. Dai, O.&nbsp;Firat, M.&nbsp;Johnson, D.&nbsp;Lepikhin, A.&nbsp;Passos, S.&nbsp;Shakeri,
E.&nbsp;Taropa, P.&nbsp;Bailey, Z.&nbsp;Chen <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Palm 2 technical report,”
<em id="bib.bib120.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.10403</em>, 2023.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
A.&nbsp;Radford, R.&nbsp;Józefowicz, and I.&nbsp;Sutskever, “Learning to generate
reviews and discovering sentiment,” <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1704.01444, 2017.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
A.&nbsp;Radford, K.&nbsp;Narasimhan, T.&nbsp;Salimans, I.&nbsp;Sutskever <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Improving
language understanding by generative pre-training,” 2018.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
B.&nbsp;McCann, N.&nbsp;S. Keskar, C.&nbsp;Xiong, and R.&nbsp;Socher, “The natural language
decathlon: Multitask learning as question answering,” <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/1806.08730, 2018.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhang, S.&nbsp;Sun, M.&nbsp;Galley, Y.&nbsp;Chen, C.&nbsp;Brockett, X.&nbsp;Gao, J.&nbsp;Gao, J.&nbsp;Liu, and
B.&nbsp;Dolan, “DIALOGPT : Large-scale generative pre-training for
conversational response generation,” in <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics: System
Demonstrations, ACL 2020, Online, July 5-10, 2020</em>, A.&nbsp;Celikyilmaz and
T.&nbsp;Wen, Eds.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2020, pp. 270–278.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
D.&nbsp;Ham, J.&nbsp;Lee, Y.&nbsp;Jang, and K.&nbsp;Kim, “End-to-end neural pipeline for
goal-oriented dialogue systems using GPT-2,” in <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
58th Annual Meeting of the Association for Computational Linguistics, ACL
2020, Online, July 5-10, 2020</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2020, pp. 583–592.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
I.&nbsp;Drori, S.&nbsp;Tran, R.&nbsp;Wang, N.&nbsp;Cheng, K.&nbsp;Liu, L.&nbsp;Tang, E.&nbsp;Ke, N.&nbsp;Singh, T.&nbsp;L.
Patti, J.&nbsp;Lynch, A.&nbsp;Shporer, N.&nbsp;Verma, E.&nbsp;Wu, and G.&nbsp;Strang, “A neural
network solves and generates mathematics problems by program synthesis:
Calculus, differential equations, linear algebra, and more,” <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2112.15594, 2021.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
A.&nbsp;Neelakantan, T.&nbsp;Xu, R.&nbsp;Puri, A.&nbsp;Radford, J.&nbsp;M. Han, J.&nbsp;Tworek, Q.&nbsp;Yuan,
N.&nbsp;Tezak, J.&nbsp;W. Kim, C.&nbsp;Hallacy, J.&nbsp;Heidecke, P.&nbsp;Shyam, B.&nbsp;Power, T.&nbsp;E.
Nekoul, G.&nbsp;Sastry, G.&nbsp;Krueger, D.&nbsp;Schnurr, F.&nbsp;P. Such, K.&nbsp;Hsu, M.&nbsp;Thompson,
T.&nbsp;Khan, T.&nbsp;Sherbakov, J.&nbsp;Jang, P.&nbsp;Welinder, and L.&nbsp;Weng, “Text and code
embeddings by contrastive pre-training,” <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2201.10005,
2022.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
J.&nbsp;Schulman, F.&nbsp;Wolski, P.&nbsp;Dhariwal, A.&nbsp;Radford, and O.&nbsp;Klimov, “Proximal
policy optimization algorithms,” <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1707.06347</em>,
2017.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
N.&nbsp;Stiennon, L.&nbsp;Ouyang, J.&nbsp;Wu, D.&nbsp;M. Ziegler, R.&nbsp;Lowe, C.&nbsp;Voss, A.&nbsp;Radford,
D.&nbsp;Amodei, and P.&nbsp;F. Christiano, “Learning to summarize from human
feedback,” <em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2009.01325, 2020.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
OpenAI, “Our approach to alignment research,” <em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">OpenAI Blog</em>, August
2022.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
——, “Introducing chatgpt,” <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">OpenAI Blog</em>, November 2022.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
D.&nbsp;Ganguli, L.&nbsp;Lovitt, J.&nbsp;Kernion, A.&nbsp;Askell, Y.&nbsp;Bai, S.&nbsp;Kadavath, B.&nbsp;Mann,
E.&nbsp;Perez, N.&nbsp;Schiefer, K.&nbsp;Ndousse, A.&nbsp;Jones, S.&nbsp;Bowman, A.&nbsp;Chen, T.&nbsp;Conerly,
N.&nbsp;DasSarma, D.&nbsp;Drain, N.&nbsp;Elhage, S.&nbsp;E. Showk, S.&nbsp;Fort, Z.&nbsp;Hatfield-Dodds,
T.&nbsp;Henighan, D.&nbsp;Hernandez, T.&nbsp;Hume, J.&nbsp;Jacobson, S.&nbsp;Johnston, S.&nbsp;Kravec,
C.&nbsp;Olsson, S.&nbsp;Ringer, E.&nbsp;Tran-Johnson, D.&nbsp;Amodei, T.&nbsp;Brown, N.&nbsp;Joseph,
S.&nbsp;McCandlish, C.&nbsp;Olah, J.&nbsp;Kaplan, and J.&nbsp;Clark, “Red teaming language
models to reduce harms: Methods, scaling behaviors, and lessons learned,”
<em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2209.07858, 2022.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
OpenAI, “Gpt-4v(ision) system card,” <em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">OpenAI</em>, 2023.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
——, “Lessons learned on language model safety and misuse,” <em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">OpenAI
blog</em>, 2022.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
E.&nbsp;Almazrouei, H.&nbsp;Alobeidli, A.&nbsp;Alshamsi, A.&nbsp;Cappelli, R.&nbsp;Cojocaru, M.&nbsp;Debbah,
E.&nbsp;Goffinet, D.&nbsp;Heslow, J.&nbsp;Launay, Q.&nbsp;Malartic, B.&nbsp;Noune, B.&nbsp;Pannier, and
G.&nbsp;Penedo, “Falcon-40B: an open large language model with state-of-the-art
performance,” 2023.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
L.&nbsp;Huawei Technologies&nbsp;Co., “Huawei mindspore ai development framework,” in
<em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence Technology</em>.&nbsp;&nbsp;&nbsp;Springer, 2022, pp. 137–162.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
R.&nbsp;Taori, I.&nbsp;Gulrajani, T.&nbsp;Zhang, Y.&nbsp;Dubois, X.&nbsp;Li, C.&nbsp;Guestrin, P.&nbsp;Liang, and
T.&nbsp;B. Hashimoto, “Stanford alpaca: An instruction-following llama model,”
<a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>, 2023.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
W.-L. Chiang, Z.&nbsp;Li, Z.&nbsp;Lin, Y.&nbsp;Sheng, Z.&nbsp;Wu, H.&nbsp;Zhang, L.&nbsp;Zheng, S.&nbsp;Zhuang,
Y.&nbsp;Zhuang, J.&nbsp;E. Gonzalez, I.&nbsp;Stoica, and E.&nbsp;P. Xing, “Vicuna: An
open-source chatbot impressing gpt-4 with 90%* chatgpt quality,” 2023.
[Online]. Available: <a target="_blank" href="https://vicuna.lmsys.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://vicuna.lmsys.org</a>

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
2023. [Online]. Available:
<a target="_blank" href="https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama</a>

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
Y.&nbsp;You, “Colossalchat: An open-source solution for cloning chatgpt with a
complete rlhf pipeline,” 2023. [Online]. Available:
<a target="_blank" href="https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b</a>

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
G.&nbsp;Penedo, Q.&nbsp;Malartic, D.&nbsp;Hesslow, R.&nbsp;Cojocaru, A.&nbsp;Cappelli, H.&nbsp;Alobeidli,
B.&nbsp;Pannier, E.&nbsp;Almazrouei, and J.&nbsp;Launay, “The RefinedWeb dataset for
Falcon LLM: outperforming curated corpora with web data, and web data
only,” <em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.01116</em>, 2023.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
R.&nbsp;Taori, I.&nbsp;Gulrajani, T.&nbsp;Zhang, Y.&nbsp;Dubois, X.&nbsp;Li, C.&nbsp;Guestrin, P.&nbsp;Liang, and
T.&nbsp;B. Hashimoto, “Stanford alpaca: An instruction-following llama model,”
<a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>, 2023.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wang, Y.&nbsp;Kordi, S.&nbsp;Mishra, A.&nbsp;Liu, N.&nbsp;A. Smith, D.&nbsp;Khashabi, and
H.&nbsp;Hajishirzi, “Self-instruct: Aligning language model with self generated
instructions,” <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.10560, 2022.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
Alpaca-LoRA, “Instruct-tune llama on consumer hardware,”
<a target="_blank" href="https://github.com/tloen/alpaca-lora" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tloen/alpaca-lora</a>, 2023.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
E.&nbsp;J. Hu, Y.&nbsp;Shen, P.&nbsp;Wallis, Z.&nbsp;Allen-Zhu, Y.&nbsp;Li, S.&nbsp;Wang, L.&nbsp;Wang, and
W.&nbsp;Chen, “Lora: Low-rank adaptation of large language models,” in <em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">The
Tenth International Conference on Learning Representations, ICLR 2022,
Virtual Event, April 25-29, 2022</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2022.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
X.&nbsp;Geng, A.&nbsp;Gudibande, H.&nbsp;Liu, E.&nbsp;Wallace, P.&nbsp;Abbeel, S.&nbsp;Levine, and D.&nbsp;Song,
“Koala: A dialogue model for academic research,” Blog post, April 2023.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
Y.&nbsp;Ji, Y.&nbsp;Deng, Y.&nbsp;Gong, Y.&nbsp;Peng, Q.&nbsp;Niu, B.&nbsp;Ma, and X.&nbsp;Li, “Belle: Be
everyone’s large language model engine,”
<a target="_blank" href="https://github.com/LianjiaTech/BELLE" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/LianjiaTech/BELLE</a>, 2023.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
D.&nbsp;Eccleston, “Sharegpt,” <a target="_blank" href="https://sharegpt.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://sharegpt.com/</a>, 2023.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
H.&nbsp;Liu, C.&nbsp;Li, Q.&nbsp;Wu, and Y.&nbsp;J. Lee, “Visual instruction tuning,”
<em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.08485, 2023.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
D.&nbsp;Zhu, J.&nbsp;Chen, X.&nbsp;Shen, X.&nbsp;Li, and M.&nbsp;Elhoseiny, “Minigpt-4: Enhancing
vision-language understanding with advanced large language models,”
<em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.10592, 2023.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
W.&nbsp;Dai, J.&nbsp;Li, D.&nbsp;Li, A.&nbsp;M.&nbsp;H. Tiong, J.&nbsp;Zhao, W.&nbsp;Wang, B.&nbsp;Li, P.&nbsp;Fung, and
S.&nbsp;C.&nbsp;H. Hoi, “Instructblip: Towards general-purpose vision-language models
with instruction tuning,” <em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.06500, 2023.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
Y.&nbsp;Su, T.&nbsp;Lan, H.&nbsp;Li, J.&nbsp;Xu, Y.&nbsp;Wang, and D.&nbsp;Cai, “Pandagpt: One model to
instruction-follow them all,” 2023.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhu, R.&nbsp;Kiros, R.&nbsp;S. Zemel, R.&nbsp;Salakhutdinov, R.&nbsp;Urtasun, A.&nbsp;Torralba, and
S.&nbsp;Fidler, “Aligning books and movies: Towards story-like visual
explanations by watching movies and reading books,” in <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">2015 IEEE
International Conference on Computer Vision, ICCV 2015, Santiago, Chile,
December 7-13, 2015</em>.&nbsp;&nbsp;&nbsp;IEEE Computer
Society, 2015, pp. 19–27.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
“Project gutenberg.” [Online]. Available: <a target="_blank" href="https://www.gutenberg.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.gutenberg.org/</a>

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
T.&nbsp;H. Trinh and Q.&nbsp;V. Le, “A simple method for commonsense reasoning,”
<em id="bib.bib155.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1806.02847, 2018.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
R.&nbsp;Zellers, A.&nbsp;Holtzman, H.&nbsp;Rashkin, Y.&nbsp;Bisk, A.&nbsp;Farhadi, F.&nbsp;Roesner, and
Y.&nbsp;Choi, “Defending against neural fake news,” in <em id="bib.bib156.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems 32: Annual Conference on Neural Information
Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,
Canada</em>, H.&nbsp;M. Wallach, H.&nbsp;Larochelle, A.&nbsp;Beygelzimer,
F.&nbsp;d’Alché-Buc, E.&nbsp;B. Fox, and R.&nbsp;Garnett, Eds., 2019, pp.
9051–9062.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
A.&nbsp;Gokaslan, V.&nbsp;C.&nbsp;E. Pavlick, and S.&nbsp;Tellex, “Openwebtext corpus,”
<a target="_blank" href="http://Skylion007.github.io/OpenWebTextCorpus" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://Skylion007.github.io/OpenWebTextCorpus</a>, 2019.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
J.&nbsp;Baumgartner, S.&nbsp;Zannettou, B.&nbsp;Keegan, M.&nbsp;Squire, and J.&nbsp;Blackburn, “The
pushshift reddit dataset,” in <em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fourteenth
International AAAI Conference on Web and Social Media, ICWSM 2020, Held
Virtually, Original Venue: Atlanta, Georgia, USA, June 8-11, 2020</em>.&nbsp;&nbsp;&nbsp;AAAI Press, 2020, pp. 830–839.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
“Wikipedia.” [Online]. Available:
<a target="_blank" href="https://en.wikipedia.org/wiki/Main_Page" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://en.wikipedia.org/wiki/Main_Page</a>

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
“Bigquery dataset.” [Online]. Available:
<a target="_blank" href="https://cloud.google.com/bigquery?hl=zh-cn" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cloud.google.com/bigquery?hl=zh-cn</a>

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock">
L.&nbsp;Gao, S.&nbsp;Biderman, S.&nbsp;Black, L.&nbsp;Golding, T.&nbsp;Hoppe, C.&nbsp;Foster, J.&nbsp;Phang,
H.&nbsp;He, A.&nbsp;Thite, N.&nbsp;Nabeshima, S.&nbsp;Presser, and C.&nbsp;Leahy, “The pile: An 800gb
dataset of diverse text for language modeling,” <em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2101.00027, 2021.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock">
H.&nbsp;Laurençon, L.&nbsp;Saulnier, T.&nbsp;Wang, C.&nbsp;Akiki, A.&nbsp;V. del Moral,
T.&nbsp;Le&nbsp;Scao, L.&nbsp;Von&nbsp;Werra, C.&nbsp;Mou, E.&nbsp;G. Ponferrada, H.&nbsp;Nguyen <em id="bib.bib162.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>,
“The bigscience roots corpus: A 1.6 tb composite multilingual dataset,” in
<em id="bib.bib162.2.2" class="ltx_emph ltx_font_italic">Thirty-sixth Conference on Neural Information Processing Systems
Datasets and Benchmarks Track</em>, 2022.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock">
“Common crawl.” [Online]. Available: <a target="_blank" href="https://commoncrawl.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://commoncrawl.org/</a>

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock">
“A reproduction version of cc-stories on hugging face.” [Online]. Available:
<a target="_blank" href="https://huggingface.co/datasets/spacemanidol/cc-stories" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/spacemanidol/cc-stories</a>

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock">
B.&nbsp;Wang and A.&nbsp;Komatsuzaki, “GPT-J-6B: A 6 Billion Parameter Autoregressive
Language Model,” <a target="_blank" href="https://github.com/kingoflolz/mesh-transformer-jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kingoflolz/mesh-transformer-jax</a>,
2021.

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock">
S.&nbsp;Mishra, D.&nbsp;Khashabi, C.&nbsp;Baral, and H.&nbsp;Hajishirzi, “Cross-task
generalization via natural language crowdsourcing instructions,” in
<em id="bib.bib166.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin,
Ireland, May 22-27, 2022</em>, S.&nbsp;Muresan, P.&nbsp;Nakov, and A.&nbsp;Villavicencio, Eds.,
2022, pp. 3470–3487.

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock">
S.&nbsp;H. Bach, V.&nbsp;Sanh, Z.&nbsp;X. Yong, A.&nbsp;Webson, C.&nbsp;Raffel, N.&nbsp;V. Nayak, A.&nbsp;Sharma,
T.&nbsp;Kim, M.&nbsp;S. Bari, T.&nbsp;Févry, Z.&nbsp;Alyafeai, M.&nbsp;Dey, A.&nbsp;Santilli, Z.&nbsp;Sun,
S.&nbsp;Ben-David, C.&nbsp;Xu, G.&nbsp;Chhablani, H.&nbsp;Wang, J.&nbsp;A. Fries, M.&nbsp;S. AlShaibani,
S.&nbsp;Sharma, U.&nbsp;Thakker, K.&nbsp;Almubarak, X.&nbsp;Tang, D.&nbsp;R. Radev, M.&nbsp;T. Jiang, and
A.&nbsp;M. Rush, “Promptsource: An integrated development environment and
repository for natural language prompts,” in <em id="bib.bib167.1.1" class="ltx_emph ltx_font_italic">ACL (demo)</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022,
pp. 93–104.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock">
T.&nbsp;Tang, J.&nbsp;Li, W.&nbsp;X. Zhao, and J.&nbsp;Wen, “MVP: multi-task supervised
pre-training for natural language generation,” <em id="bib.bib168.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2206.12131, 2022.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock">
H.&nbsp;Nguyen, S.&nbsp;Suri, K.&nbsp;Tsui, Shahules786, T.&nbsp;team, and C.&nbsp;Schuhmann, “The oig
dataset,” <a target="_blank" href="https://laion.ai/blog/oig-dataset/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://laion.ai/blog/oig-dataset/</a>, 2023.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bai, A.&nbsp;Jones, K.&nbsp;Ndousse, A.&nbsp;Askell, A.&nbsp;Chen, N.&nbsp;DasSarma, D.&nbsp;Drain,
S.&nbsp;Fort, D.&nbsp;Ganguli, T.&nbsp;Henighan, N.&nbsp;Joseph, S.&nbsp;Kadavath, J.&nbsp;Kernion,
T.&nbsp;Conerly, S.&nbsp;E. Showk, N.&nbsp;Elhage, Z.&nbsp;Hatfield-Dodds, D.&nbsp;Hernandez,
T.&nbsp;Hume, S.&nbsp;Johnston, S.&nbsp;Kravec, L.&nbsp;Lovitt, N.&nbsp;Nanda, C.&nbsp;Olsson, D.&nbsp;Amodei,
T.&nbsp;B. Brown, J.&nbsp;Clark, S.&nbsp;McCandlish, C.&nbsp;Olah, B.&nbsp;Mann, and J.&nbsp;Kaplan,
“Training a helpful and harmless assistant with reinforcement learning from
human feedback,” <em id="bib.bib170.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2204.05862, 2022. [Online].
Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2204.05862" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2204.05862</a>

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock">
B.&nbsp;Guo, X.&nbsp;Zhang, Z.&nbsp;Wang, M.&nbsp;Jiang, J.&nbsp;Nie, Y.&nbsp;Ding, J.&nbsp;Yue, and Y.&nbsp;Wu, “How
close is chatgpt to human experts? comparison corpus, evaluation, and
detection,” <em id="bib.bib171.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.07597</em>, 2023.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock">
M.&nbsp;Conover, M.&nbsp;Hayes, A.&nbsp;Mathur, J.&nbsp;Xie, J.&nbsp;Wan, S.&nbsp;Shah, A.&nbsp;Ghodsi,
P.&nbsp;Wendell, M.&nbsp;Zaharia, and R.&nbsp;Xin. (2023) Free dolly: Introducing the
world’s first truly open instruction-tuned llm.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock">
A.&nbsp;Köpf, Y.&nbsp;Kilcher, D.&nbsp;von Rütte, S.&nbsp;Anagnostidis, Z.-R. Tam,
K.&nbsp;Stevens, A.&nbsp;Barhoum, N.&nbsp;M. Duc, O.&nbsp;Stanley, R.&nbsp;Nagyfi <em id="bib.bib173.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>,
“Openassistant conversations–democratizing large language model
alignment,” <em id="bib.bib173.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.07327</em>, 2023.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock">
J.&nbsp;Cheung, “Guanaco - generative universal assistant for natural-language
adaptive context-aware omnilingual outputs,”
<a target="_blank" href="https://guanaco-model.github.io/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://guanaco-model.github.io/</a>, 2023.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock">
C.&nbsp;Xu, D.&nbsp;Guo, N.&nbsp;Duan, and J.&nbsp;McAuley, “Baize: An open-source chat model with
parameter-efficient tuning on self-chat data,” <em id="bib.bib175.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2304.01196</em>, 2023.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock">
Y.&nbsp;Ji, Y.&nbsp;Gong, Y.&nbsp;Deng, Y.&nbsp;Peng, Q.&nbsp;Niu, B.&nbsp;Ma, and X.&nbsp;Li, “Towards better
instruction following language models for chinese: Investigating the impact
of training data and evaluation,” <em id="bib.bib176.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.07854</em>,
2023.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock">
K.&nbsp;Ethayarajh, Y.&nbsp;Choi, and S.&nbsp;Swayamdipta, “Understanding dataset difficulty
with <math id="bib.bib177.1.m1.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="bib.bib177.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="bib.bib177.1.m1.1.1" xref="bib.bib177.1.m1.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="bib.bib177.1.m1.1b"><ci id="bib.bib177.1.m1.1.1.cmml" xref="bib.bib177.1.m1.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib177.1.m1.1c">\mathcal{V}</annotation></semantics></math>-usable information,” in <em id="bib.bib177.2.1" class="ltx_emph ltx_font_italic">Proceedings of the 39th
International Conference on Machine Learning</em>, 2022, pp. 5988–6008.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock">
N.&nbsp;Lambert, L.&nbsp;Tunstall, N.&nbsp;Rajani, and T.&nbsp;Thrush. (2023) Huggingface h4 stack
exchange preference dataset. [Online]. Available:
<a target="_blank" href="https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences</a>

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock">
R.&nbsp;Liu, R.&nbsp;Yang, C.&nbsp;Jia, G.&nbsp;Zhang, D.&nbsp;Zhou, A.&nbsp;M. Dai, D.&nbsp;Yang, and
S.&nbsp;Vosoughi, “Training socially aligned language models in simulated human
society,” <em id="bib.bib179.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.16960, 2023.

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock">
G.&nbsp;Xu, J.&nbsp;Liu, M.&nbsp;Yan, H.&nbsp;Xu, J.&nbsp;Si, Z.&nbsp;Zhou, P.&nbsp;Yi, X.&nbsp;Gao, J.&nbsp;Sang, R.&nbsp;Zhang,
J.&nbsp;Zhang, C.&nbsp;Peng, F.&nbsp;Huang, and J.&nbsp;Zhou, “Cvalues: Measuring the values of
chinese large language models from safety to responsibility,” 2023.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock">
J.&nbsp;Dai, X.&nbsp;Pan, R.&nbsp;Sun, J.&nbsp;Ji, X.&nbsp;Xu, M.&nbsp;Liu, Y.&nbsp;Wang, and Y.&nbsp;Yang, “Safe
rlhf: Safe reinforcement learning from human feedback,” <em id="bib.bib181.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2310.12773</em>, 2023.

</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[182]</span>
<span class="ltx_bibblock">
V.&nbsp;Sanh, A.&nbsp;Webson, C.&nbsp;Raffel, S.&nbsp;H. Bach, L.&nbsp;Sutawika, Z.&nbsp;Alyafeai,
A.&nbsp;Chaffin, A.&nbsp;Stiegler, A.&nbsp;Raja, M.&nbsp;Dey, M.&nbsp;S. Bari, C.&nbsp;Xu, U.&nbsp;Thakker,
S.&nbsp;S. Sharma, E.&nbsp;Szczechla, T.&nbsp;Kim, G.&nbsp;Chhablani, N.&nbsp;V. Nayak, D.&nbsp;Datta,
J.&nbsp;Chang, M.&nbsp;T. Jiang, H.&nbsp;Wang, M.&nbsp;Manica, S.&nbsp;Shen, Z.&nbsp;X. Yong, H.&nbsp;Pandey,
R.&nbsp;Bawden, T.&nbsp;Wang, T.&nbsp;Neeraj, J.&nbsp;Rozen, A.&nbsp;Sharma, A.&nbsp;Santilli,
T.&nbsp;Févry, J.&nbsp;A. Fries, R.&nbsp;Teehan, T.&nbsp;L. Scao, S.&nbsp;Biderman, L.&nbsp;Gao,
T.&nbsp;Wolf, and A.&nbsp;M. Rush, “Multitask prompted training enables zero-shot task
generalization,” in <em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning
Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2022.

</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[183]</span>
<span class="ltx_bibblock">
S.&nbsp;Longpre, L.&nbsp;Hou, T.&nbsp;Vu, A.&nbsp;Webson, H.&nbsp;W. Chung, Y.&nbsp;Tay, D.&nbsp;Zhou, Q.&nbsp;V. Le,
B.&nbsp;Zoph, J.&nbsp;Wei <em id="bib.bib183.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “The flan collection: Designing data and
methods for effective instruction tuning,” <em id="bib.bib183.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2301.13688</em>, 2023.

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[184]</span>
<span class="ltx_bibblock">
K.&nbsp;Cobbe, V.&nbsp;Kosaraju, M.&nbsp;Bavarian, J.&nbsp;Hilton, R.&nbsp;Nakano, C.&nbsp;Hesse, and
J.&nbsp;Schulman, “Training verifiers to solve math word problems,” <em id="bib.bib184.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2110.14168, 2021.

</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[185]</span>
<span class="ltx_bibblock">
M.&nbsp;Geva, D.&nbsp;Khashabi, E.&nbsp;Segal, T.&nbsp;Khot, D.&nbsp;Roth, and J.&nbsp;Berant, “Did
aristotle use a laptop? A question answering benchmark with implicit
reasoning strategies,” <em id="bib.bib185.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, vol.&nbsp;9, pp.
346–361, 2021.

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[186]</span>
<span class="ltx_bibblock">
O.&nbsp;Camburu, B.&nbsp;Shillingford, P.&nbsp;Minervini, T.&nbsp;Lukasiewicz, and P.&nbsp;Blunsom,
“Make up your mind! adversarial generation of inconsistent natural language
explanations,” in <em id="bib.bib186.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics, ACL 2020, Online, July 5-10,
2020</em>, D.&nbsp;Jurafsky, J.&nbsp;Chai, N.&nbsp;Schluter, and J.&nbsp;R. Tetreault, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2020,
pp. 4157–4165.

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[187]</span>
<span class="ltx_bibblock">
T.&nbsp;Wolf, L.&nbsp;Debut, V.&nbsp;Sanh, J.&nbsp;Chaumond, C.&nbsp;Delangue, A.&nbsp;Moi, P.&nbsp;Cistac,
T.&nbsp;Rault, R.&nbsp;Louf, M.&nbsp;Funtowicz, J.&nbsp;Davison, S.&nbsp;Shleifer, P.&nbsp;von Platen,
C.&nbsp;Ma, Y.&nbsp;Jernite, J.&nbsp;Plu, C.&nbsp;Xu, T.&nbsp;L. Scao, S.&nbsp;Gugger, M.&nbsp;Drame, Q.&nbsp;Lhoest,
and A.&nbsp;M. Rush, “Transformers: State-of-the-art natural language
processing,” in <em id="bib.bib187.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: System Demonstrations, EMNLP 2020 -
Demos, Online, November 16-20, 2020</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2020, pp. 38–45.

</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[188]</span>
<span class="ltx_bibblock">
J.&nbsp;Bradbury, R.&nbsp;Frostig, P.&nbsp;Hawkins, M.&nbsp;J. Johnson, C.&nbsp;Leary, D.&nbsp;Maclaurin,
G.&nbsp;Necula, A.&nbsp;Paszke, J.&nbsp;VanderPlas, S.&nbsp;Wanderman-Milne, and Q.&nbsp;Zhang,
“JAX: composable transformations of Python+NumPy programs,” 2018.
[Online]. Available: <a target="_blank" href="http://github.com/google/jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://github.com/google/jax</a>

</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[189]</span>
<span class="ltx_bibblock">
Z.&nbsp;Bian, H.&nbsp;Liu, B.&nbsp;Wang, H.&nbsp;Huang, Y.&nbsp;Li, C.&nbsp;Wang, F.&nbsp;Cui, and Y.&nbsp;You,
“Colossal-ai: A unified deep learning system for large-scale parallel
training,” <em id="bib.bib189.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2110.14883, 2021.

</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[190]</span>
<span class="ltx_bibblock">
J.&nbsp;Fang, Y.&nbsp;Yu, S.&nbsp;Li, Y.&nbsp;You, and J.&nbsp;Zhou, “Patrickstar: Parallel training of
pre-trained models via a chunk-based memory management,” <em id="bib.bib190.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2108.05818, 2021.

</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[191]</span>
<span class="ltx_bibblock">
“Bmtrain: Effient training for big models.” [Online]. Available:
<a target="_blank" href="https://github.com/OpenBMB/BMTrain" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/OpenBMB/BMTrain</a>

</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[192]</span>
<span class="ltx_bibblock">
J.&nbsp;He, J.&nbsp;Qiu, A.&nbsp;Zeng, Z.&nbsp;Yang, J.&nbsp;Zhai, and J.&nbsp;Tang, “Fastmoe: A fast
mixture-of-expert training system,” <em id="bib.bib192.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2103.13262, 2021.

</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[193]</span>
<span class="ltx_bibblock">
W.&nbsp;Kwon, Z.&nbsp;Li, S.&nbsp;Zhuang, Y.&nbsp;Sheng, L.&nbsp;Zheng, C.&nbsp;H. Yu, J.&nbsp;E. Gonzalez,
H.&nbsp;Zhang, and I.&nbsp;Stoica, “Efficient memory management for large language
model serving with pagedattention,” in <em id="bib.bib193.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM SIGOPS
29th Symposium on Operating Systems Principles</em>, 2023.

</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[194]</span>
<span class="ltx_bibblock">
(2023) Deepspeed-mii. [Online]. Available:
<a target="_blank" href="https://github.com/microsoft/DeepSpeed-MII" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/microsoft/DeepSpeed-MII</a>

</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[195]</span>
<span class="ltx_bibblock">
A.&nbsp;Q. Jiang, A.&nbsp;Sablayrolles, A.&nbsp;Mensch, C.&nbsp;Bamford, D.&nbsp;S. Chaplot, D.&nbsp;de&nbsp;las
Casas, F.&nbsp;Bressand, G.&nbsp;Lengyel, G.&nbsp;Lample, L.&nbsp;Saulnier, L.&nbsp;R. Lavaud, M.-A.
Lachaux, P.&nbsp;Stock, T.&nbsp;L. Scao, T.&nbsp;Lavril, T.&nbsp;Wang, T.&nbsp;Lacroix, and W.&nbsp;E.
Sayed, “Mistral 7b,” 2023.

</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[196]</span>
<span class="ltx_bibblock">
Z.&nbsp;Yao, R.&nbsp;Y. Aminabadi, O.&nbsp;Ruwase, S.&nbsp;Rajbhandari, X.&nbsp;Wu, A.&nbsp;A. Awan,
J.&nbsp;Rasley, M.&nbsp;Zhang, C.&nbsp;Li, C.&nbsp;Holmes, Z.&nbsp;Zhou, M.&nbsp;Wyatt, M.&nbsp;Smith,
L.&nbsp;Kurilenko, H.&nbsp;Qin, M.&nbsp;Tanaka, S.&nbsp;Che, S.&nbsp;L. Song, and Y.&nbsp;He,
“DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like
Models at All Scales,” <em id="bib.bib196.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.01320</em>, 2023.

</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[197]</span>
<span class="ltx_bibblock">
A.&nbsp;Paszke, S.&nbsp;Gross, F.&nbsp;Massa, A.&nbsp;Lerer, J.&nbsp;Bradbury, G.&nbsp;Chanan, T.&nbsp;Killeen,
Z.&nbsp;Lin, N.&nbsp;Gimelshein, L.&nbsp;Antiga, A.&nbsp;Desmaison, A.&nbsp;Köpf, E.&nbsp;Z. Yang,
Z.&nbsp;DeVito, M.&nbsp;Raison, A.&nbsp;Tejani, S.&nbsp;Chilamkurthy, B.&nbsp;Steiner, L.&nbsp;Fang,
J.&nbsp;Bai, and S.&nbsp;Chintala, “Pytorch: An imperative style, high-performance
deep learning library,” in <em id="bib.bib197.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems 32: Annual Conference on Neural Information Processing Systems 2019,
NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada</em>, H.&nbsp;M. Wallach,
H.&nbsp;Larochelle, A.&nbsp;Beygelzimer, F.&nbsp;d’Alché-Buc, E.&nbsp;B. Fox, and
R.&nbsp;Garnett, Eds., 2019, pp. 8024–8035.

</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[198]</span>
<span class="ltx_bibblock">
M.&nbsp;Abadi, P.&nbsp;Barham, J.&nbsp;Chen, Z.&nbsp;Chen, A.&nbsp;Davis, J.&nbsp;Dean, M.&nbsp;Devin,
S.&nbsp;Ghemawat, G.&nbsp;Irving, M.&nbsp;Isard, M.&nbsp;Kudlur, J.&nbsp;Levenberg, R.&nbsp;Monga,
S.&nbsp;Moore, D.&nbsp;G. Murray, B.&nbsp;Steiner, P.&nbsp;A. Tucker, V.&nbsp;Vasudevan, P.&nbsp;Warden,
M.&nbsp;Wicke, Y.&nbsp;Yu, and X.&nbsp;Zheng, “Tensorflow: A system for large-scale
machine learning,” in <em id="bib.bib198.1.1" class="ltx_emph ltx_font_italic">12th USENIX Symposium on Operating Systems
Design and Implementation, OSDI 2016, Savannah, GA, USA, November 2-4,
2016</em>, K.&nbsp;Keeton and T.&nbsp;Roscoe, Eds.&nbsp;&nbsp;&nbsp;USENIX Association, 2016, pp. 265–283.

</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[199]</span>
<span class="ltx_bibblock">
T.&nbsp;Chen, M.&nbsp;Li, Y.&nbsp;Li, M.&nbsp;Lin, N.&nbsp;Wang, M.&nbsp;Wang, T.&nbsp;Xiao, B.&nbsp;Xu, C.&nbsp;Zhang, and
Z.&nbsp;Zhang, “Mxnet: A flexible and efficient machine learning library for
heterogeneous distributed systems,” <em id="bib.bib199.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1512.01274, 2015.

</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[200]</span>
<span class="ltx_bibblock">
Y.&nbsp;Ma, D.&nbsp;Yu, T.&nbsp;Wu, and H.&nbsp;Wang, “Paddlepaddle: An open-source deep learning
platform from industrial practice,” <em id="bib.bib200.1.1" class="ltx_emph ltx_font_italic">Frontiers of Data and Domputing</em>,
vol.&nbsp;1, no.&nbsp;1, p. 105, 2019.

</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[201]</span>
<span class="ltx_bibblock">
J.&nbsp;Yuan, X.&nbsp;Li, C.&nbsp;Cheng, J.&nbsp;Liu, R.&nbsp;Guo, S.&nbsp;Cai, C.&nbsp;Yao, F.&nbsp;Yang, X.&nbsp;Yi,
C.&nbsp;Wu, H.&nbsp;Zhang, and J.&nbsp;Zhao, “Oneflow: Redesign the distributed deep
learning framework from scratch,” <em id="bib.bib201.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2110.15032, 2021.

</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[202]</span>
<span class="ltx_bibblock">
S.&nbsp;Roller, E.&nbsp;Dinan, N.&nbsp;Goyal, D.&nbsp;Ju, M.&nbsp;Williamson, Y.&nbsp;Liu, J.&nbsp;Xu, M.&nbsp;Ott,
E.&nbsp;M. Smith, Y.&nbsp;Boureau, and J.&nbsp;Weston, “Recipes for building an open-domain
chatbot,” in <em id="bib.bib202.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Conference of the European
Chapter of the Association for Computational Linguistics: Main Volume, EACL
2021, Online, April 19 - 23, 2021</em>, 2021, pp. 300–325.

</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[203]</span>
<span class="ltx_bibblock">
A.&nbsp;Lewkowycz, A.&nbsp;Andreassen, D.&nbsp;Dohan, E.&nbsp;Dyer, H.&nbsp;Michalewski, V.&nbsp;V. Ramasesh,
A.&nbsp;Slone, C.&nbsp;Anil, I.&nbsp;Schlag, T.&nbsp;Gutman-Solo, Y.&nbsp;Wu, B.&nbsp;Neyshabur,
G.&nbsp;Gur-Ari, and V.&nbsp;Misra, “Solving quantitative reasoning problems with
language models,” <em id="bib.bib203.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2206.14858, 2022.

</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[204]</span>
<span class="ltx_bibblock">
T.&nbsp;Saier, J.&nbsp;Krause, and M.&nbsp;Färber, “unarxive 2022: All arxiv publications
pre-processed for nlp, including structured full-text and citation network,”
<em id="bib.bib204.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.14957</em>, 2023.

</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[205]</span>
<span class="ltx_bibblock">
H.&nbsp;A. Simon, “Experiments with a heuristic compiler,” <em id="bib.bib205.1.1" class="ltx_emph ltx_font_italic">J. ACM</em>,
vol.&nbsp;10, no.&nbsp;4, pp. 493–506, 1963.

</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[206]</span>
<span class="ltx_bibblock">
Z.&nbsp;Manna and R.&nbsp;J. Waldinger, “Toward automatic program synthesis,”
<em id="bib.bib206.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em>, vol.&nbsp;14, no.&nbsp;3, pp. 151–165, 1971.

</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[207]</span>
<span class="ltx_bibblock">
Z.&nbsp;Feng, D.&nbsp;Guo, D.&nbsp;Tang, N.&nbsp;Duan, X.&nbsp;Feng, M.&nbsp;Gong, L.&nbsp;Shou, B.&nbsp;Qin, T.&nbsp;Liu,
D.&nbsp;Jiang, and M.&nbsp;Zhou, “Codebert: A pre-trained model for programming and
natural languages,” in <em id="bib.bib207.1.1" class="ltx_emph ltx_font_italic">Findings of EMNLP</em>, 2020.

</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[208]</span>
<span class="ltx_bibblock">
J.&nbsp;Austin, A.&nbsp;Odena, M.&nbsp;I. Nye, M.&nbsp;Bosma, H.&nbsp;Michalewski, D.&nbsp;Dohan, E.&nbsp;Jiang,
C.&nbsp;J. Cai, M.&nbsp;Terry, Q.&nbsp;V. Le, and C.&nbsp;Sutton, “Program synthesis with large
language models,” <em id="bib.bib208.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2108.07732, 2021.

</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[209]</span>
<span class="ltx_bibblock">
S.&nbsp;Black, L.&nbsp;Gao, P.&nbsp;Wang, C.&nbsp;Leahy, and S.&nbsp;Biderman, “GPT-Neo: Large Scale
Autoregressive Language Modeling with Mesh-Tensorflow,” 2021.

</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[210]</span>
<span class="ltx_bibblock">
F.&nbsp;F. Xu, U.&nbsp;Alon, G.&nbsp;Neubig, and V.&nbsp;J. Hellendoorn, “A systematic evaluation
of large language models of code,” in <em id="bib.bib210.1.1" class="ltx_emph ltx_font_italic">MAPS@PLDI</em>, 2022.

</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[211]</span>
<span class="ltx_bibblock">
A.&nbsp;Madaan, S.&nbsp;Zhou, U.&nbsp;Alon, Y.&nbsp;Yang, and G.&nbsp;Neubig, “Language models of code
are few-shot commonsense learners,” in <em id="bib.bib211.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022
Conference on Empirical Methods in Natural Language Processing, EMNLP 2022,
Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, Y.&nbsp;Goldberg,
Z.&nbsp;Kozareva, and Y.&nbsp;Zhang, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022, pp. 1384–1403.

</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[212]</span>
<span class="ltx_bibblock">
S.&nbsp;Longpre, G.&nbsp;Yauney, E.&nbsp;Reif, K.&nbsp;Lee, A.&nbsp;Roberts, B.&nbsp;Zoph, D.&nbsp;Zhou, J.&nbsp;Wei,
K.&nbsp;Robinson, D.&nbsp;Mimno <em id="bib.bib212.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “A pretrainer’s guide to training data:
Measuring the effects of data age, domain coverage, quality, &amp; toxicity,”
<em id="bib.bib212.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.13169</em>, 2023.

</span>
</li>
<li id="bib.bib213" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[213]</span>
<span class="ltx_bibblock">
D.&nbsp;Chen, Y.&nbsp;Huang, Z.&nbsp;Ma, H.&nbsp;Chen, X.&nbsp;Pan, C.&nbsp;Ge, D.&nbsp;Gao, Y.&nbsp;Xie, Z.&nbsp;Liu,
J.&nbsp;Gao, Y.&nbsp;Li, B.&nbsp;Ding, and J.&nbsp;Zhou, “Data-juicer: A one-stop data
processing system for large language models,” 2023.

</span>
</li>
<li id="bib.bib214" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[214]</span>
<span class="ltx_bibblock">
D.&nbsp;Hernandez, T.&nbsp;B. Brown, T.&nbsp;Conerly, N.&nbsp;DasSarma, D.&nbsp;Drain, S.&nbsp;E. Showk,
N.&nbsp;Elhage, Z.&nbsp;Hatfield-Dodds, T.&nbsp;Henighan, T.&nbsp;Hume, S.&nbsp;Johnston, B.&nbsp;Mann,
C.&nbsp;Olah, C.&nbsp;Olsson, D.&nbsp;Amodei, N.&nbsp;Joseph, J.&nbsp;Kaplan, and S.&nbsp;McCandlish,
“Scaling laws and interpretability of learning from repeated data,”
<em id="bib.bib214.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2205.10487, 2022.

</span>
</li>
<li id="bib.bib215" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[215]</span>
<span class="ltx_bibblock">
A.&nbsp;Holtzman, J.&nbsp;Buys, L.&nbsp;Du, M.&nbsp;Forbes, and Y.&nbsp;Choi, “The curious case of
neural text degeneration,” in <em id="bib.bib215.1.1" class="ltx_emph ltx_font_italic">8th International Conference on Learning
Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,
2020</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2020.

</span>
</li>
<li id="bib.bib216" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[216]</span>
<span class="ltx_bibblock">
K.&nbsp;Lee, D.&nbsp;Ippolito, A.&nbsp;Nystrom, C.&nbsp;Zhang, D.&nbsp;Eck, C.&nbsp;Callison-Burch, and
N.&nbsp;Carlini, “Deduplicating training data makes language models better,” in
<em id="bib.bib216.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin,
Ireland, May 22-27, 2022</em>, 2022, pp. 8424–8445.

</span>
</li>
<li id="bib.bib217" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[217]</span>
<span class="ltx_bibblock">
N.&nbsp;Carlini, D.&nbsp;Ippolito, M.&nbsp;Jagielski, K.&nbsp;Lee, F.&nbsp;Tramèr, and C.&nbsp;Zhang,
“Quantifying memorization across neural language models,” <em id="bib.bib217.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
2022.

</span>
</li>
<li id="bib.bib218" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[218]</span>
<span class="ltx_bibblock">
N.&nbsp;Carlini, F.&nbsp;Tramèr, E.&nbsp;Wallace, M.&nbsp;Jagielski, A.&nbsp;Herbert-Voss,
K.&nbsp;Lee, A.&nbsp;Roberts, T.&nbsp;B. Brown, D.&nbsp;Song, Ú.&nbsp;Erlingsson, A.&nbsp;Oprea, and
C.&nbsp;Raffel, “Extracting training data from large language models,” in
<em id="bib.bib218.1.1" class="ltx_emph ltx_font_italic">30th USENIX Security Symposium, USENIX Security 2021, August 11-13,
2021</em>, 2021, pp. 2633–2650.

</span>
</li>
<li id="bib.bib219" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[219]</span>
<span class="ltx_bibblock">
N.&nbsp;Kandpal, E.&nbsp;Wallace, and C.&nbsp;Raffel, “Deduplicating training data mitigates
privacy risks in language models,” in <em id="bib.bib219.1.1" class="ltx_emph ltx_font_italic">International Conference on
Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland,
USA</em>.&nbsp;&nbsp;&nbsp;PMLR, 2022, pp.
10 697–10 707.

</span>
</li>
<li id="bib.bib220" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[220]</span>
<span class="ltx_bibblock">
J.&nbsp;D. Lafferty, A.&nbsp;McCallum, and F.&nbsp;C.&nbsp;N. Pereira, “Conditional random fields:
Probabilistic models for segmenting and labeling sequence data,” in
<em id="bib.bib220.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighteenth International Conference on Machine
Learning (ICML 2001), Williams College, Williamstown, MA, USA, June 28 -
July 1, 2001</em>, C.&nbsp;E. Brodley and A.&nbsp;P. Danyluk, Eds.&nbsp;&nbsp;&nbsp;Morgan Kaufmann, 2001, pp. 282–289.

</span>
</li>
<li id="bib.bib221" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[221]</span>
<span class="ltx_bibblock">
P.&nbsp;Gage, “A new algorithm for data compression,” <em id="bib.bib221.1.1" class="ltx_emph ltx_font_italic">C Users Journal</em>,
vol.&nbsp;12, no.&nbsp;2, pp. 23–38, 1994.

</span>
</li>
<li id="bib.bib222" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[222]</span>
<span class="ltx_bibblock">
R.&nbsp;Sennrich, B.&nbsp;Haddow, and A.&nbsp;Birch, “Neural machine translation of rare
words with subword units,” in <em id="bib.bib222.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 54th Annual Meeting
of the Association for Computational Linguistics, ACL 2016, August 7-12,
2016, Berlin, Germany, Volume 1: Long Papers</em>.&nbsp;&nbsp;&nbsp;The Association for Computer Linguistics, 2016.

</span>
</li>
<li id="bib.bib223" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[223]</span>
<span class="ltx_bibblock">
M.&nbsp;Schuster and K.&nbsp;Nakajima, “Japanese and korean voice search,” in
<em id="bib.bib223.1.1" class="ltx_emph ltx_font_italic">2012 IEEE international conference on acoustics, speech and signal
processing (ICASSP)</em>.&nbsp;&nbsp;&nbsp;IEEE, 2012, pp.
5149–5152.

</span>
</li>
<li id="bib.bib224" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[224]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wu, M.&nbsp;Schuster, Z.&nbsp;Chen, Q.&nbsp;V. Le, M.&nbsp;Norouzi, W.&nbsp;Macherey, M.&nbsp;Krikun,
Y.&nbsp;Cao, Q.&nbsp;Gao, K.&nbsp;Macherey, J.&nbsp;Klingner, A.&nbsp;Shah, M.&nbsp;Johnson, X.&nbsp;Liu,
L.&nbsp;Kaiser, S.&nbsp;Gouws, Y.&nbsp;Kato, T.&nbsp;Kudo, H.&nbsp;Kazawa, K.&nbsp;Stevens, G.&nbsp;Kurian,
N.&nbsp;Patil, W.&nbsp;Wang, C.&nbsp;Young, J.&nbsp;Smith, J.&nbsp;Riesa, A.&nbsp;Rudnick, O.&nbsp;Vinyals,
G.&nbsp;Corrado, M.&nbsp;Hughes, and J.&nbsp;Dean, “Google’s neural machine translation
system: Bridging the gap between human and machine translation,”
<em id="bib.bib224.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1609.08144, 2016.

</span>
</li>
<li id="bib.bib225" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[225]</span>
<span class="ltx_bibblock">
T.&nbsp;Kudo, “Subword regularization: Improving neural network translation models
with multiple subword candidates,” in <em id="bib.bib225.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual
Meeting of the Association for Computational Linguistics, ACL 2018,
Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers</em>, I.&nbsp;Gurevych
and Y.&nbsp;Miyao, Eds.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2018, pp. 66–75.

</span>
</li>
<li id="bib.bib226" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[226]</span>
<span class="ltx_bibblock">
T.&nbsp;Kudo and J.&nbsp;Richardson, “Sentencepiece: A simple and language independent
subword tokenizer and detokenizer for neural text processing,” in
<em id="bib.bib226.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2018: System Demonstrations, Brussels, Belgium,
October 31 - November 4, 2018</em>, E.&nbsp;Blanco and W.&nbsp;Lu, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2018.

</span>
</li>
<li id="bib.bib227" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[227]</span>
<span class="ltx_bibblock">
M.&nbsp;Davis and M.&nbsp;Dürst, “Unicode normalization forms,” 2001.

</span>
</li>
<li id="bib.bib228" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[228]</span>
<span class="ltx_bibblock">
P.&nbsp;Nakkiran, G.&nbsp;Kaplun, Y.&nbsp;Bansal, T.&nbsp;Yang, B.&nbsp;Barak, and I.&nbsp;Sutskever, “Deep
double descent: Where bigger models and more data hurt,” in <em id="bib.bib228.1.1" class="ltx_emph ltx_font_italic">8th
International Conference on Learning Representations, ICLR 2020, Addis
Ababa, Ethiopia, April 26-30, 2020</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2020.

</span>
</li>
<li id="bib.bib229" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[229]</span>
<span class="ltx_bibblock">
K.&nbsp;Tirumala, D.&nbsp;Simig, A.&nbsp;Aghajanyan, and A.&nbsp;S. Morcos, “D4: Improving llm
pretraining via document de-duplication and diversification,” <em id="bib.bib229.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2308.12284</em>, 2023.

</span>
</li>
<li id="bib.bib230" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[230]</span>
<span class="ltx_bibblock">
Z.&nbsp;Shen, T.&nbsp;Tao, L.&nbsp;Ma, W.&nbsp;Neiswanger, J.&nbsp;Hestness, N.&nbsp;Vassilieva, D.&nbsp;Soboleva,
and E.&nbsp;Xing, “Slimpajama-dc: Understanding data combinations for llm
training,” <em id="bib.bib230.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.10818</em>, 2023.

</span>
</li>
<li id="bib.bib231" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[231]</span>
<span class="ltx_bibblock">
S.&nbsp;M. Xie, S.&nbsp;Santurkar, T.&nbsp;Ma, and P.&nbsp;Liang, “Data selection for language
models via importance resampling,” <em id="bib.bib231.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.03169</em>,
2023.

</span>
</li>
<li id="bib.bib232" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[232]</span>
<span class="ltx_bibblock">
X.&nbsp;Wang, W.&nbsp;Zhou, Q.&nbsp;Zhang, J.&nbsp;Zhou, S.&nbsp;Gao, J.&nbsp;Wang, M.&nbsp;Zhang, X.&nbsp;Gao,
Y.&nbsp;Chen, and T.&nbsp;Gui, “Farewell to aimless large-scale pretraining:
Influential subset selection for language model,” <em id="bib.bib232.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2305.12816</em>, 2023.

</span>
</li>
<li id="bib.bib233" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[233]</span>
<span class="ltx_bibblock">
D.&nbsp;Paperno, G.&nbsp;Kruszewski, A.&nbsp;Lazaridou, Q.&nbsp;N. Pham, R.&nbsp;Bernardi, S.&nbsp;Pezzelle,
M.&nbsp;Baroni, G.&nbsp;Boleda, and R.&nbsp;Fernández, “The LAMBADA dataset: Word
prediction requiring a broad discourse context,” in <em id="bib.bib233.1.1" class="ltx_emph ltx_font_italic">ACL
(1)</em>.&nbsp;&nbsp;&nbsp;The Association for Computer
Linguistics, 2016.

</span>
</li>
<li id="bib.bib234" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[234]</span>
<span class="ltx_bibblock">
M.&nbsp;F. Chen, N.&nbsp;Roberts, K.&nbsp;Bhatia, J.&nbsp;Wang, C.&nbsp;Zhang, F.&nbsp;Sala, and C.&nbsp;Ré,
“Skill-it! a data-driven skills framework for understanding and training
language models,” <em id="bib.bib234.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.14430</em>, 2023.

</span>
</li>
<li id="bib.bib235" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[235]</span>
<span class="ltx_bibblock">
B.&nbsp;Rozière, J.&nbsp;Gehring, F.&nbsp;Gloeckle, S.&nbsp;Sootla, I.&nbsp;Gat, X.&nbsp;E. Tan,
Y.&nbsp;Adi, J.&nbsp;Liu, T.&nbsp;Remez, J.&nbsp;Rapin, A.&nbsp;Kozhevnikov, I.&nbsp;Evtimov, J.&nbsp;Bitton,
M.&nbsp;Bhatt, C.&nbsp;Canton-Ferrer, A.&nbsp;Grattafiori, W.&nbsp;Xiong, A.&nbsp;Défossez,
J.&nbsp;Copet, F.&nbsp;Azhar, H.&nbsp;Touvron, L.&nbsp;Martin, N.&nbsp;Usunier, T.&nbsp;Scialom, and
G.&nbsp;Synnaeve, “Code llama: Open foundation models for code,” <em id="bib.bib235.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2308.12950, 2023.

</span>
</li>
<li id="bib.bib236" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[236]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bengio, J.&nbsp;Louradour, R.&nbsp;Collobert, and J.&nbsp;Weston, “Curriculum learning,”
in <em id="bib.bib236.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2009, pp. 41–48.

</span>
</li>
<li id="bib.bib237" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[237]</span>
<span class="ltx_bibblock">
C.&nbsp;Xu, C.&nbsp;Rosset, L.&nbsp;Del&nbsp;Corro, S.&nbsp;Mahajan, J.&nbsp;McAuley, J.&nbsp;Neville, A.&nbsp;H.
Awadallah, and N.&nbsp;Rao, “Contrastive post-training large language models on
data curriculum,” <em id="bib.bib237.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.02263</em>, 2023.

</span>
</li>
<li id="bib.bib238" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[238]</span>
<span class="ltx_bibblock">
S.&nbsp;Tworkowski, K.&nbsp;Staniszewski, M.&nbsp;Pacek, Y.&nbsp;Wu, H.&nbsp;Michalewski, and P.&nbsp;Milos,
“Focused transformer: Contrastive training for context scaling,”
<em id="bib.bib238.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.03170, 2023.

</span>
</li>
<li id="bib.bib239" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[239]</span>
<span class="ltx_bibblock">
Z.&nbsp;Azerbayev, H.&nbsp;Schoelkopf, K.&nbsp;Paster, M.&nbsp;D. Santos, S.&nbsp;McAleer, A.&nbsp;Q. Jiang,
J.&nbsp;Deng, S.&nbsp;Biderman, and S.&nbsp;Welleck, “Llemma: An open language model for
mathematics,” <em id="bib.bib239.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.10631</em>, 2023.

</span>
</li>
<li id="bib.bib240" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[240]</span>
<span class="ltx_bibblock">
S.&nbsp;Chen, S.&nbsp;Wong, L.&nbsp;Chen, and Y.&nbsp;Tian, “Extending context window of large
language models via positional interpolation,” <em id="bib.bib240.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.15595, 2023.

</span>
</li>
<li id="bib.bib241" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[241]</span>
<span class="ltx_bibblock">
G.&nbsp;Wenzek, M.-A. Lachaux, A.&nbsp;Conneau, V.&nbsp;Chaudhary, F.&nbsp;Guzmán, A.&nbsp;Joulin,
and É.&nbsp;Grave, “Ccnet: Extracting high quality monolingual datasets from
web crawl data,” in <em id="bib.bib241.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and
Evaluation Conference</em>, 2020, pp. 4003–4012.

</span>
</li>
<li id="bib.bib242" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[242]</span>
<span class="ltx_bibblock">
A.&nbsp;Joulin, E.&nbsp;Grave, P.&nbsp;Bojanowski, and T.&nbsp;Mikolov, “Bag of tricks for
efficient text classification,” in <em id="bib.bib242.1.1" class="ltx_emph ltx_font_italic">EACL</em>, 2017, pp. 427–431.

</span>
</li>
<li id="bib.bib243" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[243]</span>
<span class="ltx_bibblock">
D.&nbsp;Chen, Y.&nbsp;Huang, Z.&nbsp;Ma, H.&nbsp;Chen, X.&nbsp;Pan, C.&nbsp;Ge, D.&nbsp;Gao, Y.&nbsp;Xie, Z.&nbsp;Liu,
J.&nbsp;Gao <em id="bib.bib243.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Data-juicer: A one-stop data processing system for
large language models,” <em id="bib.bib243.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.02033</em>, 2023.

</span>
</li>
<li id="bib.bib244" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[244]</span>
<span class="ltx_bibblock">
B.&nbsp;Zhang, B.&nbsp;Ghorbani, A.&nbsp;Bapna, Y.&nbsp;Cheng, X.&nbsp;Garcia, J.&nbsp;Shen, and O.&nbsp;Firat,
“Examining scaling and transfer of language model architectures for machine
translation,” in <em id="bib.bib244.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning, ICML
2022, 17-23 July 2022, Baltimore, Maryland, USA</em>, 2022, pp.
26 176–26 192.

</span>
</li>
<li id="bib.bib245" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[245]</span>
<span class="ltx_bibblock">
L.&nbsp;Dong, N.&nbsp;Yang, W.&nbsp;Wang, F.&nbsp;Wei, X.&nbsp;Liu, Y.&nbsp;Wang, J.&nbsp;Gao, M.&nbsp;Zhou, and
H.&nbsp;Hon, “Unified language model pre-training for natural language
understanding and generation,” in <em id="bib.bib245.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems 32: Annual Conference on Neural Information Processing
Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada</em>,
2019, pp. 13 042–13 054.

</span>
</li>
<li id="bib.bib246" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[246]</span>
<span class="ltx_bibblock">
A.&nbsp;Clark, D.&nbsp;de&nbsp;Las&nbsp;Casas, A.&nbsp;Guy, A.&nbsp;Mensch, M.&nbsp;Paganini, J.&nbsp;Hoffmann,
B.&nbsp;Damoc, B.&nbsp;A. Hechtman, T.&nbsp;Cai, S.&nbsp;Borgeaud, G.&nbsp;van&nbsp;den Driessche,
E.&nbsp;Rutherford, T.&nbsp;Hennigan, M.&nbsp;J. Johnson, A.&nbsp;Cassirer, C.&nbsp;Jones,
E.&nbsp;Buchatskaya, D.&nbsp;Budden, L.&nbsp;Sifre, S.&nbsp;Osindero, O.&nbsp;Vinyals, M.&nbsp;Ranzato,
J.&nbsp;W. Rae, E.&nbsp;Elsen, K.&nbsp;Kavukcuoglu, and K.&nbsp;Simonyan, “Unified scaling laws
for routed language models,” in <em id="bib.bib246.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA</em>, 2022,
pp. 4057–4086.

</span>
</li>
<li id="bib.bib247" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[247]</span>
<span class="ltx_bibblock">
A.&nbsp;Gu, K.&nbsp;Goel, and C.&nbsp;Ré, “Efficiently modeling long sequences with
structured state spaces,” in <em id="bib.bib247.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on
Learning Representations, ICLR 2022, Virtual Event, April 25-29,
2022</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2022. [Online].
Available: <a target="_blank" href="https://openreview.net/forum?id=uYLFoz1vlAC" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=uYLFoz1vlAC</a>

</span>
</li>
<li id="bib.bib248" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[248]</span>
<span class="ltx_bibblock">
H.&nbsp;Mehta, A.&nbsp;Gupta, A.&nbsp;Cutkosky, and B.&nbsp;Neyshabur, “Long range language
modeling via gated state spaces,” <em id="bib.bib248.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2206.13947, 2022.
[Online]. Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2206.13947" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2206.13947</a>

</span>
</li>
<li id="bib.bib249" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[249]</span>
<span class="ltx_bibblock">
T.&nbsp;Dao, D.&nbsp;Y. Fu, K.&nbsp;K. Saab, A.&nbsp;W. Thomas, A.&nbsp;Rudra, and C.&nbsp;Ré, “Hungry
hungry hippos: Towards language modeling with state space models,”
<em id="bib.bib249.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.14052, 2022. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2212.14052" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2212.14052</a>

</span>
</li>
<li id="bib.bib250" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[250]</span>
<span class="ltx_bibblock">
M.&nbsp;Poli, S.&nbsp;Massaroli, E.&nbsp;Nguyen, D.&nbsp;Y. Fu, T.&nbsp;Dao, S.&nbsp;Baccus, Y.&nbsp;Bengio,
S.&nbsp;Ermon, and C.&nbsp;Ré, “Hyena hierarchy: Towards larger convolutional
language models,” in <em id="bib.bib250.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2023.

</span>
</li>
<li id="bib.bib251" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[251]</span>
<span class="ltx_bibblock">
B.&nbsp;Peng, E.&nbsp;Alcaide, Q.&nbsp;Anthony, A.&nbsp;Albalak, S.&nbsp;Arcadinho, H.&nbsp;Cao, X.&nbsp;Cheng,
M.&nbsp;Chung, M.&nbsp;Grella, K.&nbsp;K.&nbsp;G. V., X.&nbsp;He, H.&nbsp;Hou, P.&nbsp;Kazienko, J.&nbsp;Kocon,
J.&nbsp;Kong, B.&nbsp;Koptyra, H.&nbsp;Lau, K.&nbsp;S.&nbsp;I. Mantri, F.&nbsp;Mom, A.&nbsp;Saito, X.&nbsp;Tang,
B.&nbsp;Wang, J.&nbsp;S. Wind, S.&nbsp;Wozniak, R.&nbsp;Zhang, Z.&nbsp;Zhang, Q.&nbsp;Zhao, P.&nbsp;Zhou,
J.&nbsp;Zhu, and R.&nbsp;Zhu, “RWKV: reinventing rnns for the transformer era,”
<em id="bib.bib251.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.13048, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2305.13048" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.13048</a>

</span>
</li>
<li id="bib.bib252" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[252]</span>
<span class="ltx_bibblock">
Y.&nbsp;Sun, L.&nbsp;Dong, S.&nbsp;Huang, S.&nbsp;Ma, Y.&nbsp;Xia, J.&nbsp;Xue, J.&nbsp;Wang, and F.&nbsp;Wei,
“Retentive network: A successor to transformer for large language models,”
<em id="bib.bib252.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.08621</em>, 2023.

</span>
</li>
<li id="bib.bib253" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[253]</span>
<span class="ltx_bibblock">
J.&nbsp;T. Smith, A.&nbsp;Warrington, and S.&nbsp;Linderman, “Simplified state space layers
for sequence modeling,” in <em id="bib.bib253.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2023.

</span>
</li>
<li id="bib.bib254" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[254]</span>
<span class="ltx_bibblock">
A.&nbsp;Orvieto, S.&nbsp;L. Smith, A.&nbsp;Gu, A.&nbsp;Fernando, C.&nbsp;Gulcehre, R.&nbsp;Pascanu, and
S.&nbsp;De, “Resurrecting recurrent neural networks for long sequences,” in
<em id="bib.bib254.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2023.

</span>
</li>
<li id="bib.bib255" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[255]</span>
<span class="ltx_bibblock">
M.&nbsp;Ding, Z.&nbsp;Yang, W.&nbsp;Hong, W.&nbsp;Zheng, C.&nbsp;Zhou, D.&nbsp;Yin, J.&nbsp;Lin, X.&nbsp;Zou, Z.&nbsp;Shao,
H.&nbsp;Yang, and J.&nbsp;Tang, “Cogview: Mastering text-to-image generation via
transformers,” in <em id="bib.bib255.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS
2021, December 6-14, 2021, virtual</em>, 2021, pp. 19 822–19 835.

</span>
</li>
<li id="bib.bib256" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[256]</span>
<span class="ltx_bibblock">
L.&nbsp;J. Ba, J.&nbsp;R. Kiros, and G.&nbsp;E. Hinton, “Layer normalization,” vol.
abs/1607.06450, 2016.

</span>
</li>
<li id="bib.bib257" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[257]</span>
<span class="ltx_bibblock">
B.&nbsp;Zhang and R.&nbsp;Sennrich, “Root mean square layer normalization,” in
<em id="bib.bib257.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 32: Annual Conference
on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14,
2019, Vancouver, BC, Canada</em>, 2019, pp. 12 360–12 371.

</span>
</li>
<li id="bib.bib258" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[258]</span>
<span class="ltx_bibblock">
H.&nbsp;Wang, S.&nbsp;Ma, L.&nbsp;Dong, S.&nbsp;Huang, D.&nbsp;Zhang, and F.&nbsp;Wei, “Deepnet: Scaling
transformers to 1, 000 layers,” vol. abs/2203.00555, 2022.

</span>
</li>
<li id="bib.bib259" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[259]</span>
<span class="ltx_bibblock">
V.&nbsp;Nair and G.&nbsp;E. Hinton, “Rectified linear units improve restricted boltzmann
machines,” in <em id="bib.bib259.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th international conference on
machine learning (ICML-10)</em>, 2010, pp. 807–814.

</span>
</li>
<li id="bib.bib260" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[260]</span>
<span class="ltx_bibblock">
A.&nbsp;Wang, A.&nbsp;Singh, J.&nbsp;Michael, F.&nbsp;Hill, O.&nbsp;Levy, and S.&nbsp;R. Bowman, “GLUE:
A multi-task benchmark and analysis platform for natural language
understanding,” in <em id="bib.bib260.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Workshop: Analyzing and
Interpreting Neural Networks for NLP, BlackboxNLP@EMNLP 2018, Brussels,
Belgium, November 1, 2018</em>, T.&nbsp;Linzen, G.&nbsp;Chrupala, and A.&nbsp;Alishahi,
Eds.&nbsp;&nbsp;&nbsp;Association for Computational
Linguistics, 2018, pp. 353–355.

</span>
</li>
<li id="bib.bib261" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[261]</span>
<span class="ltx_bibblock">
P.&nbsp;Ramachandran, B.&nbsp;Zoph, and Q.&nbsp;V. Le, “Searching for activation functions,”
<em id="bib.bib261.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.05941</em>, 2017.

</span>
</li>
<li id="bib.bib262" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[262]</span>
<span class="ltx_bibblock">
N.&nbsp;Shazeer, “GLU variants improve transformer,” vol. abs/2002.05202, 2020.

</span>
</li>
<li id="bib.bib263" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[263]</span>
<span class="ltx_bibblock">
J.&nbsp;Su, Y.&nbsp;Lu, S.&nbsp;Pan, B.&nbsp;Wen, and Y.&nbsp;Liu, “Roformer: Enhanced transformer with
rotary position embedding,” vol. abs/2104.09864, 2021.

</span>
</li>
<li id="bib.bib264" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[264]</span>
<span class="ltx_bibblock">
O.&nbsp;Press, N.&nbsp;A. Smith, and M.&nbsp;Lewis, “Train short, test long: Attention with
linear biases enables input length extrapolation,” in <em id="bib.bib264.1.1" class="ltx_emph ltx_font_italic">The Tenth
International Conference on Learning Representations, ICLR 2022, Virtual
Event, April 25-29, 2022</em>, 2022.

</span>
</li>
<li id="bib.bib265" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[265]</span>
<span class="ltx_bibblock">
S.&nbsp;Ioffe and C.&nbsp;Szegedy, “Batch normalization: Accelerating deep network
training by reducing internal covariate shift,” in <em id="bib.bib265.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
32nd International Conference on Machine Learning, ICML 2015, Lille,
France, 6-11 July 2015</em>, ser. JMLR Workshop and Conference Proceedings,
F.&nbsp;R. Bach and D.&nbsp;M. Blei, Eds., vol.&nbsp;37.&nbsp;&nbsp;&nbsp;JMLR.org, 2015, pp. 448–456. [Online]. Available:
<a target="_blank" href="http://proceedings.mlr.press/v37/ioffe15.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://proceedings.mlr.press/v37/ioffe15.html</a>

</span>
</li>
<li id="bib.bib266" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[266]</span>
<span class="ltx_bibblock">
S.&nbsp;Narang, H.&nbsp;W. Chung, Y.&nbsp;Tay, L.&nbsp;Fedus, T.&nbsp;Févry, M.&nbsp;Matena, K.&nbsp;Malkan,
N.&nbsp;Fiedel, N.&nbsp;Shazeer, Z.&nbsp;Lan, Y.&nbsp;Zhou, W.&nbsp;Li, N.&nbsp;Ding, J.&nbsp;Marcus,
A.&nbsp;Roberts, and C.&nbsp;Raffel, “Do transformer modifications transfer across
implementations and applications?” in <em id="bib.bib266.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021
Conference on Empirical Methods in Natural Language Processing, EMNLP 2021,
Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021</em>, 2021,
pp. 5758–5773.

</span>
</li>
<li id="bib.bib267" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[267]</span>
<span class="ltx_bibblock">
R.&nbsp;Xiong, Y.&nbsp;Yang, D.&nbsp;He, K.&nbsp;Zheng, S.&nbsp;Zheng, C.&nbsp;Xing, H.&nbsp;Zhang, Y.&nbsp;Lan,
L.&nbsp;Wang, and T.&nbsp;Liu, “On layer normalization in the transformer
architecture,” in <em id="bib.bib267.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2020.

</span>
</li>
<li id="bib.bib268" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[268]</span>
<span class="ltx_bibblock">
A.&nbsp;Baevski and M.&nbsp;Auli, “Adaptive input representations for neural language
modeling,” in <em id="bib.bib268.1.1" class="ltx_emph ltx_font_italic">7th International Conference on Learning
Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2019.

</span>
</li>
<li id="bib.bib269" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[269]</span>
<span class="ltx_bibblock">
L.&nbsp;Liu, X.&nbsp;Liu, J.&nbsp;Gao, W.&nbsp;Chen, and J.&nbsp;Han, “Understanding the difficulty of
training transformers,” in <em id="bib.bib269.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing, EMNLP 2020, Online,
November 16-20, 2020</em>.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2020, pp. 5747–5763.

</span>
</li>
<li id="bib.bib270" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[270]</span>
<span class="ltx_bibblock">
D.&nbsp;Hendrycks and K.&nbsp;Gimpel, “Gaussian error linear units (gelus),”
<em id="bib.bib270.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.08415</em>, 2016.

</span>
</li>
<li id="bib.bib271" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[271]</span>
<span class="ltx_bibblock">
Y.&nbsp;N. Dauphin, A.&nbsp;Fan, M.&nbsp;Auli, and D.&nbsp;Grangier, “Language modeling with gated
convolutional networks,” in <em id="bib.bib271.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 34th International
Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11
August 2017</em>, 2017, pp. 933–941.

</span>
</li>
<li id="bib.bib272" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[272]</span>
<span class="ltx_bibblock">
T.&nbsp;L. Scao, T.&nbsp;Wang, D.&nbsp;Hesslow, S.&nbsp;Bekman, M.&nbsp;S. Bari, S.&nbsp;Biderman,
H.&nbsp;Elsahar, N.&nbsp;Muennighoff, J.&nbsp;Phang, O.&nbsp;Press, C.&nbsp;Raffel, V.&nbsp;Sanh, S.&nbsp;Shen,
L.&nbsp;Sutawika, J.&nbsp;Tae, Z.&nbsp;X. Yong, J.&nbsp;Launay, and I.&nbsp;Beltagy, “What language
model to train if you have one million GPU hours?” in <em id="bib.bib272.1.1" class="ltx_emph ltx_font_italic">Findings of
the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi,
United Arab Emirates, December 7-11, 2022</em>, 2022, pp. 765–782.

</span>
</li>
<li id="bib.bib273" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[273]</span>
<span class="ltx_bibblock">
P.&nbsp;Shaw, J.&nbsp;Uszkoreit, and A.&nbsp;Vaswani, “Self-attention with relative position
representations,” in <em id="bib.bib273.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT, New Orleans, Louisiana, USA, June 1-6,
2018, Volume 2 (Short Papers)</em>, M.&nbsp;A. Walker, H.&nbsp;Ji, and A.&nbsp;Stent, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics,
2018, pp. 464–468. [Online]. Available:
<a target="_blank" href="https://doi.org/10.18653/v1/n18-2074" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/n18-2074</a>

</span>
</li>
<li id="bib.bib274" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[274]</span>
<span class="ltx_bibblock">
Z.&nbsp;Dai, Z.&nbsp;Yang, Y.&nbsp;Yang, J.&nbsp;G. Carbonell, Q.&nbsp;V. Le, and R.&nbsp;Salakhutdinov,
“Transformer-xl: Attentive language models beyond a fixed-length context,”
in <em id="bib.bib274.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Conference of the Association for
Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2,
2019, Volume 1: Long Papers</em>, A.&nbsp;Korhonen, D.&nbsp;R. Traum, and L.&nbsp;Màrquez,
Eds.&nbsp;&nbsp;&nbsp;Association for Computational
Linguistics, 2019, pp. 2978–2988. [Online]. Available:
<a target="_blank" href="https://doi.org/10.18653/v1/p19-1285" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/p19-1285</a>

</span>
</li>
<li id="bib.bib275" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[275]</span>
<span class="ltx_bibblock">
Z.&nbsp;Yang, Z.&nbsp;Dai, Y.&nbsp;Yang, J.&nbsp;Carbonell, R.&nbsp;R. Salakhutdinov, and Q.&nbsp;V. Le,
“Xlnet: Generalized autoregressive pretraining for language understanding,”
<em id="bib.bib275.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.&nbsp;32, 2019.

</span>
</li>
<li id="bib.bib276" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[276]</span>
<span class="ltx_bibblock">
B.&nbsp;Peng, J.&nbsp;Quesnelle, H.&nbsp;Fan, and E.&nbsp;Shippole, “Yarn: Efficient context
window extension of large language models,” <em id="bib.bib276.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2309.00071, 2023.

</span>
</li>
<li id="bib.bib277" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[277]</span>
<span class="ltx_bibblock">
Y.&nbsp;Sun, L.&nbsp;Dong, B.&nbsp;Patra, S.&nbsp;Ma, S.&nbsp;Huang, A.&nbsp;Benhaim, V.&nbsp;Chaudhary, X.&nbsp;Song,
and F.&nbsp;Wei, “A length-extrapolatable transformer,” <em id="bib.bib277.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2212.10554, 2022. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2212.10554" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2212.10554</a>

</span>
</li>
<li id="bib.bib278" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[278]</span>
<span class="ltx_bibblock">
H.&nbsp;Peng, N.&nbsp;Pappas, D.&nbsp;Yogatama, R.&nbsp;Schwartz, N.&nbsp;A. Smith, and L.&nbsp;Kong,
“Random feature attention,” in <em id="bib.bib278.1.1" class="ltx_emph ltx_font_italic">9th International Conference on
Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7,
2021</em>.

</span>
</li>
<li id="bib.bib279" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[279]</span>
<span class="ltx_bibblock">
M.&nbsp;Zaheer, G.&nbsp;Guruganesh, K.&nbsp;A. Dubey, J.&nbsp;Ainslie, C.&nbsp;Alberti,
S.&nbsp;Ontañón, P.&nbsp;Pham, A.&nbsp;Ravula, Q.&nbsp;Wang, L.&nbsp;Yang, and A.&nbsp;Ahmed,
“Big bird: Transformers for longer sequences,” in <em id="bib.bib279.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems 33: Annual Conference on Neural Information
Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>, 2020.

</span>
</li>
<li id="bib.bib280" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[280]</span>
<span class="ltx_bibblock">
R.&nbsp;Child, S.&nbsp;Gray, A.&nbsp;Radford, and I.&nbsp;Sutskever, “Generating long sequences
with sparse transformers,” <em id="bib.bib280.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1904.10509, 2019.

</span>
</li>
<li id="bib.bib281" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[281]</span>
<span class="ltx_bibblock">
N.&nbsp;Shazeer, “Fast transformer decoding: One write-head is all you need,”
<em id="bib.bib281.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1911.02150, 2019. [Online]. Available:
<a target="_blank" href="http://arxiv.org/abs/1911.02150" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1911.02150</a>

</span>
</li>
<li id="bib.bib282" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[282]</span>
<span class="ltx_bibblock">
J.&nbsp;Ainslie, J.&nbsp;Lee-Thorp, M.&nbsp;de&nbsp;Jong, Y.&nbsp;Zemlyanskiy, F.&nbsp;Lebrón, and
S.&nbsp;Sanghai, “Gqa: Training generalized multi-query transformer models from
multi-head checkpoints,” <em id="bib.bib282.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.13245</em>, 2023.

</span>
</li>
<li id="bib.bib283" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[283]</span>
<span class="ltx_bibblock">
T.&nbsp;Dao, D.&nbsp;Y. Fu, S.&nbsp;Ermon, A.&nbsp;Rudra, and C.&nbsp;Re, “Flashattention: Fast and
memory-efficient exact attention with IO-awareness,” in <em id="bib.bib283.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>,
2022.

</span>
</li>
<li id="bib.bib284" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[284]</span>
<span class="ltx_bibblock">
T.&nbsp;Dao, “Flashattention-2: Faster attention with better parallelism and work
partitioning,” <em id="bib.bib284.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.08691</em>, 2023.

</span>
</li>
<li id="bib.bib285" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[285]</span>
<span class="ltx_bibblock">
“vllm: Easy, fast, and cheap llm serving with pagedattention.” [Online].
Available: <a target="_blank" href="https://vllm.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://vllm.ai/</a>

</span>
</li>
<li id="bib.bib286" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[286]</span>
<span class="ltx_bibblock">
A.&nbsp;Yuan, A.&nbsp;Coenen, E.&nbsp;Reif, and D.&nbsp;Ippolito, “Wordcraft: story writing with
large language models,” in <em id="bib.bib286.1.1" class="ltx_emph ltx_font_italic">27th International Conference on
Intelligent User Interfaces</em>, 2022, pp. 841–852.

</span>
</li>
<li id="bib.bib287" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[287]</span>
<span class="ltx_bibblock">
A.&nbsp;Kazemnejad, I.&nbsp;Padhi, K.&nbsp;N. Ramamurthy, P.&nbsp;Das, and S.&nbsp;Reddy, “The impact
of positional encoding on length generalization in transformers,”
<em id="bib.bib287.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.19466, 2023.

</span>
</li>
<li id="bib.bib288" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[288]</span>
<span class="ltx_bibblock">
W.&nbsp;Xiong, J.&nbsp;Liu, I.&nbsp;Molybog, H.&nbsp;Zhang, P.&nbsp;Bhargava, R.&nbsp;Hou, L.&nbsp;Martin,
R.&nbsp;Rungta, K.&nbsp;A. Sankararaman, B.&nbsp;Oguz, M.&nbsp;Khabsa, H.&nbsp;Fang, Y.&nbsp;Mehdad,
S.&nbsp;Narang, K.&nbsp;Malik, A.&nbsp;Fan, S.&nbsp;Bhosale, S.&nbsp;Edunov, M.&nbsp;Lewis, S.&nbsp;Wang, and
H.&nbsp;Ma, “Effective long-context scaling of foundation models,” <em id="bib.bib288.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2309.16039, 2023.

</span>
</li>
<li id="bib.bib289" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[289]</span>
<span class="ltx_bibblock">
kaiokendev, “Things I’m learning while training superhot.” 2023.

</span>
</li>
<li id="bib.bib290" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[290]</span>
<span class="ltx_bibblock">
Z.&nbsp;Dong, T.&nbsp;Tang, J.&nbsp;Li, W.&nbsp;X. Zhao, and J.&nbsp;Wen, “BAMBOO: A comprehensive
benchmark for evaluating long text modeling capacities of large language
models,” <em id="bib.bib290.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.13345, 2023.

</span>
</li>
<li id="bib.bib291" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[291]</span>
<span class="ltx_bibblock">
J.&nbsp;Su. (2023) Transformer upgrade path: 12, infinite extrapolation of rerope?

</span>
</li>
<li id="bib.bib292" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[292]</span>
<span class="ltx_bibblock">
X.&nbsp;Liu, H.&nbsp;Yan, S.&nbsp;Zhang, C.&nbsp;An, X.&nbsp;Qiu, and D.&nbsp;Lin, “Scaling laws of
rope-based extrapolation,” <em id="bib.bib292.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.05209, 2023.

</span>
</li>
<li id="bib.bib293" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[293]</span>
<span class="ltx_bibblock">
A.&nbsp;Pal, D.&nbsp;Karkhanis, M.&nbsp;Roberts, S.&nbsp;Dooley, A.&nbsp;Sundararajan, and S.&nbsp;Naidu,
“Giraffe: Adventures in expanding context lengths in llms,” <em id="bib.bib293.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2308.10882, 2023.

</span>
</li>
<li id="bib.bib294" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[294]</span>
<span class="ltx_bibblock">
G.&nbsp;Izacard and E.&nbsp;Grave, “Leveraging passage retrieval with generative models
for open domain question answering,” in <em id="bib.bib294.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th
Conference of the European Chapter of the Association for Computational
Linguistics: Main Volume, EACL 2021, Online, April 19 - 23, 2021</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics,
2021, pp. 874–880.

</span>
</li>
<li id="bib.bib295" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[295]</span>
<span class="ltx_bibblock">
N.&nbsp;Ratner, Y.&nbsp;Levine, Y.&nbsp;Belinkov, O.&nbsp;Ram, I.&nbsp;Magar, O.&nbsp;Abend, E.&nbsp;Karpas,
A.&nbsp;Shashua, K.&nbsp;Leyton-Brown, and Y.&nbsp;Shoham, “Parallel context windows for
large language models,” in <em id="bib.bib295.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Volume 1: Long Papers), ACL
2023, Toronto, Canada, July 9-14, 2023</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2023, pp. 6383–6402.

</span>
</li>
<li id="bib.bib296" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[296]</span>
<span class="ltx_bibblock">
Y.&nbsp;Hao, Y.&nbsp;Sun, L.&nbsp;Dong, Z.&nbsp;Han, Y.&nbsp;Gu, and F.&nbsp;Wei, “Structured prompting:
Scaling in-context learning to 1, 000 examples,” <em id="bib.bib296.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2022.

</span>
</li>
<li id="bib.bib297" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[297]</span>
<span class="ltx_bibblock">
I.&nbsp;Beltagy, M.&nbsp;E. Peters, and A.&nbsp;Cohan, “Longformer: The long-document
transformer,” <em id="bib.bib297.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2004.05150, 2020.

</span>
</li>
<li id="bib.bib298" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[298]</span>
<span class="ltx_bibblock">
G.&nbsp;Xiao, Y.&nbsp;Tian, B.&nbsp;Chen, S.&nbsp;Han, and M.&nbsp;Lewis, “Efficient streaming language
models with attention sinks,” <em id="bib.bib298.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.17453, 2023.

</span>
</li>
<li id="bib.bib299" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[299]</span>
<span class="ltx_bibblock">
N.&nbsp;F. Liu, K.&nbsp;Lin, J.&nbsp;Hewitt, A.&nbsp;Paranjape, M.&nbsp;Bevilacqua, F.&nbsp;Petroni, and
P.&nbsp;Liang, “Lost in the middle: How language models use long contexts,”
<em id="bib.bib299.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.03172, 2023.

</span>
</li>
<li id="bib.bib300" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[300]</span>
<span class="ltx_bibblock">
C.&nbsp;Han, Q.&nbsp;Wang, W.&nbsp;Xiong, Y.&nbsp;Chen, H.&nbsp;Ji, and S.&nbsp;Wang, “Lm-infinite: Simple
on-the-fly length generalization for large language models,” <em id="bib.bib300.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2308.16137, 2023.

</span>
</li>
<li id="bib.bib301" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[301]</span>
<span class="ltx_bibblock">
A.&nbsp;Bertsch, U.&nbsp;Alon, G.&nbsp;Neubig, and M.&nbsp;R. Gormley, “Unlimiformer: Long-range
transformers with unlimited length input,” <em id="bib.bib301.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.01625,
2023.

</span>
</li>
<li id="bib.bib302" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[302]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wu, M.&nbsp;N. Rabe, D.&nbsp;Hutchins, and C.&nbsp;Szegedy, “Memorizing transformers,” in
<em id="bib.bib302.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR
2022, Virtual Event, April 25-29, 2022</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2022.

</span>
</li>
<li id="bib.bib303" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[303]</span>
<span class="ltx_bibblock">
H.&nbsp;Chen, R.&nbsp;Pasunuru, J.&nbsp;Weston, and A.&nbsp;Celikyilmaz, “Walking down the memory
maze: Beyond context limit through interactive reading,” <em id="bib.bib303.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2310.05029, 2023.

</span>
</li>
<li id="bib.bib304" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[304]</span>
<span class="ltx_bibblock">
W.&nbsp;Zhou, Y.&nbsp;E. Jiang, P.&nbsp;Cui, T.&nbsp;Wang, Z.&nbsp;Xiao, Y.&nbsp;Hou, R.&nbsp;Cotterell, and
M.&nbsp;Sachan, “Recurrentgpt: Interactive generation of (arbitrarily) long
text,” <em id="bib.bib304.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.13304, 2023.

</span>
</li>
<li id="bib.bib305" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[305]</span>
<span class="ltx_bibblock">
C.&nbsp;Packer, V.&nbsp;Fang, S.&nbsp;G. Patil, K.&nbsp;Lin, S.&nbsp;Wooders, and J.&nbsp;E. Gonzalez,
“Memgpt: Towards llms as operating systems,” <em id="bib.bib305.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2310.08560, 2023.

</span>
</li>
<li id="bib.bib306" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[306]</span>
<span class="ltx_bibblock">
P.&nbsp;Xu, W.&nbsp;Ping, X.&nbsp;Wu, L.&nbsp;McAfee, C.&nbsp;Zhu, Z.&nbsp;Liu, S.&nbsp;Subramanian,
E.&nbsp;Bakhturina, M.&nbsp;Shoeybi, and B.&nbsp;Catanzaro, “Retrieval meets long context
large language models,” <em id="bib.bib306.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.03025, 2023.

</span>
</li>
<li id="bib.bib307" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[307]</span>
<span class="ltx_bibblock">
K.&nbsp;Murray and D.&nbsp;Chiang, “Correcting length bias in neural machine
translation,” in <em id="bib.bib307.1.1" class="ltx_emph ltx_font_italic">WMT</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2018, pp. 212–223.

</span>
</li>
<li id="bib.bib308" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[308]</span>
<span class="ltx_bibblock">
A.&nbsp;Holtzman, J.&nbsp;Buys, L.&nbsp;Du, M.&nbsp;Forbes, and Y.&nbsp;Choi, “The curious case of
neural text degeneration,” in <em id="bib.bib308.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2020.

</span>
</li>
<li id="bib.bib309" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[309]</span>
<span class="ltx_bibblock">
C.-M. U. P. P. D. O.&nbsp;C. SCIENCE, <em id="bib.bib309.1.1" class="ltx_emph ltx_font_italic">Speech Understanding Systems. Summary of
Results of the Five-Year Research Effort at Carnegie-Mellon University</em>,
1977.

</span>
</li>
<li id="bib.bib310" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[310]</span>
<span class="ltx_bibblock">
P.&nbsp;Koehn and R.&nbsp;Knowles, “Six challenges for neural machine translation,” in
<em id="bib.bib310.1.1" class="ltx_emph ltx_font_italic">NMT@ACL</em>.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2017, pp. 28–39.

</span>
</li>
<li id="bib.bib311" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[311]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wu, M.&nbsp;Schuster, Z.&nbsp;Chen, Q.&nbsp;V. Le, M.&nbsp;Norouzi, W.&nbsp;Macherey, M.&nbsp;Krikun,
Y.&nbsp;Cao, Q.&nbsp;Gao, K.&nbsp;Macherey, J.&nbsp;Klingner, A.&nbsp;Shah, M.&nbsp;Johnson, X.&nbsp;Liu,
L.&nbsp;Kaiser, S.&nbsp;Gouws, Y.&nbsp;Kato, T.&nbsp;Kudo, H.&nbsp;Kazawa, K.&nbsp;Stevens, G.&nbsp;Kurian,
N.&nbsp;Patil, W.&nbsp;Wang, C.&nbsp;Young, J.&nbsp;Smith, J.&nbsp;Riesa, A.&nbsp;Rudnick, O.&nbsp;Vinyals,
G.&nbsp;Corrado, M.&nbsp;Hughes, and J.&nbsp;Dean, “Google’s neural machine translation
system: Bridging the gap between human and machine translation,”
<em id="bib.bib311.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1609.08144, 2016.

</span>
</li>
<li id="bib.bib312" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[312]</span>
<span class="ltx_bibblock">
R.&nbsp;Paulus, C.&nbsp;Xiong, and R.&nbsp;Socher, “A deep reinforced model for abstractive
summarization,” in <em id="bib.bib312.1.1" class="ltx_emph ltx_font_italic">ICLR (Poster)</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2018.

</span>
</li>
<li id="bib.bib313" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[313]</span>
<span class="ltx_bibblock">
A.&nbsp;K. Vijayakumar, M.&nbsp;Cogswell, R.&nbsp;R. Selvaraju, Q.&nbsp;Sun, S.&nbsp;Lee, D.&nbsp;J.
Crandall, and D.&nbsp;Batra, “Diverse beam search: Decoding diverse solutions
from neural sequence models,” <em id="bib.bib313.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1610.02424, 2016.

</span>
</li>
<li id="bib.bib314" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[314]</span>
<span class="ltx_bibblock">
A.&nbsp;Fan, M.&nbsp;Lewis, and Y.&nbsp;N. Dauphin, “Hierarchical neural story generation,”
in <em id="bib.bib314.1.1" class="ltx_emph ltx_font_italic">ACL (1)</em>.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2018, pp. 889–898.

</span>
</li>
<li id="bib.bib315" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[315]</span>
<span class="ltx_bibblock">
J.&nbsp;Hewitt, C.&nbsp;D. Manning, and P.&nbsp;Liang, “Truncation sampling as language model
desmoothing,” in <em id="bib.bib315.1.1" class="ltx_emph ltx_font_italic">EMNLP (Findings)</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022, pp. 3414–3427.

</span>
</li>
<li id="bib.bib316" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[316]</span>
<span class="ltx_bibblock">
Y.&nbsp;Su, T.&nbsp;Lan, Y.&nbsp;Wang, D.&nbsp;Yogatama, L.&nbsp;Kong, and N.&nbsp;Collier, “A contrastive
framework for neural text generation,” in <em id="bib.bib316.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib317" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[317]</span>
<span class="ltx_bibblock">
C.&nbsp;Meister, T.&nbsp;Pimentel, G.&nbsp;Wiher, and R.&nbsp;Cotterell, “Locally typical
sampling,” <em id="bib.bib317.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, 2023.

</span>
</li>
<li id="bib.bib318" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[318]</span>
<span class="ltx_bibblock">
X.&nbsp;L. Li, A.&nbsp;Holtzman, D.&nbsp;Fried, P.&nbsp;Liang, J.&nbsp;Eisner, T.&nbsp;Hashimoto,
L.&nbsp;Zettlemoyer, and M.&nbsp;Lewis, “Contrastive decoding: Open-ended text
generation as optimization,” in <em id="bib.bib318.1.1" class="ltx_emph ltx_font_italic">ACL (1)</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2023, pp.
12 286–12 312.

</span>
</li>
<li id="bib.bib319" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[319]</span>
<span class="ltx_bibblock">
Y.&nbsp;Chuang, Y.&nbsp;Xie, H.&nbsp;Luo, Y.&nbsp;Kim, J.&nbsp;R. Glass, and P.&nbsp;He, “Dola: Decoding by
contrasting layers improves factuality in large language models,”
<em id="bib.bib319.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.03883, 2023.

</span>
</li>
<li id="bib.bib320" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[320]</span>
<span class="ltx_bibblock">
L.&nbsp;Chen, “Dissecting batching effects in gpt inference,” 2023. [Online].
Available: <a target="_blank" href="https://le.qun.ch/en/blog/2023/05/13/transformer-batching/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://le.qun.ch/en/blog/2023/05/13/transformer-batching/</a>

</span>
</li>
<li id="bib.bib321" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[321]</span>
<span class="ltx_bibblock">
Y.&nbsp;Sheng, L.&nbsp;Zheng, B.&nbsp;Yuan, Z.&nbsp;Li, M.&nbsp;Ryabinin, B.&nbsp;Chen, P.&nbsp;Liang,
C.&nbsp;Ré, I.&nbsp;Stoica, and C.&nbsp;Zhang, “Flexgen: High-throughput generative
inference of large language models with a single GPU,” in <em id="bib.bib321.1.1" class="ltx_emph ltx_font_italic">ICML</em>,
ser. Proceedings of Machine Learning Research, vol. 202.&nbsp;&nbsp;&nbsp;PMLR, 2023, pp. 31 094–31 116.

</span>
</li>
<li id="bib.bib322" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[322]</span>
<span class="ltx_bibblock">
T.&nbsp;Dao, D.&nbsp;Haziza, F.&nbsp;Massa, and G.&nbsp;Sizov, “Flash-decoding for long-context
inference,” <a target="_blank" href="https://crfm.stanford.edu/2023/10/12/flashdecoding.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://crfm.stanford.edu/2023/10/12/flashdecoding.html</a>,
2023.

</span>
</li>
<li id="bib.bib323" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[323]</span>
<span class="ltx_bibblock">
Y.&nbsp;Leviathan, M.&nbsp;Kalman, and Y.&nbsp;Matias, “Fast inference from transformers via
speculative decoding,” in <em id="bib.bib323.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine
Learning</em>, 2023.

</span>
</li>
<li id="bib.bib324" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[324]</span>
<span class="ltx_bibblock">
C.&nbsp;Chen, S.&nbsp;Borgeaud, G.&nbsp;Irving, J.&nbsp;Lespiau, L.&nbsp;Sifre, and J.&nbsp;Jumper,
“Accelerating large language model decoding with speculative sampling,”
<em id="bib.bib324.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.01318, 2023.

</span>
</li>
<li id="bib.bib325" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[325]</span>
<span class="ltx_bibblock">
X.&nbsp;Miao, G.&nbsp;Oliaro, Z.&nbsp;Zhang, X.&nbsp;Cheng, Z.&nbsp;Wang, R.&nbsp;Y.&nbsp;Y. Wong, Z.&nbsp;Chen,
D.&nbsp;Arfeen, R.&nbsp;Abhyankar, and Z.&nbsp;Jia, “Specinfer: Accelerating generative
LLM serving with speculative inference and token tree verification,”
<em id="bib.bib325.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.09781, 2023.

</span>
</li>
<li id="bib.bib326" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[326]</span>
<span class="ltx_bibblock">
B.&nbsp;Spector and C.&nbsp;Ré, “Accelerating LLM inference with staged
speculative decoding,” <em id="bib.bib326.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.04623, 2023.

</span>
</li>
<li id="bib.bib327" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[327]</span>
<span class="ltx_bibblock">
L.&nbsp;D. Corro, A.&nbsp;D. Giorno, S.&nbsp;Agarwal, B.&nbsp;Yu, A.&nbsp;H. Awadallah, and
S.&nbsp;Mukherjee, “Skipdecode: Autoregressive skip decoding with batching and
caching for efficient LLM inference,” <em id="bib.bib327.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.02628,
2023.

</span>
</li>
<li id="bib.bib328" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[328]</span>
<span class="ltx_bibblock">
D.&nbsp;P. Kingma and J.&nbsp;Ba, “Adam: A method for stochastic optimization,” in
<em id="bib.bib328.1.1" class="ltx_emph ltx_font_italic">3rd International Conference on Learning Representations, ICLR 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings</em>, Y.&nbsp;Bengio
and Y.&nbsp;LeCun, Eds., 2015.

</span>
</li>
<li id="bib.bib329" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[329]</span>
<span class="ltx_bibblock">
I.&nbsp;Loshchilov and F.&nbsp;Hutter, “Fixing weight decay regularization in adam,”
<em id="bib.bib329.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1711.05101, 2017.

</span>
</li>
<li id="bib.bib330" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[330]</span>
<span class="ltx_bibblock">
N.&nbsp;Shazeer and M.&nbsp;Stern, “Adafactor: Adaptive learning rates with sublinear
memory cost,” in <em id="bib.bib330.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 35th International Conference on
Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden,
July 10-15, 2018</em>, ser. Proceedings of Machine Learning Research, J.&nbsp;G. Dy
and A.&nbsp;Krause, Eds., vol.&nbsp;80.&nbsp;&nbsp;&nbsp;PMLR,
2018, pp. 4603–4611.

</span>
</li>
<li id="bib.bib331" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[331]</span>
<span class="ltx_bibblock">
Y.&nbsp;Huang, Y.&nbsp;Cheng, A.&nbsp;Bapna, O.&nbsp;Firat, D.&nbsp;Chen, M.&nbsp;X. Chen, H.&nbsp;Lee, J.&nbsp;Ngiam,
Q.&nbsp;V. Le, Y.&nbsp;Wu, and Z.&nbsp;Chen, “Gpipe: Efficient training of giant neural
networks using pipeline parallelism,” in <em id="bib.bib331.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems 32: Annual Conference on Neural Information
Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,
Canada</em>, H.&nbsp;M. Wallach, H.&nbsp;Larochelle, A.&nbsp;Beygelzimer,
F.&nbsp;d’Alché-Buc, E.&nbsp;B. Fox, and R.&nbsp;Garnett, Eds., 2019, pp. 103–112.

</span>
</li>
<li id="bib.bib332" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[332]</span>
<span class="ltx_bibblock">
A.&nbsp;Harlap, D.&nbsp;Narayanan, A.&nbsp;Phanishayee, V.&nbsp;Seshadri, N.&nbsp;R. Devanur, G.&nbsp;R.
Ganger, and P.&nbsp;B. Gibbons, “Pipedream: Fast and efficient pipeline parallel
DNN training,” <em id="bib.bib332.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1806.03377, 2018.

</span>
</li>
<li id="bib.bib333" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[333]</span>
<span class="ltx_bibblock">
S.&nbsp;Rajbhandari, J.&nbsp;Rasley, O.&nbsp;Ruwase, and Y.&nbsp;He, “Zero: memory optimizations
toward training trillion parameter models,” in <em id="bib.bib333.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
International Conference for High Performance Computing, Networking, Storage
and Analysis, SC 2020, Virtual Event / Atlanta, Georgia, USA, November
9-19, 2020</em>, C.&nbsp;Cuicchi, I.&nbsp;Qualters, and W.&nbsp;T. Kramer, Eds.&nbsp;&nbsp;&nbsp;IEEE/ACM, 2020, p.&nbsp;20.

</span>
</li>
<li id="bib.bib334" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[334]</span>
<span class="ltx_bibblock">
P.&nbsp;Micikevicius, S.&nbsp;Narang, J.&nbsp;Alben, G.&nbsp;F. Diamos, E.&nbsp;Elsen, D.&nbsp;García,
B.&nbsp;Ginsburg, M.&nbsp;Houston, O.&nbsp;Kuchaiev, G.&nbsp;Venkatesh, and H.&nbsp;Wu, “Mixed
precision training,” <em id="bib.bib334.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1710.03740, 2017.

</span>
</li>
<li id="bib.bib335" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[335]</span>
<span class="ltx_bibblock">
Q.&nbsp;Xu, S.&nbsp;Li, C.&nbsp;Gong, and Y.&nbsp;You, “An efficient 2d method for training
super-large deep learning models,” <em id="bib.bib335.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2104.05343, 2021.

</span>
</li>
<li id="bib.bib336" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[336]</span>
<span class="ltx_bibblock">
B.&nbsp;Wang, Q.&nbsp;Xu, Z.&nbsp;Bian, and Y.&nbsp;You, “Tesseract: Parallelize the tensor
parallelism efficiently,” in <em id="bib.bib336.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 51st International
Conference on Parallel Processing, ICPP 2022, Bordeaux, France, 29 August
2022 - 1 September 2022</em>.&nbsp;&nbsp;&nbsp;ACM, 2022.

</span>
</li>
<li id="bib.bib337" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[337]</span>
<span class="ltx_bibblock">
Z.&nbsp;Bian, Q.&nbsp;Xu, B.&nbsp;Wang, and Y.&nbsp;You, “Maximizing parallelism in distributed
training for huge neural networks,” <em id="bib.bib337.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2105.14450, 2021.

</span>
</li>
<li id="bib.bib338" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[338]</span>
<span class="ltx_bibblock">
S.&nbsp;Li, F.&nbsp;Xue, C.&nbsp;Baranwal, Y.&nbsp;Li, and Y.&nbsp;You, “Sequence parallelism: Long
sequence training from system perspective,” <em id="bib.bib338.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, pp.
arXiv–2105, 2021.

</span>
</li>
<li id="bib.bib339" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[339]</span>
<span class="ltx_bibblock">
FairScale authors, “Fairscale: A general purpose modular pytorch library for
high performance and large scale training,”
<a target="_blank" href="https://github.com/facebookresearch/fairscale" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/facebookresearch/fairscale</a>, 2021.

</span>
</li>
<li id="bib.bib340" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[340]</span>
<span class="ltx_bibblock">
L.&nbsp;Zheng, Z.&nbsp;Li, H.&nbsp;Zhang, Y.&nbsp;Zhuang, Z.&nbsp;Chen, Y.&nbsp;Huang, Y.&nbsp;Wang, Y.&nbsp;Xu,
D.&nbsp;Zhuo, E.&nbsp;P. Xing <em id="bib.bib340.3.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Alpa: Automating inter-and
<math id="bib.bib340.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib340.1.m1.1a"><mo stretchy="false" id="bib.bib340.1.m1.1.1" xref="bib.bib340.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib340.1.m1.1b"><ci id="bib.bib340.1.m1.1.1.cmml" xref="bib.bib340.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib340.1.m1.1c">\{</annotation></semantics></math>Intra-Operator<math id="bib.bib340.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib340.2.m2.1a"><mo stretchy="false" id="bib.bib340.2.m2.1.1" xref="bib.bib340.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib340.2.m2.1b"><ci id="bib.bib340.2.m2.1.1.cmml" xref="bib.bib340.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib340.2.m2.1c">\}</annotation></semantics></math> parallelism for distributed deep learning,” in
<em id="bib.bib340.4.2" class="ltx_emph ltx_font_italic">OSDI</em>, 2022, pp. 559–578.

</span>
</li>
<li id="bib.bib341" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[341]</span>
<span class="ltx_bibblock">
T.&nbsp;Chen, B.&nbsp;Xu, C.&nbsp;Zhang, and C.&nbsp;Guestrin, “Training deep nets with sublinear
memory cost,” <em id="bib.bib341.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1604.06174, 2016.

</span>
</li>
<li id="bib.bib342" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[342]</span>
<span class="ltx_bibblock">
R.&nbsp;Lou, K.&nbsp;Zhang, and W.&nbsp;Yin, “Is prompt all you need? no. A comprehensive
and broader view of instruction learning,” <em id="bib.bib342.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.10475,
2023.

</span>
</li>
<li id="bib.bib343" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[343]</span>
<span class="ltx_bibblock">
X.&nbsp;Liu, P.&nbsp;He, W.&nbsp;Chen, and J.&nbsp;Gao, “Multi-task deep neural networks for
natural language understanding,” in <em id="bib.bib343.1.1" class="ltx_emph ltx_font_italic">ACL (1)</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2019, pp.
4487–4496.

</span>
</li>
<li id="bib.bib344" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[344]</span>
<span class="ltx_bibblock">
A.&nbsp;Aghajanyan, A.&nbsp;Gupta, A.&nbsp;Shrivastava, X.&nbsp;Chen, L.&nbsp;Zettlemoyer, and S.&nbsp;Gupta,
“Muppet: Massive multi-task representations with pre-finetuning,” in
<em id="bib.bib344.1.1" class="ltx_emph ltx_font_italic">EMNLP (1)</em>.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2021, pp. 5799–5811.

</span>
</li>
<li id="bib.bib345" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[345]</span>
<span class="ltx_bibblock">
S.&nbsp;Longpre, L.&nbsp;Hou, T.&nbsp;Vu, A.&nbsp;Webson, H.&nbsp;W. Chung, Y.&nbsp;Tay, D.&nbsp;Zhou, Q.&nbsp;V. Le,
B.&nbsp;Zoph, J.&nbsp;Wei, and A.&nbsp;Roberts, “The flan collection: Designing data and
methods for effective instruction tuning,” <em id="bib.bib345.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2301.13688,
2023.

</span>
</li>
<li id="bib.bib346" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[346]</span>
<span class="ltx_bibblock">
C.&nbsp;Xu, Q.&nbsp;Sun, K.&nbsp;Zheng, X.&nbsp;Geng, P.&nbsp;Zhao, J.&nbsp;Feng, C.&nbsp;Tao, and D.&nbsp;Jiang,
“Wizardlm: Empowering large language models to follow complex
instructions,” <em id="bib.bib346.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.12244, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2304.12244" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2304.12244</a>

</span>
</li>
<li id="bib.bib347" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[347]</span>
<span class="ltx_bibblock">
Z.&nbsp;Sun, Y.&nbsp;Shen, Q.&nbsp;Zhou, H.&nbsp;Zhang, Z.&nbsp;Chen, D.&nbsp;Cox, Y.&nbsp;Yang, and C.&nbsp;Gan,
“Principle-driven self-alignment of language models from scratch with
minimal human supervision,” <em id="bib.bib347.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.03047</em>, 2023.

</span>
</li>
<li id="bib.bib348" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[348]</span>
<span class="ltx_bibblock">
X.&nbsp;Li, P.&nbsp;Yu, C.&nbsp;Zhou, T.&nbsp;Schick, L.&nbsp;Zettlemoyer, O.&nbsp;Levy, J.&nbsp;Weston, and
M.&nbsp;Lewis, “Self-alignment with instruction backtranslation,” <em id="bib.bib348.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2308.06259, 2023.

</span>
</li>
<li id="bib.bib349" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[349]</span>
<span class="ltx_bibblock">
C.&nbsp;Zhou, P.&nbsp;Liu, P.&nbsp;Xu, S.&nbsp;Iyer, J.&nbsp;Sun, Y.&nbsp;Mao, X.&nbsp;Ma, A.&nbsp;Efrat, P.&nbsp;Yu, L.&nbsp;Yu
<em id="bib.bib349.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Lima: Less is more for alignment,” <em id="bib.bib349.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2305.11206</em>, 2023.

</span>
</li>
<li id="bib.bib350" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[350]</span>
<span class="ltx_bibblock">
L.&nbsp;Chen, S.&nbsp;Li, J.&nbsp;Yan, H.&nbsp;Wang, K.&nbsp;Gunaratna, V.&nbsp;Yadav, Z.&nbsp;Tang,
V.&nbsp;Srinivasan, T.&nbsp;Zhou, H.&nbsp;Huang, and H.&nbsp;Jin, “Alpagasus: Training A
better alpaca with fewer data,” <em id="bib.bib350.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.08701, 2023.

</span>
</li>
<li id="bib.bib351" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[351]</span>
<span class="ltx_bibblock">
S.&nbsp;Mukherjee, A.&nbsp;Mitra, G.&nbsp;Jawahar, S.&nbsp;Agarwal, H.&nbsp;Palangi, and A.&nbsp;H.
Awadallah, “Orca: Progressive learning from complex explanation traces of
GPT-4,” <em id="bib.bib351.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.02707, 2023.

</span>
</li>
<li id="bib.bib352" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[352]</span>
<span class="ltx_bibblock">
YuLan-Chat-Team, “Yulan-chat: An open-source bilingual chatbot,”
<a target="_blank" href="https://github.com/RUC-GSAI/YuLan-Chat" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/RUC-GSAI/YuLan-Chat</a>, 2023.

</span>
</li>
<li id="bib.bib353" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[353]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wang, H.&nbsp;Ivison, P.&nbsp;Dasigi, J.&nbsp;Hessel, T.&nbsp;Khot, K.&nbsp;R. Chandu, D.&nbsp;Wadden,
K.&nbsp;MacMillan, N.&nbsp;A. Smith, I.&nbsp;Beltagy, and H.&nbsp;Hajishirzi, “How far can
camels go? exploring the state of instruction tuning on open resources,”
<em id="bib.bib353.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.04751, 2023.

</span>
</li>
<li id="bib.bib354" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[354]</span>
<span class="ltx_bibblock">
B.&nbsp;Peng, C.&nbsp;Li, P.&nbsp;He, M.&nbsp;Galley, and J.&nbsp;Gao, “Instruction tuning with
GPT-4,” <em id="bib.bib354.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.03277, 2023.

</span>
</li>
<li id="bib.bib355" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[355]</span>
<span class="ltx_bibblock">
M.&nbsp;M. Krell, M.&nbsp;Kosec, S.&nbsp;P. Perez, and A.&nbsp;Fitzgibbon, “Efficient sequence
packing without cross-contamination: Accelerating large language models
without impacting performance,” <em id="bib.bib355.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.02027</em>,
2021.

</span>
</li>
<li id="bib.bib356" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[356]</span>
<span class="ltx_bibblock">
K.&nbsp;Singhal, S.&nbsp;Azizi, T.&nbsp;Tu, S.&nbsp;S. Mahdavi, J.&nbsp;Wei, H.&nbsp;W. Chung, N.&nbsp;Scales,
A.&nbsp;Tanwani, H.&nbsp;Cole-Lewis, S.&nbsp;Pfohl <em id="bib.bib356.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Large language models
encode clinical knowledge,” <em id="bib.bib356.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.13138</em>, 2022.

</span>
</li>
<li id="bib.bib357" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[357]</span>
<span class="ltx_bibblock">
J.&nbsp;Zhang, R.&nbsp;Xie, Y.&nbsp;Hou, W.&nbsp;X. Zhao, L.&nbsp;Lin, and J.&nbsp;Wen, “Recommendation as
instruction following: A large language model empowered recommendation
approach,” <em id="bib.bib357.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.07001, 2023.

</span>
</li>
<li id="bib.bib358" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[358]</span>
<span class="ltx_bibblock">
H.&nbsp;Wang, C.&nbsp;Liu, N.&nbsp;Xi, Z.&nbsp;Qiang, S.&nbsp;Zhao, B.&nbsp;Qin, and T.&nbsp;Liu, “Huatuo: Tuning
llama model with chinese medical knowledge,” <em id="bib.bib358.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2304.06975</em>, 2023.

</span>
</li>
<li id="bib.bib359" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[359]</span>
<span class="ltx_bibblock">
Q.&nbsp;Huang, M.&nbsp;Tao, Z.&nbsp;An, C.&nbsp;Zhang, C.&nbsp;Jiang, Z.&nbsp;Chen, Z.&nbsp;Wu, and Y.&nbsp;Feng,
“Lawyer llama technical report,” <em id="bib.bib359.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.15062</em>,
2023.

</span>
</li>
<li id="bib.bib360" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[360]</span>
<span class="ltx_bibblock">
S.&nbsp;Wu, O.&nbsp;Irsoy, S.&nbsp;Lu, V.&nbsp;Dabravolski, M.&nbsp;Dredze, S.&nbsp;Gehrmann, P.&nbsp;Kambadur,
D.&nbsp;Rosenberg, and G.&nbsp;Mann, “Bloomberggpt: A large language model for
finance,” <em id="bib.bib360.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.17564</em>, 2023.

</span>
</li>
<li id="bib.bib361" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[361]</span>
<span class="ltx_bibblock">
T.&nbsp;Liu and B.&nbsp;K.&nbsp;H. Low, “Goat: Fine-tuned llama outperforms gpt-4 on
arithmetic tasks,” <em id="bib.bib361.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14201</em>, 2023.

</span>
</li>
<li id="bib.bib362" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[362]</span>
<span class="ltx_bibblock">
T.&nbsp;Sun, X.&nbsp;Zhang, Z.&nbsp;He, P.&nbsp;Li, Q.&nbsp;Cheng, H.&nbsp;Yan, X.&nbsp;Liu, Y.&nbsp;Shao, Q.&nbsp;Tang,
X.&nbsp;Zhao, K.&nbsp;Chen, Y.&nbsp;Zheng, Z.&nbsp;Zhou, R.&nbsp;Li, J.&nbsp;Zhan, Y.&nbsp;Zhou, L.&nbsp;Li, X.&nbsp;Yang,
L.&nbsp;Wu, Z.&nbsp;Yin, X.&nbsp;Huang, and X.&nbsp;Qiu, “Moss: Training conversational language
models from synthetic data,” 2023.

</span>
</li>
<li id="bib.bib363" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[363]</span>
<span class="ltx_bibblock">
Y.&nbsp;Dubois, X.&nbsp;Li, R.&nbsp;Taori, T.&nbsp;Zhang, I.&nbsp;Gulrajani, J.&nbsp;Ba, C.&nbsp;Guestrin,
P.&nbsp;Liang, and T.&nbsp;B. Hashimoto, “Alpacafarm: A simulation framework for
methods that learn from human feedback,” <em id="bib.bib363.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.14387,
2023. [Online]. Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2305.14387" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.14387</a>

</span>
</li>
<li id="bib.bib364" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[364]</span>
<span class="ltx_bibblock">
D.&nbsp;Hendrycks, C.&nbsp;Burns, S.&nbsp;Basart, A.&nbsp;Zou, M.&nbsp;Mazeika, D.&nbsp;Song, and
J.&nbsp;Steinhardt, “Measuring massive multitask language understanding,” in
<em id="bib.bib364.1.1" class="ltx_emph ltx_font_italic">ICLR</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2021.

</span>
</li>
<li id="bib.bib365" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[365]</span>
<span class="ltx_bibblock">
M.&nbsp;Suzgun, N.&nbsp;Scales, N.&nbsp;Schärli, S.&nbsp;Gehrmann, Y.&nbsp;Tay, H.&nbsp;W. Chung,
A.&nbsp;Chowdhery, Q.&nbsp;V. Le, E.&nbsp;H. Chi, D.&nbsp;Zhou, and J.&nbsp;Wei, “Challenging
big-bench tasks and whether chain-of-thought can solve them,” <em id="bib.bib365.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2210.09261, 2022.

</span>
</li>
<li id="bib.bib366" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[366]</span>
<span class="ltx_bibblock">
Z.&nbsp;Kenton, T.&nbsp;Everitt, L.&nbsp;Weidinger, I.&nbsp;Gabriel, V.&nbsp;Mikulik, and G.&nbsp;Irving,
“Alignment of language agents,” <em id="bib.bib366.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2103.14659, 2021.

</span>
</li>
<li id="bib.bib367" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[367]</span>
<span class="ltx_bibblock">
D.&nbsp;M. Ziegler, N.&nbsp;Stiennon, J.&nbsp;Wu, T.&nbsp;B. Brown, A.&nbsp;Radford, D.&nbsp;Amodei, P.&nbsp;F.
Christiano, and G.&nbsp;Irving, “Fine-tuning language models from human
preferences,” <em id="bib.bib367.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1909.08593, 2019.

</span>
</li>
<li id="bib.bib368" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[368]</span>
<span class="ltx_bibblock">
A.&nbsp;Askell, Y.&nbsp;Bai, A.&nbsp;Chen, D.&nbsp;Drain, D.&nbsp;Ganguli, T.&nbsp;Henighan, A.&nbsp;Jones,
N.&nbsp;Joseph, B.&nbsp;Mann, N.&nbsp;DasSarma, N.&nbsp;Elhage, Z.&nbsp;Hatfield-Dodds,
D.&nbsp;Hernandez, J.&nbsp;Kernion, K.&nbsp;Ndousse, C.&nbsp;Olsson, D.&nbsp;Amodei, T.&nbsp;B. Brown,
J.&nbsp;Clark, S.&nbsp;McCandlish, C.&nbsp;Olah, and J.&nbsp;Kaplan, “A general language
assistant as a laboratory for alignment,” <em id="bib.bib368.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2112.00861,
2021.

</span>
</li>
<li id="bib.bib369" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[369]</span>
<span class="ltx_bibblock">
E.&nbsp;Perez, S.&nbsp;Huang, H.&nbsp;F. Song, T.&nbsp;Cai, R.&nbsp;Ring, J.&nbsp;Aslanides, A.&nbsp;Glaese,
N.&nbsp;McAleese, and G.&nbsp;Irving, “Red teaming language models with language
models,” in <em id="bib.bib369.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in
Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates,
December 7-11, 2022</em>, Y.&nbsp;Goldberg, Z.&nbsp;Kozareva, and Y.&nbsp;Zhang, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022,
pp. 3419–3448.

</span>
</li>
<li id="bib.bib370" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[370]</span>
<span class="ltx_bibblock">
J.&nbsp;Menick, M.&nbsp;Trebacz, V.&nbsp;Mikulik, J.&nbsp;Aslanides, H.&nbsp;F. Song, M.&nbsp;Chadwick,
M.&nbsp;Glaese, S.&nbsp;Young, L.&nbsp;Campbell-Gillingham, G.&nbsp;Irving, and N.&nbsp;McAleese,
“Teaching language models to support answers with verified quotes,”
<em id="bib.bib370.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2203.11147, 2022.

</span>
</li>
<li id="bib.bib371" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[371]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bai, S.&nbsp;Kadavath, S.&nbsp;Kundu, A.&nbsp;Askell, J.&nbsp;Kernion, A.&nbsp;Jones, A.&nbsp;Chen,
A.&nbsp;Goldie, A.&nbsp;Mirhoseini, C.&nbsp;McKinnon, C.&nbsp;Chen, C.&nbsp;Olsson, C.&nbsp;Olah,
D.&nbsp;Hernandez, D.&nbsp;Drain, D.&nbsp;Ganguli, D.&nbsp;Li, E.&nbsp;Tran-Johnson, E.&nbsp;Perez,
J.&nbsp;Kerr, J.&nbsp;Mueller, J.&nbsp;Ladish, J.&nbsp;Landau, K.&nbsp;Ndousse, K.&nbsp;Lukosiute,
L.&nbsp;Lovitt, M.&nbsp;Sellitto, N.&nbsp;Elhage, N.&nbsp;Schiefer, N.&nbsp;Mercado, N.&nbsp;DasSarma,
R.&nbsp;Lasenby, R.&nbsp;Larson, S.&nbsp;Ringer, S.&nbsp;Johnston, S.&nbsp;Kravec, S.&nbsp;E. Showk,
S.&nbsp;Fort, T.&nbsp;Lanham, T.&nbsp;Telleen-Lawton, T.&nbsp;Conerly, T.&nbsp;Henighan, T.&nbsp;Hume,
S.&nbsp;R. Bowman, Z.&nbsp;Hatfield-Dodds, B.&nbsp;Mann, D.&nbsp;Amodei, N.&nbsp;Joseph,
S.&nbsp;McCandlish, T.&nbsp;Brown, and J.&nbsp;Kaplan, “Constitutional AI: harmlessness
from AI feedback,” <em id="bib.bib371.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.08073, 2022. [Online].
Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2212.08073" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2212.08073</a>

</span>
</li>
<li id="bib.bib372" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[372]</span>
<span class="ltx_bibblock">
H.&nbsp;Lee, S.&nbsp;Phatale, H.&nbsp;Mansoor, K.&nbsp;Lu, T.&nbsp;Mesnard, C.&nbsp;Bishop, V.&nbsp;Carbune, and
A.&nbsp;Rastogi, “RLAIF: scaling reinforcement learning from human feedback
with AI feedback,” <em id="bib.bib372.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.00267, 2023.

</span>
</li>
<li id="bib.bib373" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[373]</span>
<span class="ltx_bibblock">
H.&nbsp;Dong, W.&nbsp;Xiong, D.&nbsp;Goyal, R.&nbsp;Pan, S.&nbsp;Diao, J.&nbsp;Zhang, K.&nbsp;Shum, and T.&nbsp;Zhang,
“RAFT: reward ranked finetuning for generative foundation model
alignment,” <em id="bib.bib373.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.06767, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2304.06767" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2304.06767</a>

</span>
</li>
<li id="bib.bib374" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[374]</span>
<span class="ltx_bibblock">
A.&nbsp;Askell, Y.&nbsp;Bai, A.&nbsp;Chen, D.&nbsp;Drain, D.&nbsp;Ganguli, T.&nbsp;Henighan, A.&nbsp;Jones,
N.&nbsp;Joseph, B.&nbsp;Mann, N.&nbsp;DasSarma <em id="bib.bib374.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “A general language assistant
as a laboratory for alignment,” <em id="bib.bib374.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.00861</em>,
2021.

</span>
</li>
<li id="bib.bib375" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[375]</span>
<span class="ltx_bibblock">
R.&nbsp;Zheng, S.&nbsp;Dou, S.&nbsp;Gao, W.&nbsp;Shen, B.&nbsp;Wang, Y.&nbsp;Liu, S.&nbsp;Jin, Q.&nbsp;Liu, L.&nbsp;Xiong,
L.&nbsp;Chen <em id="bib.bib375.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Secrets of rlhf in large language models part i:
Ppo,” <em id="bib.bib375.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.04964</em>, 2023.

</span>
</li>
<li id="bib.bib376" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[376]</span>
<span class="ltx_bibblock">
J.&nbsp;Uesato, N.&nbsp;Kushman, R.&nbsp;Kumar, H.&nbsp;F. Song, N.&nbsp;Y. Siegel, L.&nbsp;Wang,
A.&nbsp;Creswell, G.&nbsp;Irving, and I.&nbsp;Higgins, “Solving math word problems with
process- and outcome-based feedback,” <em id="bib.bib376.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.14275,
2022.

</span>
</li>
<li id="bib.bib377" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[377]</span>
<span class="ltx_bibblock">
H.&nbsp;Lightman, V.&nbsp;Kosaraju, Y.&nbsp;Burda, H.&nbsp;Edwards, B.&nbsp;Baker, T.&nbsp;Lee, J.&nbsp;Leike,
J.&nbsp;Schulman, I.&nbsp;Sutskever, and K.&nbsp;Cobbe, “Let’s verify step by step,”
<em id="bib.bib377.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.20050, 2023.

</span>
</li>
<li id="bib.bib378" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[378]</span>
<span class="ltx_bibblock">
D.&nbsp;Hendrycks, S.&nbsp;Basart, S.&nbsp;Kadavath, M.&nbsp;Mazeika, A.&nbsp;Arora, E.&nbsp;Guo, C.&nbsp;Burns,
S.&nbsp;Puranik, H.&nbsp;He, D.&nbsp;Song, and J.&nbsp;Steinhardt, “Measuring coding challenge
competence with APPS,” in <em id="bib.bib378.1.1" class="ltx_emph ltx_font_italic">NeurIPS Datasets and Benchmarks</em>, 2021.

</span>
</li>
<li id="bib.bib379" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[379]</span>
<span class="ltx_bibblock">
Q.&nbsp;Ma, H.&nbsp;Zhou, T.&nbsp;Liu, J.&nbsp;Yuan, P.&nbsp;Liu, Y.&nbsp;You, and H.&nbsp;Yang, “Let’s reward
step by step: Step-level reward model as the navigators for reasoning,”
<em id="bib.bib379.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.10080, 2023.

</span>
</li>
<li id="bib.bib380" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[380]</span>
<span class="ltx_bibblock">
D.&nbsp;Silver, J.&nbsp;Schrittwieser, K.&nbsp;Simonyan, I.&nbsp;Antonoglou, A.&nbsp;Huang, A.&nbsp;Guez,
T.&nbsp;Hubert, L.&nbsp;Baker, M.&nbsp;Lai, A.&nbsp;Bolton, Y.&nbsp;Chen, T.&nbsp;P. Lillicrap, F.&nbsp;Hui,
L.&nbsp;Sifre, G.&nbsp;van&nbsp;den Driessche, T.&nbsp;Graepel, and D.&nbsp;Hassabis, “Mastering the
game of go without human knowledge,” <em id="bib.bib380.1.1" class="ltx_emph ltx_font_italic">Nat.</em>, pp. 354–359, 2017.

</span>
</li>
<li id="bib.bib381" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[381]</span>
<span class="ltx_bibblock">
T.&nbsp;Anthony, Z.&nbsp;Tian, and D.&nbsp;Barber, “Thinking fast and slow with deep learning
and tree search,” in <em id="bib.bib381.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
30: Annual Conference on Neural Information Processing Systems 2017, December
4-9, 2017, Long Beach, CA, USA</em>, 2017, pp. 5360–5370.

</span>
</li>
<li id="bib.bib382" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[382]</span>
<span class="ltx_bibblock">
H.&nbsp;Luo, Q.&nbsp;Sun, C.&nbsp;Xu, P.&nbsp;Zhao, J.&nbsp;Lou, C.&nbsp;Tao, X.&nbsp;Geng, Q.&nbsp;Lin, S.&nbsp;Chen, and
D.&nbsp;Zhang, “Wizardmath: Empowering mathematical reasoning for large language
models via reinforced evol-instruct,” <em id="bib.bib382.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.09583,
2023.

</span>
</li>
<li id="bib.bib383" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[383]</span>
<span class="ltx_bibblock">
R.&nbsp;Liu, C.&nbsp;Jia, G.&nbsp;Zhang, Z.&nbsp;Zhuang, T.&nbsp;X. Liu, and S.&nbsp;Vosoughi, “Second
thoughts are best: Learning to re-align with human values from text edits,”
in <em id="bib.bib383.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib384" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[384]</span>
<span class="ltx_bibblock">
X.&nbsp;Lu, S.&nbsp;Welleck, J.&nbsp;Hessel, L.&nbsp;Jiang, L.&nbsp;Qin, P.&nbsp;West, P.&nbsp;Ammanabrolu, and
Y.&nbsp;Choi, “QUARK: controllable text generation with reinforced
unlearning,” in <em id="bib.bib384.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib385" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[385]</span>
<span class="ltx_bibblock">
J.&nbsp;Scheurer, J.&nbsp;A. Campos, T.&nbsp;Korbak, J.&nbsp;S. Chan, A.&nbsp;Chen, K.&nbsp;Cho, and
E.&nbsp;Perez, “Training language models with language feedback at scale,”
<em id="bib.bib385.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.16755, 2023.

</span>
</li>
<li id="bib.bib386" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[386]</span>
<span class="ltx_bibblock">
G.&nbsp;Guo, R.&nbsp;Zhao, T.&nbsp;Tang, W.&nbsp;X. Zhao, and J.-R. Wen, “Beyond imitation:
Leveraging fine-grained quality signals for alignment,” <em id="bib.bib386.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2311.04072</em>, 2023.

</span>
</li>
<li id="bib.bib387" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[387]</span>
<span class="ltx_bibblock">
R.&nbsp;Krishna, D.&nbsp;Lee, L.&nbsp;Fei-Fei, and M.&nbsp;S. Bernstein, “Socially situated
artificial intelligence enables learning from human interaction,”
<em id="bib.bib387.1.1" class="ltx_emph ltx_font_italic">Proceedings of the National Academy of Sciences of the United States of
America</em>, vol. 119, 2022. [Online]. Available:
<a target="_blank" href="https://api.semanticscholar.org/CorpusID:252381954" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:252381954</a>

</span>
</li>
<li id="bib.bib388" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[388]</span>
<span class="ltx_bibblock">
H.&nbsp;Liu, C.&nbsp;Sferrazza, and P.&nbsp;Abbeel, “Chain of hindsight aligns language
models with feedback,” <em id="bib.bib388.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.02676, 2023.

</span>
</li>
<li id="bib.bib389" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[389]</span>
<span class="ltx_bibblock">
R.&nbsp;Rafailov, A.&nbsp;Sharma, E.&nbsp;Mitchell, S.&nbsp;Ermon, C.&nbsp;D. Manning, and C.&nbsp;Finn,
“Direct preference optimization: Your language model is secretly a reward
model,” <em id="bib.bib389.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.18290, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2305.18290" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.18290</a>

</span>
</li>
<li id="bib.bib390" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[390]</span>
<span class="ltx_bibblock">
Z.&nbsp;Yuan, H.&nbsp;Yuan, C.&nbsp;Tan, W.&nbsp;Wang, S.&nbsp;Huang, and F.&nbsp;Huang, “RRHF: rank
responses to align language models with human feedback without tears,”
<em id="bib.bib390.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.05302, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2304.05302" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2304.05302</a>

</span>
</li>
<li id="bib.bib391" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[391]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhao, R.&nbsp;Joshi, T.&nbsp;Liu, M.&nbsp;Khalman, M.&nbsp;Saleh, and P.&nbsp;J. Liu, “Slic-hf:
Sequence likelihood calibration with human feedback,” <em id="bib.bib391.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.10425, 2023.

</span>
</li>
<li id="bib.bib392" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[392]</span>
<span class="ltx_bibblock">
T.&nbsp;Zhang, F.&nbsp;Liu, J.&nbsp;Wong, P.&nbsp;Abbeel, and J.&nbsp;E. Gonzalez, “The wisdom of
hindsight makes language models better instruction followers,” <em id="bib.bib392.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2302.05206, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2302.05206" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2302.05206</a>

</span>
</li>
<li id="bib.bib393" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[393]</span>
<span class="ltx_bibblock">
A.&nbsp;Hussein, M.&nbsp;M. Gaber, E.&nbsp;Elyan, and C.&nbsp;Jayne, “Imitation learning: A survey
of learning methods,” <em id="bib.bib393.1.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em>, vol.&nbsp;50, no.&nbsp;2, apr 2017.
[Online]. Available: <a target="_blank" href="https://doi.org/10.1145/3054912" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3054912</a>

</span>
</li>
<li id="bib.bib394" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[394]</span>
<span class="ltx_bibblock">
S.&nbsp;Levine, “Should i imitate or reinforce,” 2022. [Online]. Available:
<a target="_blank" href="https://www.youtube.com/watch?v=sVPm7zOrBxM" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.youtube.com/watch?v=sVPm7zOrBxM</a>

</span>
</li>
<li id="bib.bib395" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[395]</span>
<span class="ltx_bibblock">
J.&nbsp;Schulman, “Reinforcement learning from human feedback: Progress and
challenges,” 2023. [Online]. Available:
<a target="_blank" href="https://www.youtube.com/watch?v=hhiLw5Q_UFg" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.youtube.com/watch?v=hhiLw5Q_UFg</a>

</span>
</li>
<li id="bib.bib396" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[396]</span>
<span class="ltx_bibblock">
X.&nbsp;L. Li and P.&nbsp;Liang, “Prefix-tuning: Optimizing continuous prompts for
generation,” in <em id="bib.bib396.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the 11th International Joint
Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long
Papers), Virtual Event, August 1-6, 2021</em>, C.&nbsp;Zong, F.&nbsp;Xia, W.&nbsp;Li, and
R.&nbsp;Navigli, Eds.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2021, pp. 4582–4597.

</span>
</li>
<li id="bib.bib397" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[397]</span>
<span class="ltx_bibblock">
B.&nbsp;Lester, R.&nbsp;Al-Rfou, and N.&nbsp;Constant, “The power of scale for
parameter-efficient prompt tuning,” in <em id="bib.bib397.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021
Conference on Empirical Methods in Natural Language Processing, EMNLP 2021,
Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021</em>,
M.&nbsp;Moens, X.&nbsp;Huang, L.&nbsp;Specia, and S.&nbsp;W. Yih, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp. 3045–3059.

</span>
</li>
<li id="bib.bib398" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[398]</span>
<span class="ltx_bibblock">
N.&nbsp;Houlsby, A.&nbsp;Giurgiu, S.&nbsp;Jastrzebski, B.&nbsp;Morrone, Q.&nbsp;de&nbsp;Laroussilhe,
A.&nbsp;Gesmundo, M.&nbsp;Attariyan, and S.&nbsp;Gelly, “Parameter-efficient transfer
learning for NLP,” in <em id="bib.bib398.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 36th International
Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach,
California, USA</em>, 2019, pp. 2790–2799.

</span>
</li>
<li id="bib.bib399" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[399]</span>
<span class="ltx_bibblock">
Z.&nbsp;Hu, Y.&nbsp;Lan, L.&nbsp;Wang, W.&nbsp;Xu, E.&nbsp;Lim, R.&nbsp;K. Lee, L.&nbsp;Bing, and S.&nbsp;Poria,
“Llm-adapters: An adapter family for parameter-efficient fine-tuning of
large language models,” <em id="bib.bib399.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.01933, 2023.

</span>
</li>
<li id="bib.bib400" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[400]</span>
<span class="ltx_bibblock">
J.&nbsp;He, C.&nbsp;Zhou, X.&nbsp;Ma, T.&nbsp;Berg-Kirkpatrick, and G.&nbsp;Neubig, “Towards a
unified view of parameter-efficient transfer learning,” in <em id="bib.bib400.1.1" class="ltx_emph ltx_font_italic">The Tenth
International Conference on Learning Representations, ICLR 2022, Virtual
Event, April 25-29, 2022</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2022.

</span>
</li>
<li id="bib.bib401" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[401]</span>
<span class="ltx_bibblock">
X.&nbsp;Liu, K.&nbsp;Ji, Y.&nbsp;Fu, Z.&nbsp;Du, Z.&nbsp;Yang, and J.&nbsp;Tang, “P-tuning v2: Prompt tuning
can be comparable to fine-tuning universally across scales and tasks,”
<em id="bib.bib401.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2110.07602, 2021.

</span>
</li>
<li id="bib.bib402" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[402]</span>
<span class="ltx_bibblock">
X.&nbsp;Liu, Y.&nbsp;Zheng, Z.&nbsp;Du, M.&nbsp;Ding, Y.&nbsp;Qian, Z.&nbsp;Yang, and J.&nbsp;Tang, “GPT
understands, too,” <em id="bib.bib402.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2103.10385, 2021.

</span>
</li>
<li id="bib.bib403" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[403]</span>
<span class="ltx_bibblock">
Y.&nbsp;Gu, X.&nbsp;Han, Z.&nbsp;Liu, and M.&nbsp;Huang, “Ppt: Pre-trained prompt tuning for
few-shot learning,” in <em id="bib.bib403.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers)</em>, 2022, pp.
8410–8423.

</span>
</li>
<li id="bib.bib404" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[404]</span>
<span class="ltx_bibblock">
Z.&nbsp;Jiang, F.&nbsp;F. Xu, J.&nbsp;Araki, and G.&nbsp;Neubig, “How can we know what language
models know?” <em id="bib.bib404.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational
Linguistics</em>, vol.&nbsp;8, pp. 423–438, 2020.

</span>
</li>
<li id="bib.bib405" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[405]</span>
<span class="ltx_bibblock">
T.&nbsp;Shin, Y.&nbsp;Razeghi, R.&nbsp;L. Logan&nbsp;IV, E.&nbsp;Wallace, and S.&nbsp;Singh, “Autoprompt:
Eliciting knowledge from language models with automatically generated
prompts,” in <em id="bib.bib405.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP)</em>, 2020, pp. 4222–4235.

</span>
</li>
<li id="bib.bib406" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[406]</span>
<span class="ltx_bibblock">
Q.&nbsp;Zhang, M.&nbsp;Chen, A.&nbsp;Bukharin, P.&nbsp;He, Y.&nbsp;Cheng, W.&nbsp;Chen, and T.&nbsp;Zhao,
“Adaptive budget allocation for parameter-efficient fine-tuning,”
<em id="bib.bib406.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.10512, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2303.10512" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2303.10512</a>

</span>
</li>
<li id="bib.bib407" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[407]</span>
<span class="ltx_bibblock">
M.&nbsp;Valipour, M.&nbsp;Rezagholizadeh, I.&nbsp;Kobyzev, and A.&nbsp;Ghodsi, “Dylora: Parameter
efficient tuning of pre-trained models using dynamic search-free low-rank
adaptation,” <em id="bib.bib407.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.07558, 2022. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2210.07558" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2210.07558</a>

</span>
</li>
<li id="bib.bib408" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[408]</span>
<span class="ltx_bibblock">
N.&nbsp;Ding, Y.&nbsp;Qin, G.&nbsp;Yang, F.&nbsp;Wei, Y.&nbsp;Zonghan, Y.&nbsp;Su, S.&nbsp;Hu, Y.&nbsp;Chen, C.-M.
Chan, W.&nbsp;Chen, J.&nbsp;Yi, W.&nbsp;Zhao, X.&nbsp;Wang, Z.&nbsp;Liu, H.-T. Zheng, J.&nbsp;Chen, Y.&nbsp;Liu,
J.&nbsp;Tang, J.&nbsp;Li, and M.&nbsp;Sun, “Parameter-efficient fine-tuning of large-scale
pre-trained language models,” <em id="bib.bib408.1.1" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, vol.&nbsp;5,
pp. 1–16, 03 2023.

</span>
</li>
<li id="bib.bib409" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[409]</span>
<span class="ltx_bibblock">
R.&nbsp;Zhang, J.&nbsp;Han, A.&nbsp;Zhou, X.&nbsp;Hu, S.&nbsp;Yan, P.&nbsp;Lu, H.&nbsp;Li, P.&nbsp;Gao, and Y.&nbsp;Qiao,
“Llama-adapter: Efficient fine-tuning of language models with zero-init
attention,” <em id="bib.bib409.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.16199, 2023.

</span>
</li>
<li id="bib.bib410" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[410]</span>
<span class="ltx_bibblock">
J.&nbsp;Pfeiffer, I.&nbsp;Vulic, I.&nbsp;Gurevych, and S.&nbsp;Ruder, “MAD-X: an adapter-based
framework for multi-task cross-lingual transfer,” in <em id="bib.bib410.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2020 Conference on Empirical Methods in Natural Language Processing,
EMNLP 2020, Online, November 16-20, 2020</em>, B.&nbsp;Webber, T.&nbsp;Cohn, Y.&nbsp;He, and
Y.&nbsp;Liu, Eds.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2020, pp. 7654–7673.

</span>
</li>
<li id="bib.bib411" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[411]</span>
<span class="ltx_bibblock">
S.&nbsp;Mangrulkar, S.&nbsp;Gugger, L.&nbsp;Debut, Y.&nbsp;Belkada, and S.&nbsp;Paul, “Peft:
State-of-the-art parameter-efficient fine-tuning methods,”
<a target="_blank" href="https://github.com/huggingface/peft" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/peft</a>, 2022.

</span>
</li>
<li id="bib.bib412" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[412]</span>
<span class="ltx_bibblock">
A.&nbsp;Gholami, S.&nbsp;Kim, Z.&nbsp;Dong, Z.&nbsp;Yao, M.&nbsp;W. Mahoney, and K.&nbsp;Keutzer, “A survey
of quantization methods for efficient neural network inference,”
<em id="bib.bib412.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2103.13630, 2021. [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/2103.13630" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2103.13630</a>

</span>
</li>
<li id="bib.bib413" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[413]</span>
<span class="ltx_bibblock">
T.&nbsp;Dettmers, M.&nbsp;Lewis, Y.&nbsp;Belkada, and L.&nbsp;Zettlemoyer, “Llm.int8(): 8-bit
matrix multiplication for transformers at scale,” <em id="bib.bib413.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2208.07339, 2022.

</span>
</li>
<li id="bib.bib414" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[414]</span>
<span class="ltx_bibblock">
G.&nbsp;Xiao, J.&nbsp;Lin, M.&nbsp;Seznec, J.&nbsp;Demouth, and S.&nbsp;Han, “Smoothquant: Accurate and
efficient post-training quantization for large language models,”
<em id="bib.bib414.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.10438, 2022. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2211.10438" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2211.10438</a>

</span>
</li>
<li id="bib.bib415" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[415]</span>
<span class="ltx_bibblock">
Z.&nbsp;Yao, R.&nbsp;Y. Aminabadi, M.&nbsp;Zhang, X.&nbsp;Wu, C.&nbsp;Li, and Y.&nbsp;He, “Zeroquant:
Efficient and affordable post-training quantization for large-scale
transformers,” in <em id="bib.bib415.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib416" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[416]</span>
<span class="ltx_bibblock">
J.&nbsp;Lin, J.&nbsp;Tang, H.&nbsp;Tang, S.&nbsp;Yang, X.&nbsp;Dang, and S.&nbsp;Han, “Awq: Activation-aware
weight quantization for llm compression and acceleration,” 2023.

</span>
</li>
<li id="bib.bib417" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[417]</span>
<span class="ltx_bibblock">
E.&nbsp;Frantar, S.&nbsp;Ashkboos, T.&nbsp;Hoefler, and D.&nbsp;Alistarh, “Gptq: Accurate
post-training quantization for generative pre-trained transformers,”
<em id="bib.bib417.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.17323</em>, 2022.

</span>
</li>
<li id="bib.bib418" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[418]</span>
<span class="ltx_bibblock">
E.&nbsp;Frantar and D.&nbsp;Alistarh, “Optimal brain compression: A framework for
accurate post-training quantization and pruning,” in <em id="bib.bib418.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib419" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[419]</span>
<span class="ltx_bibblock">
T.&nbsp;Dettmers, A.&nbsp;Pagnoni, A.&nbsp;Holtzman, and L.&nbsp;Zettlemoyer, “Qlora: Efficient
finetuning of quantized llms,” <em id="bib.bib419.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14314</em>, 2023.

</span>
</li>
<li id="bib.bib420" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[420]</span>
<span class="ltx_bibblock">
Z.&nbsp;Liu, B.&nbsp;Oguz, C.&nbsp;Zhao, E.&nbsp;Chang, P.&nbsp;Stock, Y.&nbsp;Mehdad, Y.&nbsp;Shi,
R.&nbsp;Krishnamoorthi, and V.&nbsp;Chandra, “Llm-qat: Data-free quantization aware
training for large language models,” 2023.

</span>
</li>
<li id="bib.bib421" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[421]</span>
<span class="ltx_bibblock">
Z.&nbsp;Yao, X.&nbsp;Wu, C.&nbsp;Li, S.&nbsp;Youn, and Y.&nbsp;He, “Zeroquant-v2: Exploring
post-training quantization in llms from comprehensive study to low rank
compensation,” 2023.

</span>
</li>
<li id="bib.bib422" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[422]</span>
<span class="ltx_bibblock">
T.&nbsp;Dettmers and L.&nbsp;Zettlemoyer, “The case for 4-bit precision: k-bit inference
scaling laws,” <em id="bib.bib422.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.09720, 2022.

</span>
</li>
<li id="bib.bib423" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[423]</span>
<span class="ltx_bibblock">
L.&nbsp;Peiyu, L.&nbsp;Zikang, G.&nbsp;Ze-Feng, G.&nbsp;Dawei, Z.&nbsp;W. Xin, L.&nbsp;Yaliang, D.&nbsp;Bolin, and
W.&nbsp;Ji-Rong, “Do emergent abilities exist in quantized large language models:
An empirical study,” <em id="bib.bib423.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.08072</em>, 2023.

</span>
</li>
<li id="bib.bib424" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[424]</span>
<span class="ltx_bibblock">
T.&nbsp;Dettmers, M.&nbsp;Lewis, Y.&nbsp;Belkada, and L.&nbsp;Zettlemoyer, “Llm.int8(): 8-bit
matrix multiplication for transformers at scale,” <em id="bib.bib424.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2208.07339, 2022. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2208.07339" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2208.07339</a>

</span>
</li>
<li id="bib.bib425" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[425]</span>
<span class="ltx_bibblock">
X.&nbsp;Wei, X.&nbsp;Cui, N.&nbsp;Cheng, X.&nbsp;Wang, X.&nbsp;Zhang, S.&nbsp;Huang, P.&nbsp;Xie, J.&nbsp;Xu, Y.&nbsp;Chen,
M.&nbsp;Zhang <em id="bib.bib425.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Zero-shot information extraction via chatting with
chatgpt,” <em id="bib.bib425.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.10205</em>, 2023.

</span>
</li>
<li id="bib.bib426" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[426]</span>
<span class="ltx_bibblock">
T.&nbsp;Dettmers, M.&nbsp;Lewis, S.&nbsp;Shleifer, and L.&nbsp;Zettlemoyer, “8-bit optimizers via
block-wise quantization,” <em id="bib.bib426.1.1" class="ltx_emph ltx_font_italic">9th International Conference on Learning
Representations, ICLR</em>, 2022.

</span>
</li>
<li id="bib.bib427" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[427]</span>
<span class="ltx_bibblock">
C.&nbsp;Tao, L.&nbsp;Hou, W.&nbsp;Zhang, L.&nbsp;Shang, X.&nbsp;Jiang, Q.&nbsp;Liu, P.&nbsp;Luo, and N.&nbsp;Wong,
“Compression of generative pre-trained language models via quantization,”
in <em id="bib.bib427.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin,
Ireland, May 22-27, 2022</em>, S.&nbsp;Muresan, P.&nbsp;Nakov, and A.&nbsp;Villavicencio,
Eds.&nbsp;&nbsp;&nbsp;Association for Computational
Linguistics, 2022, pp. 4821–4836.

</span>
</li>
<li id="bib.bib428" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[428]</span>
<span class="ltx_bibblock">
J.&nbsp;Liu, D.&nbsp;Shen, Y.&nbsp;Zhang, B.&nbsp;Dolan, L.&nbsp;Carin, and W.&nbsp;Chen, “What makes good
in-context examples for gpt-3?” in <em id="bib.bib428.1.1" class="ltx_emph ltx_font_italic">Proceedings of Deep Learning Inside
Out: The 3rd Workshop on Knowledge Extraction and Integration for Deep
Learning Architectures, DeeLIO@ACL 2022, Dublin, Ireland and Online, May 27,
2022</em>, 2022, pp. 100–114.

</span>
</li>
<li id="bib.bib429" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[429]</span>
<span class="ltx_bibblock">
O.&nbsp;Rubin, J.&nbsp;Herzig, and J.&nbsp;Berant, “Learning to retrieve prompts for
in-context learning,” in <em id="bib.bib429.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of the
North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, NAACL 2022, Seattle, WA, United States, July
10-15, 2022</em>, 2022, pp. 2655–2671.

</span>
</li>
<li id="bib.bib430" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[430]</span>
<span class="ltx_bibblock">
H.&nbsp;J. Kim, H.&nbsp;Cho, J.&nbsp;Kim, T.&nbsp;Kim, K.&nbsp;M. Yoo, and S.&nbsp;Lee, “Self-generated
in-context learning: Leveraging auto-regressive language models as a
demonstration generator,” <em id="bib.bib430.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2206.08082, 2022.

</span>
</li>
<li id="bib.bib431" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[431]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhou, A.&nbsp;I. Muresanu, Z.&nbsp;Han, K.&nbsp;Paster, S.&nbsp;Pitis, H.&nbsp;Chan, and J.&nbsp;Ba,
“Large language models are human-level prompt engineers,” in <em id="bib.bib431.1.1" class="ltx_emph ltx_font_italic">Proc. of
ICLR</em>, 2023.

</span>
</li>
<li id="bib.bib432" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[432]</span>
<span class="ltx_bibblock">
Y.&nbsp;Lu, M.&nbsp;Bartolo, A.&nbsp;Moore, S.&nbsp;Riedel, and P.&nbsp;Stenetorp, “Fantastically
ordered prompts and where to find them: Overcoming few-shot prompt order
sensitivity,” in <em id="bib.bib432.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers), ACL
2022, Dublin, Ireland, May 22-27, 2022</em>, S.&nbsp;Muresan, P.&nbsp;Nakov, and
A.&nbsp;Villavicencio, Eds., 2022, pp. 8086–8098.

</span>
</li>
<li id="bib.bib433" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[433]</span>
<span class="ltx_bibblock">
Y.&nbsp;Fu, H.&nbsp;Peng, A.&nbsp;Sabharwal, P.&nbsp;Clark, and T.&nbsp;Khot, “Complexity-based
prompting for multi-step reasoning,” <em id="bib.bib433.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.00720, 2022.

</span>
</li>
<li id="bib.bib434" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[434]</span>
<span class="ltx_bibblock">
Z.&nbsp;Zhang, A.&nbsp;Zhang, M.&nbsp;Li, and A.&nbsp;Smola, “Automatic chain of thought prompting
in large language models,” <em id="bib.bib434.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.03493, 2022.

</span>
</li>
<li id="bib.bib435" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[435]</span>
<span class="ltx_bibblock">
A.&nbsp;Creswell, M.&nbsp;Shanahan, and I.&nbsp;Higgins, “Selection-inference: Exploiting
large language models for interpretable logical reasoning,” <em id="bib.bib435.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2205.09712, 2022.

</span>
</li>
<li id="bib.bib436" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[436]</span>
<span class="ltx_bibblock">
X.&nbsp;Wang, J.&nbsp;Wei, D.&nbsp;Schuurmans, Q.&nbsp;V. Le, E.&nbsp;H. Chi, and D.&nbsp;Zhou,
“Self-consistency improves chain of thought reasoning in language models,”
<em id="bib.bib436.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2203.11171, 2022.

</span>
</li>
<li id="bib.bib437" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[437]</span>
<span class="ltx_bibblock">
Y.&nbsp;Li, Z.&nbsp;Lin, S.&nbsp;Zhang, Q.&nbsp;Fu, B.&nbsp;Chen, J.&nbsp;Lou, and W.&nbsp;Chen, “On the advance
of making language models better reasoners,” <em id="bib.bib437.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2206.02336, 2022.

</span>
</li>
<li id="bib.bib438" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[438]</span>
<span class="ltx_bibblock">
X.&nbsp;Wang, J.&nbsp;Wei, D.&nbsp;Schuurmans, Q.&nbsp;V. Le, E.&nbsp;H. Chi, and D.&nbsp;Zhou,
“Rationale-augmented ensembles in language models,” <em id="bib.bib438.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2022.

</span>
</li>
<li id="bib.bib439" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[439]</span>
<span class="ltx_bibblock">
D.&nbsp;Zhou, N.&nbsp;Schärli, L.&nbsp;Hou, J.&nbsp;Wei, N.&nbsp;Scales, X.&nbsp;Wang, D.&nbsp;Schuurmans,
O.&nbsp;Bousquet, Q.&nbsp;Le, and E.&nbsp;H. Chi, “Least-to-most prompting enables complex
reasoning in large language models,” <em id="bib.bib439.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2205.10625, 2022.

</span>
</li>
<li id="bib.bib440" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[440]</span>
<span class="ltx_bibblock">
T.&nbsp;Khot, H.&nbsp;Trivedi, M.&nbsp;Finlayson, Y.&nbsp;Fu, K.&nbsp;Richardson, P.&nbsp;Clark, and
A.&nbsp;Sabharwal, “Decomposed prompting: A modular approach for solving
complex tasks,” <em id="bib.bib440.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.02406, 2022. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2210.02406" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2210.02406</a>

</span>
</li>
<li id="bib.bib441" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[441]</span>
<span class="ltx_bibblock">
L.&nbsp;Wang, W.&nbsp;Xu, Y.&nbsp;Lan, Z.&nbsp;Hu, Y.&nbsp;Lan, R.&nbsp;K. Lee, and E.&nbsp;Lim, “Plan-and-solve
prompting: Improving zero-shot chain-of-thought reasoning by large language
models,” <em id="bib.bib441.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.04091, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2305.04091" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.04091</a>

</span>
</li>
<li id="bib.bib442" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[442]</span>
<span class="ltx_bibblock">
Q.&nbsp;Lyu, S.&nbsp;Havaldar, A.&nbsp;Stein, L.&nbsp;Zhang, D.&nbsp;Rao, E.&nbsp;Wong, M.&nbsp;Apidianaki, and
C.&nbsp;Callison-Burch, “Faithful chain-of-thought reasoning,” <em id="bib.bib442.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2301.13379, 2023.

</span>
</li>
<li id="bib.bib443" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[443]</span>
<span class="ltx_bibblock">
L.&nbsp;Gao, A.&nbsp;Madaan, S.&nbsp;Zhou, U.&nbsp;Alon, P.&nbsp;Liu, Y.&nbsp;Yang, J.&nbsp;Callan, and G.&nbsp;Neubig,
“PAL: program-aided language models,” <em id="bib.bib443.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.10435,
2022.

</span>
</li>
<li id="bib.bib444" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[444]</span>
<span class="ltx_bibblock">
Y.&nbsp;Shen, K.&nbsp;Song, X.&nbsp;Tan, D.&nbsp;Li, W.&nbsp;Lu, and Y.&nbsp;Zhuang, “Hugginggpt: Solving ai
tasks with chatgpt and its friends in huggingface,” <em id="bib.bib444.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2303.17580</em>, 2023.

</span>
</li>
<li id="bib.bib445" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[445]</span>
<span class="ltx_bibblock">
H.&nbsp;Sun, Y.&nbsp;Zhuang, L.&nbsp;Kong, B.&nbsp;Dai, and C.&nbsp;Zhang, “Adaplanner: Adaptive
planning from feedback with language models,” <em id="bib.bib445.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2305.16653</em>, 2023.

</span>
</li>
<li id="bib.bib446" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[446]</span>
<span class="ltx_bibblock">
Y.&nbsp;Lu, P.&nbsp;Lu, Z.&nbsp;Chen, W.&nbsp;Zhu, X.&nbsp;E. Wang, and W.&nbsp;Y. Wang, “Multimodal
procedural planning via dual text-image prompting,” <em id="bib.bib446.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.01795, 2023.

</span>
</li>
<li id="bib.bib447" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[447]</span>
<span class="ltx_bibblock">
S.&nbsp;Hao, Y.&nbsp;Gu, H.&nbsp;Ma, J.&nbsp;J. Hong, Z.&nbsp;Wang, D.&nbsp;Z. Wang, and Z.&nbsp;Hu, “Reasoning
with language model is planning with world model,” <em id="bib.bib447.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.14992, 2023.

</span>
</li>
<li id="bib.bib448" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[448]</span>
<span class="ltx_bibblock">
Z.&nbsp;Chen, K.&nbsp;Zhou, B.&nbsp;Zhang, Z.&nbsp;Gong, W.&nbsp;X. Zhao, and J.&nbsp;Wen, “Chatcot:
Tool-augmented chain-of-thought reasoning on chat-based large language
models,” <em id="bib.bib448.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.14323, 2023.

</span>
</li>
<li id="bib.bib449" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[449]</span>
<span class="ltx_bibblock">
S.&nbsp;Yao, J.&nbsp;Zhao, D.&nbsp;Yu, N.&nbsp;Du, I.&nbsp;Shafran, K.&nbsp;Narasimhan, and Y.&nbsp;Cao, “React:
Synergizing reasoning and acting in language models,” <em id="bib.bib449.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2210.03629, 2022.

</span>
</li>
<li id="bib.bib450" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[450]</span>
<span class="ltx_bibblock">
N.&nbsp;Shinn, F.&nbsp;Cassano, B.&nbsp;Labash, A.&nbsp;Gopinath, K.&nbsp;Narasimhan, and S.&nbsp;Yao,
“Reflexion: Language agents with verbal reinforcement learning,” 2023.

</span>
</li>
<li id="bib.bib451" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[451]</span>
<span class="ltx_bibblock">
S.&nbsp;Yao, D.&nbsp;Yu, J.&nbsp;Zhao, I.&nbsp;Shafran, T.&nbsp;L. Griffiths, Y.&nbsp;Cao, and K.&nbsp;Narasimhan,
“Tree of thoughts: Deliberate problem solving with large language models,”
<em id="bib.bib451.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.10601, 2023.

</span>
</li>
<li id="bib.bib452" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[452]</span>
<span class="ltx_bibblock">
V.&nbsp;Liu and L.&nbsp;B. Chilton, “Design guidelines for prompt engineering
text-to-image generative models,” in <em id="bib.bib452.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 CHI
Conference on Human Factors in Computing Systems</em>, 2022, pp. 1–23.

</span>
</li>
<li id="bib.bib453" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[453]</span>
<span class="ltx_bibblock">
J.&nbsp;White, Q.&nbsp;Fu, S.&nbsp;Hays, M.&nbsp;Sandborn, C.&nbsp;Olea, H.&nbsp;Gilbert, A.&nbsp;Elnashar,
J.&nbsp;Spencer-Smith, and D.&nbsp;C. Schmidt, “A prompt pattern catalog to enhance
prompt engineering with chatgpt,” <em id="bib.bib453.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.11382</em>,
2023.

</span>
</li>
<li id="bib.bib454" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[454]</span>
<span class="ltx_bibblock">
S.&nbsp;K.&nbsp;K. Santu and D.&nbsp;Feng, “Teler: A general taxonomy of LLM prompts for
benchmarking complex tasks,” <em id="bib.bib454.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.11430, 2023.
[Online]. Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2305.11430" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.11430</a>

</span>
</li>
<li id="bib.bib455" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[455]</span>
<span class="ltx_bibblock">
OpenAI, “Gpt best practices,” <em id="bib.bib455.1.1" class="ltx_emph ltx_font_italic">OpenAI</em>, 2023. [Online]. Available:
<a target="_blank" href="https://platform.openai.com/docs/guides/gpt-best-practices" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://platform.openai.com/docs/guides/gpt-best-practices</a>

</span>
</li>
<li id="bib.bib456" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[456]</span>
<span class="ltx_bibblock">
Contributors, “Ai short,” 2023. [Online]. Available:
<a target="_blank" href="https://www.aishort.top/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aishort.top/</a>

</span>
</li>
<li id="bib.bib457" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[457]</span>
<span class="ltx_bibblock">
——, “Awesome chatgpt prompts,” <em id="bib.bib457.1.1" class="ltx_emph ltx_font_italic">Github</em>, 2023. [Online]. Available:
<a target="_blank" href="https://github.com/f/awesome-chatgpt-prompts/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/f/awesome-chatgpt-prompts/</a>

</span>
</li>
<li id="bib.bib458" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[458]</span>
<span class="ltx_bibblock">
J.&nbsp;Jiang, K.&nbsp;Zhou, Z.&nbsp;Dong, K.&nbsp;Ye, W.&nbsp;X. Zhao, and J.&nbsp;Wen, “Structgpt: A
general framework for large language model to reason over structured data,”
<em id="bib.bib458.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.09645, 2023.

</span>
</li>
<li id="bib.bib459" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[459]</span>
<span class="ltx_bibblock">
L.&nbsp;Beurer-Kellner, M.&nbsp;Fischer, and M.&nbsp;Vechev, “Prompting is programming: A
query language for large language models,” <em id="bib.bib459.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on
Programming Languages</em>, vol.&nbsp;7, no. PLDI, pp. 1946–1969, 2023.

</span>
</li>
<li id="bib.bib460" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[460]</span>
<span class="ltx_bibblock">
P.&nbsp;Lu, B.&nbsp;Peng, H.&nbsp;Cheng, M.&nbsp;Galley, K.-W. Chang, Y.&nbsp;N. Wu, S.-C. Zhu, and
J.&nbsp;Gao, “Chameleon: Plug-and-play compositional reasoning with large
language models,” <em id="bib.bib460.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.09842</em>, 2023.

</span>
</li>
<li id="bib.bib461" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[461]</span>
<span class="ltx_bibblock">
R.&nbsp;Ren, Y.&nbsp;Wang, Y.&nbsp;Qu, W.&nbsp;X. Zhao, J.&nbsp;Liu, H.&nbsp;Tian, H.&nbsp;Wu, J.-R. Wen, and
H.&nbsp;Wang, “Investigating the factual knowledge boundary of large language
models with retrieval augmentation,” <em id="bib.bib461.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.11019</em>,
2023.

</span>
</li>
<li id="bib.bib462" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[462]</span>
<span class="ltx_bibblock">
Y.&nbsp;Hou, J.&nbsp;Zhang, Z.&nbsp;Lin, H.&nbsp;Lu, R.&nbsp;Xie, J.&nbsp;J. McAuley, and W.&nbsp;X. Zhao, “Large
language models are zero-shot rankers for recommender systems,” <em id="bib.bib462.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2305.08845, 2023.

</span>
</li>
<li id="bib.bib463" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[463]</span>
<span class="ltx_bibblock">
S.&nbsp;Chang and E.&nbsp;Fosler-Lussier, “How to prompt llms for text-to-sql: A
study in zero-shot, single-domain, and cross-domain settings,” <em id="bib.bib463.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2305.11853, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2305.11853" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.11853</a>

</span>
</li>
<li id="bib.bib464" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[464]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wen, N.&nbsp;Jain, J.&nbsp;Kirchenbauer, M.&nbsp;Goldblum, J.&nbsp;Geiping, and T.&nbsp;Goldstein,
“Hard prompts made easy: Gradient-based discrete optimization for prompt
tuning and discovery,” <em id="bib.bib464.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.03668, 2023. [Online].
Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2302.03668" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2302.03668</a>

</span>
</li>
<li id="bib.bib465" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[465]</span>
<span class="ltx_bibblock">
T.&nbsp;Gao, A.&nbsp;Fisch, and D.&nbsp;Chen, “Making pre-trained language models better
few-shot learners,” in <em id="bib.bib465.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the 11th International Joint
Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long
Papers), Virtual Event, August 1-6, 2021</em>, C.&nbsp;Zong, F.&nbsp;Xia, W.&nbsp;Li, and
R.&nbsp;Navigli, Eds.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2021, pp. 3816–3830.

</span>
</li>
<li id="bib.bib466" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[466]</span>
<span class="ltx_bibblock">
L.&nbsp;Chen, J.&nbsp;Chen, T.&nbsp;Goldstein, H.&nbsp;Huang, and T.&nbsp;Zhou, “Instructzero:
Efficient instruction optimization for black-box large language models,”
<em id="bib.bib466.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.03082, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2306.03082" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2306.03082</a>

</span>
</li>
<li id="bib.bib467" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[467]</span>
<span class="ltx_bibblock">
M.&nbsp;Deng, J.&nbsp;Wang, C.&nbsp;Hsieh, Y.&nbsp;Wang, H.&nbsp;Guo, T.&nbsp;Shu, M.&nbsp;Song, E.&nbsp;P. Xing, and
Z.&nbsp;Hu, “Rlprompt: Optimizing discrete text prompts with reinforcement
learning,” in <em id="bib.bib467.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods
in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab
Emirates, December 7-11, 2022</em>, Y.&nbsp;Goldberg, Z.&nbsp;Kozareva, and Y.&nbsp;Zhang,
Eds.&nbsp;&nbsp;&nbsp;Association for Computational
Linguistics, 2022, pp. 3369–3391.

</span>
</li>
<li id="bib.bib468" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[468]</span>
<span class="ltx_bibblock">
T.&nbsp;Zhang, X.&nbsp;Wang, D.&nbsp;Zhou, D.&nbsp;Schuurmans, and J.&nbsp;E. Gonzalez, “TEMPERA:
test-time prompt editing via reinforcement learning,” in <em id="bib.bib468.1.1" class="ltx_emph ltx_font_italic">The Eleventh
International Conference on Learning Representations, ICLR 2023, Kigali,
Rwanda, May 1-5, 2023</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2023.

</span>
</li>
<li id="bib.bib469" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[469]</span>
<span class="ltx_bibblock">
H.&nbsp;Xu, Y.&nbsp;Chen, Y.&nbsp;Du, N.&nbsp;Shao, Y.&nbsp;Wang, H.&nbsp;Li, and Z.&nbsp;Yang, “GPS: genetic
prompt search for efficient few-shot learning,” in <em id="bib.bib469.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2022 Conference on Empirical Methods in Natural Language Processing, EMNLP
2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, Y.&nbsp;Goldberg,
Z.&nbsp;Kozareva, and Y.&nbsp;Zhang, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022, pp. 8162–8171.

</span>
</li>
<li id="bib.bib470" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[470]</span>
<span class="ltx_bibblock">
A.&nbsp;Prasad, P.&nbsp;Hase, X.&nbsp;Zhou, and M.&nbsp;Bansal, “Grips: Gradient-free, edit-based
instruction search for prompting large language models,” in
<em id="bib.bib470.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 17th Conference of the European Chapter of the
Association for Computational Linguistics, EACL 2023, Dubrovnik, Croatia,
May 2-6, 2023</em>, A.&nbsp;Vlachos and I.&nbsp;Augenstein, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2023, pp. 3827–3846.

</span>
</li>
<li id="bib.bib471" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[471]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhou, A.&nbsp;I. Muresanu, Z.&nbsp;Han, K.&nbsp;Paster, S.&nbsp;Pitis, H.&nbsp;Chan, and J.&nbsp;Ba,
“Large language models are human-level prompt engineers,” in <em id="bib.bib471.1.1" class="ltx_emph ltx_font_italic">The
Eleventh International Conference on Learning Representations, ICLR 2023,
Kigali, Rwanda, May 1-5, 2023</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2023.

</span>
</li>
<li id="bib.bib472" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[472]</span>
<span class="ltx_bibblock">
R.&nbsp;Pryzant, D.&nbsp;Iter, J.&nbsp;Li, Y.&nbsp;T. Lee, C.&nbsp;Zhu, and M.&nbsp;Zeng, “Automatic prompt
optimization with ”gradient descent” and beam search,” <em id="bib.bib472.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.03495, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2305.03495" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.03495</a>

</span>
</li>
<li id="bib.bib473" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[473]</span>
<span class="ltx_bibblock">
C.&nbsp;Yang, X.&nbsp;Wang, Y.&nbsp;Lu, H.&nbsp;Liu, Q.&nbsp;V. Le, D.&nbsp;Zhou, and X.&nbsp;Chen, “Large
language models as optimizers,” <em id="bib.bib473.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.03409, 2023.
[Online]. Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2309.03409" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2309.03409</a>

</span>
</li>
<li id="bib.bib474" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[474]</span>
<span class="ltx_bibblock">
X.&nbsp;Wang, C.&nbsp;Li, Z.&nbsp;Wang, F.&nbsp;Bai, H.&nbsp;Luo, J.&nbsp;Zhang, N.&nbsp;Jojic, E.&nbsp;P. Xing, and
Z.&nbsp;Hu, “Promptagent: Strategic planning with language models enables
expert-level prompt optimization,” <em id="bib.bib474.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.16427, 2023.
[Online]. Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2310.16427" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2310.16427</a>

</span>
</li>
<li id="bib.bib475" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[475]</span>
<span class="ltx_bibblock">
T.&nbsp;Tang, J.&nbsp;Li, W.&nbsp;X. Zhao, and J.&nbsp;Wen, “Context-tuning: Learning
contextualized prompts for natural language generation,” in
<em id="bib.bib475.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th International Conference on Computational
Linguistics, COLING 2022, Gyeongju, Republic of Korea, October 12-17,
2022</em>, N.&nbsp;Calzolari, C.&nbsp;Huang, H.&nbsp;Kim, J.&nbsp;Pustejovsky, L.&nbsp;Wanner, K.&nbsp;Choi,
P.&nbsp;Ryu, H.&nbsp;Chen, L.&nbsp;Donatelli, H.&nbsp;Ji, S.&nbsp;Kurohashi, P.&nbsp;Paggio, N.&nbsp;Xue,
S.&nbsp;Kim, Y.&nbsp;Hahm, Z.&nbsp;He, T.&nbsp;K. Lee, E.&nbsp;Santus, F.&nbsp;Bond, and S.&nbsp;Na, Eds.&nbsp;&nbsp;&nbsp;International Committee on Computational
Linguistics, 2022, pp. 6340–6354.

</span>
</li>
<li id="bib.bib476" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[476]</span>
<span class="ltx_bibblock">
T.&nbsp;Vu, B.&nbsp;Lester, N.&nbsp;Constant, R.&nbsp;Al-Rfou’, and D.&nbsp;Cer, “Spot: Better frozen
model adaptation through soft prompt transfer,” in <em id="bib.bib476.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
60th Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, S.&nbsp;Muresan,
P.&nbsp;Nakov, and A.&nbsp;Villavicencio, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022, pp. 5039–5059.

</span>
</li>
<li id="bib.bib477" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[477]</span>
<span class="ltx_bibblock">
J.&nbsp;Li, T.&nbsp;Tang, J.&nbsp;Nie, J.&nbsp;Wen, and X.&nbsp;Zhao, “Learning to transfer prompts for
text generation,” in <em id="bib.bib477.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15,
2022</em>, M.&nbsp;Carpuat, M.&nbsp;de&nbsp;Marneffe, and I.&nbsp;V.&nbsp;M. Ruíz, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022,
pp. 3506–3518.

</span>
</li>
<li id="bib.bib478" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[478]</span>
<span class="ltx_bibblock">
S.&nbsp;Min, X.&nbsp;Lyu, A.&nbsp;Holtzman, M.&nbsp;Artetxe, M.&nbsp;Lewis, H.&nbsp;Hajishirzi, and
L.&nbsp;Zettlemoyer, “Rethinking the role of demonstrations: What makes
in-context learning work?” in <em id="bib.bib478.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on
Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi,
United Arab Emirates, December 7-11, 2022</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022, pp.
11 048–11 064.

</span>
</li>
<li id="bib.bib479" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[479]</span>
<span class="ltx_bibblock">
Z.&nbsp;Zhao, E.&nbsp;Wallace, S.&nbsp;Feng, D.&nbsp;Klein, and S.&nbsp;Singh, “Calibrate before use:
Improving few-shot performance of language models,” in <em id="bib.bib479.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the 38th International Conference on Machine Learning, ICML 2021, 18-24
July 2021, Virtual Event</em>, M.&nbsp;Meila and T.&nbsp;Zhang, Eds., 2021, pp.
12 697–12 706.

</span>
</li>
<li id="bib.bib480" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[480]</span>
<span class="ltx_bibblock">
Y.&nbsp;Lee, C.&nbsp;Lim, and H.&nbsp;Choi, “Does GPT-3 generate empathetic dialogues? A
novel in-context example selection method and automatic evaluation metric for
empathetic dialogue generation,” in <em id="bib.bib480.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th
International Conference on Computational Linguistics, COLING 2022,
Gyeongju, Republic of Korea, October 12-17, 2022</em>, N.&nbsp;Calzolari, C.&nbsp;Huang,
H.&nbsp;Kim, J.&nbsp;Pustejovsky, L.&nbsp;Wanner, K.&nbsp;Choi, P.&nbsp;Ryu, H.&nbsp;Chen, L.&nbsp;Donatelli,
H.&nbsp;Ji, S.&nbsp;Kurohashi, P.&nbsp;Paggio, N.&nbsp;Xue, S.&nbsp;Kim, Y.&nbsp;Hahm, Z.&nbsp;He, T.&nbsp;K. Lee,
E.&nbsp;Santus, F.&nbsp;Bond, and S.&nbsp;Na, Eds.&nbsp;&nbsp;&nbsp;International Committee on Computational Linguistics, 2022, pp. 669–683.

</span>
</li>
<li id="bib.bib481" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[481]</span>
<span class="ltx_bibblock">
I.&nbsp;Levy, B.&nbsp;Bogin, and J.&nbsp;Berant, “Diverse demonstrations improve in-context
compositional generalization,” <em id="bib.bib481.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.06800, 2022.

</span>
</li>
<li id="bib.bib482" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[482]</span>
<span class="ltx_bibblock">
H.&nbsp;Su, J.&nbsp;Kasai, C.&nbsp;H. Wu, W.&nbsp;Shi, T.&nbsp;Wang, J.&nbsp;Xin, R.&nbsp;Zhang, M.&nbsp;Ostendorf,
L.&nbsp;Zettlemoyer, N.&nbsp;A. Smith, and T.&nbsp;Yu, “Selective annotation makes language
models better few-shot learners,” <em id="bib.bib482.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2022.

</span>
</li>
<li id="bib.bib483" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[483]</span>
<span class="ltx_bibblock">
X.&nbsp;Ye, S.&nbsp;Iyer, A.&nbsp;Celikyilmaz, V.&nbsp;Stoyanov, G.&nbsp;Durrett, and R.&nbsp;Pasunuru,
“Complementary explanations for effective in-context learning,”
<em id="bib.bib483.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2022.

</span>
</li>
<li id="bib.bib484" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[484]</span>
<span class="ltx_bibblock">
X.&nbsp;Li and X.&nbsp;Qiu, “Finding supporting examples for in-context learning,”
<em id="bib.bib484.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2023.

</span>
</li>
<li id="bib.bib485" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[485]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhang, S.&nbsp;Feng, and C.&nbsp;Tan, “Active example selection for in-context
learning,” in <em id="bib.bib485.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods
in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab
Emirates, December 7-11, 2022</em>, 2022, pp. 9134–9148.

</span>
</li>
<li id="bib.bib486" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[486]</span>
<span class="ltx_bibblock">
F.&nbsp;Gilardi, M.&nbsp;Alizadeh, and M.&nbsp;Kubli, “Chatgpt outperforms crowd-workers for
text-annotation tasks,” 2023.

</span>
</li>
<li id="bib.bib487" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[487]</span>
<span class="ltx_bibblock">
H.&nbsp;J. Kim, H.&nbsp;Cho, J.&nbsp;Kim, T.&nbsp;Kim, K.&nbsp;M. Yoo, and S.&nbsp;Lee, “Self-generated
in-context learning: Leveraging auto-regressive language models as a
demonstration generator,” <em id="bib.bib487.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2206.08082, 2022.

</span>
</li>
<li id="bib.bib488" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[488]</span>
<span class="ltx_bibblock">
S.&nbsp;M. Xie, A.&nbsp;Raghunathan, P.&nbsp;Liang, and T.&nbsp;Ma, “An explanation of in-context
learning as implicit bayesian inference,” in <em id="bib.bib488.1.1" class="ltx_emph ltx_font_italic">The Tenth International
Conference on Learning Representations, ICLR 2022, Virtual Event, April
25-29, 2022</em>, 2022.

</span>
</li>
<li id="bib.bib489" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[489]</span>
<span class="ltx_bibblock">
Z.&nbsp;Wu, Y.&nbsp;Wang, J.&nbsp;Ye, and L.&nbsp;Kong, “Self-adaptive in-context learning,”
<em id="bib.bib489.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.10375, 2022.

</span>
</li>
<li id="bib.bib490" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[490]</span>
<span class="ltx_bibblock">
Y.&nbsp;Gu, L.&nbsp;Dong, F.&nbsp;Wei, and M.&nbsp;Huang, “Pre-training to learn in context,”
<em id="bib.bib490.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.09137, 2023.

</span>
</li>
<li id="bib.bib491" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[491]</span>
<span class="ltx_bibblock">
S.&nbsp;Min, M.&nbsp;Lewis, L.&nbsp;Zettlemoyer, and H.&nbsp;Hajishirzi, “Metaicl: Learning to
learn in context,” in <em id="bib.bib491.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15,
2022</em>, M.&nbsp;Carpuat, M.&nbsp;de&nbsp;Marneffe, and I.&nbsp;V.&nbsp;M. Ruíz, Eds., 2022, pp.
2791–2809.

</span>
</li>
<li id="bib.bib492" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[492]</span>
<span class="ltx_bibblock">
M.&nbsp;Hahn and N.&nbsp;Goyal, “A theory of emergent in-context learning as implicit
structure induction,” <em id="bib.bib492.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.07971, 2023.

</span>
</li>
<li id="bib.bib493" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[493]</span>
<span class="ltx_bibblock">
J.&nbsp;Pan, T.&nbsp;Gao, H.&nbsp;Chen, and D.&nbsp;Chen, “What in-context learning ”learns”
in-context: Disentangling task recognition and task learning,” <em id="bib.bib493.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2305.09731, 2023.

</span>
</li>
<li id="bib.bib494" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[494]</span>
<span class="ltx_bibblock">
N.&nbsp;Wies, Y.&nbsp;Levine, and A.&nbsp;Shashua, “The learnability of in-context
learning,” <em id="bib.bib494.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.07895, 2023.

</span>
</li>
<li id="bib.bib495" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[495]</span>
<span class="ltx_bibblock">
A.&nbsp;Webson and E.&nbsp;Pavlick, “Do prompt-based models really understand the
meaning of their prompts?” in <em id="bib.bib495.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of
the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, NAACL 2022, Seattle, WA, United States, July
10-15, 2022</em>, 2022, pp. 2300–2344.

</span>
</li>
<li id="bib.bib496" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[496]</span>
<span class="ltx_bibblock">
J.&nbsp;von Oswald, E.&nbsp;Niklasson, E.&nbsp;Randazzo, J.&nbsp;Sacramento, A.&nbsp;Mordvintsev,
A.&nbsp;Zhmoginov, and M.&nbsp;Vladymyrov, “Transformers learn in-context by gradient
descent,” <em id="bib.bib496.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.07677, 2022.

</span>
</li>
<li id="bib.bib497" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[497]</span>
<span class="ltx_bibblock">
C.&nbsp;Olsson, N.&nbsp;Elhage, N.&nbsp;Nanda, N.&nbsp;Joseph, N.&nbsp;DasSarma, T.&nbsp;Henighan, B.&nbsp;Mann,
A.&nbsp;Askell, Y.&nbsp;Bai, A.&nbsp;Chen, T.&nbsp;Conerly, D.&nbsp;Drain, D.&nbsp;Ganguli,
Z.&nbsp;Hatfield-Dodds, D.&nbsp;Hernandez, S.&nbsp;Johnston, A.&nbsp;Jones, J.&nbsp;Kernion,
L.&nbsp;Lovitt, K.&nbsp;Ndousse, D.&nbsp;Amodei, T.&nbsp;Brown, J.&nbsp;Clark, J.&nbsp;Kaplan,
S.&nbsp;McCandlish, and C.&nbsp;Olah, “In-context learning and induction heads,”
<em id="bib.bib497.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2209.11895, 2022.

</span>
</li>
<li id="bib.bib498" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[498]</span>
<span class="ltx_bibblock">
E.&nbsp;Akyürek, D.&nbsp;Schuurmans, J.&nbsp;Andreas, T.&nbsp;Ma, and D.&nbsp;Zhou, “What
learning algorithm is in-context learning? investigations with linear
models,” <em id="bib.bib498.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.15661, 2022.

</span>
</li>
<li id="bib.bib499" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[499]</span>
<span class="ltx_bibblock">
J.&nbsp;Wei, J.&nbsp;Wei, Y.&nbsp;Tay, D.&nbsp;Tran, A.&nbsp;Webson, Y.&nbsp;Lu, X.&nbsp;Chen, H.&nbsp;Liu, D.&nbsp;Huang,
D.&nbsp;Zhou <em id="bib.bib499.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Larger language models do in-context learning
differently,” <em id="bib.bib499.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.03846</em>, 2023.

</span>
</li>
<li id="bib.bib500" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[500]</span>
<span class="ltx_bibblock">
J.&nbsp;Coda-Forno, M.&nbsp;Binz, Z.&nbsp;Akata, M.&nbsp;M. Botvinick, J.&nbsp;X. Wang, and E.&nbsp;Schulz,
“Meta-in-context learning in large language models,” <em id="bib.bib500.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.12907, 2023.

</span>
</li>
<li id="bib.bib501" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[501]</span>
<span class="ltx_bibblock">
J.&nbsp;W. Wei, L.&nbsp;Hou, A.&nbsp;K. Lampinen, X.&nbsp;Chen, D.&nbsp;Huang, Y.&nbsp;Tay, X.&nbsp;Chen, Y.&nbsp;Lu,
D.&nbsp;Zhou, T.&nbsp;Ma, and Q.&nbsp;V. Le, “Symbol tuning improves in-context learning in
language models,” <em id="bib.bib501.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.08298, 2023.

</span>
</li>
<li id="bib.bib502" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[502]</span>
<span class="ltx_bibblock">
Z.&nbsp;Chu, J.&nbsp;Chen, Q.&nbsp;Chen, W.&nbsp;Yu, T.&nbsp;He, H.&nbsp;Wang, W.&nbsp;Peng, M.&nbsp;Liu, B.&nbsp;Qin, and
T.&nbsp;Liu, “A survey of chain of thought reasoning: Advances, frontiers and
future,” <em id="bib.bib502.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.15402, 2023.

</span>
</li>
<li id="bib.bib503" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[503]</span>
<span class="ltx_bibblock">
S.&nbsp;Miao, C.&nbsp;Liang, and K.&nbsp;Su, “A diverse corpus for evaluating and developing
english math word problem solvers,” in <em id="bib.bib503.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics, ACL 2020, Online,
July 5-10, 2020</em>, D.&nbsp;Jurafsky, J.&nbsp;Chai, N.&nbsp;Schluter, and J.&nbsp;R. Tetreault,
Eds.&nbsp;&nbsp;&nbsp;Association for Computational
Linguistics, 2020, pp. 975–984.

</span>
</li>
<li id="bib.bib504" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[504]</span>
<span class="ltx_bibblock">
A.&nbsp;Talmor, J.&nbsp;Herzig, N.&nbsp;Lourie, and J.&nbsp;Berant, “Commonsenseqa: A question
answering challenge targeting commonsense knowledge,” in <em id="bib.bib504.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2019 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, NAACL-HLT 2019,
Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>,
J.&nbsp;Burstein, C.&nbsp;Doran, and T.&nbsp;Solorio, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2019, pp. 4149–4158.

</span>
</li>
<li id="bib.bib505" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[505]</span>
<span class="ltx_bibblock">
T.&nbsp;Kojima, S.&nbsp;S. Gu, M.&nbsp;Reid, Y.&nbsp;Matsuo, and Y.&nbsp;Iwasawa, “Large language
models are zero-shot reasoners,” <em id="bib.bib505.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2205.11916, 2022.

</span>
</li>
<li id="bib.bib506" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[506]</span>
<span class="ltx_bibblock">
W.&nbsp;Chen, X.&nbsp;Ma, X.&nbsp;Wang, and W.&nbsp;W. Cohen, “Program of thoughts prompting:
Disentangling computation from reasoning for numerical reasoning tasks,”
<em id="bib.bib506.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.12588, 2022.

</span>
</li>
<li id="bib.bib507" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[507]</span>
<span class="ltx_bibblock">
L.&nbsp;Gao, A.&nbsp;Madaan, S.&nbsp;Zhou, U.&nbsp;Alon, P.&nbsp;Liu, Y.&nbsp;Yang, J.&nbsp;Callan, and G.&nbsp;Neubig,
“PAL: program-aided language models,” in <em id="bib.bib507.1.1" class="ltx_emph ltx_font_italic">International Conference
on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA</em>,
A.&nbsp;Krause, E.&nbsp;Brunskill, K.&nbsp;Cho, B.&nbsp;Engelhardt, S.&nbsp;Sabato, and J.&nbsp;Scarlett,
Eds., 2023.

</span>
</li>
<li id="bib.bib508" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[508]</span>
<span class="ltx_bibblock">
X.&nbsp;Zhao, Y.&nbsp;Xie, K.&nbsp;Kawaguchi, J.&nbsp;He, and Q.&nbsp;Xie, “Automatic model selection
with large language models for reasoning,” <em id="bib.bib508.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.14333,
2023.

</span>
</li>
<li id="bib.bib509" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[509]</span>
<span class="ltx_bibblock">
Y.&nbsp;Li, Z.&nbsp;Lin, S.&nbsp;Zhang, Q.&nbsp;Fu, B.&nbsp;Chen, J.-G. Lou, and W.&nbsp;Chen, “Making large
language models better reasoners with step-aware verifier,” 2023.

</span>
</li>
<li id="bib.bib510" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[510]</span>
<span class="ltx_bibblock">
O.&nbsp;Yoran, T.&nbsp;Wolfson, B.&nbsp;Bogin, U.&nbsp;Katz, D.&nbsp;Deutch, and J.&nbsp;Berant, “Answering
questions by meta-reasoning over multiple chains of thought,” <em id="bib.bib510.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2304.13007, 2023.

</span>
</li>
<li id="bib.bib511" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[511]</span>
<span class="ltx_bibblock">
Z.&nbsp;Ling, Y.&nbsp;Fang, X.&nbsp;Li, Z.&nbsp;Huang, M.&nbsp;Lee, R.&nbsp;Memisevic, and H.&nbsp;Su, “Deductive
verification of chain-of-thought reasoning,” <em id="bib.bib511.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.03872, 2023.

</span>
</li>
<li id="bib.bib512" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[512]</span>
<span class="ltx_bibblock">
T.&nbsp;Xue, Z.&nbsp;Wang, Z.&nbsp;Wang, C.&nbsp;Han, P.&nbsp;Yu, and H.&nbsp;Ji, “RCOT: detecting and
rectifying factual inconsistency in reasoning by reversing
chain-of-thought,” <em id="bib.bib512.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.11499, 2023.

</span>
</li>
<li id="bib.bib513" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[513]</span>
<span class="ltx_bibblock">
Y.&nbsp;Weng, M.&nbsp;Zhu, F.&nbsp;Xia, B.&nbsp;Li, S.&nbsp;He, K.&nbsp;Liu, and J.&nbsp;Zhao, “Large language
models are better reasoners with self-verification,” <em id="bib.bib513.1.1" class="ltx_emph ltx_font_italic">CoRR,
abs/2212.09561</em>, 2023.

</span>
</li>
<li id="bib.bib514" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[514]</span>
<span class="ltx_bibblock">
W.&nbsp;Jiang, H.&nbsp;Shi, L.&nbsp;Yu, Z.&nbsp;Liu, Y.&nbsp;Zhang, Z.&nbsp;Li, and J.&nbsp;T. Kwok,
“Forward-backward reasoning in large language models for mathematical
verification,” 2023.

</span>
</li>
<li id="bib.bib515" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[515]</span>
<span class="ltx_bibblock">
J.&nbsp;Long, “Large language model guided tree-of-thought,” <em id="bib.bib515.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.08291, 2023.

</span>
</li>
<li id="bib.bib516" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[516]</span>
<span class="ltx_bibblock">
S.&nbsp;Mo and M.&nbsp;Xin, “Tree of uncertain thoughts reasoning for large language
models,” <em id="bib.bib516.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.07694, 2023.

</span>
</li>
<li id="bib.bib517" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[517]</span>
<span class="ltx_bibblock">
M.&nbsp;Besta, N.&nbsp;Blach, A.&nbsp;Kubicek, R.&nbsp;Gerstenberger, L.&nbsp;Gianinazzi, J.&nbsp;Gajda,
T.&nbsp;Lehmann, M.&nbsp;Podstawski, H.&nbsp;Niewiadomski, P.&nbsp;Nyczyk, and T.&nbsp;Hoefler,
“Graph of thoughts: Solving elaborate problems with large language models,”
<em id="bib.bib517.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.09687, 2023.

</span>
</li>
<li id="bib.bib518" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[518]</span>
<span class="ltx_bibblock">
B.&nbsp;Lei, P.&nbsp;Lin, C.&nbsp;Liao, and C.&nbsp;Ding, “Boosting logical reasoning in large
language models through a new framework: The graph of thought,” <em id="bib.bib518.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2308.08614, 2023.

</span>
</li>
<li id="bib.bib519" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[519]</span>
<span class="ltx_bibblock">
R.&nbsp;Ding, C.&nbsp;Zhang, L.&nbsp;Wang, Y.&nbsp;Xu, M.&nbsp;Ma, W.&nbsp;Zhang, S.&nbsp;Qin, S.&nbsp;Rajmohan,
Q.&nbsp;Lin, and D.&nbsp;Zhang, “Everything of thoughts: Defying the law of penrose
triangle for thought generation,” <em id="bib.bib519.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.04254</em>,
2023.

</span>
</li>
<li id="bib.bib520" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[520]</span>
<span class="ltx_bibblock">
P.&nbsp;Liang, R.&nbsp;Bommasani, T.&nbsp;Lee, D.&nbsp;Tsipras, D.&nbsp;Soylu, M.&nbsp;Yasunaga, Y.&nbsp;Zhang,
D.&nbsp;Narayanan, Y.&nbsp;Wu, A.&nbsp;Kumar, B.&nbsp;Newman, B.&nbsp;Yuan, B.&nbsp;Yan, C.&nbsp;Zhang,
C.&nbsp;Cosgrove, C.&nbsp;D. Manning, C.&nbsp;Ré, D.&nbsp;Acosta-Navas, D.&nbsp;A. Hudson,
E.&nbsp;Zelikman, E.&nbsp;Durmus, F.&nbsp;Ladhak, F.&nbsp;Rong, H.&nbsp;Ren, H.&nbsp;Yao, J.&nbsp;Wang,
K.&nbsp;Santhanam, L.&nbsp;J. Orr, L.&nbsp;Zheng, M.&nbsp;Yüksekgönül,
M.&nbsp;Suzgun, N.&nbsp;Kim, N.&nbsp;Guha, N.&nbsp;S. Chatterji, O.&nbsp;Khattab, P.&nbsp;Henderson,
Q.&nbsp;Huang, R.&nbsp;Chi, S.&nbsp;M. Xie, S.&nbsp;Santurkar, S.&nbsp;Ganguli, T.&nbsp;Hashimoto,
T.&nbsp;Icard, T.&nbsp;Zhang, V.&nbsp;Chaudhary, W.&nbsp;Wang, X.&nbsp;Li, Y.&nbsp;Mai, Y.&nbsp;Zhang, and
Y.&nbsp;Koreeda, “Holistic evaluation of language models,” <em id="bib.bib520.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2211.09110, 2022.

</span>
</li>
<li id="bib.bib521" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[521]</span>
<span class="ltx_bibblock">
Z.&nbsp;Bi, N.&nbsp;Zhang, Y.&nbsp;Jiang, S.&nbsp;Deng, G.&nbsp;Zheng, and H.&nbsp;Chen, “When do
program-of-thoughts work for reasoning?” <em id="bib.bib521.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.15452,
2023.

</span>
</li>
<li id="bib.bib522" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[522]</span>
<span class="ltx_bibblock">
A.&nbsp;Madaan and A.&nbsp;Yazdanbakhsh, “Text and patterns: For effective chain of
thought, it takes two to tango,” <em id="bib.bib522.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2209.07686, 2022.

</span>
</li>
<li id="bib.bib523" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[523]</span>
<span class="ltx_bibblock">
Z.&nbsp;Zhang, A.&nbsp;Zhang, M.&nbsp;Li, H.&nbsp;Zhao, G.&nbsp;Karypis, and A.&nbsp;Smola, “Multimodal
chain-of-thought reasoning in language models,” <em id="bib.bib523.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2302.00923, 2023.

</span>
</li>
<li id="bib.bib524" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[524]</span>
<span class="ltx_bibblock">
F.&nbsp;Shi, M.&nbsp;Suzgun, M.&nbsp;Freitag, X.&nbsp;Wang, S.&nbsp;Srivats, S.&nbsp;Vosoughi, H.&nbsp;W. Chung,
Y.&nbsp;Tay, S.&nbsp;Ruder, D.&nbsp;Zhou, D.&nbsp;Das, and J.&nbsp;Wei, “Language models are
multilingual chain-of-thought reasoners,” <em id="bib.bib524.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.03057,
2022.

</span>
</li>
<li id="bib.bib525" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[525]</span>
<span class="ltx_bibblock">
J.&nbsp;Qian, H.&nbsp;Wang, Z.&nbsp;Li, S.&nbsp;Li, and X.&nbsp;Yan, “Limitations of language models in
arithmetic and symbolic induction,” <em id="bib.bib525.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2208.05051, 2022.

</span>
</li>
<li id="bib.bib526" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[526]</span>
<span class="ltx_bibblock">
N.&nbsp;Bian, X.&nbsp;Han, L.&nbsp;Sun, H.&nbsp;Lin, Y.&nbsp;Lu, and B.&nbsp;He, “ChatGPT is a
Knowledgeable but Inexperienced Solver: An Investigation of Commonsense
Problem in Large Language Models,” <em id="bib.bib526.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2023.

</span>
</li>
<li id="bib.bib527" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[527]</span>
<span class="ltx_bibblock">
S.&nbsp;Yao, D.&nbsp;Yu, J.&nbsp;Zhao, I.&nbsp;Shafran, T.&nbsp;L. Griffiths, Y.&nbsp;Cao, and K.&nbsp;Narasimhan,
“Tree of thoughts: Deliberate problem solving with large language models,”
<em id="bib.bib527.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.10601, 2023.

</span>
</li>
<li id="bib.bib528" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[528]</span>
<span class="ltx_bibblock">
G.&nbsp;Wang, Y.&nbsp;Xie, Y.&nbsp;Jiang, A.&nbsp;Mandlekar, C.&nbsp;Xiao, Y.&nbsp;Zhu, L.&nbsp;Fan, and
A.&nbsp;Anandkumar, “Voyager: An open-ended embodied agent with large language
models,” <em id="bib.bib528.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.16291</em>, 2023.

</span>
</li>
<li id="bib.bib529" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[529]</span>
<span class="ltx_bibblock">
X.&nbsp;Jiang, Y.&nbsp;Dong, L.&nbsp;Wang, Q.&nbsp;Shang, and G.&nbsp;Li, “Self-planning code
generation with large language model,” <em id="bib.bib529.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.06689,
2023. [Online]. Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2303.06689" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2303.06689</a>

</span>
</li>
<li id="bib.bib530" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[530]</span>
<span class="ltx_bibblock">
I.&nbsp;Singh, V.&nbsp;Blukis, A.&nbsp;Mousavian, A.&nbsp;Goyal, D.&nbsp;Xu, J.&nbsp;Tremblay, D.&nbsp;Fox,
J.&nbsp;Thomason, and A.&nbsp;Garg, “Progprompt: Generating situated robot task plans
using large language models,” <em id="bib.bib530.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2209.11302, 2022.

</span>
</li>
<li id="bib.bib531" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[531]</span>
<span class="ltx_bibblock">
B.&nbsp;Liu, Y.&nbsp;Jiang, X.&nbsp;Zhang, Q.&nbsp;Liu, S.&nbsp;Zhang, J.&nbsp;Biswas, and P.&nbsp;Stone,
“LLM+P: empowering large language models with optimal planning
proficiency,” <em id="bib.bib531.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.11477, 2023. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2304.11477" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2304.11477</a>

</span>
</li>
<li id="bib.bib532" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[532]</span>
<span class="ltx_bibblock">
R.&nbsp;Rombach, A.&nbsp;Blattmann, D.&nbsp;Lorenz, P.&nbsp;Esser, and B.&nbsp;Ommer, “High-resolution
image synthesis with latent diffusion models,” in <em id="bib.bib532.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF
Conference on Computer Vision and Pattern Recognition, CVPR 2022, New
Orleans, LA, USA, June 18-24, 2022</em>, 2022, pp. 10 674–10 685.

</span>
</li>
<li id="bib.bib533" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[533]</span>
<span class="ltx_bibblock">
J.&nbsp;S. Park, J.&nbsp;C. O’Brien, C.&nbsp;J. Cai, M.&nbsp;R. Morris, P.&nbsp;Liang, and M.&nbsp;S.
Bernstein, “Generative agents: Interactive simulacra of human behavior,”
<em id="bib.bib533.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.03442, 2023.

</span>
</li>
<li id="bib.bib534" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[534]</span>
<span class="ltx_bibblock">
2023. [Online]. Available:
<a target="_blank" href="https://github.com/Significant-Gravitas/Auto-GPT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Significant-Gravitas/Auto-GPT</a>

</span>
</li>
<li id="bib.bib535" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[535]</span>
<span class="ltx_bibblock">
Z.&nbsp;Wang, S.&nbsp;Cai, A.&nbsp;Liu, X.&nbsp;Ma, and Y.&nbsp;Liang, “Describe, explain, plan and
select: Interactive planning with large language models enables open-world
multi-task agents,” <em id="bib.bib535.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.01560, 2023.

</span>
</li>
<li id="bib.bib536" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[536]</span>
<span class="ltx_bibblock">
J.&nbsp;Wang, X.&nbsp;Yi, R.&nbsp;Guo, H.&nbsp;Jin, P.&nbsp;Xu, S.&nbsp;Li, X.&nbsp;Wang, X.&nbsp;Guo, C.&nbsp;Li, X.&nbsp;Xu
<em id="bib.bib536.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Milvus: A purpose-built vector data management system,” in
<em id="bib.bib536.2.2" class="ltx_emph ltx_font_italic">Proceedings of the 2021 International Conference on Management of
Data</em>, 2021, pp. 2614–2627.

</span>
</li>
<li id="bib.bib537" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[537]</span>
<span class="ltx_bibblock">
W.&nbsp;Zhong, L.&nbsp;Guo, Q.&nbsp;Gao, H.&nbsp;Ye, and Y.&nbsp;Wang, “Memorybank: Enhancing large
language models with long-term memory,” <em id="bib.bib537.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.10250,
2023.

</span>
</li>
<li id="bib.bib538" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[538]</span>
<span class="ltx_bibblock">
M.&nbsp;P. Marcus, B.&nbsp;Santorini, and M.&nbsp;A. Marcinkiewicz, “Building a large
annotated corpus of english: The penn treebank,” <em id="bib.bib538.1.1" class="ltx_emph ltx_font_italic">Comput. Linguistics</em>,
vol.&nbsp;19, no.&nbsp;2, pp. 313–330, 1993.

</span>
</li>
<li id="bib.bib539" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[539]</span>
<span class="ltx_bibblock">
S.&nbsp;Merity, C.&nbsp;Xiong, J.&nbsp;Bradbury, and R.&nbsp;Socher, “Pointer sentinel mixture
models,” in <em id="bib.bib539.1.1" class="ltx_emph ltx_font_italic">ICLR (Poster)</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2017.

</span>
</li>
<li id="bib.bib540" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[540]</span>
<span class="ltx_bibblock">
O.&nbsp;Bojar, C.&nbsp;Buck, C.&nbsp;Federmann, B.&nbsp;Haddow, P.&nbsp;Koehn, J.&nbsp;Leveling, C.&nbsp;Monz,
P.&nbsp;Pecina, M.&nbsp;Post, H.&nbsp;Saint-Amand, R.&nbsp;Soricut, L.&nbsp;Specia, and A.&nbsp;Tamchyna,
“Findings of the 2014 workshop on statistical machine translation,” in
<em id="bib.bib540.1.1" class="ltx_emph ltx_font_italic">WMT@ACL</em>.&nbsp;&nbsp;&nbsp;The Association for
Computer Linguistics, 2014, pp. 12–58.

</span>
</li>
<li id="bib.bib541" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[541]</span>
<span class="ltx_bibblock">
O.&nbsp;Bojar, R.&nbsp;Chatterjee, C.&nbsp;Federmann, Y.&nbsp;Graham, B.&nbsp;Haddow, M.&nbsp;Huck,
A.&nbsp;Jimeno-Yepes, P.&nbsp;Koehn, V.&nbsp;Logacheva, C.&nbsp;Monz, M.&nbsp;Negri,
A.&nbsp;Névéol, M.&nbsp;L. Neves, M.&nbsp;Popel, M.&nbsp;Post, R.&nbsp;Rubino, C.&nbsp;Scarton,
L.&nbsp;Specia, M.&nbsp;Turchi, K.&nbsp;Verspoor, and M.&nbsp;Zampieri, “Findings of the 2016
conference on machine translation,” in <em id="bib.bib541.1.1" class="ltx_emph ltx_font_italic">WMT</em>.&nbsp;&nbsp;&nbsp;The Association for Computer Linguistics, 2016, pp.
131–198.

</span>
</li>
<li id="bib.bib542" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[542]</span>
<span class="ltx_bibblock">
L.&nbsp;Barrault, O.&nbsp;Bojar, M.&nbsp;R. Costa-jussà, C.&nbsp;Federmann, M.&nbsp;Fishel,
Y.&nbsp;Graham, B.&nbsp;Haddow, M.&nbsp;Huck, P.&nbsp;Koehn, S.&nbsp;Malmasi, C.&nbsp;Monz,
M.&nbsp;Müller, S.&nbsp;Pal, M.&nbsp;Post, and M.&nbsp;Zampieri, “Findings of the 2019
conference on machine translation (WMT19),” in <em id="bib.bib542.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Fourth Conference on Machine Translation, WMT 2019, Florence, Italy, August
1-2, 2019 - Volume 2: Shared Task Papers, Day 1</em>, O.&nbsp;Bojar, R.&nbsp;Chatterjee,
C.&nbsp;Federmann, M.&nbsp;Fishel, Y.&nbsp;Graham, B.&nbsp;Haddow, M.&nbsp;Huck, A.&nbsp;Jimeno-Yepes,
P.&nbsp;Koehn, A.&nbsp;Martins, C.&nbsp;Monz, M.&nbsp;Negri, A.&nbsp;Névéol, M.&nbsp;L. Neves,
M.&nbsp;Post, M.&nbsp;Turchi, and K.&nbsp;Verspoor, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2019, pp. 1–61.

</span>
</li>
<li id="bib.bib543" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[543]</span>
<span class="ltx_bibblock">
L.&nbsp;Barrault, M.&nbsp;Biesialska, O.&nbsp;Bojar, M.&nbsp;R. Costa-jussà, C.&nbsp;Federmann,
Y.&nbsp;Graham, R.&nbsp;Grundkiewicz, B.&nbsp;Haddow, M.&nbsp;Huck, E.&nbsp;Joanis, T.&nbsp;Kocmi,
P.&nbsp;Koehn, C.&nbsp;Lo, N.&nbsp;Ljubesic, C.&nbsp;Monz, M.&nbsp;Morishita, M.&nbsp;Nagata, T.&nbsp;Nakazawa,
S.&nbsp;Pal, M.&nbsp;Post, and M.&nbsp;Zampieri, “Findings of the 2020 conference on
machine translation (WMT20),” in <em id="bib.bib543.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifth Conference
on Machine Translation, WMT@EMNLP 2020, Online, November 19-20, 2020</em>,
L.&nbsp;Barrault, O.&nbsp;Bojar, F.&nbsp;Bougares, R.&nbsp;Chatterjee, M.&nbsp;R. Costa-jussà,
C.&nbsp;Federmann, M.&nbsp;Fishel, A.&nbsp;Fraser, Y.&nbsp;Graham, P.&nbsp;Guzman, B.&nbsp;Haddow, M.&nbsp;Huck,
A.&nbsp;Jimeno-Yepes, P.&nbsp;Koehn, A.&nbsp;Martins, M.&nbsp;Morishita, C.&nbsp;Monz, M.&nbsp;Nagata,
T.&nbsp;Nakazawa, and M.&nbsp;Negri, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2020, pp. 1–55.

</span>
</li>
<li id="bib.bib544" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[544]</span>
<span class="ltx_bibblock">
F.&nbsp;Akhbardeh, A.&nbsp;Arkhangorodsky, M.&nbsp;Biesialska, O.&nbsp;Bojar, R.&nbsp;Chatterjee,
V.&nbsp;Chaudhary, M.&nbsp;R. Costa-jussà, C.&nbsp;España-Bonet, A.&nbsp;Fan,
C.&nbsp;Federmann, M.&nbsp;Freitag, Y.&nbsp;Graham, R.&nbsp;Grundkiewicz, B.&nbsp;Haddow, L.&nbsp;Harter,
K.&nbsp;Heafield, C.&nbsp;Homan, M.&nbsp;Huck, K.&nbsp;Amponsah-Kaakyire, J.&nbsp;Kasai,
D.&nbsp;Khashabi, K.&nbsp;Knight, T.&nbsp;Kocmi, P.&nbsp;Koehn, N.&nbsp;Lourie, C.&nbsp;Monz, M.&nbsp;Morishita,
M.&nbsp;Nagata, A.&nbsp;Nagesh, T.&nbsp;Nakazawa, M.&nbsp;Negri, S.&nbsp;Pal, A.&nbsp;A. Tapo, M.&nbsp;Turchi,
V.&nbsp;Vydrin, and M.&nbsp;Zampieri, “Findings of the 2021 conference on machine
translation (WMT21),” in <em id="bib.bib544.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Sixth Conference on
Machine Translation, WMT@EMNLP 2021, Online Event, November 10-11, 2021</em>,
L.&nbsp;Barrault, O.&nbsp;Bojar, F.&nbsp;Bougares, R.&nbsp;Chatterjee, M.&nbsp;R. Costa-jussà,
C.&nbsp;Federmann, M.&nbsp;Fishel, A.&nbsp;Fraser, M.&nbsp;Freitag, Y.&nbsp;Graham, R.&nbsp;Grundkiewicz,
P.&nbsp;Guzman, B.&nbsp;Haddow, M.&nbsp;Huck, A.&nbsp;Jimeno-Yepes, P.&nbsp;Koehn, T.&nbsp;Kocmi,
A.&nbsp;Martins, M.&nbsp;Morishita, and C.&nbsp;Monz, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp. 1–88.

</span>
</li>
<li id="bib.bib545" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[545]</span>
<span class="ltx_bibblock">
T.&nbsp;Kocmi, R.&nbsp;Bawden, O.&nbsp;Bojar, A.&nbsp;Dvorkovich, C.&nbsp;Federmann, M.&nbsp;Fishel,
T.&nbsp;Gowda, Y.&nbsp;Graham, R.&nbsp;Grundkiewicz, B.&nbsp;Haddow, R.&nbsp;Knowles, P.&nbsp;Koehn,
C.&nbsp;Monz, M.&nbsp;Morishita, M.&nbsp;Nagata, T.&nbsp;Nakazawa, M.&nbsp;Novák, M.&nbsp;Popel, and
M.&nbsp;Popovic, “Findings of the 2022 conference on machine translation
(WMT22),” in <em id="bib.bib545.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Conference on Machine
Translation, WMT 2022, Abu Dhabi, United Arab Emirates (Hybrid), December
7-8, 2022</em>, P.&nbsp;Koehn, L.&nbsp;Barrault, O.&nbsp;Bojar, F.&nbsp;Bougares, R.&nbsp;Chatterjee,
M.&nbsp;R. Costa-jussà, C.&nbsp;Federmann, M.&nbsp;Fishel, A.&nbsp;Fraser, M.&nbsp;Freitag,
Y.&nbsp;Graham, R.&nbsp;Grundkiewicz, P.&nbsp;Guzman, B.&nbsp;Haddow, M.&nbsp;Huck, A.&nbsp;Jimeno-Yepes,
T.&nbsp;Kocmi, A.&nbsp;Martins, M.&nbsp;Morishita, C.&nbsp;Monz, M.&nbsp;Nagata, T.&nbsp;Nakazawa,
M.&nbsp;Negri, A.&nbsp;Névéol, M.&nbsp;Neves, M.&nbsp;Popel, M.&nbsp;Turchi, and
M.&nbsp;Zampieri, Eds.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2022, pp. 1–45.

</span>
</li>
<li id="bib.bib546" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[546]</span>
<span class="ltx_bibblock">
N.&nbsp;Goyal, C.&nbsp;Gao, V.&nbsp;Chaudhary, P.&nbsp;Chen, G.&nbsp;Wenzek, D.&nbsp;Ju, S.&nbsp;Krishnan,
M.&nbsp;Ranzato, F.&nbsp;Guzmán, and A.&nbsp;Fan, “The flores-101 evaluation
benchmark for low-resource and multilingual machine translation,”
<em id="bib.bib546.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, vol.&nbsp;10, pp. 522–538, 2022.

</span>
</li>
<li id="bib.bib547" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[547]</span>
<span class="ltx_bibblock">
R.&nbsp;Bawden, E.&nbsp;Bilinski, T.&nbsp;Lavergne, and S.&nbsp;Rosset, “Diabla: a corpus of
bilingual spontaneous written dialogues for machine translation,”
<em id="bib.bib547.1.1" class="ltx_emph ltx_font_italic">Lang. Resour. Evaluation</em>, vol.&nbsp;55, no.&nbsp;3, pp. 635–660, 2021.

</span>
</li>
<li id="bib.bib548" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[548]</span>
<span class="ltx_bibblock">
R.&nbsp;Nallapati, B.&nbsp;Zhou, C.&nbsp;N. dos Santos, Ç.&nbsp;Gülçehre, and
B.&nbsp;Xiang, “Abstractive text summarization using sequence-to-sequence rnns
and beyond,” in <em id="bib.bib548.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th SIGNLL Conference on
Computational Natural Language Learning, CoNLL 2016, Berlin, Germany, August
11-12, 2016</em>, Y.&nbsp;Goldberg and S.&nbsp;Riezler, Eds.&nbsp;&nbsp;&nbsp;ACL, 2016, pp. 280–290.

</span>
</li>
<li id="bib.bib549" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[549]</span>
<span class="ltx_bibblock">
S.&nbsp;Narayan, S.&nbsp;B. Cohen, and M.&nbsp;Lapata, “Don’t give me the details, just the
summary! topic-aware convolutional neural networks for extreme
summarization,” in <em id="bib.bib549.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2018, pp. 1797–1807.

</span>
</li>
<li id="bib.bib550" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[550]</span>
<span class="ltx_bibblock">
F.&nbsp;Ladhak, E.&nbsp;Durmus, C.&nbsp;Cardie, and K.&nbsp;Mckeown, “Wikilingua: A new benchmark
dataset for cross-lingual abstractive summarization,” in <em id="bib.bib550.1.1" class="ltx_emph ltx_font_italic">Findings of
the Association for Computational Linguistics: EMNLP 2020</em>, 2020, pp.
4034–4048.

</span>
</li>
<li id="bib.bib551" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[551]</span>
<span class="ltx_bibblock">
S.&nbsp;Moon, P.&nbsp;Shah, A.&nbsp;Kumar, and R.&nbsp;Subba, “Opendialkg: Explainable
conversational reasoning with attention-based walks over knowledge graphs,”
in <em id="bib.bib551.1.1" class="ltx_emph ltx_font_italic">ACL (1)</em>.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2019, pp. 845–854.

</span>
</li>
<li id="bib.bib552" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[552]</span>
<span class="ltx_bibblock">
Y.&nbsp;Lai, C.&nbsp;Li, Y.&nbsp;Wang, T.&nbsp;Zhang, R.&nbsp;Zhong, L.&nbsp;Zettlemoyer, S.&nbsp;W. Yih,
D.&nbsp;Fried, S.&nbsp;I. Wang, and T.&nbsp;Yu, “DS-1000: A natural and reliable
benchmark for data science code generation,” <em id="bib.bib552.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2211.11501, 2022.

</span>
</li>
<li id="bib.bib553" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[553]</span>
<span class="ltx_bibblock">
Z.&nbsp;Wang, S.&nbsp;Zhou, D.&nbsp;Fried, and G.&nbsp;Neubig, “Execution-based evaluation for
open-domain code generation,” <em id="bib.bib553.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.10481, 2022.

</span>
</li>
<li id="bib.bib554" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[554]</span>
<span class="ltx_bibblock">
T.&nbsp;Kwiatkowski, J.&nbsp;Palomaki, O.&nbsp;Redfield, M.&nbsp;Collins, A.&nbsp;P. Parikh, C.&nbsp;Alberti,
D.&nbsp;Epstein, I.&nbsp;Polosukhin, J.&nbsp;Devlin, K.&nbsp;Lee, K.&nbsp;Toutanova, L.&nbsp;Jones,
M.&nbsp;Kelcey, M.&nbsp;Chang, A.&nbsp;M. Dai, J.&nbsp;Uszkoreit, Q.&nbsp;Le, and S.&nbsp;Petrov, “Natural
questions: a benchmark for question answering research,” <em id="bib.bib554.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc.
Comput. Linguistics</em>, pp. 452–466, 2019.

</span>
</li>
<li id="bib.bib555" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[555]</span>
<span class="ltx_bibblock">
P.&nbsp;Clark, I.&nbsp;Cowhey, O.&nbsp;Etzioni, T.&nbsp;Khot, A.&nbsp;Sabharwal, C.&nbsp;Schoenick, and
O.&nbsp;Tafjord, “Think you have solved question answering? try arc, the AI2
reasoning challenge,” <em id="bib.bib555.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1803.05457, 2018.

</span>
</li>
<li id="bib.bib556" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[556]</span>
<span class="ltx_bibblock">
S.&nbsp;Lin, J.&nbsp;Hilton, and O.&nbsp;Evans, “Truthfulqa: Measuring how models mimic human
falsehoods,” in <em id="bib.bib556.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers), ACL
2022, Dublin, Ireland, May 22-27, 2022</em>, 2022, pp. 3214–3252.

</span>
</li>
<li id="bib.bib557" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[557]</span>
<span class="ltx_bibblock">
J.&nbsp;Berant, A.&nbsp;Chou, R.&nbsp;Frostig, and P.&nbsp;Liang, “Semantic parsing on freebase
from question-answer pairs,” in <em id="bib.bib557.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October
2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a
Special Interest Group of the ACL</em>, 2013, pp. 1533–1544.

</span>
</li>
<li id="bib.bib558" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[558]</span>
<span class="ltx_bibblock">
M.&nbsp;Joshi, E.&nbsp;Choi, D.&nbsp;S. Weld, and L.&nbsp;Zettlemoyer, “Triviaqa: A large scale
distantly supervised challenge dataset for reading comprehension,” in
<em id="bib.bib558.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for
Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4,
Volume 1: Long Papers</em>, 2017, pp. 1601–1611.

</span>
</li>
<li id="bib.bib559" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[559]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bisk, R.&nbsp;Zellers, R.&nbsp;L. Bras, J.&nbsp;Gao, and Y.&nbsp;Choi, “PIQA: reasoning about
physical commonsense in natural language,” in <em id="bib.bib559.1.1" class="ltx_emph ltx_font_italic">The Thirty-Fourth AAAI
Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second
Innovative Applications of Artificial Intelligence Conference, IAAI 2020,
The Tenth AAAI Symposium on Educational Advances in Artificial
Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020</em>, 2020, pp.
7432–7439.

</span>
</li>
<li id="bib.bib560" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[560]</span>
<span class="ltx_bibblock">
M.&nbsp;Dubey, D.&nbsp;Banerjee, A.&nbsp;Abdelkawi, and J.&nbsp;Lehmann, “Lc-quad 2.0: A large
dataset for complex question answering over wikidata and dbpedia,” in
<em id="bib.bib560.1.1" class="ltx_emph ltx_font_italic">The Semantic Web - ISWC 2019 - 18th International Semantic Web
Conference, Auckland, New Zealand, October 26-30, 2019, Proceedings, Part
II</em>, 2019, pp. 69–78.

</span>
</li>
<li id="bib.bib561" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[561]</span>
<span class="ltx_bibblock">
Y.&nbsp;Gu, S.&nbsp;Kase, M.&nbsp;Vanni, B.&nbsp;M. Sadler, P.&nbsp;Liang, X.&nbsp;Yan, and Y.&nbsp;Su, “Beyond
I.I.D.: three levels of generalization for question answering on knowledge
bases,” in <em id="bib.bib561.1.1" class="ltx_emph ltx_font_italic">WWW ’21: The Web Conference 2021, Virtual Event /
Ljubljana, Slovenia, April 19-23, 2021</em>, 2021, pp. 3477–3488.

</span>
</li>
<li id="bib.bib562" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[562]</span>
<span class="ltx_bibblock">
S.&nbsp;Cao, J.&nbsp;Shi, L.&nbsp;Pan, L.&nbsp;Nie, Y.&nbsp;Xiang, L.&nbsp;Hou, J.&nbsp;Li, B.&nbsp;He, and H.&nbsp;Zhang,
“KQA pro: A dataset with explicit compositional programs for complex
question answering over knowledge base,” in <em id="bib.bib562.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th
Annual Meeting of the Association for Computational Linguistics (Volume 1:
Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, 2022, pp.
6101–6119.

</span>
</li>
<li id="bib.bib563" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[563]</span>
<span class="ltx_bibblock">
X.&nbsp;Hu, X.&nbsp;Wu, Y.&nbsp;Shu, and Y.&nbsp;Qu, “Logical form generation via multi-task
learning for complex question answering over knowledge bases,” in
<em id="bib.bib563.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th International Conference on Computational
Linguistics, COLING 2022, Gyeongju, Republic of Korea, October 12-17,
2022</em>, 2022, pp. 1687–1696.

</span>
</li>
<li id="bib.bib564" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[564]</span>
<span class="ltx_bibblock">
S.&nbsp;Longpre, Y.&nbsp;Lu, and J.&nbsp;Daiber, “MKQA: A linguistically diverse
benchmark for multilingual open domain question answering,” <em id="bib.bib564.1.1" class="ltx_emph ltx_font_italic">Trans.
Assoc. Comput. Linguistics</em>, vol.&nbsp;9, pp. 1389–1406, 2021.

</span>
</li>
<li id="bib.bib565" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[565]</span>
<span class="ltx_bibblock">
T.&nbsp;Saikh, T.&nbsp;Ghosal, A.&nbsp;Mittal, A.&nbsp;Ekbal, and P.&nbsp;Bhattacharyya, “Scienceqa: a
novel resource for question answering on scholarly articles,” <em id="bib.bib565.1.1" class="ltx_emph ltx_font_italic">Int. J.
Digit. Libr.</em>, vol.&nbsp;23, no.&nbsp;3, pp. 289–301, 2022.

</span>
</li>
<li id="bib.bib566" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[566]</span>
<span class="ltx_bibblock">
T.&nbsp;Mihaylov, P.&nbsp;Clark, T.&nbsp;Khot, and A.&nbsp;Sabharwal, “Can a suit of armor conduct
electricity? A new dataset for open book question answering,” in
<em id="bib.bib566.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in Natural
Language Processing, Brussels, Belgium, October 31 - November 4, 2018</em>, 2018,
pp. 2381–2391.

</span>
</li>
<li id="bib.bib567" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[567]</span>
<span class="ltx_bibblock">
T.&nbsp;Nguyen, M.&nbsp;Rosenberg, X.&nbsp;Song, J.&nbsp;Gao, S.&nbsp;Tiwary, R.&nbsp;Majumder, and L.&nbsp;Deng,
“MS MARCO: A human generated machine reading comprehension dataset,”
in <em id="bib.bib567.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Workshop on Cognitive Computation: Integrating
neural and symbolic approaches 2016 co-located with the 30th Annual
Conference on Neural Information Processing Systems (NIPS 2016), Barcelona,
Spain, December 9, 2016</em>, 2016.

</span>
</li>
<li id="bib.bib568" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[568]</span>
<span class="ltx_bibblock">
T.&nbsp;Khot, P.&nbsp;Clark, M.&nbsp;Guerquin, P.&nbsp;Jansen, and A.&nbsp;Sabharwal, “QASC: A
dataset for question answering via sentence composition,” in <em id="bib.bib568.1.1" class="ltx_emph ltx_font_italic">The
Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The
Thirty-Second Innovative Applications of Artificial Intelligence Conference,
IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial
Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020</em>, 2020, pp.
8082–8090.

</span>
</li>
<li id="bib.bib569" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[569]</span>
<span class="ltx_bibblock">
P.&nbsp;Rajpurkar, J.&nbsp;Zhang, K.&nbsp;Lopyrev, and P.&nbsp;Liang, “Squad: 100, 000+ questions
for machine comprehension of text,” in <em id="bib.bib569.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016
Conference on Empirical Methods in Natural Language Processing, EMNLP 2016,
Austin, Texas, USA, November 1-4, 2016</em>, 2016, pp. 2383–2392.

</span>
</li>
<li id="bib.bib570" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[570]</span>
<span class="ltx_bibblock">
A.&nbsp;H. Miller, A.&nbsp;Fisch, J.&nbsp;Dodge, A.&nbsp;Karimi, A.&nbsp;Bordes, and J.&nbsp;Weston,
“Key-value memory networks for directly reading documents,” in
<em id="bib.bib570.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016</em>,
2016, pp. 1400–1409.

</span>
</li>
<li id="bib.bib571" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[571]</span>
<span class="ltx_bibblock">
B.&nbsp;Goodrich, V.&nbsp;Rao, P.&nbsp;J. Liu, and M.&nbsp;Saleh, “Assessing the factual accuracy
of generated text,” in <em id="bib.bib571.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery &amp; Data Mining, KDD 2019,
Anchorage, AK, USA, August 4-8, 2019</em>, 2019, pp. 166–175.

</span>
</li>
<li id="bib.bib572" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[572]</span>
<span class="ltx_bibblock">
K.&nbsp;Toutanova and D.&nbsp;Chen, “Observed versus latent features for knowledge base
and text inference,” in <em id="bib.bib572.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 3rd Workshop on Continuous
Vector Space Models and their Compositionality, CVSC 2015, Beijing, China,
July 26-31, 2015</em>, 2015, pp. 57–66.

</span>
</li>
<li id="bib.bib573" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[573]</span>
<span class="ltx_bibblock">
K.&nbsp;D. Bollacker, C.&nbsp;Evans, P.&nbsp;K. Paritosh, T.&nbsp;Sturge, and J.&nbsp;Taylor,
“Freebase: a collaboratively created graph database for structuring human
knowledge,” in <em id="bib.bib573.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM SIGMOD International
Conference on Management of Data, SIGMOD 2008, Vancouver, BC, Canada, June
10-12, 2008</em>, 2008, pp. 1247–1250.

</span>
</li>
<li id="bib.bib574" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[574]</span>
<span class="ltx_bibblock">
T.&nbsp;Dettmers, P.&nbsp;Minervini, P.&nbsp;Stenetorp, and S.&nbsp;Riedel, “Convolutional 2d
knowledge graph embeddings,” in <em id="bib.bib574.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirty-Second
AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative
Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI
Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New
Orleans, Louisiana, USA, February 2-7, 2018</em>, 2018, pp. 1811–1818.

</span>
</li>
<li id="bib.bib575" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[575]</span>
<span class="ltx_bibblock">
G.&nbsp;A. Miller, “Wordnet: A lexical database for english,” <em id="bib.bib575.1.1" class="ltx_emph ltx_font_italic">Commun.
ACM</em>, pp. 39–41, 1995.

</span>
</li>
<li id="bib.bib576" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[576]</span>
<span class="ltx_bibblock">
F.&nbsp;Petroni, T.&nbsp;Rocktäschel, S.&nbsp;Riedel, P.&nbsp;S.&nbsp;H. Lewis, A.&nbsp;Bakhtin, Y.&nbsp;Wu,
and A.&nbsp;H. Miller, “Language models as knowledge bases?” in
<em id="bib.bib576.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in Natural
Language Processing and the 9th International Joint Conference on Natural
Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7,
2019</em>, 2019, pp. 2463–2473.

</span>
</li>
<li id="bib.bib577" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[577]</span>
<span class="ltx_bibblock">
F.&nbsp;Mahdisoltani, J.&nbsp;Biega, and F.&nbsp;M. Suchanek, “YAGO3: A knowledge base
from multilingual wikipedias,” in <em id="bib.bib577.1.1" class="ltx_emph ltx_font_italic">Seventh Biennial Conference on
Innovative Data Systems Research, CIDR 2015, Asilomar, CA, USA, January
4-7, 2015, Online Proceedings</em>, 2015.

</span>
</li>
<li id="bib.bib578" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[578]</span>
<span class="ltx_bibblock">
F.&nbsp;M. Suchanek, G.&nbsp;Kasneci, and G.&nbsp;Weikum, “Yago: a core of semantic
knowledge,” in <em id="bib.bib578.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th International Conference on
World Wide Web, WWW 2007, Banff, Alberta, Canada, May 8-12, 2007</em>, 2007,
pp. 697–706.

</span>
</li>
<li id="bib.bib579" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[579]</span>
<span class="ltx_bibblock">
Z.&nbsp;Yang, P.&nbsp;Qi, S.&nbsp;Zhang, Y.&nbsp;Bengio, W.&nbsp;W. Cohen, R.&nbsp;Salakhutdinov, and C.&nbsp;D.
Manning, “Hotpotqa: A dataset for diverse, explainable multi-hop question
answering,” in <em id="bib.bib579.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods
in Natural Language Processing, Brussels, Belgium, October 31 - November 4,
2018</em>.&nbsp;&nbsp;&nbsp;Association for Computational
Linguistics, 2018, pp. 2369–2380.

</span>
</li>
<li id="bib.bib580" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[580]</span>
<span class="ltx_bibblock">
C.&nbsp;Clark, K.&nbsp;Lee, M.&nbsp;Chang, T.&nbsp;Kwiatkowski, M.&nbsp;Collins, and K.&nbsp;Toutanova,
“Boolq: Exploring the surprising difficulty of natural yes/no questions,”
in <em id="bib.bib580.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies,
NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and
Short Papers)</em>, J.&nbsp;Burstein, C.&nbsp;Doran, and T.&nbsp;Solorio, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2019, pp.
2924–2936.

</span>
</li>
<li id="bib.bib581" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[581]</span>
<span class="ltx_bibblock">
M.&nbsp;Sap, H.&nbsp;Rashkin, D.&nbsp;Chen, R.&nbsp;L. Bras, and Y.&nbsp;Choi, “Socialiqa: Commonsense
reasoning about social interactions,” <em id="bib.bib581.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1904.09728,
2019.

</span>
</li>
<li id="bib.bib582" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[582]</span>
<span class="ltx_bibblock">
R.&nbsp;Zellers, A.&nbsp;Holtzman, Y.&nbsp;Bisk, A.&nbsp;Farhadi, and Y.&nbsp;Choi, “Hellaswag: Can a
machine really finish your sentence?” in <em id="bib.bib582.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th
Conference of the Association for Computational Linguistics, ACL 2019,
Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers</em>,
A.&nbsp;Korhonen, D.&nbsp;R. Traum, and L.&nbsp;Màrquez, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2019, pp.
4791–4800.

</span>
</li>
<li id="bib.bib583" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[583]</span>
<span class="ltx_bibblock">
K.&nbsp;Sakaguchi, R.&nbsp;L. Bras, C.&nbsp;Bhagavatula, and Y.&nbsp;Choi, “Winogrande: An
adversarial winograd schema challenge at scale,” in <em id="bib.bib583.1.1" class="ltx_emph ltx_font_italic">AAAI</em>.&nbsp;&nbsp;&nbsp;AAAI Press, 2020, pp. 8732–8740.

</span>
</li>
<li id="bib.bib584" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[584]</span>
<span class="ltx_bibblock">
M.&nbsp;Roemmele, C.&nbsp;A. Bejan, and A.&nbsp;S. Gordon, “Choice of plausible alternatives:
An evaluation of commonsense causal reasoning,” in <em id="bib.bib584.1.1" class="ltx_emph ltx_font_italic">Logical
Formalizations of Commonsense Reasoning, Papers from the 2011 AAAI Spring
Symposium, Technical Report SS-11-06, Stanford, California, USA, March 21-23,
2011</em>.&nbsp;&nbsp;&nbsp;AAAI, 2011.

</span>
</li>
<li id="bib.bib585" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[585]</span>
<span class="ltx_bibblock">
K.&nbsp;Sakaguchi, C.&nbsp;Bhagavatula, R.&nbsp;L. Bras, N.&nbsp;Tandon, P.&nbsp;Clark, and Y.&nbsp;Choi,
“proscript: Partially ordered scripts generation,” in <em id="bib.bib585.1.1" class="ltx_emph ltx_font_italic">Findings of the
Association for Computational Linguistics: EMNLP 2021, Virtual Event /
Punta Cana, Dominican Republic, 16-20 November, 2021</em>, M.&nbsp;Moens, X.&nbsp;Huang,
L.&nbsp;Specia, and S.&nbsp;W. Yih, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp. 2138–2149.

</span>
</li>
<li id="bib.bib586" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[586]</span>
<span class="ltx_bibblock">
B.&nbsp;Dalvi, L.&nbsp;Huang, N.&nbsp;Tandon, W.&nbsp;Yih, and P.&nbsp;Clark, “Tracking state changes
in procedural text: a challenge dataset and models for process paragraph
comprehension,” in <em id="bib.bib586.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2018, New Orleans, Louisiana, USA, June
1-6, 2018, Volume 1 (Long Papers)</em>, M.&nbsp;A. Walker, H.&nbsp;Ji, and A.&nbsp;Stent,
Eds.&nbsp;&nbsp;&nbsp;Association for Computational
Linguistics, 2018, pp. 1595–1604.

</span>
</li>
<li id="bib.bib587" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[587]</span>
<span class="ltx_bibblock">
S.&nbsp;Saha, P.&nbsp;Yadav, L.&nbsp;Bauer, and M.&nbsp;Bansal, “Explagraphs: An explanation graph
generation task for structured commonsense reasoning,” in <em id="bib.bib587.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2021 Conference on Empirical Methods in Natural Language Processing,
EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November,
2021</em>, M.&nbsp;Moens, X.&nbsp;Huang, L.&nbsp;Specia, and S.&nbsp;W. Yih, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp.
7716–7740.

</span>
</li>
<li id="bib.bib588" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[588]</span>
<span class="ltx_bibblock">
O.&nbsp;Tafjord, B.&nbsp;Dalvi, and P.&nbsp;Clark, “Proofwriter: Generating implications,
proofs, and abductive statements over natural language,” in <em id="bib.bib588.1.1" class="ltx_emph ltx_font_italic">Findings
of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online
Event, August 1-6, 2021</em>, ser. Findings of ACL, C.&nbsp;Zong, F.&nbsp;Xia, W.&nbsp;Li, and
R.&nbsp;Navigli, Eds., vol. ACL/IJCNLP 2021.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp. 3621–3634.

</span>
</li>
<li id="bib.bib589" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[589]</span>
<span class="ltx_bibblock">
B.&nbsp;Dalvi, P.&nbsp;Jansen, O.&nbsp;Tafjord, Z.&nbsp;Xie, H.&nbsp;Smith, L.&nbsp;Pipatanangkura, and
P.&nbsp;Clark, “Explaining answers with entailment trees,” in <em id="bib.bib589.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2021 Conference on Empirical Methods in Natural Language Processing,
EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November,
2021</em>, M.&nbsp;Moens, X.&nbsp;Huang, L.&nbsp;Specia, and S.&nbsp;W. Yih, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp.
7358–7370.

</span>
</li>
<li id="bib.bib590" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[590]</span>
<span class="ltx_bibblock">
A.&nbsp;Saparov and H.&nbsp;He, “Language models are greedy reasoners: A systematic
formal analysis of chain-of-thought,” <em id="bib.bib590.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.01240,
2022.

</span>
</li>
<li id="bib.bib591" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[591]</span>
<span class="ltx_bibblock">
C.&nbsp;Anil, Y.&nbsp;Wu, A.&nbsp;Andreassen, A.&nbsp;Lewkowycz, V.&nbsp;Misra, V.&nbsp;V. Ramasesh,
A.&nbsp;Slone, G.&nbsp;Gur-Ari, E.&nbsp;Dyer, and B.&nbsp;Neyshabur, “Exploring length
generalization in large language models,” <em id="bib.bib591.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2207.04901,
2022.

</span>
</li>
<li id="bib.bib592" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[592]</span>
<span class="ltx_bibblock">
A.&nbsp;Patel, S.&nbsp;Bhattamishra, and N.&nbsp;Goyal, “Are NLP models really able to
solve simple math word problems?” in <em id="bib.bib592.1.1" class="ltx_emph ltx_font_italic">NAACL-HLT</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp.
2080–2094.

</span>
</li>
<li id="bib.bib593" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[593]</span>
<span class="ltx_bibblock">
S.&nbsp;Roy and D.&nbsp;Roth, “Solving general arithmetic word problems,” in
<em id="bib.bib593.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015</em>,
L.&nbsp;Màrquez, C.&nbsp;Callison-Burch, J.&nbsp;Su, D.&nbsp;Pighin, and Y.&nbsp;Marton,
Eds.&nbsp;&nbsp;&nbsp;The Association for Computational
Linguistics, 2015, pp. 1743–1752.

</span>
</li>
<li id="bib.bib594" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[594]</span>
<span class="ltx_bibblock">
A.&nbsp;Amini, S.&nbsp;Gabriel, S.&nbsp;Lin, R.&nbsp;Koncel-Kedziorski, Y.&nbsp;Choi, and
H.&nbsp;Hajishirzi, “Mathqa: Towards interpretable math word problem solving with
operation-based formalisms,” in <em id="bib.bib594.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of
the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June
2-7, 2019, Volume 1 (Long and Short Papers)</em>, J.&nbsp;Burstein, C.&nbsp;Doran, and
T.&nbsp;Solorio, Eds.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2019, pp. 2357–2367.

</span>
</li>
<li id="bib.bib595" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[595]</span>
<span class="ltx_bibblock">
W.&nbsp;Ling, D.&nbsp;Yogatama, C.&nbsp;Dyer, and P.&nbsp;Blunsom, “Program induction by rationale
generation: Learning to solve and explain algebraic word problems,” in
<em id="bib.bib595.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for
Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4,
Volume 1: Long Papers</em>, R.&nbsp;Barzilay and M.&nbsp;Kan, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2017, pp.
158–167.

</span>
</li>
<li id="bib.bib596" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[596]</span>
<span class="ltx_bibblock">
R.&nbsp;Koncel-Kedziorski, S.&nbsp;Roy, A.&nbsp;Amini, N.&nbsp;Kushman, and H.&nbsp;Hajishirzi, “Mawps:
A math word problem repository,” in <em id="bib.bib596.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 conference
of the north american chapter of the association for computational
linguistics: human language technologies</em>, 2016, pp. 1152–1157.

</span>
</li>
<li id="bib.bib597" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[597]</span>
<span class="ltx_bibblock">
D.&nbsp;Dua, Y.&nbsp;Wang, P.&nbsp;Dasigi, G.&nbsp;Stanovsky, S.&nbsp;Singh, and M.&nbsp;Gardner, “DROP:
A reading comprehension benchmark requiring discrete reasoning over
paragraphs,” in <em id="bib.bib597.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7,
2019, Volume 1 (Long and Short Papers)</em>, 2019, pp. 2368–2378.

</span>
</li>
<li id="bib.bib598" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[598]</span>
<span class="ltx_bibblock">
S.&nbsp;Welleck, J.&nbsp;Liu, R.&nbsp;L. Bras, H.&nbsp;Hajishirzi, Y.&nbsp;Choi, and K.&nbsp;Cho,
“Naturalproofs: Mathematical theorem proving in natural language,” in
<em id="bib.bib598.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Neural Information Processing Systems Track on
Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December
2021, virtual</em>, J.&nbsp;Vanschoren and S.&nbsp;Yeung, Eds., 2021.

</span>
</li>
<li id="bib.bib599" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[599]</span>
<span class="ltx_bibblock">
A.&nbsp;Q. Jiang, W.&nbsp;Li, J.&nbsp;M. Han, and Y.&nbsp;Wu, “Lisa: Language models of isabelle
proofs,” in <em id="bib.bib599.1.1" class="ltx_emph ltx_font_italic">6th Conference on Artificial Intelligence and Theorem
Proving</em>, 2021, pp. 378–392.

</span>
</li>
<li id="bib.bib600" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[600]</span>
<span class="ltx_bibblock">
K.&nbsp;Zheng, J.&nbsp;M. Han, and S.&nbsp;Polu, “minif2f: a cross-system benchmark for
formal olympiad-level mathematics,” in <em id="bib.bib600.1.1" class="ltx_emph ltx_font_italic">The Tenth International
Conference on Learning Representations, ICLR 2022, Virtual Event, April
25-29, 2022</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2022.

</span>
</li>
<li id="bib.bib601" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[601]</span>
<span class="ltx_bibblock">
Z.&nbsp;Azerbayev, B.&nbsp;Piotrowski, H.&nbsp;Schoelkopf, E.&nbsp;W. Ayers, D.&nbsp;Radev, and
J.&nbsp;Avigad, “Proofnet: Autoformalizing and formally proving
undergraduate-level mathematics,” <em id="bib.bib601.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.12433, 2023.

</span>
</li>
<li id="bib.bib602" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[602]</span>
<span class="ltx_bibblock">
J.&nbsp;Li, X.&nbsp;Cheng, W.&nbsp;X. Zhao, J.&nbsp;Nie, and J.&nbsp;Wen, “Halueval: A large-scale
hallucination evaluation benchmark for large language models,” <em id="bib.bib602.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2305.11747, 2023.

</span>
</li>
<li id="bib.bib603" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[603]</span>
<span class="ltx_bibblock">
N.&nbsp;Nangia, C.&nbsp;Vania, R.&nbsp;Bhalerao, and S.&nbsp;R. Bowman, “Crows-pairs: A
challenge dataset for measuring social biases in masked language models,” in
<em id="bib.bib603.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2020, Online, November 16-20, 2020</em>, 2020, pp.
1953–1967.

</span>
</li>
<li id="bib.bib604" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[604]</span>
<span class="ltx_bibblock">
R.&nbsp;Rudinger, J.&nbsp;Naradowsky, B.&nbsp;Leonard, and B.&nbsp;V. Durme, “Gender bias in
coreference resolution,” in <em id="bib.bib604.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the
North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, NAACL-HLT, New Orleans, Louisiana, USA, June
1-6, 2018, Volume 2 (Short Papers)</em>, 2018, pp. 8–14.

</span>
</li>
<li id="bib.bib605" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[605]</span>
<span class="ltx_bibblock">
S.&nbsp;Gehman, S.&nbsp;Gururangan, M.&nbsp;Sap, Y.&nbsp;Choi, and N.&nbsp;A. Smith,
“Realtoxicityprompts: Evaluating neural toxic degeneration in language
models,” in <em id="bib.bib605.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020, Online Event, 16-20 November 2020</em>, ser. Findings of ACL,
T.&nbsp;Cohn, Y.&nbsp;He, and Y.&nbsp;Liu, Eds., vol. EMNLP 2020.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2020, pp.
3356–3369.

</span>
</li>
<li id="bib.bib606" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[606]</span>
<span class="ltx_bibblock">
X.&nbsp;Puig, K.&nbsp;Ra, M.&nbsp;Boben, J.&nbsp;Li, T.&nbsp;Wang, S.&nbsp;Fidler, and A.&nbsp;Torralba,
“Virtualhome: Simulating household activities via programs,” in
<em id="bib.bib606.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.&nbsp;&nbsp;&nbsp;Computer Vision
Foundation / IEEE Computer Society, 2018, pp. 8494–8502.

</span>
</li>
<li id="bib.bib607" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[607]</span>
<span class="ltx_bibblock">
S.&nbsp;Srivastava, C.&nbsp;Li, M.&nbsp;Lingelbach, R.&nbsp;Martín-Martín, F.&nbsp;Xia,
K.&nbsp;E. Vainio, Z.&nbsp;Lian, C.&nbsp;Gokmen, S.&nbsp;Buch, C.&nbsp;K. Liu, S.&nbsp;Savarese, H.&nbsp;Gweon,
J.&nbsp;Wu, and L.&nbsp;Fei-Fei, “BEHAVIOR: benchmark for everyday household
activities in virtual, interactive, and ecological environments,” in
<em id="bib.bib607.1.1" class="ltx_emph ltx_font_italic">CoRL</em>, ser. Proceedings of Machine Learning Research, vol. 164.&nbsp;&nbsp;&nbsp;PMLR, 2021, pp. 477–490.

</span>
</li>
<li id="bib.bib608" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[608]</span>
<span class="ltx_bibblock">
M.&nbsp;Shridhar, J.&nbsp;Thomason, D.&nbsp;Gordon, Y.&nbsp;Bisk, W.&nbsp;Han, R.&nbsp;Mottaghi,
L.&nbsp;Zettlemoyer, and D.&nbsp;Fox, “ALFRED: A benchmark for interpreting
grounded instructions for everyday tasks,” in <em id="bib.bib608.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.&nbsp;&nbsp;&nbsp;Computer Vision Foundation / IEEE, 2020, pp.
10 737–10 746.

</span>
</li>
<li id="bib.bib609" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[609]</span>
<span class="ltx_bibblock">
M.&nbsp;Shridhar, X.&nbsp;Yuan, M.&nbsp;Côté, Y.&nbsp;Bisk, A.&nbsp;Trischler, and M.&nbsp;J.
Hausknecht, “Alfworld: Aligning text and embodied environments for
interactive learning,” in <em id="bib.bib609.1.1" class="ltx_emph ltx_font_italic">9th International Conference on Learning
Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2021.

</span>
</li>
<li id="bib.bib610" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[610]</span>
<span class="ltx_bibblock">
S.&nbsp;Yao, H.&nbsp;Chen, J.&nbsp;Yang, and K.&nbsp;Narasimhan, “Webshop: Towards scalable
real-world web interaction with grounded language agents,” in
<em id="bib.bib610.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib611" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[611]</span>
<span class="ltx_bibblock">
X.&nbsp;Deng, Y.&nbsp;Gu, B.&nbsp;Zheng, S.&nbsp;Chen, S.&nbsp;Stevens, B.&nbsp;Wang, H.&nbsp;Sun, and Y.&nbsp;Su,
“Mind2web: Towards a generalist agent for the web,” <em id="bib.bib611.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.06070, 2023.

</span>
</li>
<li id="bib.bib612" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[612]</span>
<span class="ltx_bibblock">
W.&nbsp;H. Guss, B.&nbsp;Houghton, N.&nbsp;Topin, P.&nbsp;Wang, C.&nbsp;Codel, M.&nbsp;Veloso, and
R.&nbsp;Salakhutdinov, “Minerl: A large-scale dataset of minecraft
demonstrations,” in <em id="bib.bib612.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty-Eighth International
Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China,
August 10-16, 2019</em>, S.&nbsp;Kraus, Ed.&nbsp;&nbsp;&nbsp;ijcai.org, 2019, pp. 2442–2448.

</span>
</li>
<li id="bib.bib613" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[613]</span>
<span class="ltx_bibblock">
L.&nbsp;Fan, G.&nbsp;Wang, Y.&nbsp;Jiang, A.&nbsp;Mandlekar, Y.&nbsp;Yang, H.&nbsp;Zhu, A.&nbsp;Tang, D.&nbsp;Huang,
Y.&nbsp;Zhu, and A.&nbsp;Anandkumar, “Minedojo: Building open-ended embodied agents
with internet-scale knowledge,” in <em id="bib.bib613.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib614" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[614]</span>
<span class="ltx_bibblock">
P.&nbsp;Lu, L.&nbsp;Qiu, K.&nbsp;Chang, Y.&nbsp;N. Wu, S.&nbsp;Zhu, T.&nbsp;Rajpurohit, P.&nbsp;Clark, and
A.&nbsp;Kalyan, “Dynamic prompt learning via policy gradient for semi-structured
mathematical reasoning,” <em id="bib.bib614.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2209.14610, 2022.

</span>
</li>
<li id="bib.bib615" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[615]</span>
<span class="ltx_bibblock">
B.&nbsp;Zhang, K.&nbsp;Zhou, X.&nbsp;Wei, W.&nbsp;X. Zhao, J.&nbsp;Sha, S.&nbsp;Wang, and J.&nbsp;rong Wen,
“Evaluating and improving tool-augmented computation-intensive math
reasoning,” <em id="bib.bib615.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.02408, 2023.

</span>
</li>
<li id="bib.bib616" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[616]</span>
<span class="ltx_bibblock">
R.&nbsp;Yang, L.&nbsp;Song, Y.&nbsp;Li, S.&nbsp;Zhao, Y.&nbsp;Ge, X.&nbsp;Li, and Y.&nbsp;Shan, “Gpt4tools:
Teaching large language model to use tools via self-instruction,”
<em id="bib.bib616.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.18752, 2023.

</span>
</li>
<li id="bib.bib617" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[617]</span>
<span class="ltx_bibblock">
S.&nbsp;G. Patil, T.&nbsp;Zhang, X.&nbsp;Wang, and J.&nbsp;E. Gonzalez, “Gorilla: Large language
model connected with massive apis,” <em id="bib.bib617.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.15334, 2023.

</span>
</li>
<li id="bib.bib618" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[618]</span>
<span class="ltx_bibblock">
W.&nbsp;Yih, M.&nbsp;Richardson, C.&nbsp;Meek, M.&nbsp;Chang, and J.&nbsp;Suh, “The value of semantic
parse labeling for knowledge base question answering,” in <em id="bib.bib618.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 54th Annual Meeting of the Association for Computational Linguistics,
ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 2: Short
Papers</em>.&nbsp;&nbsp;&nbsp;The Association for Computer
Linguistics, 2016.

</span>
</li>
<li id="bib.bib619" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[619]</span>
<span class="ltx_bibblock">
H.&nbsp;Puerto, G.&nbsp;G. Sahin, and I.&nbsp;Gurevych, “Metaqa: Combining expert agents for
multi-skill question answering,” in <em id="bib.bib619.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 17th Conference
of the European Chapter of the Association for Computational Linguistics,
EACL 2023, Dubrovnik, Croatia, May 2-6, 2023</em>, A.&nbsp;Vlachos and
I.&nbsp;Augenstein, Eds.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2023, pp. 3548–3562.

</span>
</li>
<li id="bib.bib620" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[620]</span>
<span class="ltx_bibblock">
P.&nbsp;Pasupat and P.&nbsp;Liang, “Compositional semantic parsing on semi-structured
tables,” in <em id="bib.bib620.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 53rd Annual Meeting of the Association
for Computational Linguistics and the 7th International Joint Conference on
Natural Language Processing of the Asian Federation of Natural Language
Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 1: Long
Papers</em>.&nbsp;&nbsp;&nbsp;The Association for Computer
Linguistics, 2015, pp. 1470–1480.

</span>
</li>
<li id="bib.bib621" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[621]</span>
<span class="ltx_bibblock">
V.&nbsp;Zhong, C.&nbsp;Xiong, and R.&nbsp;Socher, “Seq2sql: Generating structured queries
from natural language using reinforcement learning,” <em id="bib.bib621.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/1709.00103, 2017.

</span>
</li>
<li id="bib.bib622" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[622]</span>
<span class="ltx_bibblock">
W.&nbsp;Chen, H.&nbsp;Wang, J.&nbsp;Chen, Y.&nbsp;Zhang, H.&nbsp;Wang, S.&nbsp;Li, X.&nbsp;Zhou, and W.&nbsp;Y. Wang,
“Tabfact: A large-scale dataset for table-based fact verification,” in
<em id="bib.bib622.1.1" class="ltx_emph ltx_font_italic">8th International Conference on Learning Representations, ICLR 2020,
Addis Ababa, Ethiopia, April 26-30, 2020</em>.&nbsp;&nbsp;&nbsp;OpenReview.net, 2020.

</span>
</li>
<li id="bib.bib623" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[623]</span>
<span class="ltx_bibblock">
T.&nbsp;Yu, R.&nbsp;Zhang, K.&nbsp;Yang, M.&nbsp;Yasunaga, D.&nbsp;Wang, Z.&nbsp;Li, J.&nbsp;Ma, I.&nbsp;Li, Q.&nbsp;Yao,
S.&nbsp;Roman, Z.&nbsp;Zhang, and D.&nbsp;R. Radev, “Spider: A large-scale human-labeled
dataset for complex and cross-domain semantic parsing and text-to-sql task,”
in <em id="bib.bib623.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in Natural
Language Processing, Brussels, Belgium, October 31 - November 4, 2018</em>,
E.&nbsp;Riloff, D.&nbsp;Chiang, J.&nbsp;Hockenmaier, and J.&nbsp;Tsujii, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2018, pp.
3911–3921.

</span>
</li>
<li id="bib.bib624" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[624]</span>
<span class="ltx_bibblock">
D.&nbsp;Bahdanau, K.&nbsp;Cho, and Y.&nbsp;Bengio, “Neural machine translation by jointly
learning to align and translate,” in <em id="bib.bib624.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2015.

</span>
</li>
<li id="bib.bib625" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[625]</span>
<span class="ltx_bibblock">
K.&nbsp;Papineni, S.&nbsp;Roukos, T.&nbsp;Ward, and W.&nbsp;Zhu, “Bleu: a method for automatic
evaluation of machine translation,” in <em id="bib.bib625.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th Annual
Meeting of the Association for Computational Linguistics, July 6-12, 2002,
Philadelphia, PA, USA</em>.&nbsp;&nbsp;&nbsp;ACL, 2002,
pp. 311–318.

</span>
</li>
<li id="bib.bib626" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[626]</span>
<span class="ltx_bibblock">
C.-Y. Lin, “ROUGE: A package for automatic evaluation of summaries,” in
<em id="bib.bib626.1.1" class="ltx_emph ltx_font_italic">Text Summarization Branches Out</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, Jul. 2004, pp. 74–81.

</span>
</li>
<li id="bib.bib627" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[627]</span>
<span class="ltx_bibblock">
W.&nbsp;Jiao, W.&nbsp;Wang, J.-t. Huang, X.&nbsp;Wang, and Z.&nbsp;Tu, “Is chatgpt a good
translator? a preliminary study,” <em id="bib.bib627.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.08745</em>,
2023.

</span>
</li>
<li id="bib.bib628" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[628]</span>
<span class="ltx_bibblock">
T.&nbsp;Zhang, F.&nbsp;Ladhak, E.&nbsp;Durmus, P.&nbsp;Liang, K.&nbsp;R. McKeown, and T.&nbsp;B. Hashimoto,
“Benchmarking large language models for news summarization,” <em id="bib.bib628.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2301.13848, 2023.

</span>
</li>
<li id="bib.bib629" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[629]</span>
<span class="ltx_bibblock">
T.&nbsp;Goyal, J.&nbsp;J. Li, and G.&nbsp;Durrett, “News summarization and evaluation in the
era of GPT-3,” <em id="bib.bib629.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2209.12356, 2022.

</span>
</li>
<li id="bib.bib630" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[630]</span>
<span class="ltx_bibblock">
S.&nbsp;Gehrmann, E.&nbsp;Clark, and T.&nbsp;Sellam, “Repairing the cracked foundation: A
survey of obstacles in evaluation practices for generated text,”
<em id="bib.bib630.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2202.06935, 2022.

</span>
</li>
<li id="bib.bib631" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[631]</span>
<span class="ltx_bibblock">
J.&nbsp;Wang, Y.&nbsp;Liang, F.&nbsp;Meng, H.&nbsp;Shi, Z.&nbsp;Li, J.&nbsp;Xu, J.&nbsp;Qu, and J.&nbsp;Zhou, “Is
chatgpt a good NLG evaluator? A preliminary study,” <em id="bib.bib631.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2303.04048, 2023.

</span>
</li>
<li id="bib.bib632" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[632]</span>
<span class="ltx_bibblock">
Y.&nbsp;Liu, D.&nbsp;Iter, Y.&nbsp;Xu, S.&nbsp;Wang, R.&nbsp;Xu, and C.&nbsp;Zhu, “G-eval: NLG evaluation
using GPT-4 with better human alignment,” <em id="bib.bib632.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2303.16634, 2023.

</span>
</li>
<li id="bib.bib633" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[633]</span>
<span class="ltx_bibblock">
K.&nbsp;Yang, Y.&nbsp;Tian, N.&nbsp;Peng, and D.&nbsp;Klein, “Re3: Generating longer stories with
recursive reprompting and revision,” in <em id="bib.bib633.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022
Conference on Empirical Methods in Natural Language Processing, EMNLP 2022,
Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, Y.&nbsp;Goldberg,
Z.&nbsp;Kozareva, and Y.&nbsp;Zhang, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022, pp. 4393–4479.

</span>
</li>
<li id="bib.bib634" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[634]</span>
<span class="ltx_bibblock">
W.&nbsp;Zhou, Y.&nbsp;E. Jiang, P.&nbsp;Cui, T.&nbsp;Wang, Z.&nbsp;Xiao, Y.&nbsp;Hou, R.&nbsp;Cotterell, and
M.&nbsp;Sachan, “Recurrentgpt: Interactive generation of (arbitrarily) long
text,” <em id="bib.bib634.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.13304, 2023.

</span>
</li>
<li id="bib.bib635" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[635]</span>
<span class="ltx_bibblock">
S.&nbsp;Gulwani, O.&nbsp;Polozov, and R.&nbsp;Singh, “Program synthesis,” <em id="bib.bib635.1.1" class="ltx_emph ltx_font_italic">Found.
Trends Program. Lang.</em>, vol.&nbsp;4, no. 1-2, pp. 1–119, 2017.

</span>
</li>
<li id="bib.bib636" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[636]</span>
<span class="ltx_bibblock">
S.&nbsp;Zhang, Z.&nbsp;Chen, Y.&nbsp;Shen, M.&nbsp;Ding, J.&nbsp;B. Tenenbaum, and C.&nbsp;Gan, “Planning
with large language models for code generation,” 2023.

</span>
</li>
<li id="bib.bib637" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[637]</span>
<span class="ltx_bibblock">
M.&nbsp;Welsh, “The end of programming,” <em id="bib.bib637.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em>, vol.&nbsp;66, no.&nbsp;1, pp.
34–35, 2023.

</span>
</li>
<li id="bib.bib638" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[638]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bang, S.&nbsp;Cahyawijaya, N.&nbsp;Lee, W.&nbsp;Dai, D.&nbsp;Su, B.&nbsp;Wilie, H.&nbsp;Lovenia, Z.&nbsp;Ji,
T.&nbsp;Yu, W.&nbsp;Chung, Q.&nbsp;V. Do, Y.&nbsp;Xu, and P.&nbsp;Fung, “A multitask, multilingual,
multimodal evaluation of chatgpt on reasoning, hallucination, and
interactivity,” <em id="bib.bib638.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.04023, 2023.

</span>
</li>
<li id="bib.bib639" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[639]</span>
<span class="ltx_bibblock">
Y.&nbsp;Liu, A.&nbsp;R. Fabbri, P.&nbsp;Liu, Y.&nbsp;Zhao, L.&nbsp;Nan, R.&nbsp;Han, S.&nbsp;Han, S.&nbsp;R. Joty,
C.&nbsp;Wu, C.&nbsp;Xiong, and D.&nbsp;Radev, “Revisiting the gold standard: Grounding
summarization evaluation with robust human evaluation,” <em id="bib.bib639.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2212.07981, 2022.

</span>
</li>
<li id="bib.bib640" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[640]</span>
<span class="ltx_bibblock">
A.&nbsp;R. Fabbri, W.&nbsp;Kryscinski, B.&nbsp;McCann, C.&nbsp;Xiong, R.&nbsp;Socher, and D.&nbsp;R. Radev,
“Summeval: Re-evaluating summarization evaluation,” <em id="bib.bib640.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc.
Comput. Linguistics</em>, vol.&nbsp;9, pp. 391–409, 2021.

</span>
</li>
<li id="bib.bib641" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[641]</span>
<span class="ltx_bibblock">
T.&nbsp;Tang, H.&nbsp;Lu, Y.&nbsp;E. Jiang, H.&nbsp;Huang, D.&nbsp;Zhang, W.&nbsp;X. Zhao, and F.&nbsp;Wei, “Not
all metrics are guilty: Improving NLG evaluation with LLM paraphrasing,”
<em id="bib.bib641.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.15067, 2023.

</span>
</li>
<li id="bib.bib642" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[642]</span>
<span class="ltx_bibblock">
X.&nbsp;Wang, X.&nbsp;Tang, W.&nbsp;X. Zhao, J.&nbsp;Wang, and J.&nbsp;Wen, “Rethinking the evaluation
for conversational recommendation in the era of large language models,”
<em id="bib.bib642.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.13112, 2023.

</span>
</li>
<li id="bib.bib643" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[643]</span>
<span class="ltx_bibblock">
M.&nbsp;Gao, J.&nbsp;Ruan, R.&nbsp;Sun, X.&nbsp;Yin, S.&nbsp;Yang, and X.&nbsp;Wan, “Human-like
summarization evaluation with chatgpt,” <em id="bib.bib643.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.02554,
2023.

</span>
</li>
<li id="bib.bib644" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[644]</span>
<span class="ltx_bibblock">
Y.&nbsp;Ji, Y.&nbsp;Gong, Y.&nbsp;Peng, C.&nbsp;Ni, P.&nbsp;Sun, D.&nbsp;Pan, B.&nbsp;Ma, and X.&nbsp;Li, “Exploring
chatgpt’s ability to rank content: A preliminary study on consistency with
human preferences,” <em id="bib.bib644.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.07610, 2023.

</span>
</li>
<li id="bib.bib645" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[645]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bai, J.&nbsp;Ying, Y.&nbsp;Cao, X.&nbsp;Lv, Y.&nbsp;He, X.&nbsp;Wang, J.&nbsp;Yu, K.&nbsp;Zeng, Y.&nbsp;Xiao,
H.&nbsp;Lyu, J.&nbsp;Zhang, J.&nbsp;Li, and L.&nbsp;Hou, “Benchmarking foundation models with
language-model-as-an-examiner,” <em id="bib.bib645.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.04181, 2023.

</span>
</li>
<li id="bib.bib646" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[646]</span>
<span class="ltx_bibblock">
Y.&nbsp;Liu, S.&nbsp;Feng, D.&nbsp;Wang, Y.&nbsp;Zhang, and H.&nbsp;Schütze, “Evaluate what you
can’t evaluate: Unassessable generated responses quality,” <em id="bib.bib646.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.14658, 2023.

</span>
</li>
<li id="bib.bib647" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[647]</span>
<span class="ltx_bibblock">
P.&nbsp;Wang, L.&nbsp;Li, L.&nbsp;Chen, D.&nbsp;Zhu, B.&nbsp;Lin, Y.&nbsp;Cao, Q.&nbsp;Liu, T.&nbsp;Liu, and Z.&nbsp;Sui,
“Large language models are not fair evaluators,” <em id="bib.bib647.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.17926, 2023.

</span>
</li>
<li id="bib.bib648" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[648]</span>
<span class="ltx_bibblock">
J.&nbsp;Ye, X.&nbsp;Chen, N.&nbsp;Xu, C.&nbsp;Zu, Z.&nbsp;Shao, S.&nbsp;Liu, Y.&nbsp;Cui, Z.&nbsp;Zhou, C.&nbsp;Gong,
Y.&nbsp;Shen, J.&nbsp;Zhou, S.&nbsp;Chen, T.&nbsp;Gui, Q.&nbsp;Zhang, and X.&nbsp;Huang, “A comprehensive
capability analysis of gpt-3 and gpt-3.5 series models,” <em id="bib.bib648.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2303.10420</em>, 2023.

</span>
</li>
<li id="bib.bib649" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[649]</span>
<span class="ltx_bibblock">
M.&nbsp;McCloskey and N.&nbsp;J. Cohen, “Catastrophic interference in connectionist
networks: The sequential learning problem,” in <em id="bib.bib649.1.1" class="ltx_emph ltx_font_italic">Psychology of learning
and motivation</em>, 1989, pp. 109–165.

</span>
</li>
<li id="bib.bib650" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[650]</span>
<span class="ltx_bibblock">
R.&nbsp;Kemker, M.&nbsp;McClure, A.&nbsp;Abitino, T.&nbsp;L. Hayes, and C.&nbsp;Kanan, “Measuring
catastrophic forgetting in neural networks,” in <em id="bib.bib650.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the
30th innovative Applications of Artificial Intelligence (IAAI-18), and the
8th AAAI Symposium on Educational Advances in Artificial Intelligence
(EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018</em>, 2018, pp.
3390–3398.

</span>
</li>
<li id="bib.bib651" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[651]</span>
<span class="ltx_bibblock">
T.&nbsp;Xie, C.&nbsp;H. Wu, P.&nbsp;Shi, R.&nbsp;Zhong, T.&nbsp;Scholak, M.&nbsp;Yasunaga, C.&nbsp;Wu, M.&nbsp;Zhong,
P.&nbsp;Yin, S.&nbsp;I. Wang, V.&nbsp;Zhong, B.&nbsp;Wang, C.&nbsp;Li, C.&nbsp;Boyle, A.&nbsp;Ni, Z.&nbsp;Yao,
D.&nbsp;Radev, C.&nbsp;Xiong, L.&nbsp;Kong, R.&nbsp;Zhang, N.&nbsp;A. Smith, L.&nbsp;Zettlemoyer, and
T.&nbsp;Yu, “Unifiedskg: Unifying and multi-tasking structured knowledge
grounding with text-to-text language models,” in <em id="bib.bib651.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022,
pp. 602–631.

</span>
</li>
<li id="bib.bib652" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[652]</span>
<span class="ltx_bibblock">
A.&nbsp;Roberts, C.&nbsp;Raffel, and N.&nbsp;Shazeer, “How much knowledge can you pack into
the parameters of a language model?” in <em id="bib.bib652.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing, EMNLP 2020,
Online, November 16-20, 2020</em>, 2020, pp. 5418–5426.

</span>
</li>
<li id="bib.bib653" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[653]</span>
<span class="ltx_bibblock">
G.&nbsp;Izacard, P.&nbsp;S.&nbsp;H. Lewis, M.&nbsp;Lomeli, L.&nbsp;Hosseini, F.&nbsp;Petroni, T.&nbsp;Schick,
J.&nbsp;Dwivedi-Yu, A.&nbsp;Joulin, S.&nbsp;Riedel, and E.&nbsp;Grave, “Few-shot learning with
retrieval augmented language models,” <em id="bib.bib653.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2208.03299,
2022.

</span>
</li>
<li id="bib.bib654" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[654]</span>
<span class="ltx_bibblock">
K.&nbsp;Guu, K.&nbsp;Lee, Z.&nbsp;Tung, P.&nbsp;Pasupat, and M.&nbsp;Chang, “Retrieval augmented
language model pre-training,” in <em id="bib.bib654.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 37th International
Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event</em>,
2020, pp. 3929–3938.

</span>
</li>
<li id="bib.bib655" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[655]</span>
<span class="ltx_bibblock">
P.&nbsp;S.&nbsp;H. Lewis, E.&nbsp;Perez, A.&nbsp;Piktus, F.&nbsp;Petroni, V.&nbsp;Karpukhin, N.&nbsp;Goyal,
H.&nbsp;Küttler, M.&nbsp;Lewis, W.&nbsp;Yih, T.&nbsp;Rocktäschel, S.&nbsp;Riedel, and
D.&nbsp;Kiela, “Retrieval-augmented generation for knowledge-intensive NLP
tasks,” in <em id="bib.bib655.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33:
Annual Conference on Neural Information Processing Systems 2020, NeurIPS
2020, December 6-12, 2020, virtual</em>, 2020.

</span>
</li>
<li id="bib.bib656" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[656]</span>
<span class="ltx_bibblock">
Y.&nbsp;Lan, G.&nbsp;He, J.&nbsp;Jiang, J.&nbsp;Jiang, W.&nbsp;X. Zhao, and J.&nbsp;Wen, “Complex knowledge
base question answering: A survey,” <em id="bib.bib656.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2108.06688,
2021.

</span>
</li>
<li id="bib.bib657" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[657]</span>
<span class="ltx_bibblock">
S.&nbsp;Borgeaud, A.&nbsp;Mensch, J.&nbsp;Hoffmann, T.&nbsp;Cai, E.&nbsp;Rutherford, K.&nbsp;Millican,
G.&nbsp;van&nbsp;den Driessche, J.&nbsp;Lespiau, B.&nbsp;Damoc, A.&nbsp;Clark, D.&nbsp;de&nbsp;Las&nbsp;Casas,
A.&nbsp;Guy, J.&nbsp;Menick, R.&nbsp;Ring, T.&nbsp;Hennigan, S.&nbsp;Huang, L.&nbsp;Maggiore, C.&nbsp;Jones,
A.&nbsp;Cassirer, A.&nbsp;Brock, M.&nbsp;Paganini, G.&nbsp;Irving, O.&nbsp;Vinyals, S.&nbsp;Osindero,
K.&nbsp;Simonyan, J.&nbsp;W. Rae, E.&nbsp;Elsen, and L.&nbsp;Sifre, “Improving language models
by retrieving from trillions of tokens,” in <em id="bib.bib657.1.1" class="ltx_emph ltx_font_italic">International Conference
on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland,
USA</em>, ser. Proceedings of Machine Learning Research, K.&nbsp;Chaudhuri,
S.&nbsp;Jegelka, L.&nbsp;Song, C.&nbsp;Szepesvári, G.&nbsp;Niu, and S.&nbsp;Sabato, Eds., vol.
162.&nbsp;&nbsp;&nbsp;PMLR, 2022, pp. 2206–2240.

</span>
</li>
<li id="bib.bib658" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[658]</span>
<span class="ltx_bibblock">
S.&nbsp;Xu, L.&nbsp;Pang, H.&nbsp;Shen, X.&nbsp;Cheng, and T.-S. Chua, “Search-in-the-chain:
Towards accurate, credible and traceable large language models for
knowledge-intensive tasks,” <em id="bib.bib658.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.14732, 2023.

</span>
</li>
<li id="bib.bib659" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[659]</span>
<span class="ltx_bibblock">
B.&nbsp;Peng, M.&nbsp;Galley, P.&nbsp;He, H.&nbsp;Cheng, Y.&nbsp;Xie, Y.&nbsp;Hu, Q.&nbsp;Huang, L.&nbsp;Liden, Z.&nbsp;Yu,
W.&nbsp;Chen, and J.&nbsp;Gao, “Check your facts and try again: Improving large
language models with external knowledge and automated feedback,”
<em id="bib.bib659.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.12813, 2023.

</span>
</li>
<li id="bib.bib660" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[660]</span>
<span class="ltx_bibblock">
Z.&nbsp;Jiang, F.&nbsp;F. Xu, L.&nbsp;Gao, Z.&nbsp;Sun, Q.&nbsp;Liu, J.&nbsp;Dwivedi-Yu, Y.&nbsp;Yang,
J.&nbsp;Callan, and G.&nbsp;Neubig, “Active retrieval augmented generation,”
<em id="bib.bib660.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.06983, 2023.

</span>
</li>
<li id="bib.bib661" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[661]</span>
<span class="ltx_bibblock">
L.&nbsp;Huang, W.&nbsp;Yu, W.&nbsp;Ma, W.&nbsp;Zhong, Z.&nbsp;Feng, H.&nbsp;Wang, Q.&nbsp;Chen, W.&nbsp;Peng, X.&nbsp;Feng,
B.&nbsp;Qin, and T.&nbsp;Liu, “A survey on hallucination in large language models:
Principles, taxonomy, challenges, and open questions,” <em id="bib.bib661.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2311.05232, 2023.

</span>
</li>
<li id="bib.bib662" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[662]</span>
<span class="ltx_bibblock">
Y.&nbsp;Li, Y.&nbsp;Du, K.&nbsp;Zhou, J.&nbsp;Wang, W.&nbsp;X. Zhao, and J.&nbsp;Wen, “Evaluating object
hallucination in large vision-language models,” <em id="bib.bib662.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.10355, 2023.

</span>
</li>
<li id="bib.bib663" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[663]</span>
<span class="ltx_bibblock">
S.&nbsp;Kadavath, T.&nbsp;Conerly, A.&nbsp;Askell, T.&nbsp;J. Henighan, D.&nbsp;Drain, E.&nbsp;Perez,
N.&nbsp;Schiefer, Z.&nbsp;Dodds, N.&nbsp;DasSarma, E.&nbsp;Tran-Johnson, S.&nbsp;Johnston,
S.&nbsp;El-Showk, A.&nbsp;Jones, N.&nbsp;Elhage, T.&nbsp;Hume, A.&nbsp;Chen, Y.&nbsp;Bai, S.&nbsp;Bowman,
S.&nbsp;Fort, D.&nbsp;Ganguli, D.&nbsp;Hernandez, J.&nbsp;Jacobson, J.&nbsp;Kernion, S.&nbsp;Kravec,
L.&nbsp;Lovitt, K.&nbsp;Ndousse, C.&nbsp;Olsson, S.&nbsp;Ringer, D.&nbsp;Amodei, T.&nbsp;B. Brown,
J.&nbsp;Clark, N.&nbsp;Joseph, B.&nbsp;Mann, S.&nbsp;McCandlish, C.&nbsp;Olah, and J.&nbsp;Kaplan,
“Language models (mostly) know what they know,” <em id="bib.bib663.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2207.05221, 2022.

</span>
</li>
<li id="bib.bib664" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[664]</span>
<span class="ltx_bibblock">
P.&nbsp;Manakul, A.&nbsp;Liusie, and M.&nbsp;J.&nbsp;F. Gales, “Selfcheckgpt: Zero-resource
black-box hallucination detection for generative large language models,”
<em id="bib.bib664.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/2305.06983, 2023.

</span>
</li>
<li id="bib.bib665" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[665]</span>
<span class="ltx_bibblock">
S.&nbsp;Agarwal, I.&nbsp;Akkaya, V.&nbsp;Balcom, M.&nbsp;Bavarian, G.&nbsp;Bernadett-Shapiro,
G.&nbsp;Brockman, M.&nbsp;Brundage, J.&nbsp;Chan, F.&nbsp;Chantzis, N.&nbsp;Deutsch, B.&nbsp;Eastman,
A.&nbsp;Eleti, N.&nbsp;Felix, S.&nbsp;P. Fishman, I.&nbsp;Fulford, C.&nbsp;Gibson, J.&nbsp;Gross,
M.&nbsp;Heaton, J.&nbsp;Hilton, X.&nbsp;Hu, S.&nbsp;Jain, H.&nbsp;Jin, L.&nbsp;Kilpatrick, C.&nbsp;Kim,
M.&nbsp;Kolhede, A.&nbsp;Mayne, P.&nbsp;McMillan, D.&nbsp;Medina, J.&nbsp;Menick, A.&nbsp;Mishchenko,
A.&nbsp;Nair, R.&nbsp;Nayak, A.&nbsp;Neelakantan, R.&nbsp;Nuttall, J.&nbsp;Parish, A.&nbsp;T. Passos,
A.&nbsp;Perelman, F.&nbsp;de&nbsp;Avila Belbute&nbsp;Peres, V.&nbsp;Pong, J.&nbsp;Schulman, E.&nbsp;Sigler,
N.&nbsp;Staudacher, N.&nbsp;Turley, J.&nbsp;Tworek, R.&nbsp;Greene, A.&nbsp;Vijayvergiya, C.&nbsp;Voss,
J.&nbsp;Weng, M.&nbsp;Wiethoff, S.&nbsp;Yoo, K.&nbsp;Yu, W.&nbsp;Zaremba, S.&nbsp;Zhao, W.&nbsp;Zhuk, and
B.&nbsp;Zoph, “Chatgpt plugins,” <em id="bib.bib665.1.1" class="ltx_emph ltx_font_italic">OpenAI Blog</em>, March 2023.

</span>
</li>
<li id="bib.bib666" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[666]</span>
<span class="ltx_bibblock">
A.&nbsp;Lazaridou, E.&nbsp;Gribovskaya, W.&nbsp;Stokowiec, and N.&nbsp;Grigorev,
“Internet-augmented language models through few-shot prompting for
open-domain question answering,” <em id="bib.bib666.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2203.05115, 2022.

</span>
</li>
<li id="bib.bib667" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[667]</span>
<span class="ltx_bibblock">
H.&nbsp;Qian, Y.&nbsp;Zhu, Z.&nbsp;Dou, H.&nbsp;Gu, X.&nbsp;Zhang, Z.&nbsp;Liu, R.&nbsp;Lai, Z.&nbsp;Cao, J.&nbsp;Nie, and
J.&nbsp;Wen, “Webbrain: Learning to generate factually correct articles for
queries by grounding on large web corpus,” <em id="bib.bib667.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.04358,
2023.

</span>
</li>
<li id="bib.bib668" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[668]</span>
<span class="ltx_bibblock">
J.&nbsp;Liu, J.&nbsp;Jin, Z.&nbsp;Wang, J.&nbsp;Cheng, Z.&nbsp;Dou, and J.&nbsp;Wen, “RETA-LLM: A
retrieval-augmented large language model toolkit,” <em id="bib.bib668.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.05212, 2023.

</span>
</li>
<li id="bib.bib669" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[669]</span>
<span class="ltx_bibblock">
D.&nbsp;Dai, L.&nbsp;Dong, Y.&nbsp;Hao, Z.&nbsp;Sui, B.&nbsp;Chang, and F.&nbsp;Wei, “Knowledge neurons in
pretrained transformers,” in <em id="bib.bib669.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of
the Association for Computational Linguistics (Volume 1: Long Papers), ACL
2022, Dublin, Ireland, May 22-27, 2022</em>, S.&nbsp;Muresan, P.&nbsp;Nakov, and
A.&nbsp;Villavicencio, Eds.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2022, pp. 8493–8502.

</span>
</li>
<li id="bib.bib670" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[670]</span>
<span class="ltx_bibblock">
K.&nbsp;Meng, D.&nbsp;Bau, A.&nbsp;J. Andonian, and Y.&nbsp;Belinkov, “Locating and editing
factual associations in gpt,” in <em id="bib.bib670.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems</em>, 2022.

</span>
</li>
<li id="bib.bib671" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[671]</span>
<span class="ltx_bibblock">
M.&nbsp;Geva, R.&nbsp;Schuster, J.&nbsp;Berant, and O.&nbsp;Levy, “Transformer feed-forward layers
are key-value memories,” in <em id="bib.bib671.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on
Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event
/ Punta Cana, Dominican Republic, 7-11 November, 2021</em>, M.&nbsp;Moens, X.&nbsp;Huang,
L.&nbsp;Specia, and S.&nbsp;W. Yih, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp. 5484–5495.

</span>
</li>
<li id="bib.bib672" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[672]</span>
<span class="ltx_bibblock">
Y.&nbsp;Yao, P.&nbsp;Wang, B.&nbsp;Tian, S.&nbsp;Cheng, Z.&nbsp;Li, S.&nbsp;Deng, H.&nbsp;Chen, and N.&nbsp;Zhang,
“Editing large language models: Problems, methods, and opportunities,”
<em id="bib.bib672.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.13172, 2023.

</span>
</li>
<li id="bib.bib673" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[673]</span>
<span class="ltx_bibblock">
P.&nbsp;Wang, N.&nbsp;Zhang, X.&nbsp;Xie, Y.&nbsp;Yao, B.&nbsp;Tian, M.&nbsp;Wang, Z.&nbsp;Xi, S.&nbsp;Cheng, K.&nbsp;Liu,
G.&nbsp;Zheng, and H.&nbsp;Chen, “Easyedit: An easy-to-use knowledge editing framework
for large language models,” <em id="bib.bib673.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.07269, 2023.

</span>
</li>
<li id="bib.bib674" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[674]</span>
<span class="ltx_bibblock">
Z.&nbsp;Shao, Y.&nbsp;Gong, Y.&nbsp;Shen, M.&nbsp;Huang, N.&nbsp;Duan, and W.&nbsp;Chen, “Synthetic
prompting: Generating chain-of-thought demonstrations for large language
models,” <em id="bib.bib674.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.00618, 2023.

</span>
</li>
<li id="bib.bib675" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[675]</span>
<span class="ltx_bibblock">
Sifatkaur, M.&nbsp;Singh, V.&nbsp;S. B, and N.&nbsp;Malviya, “Mind meets machine: Unravelling
gpt-4’s cognitive psychology,” <em id="bib.bib675.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.11436, 2023.

</span>
</li>
<li id="bib.bib676" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[676]</span>
<span class="ltx_bibblock">
M.&nbsp;I. Nye, A.&nbsp;J. Andreassen, G.&nbsp;Gur-Ari, H.&nbsp;Michalewski, J.&nbsp;Austin,
D.&nbsp;Bieber, D.&nbsp;Dohan, A.&nbsp;Lewkowycz, M.&nbsp;Bosma, D.&nbsp;Luan, C.&nbsp;Sutton, and
A.&nbsp;Odena, “Show your work: Scratchpads for intermediate computation with
language models,” <em id="bib.bib676.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2112.00114, 2021.

</span>
</li>
<li id="bib.bib677" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[677]</span>
<span class="ltx_bibblock">
J.&nbsp;Qian, H.&nbsp;Wang, Z.&nbsp;Li, S.&nbsp;Li, and X.&nbsp;Yan, “Limitations of language models in
arithmetic and symbolic induction,” <em id="bib.bib677.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2208.05051, 2022.

</span>
</li>
<li id="bib.bib678" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[678]</span>
<span class="ltx_bibblock">
W.&nbsp;X. Zhao, K.&nbsp;Zhou, Z.&nbsp;Gong, B.&nbsp;Zhang, Y.&nbsp;Zhou, J.&nbsp;Sha, Z.&nbsp;Chen, S.&nbsp;Wang,
C.&nbsp;Liu, and J.&nbsp;Wen, “Jiuzhang: A chinese pre-trained language model for
mathematical problem understanding,” in <em id="bib.bib678.1.1" class="ltx_emph ltx_font_italic">KDD ’22: The 28th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC,
USA, August 14 - 18, 2022</em>, A.&nbsp;Zhang and H.&nbsp;Rangwala, Eds.&nbsp;&nbsp;&nbsp;ACM, 2022, pp. 4571–4581.

</span>
</li>
<li id="bib.bib679" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[679]</span>
<span class="ltx_bibblock">
Q.&nbsp;Wang, C.&nbsp;Kaliszyk, and J.&nbsp;Urban, “First experiments with neural translation
of informal to formal mathematics,” in <em id="bib.bib679.1.1" class="ltx_emph ltx_font_italic">Intelligent Computer
Mathematics - 11th International Conference, CICM 2018, Hagenberg, Austria,
August 13-17, 2018, Proceedings</em>, ser. Lecture Notes in Computer Science,
F.&nbsp;Rabe, W.&nbsp;M. Farmer, G.&nbsp;O. Passmore, and A.&nbsp;Youssef, Eds., vol.
11006.&nbsp;&nbsp;&nbsp;Springer, 2018, pp. 255–270.

</span>
</li>
<li id="bib.bib680" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[680]</span>
<span class="ltx_bibblock">
S.&nbsp;Polu and I.&nbsp;Sutskever, “Generative language modeling for automated theorem
proving,” <em id="bib.bib680.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2009.03393, 2020.

</span>
</li>
<li id="bib.bib681" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[681]</span>
<span class="ltx_bibblock">
A.&nbsp;Q. Jiang, W.&nbsp;Li, S.&nbsp;Tworkowski, K.&nbsp;Czechowski, T.&nbsp;Odrzygózdz,
P.&nbsp;Milos, Y.&nbsp;Wu, and M.&nbsp;Jamnik, “Thor: Wielding hammers to integrate
language models and automated theorem provers,” <em id="bib.bib681.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2205.10893, 2022.

</span>
</li>
<li id="bib.bib682" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[682]</span>
<span class="ltx_bibblock">
S.&nbsp;Polu, J.&nbsp;M. Han, K.&nbsp;Zheng, M.&nbsp;Baksys, I.&nbsp;Babuschkin, and I.&nbsp;Sutskever,
“Formal mathematics statement curriculum learning,” <em id="bib.bib682.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2202.01344, 2022.

</span>
</li>
<li id="bib.bib683" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[683]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wu, A.&nbsp;Q. Jiang, W.&nbsp;Li, M.&nbsp;N. Rabe, C.&nbsp;Staats, M.&nbsp;Jamnik, and C.&nbsp;Szegedy,
“Autoformalization with large language models,” <em id="bib.bib683.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2205.12615, 2022.

</span>
</li>
<li id="bib.bib684" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[684]</span>
<span class="ltx_bibblock">
A.&nbsp;Q. Jiang, S.&nbsp;Welleck, J.&nbsp;P. Zhou, W.&nbsp;Li, J.&nbsp;Liu, M.&nbsp;Jamnik, T.&nbsp;Lacroix,
Y.&nbsp;Wu, and G.&nbsp;Lample, “Draft, sketch, and prove: Guiding formal theorem
provers with informal proofs,” <em id="bib.bib684.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.12283, 2022.

</span>
</li>
<li id="bib.bib685" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[685]</span>
<span class="ltx_bibblock">
A.&nbsp;Madaan, N.&nbsp;Tandon, P.&nbsp;Gupta, S.&nbsp;Hallinan, L.&nbsp;Gao, S.&nbsp;Wiegreffe, U.&nbsp;Alon,
N.&nbsp;Dziri, S.&nbsp;Prabhumoye, Y.&nbsp;Yang, S.&nbsp;Welleck, B.&nbsp;P. Majumder, S.&nbsp;Gupta,
A.&nbsp;Yazdanbakhsh, and P.&nbsp;Clark, “Self-refine: Iterative refinement with
self-feedback,” <em id="bib.bib685.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.17651, 2023.

</span>
</li>
<li id="bib.bib686" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[686]</span>
<span class="ltx_bibblock">
N.&nbsp;Shinn, B.&nbsp;Labash, and A.&nbsp;Gopinath, “Reflexion: an autonomous agent with
dynamic memory and self-reflection,” <em id="bib.bib686.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.11366, 2023.

</span>
</li>
<li id="bib.bib687" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[687]</span>
<span class="ltx_bibblock">
Z.&nbsp;Gou, Z.&nbsp;Shao, Y.&nbsp;Gong, Y.&nbsp;Shen, Y.&nbsp;Yang, N.&nbsp;Duan, and W.&nbsp;Chen, “CRITIC:
large language models can self-correct with tool-interactive critiquing,”
<em id="bib.bib687.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.11738, 2023.

</span>
</li>
<li id="bib.bib688" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[688]</span>
<span class="ltx_bibblock">
J.&nbsp;Uesato, N.&nbsp;Kushman, R.&nbsp;Kumar, H.&nbsp;F. Song, N.&nbsp;Y. Siegel, L.&nbsp;Wang,
A.&nbsp;Creswell, G.&nbsp;Irving, and I.&nbsp;Higgins, “Solving math word problems with
process- and outcome-based feedback,” <em id="bib.bib688.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2211.14275,
2022.

</span>
</li>
<li id="bib.bib689" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[689]</span>
<span class="ltx_bibblock">
H.&nbsp;Lightman, V.&nbsp;Kosaraju, Y.&nbsp;Burda, H.&nbsp;Edwards, B.&nbsp;Baker, T.&nbsp;Lee, J.&nbsp;Leike,
J.&nbsp;Schulman, I.&nbsp;Sutskever, and K.&nbsp;Cobbe, “Let’s verify step by step,”
<em id="bib.bib689.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.20050, 2023.

</span>
</li>
<li id="bib.bib690" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[690]</span>
<span class="ltx_bibblock">
Z.&nbsp;Yuan, H.&nbsp;Yuan, C.&nbsp;Tan, W.&nbsp;Wang, and S.&nbsp;Huang, “How well do large language
models perform in arithmetic tasks?” <em id="bib.bib690.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.02015, 2023.

</span>
</li>
<li id="bib.bib691" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[691]</span>
<span class="ltx_bibblock">
X.&nbsp;Pi, Q.&nbsp;Liu, B.&nbsp;Chen, M.&nbsp;Ziyadi, Z.&nbsp;Lin, Q.&nbsp;Fu, Y.&nbsp;Gao, J.&nbsp;Lou, and W.&nbsp;Chen,
“Reasoning like program executors,” in <em id="bib.bib691.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022
Conference on Empirical Methods in Natural Language Processing, EMNLP 2022,
Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, 2022, pp. 761–779.

</span>
</li>
<li id="bib.bib692" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[692]</span>
<span class="ltx_bibblock">
H.&nbsp;Zhou, A.&nbsp;Nova, H.&nbsp;Larochelle, A.&nbsp;C. Courville, B.&nbsp;Neyshabur, and H.&nbsp;Sedghi,
“Teaching algorithmic reasoning via in-context learning,” <em id="bib.bib692.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2211.09066, 2022.

</span>
</li>
<li id="bib.bib693" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[693]</span>
<span class="ltx_bibblock">
A.&nbsp;Parisi, Y.&nbsp;Zhao, and N.&nbsp;Fiedel, “TALM: tool augmented language models,”
<em id="bib.bib693.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2205.12255, 2022.

</span>
</li>
<li id="bib.bib694" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[694]</span>
<span class="ltx_bibblock">
W.&nbsp;Huang, P.&nbsp;Abbeel, D.&nbsp;Pathak, and I.&nbsp;Mordatch, “Language models as zero-shot
planners: Extracting actionable knowledge for embodied agents,” in
<em id="bib.bib694.1.1" class="ltx_emph ltx_font_italic">ICML</em>, ser. Proceedings of Machine Learning Research, vol. 162.&nbsp;&nbsp;&nbsp;PMLR, 2022, pp. 9118–9147.

</span>
</li>
<li id="bib.bib695" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[695]</span>
<span class="ltx_bibblock">
T.&nbsp;Carta, C.&nbsp;Romac, T.&nbsp;Wolf, S.&nbsp;Lamprier, O.&nbsp;Sigaud, and P.&nbsp;Oudeyer,
“Grounding large language models in interactive environments with online
reinforcement learning,” <em id="bib.bib695.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.02662, 2023.

</span>
</li>
<li id="bib.bib696" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[696]</span>
<span class="ltx_bibblock">
X.&nbsp;Zhu, Y.&nbsp;Chen, H.&nbsp;Tian, C.&nbsp;Tao, W.&nbsp;Su, C.&nbsp;Yang, G.&nbsp;Huang, B.&nbsp;Li, L.&nbsp;Lu,
X.&nbsp;Wang, Y.&nbsp;Qiao, Z.&nbsp;Zhang, and J.&nbsp;Dai, “Ghost in the minecraft: Generally
capable agents for open-world environments via large language models with
text-based knowledge and memory,” <em id="bib.bib696.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.17144, 2023.

</span>
</li>
<li id="bib.bib697" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[697]</span>
<span class="ltx_bibblock">
G.&nbsp;Wang, Y.&nbsp;Xie, Y.&nbsp;Jiang, A.&nbsp;Mandlekar, C.&nbsp;Xiao, Y.&nbsp;Zhu, L.&nbsp;Fan, and
A.&nbsp;Anandkumar, “Voyager: An open-ended embodied agent with large language
models,” <em id="bib.bib697.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.16291, 2023.

</span>
</li>
<li id="bib.bib698" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[698]</span>
<span class="ltx_bibblock">
M.&nbsp;Ahn, A.&nbsp;Brohan, N.&nbsp;Brown, Y.&nbsp;Chebotar, O.&nbsp;Cortes, B.&nbsp;David, C.&nbsp;Finn,
K.&nbsp;Gopalakrishnan, K.&nbsp;Hausman, A.&nbsp;Herzog, D.&nbsp;Ho, J.&nbsp;Hsu, J.&nbsp;Ibarz, B.&nbsp;Ichter,
A.&nbsp;Irpan, E.&nbsp;Jang, R.&nbsp;J. Ruano, K.&nbsp;Jeffrey, S.&nbsp;Jesmonth, N.&nbsp;J. Joshi,
R.&nbsp;Julian, D.&nbsp;Kalashnikov, Y.&nbsp;Kuang, K.&nbsp;Lee, S.&nbsp;Levine, Y.&nbsp;Lu, L.&nbsp;Luu,
C.&nbsp;Parada, P.&nbsp;Pastor, J.&nbsp;Quiambao, K.&nbsp;Rao, J.&nbsp;Rettinghouse, D.&nbsp;Reyes,
P.&nbsp;Sermanet, N.&nbsp;Sievers, C.&nbsp;Tan, A.&nbsp;Toshev, V.&nbsp;Vanhoucke, F.&nbsp;Xia, T.&nbsp;Xiao,
P.&nbsp;Xu, S.&nbsp;Xu, and M.&nbsp;Yan, “Do as I can, not as I say: Grounding language
in robotic affordances,” <em id="bib.bib698.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2204.01691, 2022.

</span>
</li>
<li id="bib.bib699" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[699]</span>
<span class="ltx_bibblock">
J.&nbsp;Liang, W.&nbsp;Huang, F.&nbsp;Xia, P.&nbsp;Xu, K.&nbsp;Hausman, B.&nbsp;Ichter, P.&nbsp;Florence, and
A.&nbsp;Zeng, “Code as policies: Language model programs for embodied control,”
<em id="bib.bib699.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2209.07753, 2022.

</span>
</li>
<li id="bib.bib700" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[700]</span>
<span class="ltx_bibblock">
Y.&nbsp;Fu, H.&nbsp;Peng, T.&nbsp;Khot, and M.&nbsp;Lapata, “Improving language model negotiation
with self-play and in-context learning from AI feedback,” <em id="bib.bib700.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2305.10142, 2023.

</span>
</li>
<li id="bib.bib701" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[701]</span>
<span class="ltx_bibblock">
N.&nbsp;Mehta, M.&nbsp;Teruel, P.&nbsp;F. Sanz, X.&nbsp;Deng, A.&nbsp;H. Awadallah, and J.&nbsp;Kiseleva,
“Improving grounded language understanding in a collaborative environment by
interacting with agents through help feedback,” <em id="bib.bib701.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2304.10750, 2023.

</span>
</li>
<li id="bib.bib702" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[702]</span>
<span class="ltx_bibblock">
S.&nbsp;G. Patil, T.&nbsp;Zhang, X.&nbsp;Wang, and J.&nbsp;E. Gonzalez, “Gorilla: Large language
model connected with massive apis,” <em id="bib.bib702.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.15334, 2023.

</span>
</li>
<li id="bib.bib703" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[703]</span>
<span class="ltx_bibblock">
S.&nbsp;Hao, T.&nbsp;Liu, Z.&nbsp;Wang, and Z.&nbsp;Hu, “Toolkengpt: Augmenting frozen language
models with massive tools via tool embeddings,” <em id="bib.bib703.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.11554, 2023.

</span>
</li>
<li id="bib.bib704" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[704]</span>
<span class="ltx_bibblock">
Y.&nbsp;Liang, C.&nbsp;Wu, T.&nbsp;Song, W.&nbsp;Wu, Y.&nbsp;Xia, Y.&nbsp;Liu, Y.&nbsp;Ou, S.&nbsp;Lu, L.&nbsp;Ji, S.&nbsp;Mao,
Y.&nbsp;Wang, L.&nbsp;Shou, M.&nbsp;Gong, and N.&nbsp;Duan, “Taskmatrix.ai: Completing tasks by
connecting foundation models with millions of apis,” <em id="bib.bib704.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2303.16434, 2023.

</span>
</li>
<li id="bib.bib705" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[705]</span>
<span class="ltx_bibblock">
T.&nbsp;Cai, X.&nbsp;Wang, T.&nbsp;Ma, X.&nbsp;Chen, and D.&nbsp;Zhou, “Large language models as tool
makers,” <em id="bib.bib705.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.17126, 2023.

</span>
</li>
<li id="bib.bib706" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[706]</span>
<span class="ltx_bibblock">
J.&nbsp;Huang, S.&nbsp;S. Gu, L.&nbsp;Hou, Y.&nbsp;Wu, X.&nbsp;Wang, H.&nbsp;Yu, and J.&nbsp;Han, “Large language
models can self-improve,” <em id="bib.bib706.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.11610, 2022.

</span>
</li>
<li id="bib.bib707" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[707]</span>
<span class="ltx_bibblock">
E.&nbsp;Beeching, C.&nbsp;Fourrier, N.&nbsp;Habib, S.&nbsp;Han, N.&nbsp;Lambert, N.&nbsp;Rajani,
O.&nbsp;Sanseviero, L.&nbsp;Tunstall, and T.&nbsp;Wolf, “Open llm leaderboard,”
<a target="_blank" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a>, 2023.

</span>
</li>
<li id="bib.bib708" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[708]</span>
<span class="ltx_bibblock">
W.&nbsp;Zhong, R.&nbsp;Cui, Y.&nbsp;Guo, Y.&nbsp;Liang, S.&nbsp;Lu, Y.&nbsp;Wang, A.&nbsp;Saied, W.&nbsp;Chen, and
N.&nbsp;Duan, “Agieval: A human-centric benchmark for evaluating foundation
models,” <em id="bib.bib708.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.06364, 2023.

</span>
</li>
<li id="bib.bib709" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[709]</span>
<span class="ltx_bibblock">
H.&nbsp;Zeng, “Measuring massive multitask chinese understanding,” <em id="bib.bib709.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2304.12986, 2023.

</span>
</li>
<li id="bib.bib710" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[710]</span>
<span class="ltx_bibblock">
C.&nbsp;Liu, R.&nbsp;Jin, Y.&nbsp;Ren, L.&nbsp;Yu, T.&nbsp;Dong, X.&nbsp;Peng, S.&nbsp;Zhang, J.&nbsp;Peng, P.&nbsp;Zhang,
Q.&nbsp;Lyu, X.&nbsp;Su, Q.&nbsp;Liu, and D.&nbsp;Xiong, “M3KE: A massive multi-level
multi-subject knowledge evaluation benchmark for chinese large language
models,” <em id="bib.bib710.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.10263, 2023.

</span>
</li>
<li id="bib.bib711" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[711]</span>
<span class="ltx_bibblock">
Y.&nbsp;Huang, Y.&nbsp;Bai, Z.&nbsp;Zhu, J.&nbsp;Zhang, J.&nbsp;Zhang, T.&nbsp;Su, J.&nbsp;Liu, C.&nbsp;Lv, Y.&nbsp;Zhang,
J.&nbsp;Lei, Y.&nbsp;Fu, M.&nbsp;Sun, and J.&nbsp;He, “C-eval: A multi-level multi-discipline
chinese evaluation suite for foundation models,” <em id="bib.bib711.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.08322, 2023.

</span>
</li>
<li id="bib.bib712" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[712]</span>
<span class="ltx_bibblock">
Z.&nbsp;Gu, X.&nbsp;Zhu, H.&nbsp;Ye, L.&nbsp;Zhang, J.&nbsp;Wang, S.&nbsp;Jiang, Z.&nbsp;Xiong, Z.&nbsp;Li, Q.&nbsp;He,
R.&nbsp;Xu, W.&nbsp;Huang, W.&nbsp;Zheng, H.&nbsp;Feng, and Y.&nbsp;Xiao, “Xiezhi: An ever-updating
benchmark for holistic domain knowledge evaluation,” <em id="bib.bib712.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.05783, 2023.

</span>
</li>
<li id="bib.bib713" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[713]</span>
<span class="ltx_bibblock">
O.&nbsp;Contributors, “Opencompass: A universal evaluation platform for foundation
models,” <a target="_blank" href="https://github.com/InternLM/OpenCompass" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/InternLM/OpenCompass</a>, 2023.

</span>
</li>
<li id="bib.bib714" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[714]</span>
<span class="ltx_bibblock">
Y.&nbsp;Fu, L.&nbsp;Ou, M.&nbsp;Chen, Y.&nbsp;Wan, H.&nbsp;Peng, and T.&nbsp;Khot, “Chain-of-thought hub:
A continuous effort to measure large language models’ reasoning
performance,” <em id="bib.bib714.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.17306, 2023.

</span>
</li>
<li id="bib.bib715" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[715]</span>
<span class="ltx_bibblock">
J.&nbsp;Yu, X.&nbsp;Wang, S.&nbsp;Tu, S.&nbsp;Cao, D.&nbsp;Zhang-li, X.&nbsp;Lv, H.&nbsp;Peng, Z.&nbsp;Yao, X.&nbsp;Zhang,
H.&nbsp;Li, C.&nbsp;Li, Z.&nbsp;Zhang, Y.&nbsp;Bai, Y.&nbsp;Liu, A.&nbsp;Xin, N.&nbsp;Lin, K.&nbsp;Yun, L.&nbsp;Gong,
J.&nbsp;Chen, Z.&nbsp;Wu, Y.&nbsp;Qi, W.&nbsp;Li, Y.&nbsp;Guan, K.&nbsp;Zeng, J.&nbsp;Qi, H.&nbsp;Jin, J.&nbsp;Liu, Y.&nbsp;Gu,
Y.&nbsp;Yao, N.&nbsp;Ding, L.&nbsp;Hou, Z.&nbsp;Liu, B.&nbsp;Xu, J.&nbsp;Tang, and J.&nbsp;Li, “Kola: Carefully
benchmarking world knowledge of large language models,” <em id="bib.bib715.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.09296, 2023.

</span>
</li>
<li id="bib.bib716" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[716]</span>
<span class="ltx_bibblock">
T.&nbsp;Sawada, D.&nbsp;Paleka, A.&nbsp;Havrilla, P.&nbsp;Tadepalli, P.&nbsp;Vidas, A.&nbsp;Kranias, J.&nbsp;J.
Nay, K.&nbsp;Gupta, and A.&nbsp;Komatsuzaki, “ARB: advanced reasoning benchmark for
large language models,” <em id="bib.bib716.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.13692, 2023.

</span>
</li>
<li id="bib.bib717" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[717]</span>
<span class="ltx_bibblock">
Y.&nbsp;Peng, S.&nbsp;Li, W.&nbsp;Gu, Y.&nbsp;Li, W.&nbsp;Wang, C.&nbsp;Gao, and M.&nbsp;R. Lyu, “Revisiting,
benchmarking and exploring API recommendation: How far are we?”
<em id="bib.bib717.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Software Eng.</em>, vol.&nbsp;49, no.&nbsp;4, pp. 1876–1897, 2023.

</span>
</li>
<li id="bib.bib718" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[718]</span>
<span class="ltx_bibblock">
M.&nbsp;Li, F.&nbsp;Song, B.&nbsp;Yu, H.&nbsp;Yu, Z.&nbsp;Li, F.&nbsp;Huang, and Y.&nbsp;Li, “Api-bank: A
benchmark for tool-augmented llms,” <em id="bib.bib718.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.08244, 2023.

</span>
</li>
<li id="bib.bib719" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[719]</span>
<span class="ltx_bibblock">
Q.&nbsp;Tang, Z.&nbsp;Deng, H.&nbsp;Lin, X.&nbsp;Han, Q.&nbsp;Liang, and L.&nbsp;Sun, “Toolalpaca:
Generalized tool learning for language models with 3000 simulated cases,”
<em id="bib.bib719.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.05301, 2023.

</span>
</li>
<li id="bib.bib720" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[720]</span>
<span class="ltx_bibblock">
Q.&nbsp;Xu, F.&nbsp;Hong, B.&nbsp;Li, C.&nbsp;Hu, Z.&nbsp;Chen, and J.&nbsp;Zhang, “On the tool manipulation
capability of open-source large language models,” <em id="bib.bib720.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.16504, 2023.

</span>
</li>
<li id="bib.bib721" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[721]</span>
<span class="ltx_bibblock">
Y.&nbsp;Qin, S.&nbsp;Liang, Y.&nbsp;Ye, K.&nbsp;Zhu, L.&nbsp;Yan, Y.&nbsp;Lu, Y.&nbsp;Lin, X.&nbsp;Cong, X.&nbsp;Tang,
B.&nbsp;Qian, S.&nbsp;Zhao, R.&nbsp;Tian, R.&nbsp;Xie, J.&nbsp;Zhou, M.&nbsp;Gerstein, D.&nbsp;Li, Z.&nbsp;Liu, and
M.&nbsp;Sun, “Toolllm: Facilitating large language models to master 16000+
real-world apis,” <em id="bib.bib721.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.16789, 2023.

</span>
</li>
<li id="bib.bib722" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[722]</span>
<span class="ltx_bibblock">
Z.&nbsp;Liu, W.&nbsp;Yao, J.&nbsp;Zhang, L.&nbsp;Xue, S.&nbsp;Heinecke, R.&nbsp;Murthy, Y.&nbsp;Feng, Z.&nbsp;Chen,
J.&nbsp;C. Niebles, D.&nbsp;Arpit, R.&nbsp;Xu, P.&nbsp;Mui, H.&nbsp;Wang, C.&nbsp;Xiong, and S.&nbsp;Savarese,
“BOLAA: benchmarking and orchestrating llm-augmented autonomous agents,”
<em id="bib.bib722.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.05960, 2023.

</span>
</li>
<li id="bib.bib723" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[723]</span>
<span class="ltx_bibblock">
X.&nbsp;Liu, H.&nbsp;Yu, H.&nbsp;Zhang, Y.&nbsp;Xu, X.&nbsp;Lei, H.&nbsp;Lai, Y.&nbsp;Gu, H.&nbsp;Ding, K.&nbsp;Men,
K.&nbsp;Yang, S.&nbsp;Zhang, X.&nbsp;Deng, A.&nbsp;Zeng, Z.&nbsp;Du, C.&nbsp;Zhang, S.&nbsp;Shen, T.&nbsp;Zhang,
Y.&nbsp;Su, H.&nbsp;Sun, M.&nbsp;Huang, Y.&nbsp;Dong, and J.&nbsp;Tang, “Agentbench: Evaluating llms
as agents,” <em id="bib.bib723.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.03688, 2023.

</span>
</li>
<li id="bib.bib724" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[724]</span>
<span class="ltx_bibblock">
K.&nbsp;Zhu, J.&nbsp;Wang, J.&nbsp;Zhou, Z.&nbsp;Wang, H.&nbsp;Chen, Y.&nbsp;Wang, L.&nbsp;Yang, W.&nbsp;Ye, N.&nbsp;Z.
Gong, Y.&nbsp;Zhang, and X.&nbsp;Xie, “Promptbench: Towards evaluating the robustness
of large language models on adversarial prompts,” <em id="bib.bib724.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.04528, 2023.

</span>
</li>
<li id="bib.bib725" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[725]</span>
<span class="ltx_bibblock">
R.&nbsp;S. Shah, K.&nbsp;Chawla, D.&nbsp;Eidnani, A.&nbsp;Shah, W.&nbsp;Du, S.&nbsp;Chava, N.&nbsp;Raman,
C.&nbsp;Smiley, J.&nbsp;Chen, and D.&nbsp;Yang, “WHEN FLUE MEETS FLANG: benchmarks
and large pre-trained language model for financial domain,” <em id="bib.bib725.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2211.00083, 2022.

</span>
</li>
<li id="bib.bib726" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[726]</span>
<span class="ltx_bibblock">
N.&nbsp;Guha, D.&nbsp;E. Ho, J.&nbsp;Nyarko, and C.&nbsp;Ré, “Legalbench: Prototyping a
collaborative benchmark for legal reasoning,” <em id="bib.bib726.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2209.06120, 2022.

</span>
</li>
<li id="bib.bib727" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[727]</span>
<span class="ltx_bibblock">
L.&nbsp;Zheng, W.&nbsp;Chiang, Y.&nbsp;Sheng, S.&nbsp;Zhuang, Z.&nbsp;Wu, Y.&nbsp;Zhuang, Z.&nbsp;Lin, Z.&nbsp;Li,
D.&nbsp;Li, E.&nbsp;P. Xing, H.&nbsp;Zhang, J.&nbsp;E. Gonzalez, and I.&nbsp;Stoica, “Judging
llm-as-a-judge with mt-bench and chatbot arena,” <em id="bib.bib727.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.05685, 2023.

</span>
</li>
<li id="bib.bib728" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[728]</span>
<span class="ltx_bibblock">
X.&nbsp;Wang, Z.&nbsp;Hu, P.&nbsp;Lu, Y.&nbsp;Zhu, J.&nbsp;Zhang, S.&nbsp;Subramaniam, A.&nbsp;R. Loomba,
S.&nbsp;Zhang, Y.&nbsp;Sun, and W.&nbsp;Wang, “Scibench: Evaluating college-level
scientific problem-solving abilities of large language models,” <em id="bib.bib728.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2307.10635, 2023.

</span>
</li>
<li id="bib.bib729" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[729]</span>
<span class="ltx_bibblock">
X.&nbsp;Li, T.&nbsp;Zhang, Y.&nbsp;Dubois, R.&nbsp;Taori, I.&nbsp;Gulrajani, C.&nbsp;Guestrin, P.&nbsp;Liang, and
T.&nbsp;B. Hashimoto, “Alpacaeval: An automatic evaluator of
instruction-following models,”
<a target="_blank" href="https://github.com/tatsu-lab/alpaca_eval" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/alpaca_eval</a>, 2023.

</span>
</li>
<li id="bib.bib730" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[730]</span>
<span class="ltx_bibblock">
Y.&nbsp;Huang, Q.&nbsp;Zhang, P.&nbsp;S. Yu, and L.&nbsp;Sun, “Trustgpt: A benchmark for
trustworthy and responsible large language models,” <em id="bib.bib730.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.11507, 2023.

</span>
</li>
<li id="bib.bib731" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[731]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bai, J.&nbsp;Ying, Y.&nbsp;Cao, X.&nbsp;Lv, Y.&nbsp;He, X.&nbsp;Wang, J.&nbsp;Yu, K.&nbsp;Zeng, Y.&nbsp;Xiao,
H.&nbsp;Lyu, J.&nbsp;Zhang, J.&nbsp;Li, and L.&nbsp;Hou, “Benchmarking foundation models with
language-model-as-an-examiner,” <em id="bib.bib731.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.04181, 2023.

</span>
</li>
<li id="bib.bib732" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[732]</span>
<span class="ltx_bibblock">
C.&nbsp;Chan, W.&nbsp;Chen, Y.&nbsp;Su, J.&nbsp;Yu, W.&nbsp;Xue, S.&nbsp;Zhang, J.&nbsp;Fu, and Z.&nbsp;Liu,
“Chateval: Towards better llm-based evaluators through multi-agent debate,”
<em id="bib.bib732.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.07201, 2023.

</span>
</li>
<li id="bib.bib733" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[733]</span>
<span class="ltx_bibblock">
Y.&nbsp;Chang, X.&nbsp;Wang, J.&nbsp;Wang, Y.&nbsp;Wu, K.&nbsp;Zhu, H.&nbsp;Chen, L.&nbsp;Yang, X.&nbsp;Yi, C.&nbsp;Wang,
Y.&nbsp;Wang, W.&nbsp;Ye, Y.&nbsp;Zhang, Y.&nbsp;Chang, P.&nbsp;S. Yu, Q.&nbsp;Yang, and X.&nbsp;Xie, “A survey
on evaluation of large language models,” <em id="bib.bib733.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.03109,
2023.

</span>
</li>
<li id="bib.bib734" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[734]</span>
<span class="ltx_bibblock">
Z.&nbsp;Zhuang, Q.&nbsp;Chen, L.&nbsp;Ma, M.&nbsp;Li, Y.&nbsp;Han, Y.&nbsp;Qian, H.&nbsp;Bai, Z.&nbsp;Feng, W.&nbsp;Zhang,
and T.&nbsp;Liu, “Through the lens of core competency: Survey on evaluation of
large language models,” <em id="bib.bib734.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.07902, 2023.

</span>
</li>
<li id="bib.bib735" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[735]</span>
<span class="ltx_bibblock">
J.&nbsp;H. Clark, J.&nbsp;Palomaki, V.&nbsp;Nikolaev, E.&nbsp;Choi, D.&nbsp;Garrette, M.&nbsp;Collins, and
T.&nbsp;Kwiatkowski, “Tydi QA: A benchmark for information-seeking question
answering in typologically diverse languages,” <em id="bib.bib735.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput.
Linguistics</em>, vol.&nbsp;8, pp. 454–470, 2020.

</span>
</li>
<li id="bib.bib736" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[736]</span>
<span class="ltx_bibblock">
L.&nbsp;Gao, J.&nbsp;Tow, S.&nbsp;Biderman, S.&nbsp;Black, A.&nbsp;DiPofi, C.&nbsp;Foster, L.&nbsp;Golding,
J.&nbsp;Hsu, K.&nbsp;McDonell, N.&nbsp;Muennighoff, J.&nbsp;Phang, L.&nbsp;Reynolds, E.&nbsp;Tang,
A.&nbsp;Thite, B.&nbsp;Wang, K.&nbsp;Wang, and A.&nbsp;Zou, “A framework for few-shot language
model evaluation,” Sep. 2021.

</span>
</li>
<li id="bib.bib737" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[737]</span>
<span class="ltx_bibblock">
R.&nbsp;Shah, K.&nbsp;Chawla, D.&nbsp;Eidnani, A.&nbsp;Shah, W.&nbsp;Du, S.&nbsp;Chava, N.&nbsp;Raman, C.&nbsp;Smiley,
J.&nbsp;Chen, and D.&nbsp;Yang, “When flue meets flang: Benchmarks and large
pretrained language model for financial domain,” in <em id="bib.bib737.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2022 Conference on Empirical Methods in Natural Language Processing</em>, 2022,
pp. 2322–2335.

</span>
</li>
<li id="bib.bib738" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[738]</span>
<span class="ltx_bibblock">
K.&nbsp;Zhou, Y.&nbsp;Zhu, Z.&nbsp;Chen, W.&nbsp;Chen, W.&nbsp;X. Zhao, X.&nbsp;Chen, Y.&nbsp;Lin, J.-R. Wen, and
J.&nbsp;Han, “Don’t make your llm an evaluation benchmark cheater,” <em id="bib.bib738.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2311.01964</em>, 2023.

</span>
</li>
<li id="bib.bib739" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[739]</span>
<span class="ltx_bibblock">
C.&nbsp;Zan, K.&nbsp;Peng, L.&nbsp;Ding, B.&nbsp;Qiu, B.&nbsp;Liu, S.&nbsp;He, Q.&nbsp;Lu, Z.&nbsp;Zhang, C.&nbsp;Liu,
W.&nbsp;Liu, Y.&nbsp;Zhan, and D.&nbsp;Tao, “Vega-mt: The JD explore academy machine
translation system for WMT22,” in <em id="bib.bib739.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh
Conference on Machine Translation, WMT 2022, Abu Dhabi, United Arab
Emirates (Hybrid), December 7-8, 2022</em>, P.&nbsp;Koehn, L.&nbsp;Barrault, O.&nbsp;Bojar,
F.&nbsp;Bougares, R.&nbsp;Chatterjee, M.&nbsp;R. Costa-jussà, C.&nbsp;Federmann,
M.&nbsp;Fishel, A.&nbsp;Fraser, M.&nbsp;Freitag, Y.&nbsp;Graham, R.&nbsp;Grundkiewicz, P.&nbsp;Guzman,
B.&nbsp;Haddow, M.&nbsp;Huck, A.&nbsp;Jimeno-Yepes, T.&nbsp;Kocmi, A.&nbsp;Martins, M.&nbsp;Morishita,
C.&nbsp;Monz, M.&nbsp;Nagata, T.&nbsp;Nakazawa, M.&nbsp;Negri, A.&nbsp;Névéol, M.&nbsp;Neves,
M.&nbsp;Popel, M.&nbsp;Turchi, and M.&nbsp;Zampieri, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022, pp. 411–422.

</span>
</li>
<li id="bib.bib740" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[740]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhao, M.&nbsp;Khalman, R.&nbsp;Joshi, S.&nbsp;Narayan, M.&nbsp;Saleh, and P.&nbsp;J. Liu,
“Calibrating sequence likelihood improves conditional language generation,”
<em id="bib.bib740.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2210.00045, 2022. [Online]. Available:
<a target="_blank" href="https://doi.org/10.48550/arXiv.2210.00045" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2210.00045</a>

</span>
</li>
<li id="bib.bib741" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[741]</span>
<span class="ltx_bibblock">
D.&nbsp;Khashabi, S.&nbsp;Min, T.&nbsp;Khot, A.&nbsp;Sabharwal, O.&nbsp;Tafjord, P.&nbsp;Clark, and
H.&nbsp;Hajishirzi, “Unifiedqa: Crossing format boundaries with a single QA
system,” in <em id="bib.bib741.1.1" class="ltx_emph ltx_font_italic">EMNLP (Findings)</em>, ser. Findings of ACL, vol. EMNLP
2020.&nbsp;&nbsp;&nbsp;Association for Computational
Linguistics, 2020, pp. 1896–1907.

</span>
</li>
<li id="bib.bib742" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[742]</span>
<span class="ltx_bibblock">
X.&nbsp;Zhu, J.&nbsp;Wang, L.&nbsp;Zhang, Y.&nbsp;Zhang, R.&nbsp;Gan, J.&nbsp;Zhang, and Y.&nbsp;Yang, “Solving
math word problem via cooperative reasoning induced language models,”
<em id="bib.bib742.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.16257</em>, 2022.

</span>
</li>
<li id="bib.bib743" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[743]</span>
<span class="ltx_bibblock">
A.&nbsp;Nguyen, N.&nbsp;Karampatziakis, and W.&nbsp;Chen, “Meet in the middle: A new
pre-training paradigm,” <em id="bib.bib743.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.07295, 2023. [Online].
Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2303.07295" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2303.07295</a>

</span>
</li>
<li id="bib.bib744" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[744]</span>
<span class="ltx_bibblock">
H.&nbsp;Li, J.&nbsp;Zhang, C.&nbsp;Li, and H.&nbsp;Chen, “RESDSQL: decoupling schema linking and
skeleton parsing for text-to-sql,” <em id="bib.bib744.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.05965, 2023.
[Online]. Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2302.05965" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2302.05965</a>

</span>
</li>
<li id="bib.bib745" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[745]</span>
<span class="ltx_bibblock">
W.&nbsp;Kang and J.&nbsp;J. McAuley, “Self-attentive sequential recommendation,” in
<em id="bib.bib745.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Data Mining, ICDM 2018, Singapore,
November 17-20, 2018</em>.&nbsp;&nbsp;&nbsp;IEEE Computer
Society, 2018, pp. 197–206.

</span>
</li>
<li id="bib.bib746" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[746]</span>
<span class="ltx_bibblock">
B.&nbsp;Yang, C.&nbsp;Han, Y.&nbsp;Li, L.&nbsp;Zuo, and Z.&nbsp;Yu, “Improving conversational
recommendation systems’ quality with context-aware item meta-information,”
in <em id="bib.bib746.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: NAACL
2022, Seattle, WA, United States, July 10-15, 2022</em>, M.&nbsp;Carpuat,
M.&nbsp;de&nbsp;Marneffe, and I.&nbsp;V.&nbsp;M. Ruíz, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2022, pp. 38–48.

</span>
</li>
<li id="bib.bib747" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[747]</span>
<span class="ltx_bibblock">
E.&nbsp;Almazrouei, H.&nbsp;Alobeidli, A.&nbsp;Alshamsi, A.&nbsp;Cappelli, R.&nbsp;Cojocaru, M.&nbsp;Debbah,
E.&nbsp;Goffinet, D.&nbsp;Heslow, J.&nbsp;Launay, Q.&nbsp;Malartic, B.&nbsp;Noune, B.&nbsp;Pannier, and
G.&nbsp;Penedo, “Falcon-40B: an open large language model with state-of-the-art
performance,” 2023.

</span>
</li>
<li id="bib.bib748" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[748]</span>
<span class="ltx_bibblock">
S.&nbsp;Martin, J.&nbsp;Liermann, and H.&nbsp;Ney, “Algorithms for bigram and trigram word
clustering,” <em id="bib.bib748.1.1" class="ltx_emph ltx_font_italic">Speech communication</em>, vol.&nbsp;24, no.&nbsp;1, pp. 19–37, 1998.

</span>
</li>
<li id="bib.bib749" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[749]</span>
<span class="ltx_bibblock">
R.&nbsp;Navigli, “Word sense disambiguation: A survey,” <em id="bib.bib749.1.1" class="ltx_emph ltx_font_italic">ACM computing
surveys (CSUR)</em>, vol.&nbsp;41, no.&nbsp;2, pp. 1–69, 2009.

</span>
</li>
<li id="bib.bib750" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[750]</span>
<span class="ltx_bibblock">
W.&nbsp;H. Gomaa, A.&nbsp;A. Fahmy <em id="bib.bib750.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “A survey of text similarity
approaches,” <em id="bib.bib750.2.2" class="ltx_emph ltx_font_italic">international journal of Computer Applications</em>, vol.&nbsp;68,
no.&nbsp;13, pp. 13–18, 2013.

</span>
</li>
<li id="bib.bib751" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[751]</span>
<span class="ltx_bibblock">
S.&nbsp;Minaee, N.&nbsp;Kalchbrenner, E.&nbsp;Cambria, N.&nbsp;Nikzad, M.&nbsp;Chenaghlu, and J.&nbsp;Gao,
“Deep learning–based text classification: a comprehensive review,”
<em id="bib.bib751.1.1" class="ltx_emph ltx_font_italic">ACM computing surveys (CSUR)</em>, vol.&nbsp;54, no.&nbsp;3, pp. 1–40, 2021.

</span>
</li>
<li id="bib.bib752" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[752]</span>
<span class="ltx_bibblock">
N.&nbsp;Alex, E.&nbsp;Lifland, L.&nbsp;Tunstall, A.&nbsp;Thakur, P.&nbsp;Maham, C.&nbsp;J. Riedel, E.&nbsp;Hine,
C.&nbsp;Ashurst, P.&nbsp;Sedille, A.&nbsp;Carlier, M.&nbsp;Noetel, and A.&nbsp;Stuhlmüller,
“RAFT: A real-world few-shot text classification benchmark,” in
<em id="bib.bib752.1.1" class="ltx_emph ltx_font_italic">NeurIPS Datasets and Benchmarks</em>, 2021.

</span>
</li>
<li id="bib.bib753" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[753]</span>
<span class="ltx_bibblock">
C.&nbsp;Qin, A.&nbsp;Zhang, Z.&nbsp;Zhang, J.&nbsp;Chen, M.&nbsp;Yasunaga, and D.&nbsp;Yang, “Is chatgpt a
general-purpose natural language processing task solver?” <em id="bib.bib753.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2302.06476, 2023.

</span>
</li>
<li id="bib.bib754" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[754]</span>
<span class="ltx_bibblock">
X.&nbsp;Chen, J.&nbsp;Ye, C.&nbsp;Zu, N.&nbsp;Xu, R.&nbsp;Zheng, M.&nbsp;Peng, J.&nbsp;Zhou, T.&nbsp;Gui, Q.&nbsp;Zhang, and
X.&nbsp;Huang, “How robust is gpt-3.5 to predecessors? a comprehensive study on
language understanding tasks,” 2023.

</span>
</li>
<li id="bib.bib755" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[755]</span>
<span class="ltx_bibblock">
D.&nbsp;Nadeau and S.&nbsp;Sekine, “A survey of named entity recognition and
classification,” <em id="bib.bib755.1.1" class="ltx_emph ltx_font_italic">Lingvisticae Investigationes</em>, vol.&nbsp;30, no.&nbsp;1, pp.
3–26, 2007.

</span>
</li>
<li id="bib.bib756" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[756]</span>
<span class="ltx_bibblock">
A.&nbsp;Ratnaparkhi, “A maximum entropy model for part-of-speech tagging,” in
<em id="bib.bib756.1.1" class="ltx_emph ltx_font_italic">Conference on empirical methods in natural language processing</em>, 1996.

</span>
</li>
<li id="bib.bib757" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[757]</span>
<span class="ltx_bibblock">
V.&nbsp;Yadav and S.&nbsp;Bethard, “A survey on recent advances in named entity
recognition from deep learning models,” in <em id="bib.bib757.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th
International Conference on Computational Linguistics</em>, 2018, pp. 2145–2158.

</span>
</li>
<li id="bib.bib758" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[758]</span>
<span class="ltx_bibblock">
F.&nbsp;Souza, R.&nbsp;Nogueira, and R.&nbsp;Lotufo, “Portuguese named entity recognition
using bert-crf,” <em id="bib.bib758.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.10649</em>, 2019.

</span>
</li>
<li id="bib.bib759" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[759]</span>
<span class="ltx_bibblock">
S.&nbsp;Pawar, G.&nbsp;K. Palshikar, and P.&nbsp;Bhattacharyya, “Relation extraction: A
survey,” <em id="bib.bib759.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1712.05191</em>, 2017.

</span>
</li>
<li id="bib.bib760" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[760]</span>
<span class="ltx_bibblock">
C.&nbsp;Walker and et&nbsp;al., “Ace 2005 multilingual training corpus ldc2006t06,”
Philadelphia, 2006.

</span>
</li>
<li id="bib.bib761" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[761]</span>
<span class="ltx_bibblock">
J.&nbsp;Gao, H.&nbsp;Zhao, C.&nbsp;Yu, and R.&nbsp;Xu, “Exploring the feasibility of chatgpt for
event extraction,” <em id="bib.bib761.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.03836, 2023.

</span>
</li>
<li id="bib.bib762" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[762]</span>
<span class="ltx_bibblock">
Y.&nbsp;Ma, Y.&nbsp;Cao, Y.&nbsp;Hong, and A.&nbsp;Sun, “Large language model is not a good
few-shot information extractor, but a good reranker for hard samples!”
<em id="bib.bib762.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.08559, 2023.

</span>
</li>
<li id="bib.bib763" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[763]</span>
<span class="ltx_bibblock">
R.&nbsp;Tang, X.&nbsp;Han, X.&nbsp;Jiang, and X.&nbsp;Hu, “Does synthetic data generation of llms
help clinical text mining?” <em id="bib.bib763.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.04360</em>, 2023.

</span>
</li>
<li id="bib.bib764" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[764]</span>
<span class="ltx_bibblock">
A.&nbsp;Vaswani, S.&nbsp;Bengio, E.&nbsp;Brevdo, F.&nbsp;Chollet, A.&nbsp;Gomez, S.&nbsp;Gouws, L.&nbsp;Jones,
Ł.&nbsp;Kaiser, N.&nbsp;Kalchbrenner, N.&nbsp;Parmar <em id="bib.bib764.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Tensor2tensor for
neural machine translation,” in <em id="bib.bib764.2.2" class="ltx_emph ltx_font_italic">Proceedings of the 13th Conference of
the Association for Machine Translation in the Americas (Volume 1: Research
Track)</em>, 2018, pp. 193–199.

</span>
</li>
<li id="bib.bib765" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[765]</span>
<span class="ltx_bibblock">
B.&nbsp;Zhang, B.&nbsp;Haddow, and A.&nbsp;Birch, “Prompting large language model for machine
translation: A case study,” <em id="bib.bib765.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.07069</em>, 2023.

</span>
</li>
<li id="bib.bib766" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[766]</span>
<span class="ltx_bibblock">
M.&nbsp;Ghazvininejad, H.&nbsp;Gonen, and L.&nbsp;Zettlemoyer, “Dictionary-based phrase-level
prompting of large language models for machine translation,” <em id="bib.bib766.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2302.07856</em>, 2023.

</span>
</li>
<li id="bib.bib767" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[767]</span>
<span class="ltx_bibblock">
L.&nbsp;Wang, C.&nbsp;Lyu, T.&nbsp;Ji, Z.&nbsp;Zhang, D.&nbsp;Yu, S.&nbsp;Shi, and Z.&nbsp;Tu, “Document-level
machine translation with large language models,” <em id="bib.bib767.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2304.02210</em>, 2023.

</span>
</li>
<li id="bib.bib768" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[768]</span>
<span class="ltx_bibblock">
W.&nbsp;Jiao, J.-t. Huang, W.&nbsp;Wang, X.&nbsp;Wang, S.&nbsp;Shi, and Z.&nbsp;Tu, “Parrot:
Translating during chat using large language models,” <em id="bib.bib768.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2304.02426</em>, 2023.

</span>
</li>
<li id="bib.bib769" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[769]</span>
<span class="ltx_bibblock">
W.&nbsp;Yang, C.&nbsp;Li, J.&nbsp;Zhang, and C.&nbsp;Zong, “Bigtrans: Augmenting large language
models with multilingual translation capability over 100 languages,”
<em id="bib.bib769.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.18098</em>, 2023.

</span>
</li>
<li id="bib.bib770" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[770]</span>
<span class="ltx_bibblock">
J.&nbsp;Kocon, I.&nbsp;Cichecki, O.&nbsp;Kaszyca, M.&nbsp;Kochanek, D.&nbsp;Szydlo, J.&nbsp;Baran,
J.&nbsp;Bielaniewicz, M.&nbsp;Gruza, A.&nbsp;Janz, K.&nbsp;Kanclerz, A.&nbsp;Kocon, B.&nbsp;Koptyra,
W.&nbsp;Mieleszczenko-Kowszewicz, P.&nbsp;Milkowski, M.&nbsp;Oleksy, M.&nbsp;Piasecki,
L.&nbsp;Radlinski, K.&nbsp;Wojtasik, S.&nbsp;Wozniak, and P.&nbsp;Kazienko, “Chatgpt: Jack of
all trades, master of none,” <em id="bib.bib770.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.10724, 2023.

</span>
</li>
<li id="bib.bib771" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[771]</span>
<span class="ltx_bibblock">
Q.&nbsp;Zhong, L.&nbsp;Ding, J.&nbsp;Liu, B.&nbsp;Du, and D.&nbsp;Tao, “Can chatgpt understand too? A
comparative study on chatgpt and fine-tuned BERT,” <em id="bib.bib771.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2302.10198, 2023.

</span>
</li>
<li id="bib.bib772" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[772]</span>
<span class="ltx_bibblock">
D.&nbsp;Cheng, S.&nbsp;Huang, J.&nbsp;Bi, Y.&nbsp;Zhan, J.&nbsp;Liu, Y.&nbsp;Wang, H.&nbsp;Sun, F.&nbsp;Wei, D.&nbsp;Deng,
and Q.&nbsp;Zhang, “Uprise: Universal prompt retrieval for improving zero-shot
evaluation,” <em id="bib.bib772.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.08518</em>, 2023.

</span>
</li>
<li id="bib.bib773" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[773]</span>
<span class="ltx_bibblock">
R.&nbsp;Ren, Y.&nbsp;Qu, J.&nbsp;Liu, W.&nbsp;X. Zhao, Q.&nbsp;She, H.&nbsp;Wu, H.&nbsp;Wang, and J.-R. Wen,
“Rocketqav2: A joint training method for dense passage retrieval and passage
re-ranking,” in <em id="bib.bib773.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical
Methods in Natural Language Processing</em>, 2021, pp. 2825–2835.

</span>
</li>
<li id="bib.bib774" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[774]</span>
<span class="ltx_bibblock">
W.&nbsp;Sun, L.&nbsp;Yan, X.&nbsp;Ma, P.&nbsp;Ren, D.&nbsp;Yin, and Z.&nbsp;Ren, “Is chatgpt good at search?
investigating large language models as re-ranking agent,” <em id="bib.bib774.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2304.09542</em>, 2023.

</span>
</li>
<li id="bib.bib775" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[775]</span>
<span class="ltx_bibblock">
Z.&nbsp;Qin, R.&nbsp;Jagerman, K.&nbsp;Hui, H.&nbsp;Zhuang, J.&nbsp;Wu, J.&nbsp;Shen, T.&nbsp;Liu, J.&nbsp;Liu,
D.&nbsp;Metzler, X.&nbsp;Wang <em id="bib.bib775.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Large language models are effective text
rankers with pairwise ranking prompting,” <em id="bib.bib775.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2306.17563</em>, 2023.

</span>
</li>
<li id="bib.bib776" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[776]</span>
<span class="ltx_bibblock">
S.&nbsp;Cho, S.&nbsp;Jeong, J.&nbsp;Seo, and J.&nbsp;C. Park, “Discrete prompt optimization via
constrained generation for zero-shot re-ranker,” <em id="bib.bib776.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2305.13729</em>, 2023.

</span>
</li>
<li id="bib.bib777" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[777]</span>
<span class="ltx_bibblock">
R.&nbsp;Tang, X.&nbsp;Zhang, X.&nbsp;Ma, J.&nbsp;Lin, and F.&nbsp;Ture, “Found in the middle:
Permutation self-consistency improves listwise ranking in large language
models,” <em id="bib.bib777.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.07712</em>, 2023.

</span>
</li>
<li id="bib.bib778" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[778]</span>
<span class="ltx_bibblock">
X.&nbsp;Ma, X.&nbsp;Zhang, R.&nbsp;Pradeep, and J.&nbsp;Lin, “Zero-shot listwise document
reranking with a large language model,” <em id="bib.bib778.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2305.02156</em>, 2023.

</span>
</li>
<li id="bib.bib779" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[779]</span>
<span class="ltx_bibblock">
S.&nbsp;Zhuang, H.&nbsp;Zhuang, B.&nbsp;Koopman, and G.&nbsp;Zuccon, “A setwise approach for
effective and highly efficient zero-shot ranking with large language
models,” <em id="bib.bib779.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.09497</em>, 2023.

</span>
</li>
<li id="bib.bib780" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[780]</span>
<span class="ltx_bibblock">
H.&nbsp;Zhuang, Z.&nbsp;Qin, K.&nbsp;Hui, J.&nbsp;Wu, L.&nbsp;Yan, X.&nbsp;Wang, and M.&nbsp;Berdersky, “Beyond
yes and no: Improving zero-shot llm rankers via scoring fine-grained
relevance labels,” <em id="bib.bib780.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.14122</em>, 2023.

</span>
</li>
<li id="bib.bib781" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[781]</span>
<span class="ltx_bibblock">
N.&nbsp;Ziems, W.&nbsp;Yu, Z.&nbsp;Zhang, and M.&nbsp;Jiang, “Large language models are built-in
autoregressive search engines,” <em id="bib.bib781.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.09612</em>,
2023.

</span>
</li>
<li id="bib.bib782" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[782]</span>
<span class="ltx_bibblock">
X.&nbsp;Ma, L.&nbsp;Wang, N.&nbsp;Yang, F.&nbsp;Wei, and J.&nbsp;Lin, “Fine-tuning llama for
multi-stage text retrieval,” <em id="bib.bib782.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.08319</em>, 2023.

</span>
</li>
<li id="bib.bib783" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[783]</span>
<span class="ltx_bibblock">
R.&nbsp;Pradeep, S.&nbsp;Sharifymoghaddam, and J.&nbsp;Lin, “Rankvicuna: Zero-shot listwise
document reranking with open-source large language models,” <em id="bib.bib783.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2309.15088</em>, 2023.

</span>
</li>
<li id="bib.bib784" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[784]</span>
<span class="ltx_bibblock">
Y.&nbsp;Tay, V.&nbsp;Q. Tran, M.&nbsp;Dehghani, J.&nbsp;Ni, D.&nbsp;Bahri, H.&nbsp;Mehta, Z.&nbsp;Qin, K.&nbsp;Hui,
Z.&nbsp;Zhao, J.&nbsp;Gupta <em id="bib.bib784.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Transformer memory as a differentiable
search index,” in <em id="bib.bib784.2.2" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
2022.

</span>
</li>
<li id="bib.bib785" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[785]</span>
<span class="ltx_bibblock">
R.&nbsp;Ren, W.&nbsp;X. Zhao, J.&nbsp;Liu, H.&nbsp;Wu, J.-R. Wen, and H.&nbsp;Wang, “TOME: A
two-stage approach for model-based retrieval,” in <em id="bib.bib785.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
61st Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers)</em>.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2023, pp. 6102–6114. [Online]. Available:
<a target="_blank" href="https://aclanthology.org/2023.acl-long.336" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2023.acl-long.336</a>

</span>
</li>
<li id="bib.bib786" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[786]</span>
<span class="ltx_bibblock">
Y.&nbsp;Qu, Y.&nbsp;Ding, J.&nbsp;Liu, K.&nbsp;Liu, R.&nbsp;Ren, W.&nbsp;X. Zhao, D.&nbsp;Dong, H.&nbsp;Wu, and
H.&nbsp;Wang, “Rocketqa: An optimized training approach to dense passage
retrieval for open-domain question answering,” in <em id="bib.bib786.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2021 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies</em>, 2021, pp.
5835–5847.

</span>
</li>
<li id="bib.bib787" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[787]</span>
<span class="ltx_bibblock">
R.&nbsp;Ren, S.&nbsp;Lv, Y.&nbsp;Qu, J.&nbsp;Liu, W.&nbsp;X. Zhao, Q.&nbsp;She, H.&nbsp;Wu, H.&nbsp;Wang, and J.-R.
Wen, “Pair: Leveraging passage-centric similarity relation for improving
dense passage retrieval,” in <em id="bib.bib787.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for
Computational Linguistics: ACL-IJCNLP 2021</em>, 2021, pp. 2173–2183.

</span>
</li>
<li id="bib.bib788" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[788]</span>
<span class="ltx_bibblock">
Z.&nbsp;Peng, X.&nbsp;Wu, and Y.&nbsp;Fang, “Soft prompt tuning for augmenting dense
retrieval with large language models,” <em id="bib.bib788.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2307.08303</em>, 2023.

</span>
</li>
<li id="bib.bib789" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[789]</span>
<span class="ltx_bibblock">
Z.&nbsp;Dai, V.&nbsp;Y. Zhao, J.&nbsp;Ma, Y.&nbsp;Luan, J.&nbsp;Ni, J.&nbsp;Lu, A.&nbsp;Bakalov, K.&nbsp;Guu, K.&nbsp;Hall,
and M.-W. Chang, “Promptagator: Few-shot dense retrieval from 8 examples,”
in <em id="bib.bib789.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>,
2023.

</span>
</li>
<li id="bib.bib790" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[790]</span>
<span class="ltx_bibblock">
A.&nbsp;Askari, M.&nbsp;Aliannejadi, E.&nbsp;Kanoulas, and S.&nbsp;Verberne, “Generating synthetic
documents for cross-encoder re-rankers: A comparative study of chatgpt and
human experts,” <em id="bib.bib790.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.02320</em>, 2023.

</span>
</li>
<li id="bib.bib791" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[791]</span>
<span class="ltx_bibblock">
K.&nbsp;Mao, Z.&nbsp;Dou, H.&nbsp;Chen, F.&nbsp;Mo, and H.&nbsp;Qian, “Large language models know your
contextual search intent: A prompting framework for conversational search,”
<em id="bib.bib791.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.06573</em>, 2023.

</span>
</li>
<li id="bib.bib792" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[792]</span>
<span class="ltx_bibblock">
L.&nbsp;Gao, X.&nbsp;Ma, J.&nbsp;Lin, and J.&nbsp;Callan, “Precise zero-shot dense retrieval
without relevance labels,” in <em id="bib.bib792.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting
of the Association for Computational Linguistics (Volume 1: Long
Papers)</em>.&nbsp;&nbsp;&nbsp;Association for
Computational Linguistics, 2023, pp. 1762–1777.

</span>
</li>
<li id="bib.bib793" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[793]</span>
<span class="ltx_bibblock">
L.&nbsp;Wang, N.&nbsp;Yang, and F.&nbsp;Wei, “Query2doc: Query expansion with large language
models,” <em id="bib.bib793.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.07678</em>, 2023.

</span>
</li>
<li id="bib.bib794" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[794]</span>
<span class="ltx_bibblock">
G.&nbsp;Ma, X.&nbsp;Wu, P.&nbsp;Wang, Z.&nbsp;Lin, and S.&nbsp;Hu, “Pre-training with large language
model-based document expansion for dense passage retrieval,” <em id="bib.bib794.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2308.08285</em>, 2023.

</span>
</li>
<li id="bib.bib795" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[795]</span>
<span class="ltx_bibblock">
W.&nbsp;Sun, Z.&nbsp;Chen, X.&nbsp;Ma, L.&nbsp;Yan, S.&nbsp;Wang, P.&nbsp;Ren, Z.&nbsp;Chen, D.&nbsp;Yin, and Z.&nbsp;Ren,
“Instruction distillation makes large language models efficient zero-shot
rankers,” <em id="bib.bib795.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.01555</em>, 2023.

</span>
</li>
<li id="bib.bib796" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[796]</span>
<span class="ltx_bibblock">
X.&nbsp;Wang, W.&nbsp;Zhu, and W.&nbsp;Y. Wang, “Large language models are implicitly topic
models: Explaining and finding good demonstrations for in-context learning,”
<em id="bib.bib796.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2301.11916, 2023.

</span>
</li>
<li id="bib.bib797" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[797]</span>
<span class="ltx_bibblock">
C.&nbsp;Li, Z.&nbsp;Gan, Z.&nbsp;Yang, J.&nbsp;Yang, L.&nbsp;Li, L.&nbsp;Wang, and J.&nbsp;Gao, “Multimodal
foundation models: From specialists to general-purpose assistants,”
<em id="bib.bib797.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.10020, 2023.

</span>
</li>
<li id="bib.bib798" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[798]</span>
<span class="ltx_bibblock">
W.&nbsp;X. Zhao, S.&nbsp;Mu, Y.&nbsp;Hou, Z.&nbsp;Lin, Y.&nbsp;Chen, X.&nbsp;Pan, K.&nbsp;Li, Y.&nbsp;Lu, H.&nbsp;Wang,
C.&nbsp;Tian, Y.&nbsp;Min, Z.&nbsp;Feng, X.&nbsp;Fan, X.&nbsp;Chen, P.&nbsp;Wang, W.&nbsp;Ji, Y.&nbsp;Li, X.&nbsp;Wang,
and J.&nbsp;Wen, “Recbole: Towards a unified, comprehensive and efficient
framework for recommendation algorithms,” in <em id="bib.bib798.1.1" class="ltx_emph ltx_font_italic">CIKM</em>, G.&nbsp;Demartini,
G.&nbsp;Zuccon, J.&nbsp;S. Culpepper, Z.&nbsp;Huang, and H.&nbsp;Tong, Eds.&nbsp;&nbsp;&nbsp;ACM, 2021, pp. 4653–4664.

</span>
</li>
<li id="bib.bib799" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[799]</span>
<span class="ltx_bibblock">
K.&nbsp;Zhou, H.&nbsp;Wang, W.&nbsp;X. Zhao, Y.&nbsp;Zhu, S.&nbsp;Wang, F.&nbsp;Zhang, Z.&nbsp;Wang, and J.&nbsp;Wen,
“S3-rec: Self-supervised learning for sequential recommendation with mutual
information maximization,” in <em id="bib.bib799.1.1" class="ltx_emph ltx_font_italic">CIKM</em>, M.&nbsp;d’Aquin, S.&nbsp;Dietze,
C.&nbsp;Hauff, E.&nbsp;Curry, and P.&nbsp;Cudré-Mauroux, Eds.&nbsp;&nbsp;&nbsp;ACM, 2020, pp. 1893–1902.

</span>
</li>
<li id="bib.bib800" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[800]</span>
<span class="ltx_bibblock">
W.&nbsp;X. Zhao, Y.&nbsp;Hou, X.&nbsp;Pan, C.&nbsp;Yang, Z.&nbsp;Zhang, Z.&nbsp;Lin, J.&nbsp;Zhang, S.&nbsp;Bian,
J.&nbsp;Tang, W.&nbsp;Sun, Y.&nbsp;Chen, L.&nbsp;Xu, G.&nbsp;Zhang, Z.&nbsp;Tian, C.&nbsp;Tian, S.&nbsp;Mu, X.&nbsp;Fan,
X.&nbsp;Chen, and J.&nbsp;Wen, “Recbole 2.0: Towards a more up-to-date recommendation
library,” in <em id="bib.bib800.1.1" class="ltx_emph ltx_font_italic">CIKM</em>, M.&nbsp;A. Hasan and L.&nbsp;Xiong, Eds.&nbsp;&nbsp;&nbsp;ACM, 2022, pp. 4722–4726.

</span>
</li>
<li id="bib.bib801" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[801]</span>
<span class="ltx_bibblock">
L.&nbsp;Xu, Z.&nbsp;Tian, G.&nbsp;Zhang, J.&nbsp;Zhang, L.&nbsp;Wang, B.&nbsp;Zheng, Y.&nbsp;Li, J.&nbsp;Tang,
Z.&nbsp;Zhang, Y.&nbsp;Hou, X.&nbsp;Pan, W.&nbsp;X. Zhao, X.&nbsp;Chen, and J.&nbsp;Wen, “Towards a more
user-friendly and easy-to-use benchmark library for recommender systems,” in
<em id="bib.bib801.1.1" class="ltx_emph ltx_font_italic">SIGIR</em>, H.&nbsp;Chen, W.&nbsp;E. Duh, H.&nbsp;Huang, M.&nbsp;P. Kato, J.&nbsp;Mothe, and
B.&nbsp;Poblete, Eds.&nbsp;&nbsp;&nbsp;ACM, 2023, pp.
2837–2847.

</span>
</li>
<li id="bib.bib802" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[802]</span>
<span class="ltx_bibblock">
S.&nbsp;Rendle, C.&nbsp;Freudenthaler, Z.&nbsp;Gantner, and L.&nbsp;Schmidt-Thieme, “BPR:
bayesian personalized ranking from implicit feedback,” <em id="bib.bib802.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/1205.2618, 2012.

</span>
</li>
<li id="bib.bib803" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[803]</span>
<span class="ltx_bibblock">
W.&nbsp;Fan, Z.&nbsp;Zhao, J.&nbsp;Li, Y.&nbsp;Liu, X.&nbsp;Mei, Y.&nbsp;Wang, J.&nbsp;Tang, and Q.&nbsp;Li,
“Recommender systems in the era of large language models (llms),”
<em id="bib.bib803.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2023.

</span>
</li>
<li id="bib.bib804" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[804]</span>
<span class="ltx_bibblock">
L.&nbsp;Wu, Z.&nbsp;Zheng, Z.&nbsp;Qiu, H.&nbsp;Wang, H.&nbsp;Gu, T.&nbsp;Shen, C.&nbsp;Qin, C.&nbsp;Zhu, H.&nbsp;Zhu,
Q.&nbsp;Liu, H.&nbsp;Xiong, and E.&nbsp;Chen, “A survey on large language models for
recommendation,” <em id="bib.bib804.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2023.

</span>
</li>
<li id="bib.bib805" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[805]</span>
<span class="ltx_bibblock">
Y.&nbsp;Gao, T.&nbsp;Sheng, Y.&nbsp;Xiang, Y.&nbsp;Xiong, H.&nbsp;Wang, and J.&nbsp;Zhang, “Chat-rec:
Towards interactive and explainable llms-augmented recommender system,”
<em id="bib.bib805.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.14524, 2023.

</span>
</li>
<li id="bib.bib806" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[806]</span>
<span class="ltx_bibblock">
S.&nbsp;Dai, N.&nbsp;Shao, H.&nbsp;Zhao, W.&nbsp;Yu, Z.&nbsp;Si, C.&nbsp;Xu, Z.&nbsp;Sun, X.&nbsp;Zhang, and J.&nbsp;Xu,
“Uncovering chatgpt’s capabilities in recommender systems,” in
<em id="bib.bib806.1.1" class="ltx_emph ltx_font_italic">RecSys</em>, J.&nbsp;Zhang, L.&nbsp;Chen, S.&nbsp;Berkovsky, M.&nbsp;Zhang, T.&nbsp;D. Noia,
J.&nbsp;Basilico, L.&nbsp;Pizzato, and Y.&nbsp;Song, Eds.&nbsp;&nbsp;&nbsp;ACM, 2023, pp. 1126–1132.

</span>
</li>
<li id="bib.bib807" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[807]</span>
<span class="ltx_bibblock">
Y.&nbsp;Hou, J.&nbsp;Zhang, Z.&nbsp;Lin, H.&nbsp;Lu, R.&nbsp;Xie, J.&nbsp;J. McAuley, and W.&nbsp;X. Zhao, “Large
language models are zero-shot rankers for recommender systems,”
<em id="bib.bib807.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2023.

</span>
</li>
<li id="bib.bib808" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[808]</span>
<span class="ltx_bibblock">
J.&nbsp;Liu, C.&nbsp;Liu, R.&nbsp;Lv, K.&nbsp;Zhou, and Y.&nbsp;Zhang, “Is chatgpt a good recommender?
A preliminary study,” <em id="bib.bib808.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.10149, 2023.

</span>
</li>
<li id="bib.bib809" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[809]</span>
<span class="ltx_bibblock">
K.&nbsp;Bao, J.&nbsp;Zhang, Y.&nbsp;Zhang, W.&nbsp;Wang, F.&nbsp;Feng, and X.&nbsp;He, “Tallrec: An
effective and efficient tuning framework to align large language model with
recommendation,” in <em id="bib.bib809.1.1" class="ltx_emph ltx_font_italic">RecSys</em>, J.&nbsp;Zhang, L.&nbsp;Chen, S.&nbsp;Berkovsky,
M.&nbsp;Zhang, T.&nbsp;D. Noia, J.&nbsp;Basilico, L.&nbsp;Pizzato, and Y.&nbsp;Song, Eds.&nbsp;&nbsp;&nbsp;ACM, 2023, pp. 1007–1014.

</span>
</li>
<li id="bib.bib810" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[810]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhu, L.&nbsp;Wu, Q.&nbsp;Guo, L.&nbsp;Hong, and J.&nbsp;Li, “Collaborative large language model
for recommender systems,” <em id="bib.bib810.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.01343</em>, 2023.

</span>
</li>
<li id="bib.bib811" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[811]</span>
<span class="ltx_bibblock">
B.&nbsp;Zheng, Y.&nbsp;Hou, H.&nbsp;Lu, Y.&nbsp;Chen, W.&nbsp;X. Zhao, and J.-R. Wen, “Adapting large
language models by integrating collaborative semantics for recommendation,”
2023. [Online]. Available:
<a target="_blank" href="https://api.semanticscholar.org/CorpusID:265213194" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:265213194</a>

</span>
</li>
<li id="bib.bib812" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[812]</span>
<span class="ltx_bibblock">
Y.&nbsp;Xi, W.&nbsp;Liu, J.&nbsp;Lin, J.&nbsp;Zhu, B.&nbsp;Chen, R.&nbsp;Tang, W.&nbsp;Zhang, R.&nbsp;Zhang, and Y.&nbsp;Yu,
“Towards open-world recommendation with knowledge augmentation from large
language models,” <em id="bib.bib812.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.10933, 2023.

</span>
</li>
<li id="bib.bib813" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[813]</span>
<span class="ltx_bibblock">
Q.&nbsp;Liu, N.&nbsp;Chen, T.&nbsp;Sakai, and X.&nbsp;Wu, “A first look at llm-powered generative
news recommendation,” <em id="bib.bib813.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.06566, 2023.

</span>
</li>
<li id="bib.bib814" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[814]</span>
<span class="ltx_bibblock">
R.&nbsp;Li, W.&nbsp;Deng, Y.&nbsp;Cheng, Z.&nbsp;Yuan, J.&nbsp;Zhang, and F.&nbsp;Yuan, “Exploring the upper
limits of text-based collaborative filtering using large language models:
Discoveries and insights,” <em id="bib.bib814.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.11700, 2023.

</span>
</li>
<li id="bib.bib815" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[815]</span>
<span class="ltx_bibblock">
W.&nbsp;Wei, X.&nbsp;Ren, J.&nbsp;Tang, Q.&nbsp;Wang, L.&nbsp;Su, S.&nbsp;Cheng, J.&nbsp;Wang, D.&nbsp;Yin, and
C.&nbsp;Huang, “Llmrec: Large language models with graph augmentation for
recommendation,” <em id="bib.bib815.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2311.00423, 2023.

</span>
</li>
<li id="bib.bib816" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[816]</span>
<span class="ltx_bibblock">
X.&nbsp;Li, B.&nbsp;Chen, L.&nbsp;Hou, and R.&nbsp;Tang, “Ctrl: Connect tabular and language model
for ctr prediction,” <em id="bib.bib816.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.02841</em>, 2023.

</span>
</li>
<li id="bib.bib817" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[817]</span>
<span class="ltx_bibblock">
A.&nbsp;Muhamed, I.&nbsp;Keivanloo, S.&nbsp;Perera, J.&nbsp;Mracek, Y.&nbsp;Xu, Q.&nbsp;Cui, S.&nbsp;Rajagopalan,
B.&nbsp;Zeng, and T.&nbsp;Chilimbi, “Ctr-bert: Cost-effective knowledge distillation
for billion-parameter teacher models,” in <em id="bib.bib817.1.1" class="ltx_emph ltx_font_italic">NeurIPS Efficient Natural
Language and Speech Processing Workshop</em>, 2021.

</span>
</li>
<li id="bib.bib818" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[818]</span>
<span class="ltx_bibblock">
L.&nbsp;Wang, C.&nbsp;Ma, X.&nbsp;Feng, Z.&nbsp;Zhang, H.&nbsp;Yang, J.&nbsp;Zhang, Z.&nbsp;Chen, J.&nbsp;Tang,
X.&nbsp;Chen, Y.&nbsp;Lin, W.&nbsp;X. Zhao, Z.&nbsp;Wei, and J.&nbsp;Wen, “A survey on large language
model based autonomous agents,” <em id="bib.bib818.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.11432, 2023.

</span>
</li>
<li id="bib.bib819" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[819]</span>
<span class="ltx_bibblock">
L.&nbsp;Wang, J.&nbsp;Zhang, X.&nbsp;Chen, Y.&nbsp;Lin, R.&nbsp;Song, W.&nbsp;X. Zhao, and J.&nbsp;Wen,
“Recagent: A novel simulation paradigm for recommender systems,”
<em id="bib.bib819.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.02552, 2023.

</span>
</li>
<li id="bib.bib820" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[820]</span>
<span class="ltx_bibblock">
E.&nbsp;Ie, C.&nbsp;Hsu, M.&nbsp;Mladenov, V.&nbsp;Jain, S.&nbsp;Narvekar, J.&nbsp;Wang, R.&nbsp;Wu, and
C.&nbsp;Boutilier, “Recsim: A configurable simulation platform for recommender
systems,” <em id="bib.bib820.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1909.04847, 2019.

</span>
</li>
<li id="bib.bib821" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[821]</span>
<span class="ltx_bibblock">
J.&nbsp;Zhang, Y.&nbsp;Hou, R.&nbsp;Xie, W.&nbsp;Sun, J.&nbsp;J. McAuley, W.&nbsp;X. Zhao, L.&nbsp;Lin, and
J.&nbsp;Wen, “Agentcf: Collaborative learning with autonomous language agents for
recommender systems,” <em id="bib.bib821.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.09233, 2023.

</span>
</li>
<li id="bib.bib822" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[822]</span>
<span class="ltx_bibblock">
A.&nbsp;Zhang, L.&nbsp;Sheng, Y.&nbsp;Chen, H.&nbsp;Li, Y.&nbsp;Deng, X.&nbsp;Wang, and T.&nbsp;Chua, “On
generative agents in recommendation,” <em id="bib.bib822.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.10108,
2023.

</span>
</li>
<li id="bib.bib823" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[823]</span>
<span class="ltx_bibblock">
Y.&nbsp;Du, Z.&nbsp;Liu, J.&nbsp;Li, and W.&nbsp;X. Zhao, “A survey of vision-language pre-trained
models,” in <em id="bib.bib823.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirty-First International Joint
Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29
July 2022</em>, L.&nbsp;D. Raedt, Ed.&nbsp;&nbsp;&nbsp;ijcai.org, 2022, pp. 5436–5443.

</span>
</li>
<li id="bib.bib824" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[824]</span>
<span class="ltx_bibblock">
Z.&nbsp;Gan, L.&nbsp;Li, C.&nbsp;Li, L.&nbsp;Wang, Z.&nbsp;Liu, and J.&nbsp;Gao, “Vision-language
pre-training: Basics, recent advances, and future trends,” <em id="bib.bib824.1.1" class="ltx_emph ltx_font_italic">Found.
Trends Comput. Graph. Vis.</em>, vol.&nbsp;14, no. 3-4, pp. 163–352, 2022.

</span>
</li>
<li id="bib.bib825" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[825]</span>
<span class="ltx_bibblock">
P.&nbsp;K. Rubenstein, C.&nbsp;Asawaroengchai, D.&nbsp;D. Nguyen, A.&nbsp;Bapna, Z.&nbsp;Borsos,
F.&nbsp;de&nbsp;Chaumont&nbsp;Quitry, P.&nbsp;Chen, D.&nbsp;E. Badawy, W.&nbsp;Han, E.&nbsp;Kharitonov
<em id="bib.bib825.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Audiopalm: A large language model that can speak and
listen,” <em id="bib.bib825.2.2" class="ltx_emph ltx_font_italic">CoRR</em>, 2023.

</span>
</li>
<li id="bib.bib826" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[826]</span>
<span class="ltx_bibblock">
J.&nbsp;Alayrac, J.&nbsp;Donahue, P.&nbsp;Luc, A.&nbsp;Miech, I.&nbsp;Barr, Y.&nbsp;Hasson, K.&nbsp;Lenc,
A.&nbsp;Mensch, K.&nbsp;Millican, M.&nbsp;Reynolds, R.&nbsp;Ring, E.&nbsp;Rutherford, S.&nbsp;Cabi, T.&nbsp;Han,
Z.&nbsp;Gong, S.&nbsp;Samangooei, M.&nbsp;Monteiro, J.&nbsp;L. Menick, S.&nbsp;Borgeaud, A.&nbsp;Brock,
A.&nbsp;Nematzadeh, S.&nbsp;Sharifzadeh, M.&nbsp;Binkowski, R.&nbsp;Barreira, O.&nbsp;Vinyals,
A.&nbsp;Zisserman, and K.&nbsp;Simonyan, “Flamingo: a visual language model for
few-shot learning,” in <em id="bib.bib826.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib827" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[827]</span>
<span class="ltx_bibblock">
C.&nbsp;Schuhmann, R.&nbsp;Beaumont, R.&nbsp;Vencu, C.&nbsp;Gordon, R.&nbsp;Wightman, M.&nbsp;Cherti,
T.&nbsp;Coombes, A.&nbsp;Katta, C.&nbsp;Mullis, M.&nbsp;Wortsman, P.&nbsp;Schramowski, S.&nbsp;Kundurthy,
K.&nbsp;Crowson, L.&nbsp;Schmidt, R.&nbsp;Kaczmarczyk, and J.&nbsp;Jitsev, “LAION-5B: an open
large-scale dataset for training next generation image-text models,” in
<em id="bib.bib827.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib828" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[828]</span>
<span class="ltx_bibblock">
S.&nbsp;Changpinyo, P.&nbsp;Sharma, N.&nbsp;Ding, and R.&nbsp;Soricut, “Conceptual 12m: Pushing
web-scale image-text pre-training to recognize long-tail visual concepts,”
in <em id="bib.bib828.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition, CVPR
2021, virtual, June 19-25, 2021</em>.&nbsp;&nbsp;&nbsp;Computer Vision Foundation / IEEE, 2021, pp. 3558–3568.

</span>
</li>
<li id="bib.bib829" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[829]</span>
<span class="ltx_bibblock">
Q.&nbsp;Ye, H.&nbsp;Xu, G.&nbsp;Xu, J.&nbsp;Ye, M.&nbsp;Yan, Y.&nbsp;Zhou, J.&nbsp;Wang, A.&nbsp;Hu, P.&nbsp;Shi, Y.&nbsp;Shi,
C.&nbsp;Li, Y.&nbsp;Xu, H.&nbsp;Chen, J.&nbsp;Tian, Q.&nbsp;Qi, J.&nbsp;Zhang, and F.&nbsp;Huang, “mplug-owl:
Modularization empowers large language models with multimodality,”
<em id="bib.bib829.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.14178, 2023.

</span>
</li>
<li id="bib.bib830" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[830]</span>
<span class="ltx_bibblock">
J.&nbsp;Bai, S.&nbsp;Bai, S.&nbsp;Yang, S.&nbsp;Wang, S.&nbsp;Tan, P.&nbsp;Wang, J.&nbsp;Lin, C.&nbsp;Zhou, and
J.&nbsp;Zhou, “Qwen-vl: A frontier large vision-language model with versatile
abilities,” <em id="bib.bib830.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.12966, 2023.

</span>
</li>
<li id="bib.bib831" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[831]</span>
<span class="ltx_bibblock">
H.&nbsp;Liu, C.&nbsp;Li, Y.&nbsp;Li, and Y.&nbsp;J. Lee, “Improved baselines with visual
instruction tuning,” <em id="bib.bib831.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.03744, 2023.

</span>
</li>
<li id="bib.bib832" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[832]</span>
<span class="ltx_bibblock">
P.&nbsp;Zhang, X.&nbsp;Dong, B.&nbsp;Wang, Y.&nbsp;Cao, C.&nbsp;Xu, L.&nbsp;Ouyang, Z.&nbsp;Zhao, S.&nbsp;Ding,
S.&nbsp;Zhang, H.&nbsp;Duan, W.&nbsp;Zhang, H.&nbsp;Yan, X.&nbsp;Zhang, W.&nbsp;Li, J.&nbsp;Li, K.&nbsp;Chen, C.&nbsp;He,
X.&nbsp;Zhang, Y.&nbsp;Qiao, D.&nbsp;Lin, and J.&nbsp;Wang, “Internlm-xcomposer: A
vision-language large model for advanced text-image comprehension and
composition,” <em id="bib.bib832.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.15112, 2023.

</span>
</li>
<li id="bib.bib833" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[833]</span>
<span class="ltx_bibblock">
K.&nbsp;Chen, Z.&nbsp;Zhang, W.&nbsp;Zeng, R.&nbsp;Zhang, F.&nbsp;Zhu, and R.&nbsp;Zhao, “Shikra: Unleashing
multimodal llm’s referential dialogue magic,” <em id="bib.bib833.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.15195, 2023.

</span>
</li>
<li id="bib.bib834" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[834]</span>
<span class="ltx_bibblock">
F.&nbsp;Liu, K.&nbsp;Lin, L.&nbsp;Li, J.&nbsp;Wang, Y.&nbsp;Yacoob, and L.&nbsp;Wang, “Aligning large
multi-modal model with robust instruction tuning,” <em id="bib.bib834.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.14565, 2023.

</span>
</li>
<li id="bib.bib835" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[835]</span>
<span class="ltx_bibblock">
Y.&nbsp;Du, H.&nbsp;Guo, K.&nbsp;Zhou, W.&nbsp;X. Zhao, J.&nbsp;Wang, C.&nbsp;Wang, M.&nbsp;Cai, R.&nbsp;Song, and
J.-R. Wen, “What makes for good visual instructions? synthesizing complex
visual reasoning instructions for visual instruction tuning,” 2023.

</span>
</li>
<li id="bib.bib836" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[836]</span>
<span class="ltx_bibblock">
D.&nbsp;Gurari, Q.&nbsp;Li, A.&nbsp;J. Stangl, A.&nbsp;Guo, C.&nbsp;Lin, K.&nbsp;Grauman, J.&nbsp;Luo, and J.&nbsp;P.
Bigham, “Vizwiz grand challenge: Answering visual questions from blind
people,” in <em id="bib.bib836.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.&nbsp;&nbsp;&nbsp;Computer
Vision Foundation / IEEE Computer Society, 2018, pp. 3608–3617.

</span>
</li>
<li id="bib.bib837" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[837]</span>
<span class="ltx_bibblock">
A.&nbsp;Mishra, K.&nbsp;Alahari, and C.&nbsp;V. Jawahar, “Top-down and bottom-up cues for
scene text recognition,” in <em id="bib.bib837.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.&nbsp;&nbsp;&nbsp;IEEE Computer Society, 2012, pp. 2687–2694.

</span>
</li>
<li id="bib.bib838" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[838]</span>
<span class="ltx_bibblock">
Y.&nbsp;Liu, H.&nbsp;Duan, Y.&nbsp;Zhang, B.&nbsp;Li, S.&nbsp;Zhang, W.&nbsp;Zhao, Y.&nbsp;Yuan, J.&nbsp;Wang, C.&nbsp;He,
Z.&nbsp;Liu, K.&nbsp;Chen, and D.&nbsp;Lin, “Mmbench: Is your multi-modal model an
all-around player?” <em id="bib.bib838.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.06281, 2023.

</span>
</li>
<li id="bib.bib839" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[839]</span>
<span class="ltx_bibblock">
C.&nbsp;Fu, P.&nbsp;Chen, Y.&nbsp;Shen, Y.&nbsp;Qin, M.&nbsp;Zhang, X.&nbsp;Lin, Z.&nbsp;Qiu, W.&nbsp;Lin, J.&nbsp;Yang,
X.&nbsp;Zheng, K.&nbsp;Li, X.&nbsp;Sun, and R.&nbsp;Ji, “MME: A comprehensive evaluation
benchmark for multimodal large language models,” <em id="bib.bib839.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2306.13394, 2023.

</span>
</li>
<li id="bib.bib840" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[840]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhang, Y.&nbsp;Li, L.&nbsp;Cui, D.&nbsp;Cai, L.&nbsp;Liu, T.&nbsp;Fu, X.&nbsp;Huang, E.&nbsp;Zhao, Y.&nbsp;Zhang,
Y.&nbsp;Chen, L.&nbsp;Wang, A.&nbsp;T. Luu, W.&nbsp;Bi, F.&nbsp;Shi, and S.&nbsp;Shi, “Siren’s song in the
AI ocean: A survey on hallucination in large language models,”
<em id="bib.bib840.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.01219, 2023.

</span>
</li>
<li id="bib.bib841" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[841]</span>
<span class="ltx_bibblock">
A.&nbsp;Gunjal, J.&nbsp;Yin, and E.&nbsp;Bas, “Detecting and preventing hallucinations in
large vision language models,” <em id="bib.bib841.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.06394, 2023.

</span>
</li>
<li id="bib.bib842" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[842]</span>
<span class="ltx_bibblock">
J.&nbsp;Lu, J.&nbsp;Rao, K.&nbsp;Chen, X.&nbsp;Guo, Y.&nbsp;Zhang, B.&nbsp;Sun, C.&nbsp;Yang, and J.&nbsp;Yang,
“Evaluation and mitigation of agnosia in multimodal large language models,”
<em id="bib.bib842.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.04041, 2023.

</span>
</li>
<li id="bib.bib843" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[843]</span>
<span class="ltx_bibblock">
A.&nbsp;Rohrbach, L.&nbsp;A. Hendricks, K.&nbsp;Burns, T.&nbsp;Darrell, and K.&nbsp;Saenko, “Object
hallucination in image captioning,” in <em id="bib.bib843.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2018, pp.
4035–4045.

</span>
</li>
<li id="bib.bib844" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[844]</span>
<span class="ltx_bibblock">
Y.&nbsp;Li, Y.&nbsp;Du, K.&nbsp;Zhou, J.&nbsp;Wang, W.&nbsp;X. Zhao, and J.-R. Wen, “Evaluating object
hallucination in large vision-language models,” in <em id="bib.bib844.1.1" class="ltx_emph ltx_font_italic">The 2023 Conference
on Empirical Methods in Natural Language Processing</em>, 2023. [Online].
Available: <a target="_blank" href="https://openreview.net/forum?id=xozJw0kZXF" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=xozJw0kZXF</a>

</span>
</li>
<li id="bib.bib845" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[845]</span>
<span class="ltx_bibblock">
D.&nbsp;A. Hudson and C.&nbsp;D. Manning, “GQA: A new dataset for real-world visual
reasoning and compositional question answering,” in <em id="bib.bib845.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.&nbsp;&nbsp;&nbsp;Computer Vision Foundation / IEEE, 2019, pp.
6700–6709.

</span>
</li>
<li id="bib.bib846" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[846]</span>
<span class="ltx_bibblock">
P.&nbsp;Lu, S.&nbsp;Mishra, T.&nbsp;Xia, L.&nbsp;Qiu, K.&nbsp;Chang, S.&nbsp;Zhu, O.&nbsp;Tafjord, P.&nbsp;Clark, and
A.&nbsp;Kalyan, “Learn to explain: Multimodal reasoning via thought chains for
science question answering,” in <em id="bib.bib846.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib847" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[847]</span>
<span class="ltx_bibblock">
A.&nbsp;Singh, V.&nbsp;Natarjan, M.&nbsp;Shah, Y.&nbsp;Jiang, X.&nbsp;Chen, D.&nbsp;Parikh, and M.&nbsp;Rohrbach,
“Towards vqa models that can read,” in <em id="bib.bib847.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition</em>, 2019, pp. 8317–8326.

</span>
</li>
<li id="bib.bib848" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[848]</span>
<span class="ltx_bibblock">
F.&nbsp;Liu, T.&nbsp;Guan, Z.&nbsp;Li, L.&nbsp;Chen, Y.&nbsp;Yacoob, D.&nbsp;Manocha, and T.&nbsp;Zhou,
“Hallusionbench: You see what you think? or you think what you see? an
image-context reasoning benchmark challenging for gpt-4v(ision), llava-1.5,
and other multi-modality models,” <em id="bib.bib848.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.14566, 2023.

</span>
</li>
<li id="bib.bib849" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[849]</span>
<span class="ltx_bibblock">
S.&nbsp;Antol, A.&nbsp;Agrawal, J.&nbsp;Lu, M.&nbsp;Mitchell, D.&nbsp;Batra, C.&nbsp;L. Zitnick, and
D.&nbsp;Parikh, “VQA: visual question answering,” in <em id="bib.bib849.1.1" class="ltx_emph ltx_font_italic">ICCV</em>.&nbsp;&nbsp;&nbsp;IEEE Computer Society, 2015, pp. 2425–2433.

</span>
</li>
<li id="bib.bib850" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[850]</span>
<span class="ltx_bibblock">
R.&nbsp;Vedantam, C.&nbsp;L. Zitnick, and D.&nbsp;Parikh, “Cider: Consensus-based image
description evaluation,” in <em id="bib.bib850.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.&nbsp;&nbsp;&nbsp;IEEE Computer Society, 2015, pp. 4566–4575.

</span>
</li>
<li id="bib.bib851" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[851]</span>
<span class="ltx_bibblock">
H.&nbsp;Liu, C.&nbsp;Li, Q.&nbsp;Wu, and Y.&nbsp;J. Lee, “Visual instruction tuning,”
<em id="bib.bib851.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.08485, 2023.

</span>
</li>
<li id="bib.bib852" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[852]</span>
<span class="ltx_bibblock">
P.&nbsp;Xu, W.&nbsp;Shao, K.&nbsp;Zhang, P.&nbsp;Gao, S.&nbsp;Liu, M.&nbsp;Lei, F.&nbsp;Meng, S.&nbsp;Huang, Y.&nbsp;Qiao,
and P.&nbsp;Luo, “Lvlm-ehub: A comprehensive evaluation benchmark for large
vision-language models,” <em id="bib.bib852.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.09265, 2023.

</span>
</li>
<li id="bib.bib853" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[853]</span>
<span class="ltx_bibblock">
Z.&nbsp;Li, Y.&nbsp;Wang, M.&nbsp;Du, Q.&nbsp;Liu, B.&nbsp;Wu, J.&nbsp;Zhang, C.&nbsp;Zhou, Z.&nbsp;Fan, J.&nbsp;Fu,
J.&nbsp;Chen, X.&nbsp;Huang, and Z.&nbsp;Wei, “Reform-eval: Evaluating large vision
language models via unified re-formulation of task-oriented benchmarks,”
<em id="bib.bib853.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.02569, 2023.

</span>
</li>
<li id="bib.bib854" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[854]</span>
<span class="ltx_bibblock">
B.&nbsp;Li, R.&nbsp;Wang, G.&nbsp;Wang, Y.&nbsp;Ge, Y.&nbsp;Ge, and Y.&nbsp;Shan, “Seed-bench: Benchmarking
multimodal llms with generative comprehension,” <em id="bib.bib854.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2307.16125, 2023.

</span>
</li>
<li id="bib.bib855" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[855]</span>
<span class="ltx_bibblock">
W.&nbsp;Yu, Z.&nbsp;Yang, L.&nbsp;Li, J.&nbsp;Wang, K.&nbsp;Lin, Z.&nbsp;Liu, X.&nbsp;Wang, and L.&nbsp;Wang, “Mm-vet:
Evaluating large multimodal models for integrated capabilities,”
<em id="bib.bib855.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.02490, 2023.

</span>
</li>
<li id="bib.bib856" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[856]</span>
<span class="ltx_bibblock">
J.&nbsp;Wang, L.&nbsp;Meng, Z.&nbsp;Weng, B.&nbsp;He, Z.&nbsp;Wu, and Y.&nbsp;Jiang, “To see is to believe:
Prompting GPT-4V for better visual instruction tuning,” <em id="bib.bib856.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2311.07574, 2023.

</span>
</li>
<li id="bib.bib857" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[857]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhang, R.&nbsp;Zhang, J.&nbsp;Gu, Y.&nbsp;Zhou, N.&nbsp;Lipka, D.&nbsp;Yang, and T.&nbsp;Sun, “Llavar:
Enhanced visual instruction tuning for text-rich image understanding,”
<em id="bib.bib857.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.17107</em>, 2023.

</span>
</li>
<li id="bib.bib858" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[858]</span>
<span class="ltx_bibblock">
X.&nbsp;Qi, K.&nbsp;Huang, A.&nbsp;Panda, M.&nbsp;Wang, and P.&nbsp;Mittal, “Visual adversarial
examples jailbreak aligned large language models,” in <em id="bib.bib858.1.1" class="ltx_emph ltx_font_italic">The Second
Workshop on New Frontiers in Adversarial Machine Learning</em>, 2023.

</span>
</li>
<li id="bib.bib859" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[859]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhou, C.&nbsp;Cui, J.&nbsp;Yoon, L.&nbsp;Zhang, Z.&nbsp;Deng, C.&nbsp;Finn, M.&nbsp;Bansal, and H.&nbsp;Yao,
“Analyzing and mitigating object hallucination in large vision-language
models,” <em id="bib.bib859.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.00754</em>, 2023.

</span>
</li>
<li id="bib.bib860" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[860]</span>
<span class="ltx_bibblock">
Z.&nbsp;Sun, S.&nbsp;Shen, S.&nbsp;Cao, H.&nbsp;Liu, C.&nbsp;Li, Y.&nbsp;Shen, C.&nbsp;Gan, L.-Y. Gui, Y.-X. Wang,
Y.&nbsp;Yang <em id="bib.bib860.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Aligning large multimodal models with factually
augmented rlhf,” <em id="bib.bib860.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.14525</em>, 2023.

</span>
</li>
<li id="bib.bib861" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[861]</span>
<span class="ltx_bibblock">
S.&nbsp;Pan, L.&nbsp;Luo, Y.&nbsp;Wang, C.&nbsp;Chen, J.&nbsp;Wang, and X.&nbsp;Wu, “Unifying large language
models and knowledge graphs: A roadmap,” <em id="bib.bib861.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.08302,
2023.

</span>
</li>
<li id="bib.bib862" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[862]</span>
<span class="ltx_bibblock">
E.&nbsp;Jiménez-Ruiz, O.&nbsp;Hassanzadeh, V.&nbsp;Efthymiou, J.&nbsp;Chen, and
K.&nbsp;Srinivas, “Semtab 2019: Resources to benchmark tabular data to knowledge
graph matching systems,” in <em id="bib.bib862.1.1" class="ltx_emph ltx_font_italic">The Semantic Web - 17th International
Conference, ESWC 2020, Heraklion, Crete, Greece, May 31-June 4, 2020,
Proceedings</em>, ser. Lecture Notes in Computer Science, vol. 12123.&nbsp;&nbsp;&nbsp;Springer, 2020, pp. 514–530.

</span>
</li>
<li id="bib.bib863" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[863]</span>
<span class="ltx_bibblock">
Y.&nbsp;Sun, S.&nbsp;Wang, S.&nbsp;Feng, S.&nbsp;Ding, C.&nbsp;Pang, J.&nbsp;Shang, J.&nbsp;Liu, X.&nbsp;Chen, Y.&nbsp;Zhao,
Y.&nbsp;Lu, W.&nbsp;Liu, Z.&nbsp;Wu, W.&nbsp;Gong, J.&nbsp;Liang, Z.&nbsp;Shang, P.&nbsp;Sun, W.&nbsp;Liu, X.&nbsp;Ouyang,
D.&nbsp;Yu, H.&nbsp;Tian, H.&nbsp;Wu, and H.&nbsp;Wang, “ERNIE 3.0: Large-scale knowledge
enhanced pre-training for language understanding and generation,”
<em id="bib.bib863.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2107.02137, 2021. [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/2107.02137" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2107.02137</a>

</span>
</li>
<li id="bib.bib864" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[864]</span>
<span class="ltx_bibblock">
Z.&nbsp;Zhang, X.&nbsp;Han, Z.&nbsp;Liu, X.&nbsp;Jiang, M.&nbsp;Sun, and Q.&nbsp;Liu, “ERNIE: enhanced
language representation with informative entities,” in <em id="bib.bib864.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the 57th Conference of the Association for Computational Linguistics, ACL
2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics,
2019, pp. 1441–1451.

</span>
</li>
<li id="bib.bib865" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[865]</span>
<span class="ltx_bibblock">
X.&nbsp;Wang, T.&nbsp;Gao, Z.&nbsp;Zhu, Z.&nbsp;Zhang, Z.&nbsp;Liu, J.&nbsp;Li, and J.&nbsp;Tang, “KEPLER: A
unified model for knowledge embedding and pre-trained language
representation,” <em id="bib.bib865.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, vol.&nbsp;9, pp.
176–194, 2021.

</span>
</li>
<li id="bib.bib866" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[866]</span>
<span class="ltx_bibblock">
J.&nbsp;Zhang, X.&nbsp;Zhang, J.&nbsp;Yu, J.&nbsp;Tang, J.&nbsp;Tang, C.&nbsp;Li, and H.&nbsp;Chen, “Subgraph
retrieval enhanced model for multi-hop knowledge base question answering,”
in <em id="bib.bib866.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin,
Ireland, May 22-27, 2022</em>.&nbsp;&nbsp;&nbsp;Association
for Computational Linguistics, 2022, pp. 5773–5784.

</span>
</li>
<li id="bib.bib867" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[867]</span>
<span class="ltx_bibblock">
P.&nbsp;Ke, H.&nbsp;Ji, Y.&nbsp;Ran, X.&nbsp;Cui, L.&nbsp;Wang, L.&nbsp;Song, X.&nbsp;Zhu, and M.&nbsp;Huang,
“Jointgt: Graph-text joint representation learning for text generation from
knowledge graphs,” in <em id="bib.bib867.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational
Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021</em>, ser.
Findings of ACL, vol. ACL/IJCNLP 2021.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp. 2526–2538.

</span>
</li>
<li id="bib.bib868" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[868]</span>
<span class="ltx_bibblock">
O.&nbsp;Agarwal, H.&nbsp;Ge, S.&nbsp;Shakeri, and R.&nbsp;Al-Rfou, “Large scale knowledge graph
based synthetic corpus generation for knowledge-enhanced language model
pre-training,” <em id="bib.bib868.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2010.12688, 2020.

</span>
</li>
<li id="bib.bib869" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[869]</span>
<span class="ltx_bibblock">
W.&nbsp;Chen, Y.&nbsp;Su, X.&nbsp;Yan, and W.&nbsp;Y. Wang, “KGPT: knowledge-grounded
pre-training for data-to-text generation,” in <em id="bib.bib869.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing, EMNLP 2020,
Online, November 16-20, 2020</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2020, pp. 8635–8648.

</span>
</li>
<li id="bib.bib870" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[870]</span>
<span class="ltx_bibblock">
Y.&nbsp;Gu, X.&nbsp;Deng, and Y.&nbsp;Su, “Don’t generate, discriminate: A proposal for
grounding language models to real-world environments,” in <em id="bib.bib870.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 61st Annual Meeting of the Association for Computational Linguistics
(Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics,
2023, pp. 4928–4949.

</span>
</li>
<li id="bib.bib871" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[871]</span>
<span class="ltx_bibblock">
L.&nbsp;Luo, Y.&nbsp;Li, G.&nbsp;Haffari, and S.&nbsp;Pan, “Reasoning on graphs: Faithful and
interpretable large language model reasoning,” <em id="bib.bib871.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2310.01061, 2023.

</span>
</li>
<li id="bib.bib872" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[872]</span>
<span class="ltx_bibblock">
Y.&nbsp;Lan and J.&nbsp;Jiang, “Query graph generation for answering multi-hop complex
questions from knowledge bases,” in <em id="bib.bib872.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics, ACL 2020, Online,
July 5-10, 2020</em>, D.&nbsp;J. and, Ed.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2020, pp. 969–974.

</span>
</li>
<li id="bib.bib873" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[873]</span>
<span class="ltx_bibblock">
P.&nbsp;Wang, N.&nbsp;Zhang, X.&nbsp;Xie, Y.&nbsp;Yao, B.&nbsp;Tian, M.&nbsp;Wang, Z.&nbsp;Xi, S.&nbsp;Cheng, K.&nbsp;Liu,
G.&nbsp;Zheng, and H.&nbsp;Chen, “Easyedit: An easy-to-use knowledge editing framework
for large language models,” <em id="bib.bib873.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.07269, 2023.

</span>
</li>
<li id="bib.bib874" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[874]</span>
<span class="ltx_bibblock">
Y.&nbsp;Yao, P.&nbsp;Wang, B.&nbsp;Tian, S.&nbsp;Cheng, Z.&nbsp;Li, S.&nbsp;Deng, H.&nbsp;Chen, and N.&nbsp;Zhang,
“Editing large language models: Problems, methods, and opportunities,”
<em id="bib.bib874.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.13172, 2023.

</span>
</li>
<li id="bib.bib875" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[875]</span>
<span class="ltx_bibblock">
S.&nbsp;Choi, T.&nbsp;Fang, Z.&nbsp;Wang, and Y.&nbsp;Song, “KCTS: knowledge-constrained tree
search decoding with token-level hallucination detection,” <em id="bib.bib875.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2310.09044, 2023.

</span>
</li>
<li id="bib.bib876" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[876]</span>
<span class="ltx_bibblock">
S.&nbsp;Zhang, L.&nbsp;Pan, J.&nbsp;Zhao, and W.&nbsp;Y. Wang, “Mitigating language model
hallucination with interactive question-knowledge alignment,” <em id="bib.bib876.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2305.13669, 2023.

</span>
</li>
<li id="bib.bib877" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[877]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhu, X.&nbsp;Wang, J.&nbsp;Chen, S.&nbsp;Qiao, Y.&nbsp;Ou, Y.&nbsp;Yao, S.&nbsp;Deng, H.&nbsp;Chen, and
N.&nbsp;Zhang, “Llms for knowledge graph construction and reasoning: Recent
capabilities and future opportunities,” <em id="bib.bib877.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.13168,
2023. [Online]. Available: <a target="_blank" href="https://doi.org/10.48550/arXiv.2305.13168" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.13168</a>

</span>
</li>
<li id="bib.bib878" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[878]</span>
<span class="ltx_bibblock">
S.&nbsp;Russell and P.&nbsp;Norvig, <em id="bib.bib878.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence: A Modern Approach
(4th Edition)</em>.&nbsp;&nbsp;&nbsp;Pearson, 2020.
[Online]. Available: <a target="_blank" href="http://aima.cs.berkeley.edu/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://aima.cs.berkeley.edu/</a>

</span>
</li>
<li id="bib.bib879" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[879]</span>
<span class="ltx_bibblock">
B.&nbsp;M. Lake, T.&nbsp;D. Ullman, J.&nbsp;B. Tenenbaum, and S.&nbsp;J. Gershman, “Building
machines that learn and think like people,” <em id="bib.bib879.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/1604.00289, 2016.

</span>
</li>
<li id="bib.bib880" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[880]</span>
<span class="ltx_bibblock">
S.&nbsp;Yao, J.&nbsp;Zhao, D.&nbsp;Yu, N.&nbsp;Du, I.&nbsp;Shafran, K.&nbsp;Narasimhan, and Y.&nbsp;Cao, “React:
Synergizing reasoning and acting in language models,” <em id="bib.bib880.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2210.03629, 2022.

</span>
</li>
<li id="bib.bib881" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[881]</span>
<span class="ltx_bibblock">
2023. [Online]. Available: <a target="_blank" href="https://github.com/AntonOsika/gpt-engineer" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/AntonOsika/gpt-engineer</a>

</span>
</li>
<li id="bib.bib882" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[882]</span>
<span class="ltx_bibblock">
X.&nbsp;Team, “Xagent: An autonomous agent for complex task solving,” 2023.

</span>
</li>
<li id="bib.bib883" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[883]</span>
<span class="ltx_bibblock">
G.&nbsp;Li, H.&nbsp;A. A.&nbsp;K. Hammoud, H.&nbsp;Itani, D.&nbsp;Khizbullin, and B.&nbsp;Ghanem, “CAMEL:
communicative agents for ”mind” exploration of large scale language model
society,” <em id="bib.bib883.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.17760, 2023.

</span>
</li>
<li id="bib.bib884" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[884]</span>
<span class="ltx_bibblock">
S.&nbsp;Hong, X.&nbsp;Zheng, J.&nbsp;Chen, Y.&nbsp;Cheng, J.&nbsp;Wang, C.&nbsp;Zhang, Z.&nbsp;Wang, S.&nbsp;K.&nbsp;S. Yau,
Z.&nbsp;Lin, L.&nbsp;Zhou, C.&nbsp;Ran, L.&nbsp;Xiao, and C.&nbsp;Wu, “Metagpt: Meta programming for
multi-agent collaborative framework,” <em id="bib.bib884.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.00352,
2023.

</span>
</li>
<li id="bib.bib885" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[885]</span>
<span class="ltx_bibblock">
C.&nbsp;Pham, B.&nbsp;Liu, Y.&nbsp;Yang, Z.&nbsp;Chen, T.&nbsp;Liu, J.&nbsp;Yuan, B.&nbsp;A. Plummer, Z.&nbsp;Wang, and
H.&nbsp;Yang, “Let models speak ciphers: Multiagent debate through embeddings,”
<em id="bib.bib885.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.06272, 2023.

</span>
</li>
<li id="bib.bib886" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[886]</span>
<span class="ltx_bibblock">
Y.&nbsp;Du, S.&nbsp;Li, A.&nbsp;Torralba, J.&nbsp;B. Tenenbaum, and I.&nbsp;Mordatch, “Improving
factuality and reasoning in language models through multiagent debate,”
<em id="bib.bib886.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.14325, 2023.

</span>
</li>
<li id="bib.bib887" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[887]</span>
<span class="ltx_bibblock">
M.&nbsp;Karpinska, N.&nbsp;Akoury, and M.&nbsp;Iyyer, “The perils of using mechanical turk to
evaluate open-ended text generation,” in <em id="bib.bib887.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021
Conference on Empirical Methods in Natural Language Processing, EMNLP 2021,
Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021</em>,
M.&nbsp;Moens, X.&nbsp;Huang, L.&nbsp;Specia, and S.&nbsp;W. Yih, Eds.&nbsp;&nbsp;&nbsp;Association for Computational Linguistics, 2021, pp. 1265–1285.

</span>
</li>
<li id="bib.bib888" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[888]</span>
<span class="ltx_bibblock">
H.&nbsp;Lee, S.&nbsp;Phatale, H.&nbsp;Mansoor, K.&nbsp;Lu, T.&nbsp;Mesnard, C.&nbsp;Bishop, V.&nbsp;Carbune, and
A.&nbsp;Rastogi, “RLAIF: scaling reinforcement learning from human feedback
with AI feedback,” <em id="bib.bib888.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.00267, 2023.

</span>
</li>
<li id="bib.bib889" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[889]</span>
<span class="ltx_bibblock">
T.&nbsp;Wang, P.&nbsp;Yu, X.&nbsp;E. Tan, S.&nbsp;O’Brien, R.&nbsp;Pasunuru, J.&nbsp;Dwivedi-Yu,
O.&nbsp;Golovneva, L.&nbsp;Zettlemoyer, M.&nbsp;Fazel-Zarandi, and A.&nbsp;Celikyilmaz,
“Shepherd: A critic for language model generation,” <em id="bib.bib889.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2308.04592, 2023.

</span>
</li>
<li id="bib.bib890" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[890]</span>
<span class="ltx_bibblock">
G.&nbsp;Cui, L.&nbsp;Yuan, N.&nbsp;Ding, G.&nbsp;Yao, W.&nbsp;Zhu, Y.&nbsp;Ni, G.&nbsp;Xie, Z.&nbsp;Liu, and M.&nbsp;Sun,
“Ultrafeedback: Boosting language models with high-quality feedback,”
<em id="bib.bib890.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.01377, 2023.

</span>
</li>
<li id="bib.bib891" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[891]</span>
<span class="ltx_bibblock">
X.&nbsp;Wang, Z.&nbsp;Wang, J.&nbsp;Liu, Y.&nbsp;Chen, L.&nbsp;Yuan, H.&nbsp;Peng, and H.&nbsp;Ji, “MINT:
evaluating llms in multi-turn interaction with tools and language feedback,”
<em id="bib.bib891.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2309.10691, 2023.

</span>
</li>
<li id="bib.bib892" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[892]</span>
<span class="ltx_bibblock">
S.&nbsp;Saha, O.&nbsp;Levy, A.&nbsp;Celikyilmaz, M.&nbsp;Bansal, J.&nbsp;Weston, and X.&nbsp;Li,
“Branch-solve-merge improves large language model evaluation and
generation,” <em id="bib.bib892.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.15123, 2023.

</span>
</li>
<li id="bib.bib893" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[893]</span>
<span class="ltx_bibblock">
X.&nbsp;Zhang, B.&nbsp;Yu, H.&nbsp;Yu, Y.&nbsp;Lv, T.&nbsp;Liu, F.&nbsp;Huang, H.&nbsp;Xu, and Y.&nbsp;Li, “Wider and
deeper LLM networks are fairer LLM evaluators,” <em id="bib.bib893.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2308.01862, 2023.

</span>
</li>
<li id="bib.bib894" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[894]</span>
<span class="ltx_bibblock">
C.&nbsp;Chan, W.&nbsp;Chen, Y.&nbsp;Su, J.&nbsp;Yu, W.&nbsp;Xue, S.&nbsp;Zhang, J.&nbsp;Fu, and Z.&nbsp;Liu,
“Chateval: Towards better llm-based evaluators through multi-agent debate,”
<em id="bib.bib894.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2308.07201, 2023.

</span>
</li>
<li id="bib.bib895" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[895]</span>
<span class="ltx_bibblock">
R.&nbsp;Li, T.&nbsp;Patel, and X.&nbsp;Du, “PRD: peer rank and discussion improve large
language model based evaluations,” <em id="bib.bib895.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.02762, 2023.

</span>
</li>
<li id="bib.bib896" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[896]</span>
<span class="ltx_bibblock">
L.&nbsp;Zhu, X.&nbsp;Wang, and X.&nbsp;Wang, “Judgelm: Fine-tuned large language models are
scalable judges,” <em id="bib.bib896.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2310.17631, 2023.

</span>
</li>
<li id="bib.bib897" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[897]</span>
<span class="ltx_bibblock">
Z.&nbsp;Zeng, J.&nbsp;Yu, T.&nbsp;Gao, Y.&nbsp;Meng, T.&nbsp;Goyal, and D.&nbsp;Chen, “Evaluating large
language models at evaluating instruction following,” <em id="bib.bib897.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2310.07641, 2023.

</span>
</li>
<li id="bib.bib898" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[898]</span>
<span class="ltx_bibblock">
R.&nbsp;Koo, M.&nbsp;Lee, V.&nbsp;Raheja, J.&nbsp;I. Park, Z.&nbsp;M. Kim, and D.&nbsp;Kang, “Benchmarking
cognitive biases in large language models as evaluators,” <em id="bib.bib898.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2309.17012, 2023.

</span>
</li>
<li id="bib.bib899" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[899]</span>
<span class="ltx_bibblock">
P.&nbsp;West, X.&nbsp;Lu, N.&nbsp;Dziri, F.&nbsp;Brahman, L.&nbsp;Li, J.&nbsp;D. Hwang, L.&nbsp;Jiang, J.&nbsp;Fisher,
A.&nbsp;Ravichander, K.&nbsp;Chandu, B.&nbsp;Newman, P.&nbsp;W. Koh, A.&nbsp;Ettinger, and Y.&nbsp;Choi,
“The generative AI paradox: ”what it can create, it may not understand”,”
<em id="bib.bib899.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2311.00059, 2023.

</span>
</li>
<li id="bib.bib900" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[900]</span>
<span class="ltx_bibblock">
J.&nbsp;Huang, X.&nbsp;Chen, S.&nbsp;Mishra, H.&nbsp;S. Zheng, A.&nbsp;W. Yu, X.&nbsp;Song, and D.&nbsp;Zhou,
“Large language models cannot self-correct reasoning yet,” <em id="bib.bib900.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2310.01798, 2023.

</span>
</li>
<li id="bib.bib901" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[901]</span>
<span class="ltx_bibblock">
K.&nbsp;Stechly, M.&nbsp;Marquez, and S.&nbsp;Kambhampati, “GPT-4 doesn’t know it’s wrong:
An analysis of iterative prompting for reasoning problems,” <em id="bib.bib901.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2310.12397, 2023.

</span>
</li>
<li id="bib.bib902" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[902]</span>
<span class="ltx_bibblock">
O.&nbsp;Nov, N.&nbsp;Singh, and D.&nbsp;M. Mann, “Putting chatgpt’s medical advice to the
(turing) test,” <em id="bib.bib902.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2301.10035, 2023.

</span>
</li>
<li id="bib.bib903" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[903]</span>
<span class="ltx_bibblock">
K.&nbsp;Yang, S.&nbsp;Ji, T.&nbsp;Zhang, Q.&nbsp;Xie, and S.&nbsp;Ananiadou, “On the evaluations of
chatgpt and emotion-enhanced prompting for mental health analysis,”
<em id="bib.bib903.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.03347, 2023.

</span>
</li>
<li id="bib.bib904" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[904]</span>
<span class="ltx_bibblock">
K.&nbsp;Jeblick, B.&nbsp;Schachtner, J.&nbsp;Dexl, A.&nbsp;Mittermeier, A.&nbsp;T. Stüber,
J.&nbsp;Topalis, T.&nbsp;Weber, P.&nbsp;Wesp, B.&nbsp;O. Sabel, J.&nbsp;Ricke, and M.&nbsp;Ingrisch,
“Chatgpt makes medicine easy to swallow: An exploratory case study on
simplified radiology reports,” <em id="bib.bib904.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.14882, 2022.

</span>
</li>
<li id="bib.bib905" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[905]</span>
<span class="ltx_bibblock">
K.&nbsp;Singhal, T.&nbsp;Tu, J.&nbsp;Gottweis, R.&nbsp;Sayres, E.&nbsp;Wulczyn, L.&nbsp;Hou, K.&nbsp;Clark,
S.&nbsp;Pfohl, H.&nbsp;Cole-Lewis, D.&nbsp;Neal, M.&nbsp;Schaekermann, A.&nbsp;Wang, M.&nbsp;Amin,
S.&nbsp;Lachgar, P.&nbsp;A. Mansfield, S.&nbsp;Prakash, B.&nbsp;Green, E.&nbsp;Dominowska, B.&nbsp;A.
y&nbsp;Arcas, N.&nbsp;Tomasev, Y.&nbsp;Liu, R.&nbsp;Wong, C.&nbsp;Semturs, S.&nbsp;S. Mahdavi, J.&nbsp;K.
Barral, D.&nbsp;R. Webster, G.&nbsp;S. Corrado, Y.&nbsp;Matias, S.&nbsp;Azizi,
A.&nbsp;Karthikesalingam, and V.&nbsp;Natarajan, “Towards expert-level medical
question answering with large language models,” <em id="bib.bib905.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.09617, 2023.

</span>
</li>
<li id="bib.bib906" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[906]</span>
<span class="ltx_bibblock">
S.&nbsp;Yang, H.&nbsp;Zhao, S.&nbsp;Zhu, G.&nbsp;Zhou, H.&nbsp;Xu, Y.&nbsp;Jia, and H.&nbsp;Zan, “Zhongjing:
Enhancing the chinese medical capabilities of large language model through
expert feedback and real-world multi-turn dialogue,” <em id="bib.bib906.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2308.03549, 2023.

</span>
</li>
<li id="bib.bib907" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[907]</span>
<span class="ltx_bibblock">
S.&nbsp;Chen, B.&nbsp;H. Kann, M.&nbsp;B. Foote, H.&nbsp;J. Aerts, G.&nbsp;K. Savova, R.&nbsp;H. Mak, and
D.&nbsp;S. Bitterman, “The utility of chatgpt for cancer treatment information,”
<em id="bib.bib907.1.1" class="ltx_emph ltx_font_italic">medRxiv</em>, 2023.

</span>
</li>
<li id="bib.bib908" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[908]</span>
<span class="ltx_bibblock">
K.&nbsp;Malinka, M.&nbsp;Peresíni, A.&nbsp;Firc, O.&nbsp;Hujnak, and F.&nbsp;Janus, “On the
educational impact of chatgpt: Is artificial intelligence ready to obtain a
university degree?” <em id="bib.bib908.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.11146, 2023.

</span>
</li>
<li id="bib.bib909" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[909]</span>
<span class="ltx_bibblock">
T.&nbsp;Susnjak, “Chatgpt: The end of online exam integrity?” <em id="bib.bib909.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2212.09292, 2022.

</span>
</li>
<li id="bib.bib910" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[910]</span>
<span class="ltx_bibblock">
K.&nbsp;Tan, T.&nbsp;Pang, and C.&nbsp;Fan, “Towards applying powerful large ai models in
classroom teaching: Opportunities, challenges and prospects,” 2023.

</span>
</li>
<li id="bib.bib911" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[911]</span>
<span class="ltx_bibblock">
F.&nbsp;Kamalov and I.&nbsp;Gurrib, “A new era of artificial intelligence in education:
A multifaceted revolution,” <em id="bib.bib911.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.18303, 2023.

</span>
</li>
<li id="bib.bib912" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[912]</span>
<span class="ltx_bibblock">
E.&nbsp;Kasneci, K.&nbsp;Seßler, S.&nbsp;Küchemann, M.&nbsp;Bannert, D.&nbsp;Dementieva,
F.&nbsp;Fischer, U.&nbsp;Gasser, G.&nbsp;Groh, S.&nbsp;Günnemann, E.&nbsp;Hüllermeier
<em id="bib.bib912.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Chatgpt for good? on opportunities and challenges of large
language models for education,” <em id="bib.bib912.2.2" class="ltx_emph ltx_font_italic">Learning and Individual Differences</em>,
vol. 103, p. 102274, 2023.

</span>
</li>
<li id="bib.bib913" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[913]</span>
<span class="ltx_bibblock">
A.&nbsp;Blair-Stanek, N.&nbsp;Holzenberger, and B.&nbsp;V. Durme, “Can GPT-3 perform
statutory reasoning?” <em id="bib.bib913.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.06100, 2023.

</span>
</li>
<li id="bib.bib914" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[914]</span>
<span class="ltx_bibblock">
D.&nbsp;Trautmann, A.&nbsp;Petrova, and F.&nbsp;Schilder, “Legal prompt engineering for
multilingual legal judgement prediction,” <em id="bib.bib914.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.02199,
2022.

</span>
</li>
<li id="bib.bib915" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[915]</span>
<span class="ltx_bibblock">
J.&nbsp;H. Choi, K.&nbsp;E. Hickman, A.&nbsp;Monahan, and D.&nbsp;Schwarcz, “Chatgpt goes to law
school,” <em id="bib.bib915.1.1" class="ltx_emph ltx_font_italic">Available at SSRN</em>, 2023.

</span>
</li>
<li id="bib.bib916" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[916]</span>
<span class="ltx_bibblock">
J.&nbsp;J. Nay, “Law informs code: A legal informatics approach to aligning
artificial intelligence with humans,” <em id="bib.bib916.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2209.13020,
2022.

</span>
</li>
<li id="bib.bib917" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[917]</span>
<span class="ltx_bibblock">
F.&nbsp;Yu, L.&nbsp;Quartey, and F.&nbsp;Schilder, “Legal prompting: Teaching a language
model to think like a lawyer,” <em id="bib.bib917.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.01326, 2022.

</span>
</li>
<li id="bib.bib918" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[918]</span>
<span class="ltx_bibblock">
D.&nbsp;Trautmann, A.&nbsp;Petrova, and F.&nbsp;Schilder, “Legal prompt engineering for
multilingual legal judgement prediction,” <em id="bib.bib918.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2212.02199,
2022.

</span>
</li>
<li id="bib.bib919" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[919]</span>
<span class="ltx_bibblock">
A.&nbsp;Tamkin, M.&nbsp;Brundage, J.&nbsp;Clark, and D.&nbsp;Ganguli, “Understanding the
capabilities, limitations, and societal impact of large language models,”
<em id="bib.bib919.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2102.02503, 2021.

</span>
</li>
<li id="bib.bib920" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[920]</span>
<span class="ltx_bibblock">
Z.&nbsp;Sun, “A short survey of viewing large language models in legal aspect,”
<em id="bib.bib920.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.09136, 2023.

</span>
</li>
<li id="bib.bib921" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[921]</span>
<span class="ltx_bibblock">
A.&nbsp;Abid, M.&nbsp;Farooqi, and J.&nbsp;Zou, “Persistent anti-muslim bias in large
language models,” in <em id="bib.bib921.1.1" class="ltx_emph ltx_font_italic">AIES ’21: AAAI/ACM Conference on AI, Ethics,
and Society, Virtual Event, USA, May 19-21, 2021</em>, M.&nbsp;Fourcade, B.&nbsp;Kuipers,
S.&nbsp;Lazar, and D.&nbsp;K. Mulligan, Eds.&nbsp;&nbsp;&nbsp;ACM, 2021, pp. 298–306.

</span>
</li>
<li id="bib.bib922" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[922]</span>
<span class="ltx_bibblock">
A.&nbsp;Shah and S.&nbsp;Chava, “Zero is not hero yet: Benchmarking zero-shot
performance of llms for financial tasks,” <em id="bib.bib922.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.16633,
2023.

</span>
</li>
<li id="bib.bib923" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[923]</span>
<span class="ltx_bibblock">
D.&nbsp;Araci, “Finbert: Financial sentiment analysis with pre-trained language
models,” <em id="bib.bib923.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1908.10063, 2019.

</span>
</li>
<li id="bib.bib924" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[924]</span>
<span class="ltx_bibblock">
J.&nbsp;C.&nbsp;S. Alvarado, K.&nbsp;Verspoor, and T.&nbsp;Baldwin, “Domain adaption of named
entity recognition to support credit risk assessment,” in <em id="bib.bib924.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the Australasian Language Technology Association Workshop, ALTA 2015,
Parramatta, Australia, December 8 - 9, 2015</em>, B.&nbsp;Hachey and K.&nbsp;Webster,
Eds.&nbsp;&nbsp;&nbsp;ACL, 2015, pp. 84–90.

</span>
</li>
<li id="bib.bib925" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[925]</span>
<span class="ltx_bibblock">
G.&nbsp;Son, H.&nbsp;Jung, M.&nbsp;Hahm, K.&nbsp;Na, and S.&nbsp;Jin, “Beyond classification: Financial
reasoning in state-of-the-art language models,” <em id="bib.bib925.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2305.01505, 2023.

</span>
</li>
<li id="bib.bib926" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[926]</span>
<span class="ltx_bibblock">
X.&nbsp;Zhang, Q.&nbsp;Yang, and D.&nbsp;Xu, “Xuanyuan 2.0: A large chinese financial chat
model with hundreds of billions parameters,” <em id="bib.bib926.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2305.12002</em>, 2023.

</span>
</li>
<li id="bib.bib927" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[927]</span>
<span class="ltx_bibblock">
H.&nbsp;Yang, X.-Y. Liu, and C.&nbsp;D. Wang, “Fingpt: Open-source financial large
language models,” <em id="bib.bib927.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.06031, 2023.

</span>
</li>
<li id="bib.bib928" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[928]</span>
<span class="ltx_bibblock">
Q.&nbsp;Jin, B.&nbsp;Dhingra, Z.&nbsp;Liu, W.&nbsp;W. Cohen, and X.&nbsp;Lu, “Pubmedqa: A dataset for
biomedical research question answering,” in <em id="bib.bib928.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019
Conference on Empirical Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language Processing, EMNLP-IJCNLP
2019, Hong Kong, China, November 3-7, 2019</em>, 2019, pp. 2567–2577.

</span>
</li>
<li id="bib.bib929" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[929]</span>
<span class="ltx_bibblock">
A.&nbsp;Krithara, A.&nbsp;Nentidis, K.&nbsp;Bougiatiotis, and G.&nbsp;Paliouras, “Bioasq-qa: A
manually curated corpus for biomedical question answering,” 2022.

</span>
</li>
<li id="bib.bib930" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[930]</span>
<span class="ltx_bibblock">
Z.&nbsp;Bi, N.&nbsp;Zhang, Y.&nbsp;Xue, Y.&nbsp;Ou, D.&nbsp;Ji, G.&nbsp;Zheng, and H.&nbsp;Chen, “Oceangpt: A
large language model for ocean science tasks,” <em id="bib.bib930.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2310.02031, 2023.

</span>
</li>
<li id="bib.bib931" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[931]</span>
<span class="ltx_bibblock">
C.&nbsp;Zhang, C.&nbsp;Zhang, C.&nbsp;Li, Y.&nbsp;Qiao, S.&nbsp;Zheng, S.&nbsp;K. Dam, M.&nbsp;Zhang, J.&nbsp;U. Kim,
S.&nbsp;T. Kim, J.&nbsp;Choi, G.&nbsp;Park, S.&nbsp;Bae, L.&nbsp;Lee, P.&nbsp;Hui, I.&nbsp;S. Kweon, and C.&nbsp;S.
Hong, “One small step for generative ai, one giant leap for AGI: A
complete survey on chatgpt in AIGC era,” <em id="bib.bib931.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.06488,
2023.

</span>
</li>
<li id="bib.bib932" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[932]</span>
<span class="ltx_bibblock">
M.&nbsp;Haman and M.&nbsp;Skolnik, “Using chatgpt to conduct a literature review.”
<em id="bib.bib932.1.1" class="ltx_emph ltx_font_italic">Accountability in research</em>, 2023.

</span>
</li>
<li id="bib.bib933" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[933]</span>
<span class="ltx_bibblock">
Ö.&nbsp;Aydın and E.&nbsp;Karaarslan, “Openai chatgpt generated literature review:
Digital twin in healthcare,” <em id="bib.bib933.1.1" class="ltx_emph ltx_font_italic">SSRN Electronic Journal</em>, 2022.

</span>
</li>
<li id="bib.bib934" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[934]</span>
<span class="ltx_bibblock">
Y.&nbsp;J. Park, D.&nbsp;Kaplan, Z.&nbsp;Ren, C.&nbsp;Hsu, C.&nbsp;Li, H.&nbsp;Xu, S.&nbsp;Li, and J.&nbsp;Li, “Can
chatgpt be used to generate scientific hypotheses?” <em id="bib.bib934.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol.
abs/2304.12208, 2023.

</span>
</li>
<li id="bib.bib935" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[935]</span>
<span class="ltx_bibblock">
M.&nbsp;M. Hassan, R.&nbsp;A. Knipper, and S.&nbsp;K.&nbsp;K. Santu, “Chatgpt as your personal
data scientist,” <em id="bib.bib935.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.13657, 2023.

</span>
</li>
<li id="bib.bib936" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[936]</span>
<span class="ltx_bibblock">
L.&nbsp;Cheng, X.&nbsp;Li, and L.&nbsp;Bing, “Is GPT-4 a good data analyst?” <em id="bib.bib936.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/2305.15038, 2023.

</span>
</li>
<li id="bib.bib937" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[937]</span>
<span class="ltx_bibblock">
S.&nbsp;I.&nbsp;M. Hussam&nbsp;Alkaissi, “Artificial hallucinations in chatgpt: Implications
in scientific writing,” <em id="bib.bib937.1.1" class="ltx_emph ltx_font_italic">PubMed</em>, 2023.

</span>
</li>
<li id="bib.bib938" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[938]</span>
<span class="ltx_bibblock">
A.&nbsp;Azaria, R.&nbsp;Azoulay, and S.&nbsp;Reches, “Chatgpt is a remarkable tool – for
experts,” <em id="bib.bib938.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.03102, 2023.

</span>
</li>
<li id="bib.bib939" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[939]</span>
<span class="ltx_bibblock">
O.&nbsp;O. Buruk, “Academic writing with GPT-3.5: reflections on practices,
efficacy and transparency,” <em id="bib.bib939.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2304.11079, 2023.

</span>
</li>
<li id="bib.bib940" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[940]</span>
<span class="ltx_bibblock">
R.&nbsp;Liu and N.&nbsp;B. Shah, “Reviewergpt? an exploratory study on using large
language models for paper reviewing,” <em id="bib.bib940.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.00622,
2023.

</span>
</li>
<li id="bib.bib941" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[941]</span>
<span class="ltx_bibblock">
M.&nbsp;Kosinski, “Theory of mind may have spontaneously emerged in large language
models,” <em id="bib.bib941.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2302.02083, 2023.

</span>
</li>
<li id="bib.bib942" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[942]</span>
<span class="ltx_bibblock">
M.&nbsp;M. Amin, E.&nbsp;Cambria, and B.&nbsp;W. Schuller, “Will affective computing emerge
from foundation models and general ai? A first evaluation on chatgpt,”
<em id="bib.bib942.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2303.03186, 2023.

</span>
</li>
<li id="bib.bib943" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[943]</span>
<span class="ltx_bibblock">
G.&nbsp;Sridhara, R.&nbsp;H. G., and S.&nbsp;Mazumdar, “Chatgpt: A study on its utility for
ubiquitous software engineering tasks,” <em id="bib.bib943.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.16837,
2023.

</span>
</li>
<li id="bib.bib944" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[944]</span>
<span class="ltx_bibblock">
W.&nbsp;Sun, C.&nbsp;Fang, Y.&nbsp;You, Y.&nbsp;Miao, Y.&nbsp;Liu, Y.&nbsp;Li, G.&nbsp;Deng, S.&nbsp;Huang, Y.&nbsp;Chen,
Q.&nbsp;Zhang, H.&nbsp;Qian, Y.&nbsp;Liu, and Z.&nbsp;Chen, “Automatic code summarization via
chatgpt: How far are we?” <em id="bib.bib944.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.12865, 2023.

</span>
</li>
<li id="bib.bib945" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[945]</span>
<span class="ltx_bibblock">
C.&nbsp;S. Xia and L.&nbsp;Zhang, “Conversational automated program repair,”
<em id="bib.bib945.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2301.13246, 2023.

</span>
</li>
<li id="bib.bib946" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[946]</span>
<span class="ltx_bibblock">
W.&nbsp;Kuang, B.&nbsp;Qian, Z.&nbsp;Li, D.&nbsp;Chen, D.&nbsp;Gao, X.&nbsp;Pan, Y.&nbsp;Xie, Y.&nbsp;Li, B.&nbsp;Ding, and
J.&nbsp;Zhou, “Federatedscope-llm: A comprehensive package for fine-tuning large
language models in federated learning,” 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2303.18222" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2303.18223" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2303.18223">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.18223" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2303.18224" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 17:19:42 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>