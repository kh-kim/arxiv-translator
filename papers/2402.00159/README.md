# 2402.00159 Dolma an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research

[ArXiv Version](https://arxiv.org/abs/2402.00159)

[Ar5iv Version](https://ar5iv.org/abs/2402.00159)

[English Version](https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2402.00159/paper.en.html)

[Korean Version](https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2402.00159/paper.ko.html)