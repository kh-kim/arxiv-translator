<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 언어 모델 사전 학습 연구를 위한 3조 토큰의 오픈 코퍼스\n' +
      '\n' +
      ' Luca Soldaini\\({}^{\\bullet}\\)\\({}^{\\,\\alpha}\\) Rodney Kinney\\({}^{\\bullet}\\)\\({}^{\\,\\alpha}\\) Akshita Bhagia\\({}^{\\bullet}\\)\\({}^{\\,\\alpha}\\) Dustin Schwenk\\({}^{\\bullet}\\)\\({}^{\\,\\alpha}\\)\n' +
      '\n' +
      'David Atkinson\\({}^{\\,\\alpha}\\) Russell Authur\\({}^{\\,\\alpha}\\) Ben Bogin\\({}^{\\,\\alpha}\\) Khyathi Chandu\\({}^{\\,\\alpha}\\)\n' +
      '\n' +
      'Jennifer Dumas\\({}^{\\,\\alpha}\\) Yanai Elazar\\({}^{\\,\\alpha}\\)\\({}^{\\,\\omega}\\) Valentin Hofmann\\({}^{\\,\\alpha}\\) Ananya Harsh Jha\\({}^{\\,\\alpha}\\)\n' +
      '\n' +
      'Sachin Kumar\\({}^{\\,\\alpha}\\) Li Lucy\\({}^{\\,\\beta}\\) Xinxi Lyu\\({}^{\\,\\omega}\\) Nathan Lambert\\({}^{\\,\\alpha}\\) Ian Magnusson\\({}^{\\,\\alpha}\\)\n' +
      '\n' +
      'Jacob Morrison\\({}^{\\,\\alpha}\\) Niklas Muennighoff Aakanksha Naik\\({}^{\\,\\alpha}\\) Crystal Nam\\({}^{\\,\\alpha}\\)\n' +
      '\n' +
      'Matthew E. Peters\\({}^{\\,\\sigma}\\) Abhilasha Ravichander\\({}^{\\,\\alpha}\\) Kyle Richardson\\({}^{\\,\\alpha}\\) Zejiang Shen\\({}^{\\,\\tau}\\)\n' +
      '\n' +
      'Emma Strubell\\({}^{\\,\\times}\\)\\({}^{\\,\\alpha}\\) Nishant Subramani\\({}^{\\,\\times}\\)\\({}^{\\,\\alpha}\\) Oyvind Tafjord\\({}^{\\,\\alpha}\\) Pete Walsh\\({}^{\\,\\alpha}\\)\n' +
      '\n' +
      'Luke Zettlemoyer\\({}^{\\,\\omega}\\) Noah A. Smith\\({}^{\\,\\alpha}\\) Hannaneh Hajishirzi\\({}^{\\,\\alpha}\\)\\({}^{\\,\\omega}\\)\n' +
      '\n' +
      'Iz Beltagy\\({}^{\\,\\alpha}\\) Dirk Groeneveld\\({}^{\\,\\alpha}\\) Jesse Dodge\\({}^{\\,\\alpha}\\)\n' +
      '\n' +
      'Kyle Lo\\({}^{\\,\\phi}\\)\\({}^{\\,\\alpha}\\)\n' +
      '\n' +
      '(주)알렌 인공지능연구소\n' +
      '\n' +
      '\\({}^{\\,\\sigma}\\)Spiffy AI \\({}^{\\,\\tau}\\)Massachusetts Institute\\({}^{\\,\\omega}\\)University of Washington\n' +
      '\n' +
      '{lucas,kylel}@allenai.org\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '언어 모델은 광범위한 자연어 처리 작업을 처리하는 데 중요한 기술이 되었지만 가장 성능이 좋은 언어 모델이 어떻게 개발되었는지에 대한 많은 세부 사항은 보고되지 않았다. 특히, 그들의 사전 훈련 말뭉치에 대한 정보는 거의 논의되지 않는다: 상업용 언어 모델은 데이터에 대한 정보를 거의 제공하지 않으며, 심지어 열린 모델도 그들이 훈련한 데이터 세트 또는 그것을 재현하기 위한 정확한 레시피를 거의 공개하지 않는다. 결과적으로, 훈련 데이터가 모델 능력에 어떻게 영향을 미치고 한계를 형성하는지를 이해하는 것과 같은 언어 모델링 연구의 특정 스레드를 수행하는 것은 어렵다. 언어 모델 사전 교육에 대한 공개 연구를 용이하게 하기 위해 웹 콘텐츠, 과학 논문, 코드, 공공 도메인 책, 소셜 미디어 및 백과사전 자료의 다양한 혼합으로 구축된 3조 토큰 영어 말뭉치인 돌마를 출시한다. 또한 데이터 큐레이션 툴킷을 오픈하여 작업의 추가 실험과 재현을 가능하게 합니다. 이 보고서에서는 돌마의 설계 원칙, 시공에 대한 세부 사항 및 내용 요약을 포함하여 돌마를 문서화한다. 우리는 이 보고서를 돌마의 중간 상태에 대한 훈련 언어 모델의 분석 및 실험 결과와 인터리브하여 콘텐츠 또는 품질 필터의 역할, 중복 제거 및 다중 소스 혼합을 포함한 중요한 데이터 큐레이션 관행에 대해 배운 내용을 공유한다. 돌마는 언어 모델링의 과학을 구축하고 연구하기 위해 설계된 최첨단 개방형 언어 모델 및 프레임워크인 OLMo를 훈련하는 데 사용되었다.\n' +
      '\n' +
      '\\begin{tabular}{c c}\n' +
      '**Dataset** & v.1.6 & huggingface.co/datasets/allenai/dolma \\\\\n' +
      '**Toolkit** & v.1.0 & github.com/allenai/dolma \\\\ \\end{tabular}\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '언어 모델은 이제 적은 샷 학습, 요약, 질의 응답 등을 포함한 무수히 많은 자연어 처리 작업을 처리하는 데 중심이다. 점점 더 강력한 언어 모델들은 대부분의 모델 개발 세부사항들을 보류하는 몇몇 기관들에 의해 구축된다(Anthropic, 2023; OpenAI, 2023; Anil et al., 2023; Gemini Team et al., 2023). 특히, LLaMA 2(Touvron et al., 2023b)와 같이 모델 자체가 공공용으로 출시되는 경우에도 언어 모델 사전 트레이닝 데이터의 구성은 모호하게 언급되는 경우가 많다. 이는 사전 훈련 말뭉치 구성이 모델 능력 및 한계에 미치는 영향, 따라서 모델 자체에 대한 이해도를 방해하고 과학적 진보에 영향을 미치고 이러한 모델과 인터페이스하는 대중에게 영향을 미친다. 우리는 대신 개방성과 투명성을 목표로 하며, 3조 개의 토큰 데이터 세트를 복제, 정밀 조사 및 확장할 도구와 함께 공개 및 문서화한다.\n' +
      '\n' +
      '우리의 목표는 더 많은 개인과 조직이 언어 모델 연구 개발에 참여할 수 있도록 하는 것입니다.\n' +
      '\n' +
      '* 데이터 투명성은 언어 모델에 의존 하는 **애플리케이션** 개발자와 사용자가 더 많은 정보에 입각한 결정을 내리는 데 도움이 됩니다 (Gebru 등, 2021). 예를 들어, 언어 모델 사전 트레이닝 데이터에서 문서 또는 용어의 증가된 보급은 관련 태스크에 대한 더 나은 수행으로 연결되었고(Razeghi et al., 2022; Kandpal et al., 2023), 사전 트레이닝 데이터에서의 사회적 편향(Feng et al., 2023; Navigli et al., 2023; Seshadri et al., 2023)은 일부 도메인에서 추가적인 고려를 필요로 할 수 있다.\n' +
      '* 데이터 구성이 모델 행동에 어떻게 영향을 미치는지 탐구하는 경험적 연구를 통해 **분석** 에 개방형 사전 훈련 데이터가 필요하므로 모델링 커뮤니티가 현재 데이터 큐레이션 관행을 조사하고 개선할 수 있습니다 (Longpre et al., 2023; Gao, 2021; Elazar et al., 2023). 본 연구의 예로는 암기(Carlini et al., 2022b; Chang et al., 2023), 중복 제거(Lee et al., 2022), 적대적 공격(Wallace et al., 2021), 벤치마크 오염(Magar and Schwartz, 2022), 트레이닝 데이터 속성(Hammoudeh and Lowd, 2022; Grosse et al., 2023) 등이 있다.\n' +
      '* 오픈 언어 모델의 성공적인 **개발** 을 위해 데이터에 대한 액세스가 필요합니다. 예를 들어, 최신 언어 모델은 사전 트레이닝 데이터에 대한 세대의 귀속과 같은 기능을 제공할 수 있다(Borgeaud et al., 2022).\n' +
      '\n' +
      '이러한 연구 라인에서 광범위한 참여와 조사를 지원하기 위해 언어 모델 사전 훈련 연구를 지원하도록 설계된 3조 토큰의 개방형 코퍼스인 **O**pen **L** 언어 **M** 모델의 **A**ppetite(돌마)** 에 대한 **D**ata를 제공합니다. 사전 훈련 데이터 믹스는 종종 소위 "범용" 영어를 포착하려는 욕구에 의해 동기가 부여된다. 우리는 커먼 크롤의 웹 텍스트, 시맨틱 학자의 과학 연구, 깃허브의 코드, 공공 도메인 책, 레딧의 소셜 미디어 게시물, 위키피디아의 백과사전 자료를 포함하여 과거 작업에 존재하는 것과 유사한 출처에서 많은 데이터를 수집한다. 우리는 우리의 데이터 세트를 다양한 인기 있는 사전 훈련 코퍼라와 비교한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c} \\hline \\hline \\multirow{2}{*}{**Source**} & \\multirow{2}{*}{**Doc Type**} & **Utf-8 bytes** & **Documents** & **Unicode** & **Llama** \\\\  & & _(GB)_ & _(millions)_ & **words** & **tokens** \\\\  & & & & _(billions)_ & _(billions)_ \\\\ \\hline Common Crawl & \\multirow{2}{*}{Web pages} & 9,022 & 3,370 & 1,775 & 2,281 \\\\ The Stack & & code & 1,043 & 210 & 260 & 411 \\\\ C4 & & web pages & 790 & 364 & 153 & 198 \\\\ Reddit & & social media & 339 & 377 & 72 & 89 \\\\ PeS2o & & STEM papers & 268 & 38.8 & 50 & 70 \\\\ Project Gutenberg & & books & 20.4 & 0.056 & 4.0 & 6.0 \\\\ Wikipedia, Wikibooks & & encyclopedic & 16.2 & 6.2 & 3.7 & 4.3 \\\\ \\hline \\multicolumn{2}{c}{**Total**} & **11,519** & **4,367** & **2,318** & **3,059** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: Dolma corpus at-a-glance. 약 200 TB의 원시 텍스트에서 제공되는 다양한 도메인 집합에서 샘플링된 3조 개의 토큰으로 구성된다. 언어 모델 사전 교육 사용을 위해 광범위하게 청소되었습니다.\n' +
      '\n' +
      '공개적으로 사용할 수 있으며 돌마가 비슷한 품질과 동등하게 다양한 데이터 구성으로 더 큰 토큰 풀을 제공한다는 것을 발견한다. 돌마는 언어 모델링의 과학을 용이하게 하도록 설계된 최신 모델의 패밀리인 OLMo(Groeneveld 등, 2024)를 사전 트레이닝하기 위해 이미 사용되었다.\n' +
      '\n' +
      '요약하면, 우리의 기여는 두 가지이다.\n' +
      '\n' +
      '* 대규모 언어 모델 사전 훈련에서 일반적으로 볼 수 있는 (_i_) 및 일반 대중이 액세스할 수 있는 (_ii_) 7개의 다른 데이터 원본에서 획득한 5B 문서에 걸쳐 다양한 **다중 원본** 3T 토큰 모음인 **Dolma Corpus** 를 릴리스합니다. 표 1은 각 소스의 데이터 양에 대한 상위 수준의 개요를 제공한다.\n' +
      '* 언어 모델 사전 교육을 위해 대규모 데이터 세트를 효율적으로 큐레이션하도록 설계된 고성능 휴대용 도구인 **Dolma Toolkit** 을 오픈 소스합니다. 이 툴킷을 통해 실무자는 큐레이션 노력을 재현하고 자체 데이터 큐레이션 파이프라인을 개발할 수 있습니다.\n' +
      '\n' +
      '이 필사본의 나머지 부분은 다음과 같이 정리된다. 먼저 돌마(SS2)의 생성을 안내한 데시데라타와 디자인 원리에 대해 설명한다. 그런 다음 언어, "품질", 내용 필터링 및 중복 제거를 위한 필터를 포함하여 원시 텍스트(SS3) 처리에 적용된 방법을 문서화합니다. 벤치마크 오염 제거 및 혼합물 비율 선택을 포함하여 사전 훈련 코퍼스(SS4)로 사용하기 위해 돌마를 준비하려면 추가 처리가 필요했다. 총 12개의 질문-응답, 상식 및 추론 태스크 세트에 대해 당혹성 추적 및 다운스트림 성능을 통해 도메인 적합성을 측정하는 절제 실험을 수행한다. 돌마를 방출하는 과정(SS5)을 논의함으로써 결론을 맺는다.\n' +
      '\n' +
      '## 2 Dolma Design Goals\n' +
      '\n' +
      '대규모 LM 사전 교육 연구를 지원하기 위해 개방성, 이전 작업과의 일관성, 크기 및 위험 완화를 중심으로 4가지 설계 요구 사항을 설정했다. 우리는 차례로 각각을 논의합니다.\n' +
      '\n' +
      'Dolma의 큐레이션은 사전 언어 모델 사전 훈련 레시피와 일치해야 한다. 다른 언어 모델링 말뭉치를 만드는 데 사용되는 데이터 소스 및 방법을 알려져 있는 범위 내에서 일치시킴으로써 광범위한 연구 커뮤니티가 우리의 말뭉치와 결과 모델 아티팩트를 사용하여 오늘날 개발되고 있는 언어 모델, 심지어 비공개로 개발된 언어 모델을 연구(그리고 면밀히 조사)할 수 있도록 한다. 이 **복제** 노력에서 알려진 범위 내에서 기존 관행(_i.e._, 언어 모델링 노력에 걸쳐 자주 나타나는 콘텐츠를 전처리 및 필터링하기 위한 데이터 원본 및 기술을 사용)을 따르고 모범 사례가 알려지지 않았거나 구현이 미묘한 방식으로 다를 때 분석, 실험 및 교육된 추측을 연기합니다. 1 특히, 이는 또한 알려진 큐레이션 관행을 더 잘 활용하고 기존 언어 모델에 대한 돌마에 대한 과학적 작업의 일반화 가능성을 최대화하기 위해 돌마를 **영어 전용** 텍스트로 범위를 지정한다는 것을 의미합니다. 2 이러한 복제 노력의 개방형 특성을 설명하기 위해 가장 큰 독점적인 일부(예: GPT-4(OpenAI, 2023), PaLM 2(Anil et al., 2023), Claude(Anthropic, 2023))뿐만 아니라 개방형(예: OPT(Zhang, 2022), LLaMA(Touvron et al., 2023), Llama 2(Touvron et al., 2023)) 언어 모델에 대한 알려진(및 알려지지 않은) 데이터 큐레이션 관행에 대한 자세한 요약을 부록 SSC에 제공합니다.\n' +
      '\n' +
      '각주 1: 우리는 이러한 재생 노력이 특정 언어 모델 사전 트레이닝 데이터 구현의 복제를 추구하지 않는다는 점에 주목한다. 대신 다양한 데이터 큐레이션 테마를 재현합니다.\n' +
      '\n' +
      '각주 2: 이 초점이 영어의 가정을 “기본” 언어로 강화한다는 것을 인식하고, 우리는 돌마를 앞으로 더 많은 언어로 확장하기를 희망한다. 이러한 노력을 지원하기 위해 데이터 큐레이션 도구를 출시합니다.\n' +
      '\n' +
      'Dolma는 큰 모델의 훈련을 지원해야 한다. Hoffmann 등(2022)은 언어 모델 크기(매개변수)와 최소 훈련 토큰 수 사이의 고정된 비율을 유지함으로써 컴퓨팅-최적 모델을 훈련할 수 있다고 제안했다. LLaMA 2 (Touvron et al., 2023)와 같은 이러한 "스케일링 법칙"을 따르는 최근 모델은 훈련 토큰의 수를 늘림으로써 여전히 성능 개선의 여지가 있음을 보여주는 것으로 보입니다.3 이것이 활발한 연구 영역이기 때문에 모델과 데이터 세트 크기 간의 관계에 대 한 추가 연구를 허용 하는 충분히 큰 코퍼스를 목표로 합니다--**2-3T 토큰**.\n' +
      '\n' +
      '돌마는 개방형 말뭉치에 기여해야 하며, 해당 언어 모델과 함께 사전 훈련 말뭉치에 대한 접근 부족은 광범위한 연구 커뮤니티의 주요 장애물이었다. 최근 몇 년 동안 공개된 수백 개의 개방형 모델 중 매우 적은 수의 개방형 모델이 훈련 데이터와 함께 공개된다: T5 및 C4(Raffel et al., 2020), BLOOM 및 ROOTS(Leong et al., 2022; Piktus et al., 2023), GPT-J/GPT-NeoX/Pythia and Pile(Wang and Komatsuzaki, 2021; Black et al., 2022; Biderman et al., 2023; Gao et al., 2020), INCITE and RedPajama v1(Together Computer, 2023b,c). 그러나 이러한 이전 코퍼스의 제한 사항은 Dolma와 같은 새 데이터 세트에 대한 필요성을 동기 부여했습니다.\n' +
      '\n' +
      '* C4(Raffel et al., 2020), Pile(Gao et al., 2020), 및 Falcon(Almazrouei et al., 2023)은 트레이닝 언어 모델에서의 사용이 입증된 고품질 데이터세트이지만, 불행히도 스케일이 제한된다. ROOTS(Piktus et al., 2023)는 크고 다양하지만 다국어 초점을 감안할 때 영어 전용 부분도 너무 작아서 영어 전용 모델을 훈련시킬 수 없다.\n' +
      '* RedPajama v2 (Together Computer, 2023a)는 규모 기준을 충족 하지만 가장 큰 언어 모델 (예: 과학 논문, 코드)을 큐레이션 하는 데 일반적으로 볼 수 있는 콘텐츠 원본에 대 한 대표적인 분포를 반영 하지 않습니다.\n' +
      '* RedPajama v1 (Together Computer, 2023c)은 Dolma를 디자인할 때 우리의 노력 및 영감의 원천과 가장 유사합니다. RedPajama v1은 LLaMA(Touvron et al., 2023a) 훈련 데이터를 복제했지만 Reddit과 같은 더 큰 과학 논문 모음 및 대화 포럼을 포함하여 RedPajama v1이 추구하지 않은 데이터 소스로 다이빙해야 하는 광범위한 복제 목표를 가지고 있다.\n' +
      '\n' +
      '전체적으로 현재까지의 **가장 큰 큐레이트된 _open_ 사전 훈련 코퍼스** 를 만들어 이러한 작업을 확장합니다. (_i_) **데이터 자체를 공유** 하 여 데이터 원본의 선택을 알려 주고, (_ii_) **큐레이트 하는 데 사용 되는 프로세스를 문서화** 합니다. 여기에는 정당화로 결정 된 결정 및 다른 사람이 작업을 재현 하 고 새 말뭉치를 만들 수 있도록 하는 오픈 소스 구현이 포함 됩니다. 결과적으로 오픈 소스 고성능 툴킷을 통해 연구자들은 돌마를 더 세분화하거나 자체 데이터 세트를 처리할 수 있도록 자체 데이터 파이프라인을 구현할 수 있다.\n' +
      '\n' +
      '돌마의 큐레이션은 훈련 전 코퍼스를 큐레이션하는 개인에 대한 위해 위험을 최소화해야 하며 코퍼스에 존재하는 정보에 대한 액세스를 용이하게 하거나 유해한 모델의 훈련을 가능하게 함으로써 개인에게 위험을 도입할 수 있다. 명시된 목표를 충족하는 동안 이러한 위험을 최소화하기 위해 프로젝트 초기에 조직 내 법률 및 윤리 전문가와 협력하고 사례별로 피드백을 기반으로 데이터 설계 결정을 평가했다. 일반적으로 우리는 사용 가능한 경우 허용되는 관행을 따르고(_e.g._, 특정 개인 식별 정보의 마스킹), 문헌에 의견이 다른 경우 측정된 접근법을 사용한다(_e.g._, 독성 콘텐츠를 식별하고 제거하는 가장 효과적인 접근법). 또한 데이터 제거를 요청할 수 있는 도구를 제공한다. 4 데이터와 AI 주변의 풍경이 진화하고 있기 때문에 우리의 결정이 옳다고 주장하지 않는다. 그럼에도 불구하고, 우리는 개인에게 심각한 피해를 주는 경우 모델 재현성, 성능 및 확장성과 같은 원하는 연구 인공물 특성을 손상시킨다고 믿는다.\n' +
      '\n' +
      '각주 4: 다음 URL에서 사용 가능: form.gle/FzPUQLJhE57JLJ3f8\n' +
      '\n' +
      '우리의 노력의 범위를 돕기 위한 이러한 디자인 목표에도 불구하고 돌마를 큐레이팅할 때 우리가 해야 하는 수많은 결정이 남아 있다. 사전 작업에서 따라야 할 명확한 레시피가 없으면 결정을 안내하기 위해 두 가지 원칙에 의존한다.\n' +
      '\n' +
      '1. [label=()]\n' +
      '2. ** 현명하게 평가 제품군을 사용합니다.* * OLMo 프로젝트 Groeneveld 등(2024)의 일부로 다양한 기능 및 작업에 걸쳐 사전 교육 중에 지침을 제공하기 위해 평가 제품군(Groeneveld 등, 2023; 부록 D의 세부 정보)을 개발했습니다. 가능할 때마다 데이터 결정은 메트릭을 개선하기 위해 이루어진다. 그러나 평가 스위트는 완벽하지 않습니다. 예를 들어, 명령어 튜닝5 이후에 모델들에게 혜택을 주는 데이터 소스들을 추가하는 것의 효과를 완전히 측정할 수 없다. 이러한 경우, 우리는 임의의 한 결정이 스위트 내의 임의의 태스크들의 성능을 급격하게 감소시키지 않도록 한다. 관심 있는 연구 방향을 우리 조직에 발전시키는 선호 결정입니다. 위의 원칙이 지침을 제공하지 않는 경우 저자와 같은 학술 또는 비영리 단체의 연구에 가장 유용할 코퍼스를 구축하려고 한다. 이것은 반드시 벤치마크 성능을 최대화하는 것을 의미하는 것은 아니며, 많은 바람직한 데이터 세트 개입은 서로 상충된다.\n' +
      '\n' +
      '각주 6: 예를 들어 돌마가 코드에 대한 사전 훈련의 영향에 대한 향후 조사를 지원하기를 원하지만 현재 평가 제품군은 코드 데이터의 영향을 완전히 평가하도록 적절하게 설계되지 않았지만 그럼에도 불구하고 이 주제에 대한 추가 연구를 위해 코퍼스에 코드를 포함한다. 마찬가지로 이전 연구에서도 제거해야 한다고 제안했다.\n' +
      '\n' +
      '## 3 Creating Dolma\n' +
      '\n' +
      '사전 트레이닝 데이터의 큐레이션은 종종 여러 소스의 원시 데이터를 세척된 일반 텍스트 문서의 단일 컬렉션으로 변환하는 복잡한 파이프라인을 정의해야 한다. 이러한 파이프라인은 다양한 소스로부터의 콘텐츠 획득(_e.g._, 크롤링, API 수집, 대량 처리), 필터링 휴리스틱 및 콘텐츠 분류기를 통한 데이터 정리, 최종 데이터 세트로의 혼합(_e.g._, 중복 제거, 소스의 업/다운 샘플링)을 지원해야 한다.\n' +
      '\n' +
      '돌마를 큐레이팅할 때, 우리는 수백 테라바이트의 텍스트 콘텐츠에 대한 효율적인 처리를 용이하게 하기 위해 고성능 툴킷을 생성한다. 이 툴킷은 높은 휴대성을 위해 설계되었으며, 소비자 하드웨어(따라서 새로운 파이프라인의 개발을 용이하게 함)에서 분산 클러스터 환경(돌마와 같은 대규모 데이터 세트를 처리하는 이상)까지 모든 플랫폼을 실행할 수 있습니다. 돌마의 큐레이션을 통해 고퍼, C4, OpenWebText와 유사한 데이터 세트를 재현하고 큐레이션하는 데 사용할 수 있는 일반적으로 사용되는 정리 및 혼합 단계를 구현했다.\n' +
      '\n' +
      '이 툴킷을 이용하여 SS 2에서 소개한 돌마 데시데라타와 일치하는 4가지 데이터 변환을 개발하고 결합한다.\n' +
      '\n' +
      '* **언어 필터링**. 영어 전용 코퍼스를 만들기 위해 자동화된 언어 식별을 위해 확장 가능한 도구에 의존합니다. 식별은 fastText의 (Joulin et al., 2016) 언어 ID 모델을 이용하여 수행된다. 각 출처의 문서 길이에 따라 전체 텍스트를 한 번에 처리하거나 문단의 점수를 평균화한다. 충분히 낮은 영어 점수를 갖는 문서들은 제거된다.7 우리는 영어 전용 문서들에 이미 사전 필터링된 데이터세트들에 대해 어떠한 언어 식별도 수행하지 않는다.8 우리는 언어 필터링이 결코 완벽하지 않으며, 다국어 데이터는 사전 트레이닝 말뭉치로부터 완전히 제거되지 않는다는 것에 주목한다(Blevins and Zettlemoyer, 2022). 각주 7: 낮은 임계값을 유지하는 것은 언어 검출기가 마이너리타이징된 그룹들에 의해 사용되는 영어 방언들에 대해 갖는 내재된 편향들을 완화하는 것을 도울 수 있다(Blodgett 등, 2016). 각 소스에 사용된 점수는 후속 섹션에 보고된다. 각주 8: 이러한 데이터 세트는 다른 분류기 및 임계값을 사용하여 영어 콘텐츠로 필터링되었을 수 있다.\n' +
      '* **품질 필터링**. "낮은 품질"로 간주되는 텍스트를 제거하는 것이 일반적인 관행이지만, 이것이 무엇을 의미하는지 또는 자동화된 도구를 사용하여 이것을 작동시키는 방법에 대한 광범위한 합의는 없다. 9 웹 소스의 경우, LLaMA(Touvron et al., 2023) 및 GPT-3(Brown et al., 2020)에 사용되는 것과 같은 모델 기반 품질 필터를 피하는 것을 제안하는 Gopher(Rae et al., 2021) 및 Falcon(Almazrouei et al., 2023)의 권장 사항을 따른다. 대신 C4(Raffel et al., 2020)와 Gopher(Rae et al., 2021)에서 사용하는 휴리스틱을 다시 구현해 커먼 크롤(Common Crawl) 처리에 적용했다. 다른 소스의 경우 독자는 해당 섹션을 각각 필요한 맞춤형 품질 필터링 전략으로 참조한다. 각주 9: 문헌에서 널리 사용되는 용어 "_quality filter,_"는 데이터세트를 필터링한 결과를 적절하게 설명하지 않는다. 품질은 인간이 평가하는 정보성, 포괄성 또는 기타 특성에 대한 논평으로 인식될 수 있다. 그러나, 돌마 및 다른 언어 모델들에서 사용되는 필터들은 본질적으로 이념적인 기준에 따라 텍스트를 선택한다(구루랑간 등, 2022). 각주 10: "_quality"의 경우와 마찬가지로 "_toxicity_"에 대한 단일 정의는 없으며, 오히려 태스크(Vidgen and Derczynski, 2020) 및 데이터세트 큐레이터의 소셜 아이덴티티에 따라 특정 정의가 달라지며(Santy et al., 2023), 주석자의 신념도 독성 언어 검출에 영향을 미친다(Sap et al., 2021). 모델을 사용하여 독성 시간을 식별한다(Carlini et al., 2022; Chen et al., 2023b). 돌마에서는 Jigsaw Toxic Comments(cjadams et al., 2017)에 대해 훈련된 fastText 분류기와 Subramani et al.(2023); Elazar et al.(2023)의 PII 카테고리를 대상으로 하는 일련의 정규식을 통해 제거를 위한 콘텐츠를 식별한다.\n' +
      '* **중복 제거**. 사전 트레이닝 말뭉치의 중복 제거는 모델 트레이닝 동안 토큰 효율을 향상시키는 효과적인 기법인 것으로 나타났다(Lee et al., 2022; Abbas et al., 2023; Tirumala et al., 2023). 돌마를 준비할 때 URL, 문서 및 단락 수준 중복 제거의 조합을 사용합니다. 블룸 필터(Bloom, 1970)를 사용하여 선형 시간 중복 제거를 달성합니다. 우리는 동일한 서브세트의 파일들에 걸쳐 이 중복 제거를 수행하지만(_e.g._, 웹 서브세트의 모든 문서들을 중복 제거), 소스들에 걸쳐서는 수행하지 않는다(_e.g._, 임의의 웹 문서가 코드 서브세트에도 나타나는지 확인하지 않는다).\n' +
      '\n' +
      '이 섹션을 상기시키기 위해 표 1에 표시된 각 데이터 소스에 대해 위의 단계가 구현되는 방법에 대한 자세한 설명을 제공한다. 결정을 지원하기 위해 두 가지 도구를 활용한다. 먼저, WIMBD 툴(Elazar et al., 2023)을 이용하여 파이프라인의 출력을 검사한다. 이 방법을 사용하면 모델을 교육하지 않고도 문제를 효율적으로 파악할 수 있습니다.\n' +
      '\n' +
      '그런 다음 최대 1500억 토큰으로 학습 된 10억 매개 변수 디코더 전용 모델을 사용 하 여 _데이터 삭제_ 를 수행 합니다. SSD.1에서 실험 설정에 대 한 자세한 설명을 제공 합니다. 이러한 삭제를 통해 평가 모음에서 데이터 파이프라인의 결과를 비교할 수 있습니다. 평가 집합은 언어 적합성을 추정하기 위해 복잡성을 측정하는 18개의 도메인과 결과 모델의 질문 응답, 추론 및 상식 능력을 평가하는 7개의 다운스트림 태스크로 구성된다. 이 섹션을 상기시키기 위해 평가 제품군에 대한 결과의 하위 집합을 제시하며, 부록 K에 모든 실험 결과를 포함한다. 의사 결정을 내릴 때 언어 적합도보다 다운스트림 작업에서 메트릭을 최적화하는 개입을 우선시합니다.\n' +
      '\n' +
      '### Web Pipeline\n' +
      '\n' +
      '돌마의 웹 서브세트는 Common Crawl.11에서 파생된 Common Crawl은 2007년부터 크롤링된 2,500억 페이지 이상의 컬렉션이다. 스냅샷으로 구성되며, 각각 시드 URL에 대한 전체 크롤링에 해당한다. 2023년 11월, 89개의 스냅 샷이 있었습니다. 돌마는 2020-05년에서 2023-06년 사이에 수집된 25개의 스냅샷에서 선별되었다.\n' +
      '\n' +
      '각주 11: Common Crawl.org\n' +
      '\n' +
      '각주 12: § 2 - 최소 2T 토큰으로 설명 된 볼륨 목표를 충족 하기 위해 충분한 스냅숏만 사용 합니다.\n' +
      '\n' +
      '1.1 Data Acquisition and \\(\\overline{\\phantom{\\rule{0.0pt}{0.0pt}}\\phantom{\\rule{0.0pt}{0.0pt}}}\\) Language Filtering\n' +
      '\n' +
      'LLaMA(Touvron et al., 2023a)를 개발하는 데 사용되는 데이터 큐레이션 관행에 따라, 우리의 웹 파이프라인은 CCNet(Wenzek et al., 2020b)을 활용하여 언어 필터링 및 초기 콘텐츠 중복 제거를 수행한다.\n' +
      '\n' +
      '도 1: Dolma의 웹 처리 파이프라인 개요.\n' +
      '\n' +
      '이 도구는 RedPajama v1(Together Computer, 2023c) 및 RedPajama v2(Together Computer, 2023a)의 Common Crawl 서브세트에도 사용되었다. CCNet은 각 문서에 대한 기본 언어를 결정하기 위해 패스트텍스트 언어 식별 모델13으로 각 웹 페이지를 처리하며, 영어 문서 점수가 0.5 이상인 모든 페이지를 유지한다(크기별로 웹 페이지의 61.7% 제거). 또한, CCNet은 각각의 스냅샷 내의 샤드들을 작은 세트들로 그룹화하고 각각에서 복제된 단락들을 제거함으로써 매우 흔한 단락들을 식별하고 제거한다. 이 단계는 주로 헤더와 탐색 요소로 구성된 문단의 약 70%를 제거했다. 전체적으로 CCNet 파이프라인은 175.1 TB에서 27.7 TB로 Common Crawl의 콘텐츠의 84.2%를 필터링합니다. 더 자세한 내용은 부록 J.4에 나와 있다.\n' +
      '\n' +
      '각주 13: [https://fasttext.cc/docs/en/language-identification.html](https://fasttext.cc/docs/en/language-identification.html)\n' +
      '\n' +
      '#### 3.1.2 Quality Filtering\n' +
      '\n' +
      '웹 크롤링된 데이터는 언어 모델 사전 훈련에 사용되기 전에 상당한 정리가 필요하다. 이 단계는 HTML에서 일반 텍스트(_e.g._, 페이지 헤더, 비정형 텍스트)로의 변환에 의해 도입된 아티팩트를 제거하고, 충분한 "prose-like" 텍스트(_e.g._, 반복 텍스트, 짧은 세그먼트)를 포함하지 않는 페이지를 폐기한다. 첫째, CCNet은 기본적으로 KenLM(Heafield, 2011)의 복잡성을 이용하여 문서를 Wikipedia-likeness를 기반으로 버킷으로 묶는 품질 필터를 제공하며, 이 버킷은 높은(21.9%), 중간(28.5%) 또는 낮은(49.6%) 품질 컨텍스트로 해석되는 경우가 많다. 그러나 모델 기반 품질 필터에 대해 Rae 등(2021) 및 Almazrouei 등(2023)에서 제기된 인수에 따라 이러한 버킷 사이에 배포된 콘텐츠에 대한 자체 수동 검사뿐만 아니라 이러한 CCNet 품질 점수를 사용하지 않기로 결정했다. 대신, Dolma에서는 Gopher(Rae et al., 2021)와 C4(Raffel et al., 2020)에 의해 소개된 휴리스틱을 결합하여 품질 필터링을 달성한다. 구체적으로, 우리는 모든 고퍼 규칙(이하, 고퍼 All)을 유지하고 구두점으로 끝나지 않는 단락(C4 NoPunc; C4 A11과 반대로)을 제거하도록 설계된 C4로부터 단일 휴리스틱을 유지한다. 부록 J.4에 제공된 필터링 규칙에 대한 자세한 설명.\n' +
      '\n' +
      '그림 2에 표시된 절제 결과는 필터링 전략을 검증한다. 우리는 C4 NoPunc 자체가 복잡성과 다운스트림 작업 모두에서 C4 All과 고퍼 All을 능가한다는 것을 발견했다. 마지막으로 고퍼 올 + C4 NoPunc을 결합하면 최고의 성능을 제공합니다. 전체적으로 고퍼 규칙은 제거를 위해 UTF-8 문자의 15.23%를 태깅한 반면 C4 규칙은 제거를 위해 문자의 22.73%를 태깅했다. 우리의 휴리스틱과 CCNet의 품질 점수를 비교할 때, 필터링 후 남은 문서는 높은(22.8%), 중간(26.2%) 및 낮은(51.0%) 품질의 CCNet 버킷에 속하여 모델과 휴리스틱 기반 품질 필터 사이의 상관 관계가 거의 나타나지 않는다.\n' +
      '\n' +
      'Elazar et al.(2023)의 도구를 사용하여 반복된 \\(n\\)-gram의 발생에 대해 필터링된 데이터 세트를 검사한다. 고퍼 및 C4 규칙을 사용한 필터링에도 불구하고, 우리는 여전히 \'-\'의 반복된 시퀀스, 6천만 번 이상 발생하는, 또는 \'bla\'의 반복된 시퀀스, 1910만 번 발생하는, 바람직하지 않은 텍스트를 발견했다(표 2 참조). 이를 기반으로 \\(n\\)-gram 휴리스틱을 구현하여 이러한 시퀀스가 포함된 문서를 식별하고 제거하며, 특히 100 UTF-8자 이상의 반복된 시퀀스를 제거한다. 이는 전체 문자의 0.003%만 제거했다.\n' +
      '\n' +
      '그림 2: 웹 처리 파이프라인의 품질 필터에 대한 모델 제거. 우리는 C4와 Gopher 규칙의 조합이 언어 적합도(왼쪽, Paloma의 _C4 100 Domains_ 서브세트(Magnusson et al., 2023)) 및 다운스트림 성능(오른쪽, HellaSwag Zellers et al.(2019)) 둘 다의 개선으로 이어진다는 것을 발견한다.\n' +
      '\n' +
      'dataset, 이들 문서의 제거는 Scao 등(2022)에서 경험적으로 발견된 바와 같이 훈련 동안 손실 스파이크를 방지할 수 있다. 우리는 또한 이것이 데이터 세트에 많은 반복된 시퀀스를 남기는 상당히 보수적인 휴리스틱이라는 점에 주목했다; 우리는 이러한 시퀀스의 수동 검사로부터 종종 불규칙성을 구문 분석하는 것과는 대조적으로 웹페이지 레이아웃 요소로 기능한다는 것을 발견했다.\n' +
      '\n' +
      '각주 14: github.com/bigscience-workshop/bigscience/blob/master/train/tr8-104B-wide/chronicles.md\n' +
      '\n' +
      '#### 3.1.3 Content Filtering\n' +
      '\n' +
      '인터넷으로부터 샘플링된 필터링 Toxic ContentData는 유해 또는 독성 콘텐츠를 포함할 수 있다(Matic et al., 2020; Luccioni and Viviano, 2021; Birhane et al., 2023, 2023). SS 2에서 강조했듯이 독성 콘텐츠에 대한 언어 모델을 훈련하여 발생할 수 있는 피해를 줄이기 위해 돌마를 필터링한다. 우리는 레이블이 지정되지 않은 주석과 함께 (다중 라벨) 카테고리 "독성", "심각한 독성", "위협", "인솔", "악성", 및/또는 "정체성 혐오"로 태깅된 포럼 주석을 포함하는 Jigsaw Toxic Comments 데이터세트(cjadams et al., 2017)를 사용하여 두 개의 fastText 분류기 - 바이너리 "증오" 검출기 및 바이너리 "NSFW" 검출기를 훈련시켰다:\n' +
      '\n' +
      '1. "증오" 디텍터의 경우 레이블이 지정되지 않은 모든 주석과 "음란" 전용 주석을 음성으로 그룹화하고 나머지 주석을 양성으로 남깁니다.\n' +
      '2. 우리의 "NSFW" 검출기의 경우, 우리는 "음란물"로 태깅된 모든 코멘트를 긍정으로 취하고 다른 나머지 코멘트를 부정으로 남긴다. 이 디텍터는 일반적으로 성적 콘텐츠가 아닌 성적 또는 음란한 토픽을 언급하는 _독성 콘텐츠_만 필터링한다는 점에 유의하는 것이 중요합니다.\n' +
      '\n' +
      '이 두 모델에 대해 수동 임계값 튜닝을 기반으로 0.40의 필터링 임계값을 사용하여 공통 크롤 문장 15에서 실행한다. 제안된 임계치는 (1) Common Crawl의 스냅샷에서 예측된 독성 문장을 검사하여 정확도와 재현율을 최대화하는 것과 (2) 너무 많은 데이터 제거를 최소화하는 것 사이의 균형을 찾는 임계값을 선택했다. 16 우리는 항상 전체 문서가 아닌 독성 문장으로 태깅된 범위만 제거한다. 우리는 이 두 모델을 공개적으로 사용할 수 있도록 만듭니다.\n' +
      '\n' +
      '각주 15: BlingFire 문장 분할기(Microsoft, 2019)를 사용하여 식별.\n' +
      '\n' +
      '각주 16: 예를 들어, "증오" 및 "NSFW" 검출기는 0.0004 및 0.00017의 임계치에서 공통 크롤로부터 토큰의 34.9% 및 29.1%를 필터링한다.\n' +
      '\n' +
      '각주 17: "NSFW" fastText 태거 및 "증오" fastText 태거.\n' +
      '\n' +
      '그림 3에서 우리는 "증오" 및 "NSFW" 검출기에 대한 두 가지 다른 임계값의 효과를 비교한다. "높은 임계값" 구성은 _less_ 콘텐츠를 제거하지만 일반적으로 평가 집합에서 더 높은 복잡성과 더 낮은 다운스트림 성능을 생성합니다. "낮은 임계치" 구성은 더 많은 콘텐츠를 제거하고 일반적으로 더 높은 성능을 갖지만, 텍스트의 더 많은 단위("증오" 및 "NSFW" UTF-8 문자에 대해 각각 7.3% 대 34.9% 및 5.5% 대 29.1%)를 제거한다. 낮은 임계값은 잘못된 긍정으로 이어질 수 있고 콘텐츠 필터와 품질 및 중복 제거 필터를 결합하여 향상된 성능을 달성할 수 있기 때문에 "증오" 및 "NSFW" 필터의 "높은 임계값" 버전을 사용하여 점수가 0.4 이상인 문장을 제거한다.\n' +
      '\n' +
      '인터넷에서 샘플링된 개인 식별 정보 데이터를 필터링하면 사용자의 개인 식별 정보(PII)도 유출될 수 있다(Luccioni and Viviano, 2021; Subramani et al., 2023); 이러한 PII는 대규모 데이터 세트(Elazar et al., 2023).\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l} \\hline \\hline Repeated \\(n\\)-gram sequence \\\\ \\hline\n' +
      '******************************************************************** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: WIMBD 툴을 통해 식별된 웹 서브세트에서 공통 반복 \\(n\\)-gram 시퀀스의 예(Elazar et al., 2023). 여기에 표시된 서열보다 더 긴 반복 서열은 WIBMD에 의해 식별된 후 제거되었다.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:9]\n' +
      '\n' +
      '2. _정확한 문서 중복 제거_: 동일한 텍스트를 포함하는 페이지 표시입니다. 구두 부호나 공백이 제거되지 않습니다. 빈 문서는 중복으로 간주됩니다. 전체적으로 URL 중복 제거 후 문서의 14.9%를 추가로 제거합니다.\n' +
      '3. _정확한 단락 중복 제거_: 페이지 간에 동일한 단락을 중복으로 표시 합니다. 이 단원의 정의는 이전 필터와 일치하며, 단락은 새로운 UFT-8 문자 "\\(\\backslash\\)n"으로 분리된 텍스트의 범위이다. 전반적으로 이 필터는 반복된 URL 중복 제거된 세트의 문서의 18.7%를 태그한다.\n' +
      '\n' +
      '이러한 다단계 접근법은 효율성을 증가시키기 위해 설계된다: 단계들 (i) 및 (ii)은 동일한 아이템의 복사본들을 제거하도록 설계된다(동일한 페이지들이 다수의 URL들을 가질 수 있고, 그러한 경우 동일한 뉴스 기사가 다수의 온라인 신문에 포함되는 경우), 따라서, 임의의 콘텐츠 또는 품질 필터링 전에 실행될 수 있어서, 처리될 페이지들의 수를 감소시킨다. 대조적으로, 스테이지(iii)는 (동일한 저자에 의해 작성된 모든 기사 아래에 나타나는 동일한 바이라인과 같은) 상이한 페이지 상에 나타나는 반복된 콘텐츠를 제거하여, 페이지의 일부를 변경하고 잠재적으로 콘텐츠 분석을 방해한다. 모든 스테이지는 효율적인 컨텐츠 중복 제거를 위해 Bloom 필터(Bloom, 1970) 데이터 구조를 사용한다.\n' +
      '\n' +
      '#### 3.1.5 Putting It All Together\n' +
      '\n' +
      '파이프라인 단계는 어떻게 구성되나요?요약하면 Dolma 웹 파이프라인은 먼저 URL 및 문서 수준 중복 제거를 수행한 다음 품질 필터링(고퍼, C4 NoPunc), 콘텐츠 필터링(독성 콘텐츠, PII) 및 마지막으로 단락 수준 중복 제거를 수행하여 CCNet의 출력을 변환합니다. 그러나 필터링의 결합된 결과는 무엇입니까?\n' +
      '\n' +
      '그림 5에서 우리는 파이프라인의 단계에 따른 복합 효과를 보여준다. 세 단계의 조합이 다운스트림 태스크에서 최상의 성능을 달성하는 반면 콘텐츠 필터링은 C4 100 도메인 서브세트의 언어 적합도를 약간 손상시킨다는 것을 발견했다. SS2에서 설명한 대로 다운스트림 평가 작업을 활용하여 결정을 내립니다. 따라서 Dolma를 만들 때 파이프라인에 있는 모든 단계를 사용합니다.\n' +
      '\n' +
      '그림 4: PII 전략에 대한 1B 모델 절제. PII로 모든 문서를 제거하는 것과 \\(\\geq 5\\) PII 인스턴스가 있는 문서만 제거하고 나머지를 마스킹하는 것, PII 필터링을 전혀 수행하지 않는 것 사이에 식별 가능한 차이가 없음을 발견했다.\n' +
      '\n' +
      '그림 5: 1B 모델 삭제에 대한 품질 필터링, 내용 필터링 및 단락 수준 중복 제거의 복합 효과. 파이프라인에서 모든 구성 요소의 조합은 언어 적합도(왼쪽, Paloma의 _C4 100 Domains_ 하위 집합(Magnusson 등, 2023))와 다운스트림 성능(오른쪽, HellaSwag Zellers 등(2019)) 모두의 개선으로 이어집니다.\n' +
      '\n' +
      '데이터 배포는 Elazar et al.(2023)의 도구를 사용하여 그림 6의 최종 데이터 구성을 검사한다. 특히 웹 도메인, 연도 및 언어 배포를 분석한다.\n' +
      '\n' +
      '우리는 돌마가 주로 2020년, 2022년, 2021년의 광범위한 인터넷 도메인들의 문서들을 포함하고 있다는 것을 주목한다. 돌마의 가장 흔한 인터넷 도메인들은 토큰당 특허.google.com이고, 그 다음이 www.nature.com 및 www.frontiersin.org이다. 실제로 Elazar 등(2023)에 보고된 다른 코퍼라와 유사하게, 돌마의 웹 문서들의 63.6%가 \'.com\' 사이트들(그 다음이 \'.org\' 및 \'.co.uk\' 사이트들)에 있다. 마지막으로, 모든 언어 식별 도구가 불완전하기 때문에 영어 전용 필터링 후 남은 언어는 무엇인지 요약한다. 영어가 잘 식별되지 않은 경우(\'un\')가 0.86%로 가장 많았고, 다음으로 중국어로 식별된 문서가 0.06%로 나타났다.\n' +
      '\n' +
      '품질 및 콘텐츠 필터가 유사한 영향을 미치나요? SS3.1.2 및 SS3.1.3에 설명된 필터가 서로 상호 작용하는 방식을 더 이해하기 위해 파이프라인에서 샘플링된 문서의 하위 집합에 대한 상관 분석을 수행합니다.\n' +
      '\n' +
      '커먼 크롤 필터에 의해 제거되는 문서 간의 상관 관계는 그림 7에 나와 있다. 우리는 상관 관계가 일반적으로 낮기 때문에 필터가 상당히 다른 문서를 선택하고 중복되지 않는다는 것을 발견했다. PII(Personal Identifiable Information) 필터와 혐오 발언을 제거하는 필터 사이에는 약간의 양의 상관관계가 있다. 혐오 발언이 사람을 향한 경우가 많기 때문일 것이다. 고퍼 필터링 규칙은 특히 데이터의 복잡도가 높은 꼬리 부분에 대해 중복 제거와 음의 상관관계가 있다. 이는 고퍼 규칙이 무작위 문자열과 같은 많은 복잡도가 높은 문서를 제거하는 데 기인하며, 이는 무작위성으로 인해 중복 제거에 걸리지 않는다. 이러한 무작위 문자열은 언어에 대한 더 나은 이해에 기여하지 않을 가능성이 높기 때문에 이를 필터링하여 중복 제거를 초과하는 필터에 의존하는 것이 중요하다.\n' +
      '\n' +
      '그림 6: 내 빅 데이터에서 무엇을 사용하여 계산된 다른 문서 메타데이터에 대한 빈도 tool from Elazar et al. (2023). 하위 그림 (c)에서 un은 언어를 식별할 수 없는 문서를 나타내며, long는 도구의 언어 ID 모듈로 처리하기에는 너무 긴 문서를 나타냅니다.\n' +
      '\n' +
      '그림 7: 공통 크롤 데이터의 머리, 중간 및 꼬리 부분에 대한 필터의 피어슨 상관 관계. 상관 관계는 각각 24M, 20M 및 43M 문서에 대해 계산됩니다. 필터는 Gopher=Gopher rules from Rae et al. (2021), Dedup.= 중복제거, PII=개인식별정보, Hate=Hate Speech and Decont.= 오염 제거\n' +
      '\n' +
      '#### 3.2.1 Data Acquisition and \\(\\overline{\\top}\\) Language Filtering\n' +
      '\n' +
      '허용 되는 라이선스 GitHub 리포지토리의 컬렉션인 **The Stack** (Kocetkov et al., 2022)에서 Dolma의 코드 하위 집합을 유도 합니다. 우리는 거의 중복 제거된 버전을 시작점으로 사용하여 중복 제거를 직접 수행할 필요성을 제거한다. 이 데이터 세트의 원시 버전은 2023년 3월에 수집되었습니다. JSON 및 CSV와 같은 확장자가 있는 파일을 제거하여 데이터가 많은 문서를 필터링합니다.\n' +
      '\n' +
      '#### 3.2.2 Quality Filtering\n' +
      '\n' +
      'RedPajama v1(Together Computer, 2023c) 및 StarCoder(Li et al., 2023) 데이터셋으로부터 유도된 휴리스틱을 적용한다. 전자는 라이센스 문(22) 및 지나치게 긴 줄 또는 대부분 수치화된 내용을 가진 문서와 같은 반복적인 파일 프리앰블을 제거하기 위한 규칙으로 구성된다. 전반적으로, RedPajama 규칙(RPJ)은 대부분 데이터이거나 템플릿을 통해 생성된 파일을 제거하도록 설계된다. 고품질 코드 조각을 추가로 선택 하기 위해 StarCoder 파이프라인에서 규칙을 활용 합니다. 이러한 휴리스틱 필터는 별이 없거나 적은 GitHub 리포지토리, 코멘트가 너무 적거나 많은 파일 및 코드 대 텍스트 비율이 낮은 HTML 파일을 필터링 합니다. 이 규칙에 대한 자세한 설명은 SSJ.4를 참조하십시오.\n' +
      '\n' +
      '각주 22: 우리는 이 정보를 돌마의 각 문서와 연관된 메타데이터에 유지한다.\n' +
      '\n' +
      '그림 9에서는 RedPajama(RPJ)와 StarCoder 규칙의 비교를 제시한다. 그 결과, RPJ 규칙과 StarCoder의 결합으로 인해 코드 데이터셋에 대한 복잡도가 낮아지고(_e.g._, HumanEval; Chen et al., 2021b), 비코드 테스트 셋에 대한 훈련 중 더 안정적인 복잡도(_e.g._, _C4 100 Domains_ subset of Paloma; Magnusson et al., 2023), 개선된 다운스트림 성능(_e.g._, HellaSwag; Zellers et al., 2019)이 향상됨을 알 수 있었다. 따라서 우리는 돌마에 대한 최종 믹스를 만들 때 이 조합을 사용하기로 선택했다.\n' +
      '\n' +
      '도 8: 코드 문서를 처리하기 위한 데이터 파이프라인의 개요.\n' +
      '\n' +
      '도 9: RedPajama 규칙(RPJ) 규칙 또는 RPJ와 StarCoder 규칙을 조합한 것을 사용할 때의 품질 필터링 비교. 두 규칙 세트를 결합하면 코드 문서(왼쪽, HumanEval; Chen et al., 2021b), 비-코드 테스트 세트(팔로마; Magnusson et al., 2023)의 _C4 100 Domains_ 서브세트 상의 보다 안정적인 복잡도 곡선 및 약간 개선된 다운스트림 성능(오른쪽, HellaSwag; Zellers et al., 2019)을 얻을 수 있다.\n' +
      '\n' +
      '#### 3.2.3 Content Filtering\n' +
      '\n' +
      '웹 파이프라인(SS 3.1)에서 개인 식별 정보를 마스킹하기 위해 동일한 필터링 규칙을 적용한다. PII 인스턴스가 5개 이상인 문서는 돌마에서 제거됩니다. 다른 모든 인스턴스에서 전자 메일, 전화 번호 및 IP 주소는 특수 토큰을 사용하여 마스킹됩니다.\n' +
      '\n' +
      '또한 코드 비밀이나 개인 정보를 제거합니다. 이를 위해 탐지-비밀(Yelp, 2013) 라이브러리를 사용하고 일치하는 문서를 제거한다.\n' +
      '\n' +
      '#### 3.2.4 Deduplication\n' +
      '\n' +
      '우리는 Koccetkov et al.(2022)에 의해 발표된 The Stack의 이미 중복 제거된 버전을 사용했으며, 그들의 접근법은 MinHash Broder(2002)와 Locally Sensitive Hashing을 사용하여 유사한 문서를 찾는 Allal et al.(2023)에 의해 처음 도입된 파이프라인을 사용한다.\n' +
      '\n' +
      '### 대화형 포럼 파이프라인\n' +
      '\n' +
      '3.1 데이터 획득 및 \\(\\overline{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{\\mathsf{}}}}}}}}}}\\) 언어 필터링\n' +
      '\n' +
      'Dolma의 대화 하위 집합은 Reddit의 데이터 API를 통해 수집되고 푸시시프트 프로젝트에 의해 배포되는 대규모 포럼 대화 모음인 **Pushshift Reddit 데이터 세트**(Baumgartner 등, 2020)에서 파생되었습니다. 우리는 2005년 12월부터 2023년 3월까지 Reddit의 378M 게시물에서 Dolma의 대화 부분 집합을 도출한다. 우리는 Reddit에 대한 대화에 초기 메시지인 _submissions_와 메시지에 대한 회신인 _comments_를 데이터 세트에 포함한다. 우리는 모든 제출과 댓글을 쓰레드에 대한 구조나 연결 없이 독립적인 문서로 취급하며, 우리의 평가에서 이 단순화된 표현은 다운스트림 작업에서 더 나은 성능을 산출한다. 이 절충안에 대한 논의는 부록 E에 나와 있다.\n' +
      '\n' +
      '일관성을 위해 웹 파이프라인과 동일한 전략을 사용하여 영어 콘텐츠가 아닌 콘텐츠를 필터링합니다. 특히, 우리는 0.5보다 큰 영어 점수로 제출과 코멘트를 유지합니다.\n' +
      '\n' +
      '#### 3.3.2 Quality Filtering\n' +
      '\n' +
      '대화 포럼 데이터는 너무 짧거나 반복적이거나 제출된 커뮤니티에 의해 부정적으로 순위가 매겨진 콘텐츠를 제거하려면 적절하게 정리되어야 한다. Henderson et al.(2019)이 소개한 파이프라인을 이용하여 Google Dataflow23을 이용하여 댓글과 댓글의 정리가 용이하도록 하였다. 500자보다 짧은 댓글과 400자24보다 짧은 댓글을 제거하였다. 또한 40,000자 이상의 문서를 제거하였다.\n' +
      '\n' +
      '각주 23: [https://cloud.google.com/dataflow](https://cloud.google.com/dataflow)\n' +
      '\n' +
      '각주 24: 데이터의 정성적 검사는 제출이 논평보다 더 고품질임을 시사했으며 따라서 우리는 더 허용 가능한 최소 길이를 사용한다.\n' +
      '\n' +
      '도 10: 대화 포럼을 처리하기 위한 데이터 파이프라인의 개요.\n' +
      '\n' +
      '낮은 점수가 대화 스레드에 깊게 내포된 코멘트(Weninger 등, 2013) 또는 감정적으로 충전된 담화를 초래할 가능성이 더 높은 콘텐츠(Davis and Graham, 2021)와 연관되기 때문에, 3표25 미만의 코멘트를 제거한다. 투표들은 WebText(Radford et al., 2019) 및 OpenWebText(Peterson, 2020) 코포라를 구성하는데 신호로서 사용되어 왔다. 우리는 저자가 삭제하거나 중재자가 제거한 문서를 폐기하고, 또한 저자가 _"18" 이상_이라고 레이블을 붙인 문서도 제거했다. 우리는 우리가 선별한 26,123개의 금지되고 안전하지 않은 작업에서 유래한 문서를 제외한다.\n' +
      '\n' +
      '각주 25: 각 문서에 대한 총 득표는 "상표", 부정 득표 또는 "하표"로도 알려진 포지티브 득표 간의 차이를 계산함으로써 얻어진다.\n' +
      '\n' +
      '각주 26: 목록은 [https://github.com/allenai/dolma/blob/main/sources/reddit/atomic_content_v5/subreddit_blocklist.txt](https://github.com/allenai/dolma/blob/main/sources/reddit/atomic_content_v5/subreddit_blocklist.txt)에서 사용할 수 있습니다. 그 목록은 금지된 서브레딧(대부분 레딧 자체의 게시물에서)을 추적한 여러 소스를 병합하여 얻었다. 또한 NSFW로 태그된 하위 레딧 내의 게시물 비율을 측정하고 이 비율이 10%를 초과할 때 하위 레딧을 차단했다.\n' +
      '\n' +
      '#### 3.3.3 Content Filtering\n' +
      '\n' +
      '웹 파이프라인(SS 3.1.3)에서 사용되는 것과 동일한 필터링 규칙을 적용하여 독성 콘텐츠를 제거하고 PII를 마스크한다. 웹 파이프라인의 경우와 달리 문서의 일부가 독성으로 태깅되면 문서를 완전히 제거한다. 레딧의 내용은 길이가 더 짧기 때문에 독성으로 분류된 단일 문장이 전체 문서도 독성을 나타내는 강력한 표시일 가능성이 더 높기 때문에 이 전략을 사용한다.\n' +
      '\n' +
      '#### 3.3.4 Deduplication\n' +
      '\n' +
      '웹 파이프라인(SS 3.1.4)에서 사용된 것과 동일한 전략을 사용한다. 제출 및 논평은 웹 문서보다 짧기 때문에 문서 수준에서만 중복 복제한다. 이 전략은 "_복사 파스타_"(코믹 효과를 위해 많은 코멘트 및 서브레딧에 걸쳐 종종 반복되는 텍스트 블록) 및 기타 반복 정보의 발생률을 감소시키는 데 유용하다.\n' +
      '\n' +
      '### 기타 데이터 원본\n' +
      '\n' +
      '이 절에서는 돌마를 도출하기 위해 사용된 추가 고품질 출처를 간략하게 요약한다. 수집 및 처리에 대한 자세한 내용은 부록 S.3 및 S.4를 참조하십시오.\n' +
      '\n' +
      '**C4 for Curated Web Content** LLaMA(Touvron et al., 2023)와 마찬가지로 C4 Raffel et al.(2020)의 문서를 Dolma 데이터 세트에 포함합니다. 우리는 웹 파이프라인을 통해 이 데이터를 재처리하여 길고 반복되는 시퀀스(SS 3.1.2)와 중복(SS 3.1.4)을 제거함으로써 이 데이터를 더욱 정제한다. 마지막으로, (SS 3.1.3)에 설명된 바와 같이 PII 마스킹을 또한 수행한다;\n' +
      '\n' +
      '**학술 문헌을 위한 PeS2o** PeS2o 데이터 세트(Soldaini 및 Lo, 2023)는 언어 모델의 사전 교육을 위해 정리, 필터링 및 형식이 지정된 약 4천만 개의 오픈 액세스 학술 논문 모음입니다. S2ORC(Semantic Scholar Open Research Corpus)로부터 도출된다(Lo 등, 2020). 이 데이터 세트는 언어 모델링 목적으로 작성되었기 때문에 그대로 사용합니다.\n' +
      '\n' +
      '**책용 프로젝트 Gutenberg** 프로젝트 Gutenberg는 7만 권 이상의 공용 도메인 책을 보관하는 저장소입니다. 2023년 4월 프로젝트 구텐베르크의 아카이브를 수집하였다. 동일한 fastText 기반 언어 식별 모델을 사용하여 영어 책을 식별하여 돌마에 포함시켰다. 데이터 시트 SS J의 자세한 내용입니다.\n' +
      '\n' +
      '**백과사전 콘텐츠를 위한 위키백과 및 위키북** 이 데이터 세트는 2023년 3월 Wikimedia 덤프에 의해 파생되었습니다. 우리는 위키피디아와 위키북의 "영어"와 "단순" 판본을 돌마의 백과사전 하위 집합의 기반으로 사용한다. 소스는 WikiExtractor27을 사용하여 처리되었다. 25개 이하의 UTF-8 세그먼트가 있는 문서를 제거하는데, 짧은 템플릿 페이지(_e.g._, 몇 개의 단어와 정보 상자만 포함된 페이지) 또는 XML 구문 분석 오류로 인해 더 짧은 페이지가 발견되었기 때문이다.\n' +
      '\n' +
      '각주 27: github.com/attardi/wikiextractor, v. 3.0.7, 커밋 접두사 8f1b434.\n' +
      '\n' +
      '돌마에 대한 언어 모델 학습\n' +
      '\n' +
      'Dolma 파이프라인의 최종 유효성 검사 단계로 **Olmo-1b** 라고 하는 디코더 전용 자기 회귀 언어 모델을 훈련, 평가 및 릴리스 합니다. 이 섹션에서는 모델 훈련과 관련된 추가 데이터 세트 큐레이션 결정에 대한 잠재적인 접근법에 대해 논의한다. SS 4.1에서는 돌마에서 벤치마크 작업(_i.e._, 오염 제거)을 제거하는 방법을 제시한다. 그런 다음 SS4.2에서는 최종 사전 훈련 코퍼스를 얻기 위해 돌마의 다양한 문서 하위 집합을 결합할 때 고려해야 할 사항에 대해 논의한다. 마지막으로 SS4.3에서 결과 **Olmo-1b** 모델의 실험 결과를 제시한다. **Olmo-1b** 는 GPT-NeoX 토큰화기 (Black 등, 2022)를 사용 하 여 Dolma에 적합 한 것으로 확인 되었으며, 부록 F에서 결정을 지원 하는 결과를 제시 합니다.\n' +
      '\n' +
      '### Dolma에서 벤치마크 오염 제거 전략\n' +
      '\n' +
      '이 섹션에서는 사전 교육에서 벤치마크 오염을 제거 하는 방법을 실험 하 고 궁극적으로 **Olmo-1b** 에서 사용 되는 것을 선택 합니다. 대규모 언어 데이터세트는 언어 모델을 평가하는 데 일반적으로 사용되는 벤치마크의 사본을 포함한다(Dodge et al., 2021; Yang et al., 2023; Elazar et al., 2023). 그러한 오염의 영향은 현재 논의되고 있다. 예를 들어, Lee 등(2022)은 C4 사전 트레이닝으로부터 검증 데이터의 중복을 제거하는 것이 이전에 복제된 검증 데이터에 대한 복잡성을 증가시킨다는 것을 보여주었다. 한편, 오염된 다운스트림 데이터와 오염되지 않은 다운스트림 데이터 사이의 사후 성능 차이를 조사하는 작업은 일관된 긍정적 또는 부정적 영향을 발견하지 못한다(Chowdhery et al., 2022; Brown et al., 2020; OpenAI, 2023). 먼저, 복잡성 벤치마크 오염 제거에 초점을 맞추고 다운스트림 작업 오염 정도를 측정한다. 우리는 다양한 소스에 대한 언어 모델 적합성을 평가하기 위해 설계된 585개의 텍스트 도메인의 벤치마크인 팔로마(마그누손 등, 2023)의 초기 버전과 관련하여 오염을 제거하는 실험을 한다. 당혹성 평가의 이러한 선택은 부록 D에 자세히 설명되어 있다.\n' +
      '\n' +
      '당혹성 평가를 위한 오염 제거 전략은 SS 3.1.4에 설명된 단락 중복 제거 도구를 사용하여 (_i_)가 13 유니코드 세그먼트 토큰28보다 길고 (_ii_) 팔로마 문서에 나타나는 경우 돌마의 모든 단락을 오염된 것으로 표시한다. 팔로마 초기 버전에 대한 C4(Raffel 등, 2020) 오염 제거에 대한 예비 실험에서 위에서 설명한 단락 기반 오염 제거 기술을 정확하게 일치하는 전체 문서와 비교한다. 결과 문서 기반 오염 제거는 12개의 하위 집합 중 1개만 오염 문서 29가 1% 이상인 낮은 일치율을 보였다. 그러나 문단 기반 오염 제거 작업을 고려할 때 12개의 복잡성 작업 중 6개가 1% 이상의 오염 문서를 가지고 있다. 후자는 예상 오염률을 더 잘 반영하기 때문에 이 섹션을 상기시키기 위해 선택했다.\n' +
      '\n' +
      '각주 28: Elazar 등(2023)에서와 같이, 우리는 거짓 양성 일치들을 피하기에 충분한 길이의 단락만을 고려한다.\n' +
      '\n' +
      '각주 29: _C4 100 도메인_ 하위 집합으로, C4에서 직접 구성됩니다.\n' +
      '\n' +
      '마지막으로 오염을 제거하는 두 가지 방법을 고려합니다. C4에 대한 예비 실험에서 문서에서 제외하여 오염된 단락만 제거하면 토큰이 0.01% 제거되고 오염이 있는 전체 문서를 제거하면 토큰이 0.02% 제거된다는 것을 발견했다. 두 경우 모두 문서의 0.01%가 영향을 받습니다. 각각 상대적으로 작은 영향을 미친다는 점을 감안할 때, 우리는 읽기 순서를 방해하는 것을 피하기 위해 전체 문서를 제거하는 것을 선택하지만, 이는 더 긴 문서를 제거하는 쪽으로 편향된다.\n' +
      '\n' +
      '당혹성 평가를 위한 오염 제거 결과 오염 제거 접근법의 위험을 평가하기 위해 실험 당시 돌마의 의도된 구성과 가장 유사한 말뭉치인 RedPajama v1(Together Computer, 2023c)의 221B 토큰 하위 집합에 2개의 1B 매개변수 모델 30개를 훈련한다. 첫 번째 모델은 RedPajama v1에 대해 그대로 훈련되고 두 번째 모델은 위에서 설명한 단락 일치, 문서 제거 오염 제거 접근법 후에 동일한 코퍼스를 사용한다. 이 하위 집합에서 오염 제거 접근법은 유니코드 토큰의 2.17%와 문서의 0.66%를 제거한다. 표 3에서 우리는 당혹감과 다운스트림 과제 수행의 차이가 미미하고 일관되게 긍정적이거나 부정적인 경향이 없음을 보여준다. 복잡성의 경우 7개의 소스가 저하되고 6개가 개선되며, 다운스트림 작업의 경우 5개가 저하되고 4개가 개선된다. 복잡성 소스에서 가장 큰 열화는 펜 트리 은행에서 22.0에서 22.3이다. 다운스트림 작업에서 가장 큰 열화는 SCIQ에서 1.5% 정확도가 84.8%로 떨어지는 것이다. 결론적으로, 결과는 오염 제거와 함께 성능 저하에 대한 일관된 증거를 보여주지 않는다.\n' +
      '\n' +
      '올모-1b의 오염 제거.우리의 실험이 벤치마크 오염을 제거하기 위한 접근법을 약화시켰기 때문에 돌마에 대해 훈련된 모델에 적용한다. 팔로마와의 중첩을 제거하기 위한 최종 접근법은 매그누슨 등(2023)에 자세히 설명되어 있다. 이 섹션에서는 구두점, 공백 및 이모지로만 구성된 중복을 무시하는 필터를 추가하여 이 섹션에서 논의된 단계를 적용합니다. 이러한 유형의 토큰은 텍스트 포맷팅에서 임의로 반복될 수 있으며, 이는 우리의 13-그램 임계치보다 큰 공통 n-그램으로 이어진다. 올모-1b를 학습하기 위해 사용된 최종 돌마 말뭉치에서는 오염된 학습 데이터에서 0.001% 미만의 문자를 찾고 문서의 0.02% 미만을 제거한다.\n' +
      '\n' +
      '하류 작업의 오염 가능성을 측정합니다. 돌마의 데이터 오염을 측정합니다. 우리는 WIMBD Elazar 등(2023)의 동일한 설정을 따르고, 단일 문서에서 발견될 수 있는 두 개 이상의 입력(예를 들어, 자연어 추론)을 갖는 태스크들로부터 인스턴스들의 퍼센티지를 계산한다. 이것은 돌마에서 정확한 일치 오염의 상한선 역할을 한다. 우리는 PromptSource Bach et al.(2022)의 82개의 데이터셋을 고려하고, 그들의 테스트 세트의 최소 5%가 Dolma에서 발견될 수 있다는 데이터셋을 보고한다. 우리는 그림 11에 결과를 보고한다.\n' +
      '\n' +
      '결과는 PromptSource의 데이터 세트의 일부가 돌마에 나타남을 나타낸다. WINograd Schema Challenge Levesque et al. (2012), Sick Marelli et al. (2014), GLUE Wang et al. (2018), SemEval (구체적으로 Task 1 from 2014), SuperGLUE Roemmele et al. (2011), SuperGLUE Wang et al. (2019)의 COPA, AX\\({}_{b}\\)(진단 태스크) 등 6개의 데이터 세트가 완전히 오염되었다. 또한, 다른 데이터 세트는 대부분 오염되어 있으며, 이들의 테스트 세트의 90% 이상이 돌마 문서: OpenAI HumanEval Chen 등(2021), SuperGLUE Pilchvar and Camacho-Collados(2019), ESNLI Camburu 등(2018), SNLI Bowman 등(2015)에 나타난다. 오염된 데이터 세트는 모델 평가에 사용하는 다운스트림 작업(_c.r.f._ 부록 D)에서 제외되었다.\n' +
      '\n' +
      '### Dolma를 사용한 하위 집합 혼합 및 업샘플링 전략\n' +
      '\n' +
      '거의 모든 대규모 언어 모델의 사전 훈련 말뭉치와 마찬가지로 돌마는 다중 소스 데이터 세트이다. 따라서 돌마에 대한 훈련은 각 데이터의 양을 결정하는 혼합 전략이 필요하다.\n' +
      '\n' +
      '도 11: PromptSource Bach 등(2022)으로부터의 데이터 세트의 오염 백분율.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c} \\hline \\hline  & **Avg** ppl & **Largest subset** & **Avg** acc & **Largest acc diff** \\\\  & **over subsets** & **ppl diff** & **on end tasks** & **on end task** \\\\  & (\\(\\downarrow\\)) & (ptB \\(\\downarrow\\)) & (\\(\\uparrow\\)) & (sciq \\(\\uparrow\\)) \\\\ \\hline\n' +
      '**제염** & 25.6 & 22.3 & 59.2 & 84.8 \\\\\n' +
      '**제염되지 않음** & 25.7 & 22.0 & 56.37 & 86.3 \\\\\n' +
      '**Difference** & -0.1 & 0.3 & 2.8 & -1.5 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: RedPajama v1(Together Computer, 2023c)에서 훈련된 1B 모델에 대한 오염 제거 접근법의 유무에 따른 성능 차이. 복잡성(ppl) 결과는 팔로마로부터의 것이고 다운스트림(엔드 태스크) 결과는 부록 D + COPA Gordon 등(2012)에 열거된 태스크로부터의 것이다. 오염 제거가 전체 모델 성능을 저하시킨다는 증거를 찾지 못했다.\n' +
      '\n' +
      '포함할 소스 및 잠재적으로 업샘플링할 소스입니다. 다른 멀티-소스 코포라(예를 들어, ROOTS(Laurenccon et al., 2023), Pile(Gao et al., 2020), RedPajama v1(Together Computer, 2023c)와 같이, 31 Dolma는 단일 혼합 전략을 규정하지 않는다. 우리는 성능을 최대화하기 위해 구성 혼합에 대해 프로그래밍 방식으로 검색할 수 있는 방법의 예를 Rae 등(2021)에 독자를 참조한다. 여기에서 다양한 데이터 소스가 상호 작용하는 방식에 대한 몇 가지 연구 질문에 답하기 위한 기회로 혼합 실험을 수행한다. SS 3에 설명된 것과 동일한 절제 설정을 사용한다.\n' +
      '\n' +
      '각주 31: RedPajama v1은 LLaMA에서 사용된 다중 소스 코퍼스의 재생산이었다(Touvron et al., 2023a). RedPajama v2(Together Computer, 2023a)는 Common Crawl에만 초점을 맞추고 따라서 단일 소스이다.\n' +
      '\n' +
      '사전 훈련을 위해 얼마나 많은 코드가 중요한가? 코드 생성이 의도된 작업이 아니더라도, 언어 모델은 어느 정도의 코드에 대해 사전 훈련되는 것이 일반적인 관행이다. 일부 연구는 평문 문서들에 대한 트레이닝에 코드를 혼합하는 것이 추론 태스크들에 대한 성능을 향상시킨다는 것을 제안했다(Madaan et al., 2022). 우리는 돌마에 대해 훈련된 모델에 대해 이 관찰이 유효한지 여부를 조사하며, 그렇다면 코드가 얼마나 필요한가?\n' +
      '\n' +
      '우리는 코드 데이터의 0%, 5% 및 15%를 포함하는 C4 및 Stack 하위 집합에서 세 가지 혼합물을 생성한다. 각각 1B 모델을 훈련합니다. 우리는 세 가지 상이한 추론 태스크들, 즉 bAbI(웨스턴 등, 2015), WebNLG Gardent 등(2017) 및 GSM8K Cobbe 등(2021)에 대해 이들 모델들을 평가한다. 첫 번째 두 가지 작업에 대해 Muennighoff 등(2023b)의 실험 설정을 따르고 5개의 무작위 시드에 걸쳐 시연 횟수(0-5)가 변경되는 ICL 설정에서 각 모델을 평가한다. Muennighoff 등(2023b)은 사전 트레이닝 데이터에 코드를 추가하는 것이 bAbI 및 WebNLG 상에서 ICL 성능을 향상시킨다는 것을 보여주며, 이들은 코드가 장거리 상태-추적 능력을 향상시킨다는 것을 제안한다. 표 4에 표시된 바와 같이 우리의 실험은 이러한 발견을 확증한다: C4 전용 모델이 모든 bAbI 작업에서 실패하지만 코드를 추가하면 웹NLG에서도 유사한 경향으로 성능이 향상된다.\n' +
      '\n' +
      '더 어려운 GSM8k 벤치마크에서는 ICL 설정에서 모든 모델이 정답을 얻지 못했고, 전체 훈련 세트에서 모델을 미세 조정하는 경우에도 오류가 발생했다. 그러나 Gao 등(2022)에서 설명한 대로 파이썬 스니펫을 써서 문제를 해결하는 프로그램 지원 출력에 대한 미세 조정을 통해 코드 모델이 C4 전용 모델보다 성능이 우수함을 발견했다. 이러한 결과는 코드에 대해 사전 훈련된 모델이 원래 태스크가 코드를 직접 포함하지 않는 경우에도 도전적인 추론 태스크에 응답하기 위해 코드 생성을 활용할 수 있음을 보여준다.\n' +
      '\n' +
      '돌마에 대한 사전 훈련을 위한 혼합 전략을 평가하는 반면 돌마는 특정 소스 혼합물을 처방하지 않지만 일반적으로 사용되는 일부 전략 32를 분석하고 팔로마 평가 제품군(마그누손 등, 2023)을 사용하여 그 효과를 비교한다. 구체적으로 표 5에 4가지 가능한 데이터 혼합물을 제시하고 평가한다.\n' +
      '\n' +
      '각주 32: 우리는 이 실험 당시 준비가 되지 않았기 때문에 이러한 혼합물에 소셜 데이터를 포함하지 않았다.\n' +
      '\n' +
      '우리는 그림 12에서 혼합물의 결과를 보여준다. 전반적으로 다른 혼합물이 특정 하위 영역을 캡처하는 결과 모델의 능력에 영향을 미친다는 것을 관찰한다. 모든 혼합물은 C4(그림 12, 왼쪽)의 100개 도메인에서 샘플링된 페이지에서 유사한 복잡성 점수를 보여 웹 문서 모델링에 대한 일반적인 효과를 나타낸다. 반면에 우리는 모델이 특수 도메인에 노출되지 않는 한 모델을 모델링하는 데 어떻게 어려움을 겪는지 주목한다. 예를 들어 _웹 전용_ 믹스에서 학습 된 모델은 코드 도메인의 데이터를 표시 하기 위해 고군분투 합니다 (그림 12, 중앙, HumanEval). 마지막으로, 다양한 데이터 혼합이 복잡성에 어떻게 영향을 미치는지 설명하기 위해 학술 논문으로 구성된 M2D2의 S2ORC 하위 집합에 대한 결과를 사용한다. 코드의 경우와 마찬가지로 _웹 전용_ 모델은 도메인 불일치로 인해 더 높은 복잡성을 나타냅니다. 반면에 _참조 +_ 및 _고퍼 유사_ 믹스에 대해 학습 된 모델은 도메인 내 콘텐츠가 더 많기 때문에 _Naive_ 믹스에 대해 학습 된 모델보다 더 낮은 복잡성을 달성 합니다. 그러나 학문적 수준의 상당한 차이에도 불구하고 우리는 주목한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c} \\hline \\hline\n' +
      '**Dataset** & **0\\% Code** & **5\\% Code** & **15\\% Code** \\\\ \\hline bAbI (ICL) & 0.0 \\(\\pm\\) 0.0 & 8.8 \\(\\pm\\) 0.9 & 10.1 \\(\\pm\\) 2.8 \\\\ WebNLG (ICL) & 16.8 \\(\\pm\\) 1.1 & 19.3 \\(\\pm\\) 1.1 & 22.0 \\(\\pm\\) 1.3 \\\\ GSM8K (FT) & 0.0 \\(\\pm\\) 0.0 & 0.0 \\(\\pm\\) 0.0 & 0.0 \\(\\pm\\) 0.0 \\\\ GSM8K+PAL (FT) & 11.8 \\(\\pm\\) 0.8 & 14.2 \\(\\pm\\) 1.3 & 14.7 \\(\\pm\\) 0.9 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 5개의 무작위 시드에 걸쳐 3개의 데이터 세트에 대해 코드 양이 증가함에 따라 사전 훈련된 3개의 모델의 성능. 우리는 bAbI 및 GSM8K에 대한 정확한 일치도를 측정하고 WebNLG에 대한 루즈-2를 측정한다.\n' +
      '\n' +
      '참조 +_와 고퍼 유사_ 사이의 논문(4.9% 대 24.2%)은 거의 동일한 결과를 얻으며, 이는 도메인 내 데이터의 상대적으로 적은 비율도 좋은 도메인 적합성을 달성하기에 충분함을 시사한다.\n' +
      '\n' +
      '### Evaluating Olmo-1b\n' +
      '\n' +
      '표 6에서 Olmo-1b를 다른 1B 모델과 비교한다. 여기서 매개변수 카운트가 일치하지만, 피티아 1B는 거의 10배 적은 토큰에 대해 훈련되고 StableLM\\({}_{2}\\)의 데이터 구성은 알려지지 않은 반면 TinyLlama만 비슷한 수의 토큰에 대해 훈련되었다. 그럼에도 불구하고 Olmo-1b가 가장 비교 가능한 모델인 TinyLlama보다 평균적으로 더 나은 성능을 보여 8개 작업 중 4개에서 더 나은 성능을 보였다. 다운스트림 작업에 대한 제로 샷 평가는 이러한 비교적 작은 1B 모델에 대해 종종 도전적이지만, 모든 모델의 모든 작업에 대한 성능은 순진한 무작위 성능보다 높다. 다운스트림 작업에 대한 자세한 내용은 부록 D에 포함되어 있다.\n' +
      '\n' +
      '그림 13에서 우리는 올모-1b를 훈련하는 데 사용하는 돌마 혼합이 사전 훈련 데이터 이외의 다른 모든 변수가 통제되는 모델의 복잡성 측면에서 다른 인기 있는 사전 훈련 말뭉치와 어떻게 비교하는지 평가한다. 특히 각 모델이 학습되는 토큰의 수를 150B로 고정하여 데이터 규모와 학습 속도 스케줄의 차이가 우리가 연구하고자 하는 데이터 구성의 효과와 혼동되지 않도록 한다. 이 분석에서는 팔로마의 1B 기준선을 사용하고 11개의 데이터 소스에서 테스트 세트의 조합에 대한 복잡성을 계산하는 팔로마의 최고 수준 메트릭을 평가한다. 이러한 베이스라인들을 비교하는 다른 더 세밀한 복잡도 결과들은 매그누슨 등(2023)에서 이용가능하다. 현재 분석에서는 공개적으로 사용할 수 없는 출처를 제외하며 관련 사항이다.\n' +
      '\n' +
      '그림 12: 돌마 데이터의 다양한 비율에 대한 1B 모델 절제. 모든 혼합은 웹 데이터(왼쪽)에서 유사하게 수행되지만 코드를 제외하면 코드 데이터 세트(중앙)에서 복잡성이 증가합니다. 마지막으로, 논문과 위키피디아를 업샘플링하여 참조 자료를 증가시키면 S2ORC(오른쪽)에서 더 낮은 복잡성을 산출한다. 전반적으로 소스 분포는 다운스트림 기능과 연결되어 있으므로 돌마 사용자는 필요에 따라 하위 집합을 샘플링해야 한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l l l l l} \\hline \\hline\n' +
      '**Mix Name** & **Description** & \\multicolumn{2}{c}{**Sampling**} & \\multicolumn{2}{c}{**Proportion**} \\\\ \\hline \\multirow{3}{*}{**Naïve**} & \\multirow{3}{*}{Sample each source in Table 1 equally.} & Web & 100\\% & \\# Web & 83.5\\% \\\\  & & \\(\\vartriangle\\)Code & 100\\% & \\(\\vartriangle\\)Code & 13.8\\% \\\\  & & \\(\\vartriangle\\)Ref. & 100\\% & \\(\\vartriangle\\)Ref. & 2.5\\% \\\\  & & Books & 100\\% & Books & 0.2\\% \\\\ \\multirow{3}{*}{**Web Only**} & Similar to Ayoola et al. (2022), we test a mixture & Web & 100\\% & \\# Web & 100\\% \\\\  & that only uses web data. & \\(\\vartriangle\\)Code & 0\\% & \\# Code & 0\\% \\\\  & It is common practice to upsample knowledge-intensive documents when composing training & Web & 100\\% & \\# Web & 81.2\\% \\\\ \\multirow{3}{*}{**Reference+**} & mixture. In our case, we upsample the PeS2o & \\(\\vartriangle\\)Code & 100\\% & \\# Code & 13.5\\% \\\\  & papers, Wikipedia, Wikibooks, and Gutenberg books subsets by 2x. & 200\\% & \\# Ref. & 4.9\\% \\\\ \\multirow{3}{*}{**Gopher-like**} & Following Rae et al. (2021), we create a mix that is heavily biased towards reference material. As we do not have access to the same sources, an exact replication of their mix is not possible. & 17\\% & Web & 68.4\\% \\\\ \\multirow{3}{*}{**Gopher-like**} & Following Rae et al. (2021), we create a mix that is heavily biased towards reference material. As we do not have access to the same sources, an exact replication of their mix is not possible. & 8\\% & \\# Code & 5.4\\% \\\\  & Following Rae et al. (2021), we create a mix that is heavily biased towards reference material. As we do not have access to the same sources, an exact replication of their mix is not possible. & 200\\% & \\# Ref. & 24.2\\% \\\\ \\multirow{3}{*}{**Gopher-like**} & \\multirow{3}{*}{Number of tokens**} & Books & 200\\% & Books & 2.0\\% \\\\  & & & & \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 혼합물 및 그 조성물의 개요.\n' +
      '\n' +
      '프린지 또는 독성 텍스트 또는 우리가 사용하는 벤치마크 오염 제거 접근법에서 지원되지 않는 코드 데이터로 구성된다. 이는 C4 (Rafiel et al., 2020), mC4-en (Chung et al., 2023), Wikitext 103 (Merity et al., 2016), Penn Treebank (Marcus et al., 1999; Nunes, 2020), RedPajama (Together Computer, 2023c), Falcon-RefinedWeb (Penedo et al., 2023), Dolma (this work), M2D2 S2ORC (Reid et al., 2022), M2D2 Wikipedia (Reid et al., 2022), C4 100 도메인 (Chronopoulou et al., 2022), 및 Dolma 100 Subreddits (this work).\n' +
      '\n' +
      '통제된 복잡성 분석에서는 다양한 큐레이트 소스의 비공통 크롤 데이터를 포함하는 것의 중요성을 보여준다. 팔로마에서 사용하는 메트릭은 모델이 소스의 동일한 비율보다는 각 소스의 표시된 영역을 동등하게 샘플링하기 때문에 모델이 더 이질적인 데이터에 어떻게 적합하는지 보여준다. 직관적으로, 파일에서 훈련된 기준선은 사전 훈련 코퍼스가 대부분 그렇게 작고 손으로 선택한 출처에서 공급된다는 것과 같은 데이터에 잘 맞다. 그러나 코퍼스에서 토큰의 총 수를 확장하고자 할 때, 이러한 다양한 평가에서 샘플 효율성을 잃지 않고 더 많은 사용 가능한 커먼 크롤 데이터를 통합하는 방법이 과제가 된다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c} \\hline \\hline \\multirow{2}{*}{**Task**} & **StableLM\\({}_{2}\\) 1.6B** & **Pythia 1B** & **TinyLlama 1.1B** & **01mo-1b** \\\\  & (Shulily et al., 2024) & (Bidemann et al., 2023) & (Zhang et al., 2024) & this work \\\\ \\hline _ARC-E_(Curk et al., 2018) & 63.7 & 50.2 & 53.2 & 58.1 \\\\ _ARC-C_(Curk et al., 2018) & 43.8 & 33.1 & 34.8 & 34.5 \\\\ _BoolQ_(Curk et al., 2019) & 76.6 & 61.8 & 64.6 & 60.7 \\\\ _HellaSwag_(Zellers et al., 2019) & 68.2 & 44.7 & 58.7 & 62.5 \\\\ _OpenBookQA_(Milwady et al., 2018) & 45.8 & 37.8 & 43.6 & 46.4 \\\\ _PIQA_(Bisk et al., 2019) & 74.0 & 69.1 & 71.1 & 73.7 \\\\ _SciQ_(Webl et al., 2017) & 94.7 & 86 & 90.5 & 88.1 \\\\ _WinoGrande_(Sakaguchi et al., 2019) & 64.9 & 53.3 & 58.9 & 58.9 \\\\ \\hline\n' +
      '**Average** & _66.5_ & **54.5** & **59.4** & **60.3** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: 다른 유사한 크기의 언어 모델에 대한 Olmo-1b의 비교. Olmo-1b는 돌마의 **예비** 버전 (v. 1.5)에서 3 조 토큰에 대해 훈련 되었습니다. 전반적으로 올모-1b는 비슷한 수의 토큰으로 훈련된 TinyLlama보다 더 나은 성능을 보인다. 올모-1b는 피티아 1B보다 성능이 우수하지만 후자는 10배 적은 토큰으로 훈련되었다. StableLM\\({}_{2}\\)은 이 표에 참조로 포함되어 있지만 학습 데이터의 구성이 알려져 있지 않기 때문에 다른 작업과 공정하게 비교할 수 없다.\n' +
      '\n' +
      '도 13: 오염 제거를 위해 지원되지 않는 코드 데이터를 제외한 Paloma(Magnusson et al., 2023)의 최종 출시 버전에서의 모든 표준 언어 모델링 및 세밀한 도메인 소스에 대한 복잡성. 모델들은 팔로마로부터 각 코퍼스의 150B 토큰들에 대해 훈련된 1B 베이스라인들이다. 팔로마는 수백 개의 세분화된 도메인의 계층화된 샘플을 취하기 때문에 C4와 같은 단일 공통 크롤 데이터에 대한 평가보다 이질적이고 큐레이팅된 소스에 대한 적합성을 강조한다. 파일에는 최소 공통 크롤 데이터가 포함되지만 대부분 작은 큐레이팅된 데이터 소스가 소진된다. 돌마와 레드파자마는 대규모 커먼 크롤 데이터를 포함하면서 다양한 도메인에 맞는 이 샘플 효율성을 유지할 가능성을 보여준다.\n' +
      '\n' +
      '팔로마 미터법 이 경우에 우리는 포함된 Common Crawl 데이터의 비율이 4배 이상 더 크더라도 돌마 기준선이 파일 기준선의 성능 곡선과 거의 일치함을 알 수 있다.\n' +
      '\n' +
      '## 5 릴리스 Dolma\n' +
      '\n' +
      '위험 완화는 대규모 웹 크롤에서 파생된 모든 데이터 세트에 사실적으로 잘못된 정보, 독성 언어, 혐오 발언, PII 및 기타 유형의 유해한 콘텐츠가 포함되어 있음을 인식한다. 이를 고려하여 이 데이터 세트를 선별하기 위해 노력했지만, 라이센스 및 액세스 제어에 대한 신중한 고려를 포함하여 위험 완화가 여러 방향에서 가장 잘 접근한다고 믿는다.\n' +
      '\n' +
      'Copyright 우리가 사용한 대부분의 데이터 세트는 저작권 및 라이선스를 염두에 두고 큐레이션되었지만(예: peS2o의 오픈 액세스 문서(Soldaini 및 Lo, 2023), 스택의 오픈 소스 리포지토리(Kocetkov 등, 2022)) 또는 이미 허용된 라이선스(예: 위키피디아는 크리에이티브 커먼즈 라이선스로 릴리스됨) 대형 웹 크롤에도 저작권이 있는 데이터가 포함되어 있음을 인식합니다. 그러나 현재 도구를 고려할 때 이 크기의 코퍼스에서 저작권이 있는 자료를 신뢰할 수 있거나 확장성 있게 탐지할 수는 없습니다. 우리의 모든 데이터 소스가 공개적으로 이용 가능하고 이미 대규모 언어 모델 사전 훈련에 사용된다는 점을 포함하여 여러 고려 사항에서 돌마를 공개적으로 공개하기로 결정한 것은 AI 및 공정 사용에 대한 우리의 공개 입장을 독자에게 참조한다(파라디 등, 2023).\n' +
      '\n' +
      'AI의 법적, 윤리적 지형이 빠르게 변화하고 있음을 인식하고 새로운 정보가 제공됨에 따라 선택을 다시 검토할 계획입니다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Abbas 등(2023) Amro Abbas, Kushal Tirumala, Daniel Simig, Surya Ganguli, and Ari S. 모코스 확인됨: 의미 중복 제거를 통해 웹 규모에서 데이터 효율적인 학습입니다. _ ArXiv_, abs/2303.09540, 2023. URL [https://api.semanticscholar.org/CorpusID:257557221](https://api.semanticscholar.org/CorpusID:257557221).\n' +
      '* Acs(2019) Judit Acs. 2019년 BERT의 어휘 탐색\n' +
      '* Agarwal 등(2009) Amit Agarwal, Hema Swetha Koppula, Krishna P. Leela, Krishna Prasad Chitrapura, Sachin Garg, Pavan Kumar GM, Chittaranjan Haty, Anirban Roy, and Amit Sasturkar. 웹 페이지의 중복 제거를 위한 URL 정규화입니다. _Proceedings of the 18th ACM Conference on Information and Knowledge Management_, CIKM \'09, page 1987-1990, New York, NY, USA, 2009. Association for Computing Machinery. ISBN 9781605585123. doi: 10.1145/1645953.1646283. URL [https://doi.org/10.1145/1645953.1646283](https://doi.org/10.1145/1645953.1646283)\n' +
      '* Ahia et al. (2023) Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R. 모텐슨, 노아 A. 스미스, 율리아 츠베코프 모든 언어는 동일한가요? tokenization in the era of commercial language models, 2023.\n' +
      '* Allal et al. (2023) Loubna Ben Allal, Raymond Li, Denis Koetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Mishra, Alex Gu, Manan Dey, Logesh Kumar Unapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Dmitry Abulkhanov, Manuel Romero, Michael Tappert, Francesco De Toni, Bernardo Garcia del Rio, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, and Leandro v 산타코더: 별을 향해 손을 뻗지 마! arXiv [cs.SE]_, January 2023.\n' +
      '* 알마즈루에이 등(2023) 에브테삼 알마즈루에이, 함자 알로베이드리, 압둘라지즈 알샴시, 알레산드로 카펠리, 룩산드라 코조카루, 메루안 데바, 에티엔 고피넷, 다니엘 헤슬로우, 줄리엔 로우네, 쿠엔틴 말artic, 바드레드딘 명사, 침례자 파니에, 및 구일허메 페네도. Falcon-40B: 최신 성능을 갖춘 개방형 대형 언어 모델입니다. _ TII UAE_, 2023.\n' +
      '* Angelescu (2013) Angelescu, Radu. GutenbergPy. [https://github.com/raduangelescu/gutenbergpy] (https://github.com/raduangelescu/gutenbergpy), 2013. Version 0.3.5 [accessed August 2023].\n' +
      '* Chen et al.(2019)Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Tachard Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Z. 첸, 에릭 추, J. 클라크, 로랑 엘 샤피, 옌핑 황, 캐슬린 S. 마이어-헬스턴, 가우라브 미쉬라, 에리카 모레이라, 마크 오메르닉, 케빈 로빈슨, 세바스티안 루더, 이 테이, 케판 샤오, 유징 장, 구스타보 에르난데스 아브레고, 준환 안, 제이콥 오스틴, 폴 바함, 얀 A. 보타, 제임스 브래드베리, 싯다르타 브라마, 케빈 마이클 브룩스, 미켈레 카타스타, 용저우 쳉, 콜린 체리, 크리스토퍼 A. 초케트-추, 아칸샤 초우드레이, C 크렙시, 샤치 데이브, 모스타파 데흐하니, 팬 펑, 블라드 피엔베르, 마커스 프리타그, 블라드 아리에, 하디 하스헤미, 르 호우, 세바스티안 게르만, 마테우 자기엘스키, 원하오 지아, 가이구르-아리, 스테벤 핸드, 하디 하스헤미, 레후아, 세바스티안 게르만, 캐서린 리, 벤자민 리, 에릭 리, 무리 리, 웨이 리, 그래서 다니엘라 손, 사이먼 토쿠민, 다샤 발터, 비제이 바수데반, 키란 보드라할리, 쉬에지 왕, 피동 왕, 지루이 왕, 도왕, 존 위팅, 유화이 우, 커쉬, 윤한 쉬, 린 우쉬, 펑청인, 자후이 유, 치올링 장, 스티븐 정, 세정, 웨이저우, 데니 저우, 슬라브 페트로프, 용후이 우가 있다. Palm 2 기술 보고서 _ ArXiv_, abs/2305.10403, 2023. URL [https://api.semanticscholar.org/CorpusID:258740735](https://api.semanticscholar.org/CorpusID:258740735).\n' +
      '* 인류[2023] 인류. Claude 소개. [https://www.anthropic.com/index/introducing-claude] (https://www.anthropic.com/index/introducing-claude), 2023.\n' +
      '* Aura et al. [2006] Tuomas Aura, Thomas A. Kuhn, and Michael Roe. Scanning electronic documents for personally identifiable information. Association for Computing Machinery, Inc., October 2006. URL [https://www.microsoft.com/en-us/research/publication/scanning-electronic-documents-for-personally-identifiable-information/](https://www.microsoft.com/en-us/research/publication/scanning-electronic-documents-for-personally-identifiable-information/).\n' +
      '* Ayoola et al. [2022] Tom Ayoola, Shubhi Tyagi, Joseph Fisher, Christos Christodoulopoulos, and Andrea Pierleoni. ReFinED: An efficient zero-shot-capable approach to end-to-end entity linking. In _Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Track_, pages 209-220, Hybrid: Seattle, Washington + Online, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-industry.24. URL [https://aclanthology.org/2022.naacl-industry.24](https://aclanthology.org/2022.naacl-industry.24).\n' +
      '* Bach et al. [2022] Stephen Bach, Victor Sanh, Zheng Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-david, Canwen Xu, Gunjan Chhablani, Han Wang, Jason Fries, Maged Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Dragomir Radev, Mike Tian-jian Jiang, and Alexander Rush. PromptSource: An integrated development environment and repository for natural language prompts. In _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations_, pages 93-104, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-demo.9. URL [https://aclanthology.org/2022.acl-demo.9](https://aclanthology.org/2022.acl-demo.9).\n' +
      '* Baumgartner 등. [2020a] Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan Squire, and Jeremy Blackburn. Pushshift reddit 데이터 세트입니다. _ ArXiv_, abs/2001.08435, 2020a. URL [https://api.semanticscholar.org/CorpusID:210868223](https://api.semanticscholar.org/CorpusID:210868223).\n' +
      '* Baumgartner 등. [2020b] Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan Squire, and Jeremy Blackburn. Pushshift reddit 데이터 세트입니다. _ arXiv [cs.SI]_, January 2020b.\n' +
      '* Biderman et al. [2023] Stella Rose Biderman, Hailey Schoelkopf, Quentin G. Anthony, Herbie Bradley, Kyle O\'Brien, Eric Hallahan, Mohammad Afah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. Pythia: A suite for analyzing large language models across training and scaling. _ArXiv_, abs/2304.01373, 2023. URL [https://api.semanticscholar.org/CorpusID:257921893](https://api.semanticscholar.org/CorpusID:257921893).\n' +
      '* Berman 등 [2023]Abeba Birhane, Vinay Prabhu, Sang Han, Vishnu Naresh Boddeti, and Alexandra Sasha Luccioni. Laiions den: 멀티모달 데이터 집합에서 혐오를 조사합니다. _ ArXiv_, abs/2311.03449, 2023a. URL [https://api.semanticscholar.org/CorpusID:2650434448](https://api.semanticscholar.org/CorpusID:2650434448).\n' +
      '* Birhane 등(2023b) Abeba Birhane, Vinay Uday Prabhu, Sangghyun Han, and Vishnu Naresh Boddeti. No hate scaling laws for data-swamp. _ ArXiv_, abs/2306.13141, 2023b. URL [https://api.semanticscholar.org/CorpusID:259243810](https://api.semanticscholar.org/CorpusID:259243810).\n' +
      '* Bisk 등(2019) Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, and Yejin Choi. PIQA: 자연 언어에서 물리적 상식에 대한 추론 _ arXiv [cs.CL]_, November 2019.\n' +
      '* Black 등(2022) Sid Black, Stella Rose Biderman, Eric Hallahan, Quentin G. Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Martin Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Benqi Wang, and Samuel Weinbach. Gpt-neox-20b: 오픈소스 자기회귀 언어 모델. _ ArXiv_, abs/2204.06745, 2022. URL [https://api.semanticscholar.org/CorpusID:248177957](https://api.semanticscholar.org/CorpusID:248177957).\n' +
      '* Blevins and Zettlemoyer (2022) Terra Blevins and Luke Zettlemoyer. 언어 오염은 사전 훈련된 영어 모델의 언어 간 기능을 설명하는 데 도움이 됩니다. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 3563-3574, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL [https://aclanthology.org/2022.emnlp-main.233](https://aclanthology.org/2022.emnlp-main.233).\n' +
      '* Blodgett 등(2016) Su Lin Blodgett, Lisa Green, and Brendan O\'Connor. 소셜 미디어의 인구학적 변증: 아프리카계 미국인 영어 사례 연구 _Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing_, pages 1119-1130, Austin, Texas, November 2016. Association for Computational Linguistics. doi: 10.18653/v1/D16-1120. URL [https://aclanthology.org/D16-1120](https://aclanthology.org/D16-1120).\n' +
      '* Bloom(1970) Burton H Bloom. 허용 가능한 오류가 있는 해시 코딩의 시공간 절충입니다. _ Communications of the ACM_, 13(7):422-426, July 1970. ISSN 0001-0782,1557-7317. doi: 10.1145/362686.362692.\n' +
      '* Borgeaud 등(2022)은 Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego De Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack Rae, Erich Elsen, and Laurent Sifre. 조 개의 토큰에서 검색하여 언어 모델을 개선합니다. Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, _Proceedings of the 39th International Conference on Machine Learning_, Volume 162 of _Proceedings of Machine Learning Research_, pages 2206-2240. PMLR, 17-23 Jul 2022. URL [https://proceedings.mlr.press/v162/borgeaud22a.html](https://proceedings.mlr.press/v162/borgeaud22a.html)\n' +
      '* Bowman 등(2015) Samuel Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. 자연어 추론 학습을 위한 주석이 달린 대형 말뭉치 _2015 자연어 처리에서의 경험적 방법에 관한 회의의 진행문_ 에서, 페이지 632-642, 2015.\n' +
      '* Broder(2002) A Z Broder. 문서의 유사성과 격리에 관하여. Proceedings _Proceedings. SEQUENCES 1997의 압축 및 복잡도(Cat. No.97TB100171) _, pages 21-29. IEEE Comput. Soc, 2002. ISBN 9780818681325. doi: 10.1109/sequen.1997.666900.\n' +
      '* Brown 등(2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. J. Henighan, Rewon Child, Aditya Ramesh, Daniel M. 지글러, 제프 우, 클레멘스 윈터, 크리스토퍼 헤세, 마크 첸, 에릭 시글러, 마테우스 리트윈, 스콧 그레이, 벤자민 체스, 잭 클라크, 크리스토퍼 베르너, 샘 맥캔들리시, 알렉 래드포드, 일야 서츠케버, 다리오 아모데이. 언어 모델은 적은 수의 학습자입니다. _ ArXiv_, abs/2005.14165, 2020. URL [https://api.semanticscholar.org/CorpusID:218971783](https://api.semanticscholar.org/CorpusID:218971783).\n' +
      '* Camburu et al. (2018) Oana-Maria Camburu, Tim Rocktaschel, Thomas Lukasiewicz, and Phil Blunsom. e-snli: 자연어 설명과 함께 자연어 추론. _ 신경 정보 처리 시스템_, 31, 2018의 발전.\n' +
      '*Camburu et al. (2019)Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, and Chiyuan Zhang. 신경 언어 모델에 걸친 암기를 정량화하는 단계 _ arXiv [cs.LG]_, February 2022a.\n' +
      '* Carlini et al. [2020] Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, and Chiyuan Zhang. Quantifying memorization across neural language models. _ArXiv_, abs/2202.07646, 2022b. URL [https://api.semanticscholar.org/CorpusID:246863735](https://api.semanticscholar.org/CorpusID:246863735).\n' +
      '* Caselli et al. [2021] Tommaso Caselli, Valerio Basile, Jelena Mitrovic, and Michael Granitzer. HateBERT: Retraining BERT for abusive language detection in English. In _Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)_, pages 17-25, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.woah-1.3. URL [https://aclanthology.org/2021.woah-1.3](https://aclanthology.org/2021.woah-1.3).\n' +
      '* Chang et al. [2023] Kent K. Chang, Mackenzie Cramer, Sandeep Soni, and David Bamman. Speak, memory: An archaeology of books known to chatgpt/gpt-4. _ArXiv_, abs/2305.00118, 2023. URL [https://api.semanticscholar.org/CorpusID:258426273](https://api.semanticscholar.org/CorpusID:258426273).\n' +
      '* Chen et al. [2021a] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saund 카, 얀 라이케, 조쉬 아치암, 베단트 미스라, 에반 모리카와, 알렉 래드포드, 매튜 나이트, 마일스 브랜디지, 미라 무라티, 카이테 메이어, 피터 웰린더, 밥 맥그루, 다리오 아모데이, 샘 맥칸드리시, 일야 서츠케버, 우지크 자렘바. 코드, 2021a에서 훈련된 대규모 언어 모델을 평가합니다.\n' +
      '* Chen et al. [2021b] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemings, Matthias Plappert, Fotios Chantzis, 엘리자베스 반스, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N Carr, Jan Leike, Josh Achiam, 코드에 대해 훈련된 대규모 언어 모델 평가 2021년 7월\n' +
      '* Chen 등 [2023a] Xiangning Chen, Chen Liang, Da Huang, Esteban Real, Kaiyuan Wang, Yao Liu, Hieu Pham, Xuanyi Dong, Thang Luong, Cho-Jui Hsieh, Yifeng Lu, and Quoc V Le. 최적화 알고리즘의 상징적 발견 2023년 2월\n' +
      '* Chen 등 [2023b] Yang Chen, Ethan Mendes, Sauvik Das, Wei Xu, and Alan Ritter. 개인 정보 보호를 위해 언어 모델을 지시할 수 있습니까? _ arXiv [cs.CL]_, October 2023b.\n' +
      '* Chowdhery et al. [2022] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam M. Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Benton C. Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunjiro Dev, Henry Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeonate Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dolan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanulayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathleen S. Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways. _ArXiv_, abs/2204.02311, 2022. URL [https://api.semanticscholar.org/CorpusID:247951931](https://api.semanticscholar.org/CorpusID:247951931).\n' +
      '* Chen et al. [2022]Alexandra Chronopoulou, Matthew Peters, and Jesse Dodge. 사전 훈련된 언어 모델을 위한 효율적인 계층적 도메인 적응 _Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_, pages 1336-1351, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.96. URL [https://aclanthology.org/2022.naacl-main.96](https://aclanthology.org/2022.naacl-main.96)\n' +
      '* Chung 등(2023) Hyung Won Chung, Noah Constant, Xavier Garcia, Adam Roberts, Yi Tay, Sharan Narang, and Orhan Firat. Unimax: Fairer and more effective language sampling for large-scale multilingual pretraining. _ ArXiv_, abs/2304.09151, 2023. URL [https://api.semanticscholar.org/CorpusID:258187051](https://api.semanticscholar.org/CorpusID:258187051).\n' +
      '* cjadams 등(2017) cjadams, Jeffrey Sorensen, Julia Elliott, Lucas Dixon, Mark McDonald, nithum, and Will Cukierski. 독성 주석 분류 챌린지, 2017. URL [https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge](https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge)입니다.\n' +
      '* Clark 등(2019) Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. Boolq: 자연스러운 예/아니오 질문의 놀라운 어려움을 탐구합니다. _ arXiv preprint arXiv:1905.10044_, 2019.\n' +
      '* Clark 등(2018) Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. 질문에 대한 답을 풀었다고 생각해? AI2 추론 도전인 ARC를 시도하십시오. 2018년 3월\n' +
      '* Cobbe et al.(2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 검증자를 학습하여 수학 단어 문제를 해결합니다. _ ArXiv_, abs/2110.14168, 2021. URL [https://api.semanticscholar.org/CorpusID:239998651](https://api.semanticscholar.org/CorpusID:239998651).\n' +
      '* Crawl(2016) Common Crawl. cc-crawl-statistics. [https://github.com/commoncrawl/cc-crawl-statistics] (https://github.com/commoncrawl/cc-crawl-statistics), 2016. [accessed August 2023].\n' +
      '* 커먼즈(2013) 크리에이티브 커먼즈. Attribution-ShareAlike 4.0 International. [https://creativecommons.org/licenses/by-sa/4.0/legalcode] (https://creativecommons.org/licenses/by-sa/4.0/legalcode), 2013. [accessed August 2023].\n' +
      '* Davis and Graham (2021) Jenny L Davis and Timothy Graham. 감정적 결과 및 주의 보상: 등급이 Reddit에 미치는 사회적 영향 _ Information, Communication and society_, 24(5):649-666, April 2021. ISSN 1369-118X,1468-4462. doi: 10.1080/1369118x.2021.1874476.\n' +
      '* Dernoncourt 등(2017) Franck Dernoncourt, Ji Young Lee, Ozlem Uzuner, and Peter Szolovits. 반복 신경망을 사용 하 여 환자 노트의 식별 해제 _ Journal of the American Medical Informatics Association: JAMIA_, 24(3):596-606, May 2017. ISSN 1067-5027,1527-974X. doi: 10.1093/자미아/ocw156.\n' +
      '* Dodge 등(2021) Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret Mitchell, and Matt Gardner. 대형 웹텍스트 말뭉치 문서화: 거대 클린 크롤링 코퍼스에 대한 사례 연구 _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pages 1286-1305, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.98.\n' +
      '* Elazar et al.(2023) Yanai Elazar, Ashita Bhagia, Ian Magnusson, Abhilasha Ravichander, Dustin Schwenk, Alane Suhr, Pete Walsh, Dirk Groeneveld, Luca Soldaini, Sameer Singh, et al. 내 빅 데이터에는 무엇이 있나요? _ arXiv preprint arXiv:2310.20707_, 2023. URL [https://arxiv.org/abs/2310.20707](https://arxiv.org/abs/2310.20707)\n' +
      '* Farhadi 등(2023) Ali Farhadi, David Atkinson, Chris Callison-Burch, Nicole DeCario, Jennifer Dumas, Kyle Lo, Crystal Nam, and Luca Soldaini. AI2 문의 알림 및 댓글 요청에 대한 응답 2023. URL [https://www.regulations.gov/comment/COLC-2023-0006-8762](https://www.regulations.gov/comment/COLC-2023-0006-8762).\n' +
      '* Feng 등(2023) Shangbin Feng, Chan Young Park, Yuhan Liu, and Yulia Tsvetkov. 사전 훈련 데이터에서 언어 모델부터 다운스트림 작업까지: 불공정한 NLP 모델로 이어지는 정치적 편향의 흔적을 추적한다. _Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers)_, pages 11737-11762, pages, Canada, Toronto, July 2023. Association for Computational Linguistics. URL [https://aclanthology.org/2023.acl-long.656](https://aclanthology.org/2023.acl-long.656).\n' +
      '* Feng 등(2021)Leo Gao. 텍스트 데이터의 품질 필터링에 대한 경험적 탐색 _ CoRR_, abs/2109.00698, 2021. URL [https://arxiv.org/abs/2109.00698](https://arxiv.org/abs/2109.00698).\n' +
      '* Gao 등(2020) Leo Gao, Stella Rose Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 파일: 언어 모델링을 위한 다양한 텍스트의 800GB 데이터 세트입니다. _ ArXiv_, abs/2101.00027, 2020. URL [https://api.semanticscholar.org/CorpusID:230435736](https://api.semanticscholar.org/CorpusID:230435736).\n' +
      '* Gao 등(2022) Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. Pal: 프로그램 지원 언어 모델. _ arXiv preprint arXiv:2211.10435_, 2022.\n' +
      '* Gardent 등(2017) Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini. NLG 마이크로 플래너를 위한 훈련 말뭉치를 만들고 있습니다. _Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers)_, pages 179-188, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1017. URL [https://aclanthology.org/P17-1017](https://aclanthology.org/P17-1017).\n' +
      '* Gebru 등(2021) Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daume Iii, and Kate Crawford. DataSet용 DataSheets. _ Communications of the ACM_, 64(12):86-92, 2021.\n' +
      '* Gehman 등(2020) Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. RealToxicityPrompts: 언어 모델에서 신경 독성 변성을 평가한다. _Findings of the Association for Computational Linguistics: EMNLP 2020_, pages 3356-3369, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.301. URL [https://aclanthology.org/2020.findings-emnlp.301](https://aclanthology.org/2020.findings-emnlp.301)\n' +
      '* Team et al. (2021) Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwik, Andrew M Dai, Anja Hauth, Katie Millican, David Silver, Slav Petrov, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul R Barham, Tom Hennigan, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Eliza Rutherford, Elemens Miquer, Maxim Krikun, Iain Barr, Nikolay Savinov, Eliza Rutherka, Becca Ayoub, Megha Goel, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr 제미니: 매우 유능한 멀티모달 모델들의 패밀리입니다. _ arXiv [cs.CL]_, December 2023.\n' +
      '* 제1권: 메인 컨퍼런스와 공유된 태스크의 회보, 제2권: 시맨틱 평가에 관한 제6회 국제 워크숍(SemEval 2012)_, 394-398 페이지, 캐나다 몬트리올, 7-8 June 2012. Association for Computational Linguistics. URL [https://aclanthology.org/S12-1052](https://aclanthology.org/S12-1052).\n' +
      '* Greenbaum [1991] Sidney Greenbaum. 얼음: 국제 영어 말뭉치. _ English Today_, 7(4):3-7, 1991.\n' +
      '* Groeneveld et al. [2023] Dirk Groeneveld, Anas Awadalla, Iz Beltagy, Akshita Bhagia, Ian Magnusson, Hao Peng, Oyvind Tafjord, Pete Walsh, Kyle Richardson, and Jesse Dodge. Catwalk: A unified language model evaluation framework for many datasets. _arXiv [cs.CL]_, December 2023.\n' +
      '* Groeneveld et al. [2024] Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson, Russell Authur, Khyathi Chandu, Arman Cohan, Jennifer Dumas, Yanai Elazar, Yuling Gu, Jack Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Valentina Pyatkin, Abhilasha Ravichander, Dustin Schwenk, Saurabh Shah, Will Smith, Nishant Subramani, Mitchell Wortsman, Pradeep Dasigi, Nathan Lambert, Kyle Richardson, Jesse Dodge, Kyle Lo, Luca Soldaini, Noah A. Smith, and Hannaneh Hajishirzi. OLMo: Accelerating the Science of Language Models. _arXiv preprint_, 2024.\n' +
      '* Grosse et al. [2023] Roger Baker Grosse, Juhan Bae, Cem Anil, Nelson Elhage, Alex Tamkin, Amirhossein Tajdini, Benoit Steiner, Dustin Li, Esin Durmus, Ethan Perez, Evan Hubinger, Kamil.e Lukovsiut.e, Karina Nguyen, Nicholas Joseph, Sam McCandlish, Jared Kaplan, and Sam Bowman. Studying large language model generalization with influence functions. 2023. URL [https://api.semanticscholar.org/CorpusID:260682872](https://api.semanticscholar.org/CorpusID:260682872).\n' +
      '* Gururangan et al. [2022] Suchin Gururangan, Dallas Card, Sarah Dreier, Emily Gade, Leroy Wang, Zeyu Wang, Luke Zettlemoyer, and Noah A. Smith. Whose language counts as high quality? measuring language ideologies in text data selection. In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 2562-2580, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL [https://aclanthology.org/2022.emmlp-main.165](https://aclanthology.org/2022.emmlp-main.165).\n' +
      '* Hammoudeh and Lowd[2022] Zayd Hammoudeh and Daniel Lowd. 훈련 데이터 영향 분석 및 추정: 설문조사. _ ArXiv_, abs/2212.04612, 2022. URL [https://api.semanticscholar.org/CorpusID:254535627](https://api.semanticscholar.org/CorpusID:254535627).\n' +
      '* Hartvigsen et al. [2022] Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar. ToxiGen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection. In _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 3309-3326, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.234. URL [https://aclanthology.org/2022.acl-long.234](https://aclanthology.org/2022.acl-long.234).\n' +
      '* Hathurusinghe et al. [2021] Rajitha Hathurusinghe, Isar Nejadgholi, and Miodrag Bolic. A privacy-preserving approach to extraction of personal information through automatic annotation and federated learning. In _Proceedings of the Third Workshop on Privacy in Natural Language Processing_, pages 36-45, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.privatenlp-1.5.\n' +
      '* Heafield [2011] Kenneth Heafield. KenLM: 더 빠르고 작은 언어 모델 쿼리입니다. _Proceedings of the Sixth Workshop on Statistical Machine Translation_, pages 187-197, Edinburgh, Scotland, July 2011. Association for Computational Linguistics. URL [https://aclanthology.org/W11-2123](https://aclanthology.org/W11-2123).\n' +
      '* Henderson et al. [2012] Matthew Henderson, Pawel Budzianowski, Inigo Casanueva, Sam Coope, Daniela Gerz, Girish Kumar, Nikola Mrksic, Georgios Spithourakis, Pei-Hao Su, Ivan Vulic, and Tsung-Hsien Wen. A repository of conversational datasets. In _Proceedings of the Workshop on NLP for Conversational AI_, jul 2019. URL [https://arxiv.org/abs/1904.06472](https://arxiv.org/abs/1904.06472). Data available at github.com/PolyAI-LDN/conversational-datasets.\n' +
      '* Hoffmann et al.(2022) Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, L. 시프르 컴퓨팅 최적화 대용량 언어 모델을 학습합니다. _ ArXiv_, abs/2203.15556, 2022. URL [https://api.semanticscholar.org/CorpusID:247778764](https://api.semanticscholar.org/CorpusID:247778764)\n' +
      '* Hong 등(2021) 지민홍, 김태희, 혜수임, 재굴추. AVocaDo: 다운스트림 도메인에 어휘를 적응시키기 위한 전략. _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pages 4692-4700, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.385. URL [https://aclanthology.org/2021.emnlp-main.385](https://aclanthology.org/2021.emnlp-main.385)\n' +
      '* Joulin 등(2016a) Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Herve Jegou, and Tomas Mikolov. Fasttext.zip: 압축 텍스트 분류 모델 _ arXiv preprint arXiv:1612.03651_, 2016a.\n' +
      '* Joulin 등(2016b) Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 효율적인 텍스트 분류를 위한 트릭 백입니다. _ arXiv preprint arXiv:1607.01759_, 2016b.\n' +
      '* Kandpal 등(2023) Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. 대형 언어 모델들은 롱테일 지식을 배우는데 어려움을 겪는다. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, _Proceedings of the 40th International Conference on Machine Learning_, Volume 202 of _Proceedings of Machine Learning Research_, pages 15696-15707. PMLR, 23-29 Jul 2023. URL [https://proceedings.mlr.press/v202/kandpal23a.html](https://proceedings.mlr.press/v202/kandpal23a.html)\n' +
      '* Kinney 등(2023)은 로드니 키니, 클로이 아나스타시아데스, 러셀 아우투스, 이즈 벨타기, 조나단 브래그, 알렉산드라 부라크진스키, 이사벨 카콜라, 스테판 캔드라, 요가난드 찬드라세카하, 아르만 코한, 마일스 크로포드, 더그 다우니, 제이슨 던켈베르거, 오렌 에치오니, 롭 에반스, 세르게이 펠드만, 조지프 Gorney, 데이비드 그레이엄, 방저우 후, 레간 허프, 다니엘 킹, 세바스티안 콜마이어, 베일리 쿠에엘, 마이클 랭건, 다니엘 린, 하오쿤 리우, 카일 로, 자론 로흐너, 켈시 맥밀란, 타일러 머레이, 크리스 뉴웰, 스미타 라오, 샤우리라 로하트기, 폴 사이어, 제장 셴, 암프리트 싱, 루카 솔다이니, 시바샨카 서브라마니안, 앰버 타나카, 알렉스 D. 웨이드, 린다 와그너, 루시 루 왕, 크리스 윌헬름, 용접 Semantic Scholar Open Data Platform. _ arXiv preprint arXiv:2301.10140_, 2023.\n' +
      '* Kirk and Nelson (2018) John Kirk and Gerald Nelson. 국제 영어 프로젝트 코퍼스: 진행 보고서. _ World Englishes_, 2018. URL [https://api.semanticscholar.org/CorpusID:150172629](https://api.semanticscholar.org/CorpusID:150172629).\n' +
      '* Koetkov 등(2022) 데니스 Koetkov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou, Carlos Munoz Ferrandis, Yacine Jernite, Margaret Mitchell, Sean Hughes, Thomas Wolf, 등. The Stack: 3 TB of permissively licensed source code. _ arXiv preprint arXiv:2211.15533_, 2022.\n' +
      '* Koppula et al.(2010) Hema Swetha Koppula, Krishna P. Leela, Amit Agarwal, Krishna Prasad Chitrapura, Sachin Garg, and Amit Sasturkar. 웹 페이지 중복 제거를 위한 url 패턴 학습 _Proceedings of the Third ACM International Conference on Web Search and Data Mining_, WSDM\'10, page 381-390, New York, NY, USA, 2010. Association for Computing Machinery. ISBN 9781605588896. doi: 10.1145/1718487.1718535. URL [https://doi.org/10.1145/1718487.1718535](https://doi.org/10.1145/1718487.1718535)\n' +
      '* Kudo(2018) Taku Kudo. 서브워드 정규화: 다수의 서브워드 후보를 갖는 신경망 번역 모델 개선. _Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers)_, pages 66-75, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1007. URL [https://aclanthology.org/P18-1007](https://aclanthology.org/P18-1007)\n' +
      '* Kudo and Richardson (2018) Taku Kudo and John Richardson. SentencePiece: 신경 텍스트 처리를 위한 간단하고 언어 독립적인 서브워드 토큰화기 및 디토크화기. _Proceedings of the 2018 Conferenceon Empirical Methods in Natural Language Processing: System Demonstrations_, pages 66-71, Brussels, Belgium, November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-2012. URL [https://aclanthology.org/D18-2012](https://aclanthology.org/D18-2012).\n' +
      '* Laurenccon 등(2023) Hugo Laurenccon, Lucile Saulnier, Thomas Wang, Christopher Akiki, Albert Villanova del Moral, Teven Le Scao, Leandro von Werra, Chenghao Mou, Eduardo Gonz\'alez Ponferrada, Huu Nguyen, Jorg Frohberg, Mario vSavsko, Quentin Lhoest, Angelina McMillan-Major, Gerard Dupont, Stella Rose Biderman, Anna Rogers, Loubna Ben Allal, Francesco De Toni, Giada Pistilli, Olivier Nguyen, Somaieh Nikpoor, Maraim Masoud, Pierre Colombo, Javier de la Rosa, Paulo Villegas, Tristan Thrush, S. 롱프리, 세바스티안 나겔, 레온 베버, 마누엘 세빌라 무뇨즈, 지안 주, 다니엘 알렉산더 반 스트라이엔, 자이드 알랴페이, 칼리드 알무바라크, 민 치엔 부, 이치아 곤잘레스-디오스, 아이토르 소로아 에탁사베, 카일로, 만안 데이, 페드로 오르티즈 수아레즈, 아론 고카슬란, 샤믹 보세, 다비드 이페올루와 아델라니, 롱 판, 히에우 트룽 트란, 이안 유, 수하스 파이, 제니 침, 바이올렛 레퍼크, 수자나 일릭, 마가렛 미첼, 사샤 루치오니, 야신 제르나이트. Bigscience root corpus: 1.6번째 복합 다국어 데이터 세트입니다. _ ArXiv_, abs/2303.03915, 2023. URL [https://api.semanticscholar.org/CorpusID:257378329](https://api.semanticscholar.org/CorpusID:257378329).\n' +
      '* Le Scao 등(2022) Teven Le Scao, Thomas Wang, Daniel Hesslow, Stas Bekman, M Saiful Bari, Stella Biderman, Hady Elsahar, Niklas Muennighoff, Jason Phang, Ofir Press, Colin Raffel, Victor Sanh, Sheng Shen, Lintang Sutawika, Jaeesung Tae, Zheng Xin Yong, Julien Launay, and Iz Beltagy. 100만 GPU 시간이 있다면 어떤 언어 모델을 훈련시킬까요? _Findings of the Association for Computational Linguistics: EMNLP 2022_, pages 765-782, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL [https://aclanthology.org/2022.findings-emnlp.54](https://aclanthology.org/2022.findings-emnlp.54).\n' +
      '* Lee 등(2022) Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. 훈련 데이터를 중복하면 언어 모델이 더 좋아집니다. _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 8424-8445, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.577. URL [https://aclanthology.org/2022.acl-long.577](https://aclanthology.org/2022.acl-long.577)\n' +
      '* Leong 등(2022) Colin Leong, Joshua Nemecek, Jacob Mansdorfer, Anna Filighera, Abraham Owodunni, and Daniel Whitenack. 블룸 라이브러리: 다양한 다운스트림 작업에 대해 300개 이상의 언어로 구성된 멀티모달 데이터 세트입니다. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 8608-8621, pages of Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL [https://aclanthology.org/2022.emnlp-main.590](https://aclanthology.org/2022.emnlp-main.590).\n' +
      '* Levesque et al. (2012) Hector J. Levesque, Ernest Davis, and Leora Morgenstern. 위노그라드 스키마 도전 _Proceedings of Th13 International Conference on Principles of Knowledge Representation and Reasoning_, KR\'12, page 552-561. AAAI Press, 2012. ISBN 9781577355601. URL [https://dl.acm.org/doi/10.5555/3031843.3031909](https://dl.acm.org/doi/10.5555/3031843.3031909)\n' +
      '* Lhoest et al. (2021) Quentin Lhoest, Albert Villanova del Moral, Patrick von Platen, Thomas Wolf, Mario Sasko, Yacine Jernite, Abhishek Thakur, Lewis Tunstall, Suraj Patil, Mariama Drame, Julien Chaumond, Julien Plu, Joe Davison, Simon Brandeis, Victor Sanh, Teven Le Scao, Kevin Canwen Xu, Nicolas Patry, Steven Liu, Angelina McMillan-Major, Philipp Schmid, Sylvain Gugger, Nathan Raw, Sylvain Lesage, Anton Lozhkov, Matthew Carrigan, Theo Matussiere, Leandro von Werra, Lysandre Debut, Stas Bekman, and Clement Delangue. 데이터 세트: 자연어 처리를 위한 커뮤니티 라이브러리입니다. [Azure Portal](https://portal.azure.com)에서 [Azure Portal](https://portal.azure.com)에서 [Azure Portal](https://portal.azure.com)에 로그인합니다.\n' +
      '* Li et al. (2021) Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Koetetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadori, Joel Lamy-Poirier, Joao Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muthasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nourhan Fahmy, Urvashi Bhattacharyya 유, 스와얌 싱, 사샤 루치오니, 파울로 빌레가스, 막심 쿠나코프, 페도르 즈다노프, 마누엘 로메로, 토니 리, 나다브 티모르, 제니퍼 딩, 클레어 슐레신저, 헤일리 슐코프, 자나 에버트, 트라이 다오, 마얀크 미쉬라, 알렉산더 구, 제니퍼 로빈슨, 캐롤린 제인 앤더슨, 브랜단 돌란-개빗, 덴마크 컨트랙터, 시바 레디, 다니엘 프리드, 드즈미트리 바다나우, 야신 제르나이트, 카를로스 무노즈 페란디스, 션 M. 휴즈, 토마스 울프, 아르준 구하, 레안드로 폰 베르라, 그리고 하르 드 브리스. Starcoder: may the source is you! _ ArXiv_, abs/2305.06161, 2023. URL [https://api.semanticscholar.org/CorpusID:258588247](https://api.semanticscholar.org/CorpusID:258588247).\n' +
      '* Lison et al. [2021] Pierre Lison, Ildiko Pilan, David Sanchez, Montserrat Batet, and Lilja Ovrelid. Anonymisation models for text data: State of the art, challenges and future directions. In _Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)_, pages 4188-4203, Stroudsburg, PA, USA, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.323.\n' +
      '* Liu et al. [2019] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. _ArXiv_, abs/1907.11692, 2019. URL [https://api.semanticscholar.org/CorpusID:198953378](https://api.semanticscholar.org/CorpusID:198953378).\n' +
      '* Lo et al. [2020] Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel Weld. S2ORC: The semantic scholar open research corpus. In _Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics_, pages 4969-4983, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.447. URL [https://aclanthology.org/2020.acl-main.447](https://aclanthology.org/2020.acl-main.447).\n' +
      '* Longpre et al. [2023] S. Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David M. Mimno, and Daphne Ippolito. A pretrainer\'s guide to training data: Measuring the effects of data age, domain coverage, quality, & toxicity. _ArXiv_, abs/2305.13169, 2023. URL [https://api.semanticscholar.org/CorpusID:258832491](https://api.semanticscholar.org/CorpusID:258832491).\n' +
      '* Luccioni and Viviano [2021] Alexandra Luccioni and Joseph Viviano. 상자 안에 뭐가 들어 있지? 커먼 크롤 코퍼스의 바람직하지 않은 내용 분석 _제59회 전산언어학협회 연차총회 및 제11회 자연어처리 국제공동회의(권 2: 짧은 논문)_에서, 페이지 182-189, 온라인, 2021년 8월. 전산언어학협회. doi: 10.18653/v1/2021.acl-short.24. URL [https://aclanthology.org/2021.acl-short.24](https://aclanthology.org/2021.acl-short.24)\n' +
      '* Lukas et al. [2023] Nils Lukas, Ahmed Salem, Robert Sim, Shruti Tople, Lukas Wutschitz, and Santiago Zanella-Beguelin. Analyzing leakage of personally identifiable information in language models. _arXiv [cs.LG]_, February 2023.\n' +
      '* Madaan et al. [2022] Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, and Graham Neubig. Language models of code are few-shot commonsense learners. In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 1384-1403, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL [https://aclanthology.org/2022.emnlp-main.90](https://aclanthology.org/2022.emnlp-main.90).\n' +
      '* Magar and Schwartz[2022] Inbal Magar and Roy Schwartz. 데이터 오염: 암기에서 착취에 이르기까지요. _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics(Volume 2: Short Papers)_, pages 157-165, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-short.18. URL [https://aclanthology.org/2022.acl-short.18](https://aclanthology.org/2022.acl-short.18)\n' +
      '* Magnusson et al. [2023] Ian Magnusson, Akshita Bhagia, Valentin Hofmann, Luca Soldaini, Ananya Harsh Jha, Oyvind Tafjord, Dustin Schwenk, Evan Pete Walsh, Yanai Elazar, Kyle Lo, Dirk Groeneveld, Iz Beltagy, Hannaneh Hajishirzi, Noah A Smith, Kyle Richardson, and Jesse Dodge. Paloma: A benchmark for evaluating language model fit. _arXiv [cs.CL]_, December 2023. URL [https://paloma.allen.ai](https://paloma.allen.ai).\n' +
      '* Marcus et al. [1994] Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark Ferguson, Karen Katz, and Britta Schasberger. The Penn Treebank: Annotating predicate argument structure. In _Human Language Technology: Proceedings of a Workshop held at Plainsboro, New Jersey, March 8-11, 1994_, 1994. URL [https://aclanthology.org/H94-1020](https://aclanthology.org/H94-1020).\n' +
      '* Marcus et al. [1999] Mitchell P. Marcus, Beatrice Santorini, Mary Ann Marcinkiewicz, and Ann Taylor. Treebank-3, 1999. URL [https://catalog.ldc.upenn.edu/LDC99T42](https://catalog.ldc.upenn.edu/LDC99T42).\n' +
      '* McCann 등 [2019] Marco Marelli, Stefano Menini, Marco Baroni, Luisa Bentivogli, Raffaella Bernardi, and Roberto Zamparelli. 구성 분포 의미 모델의 평가를 위한 SICK 치료법 _Proceedings of the 9th International Conference on Language Resources and Evaluation(LREC\'14)_, pages 216-223, Reykjavik, Iceland, May 2014. European Language Resources Association(ELRA). URL [http://www.lrec-conf.org/proceedings/lrec2014/pdf/363_Paper.pdf](http://www.lrec-conf.org/proceedings/lrec2014/pdf/363_Paper.pdf).\n' +
      '* Markov 등(2023a) Todor Markov, Chong Zhang, Sandhini Agarwal, Florentine Eloundou Nekoul, Theodore Lee, Steven Adler, Angela Jiang, and Lilian Weng. 실제 세계에서 원하지 않는 콘텐츠 탐지에 대한 전체론적 접근입니다. _ 진행 상황은... AAAI 인공지능 콘퍼런스. AAAI Conference on Artificial Intelligence_, 37(12):15009-15018, 2023a 6월. ISSN 2159-5399,2374-3468. doi: 10.1609/aaai.v37i12.26752.\n' +
      '* Markov 등(2023b) Todor Markov, Chong Zhang, Sandhini Agarwal, Florentine Eloundou Nekoul, Theodore Lee, Steven Adler, Angela Jiang, and Lilian Weng. 실세계에서 원하지 않는 콘텐츠 검출에 대한 전체론적 접근 방법. _Proceedings of 30-7th AAAI Conference on Artificial Intelligence and Thrd-Fifth Conference on Innovative Applications of Artificial Intelligence and Th13 Symposium on Educational Advances in Artificial Intelligence_, AAAI\'23/IAAI\'23/EAAI\'23. AAAI Press, 2023b. ISBN 978-1-57735-880-0. doi: 10.1609/aaai.v37i12.26752. URL [https://doi.org/10.1609/aaai.v37i12.26752](https://doi.org/10.1609/aaai.v37i12.26752)\n' +
      '* Matic 등(2020) Srdjan Matic, Costas Iordanou, Georgios Smaragdakis, and Nikolaos Laoutaris. 웹 규모에서 중요 한 url을 식별 합니다. _ ACS Internet Measurement Conference_, 2020. URL [https://api.semanticscholar.org/CorpusID:225042878](https://api.semanticscholar.org/CorpusID:225042878).\n' +
      '* Mazzarino 등(2023) Simona Mazzarino, Andrea Minieri, and Luca Gilli. Nerpii: 명명된 엔티티 인식을 수행하고 개인 식별 정보를 생성하기 위한 파이썬 라이브러리. 2023년\n' +
      '* Merity 등(2016) Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer Sentinel Mixture Models. _ arXiv preprint arXiv:1609.07843_, 2016.\n' +
      '* 데이터 보호 및 식별 해제 sdk, 2018. URL [https://microsoft.github.io/presidio/](https://microsoft.github.io/presidio/)입니다.\n' +
      '* Microsoft (2019) Microsoft. Blingfire: 번개 빠른 Finite State Machine and REgular expression manipulation library. [https://github.com/microsoft/Blingfire] (https://github.com/microsoft/Blingfire), 2019.\n' +
      '* Mihaylov et al.(2018) Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. 갑옷이 전기를 전도할 수 있나요? 오픈 북 질문 답변을 위한 새 데이터 세트입니다. _ arXiv [cs.CL]_, September 2018.\n' +
      '* Muennighoff 등(2023a) Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo, Swayam Singh, Xiangru Tang, Leandro Von Werra, and Shayne Longpre. Octopack: 명령어 튜닝 코드 대형 언어 모델입니다. _ arXiv preprint arXiv:2308.07124_, 2023a.\n' +
      '* Muennighoff 등(2023b) Niklas Muennighoff, Alexander M Rush, Boaz Barak, Teven Le Scao, Aleksandra Piktus, Nouamane Tazi, Sampo Pyysalo, Thomas Wolf, and Colin Raffel. 데이터 제약 언어 모델 크기 조정 _ arXiv preprint arXiv:2305.16264_, 2023b.\n' +
      '* Navigli 등(2023) Roberto Navigli, Simone Conia, and Bjorn Ross. 대형 언어 모델의 편향: 원본, 재고 및 토론 _ 제이 Data and Information Quality_, 15(2), jun 2023. ISSN 1936-1955. doi: 10.1145/3597307. URL [https://doi.org/10.1145/3597307](https://doi.org/10.1145/3597307)\n' +
      '* Nunes (2020) Davide Nunes. Preprocessed penn tree bank, 2020. URL [https://zenodo.org/record/3910021](https://zenodo.org/record/3910021).\n' +
      '* Press et al.(2021) Ofir Press, Noah A Smith, and Mike Lewis. 열차 짧음, 테스트 길음: 선형 바이어스를 갖는 주의력은 입력 길이 외삽을 가능하게 한다. 2021년 8월\n' +
      '* Commons (2010) Open Data Commons. ODC-By(Open Data Commons Attribution License) v1.0. [https://opendatacommons.org/licenses/by/1-0/](https://opendatacommons.org/licenses/by/1-0/), 2010. 공고. [액세스된 2023년 8월].\n' +
      '* OpenAI(2023) OpenAI. Gpt-4 기술 보고서. _ ArXiv_, abs/2303.08774, 2023. URL [https://api.semanticscholar.org/CorpusID:257532815](https://api.semanticscholar.org/CorpusID:257532815).\n' +
      '* O\'Hagan et al. (2020)Antonis Papasavva, Savvas Zannettou, Emiliano De Cristofaro, Gianluca Stringhini, and Jeremy Blackburn. 잃어버린 컨테이너의 라이더들: 정치적으로 잘못된 게시판에서 3.5년 동안 4chan 게시물을 올렸습니다. _ 제14회 국제 AAAI Conference On Web and Social Media(ICWSM), 2020_, 2020.\n' +
      '* Penedo 등(2023) Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra-Aimee Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. falcon llm에 대한 정제된 웹 데이터 세트: 웹 데이터 및 웹 데이터만으로 큐레이트된 말뭉치를 성능 저하시킵니다. _ ArXiv_, abs/2306.01116, 2023. URL [https://api.semanticscholar.org/CorpusID:259063761](https://api.semanticscholar.org/CorpusID:259063761).\n' +
      '* Peterson (2020) Joshua Peterson. openwebtext: OpenAI의 공개되지 않은 WebText 데이터 세트 스크래퍼의 Open clone입니다. 이 버전은 2020년 속도를 위해 API 대신 pushshift.io 파일을 사용합니다.\n' +
      '* Petrov 등(2023) Aleksandar Petrov, Emanuele La Malfa, Philip H. S. Torr, and Adel Bibi. 언어 모델 토큰라이저는 2023년 언어 간 불공정성을 도입한다.\n' +
      '* Piktus 등(2023) Aleksandra Piktus, Christopher Akiki, Paulo Villegas, Hugo Laurencon, Gerard Dupont, Sasha Luccioni, Yacine Jernite, and Anna Rogers. ROOTS 검색 도구: LLM에 대한 데이터 투명성입니다. _Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics(Volume 3: System Demonstrations)_, pages 304-314, pages of Canada, Toronto, July 2023. Association for Computational Linguistics. URL [https://aclanthology.org/2023.acl-demo.29](https://aclanthology.org/2023.acl-demo.29)\n' +
      '* Pilehvar and Camacho-Collados (2019) Mohammad Taher Pilehvar and Jose Camacho-Collados. Wic: 문맥에 민감한 의미 표현을 평가하기 위한 문맥 내 단어 데이터세트. _Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1(Long and Short Papers)_, pages 1267-1273, 2019.\n' +
      '* Radford 등(2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 언어 모델은 감독되지 않은 다중 작업 학습자입니다. 2019년 2월\n' +
      '* Rae 등(2021) Jack W. 래, 세바스티안 보르게우, 트레버 카이, 케이티 밀리칸, 조던 호프만, 프란시스 송, 존 아슬란데스, 사라 헨더슨, 로만 링, 수잔나 영, 엘리자 러더포드, 톰 헤니건, 제이콥 메닉, 앨빈 캐시어, 리처드 파월, 조지 반 덴 드리셰, 리사 앤 헨드릭스, 마리베스 라우, 포-센 황, 아멜리아 글레이즈, 요하네스 웰블, 수만스 다타사트리, 사프론 황, 조나단 우에사토, 존 F. J. 멜러, 이리나 히긴스, 안토니아 크레스웰, 네이선 맥앨리스, 에이미 우, 에리히 엘센, 싯탄 M. Jayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela Baganini, L. Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzade, Elena Gribovskaya, Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, N. K. Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Tobias Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson d\'Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew G. Johnson, Blake A. Hechtman, Laura Weidinger, Iason Gabriel, William S. 아이작, 에드워드 록하트, 사이먼 오신데로, 로라 리멜, 크리스 다이어, 오리올 빈야스, 카림 W. Ayoub, Jeff Stanway, L. L. Bennett, Demis Hassabis, Koray Kavukcuoglu, Geoffrey Irving. Scaling language models: Methods, analysis & insights from training gopher. _ ArXiv_, abs/2112.11446, 2021. URL [https://api.semanticscholar.org/CorpusID:245353475](https://api.semanticscholar.org/CorpusID:245353475).\n' +
      '* Raffel 등(2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Unified Text-to-Text Transformer를 사용한 전이 학습의 한계 탐색 _ The Journal of Machine Learning Research_, 21(1):5485-5551, 2020).\n' +
      '* Rajaraman and Ullman (2011) Anand Rajaraman and Jeffrey David Ullman. _ 매시브 데이터셋의 마이닝_. Cambridge University Press, USA, 2011. ISBN 1107015359.\n' +
      '* Razeghi 등(2022) Yasaman Razeghi, Robert L Logan IV, Matt Gardner, and Sameer Singh. 사전 훈련 용어 빈도수가 소수 샷 수치 추론에 미치는 영향 _Findings of the Association for Computational Linguistics: EMNLP 2022_, pages 840-854, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL [https://aclanthology.org/2022.findings-emnlp.59](https://aclanthology.org/2022.findings-emnlp.59).\n' +
      '* Raffel 등(2020)Machel Reid, Victor Zhong, Suchin Gururangan, and Luke Zettlemoyer. M2D2: 대규모 다중 도메인 언어 모델링 데이터세트. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 964-975, page 964-975, United Arab Emirates, December 2022. Association for Computational Linguistics. URL [https://aclanthology.org/2022.emnlp-main.63](https://aclanthology.org/2022.emnlp-main.63)\n' +
      '* Ribeiro 등(2021) Manoel Horta Ribeiro, Jeremy Blackburn, Barry Bradlyn, Emiliano De Cristofaro, Gianluca Stringhini, Summer Long, Stephanie Greenberg, and Savvas Zannettou. 웹을 가로지르는 맨스피어의 진화 _Proceedings of the International AAAI Conference on Web and Social Media_, Volume 15, pages 196-207, 2021.\n' +
      '* Roemmele 등(2011) Melissa Roemmele, Cosmin Adrian Bejan, and Andrew S Gordon. 그럴듯한 대안들의 선택: 상식적인 인과 추론에 대한 평가 2011년 _2011 AAAI 봄 심포지엄 시리즈_에서.\n' +
      '* Roller 등(2021) Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, and Jason Weston. 오픈 도메인 챗봇 구축을 위한 레시피입니다. _Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume_, pages 300-325, Online, April 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.eacl-main.24. URL [https://aclanthology.org/2021.eacl-main.24](https://aclanthology.org/2021.eacl-main.24)\n' +
      '* Sakaguchi 등(2019) Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. WinoGrande: 스케일에서의 적대적 위노그라드 스키마 챌린지. _ arXiv [cs.CL]_, July 2019.\n' +
      '* Santy 등(2023) Sebastian Santy, Jenny T Liang, Ronan Le Bras, Katharina Reinecke, and Maarten Sap. NLPositionality: 데이터 세트 및 모델의 디자인 편향을 특성화 합니다. _ arXiv [cs.CL]_, June 2023. doi: 10.48550/arXiv.2306.01943.\n' +
      '* Sap 등(2021) Maarten Sap, Swabha Swayamdipta, Laura Vianna, Xuhui Zhou, Yejin Choi, and Noah A Smith. 태도를 가진 주석자: 주석자 신념 및 정체성이 독성 언어 탐지를 편향시키는 방법 _ arXiv [cs.CL]_, November 2021.\n' +
      '* Scao 등(2021) Teven Le Scao, Angela Fan, Christopher Akiki, Elizabeth-Jane Pavlick, Suzana Ili\'c, Daniel Hesslow, Roman Castagn\'e, Alexandra Sasha Luccioni, Francocois Yvon, Matthias Galle, Jonathan Tow, Alexander M. Rush, Stella Rose Biderman, Albert Webson, Pawan Sasanka Ammanamchi, Thomas Wang, Benoit Sagot, Niklas Muennighgoff, Albert Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major, Iz Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro Ortiz Suarez, Victor Sanh, Hugo Laurenccon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa Etxabe, Alham Fitzhi Ajit, Amit Alfassy, Anna Rogers, Ariel Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris C. Emezue, Christopher Klamm, Colin Leong, Daniel Alexander van Strien, David Ifelouva Adelani, Dragom 라데프, 에두아르도 곤즈알레스 폰페라다, 에프라트 레브코비즈, 에단 킴, 에얄 바 나탄, 프란체스코 데 토니, 제라드 듀폰트, 독일 크루스제프스키, 지아다 피스틸리, 하디 엘사하르, 함자 벤시마이마, 히에우 트룽 트란, 이안 유, 이드리스 압둘무니어, 아이작 존슨, 이리자르 곤잘레스-디오스, 하비에르 드 라 로사, 제니 침, 제시 도지, 지안 주, 조나단 창, 조르그 프로버그, 조세핀 L. 토빙, 조이딥 바타차르지, 칼리드 알무바라크, 킴보 첸, 카일 로, 르안드로 폰 베르라, 레온 베버, 롱 판, 루브나 벤 알랄, 루도비치 탕기, 마난 데이, 마누엘 로메로 무노즈, 마라이 마수드, 마리아 그랑우리, 마리오 v사브스코, 막스황, 막시민 코아부, 마얀 싱, 마이크 티안 지안 장, 무함마드 알리 자우하르, 무스타파 갈렙, 니산트 수프라마니, 노라 카스너, 누룰라킬라 카미스, 올리비에 응우옌, 오마르 에스페젤, 오나 데 기베르트, 파울로 빌레가스, 피터 헨더슨, 피에르 콜롬보, 프리스실라 A. 아무옥, 퀜틴 루에스트, 레아 하리만, 리시 보마사니, 로베르토 로페즈, 루이 리베로, 살로미 오세이, 삼포 파이살로, 세바스티안 나젤, 샤믹 보세, 샴수딘 하 롱프리, 소미에 니쿠어, S. Silberberg, Suhas Pai, Sydney Zink, Tiago Timponi Torrent, Timo Schick, Tristan Thrush, Valentin Danchev, Vassilina Nikoulina, Veronika Laippala, Violette Lepercq, Vrina Prabhu, Zaid Alyafeai, Zeerak Talat, Arun Raja, Benjamin Heinzerling, Chenglei Si, Elizabeth Salesky, Sabrina J. Mielke, Wilson Y. Lee, Abheesht Sharma, Andrea Santilli, Antoine Chaffin, Arnaud Stiegler, Debajyoti Datta, Eliza Szczechla, Gunjan Chhablani, Han Wang, Harshit Pandey, Hendrik Strobelt, Jason Alan Fries, Jos Rozen, Leo Gao, Lintang Sutawika, M Saiful Bari, Maged S. 알사이바니, 마테오 마니카, 니할 V. 나약, 라이언 티한, 사무엘 알바니에, 성 선, 스룰릭 벤-다비드, 스테판 H. 바흐, 태운 킴, 탈리 베르스, 티볼트페브리, 트리살라 네라즈, 우르미시 타크커, 비카스 라우낙, 시앙 탕, 정신 용, 지칭 선, 쉐이크 브로디, Y 우리, 하다르 토자리에, 아담 로버츠, 형원 정, 재성 태, 제이슨 팡, 오피어 프레스, 콩롱 리, 디팍 나라얀, 하팀 보르파운, 제라드 카스퍼, 제프 라슬리, 맥스 랴비닌, 마야쉬 미슈라, 민지아 장, 모하마드 쇼이비, 미리엄 파이에로, 패트릭 폰 플라텐, 피에르 코네트, 피에르 프랑수아 라발리, 레미 라크루아, 삼얌 라즈반다리, 산치트 간디, 샤덴 스미스, 스테판 레베나, 수라즈 스미스, 팀 디테머스, 아메드 바루와, 아만프레테 싱, 아만프레테 싱, 아나 Tunuguntla, Ehud Reiter, Ekaterina Taktasheva, Ekaterina Voloshina, Eli Bogdanov, Genta Indra Winata, Hailey Schoelkopf, Jan-Christoph Kalo, Jekaterina Novikova, Jessica Zosa Forde, Xiangru Tang, Jungo Kasai, Ken Kawamura, Liam Hazan, Marine Carpuat, Miruna Clinciu, Najoung Kim, Newton Cheng, Oleg Serikov, Omer Antverg, Oskar van der Wal, Rui Zhang, Ruochen Zhang, Sebastian Gehrmann, Shachar Mirkin, S. 오셔 파이스, 타티아나 샤브리나, 토마스 시셜롬, 티안 윤, 토마스 리미시위츠, 베리나 리제르, 비탈리 프로타소프, 블라디슬라프 미하일로프, 야다 프룩사차트쿤, 요나탄 벨린코프, 자커리 밤베르거, 즈데네프크 카스너, 앨리스 루에다, 아만다 페스타나, 아미르 페이즈푸르, 암마르 칸, 에이미 파라낙, 아난다 산타 로사 산토스, 안토니 헤비아, 안티고나 운드라이즈, 아라쉬 아하골, 아레조 압돌라이, 아이야차 타무르, 아자데 하지 호세이니, 바하레 베루지, 벤자민 올루솔라 아지바데, 바라트 쿠마르 삭세나, 카를로스 무노즈 페란디스, 덴마크 계약자, 데이비드 M. Lansky, Davis David, Douwe Kiela, Duong Anh Nguyen, Edward Tan, Emily Baylor, Ezinwanne Ozoani, Fatim Tahirah Mirza, Frankline Ononniwu, Habib Rezanejad, H.A. Jones, Indrani Bhattacharya, Irene Solaiman, Irina Sedenko, Isar Nejadgholi, Jan Passmore, Joshua Seltzer, Julio Bonis Sanz, Karen Fort, Livia Macedo Dutra, Mairon Samagaio, Maraim Elbadri, Margot Mieskes, Marissa Gerchick, Martha Akinolu, Michael McKenna, Mike Qiu, M. K. Ghauri, Mykola Burynok, Nafis Abrar, Nazneen Rajani, Nour Elkott, Nourhan Fahmy, Olanrewaju Samuel, Ran An, R. P Kromann, Ryan Hao, Samira Alizadeh, Sarmad Shubber, Silas L. 왕, 소라브 로이, 실비안 비구에르, 탄콩 르, 토이 오예바데, 트리우 응우옌 하이 르, 요요 양, 자커리 카일 응우옌, 아비나브 카샤프, 아파사시아노, 앨리슨 칼라한, 아니마 슈클라, 안토니오 미란다-에스카라다, 아유시 쿠마르 싱, 벤자민 베일하르즈, 보 왕, 카이오 마테우스 폰세카 데 브리토, 첸시 저우, 치락 자인, 추신 쉬, 클레멘타인 포리에, 다니엘 르온 페리난, 다니엘 몰라노, 다이안 유, 엔리케 만자바카스, 파비오 바스, 플로리안 푸리만, 가브리엘 알타이, 지야세딘 바이라크, 걸리 번즈, 헬레나 U. Vrabec, Iman I.B. Bello, Isha Dash, Ji Soo Kang, John Giorgi, Jonas Golde, Jose David Posada, Karthi Sivaraman, Lokesh Bulchandani, Lu Liu, Luisa Shinzato, Madeleine Hahn de Bykhovetz, Maiko Takeuchi, Marc Pamies, Maria Andrea Castillo, Marianna Nezhurina, Mario Sanger, Matthias Samwald, Michael Cullan, Mthias Samwald, M Wolf, Mina Mihaljcic, Minna Liu, Moritz Freidank, Myungsun Kang, Natasha Seelam, Nathan Dalberg, Nicholas Michio Broad, Nikolaus Muellner, Pascale Fung, Patricia Haller, R. Chandrasekhar, Renata Eisenberg, Robert Martin, Rodrigo L. Canalli, Roslaine Su, Ruisi Su, Samuel Cahywijaya, Samuele Garda, Shlock S Deshmukh, Shubhanshu Mishra, Sid Kiblawi, Simon Ott, Sinee Sang-aroonsiri, Srishi Kumar, Stefan Schweter, Sushil Pratap Bharati, T. A. Laud, Th\'eo Gigant, Tomoya Kainuma, Wojciech Kusa, Yanis Labrak, Yashasvi Bajaj, Y. Venkatraman, Yifan Xu, Ying Xu, Yu Xu, Zhe Xiao Tan, Zhongli Xie, Zifan Ye, Mathilde Bras, Younes Belkada, and Thomas Wolf. Bloom: 176b 매개 변수 오픈 액세스 다국어 언어 모델입니다. _ ArXiv_, abs/2211.05100, 2022. URL [https://api.semanticscholar.org/CorpusID:253420279](https://api.semanticscholar.org/CorpusID:253420279).\n' +
      '* Sennrich et al. (2016) Rico Sennrich, Barry Haddow, and Alexandra Birch. 하위 단어 단위를 가진 희귀 단어의 신경망 기계 번역 _Proceedings of the 54 Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 1715-1725, Berlin, Germany, August 2016. Association for Computational Linguistics. doi: 10.18653/v1/P16-1162. URL [https://aclanthology.org/P16-1162](https://aclanthology.org/P16-1162).\n' +
      '* Seshadri 등(2023) Preethi Seshadri, Sameer Singh, and Yanai Elazar. 텍스트-이미지 생성에서의 바이어스 증폭 패러독스. _ arXiv preprint arXiv:2308.00755_, 2023.\n' +
      '* Shazeer(2020) Noam Shazeer. GLU 변형은 변압기를 개선합니다. 2020년 2월\n' +
      '* Soldaini and Lo (2023) Luca Soldaini and Kyle Lo. peS2o(Pretraining Efficiently on S2ORC) 데이터셋. 기술 보고서, Allen Institute for AI, 2023. ODC-By, [https://github.com/allenai/pes2o](https://github.com/allenai/pes2o).\n' +
      '* Srivastava 등(2017) Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adria Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W.\n' +
      '\n' +
      'Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Johan Andreassen, Andrea Madotto, Andrea Santilli, Andreas Stuhlmuller, Andrew M. 다이, 앤드류 라, 앤드류 람피넨, 앤디 주, 안젤라 지앙, 안젤리카 첸, 아네슬릭, 아네임스 구프타, 안토니오 노렐리, 아누 벤카테시, 아울 메네스, 아룬 키루바란, 아셔 사바왈, 오스틴 헤릭, 아비라 에프라트, 아이쿠트 에르뎀, 아일라 카라카스, 바투한 오주르트, 베남 히스테라트니아, 블레이크 호왈드, 베란 오리니온, 찰스 라토프, 캐서린 스틴슨, 세드릭 아구에타, 세드릭 아구에타, 크리스토퍼 포트, 신디 라미레즈, 코트니 애쉬크래프트, 크리스티나 가바시아, 다미 실레오, 댄 가렛, 댄 헨드릭스, 댄 킬만, 댄 로스, C. 다니엘 프리먼, 다니엘 카샤비, 다니엘 레비, 다니엘 모스구이 곤잘레스, 다니엘 페르스, 대니 에르난데스, 다길보아, 다비드 드라카드, 다비드 주겐스 Balis, Jonathan Batchelder, Jonathan Berant, Jorg Frohberg, Jos Rozen, Jose Hernandez-Orallo, Joseph Boudeman, Joseph Guerr, Joseph Jones, Joshua B. Tenenbaum, Joshua S. 규칙, 조이스 추아, 카밀 칸클레즈, 카렌 리브스, 카렌 크라우스, 카르틱 고팔라크리시난, 카테리나 이그나티예바, 카자 마카르트, 카우스트르 드홀, 케빈 김펠, 케빈 오먼디, 코리 월러스 마테우손, 크리스텐 샤프툴로, 크세니아 슈쿠루타, 쿠마르 쉬리드하, 카일 맥도넬, 카리아 리차드손, 리장, 리안 듀간, 리안후이 진, 리디아 콘트레라스-오찬도, 루이필리스 모렌치, 루이필리스-콜론, 루카 모첼라, 루카 루카 라멜, 루카 노블, 루드비히 슈미트, 루이필리스-콜론, 루카 메츠, 루피 케렘 세넬, 마르텐 보스마, 마르텐 사프, 마르트제 테르 호베, 마힌 파루키, 마나알 파루키, 만타스 마제이카, 마르코 바투란, 마르코 마렐리, 마르코 마루, 마리아 호세 라 라이어, 노아 콘스탄트, 노아 콘스탄트, 노아 원, 올리버 장, 오마르 아가, 오마르 엘바그다디, 오메르 레비, 오웨인 에반스, 파블로 안토니오 모레노 카사레스, 파스도시, 파스칼 풍, 폴 푸 량, 폴 비콜, 페가 알리포모르올라바시, 페위안 랴오, 퍼시 량, 피터 W 창, 피터 에커슬리, 푸 몬 히투, 피뉴 황, 피오트르 미코프스키, 피유시 파틸, 푸야 페제슈 푸우, 칭 류, 진랑 첸, 라빈 반자드, 레이철 에이타 루돌프, 래퍼 가브리엘, 라헬 하바커, 라몬 리스코, 라파엘 밀리에르, 리듬 가그, 리처드 반스, 리프 A. 사우루스, 라쿠 아라카와, 로베 레이맥커스, 로베르 프랑크, 로한 시칸드, 로난 프랑크, 로한 시칸드, 로난 르 브라스, 로난 류, 로난 제이콥 Mohammad, Sajant Anand, Sam Dillavou, Sam Shleifer, Sam Wiseman, Samuel Gruetter, Samuel R. 보우만, 사무엘 스턴 쇤홀즈, 상현 한, 산지예프 콰트라, 사라 A. 루스, 사릭 가저리안, 사얀 고쉬, 션 케이시, 세바스티안 비스코프, 세바스티안 게르만, 세바스티안 함단, 샤론 저우, 샤샨 스리바스티안 스리바스티안 데브나, 시몬 멜지, 스펜서 레디, 샤랑 샤이더, 시마 샤이더, 시마 샤이더, 시마 샤이더, 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리하 스리 모방 게임을 넘어 언어 모델의 기능을 정량화하고 외삽합니다. _ Transactions on Machine Learning Research_, 2023. ISSN 2835-8856. URL [https://openreview.net/forum?id=uyTL5bvosj](https://openreview.net/forum?id=uyTL5bvosj).\n' +
      '*[31]Stability AI. Stable LM 2 1.6B 소개. [https://github.com/kingoflolz/mesh-transformer-jax] (https://github.com/kingoflolz/mesh-transformer-jax), 2024.\n' +
      '* Subramani et al. [2023] Nishant Subramani, Sasha Luccioni, Jesse Dodge, and Margaret Mitchell. Detecting personal information in training corpora: an analysis. In _Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)_, pages 208-220, Toronto, Canada, July 2023. Association for Computational Linguistics. URL [https://aclanthology.org/2023.trustnlp-1.18](https://aclanthology.org/2023.trustnlp-1.18).\n' +
      '* Thoppilan et al. [2022] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, Yaguang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed Chi, and Quoc Le. LaMDA: Language models for dialog applications. _arXiv [cs.CL]_, January 2022.\n' +
      '* Tirumala et al. [2023] Kushal Tirumala, Daniel Simig, Armen Aghajanyan, and Ari S. Morcos. D4: Improving llm pretraining via document de-duplication and diversification. _ArXiv_, abs/2308.12284, 2023. URL [https://api.semanticscholar.org/CorpusID:261076313](https://api.semanticscholar.org/CorpusID:261076313).\n' +
      '* [컴퓨터]Together Computer. Redpajama-data-v2, 10 2023a. URL [https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2).\n' +
      '* [컴퓨터]Together Computer. Redpajama-incite-base-3b-v1, 5 2023b. URL [https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1).\n' +
      '* [컴퓨터]Together Computer. Redpajama-data-1t, 4 2023c. URL [https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T)입니다.\n' +
      '* [Touvron et al. 2023] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: 오픈하고 효율적인 기초 언어 모델입니다. _ ArXiv_, abs/2302.13971, 2023a. URL [https://api.semanticscholar.org/CorpusID:257219404](https://api.semanticscholar.org/CorpusID:257219404).\n' +
      '* [Touvron et al. 2023] Hugo Touvron, Louis Martin, Kevin R. 스톤, 피터 알버트, 아마드 알마하이리, 야스민 바베이, 니콜라이 바슐리코프, 소미야 바트라, 프라지왈 바르가바, 슈루티 보살, 다니엘 M. Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony S. 하트혼, 사하르 호세이니, 루이 호우, 하칸 이난, 마르신 카다스, 빅토르 케르케즈, 매디안 하바, 이사벨 M. Kloumann, A. V. Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenx Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rishi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, R. Subramanian, Xia Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zhengxu Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 라마 2: 기반 및 미세 조정 채팅 모델을 엽니다. _ ArXiv_, abs/2307.09288, 2023b. URL [https://api.semanticscholar.org/CorpusID:259950998](https://api.semanticscholar.org/CorpusID:259950998).\n' +
      '* Vidgen and Derczynski (2020) Bertie Vidgen and Leon Derczynski. 폭언 훈련 데이터의 방향, 체계적인 검토: 쓰레기 인, 쓰레기 아웃입니다. _ PloS one_, 15(12):e0243300, December 2020. ISSN 1932-6203. doi: 10.1371/journal.pone.0243300.\n' +
      '* Wallace 등(2021) Eric Wallace, Tony Zhao, Shi Feng, and Sameer Singh. NLP 모델에 대한 은폐된 데이터 중독 공격입니다. _Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_, pages 139-150, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.13. URL [https://aclanthology.org/2021.naacl-main.13](https://aclanthology.org/2021.naacl-main.13)\n' +
      '* Wang 등(2018) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. 글루: 자연어 이해를 위한 다중 작업 벤치마크 및 분석 플랫폼. _ arXiv preprint arXiv:1804.07461_, 2018.\n' +
      '* Wang 등(2019) Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 슈퍼글루: 범용 언어 이해 시스템을 위한 보다 엄격한 벤치마크. _ Neural Information Processing Systems_, 32, 2019의 발전.\n' +
      '* Wang and Komatsuzaki (2021) Ben Wang and Aran Komatsuzaki. GPT-J-6B: 60억 Parameter Autoregressive Language Model. [https://stability.ai/news/introducing-stable-lm-2] (https://stability.ai/news/introducing-stable-lm-2), 2021년 5월.\n' +
      '* Welbl 등(2017) Johannes Welbl, Nelson F Liu, and Matt Gardner. 크라우드소싱 객관식 과학 질문입니다. _ arXiv [cs.HC]_, 2017년 7월\n' +
      '* Welbl 등(2021) Johannes Welbl, Amelia Glaese, Jonathan Uesato, Sumanth Dathathri, John Mellor, Lisa Anne Hendricks, Kirsty Anderson, Pushmeet Kohli, Ben Coppin, and Po-Sen Huang. 언어 모델을 해독하는 데 어려움이 있습니다. _Findings of the Association for Computational Linguistics: EMNLP 2021_, pages 2447-2469, Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.findings-emnlp.210. URL [https://aclanthology.org/2021.findings-emnlp.210](https://aclanthology.org/2021.findings-emnlp.210)\n' +
      '* Weninger 등(2013) Tim Weninger, Xihao Avi Zhu, Jiawei Han. 소셜 뉴스 사이트의 토론 스레드에 대한 탐색 Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining_, New York, NY, USA, August 2013. ACM. ISBN 9781450322409. doi: 10.1145/2492517.2492646.\n' +
      '* Wenzek 등(2020a) Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzman, Armand Joulin, and Edouard Grave. CCNet: 웹 크롤링 데이터로부터 고품질의 단일 언어 데이터 세트를 추출하는 단계. _12번째 언어 자원 및 평가 회의의 진행문_에서, 4003-4012 페이지, 프랑스 마르세유, 2020a 5. 유럽 언어 자원 협회. ISBN 979-10-95546-34-4. URL [https://aclanthology.org/2020.lrec-1.494](https://aclanthology.org/2020.lrec-1.494)\n' +
      '* Wenzek 등(2020b) Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzman, Armand Joulin, and Edouard Grave. Ccnet: 웹 크롤 데이터에서 고품질 단일 언어 데이터 세트를 추출합니다. _제12회 언어 자원 및 평가 회의의 진행문_ 에서, 페이지 4003-4012, 2020b.\n' +
      '*Weston et al. (2015) Jason Weston, Antoine Bordes, Sumit Chopra, and Tomas Mikolov. i-완전한 질문 응답: 필수 구성 요소 장난감 작업 집합입니다. _ arXiv: Artificial Intelligence_, 2015. URL [https://api.semanticscholar.org/CorpusID:3178759](https://api.semanticscholar.org/CorpusID:3178759).\n' +
      '* Wenzek 등(2017) Albert Xu, Eshaan Pathak, Eric Wallace, Suchin Gururangan, Maarten Sap, and Dan Klein. 언어 모델을 해독하는 것은 소수 목소리를 소외시킬 위험이 있다. _Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_, pages 2390-2397, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.190. URL [https://aclanthology.org/2021.naacl-main.190](https://aclanthology.org/2021.naacl-main.190)\n' +
      '* Xue 등(2020) Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. mT5: 대용량 다국어 사전 훈련된 텍스트-텍스트 변환기. _ arXiv [cs.CL]_, October 2020.\n' +
      '* Yang et al.(2023) Shuo Yang, Wei-Lin Chiang, Lianmin Zheng, Joseph E. Gonzalez, and Ion Stoica. 변경 된 샘플이 있는 언어 모델에 대 한 벤치마크 및 오염을 다시 생각 합니다. _ ArXiv_, abs/2311.04850, 2023. URL [https://api.semanticscholar.org/CorpusID:265050721](https://api.semanticscholar.org/CorpusID:265050721).\n' +
      '* 옐프(2013) 옐프. 비밀을 탐지합니다. [https://github.com/Yelp/detect-secrets] (https://github.com/Yelp/detect-secrets), 2013. v1.4.0.\n' +
      '* Zannettou 등(2018) Savvas Zannettou, Barry Bradlyn, Emiliano De Cristofaro, Haewoon Kwak, Michael Sirivianos, Gianluca Stringini, and Jeremy Blackburn. 개브란 무엇인가: 자유로운 발언의 보루나 정통한 반향실. _Companion Proceedings of the Web Conference 2018_, WWW\'18, page 1007-1014, Republic and Canton of Geneva, CHE, 2018. International World Wide Web Conferences 운영 위원회. ISBN 9781450356404. doi: 10.1145/3184558.3191531. URL [https://doi.org/10.1145/3184558.3191531](https://doi.org/10.1145/3184558.3191531)\n' +
      '* Zellers 등(2019) Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 헬라스바그: 기계가 정말로 당신의 문장을 끝낼 수 있을까요? _Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics_, 2019.\n' +
      '* 장(2022) 하오장. 언어 모델 분해: 언어 모델의 종속성과 상관관계를 정량화한다. _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 2508-2517, 아랍에미리트 아부다비, December 2022. Association for Computational Linguistics. URL [https://aclanthology.org/2022.emnlp-main.161](https://aclanthology.org/2022.emnlp-main.161).\n' +
      '* Zhang 등(2024) Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu. TinyLlama: 오픈 소스 소형 언어 모델입니다. _ arXiv [cs.CL]_, January 2024.\n' +
      '\n' +
      '## Appendix Acknowledgements\n' +
      '\n' +
      '돌마는 많은 개인과 기관의 지원이 없었다면 불가능했을 것이다. 이 작업의 실험 구성 요소는 AMD 및 CSC와의 파트너십을 통해 가능해져 LUMI 슈퍼컴퓨터를 사용할 수 있다. 우리는 조나단 프랭클, 코디 블라케니, 매튜 레빗, 다니엘 킹과 나머지 모자이크ML 팀이 우리 데이터의 예비 버전에 대한 실험의 결과를 공유해 준 것에 감사드린다. 우리는 데이터 셔플링에 영향을 미치고 있는 난수 발생기 버그를 해결하기 위한 제안으로 트위터에 메시지를 보낸 비탈리 칠레에 감사드린다. 우리는 에르판 알-호사미, 셰인 롱프리 및 그레고리 야누니가 자체 대규모 사전 훈련 데이터 실험의 결과를 공유한 것에 감사드린다. 오픈 데이터셋과 데이터 유통 형식에 대해 사려 깊은 논의를 한 Ce Zhang과 Maurice Weber of Together AI에 감사드린다. 우리는 데이터 라이센싱과 데이터 처리 프레임워크에 대해 논의한 스텔라 비더만과 아비야 스카우런에게 감사드린다. 우리는 AI2 니콜 드카리오, 맷 라츠케, 대렐 플레사스, 켈시 맥밀란, 캐리사 쇼닉, 샘 스콘스버그, 마이클 슈미츠의 동료들이 이 프로젝트의 원활한 진행을 지원하는 웹사이트, 디자인, 내부 및 외부 커뮤니케이션, 예산 책정 및 기타 활동에 도움을 준 것에 감사드린다. 끝으로 AI2의 동료들과 친밀한 협력자들로부터 프리트비라지(라지) 암마나브로루, 마리아 안토니악, 크리스 캘리슨-버치, 피터 클라크, 프라뎁 다시기, 니콜 드카리오, 더그 다우니, 알리 파하디, 수친 구루랑간, 시드니 레빈, 마르텐 삽, 루드비히 슈미트, 윌 스미스, 율리아 츠베코프, 다니엘 S 등 유익한 토론과 피드백에 감사드린다. 용접\n' +
      '\n' +
      '## 부록 B 작성자 기여\n' +
      '\n' +
      '돌마는 많은 팀원들과 협력자들의 도움 없이는 불가능할 것입니다. 주간 프로젝트 회의, 메시징 앱 및 문서는 AI2에서 누구나 액세스할 수 있었다. 돌마에 대한 주요 결정은 특정 주제(예: 법적, 자금 지원)를 제외하고 이러한 채널에서 종종 이루어졌다. 많은 사람들이 돌마의 노력에 참여했지만(Acknowledgements SSA 참조), 이 논문의 저자는 퍼즐의 중요한 조각을 소유하고 전달한 사람들이다. 아래에서 그들의 기여도(알파벳 순서로 저자)를 상세히 설명한다.\n' +
      '\n' +
      '**데이터 수집 및 원본별 데이터 처리** 에 대 한 기여자에는 Akshita Bhagia, Dirk Groeneveld, Rodney Kinney, Kyle Lo, 더스틴 Schwenk 및 Luca Soldaini가 포함 됩니다. 모든 사람들은 이용 가능한 출처와 추구할 출처 주변의 모범 사례 및 결정에 대한 문헌 검토에 기여했다. 악시타 바기아, 로드니 키니, 더스틴 슈웬크 및 루카 솔다이니는 소스별 설계 결정을 위해 1B 모델로 데이터 수집 및 처리 및 절제 실험의 대부분을 처리했다. 카일 로와 루카 솔다이니는 우리의 출처 선택을 알리기 위해 법적 논의를 처리했다.\n' +
      '\n' +
      '**인프라 및 도구** 에 대한 기여자에는 Russell Authur, Dirk Groeneveld, Rodney Kinney, Kyle Lo 및 Luca Soldaini가 포함됩니다. 로드니 키니, 카일 로, 루카 솔다이니는 대규모 코퍼스 처리에 사용되는 공유 툴킷을 설계하고 구현했다. 더크 그로네벨트는 중복 제거 및 오염 제거를 위해 블룸 필터를 썼다. 러셀 오투르는 커먼 크롤 데이터의 획득과 저장을 위한 툴킷을 썼다.\n' +
      '\n' +
      '**원본 불가지론 데이터 처리** 에 대한 기여자에는 Khyathi Chandu, Yanai Elazar, Rodney Kinney, Kyle Lo, Xinxi Lyu, Ian Magnusson, Aakanksha Naik, Abhilasha Ravichander, Zejiang Shen 및 Luca Soldaini가 포함됩니다. 카야티 찬두와 아칸샤 나이크는 독성 텍스트 필터를 개발했다. 카일 로와 신시 류가 그것을 평가하는 데 도움을 주었다. Luca Soldaini는 언어 필터링 접근법을 개발했다. 로드니 키니, 제장셴, 루카 솔다이니가 \'퀄리티\' 필터를 개발했다. 야나이 엘라자르는 반복되는 \\(n\\)-gram 서열을 확인했다. Abhilasha Ravichander, Kyle Lo, Luca Soldaini는 PII 필터를 개발했다. 제시 도지와 이안 매그누슨은 평가 세트 오염 제거 접근법을 개발했다.\n' +
      '\n' +
      '**제거 실험**의 기여자에는 Iz Beltagy, Akshita Bhagia, Jesse Dodge, Dirk Groeneveld, Rodney Kinney, Kyle Lo, Ian Magnusson, Matthew Peters, Kyle Richardson, 더스틴 Schwenk, Luca Soldaini, Nishant Subramani, Oyvind Tafjord 및 Pete Walsh가 포함됩니다. 이 작업에는 계산 제약 조건이 주어진 실험 설계 및 우선 순위 지정, 1B 모델 실험 구현 및 실행, 결과 해석이 포함되었다. 특히 평가 툴킷에 대한 오이빈드 타피오르의 작업과 모델 구현에 대한 피트 월시의 작업이 매우 중요했다.\n' +
      '\n' +
      '최종 Dolma 아티팩트에 대 한 **사후 실험 및 분석** 에 기여 합니다. 벤 보긴은 카일 로와 니클라스 뮌니고프의 지원을 받아 다양한 코드 혼합물의 영향을 평가하기 위해 1B 모델 가중치에 대한 조사 실험을 주도했다. 야나이 엘라자르는 데이터 분석 도구를 실행하여 돌마의 구성을 요약하고 문서화했다. 발렌틴 호프만은 카일 로의 지원을 받아 토큰화 생식력 분석을 주도했다. Ananya Harsh Jha와 Ian Magnusson은 Luca Soldaini의 지원을 받아 다른 열린 데이터 세트에서 기본 1B 모델을 훈련하고 평가하는 실험을 수행했다. 사친 쿠마르와 제이콥 모리슨은 카일 로의 지원을 받아 언어 식별 및 독성 분류기 선택에 있어 체계적인 문제에 대한 분석을 수행했다. 니클라스 뮌니고프는 카일 로와 루카 솔다이니의 지원을 받아 커먼 크롤 데이터에 사용된 다른 필터 간의 상관 관계를 분석했다.\n' +
      '\n' +
      '**라이선스 및 릴리스 정책** 에 대한 기여자에는 David Atkinson, Jesse Dodge, Jennifer Dumas, Nathan Lambert, Kyle Lo, Crystal Nam 및 Luca Soldaini가 포함됩니다. 데이빗 앳킨슨, 제시 도지, 제니퍼 듀마스, 크리스탈 남이 데이터 라이선스에 대한 연구, 사전 훈련 데이터에 대한 위험 수준 결정, 릴리스 정책 정의 등 이 대부분을 주도했다. 카일 로와 루카 솔다이니는 이 과정 전반에 걸쳐 피드백을 제공하고 출시에 필요한 기술적 세부 사항을 처리했다. 네이쓴 램버트는 릴리스 프로세스에 대한 피드백을 제공했으며 특히 외부 커뮤니케이션을 중심으로 실제 릴리스 전략을 처리했다.\n' +
      '\n' +
      '위의 모든 기여자는 해당 구성 요소의 **문서화 및 쓰기** 를 도왔습니다. 특히, 리 루시는 언어 모델, 개방형 말뭉치 및 사전 훈련 말뭉치 생성 관행에 대한 광범위한 문헌 검토를 제공했다. 에마 스트러벨은 우리의 원고에 대해 귀중한 피드백을 주었다. 네이쓴 램버트는 블로그 게시물과 돌마에 대한 외부 대면 커뮤니케이션의 다른 형태에 대한 피드백을 도왔다.\n' +
      '\n' +
      '한나네 하지시르지, 노아 스미스 및 루크 제틀모이어는 광범위한 전략, 작성, 자원 모집 및 제공을 포함하여 프로젝트에 **지도**했다. OLMo 프로젝트가 주도함에 따라 Iz Beltagy, Jesse Dodge 및 Dirk Groeneveld는 다른 중요한 OLMo 프로젝트 워크스트림과의 **가시성 및 조정** 을 도왔다. 특히, 우리는 노아 스미스가 돌마라는 이름을 생각해 낸 것을 인정한다.\n' +
      '\n' +
      '마지막으로 카일로와 루카 솔다이니는 돌마 프로젝트 전반을 **주도했으며 프로젝트 관리, 계획 및 설계, 법률 및 윤리 위원회와의 논의, 데이터 및 컴퓨팅 파트너십, 인프라, 도구화, 구현, 실험, 작성/문서화 등을 포함한 모든 측면에 참여했다.\n' +
      '\n' +
      '## 부록 C 최대 LMs에 대한 데이터 사전 훈련에 대한 세부 정보\n' +
      '\n' +
      '데이터 세트 큐레이션에 대한 명확한 문서화 및 투명성의 필요성을 설명하기 위해 가장 큰 LM의 사전 트레이닝 데이터 큐레이션 관행(또는 보고 부족)에 대한 고수준의 개요를 제공한다.\n' +
      '\n' +
      '### Llama 2 (Touvron et al., 2023b)\n' +
      '\n' +
      'Touvron 등(2023b)은 Llama 2에 사용되는 사전 트레이닝 데이터에 대한 제한된 정보를 제공한다; 우리는 그들의 원고의 섹션 2.1, 4.1 및 A.6으로부터 수집할 수 있는 것을 요약한다:\n' +
      '\n' +
      '1. **Corpus 크기**. 2T 토큰.\n' +
      '2. **데이터 원본**. N/A는 메타 사용자 데이터를 사용하는 것을 피했다.\n' +
      '3. **PII**. 많은 양의 PII를 포함하는 것으로 알려져 있는 특정 웹사이트에서 제외된 데이터로 보고되었지만 이러한 사이트는 공개되지 않았다.\n' +
      '4. **독성**. 명확하게 논의되지는 않았지만 독성 필터링을 수행하지 않은 것으로 보이며, 대신 나중에 훈련 단계에서 독성 텍스트 생성을 처리하도록 선택한다. 그들은 ToxiGen(Hartvigsen et al., 2022) 상에서 피니튜닝된 HateBERT(Caselli et al., 2021) 분류기를 사용하여 각각의 문서 라인을 스코어링(그리고 문서 레벨 스코어를 생성하기 위해 평균화)한 사후 분석의 결과를 보고한다.\n' +
      '5. **언어 ID**. 사전 트레이닝 데이터 큐레이션에 사용된 것처럼 명시되지 않았지만, 그들은 검출된 언어에 대해 0.5 임계값을 갖는 fastText Language ID를 사용하여 사전 트레이닝 데이터세트의 사후 분석을 제공한다. 우리는 이것이 Llama(Touvron et al., 2023a)에 사용된 CCNet 라이브러리(Wenzek et al., 2020a)에서도 볼 수 있듯이 데이터 큐레이션을 사전 훈련하는 데 사용된 것과 동일한 프로토콜일 가능성이 있다고 가정한다.\n' +
      '6. **품질** 입니다. N/A\n' +
      '7. **중복 제거**. N/A\n' +
      '8. **오염 제거**. 그들은 그들의 중복 제거 방법에 대한 광범위한 보고를 제공하며, 이는 Lee 등(2022)으로부터의 ngram 중복 제거 도구의 수정된 버전에 의존한다.\n' +
      '9. **기타**. 특정 소스를 업샘플링했지만 자세한 내용은 보고하지 않았습니다. 그들은 또한 인구통계학적 정체성과 영어 대명사에 대한 집계 통계에 대해 PaLM 2(Anil et al., 2023)에서와 유사한 분석을 보고한다.\n' +
      '\n' +
      '### PaLM 2 (Anil et al., 2023)\n' +
      '\n' +
      'Anil 등(2023)은 PaLM 2에 사용되는 사전 트레이닝 데이터에 대한 제한된 정보를 제공한다; 우리는 그들의 원고의 섹션 3 및 D1로부터 수집할 수 있는 것을 요약한다:\n' +
      '\n' +
      '1. **Corpus 크기**. PaLM을 훈련시키는데 사용된 것(Chowdhery et al., 2022)보다 더 큰 것 이외에는 보고되지 않았다.\n' +
      '2. **데이터 원본**. 웹 문서, 책, 코드, 수학 및 대화 데이터를 사용하는 것 외에는 보고되지 않습니다.\n' +
      '3. **PII**. 수행된 필터링으로 보고되었지만 자세한 내용은 없습니다.\n' +
      '4. **독성**. 독성 텍스트는 Perspective API를 사용하여 식별되지만 재생에 필요한 세부 정보(즉, 텍스트 단위, 임계값)가 부족하다. 제거에 대한 자세한 내용은 없습니다. 그들은 대조군 토큰의 사용을 통해 독성을 다루는 것으로 보고했지만 이 방법에 대한 충분한 세부 정보를 제공하지 않는다.\n' +
      '5. **언어 ID**. 가장 빈번한 언어와 빈도를 보고합니다. 재생에 필요한 세부 정보 부족(예: 텍스트 단위, 사용된 도구, 임계값).\n' +
      '\n' +
      '6. **품질** 입니다. 수행된 필터링으로 보고되었지만 자세한 내용은 없습니다.\n' +
      '7. **중복 제거**. 수행된 필터링으로 보고되었지만 자세한 내용은 없습니다.\n' +
      '8. **오염 제거**. N/A\n' +
      '9. **기타**. Anil 등(2023)은 특정 인구통계학적 아이덴티티가 얼마나 자주 데이터에 표현되는지(또는 그렇지 않은지) 집계 통계를 보고한다. 이러한 통계는 아이덴티티(예를 들어, 미국어) 또는 영어 대명사를 포함한다. 이들은 KnowYourData 또는 GoogleCloud에서 사용할 수 있는 도구와 같은 도구를 사용하여 식별되었지만 원고는 복제에 필요한 세부 사항이 부족하다.\n' +
      '\n' +
      '### GPT-4 (OpenAI, 2023)\n' +
      '\n' +
      'OpenAI(2023)는 GPT-4에 사용되는 사전 훈련 데이터에 대한 제한된 정보를 제공하며, 시스템 카드의 원고 섹션 2, 부록 C 및 D, 각주 5, 6, 10 및 27, 섹션 1.1 및 3.1에서 수집할 수 있는 것을 요약한다.\n' +
      '\n' +
      '1. **Corpus 크기**. N/A\n' +
      '2. **데이터 원본**. N/A는 (1) 데이터가 인터넷과 제3자 제공자로부터 모두 공급되었다고 보고한 것 외에도 (2) 데이터는 주로 2021년 9월 이전에 미량의 최신 데이터와 함께 공급되었으며 (3) GSM-8K(Cobbe et al., 2021)를 전체 사전 훈련 믹스의 작은 일부로 포함했다.\n' +
      '3. **PII**. N/A\n' +
      '4. **독성**. 마르코프 등(2023b)에 이어 사전-기반 휴리스틱과 맞춤 분류기의 조합을 사용하여 "에로틱 콘텐츠"를 포함하는 사전 트레이닝으로부터 그들의 사용 정책을 위반하는 문서를 제거하였다.\n' +
      '5. **언어 ID**. 사전 교육 데이터의 대부분이 영어로 되어 있다고 보고하는 것 외에 N/A입니다.\n' +
      '6. **품질** 입니다. N/A\n' +
      '7. **중복 제거**. N/A\n' +
      '8. **Mixture**.\n' +
      '9. **오염 제거**. 오염 제거 절차에 대한 논의는 없었지만 대신 전문 및 학업 시험에 대한 오염 정도를 측정하는 사후 통계와 여러 학문적 벤치마크를 보고했다. 사전 트레이닝 데이터 예에 대한 테스트 예의 정확한 부분 문자열 일치(백색 공간을 제거한 후)에 기초하여 오염을 식별하는 방법. 그들은 BIG-Bench(Srivastava et al., 2023)로 약간의 오염을 보고했다.\n' +
      '10. **기타**. GPT-4에 대해 "데이터 고고학"을 수행하는 수많은 작업, 즉 GPT-4에서 사용되는 사전 훈련 데이터에 대한 정보를 암기용 프로브를 통해 수집하려고 시도하는 작업이 있다. 예를 들어 Chang 등(2023)은 GPT-4가 저작권이 있는 책들로부터 시퀀스들을 생성할 수 있음을 보여준다. 우리는 이러한 모든 조사 작업을 조사하려고 시도하지 않는다.\n' +
      '\n' +
      '### Claude (Anthropic, 2023)\n' +
      '\n' +
      '불행히도, 우리는 클로드에게 사용된 사전 훈련 데이터에 대해 거의 알지 못한다.\n' +
      '\n' +
      '### LLaMA (Touvron et al., 2023a)\n' +
      '\n' +
      'Touvron 등(2023a)은 LLaMA를 훈련하는 데 사용되는 사전 훈련 데이터에 대한 몇 가지 정보를 제공하며, 우리는 원고의 섹션 2.1에서 수집할 수 있는 것을 요약한다.\n' +
      '\n' +
      '1. **Corpus 크기**. 1.4T 토큰.\n' +
      '2. **데이터 원본**. LLaMA는 2017년부터 2020년까지 CommonCrawl의 5개 파편, C4(Raffel et al., 2020), Google BigQuery 공개 데이터셋의 GitHub 코드(Apache, BSD 및 MIT 라이선스로 제한), 2022년 6월부터 8월까지 위키피디아 덤프, 프로젝트 구텐베르크 책, The Pile의 Books3(Gao et al., 2020), arXiv의 LaTeX 파일 및 StackExchange 페이지를 포함하여 알려진 출처를 가진 데이터를 사용했다.\n' +
      '3. **PII**. N/A\n' +
      '\n' +
      '4. **독성**. N/A Reports evaluation on the RealToxicityPrompts (Gehman et al., 2020) benchmark.\n' +
      '5. **언어 ID**. CCNet 라이브러리(Wenzek 등, 2020)의 사용을 보고하며, 이는 fastText(Joulin 등, 2016) 분류기를 사용하여 비영어 텍스트(0.5 임계값 미만)를 제거한다. C4, GitHub, Books, arXiv 및 StackExchange 세트에 대해 추가 언어 ID가 보고되지 않았습니다. 위키피디아의 경우 라틴어 또는 키릴어 스크립트를 사용하는 페이지에 대한 제한을 보고했으며 bg, ca, cs, da, de, en, es, fr, hr, hu, it, nl, pl, pt, ro, ru, sl, sr, sv, uk.\n' +
      '6. **품질** 입니다. CommonCrawl에서 낮은 품질의 콘텐츠를 제거하기 위해 CCNet 라이브러리(Wenzek 등, 2020)의 사용을 보고하고; CCNet은 위키피디아 텍스트와의 유사성의 척도로서 텍스트의 복잡성을 점수화하기 위해 \\(n\\)-그램 언어 모델인 KenLM(Heafield, 2011)을 사용한다. 필터링을 위해 선택한 임계값을 보고하지 않습니다. 그들은 또한 페이지를 위키피디아 참조와 유사하거나 그렇지 않은 것으로 분류하도록 훈련된 선형 모델의 사용을 보고한다. 그들은 또한 GitHub 및 위키피디아 서브세트들에 대한 상용구 콘텐츠의 가벼운 휴리스틱 필터링을 보고한다.\n' +
      '7. **중복 제거**. CCNet 라이브러리(Wenzek 등, 2020)를 사용하여 커먼 크롤 텍스트에 대한 중복 라인 식별, GitHub 코드에 대한 파일 수준 정확한 일치 중복 제거, 구텐버그 및 북스3 하위 집합에 대해 90% 이상의 중복 도서를 확인했다.\n' +
      '8. **오염 제거**. N/A\n' +
      '9. **혼합** 원고는 67% CommonCrawl, 15% C4, 4.5% GitHub, 4.5% 위키피디아, 4.5% 북스, 2.5% arXiv 및 2.0% StackExchange의 혼합물을 보고한다. 모델 훈련은 위키피디아와 책(2 에포크)의 업샘플링을 제외하고 이 혼합물에 대한 단일 에포크였다.\n' +
      '10. **Other**.\n' +
      '\n' +
      '### OPT (Zhang, 2022)\n' +
      '\n' +
      '장(2022)의 원고 및 제공된 데이터시트(Gebru 등, 2021)로부터, 다음을 요약한다:\n' +
      '\n' +
      'OTT 모델은 알려진 **프로버넌스**: RoBERTa(Liu et al., 2019), Pile의 하위 집합(Gao et al., 2020) 및 푸시시프트 Reddit Dataset(Baumgartner et al., 2020)에 의해 처리된 데이터 원본(Roller et al., 2021)에서 **180B 토큰** 에 대해 학습되었습니다. 그들은 이러한 출처에 몇 가지 주목할 만한 변화를 취했다.\n' +
      '\n' +
      '1. _RoBERTa_. (장, 2022)은 CC-News 컬렉션을 2021년 9월까지 업데이트하였다.\n' +
      '2. _Pile_. (Zhang, 2022)는 CommonCrawl, DM Mathematics, Project Gutenberg, HackerNews, OpenSubtitle, OpenWebText2, USPTO 및 Wikipedia와 같은 컬렉션으로 제한된다. (Zhang, 2022)는 1B 모델 규모에서 구배 노멀 스파이크로 인한 다른 Pile 하위 집합의 생략을 보고한다.\n' +
      '3. _Pushshift Reddit_. (장, 2022)는 각 스레드에서 가장 긴 댓글 체인으로만 제한했으며, 데이터 세트를 66% 줄인 것으로 알려졌다.\n' +
      '\n' +
      '(Zhang, 2022) 또한 (1) 자카드 유사성 임계값이 0.95인 MinHashLSH(Rajaraman and Ullman, 2011)를 사용하여 **중복 제거** 및 (2) 사용된 방법을 설명하지는 않지만 영어 전용 텍스트에 대한 **언어 ID** 필터링을 설명합니다.\n' +
      '\n' +
      '**PII**, **독성**, **품질** 또는 **오염 제거** 에 대 한 처리를 수행 하는지 여부를 논의 하지 않습니다.\n' +
      '\n' +
      '## 부록 D 실험 설정\n' +
      '\n' +
      '### Ablation Setup\n' +
      '\n' +
      '이 섹션에 설명 된 모든 데이터 삭제에 대해 최대 150B 토큰에 대 한 1B 매개 변수 모델을 학습 합니다. 이는 선행 작업(Le Scao et al., 2022)에서 삭마에 사용된 유사한 모델 크기를 갖는 인라인이다. 각 모델은 16개의 레이어, 16개의 주의 헤드, 2048차원의 디코더 전용 변압기 모델입니다. ALiBi 위치 임베딩(Ofir Press et al., 2021), SwiGLU 활성화(Shazeer, 2020) 및 혼합 정밀도(mixed precision; model context size)를 \\(2048\\) 토큰으로 설정하였다. 우리는 EleutherAI사의 GPT NeoX tokenizer(Black et al., 2022)를 사용한다. 이 모델은 LionW 최적화기(Chen et al., 2023)를 사용하여 \\(1\\)e-\\(4\\) 피크 학습률, \\(2000\\) 단계의 웜업, 코사인 감쇠 및 \\(1\\)e-\\(2\\) 가중치 감쇠를 사용하여 학습된다. 배치 크기는 \\(1024\\)으로 설정되었습니다. 최대 단계 수를 95k(약 200B 토큰)로 설정하는 동안 150B 토큰으로 실험을 마칩니다.\n' +
      '\n' +
      '64 AMD 본능 MI250X 가속기를 사용합니다. 각 MI250X 가속기에는 두 개의 논리 노드가 포함되어 있으므로 훈련 코드의 관점에서 16개의 노드로 구성된 128개의 계산 단위에서 실험을 실행했다. 각 논리 단위마다 8의 마이크로 배치 크기를 사용한다. OLMo 코드베이스를 사용하여 실험을 구현한다.\n' +
      '\n' +
      '### Perplexity Evaluation Suite\n' +
      '\n' +
      '훈련 동안, 우리는 팔로마 벤치마크의 초기 버전을 사용하여 당혹감을 추적한다(Magnusson 등, 2023). 팔로마에 대한 다른 언급이 없는 한 이 초기 버전을 나타낸다. 이 버전의 Paloma는 다음 데이터 세트에서 파생되었습니다.\n' +
      '\n' +
      '* **C4**(Raffel et al., 2020; Dodge et al., 2021): 2019년 4월 Common Crawl 스크랩에서 자동으로 필터링된 표준 현대 LM 사전 훈련 코퍼스입니다.\n' +
      '* **mC4**(Xue 등, 2020); _영문 부분 집합_: 71개의 Common Crawl 스크래프에서 자동으로 필터링된 사전 훈련 코퍼스의 영어 부분입니다.\n' +
      '* **Pile** (Gao et al., 2020), _validation set_: 널리 사용되는 사용 언어 모델링 사전 훈련 코퍼스; 여러 비 웹 소스를 포함 하 여 여러 원본에서 큐레이션 된 문서를 포함 합니다.\n' +
      '* **WikiText 103**(Merity et al., 2016): Wikipedia에서 검증된 "Good" 및 "Featured" 문서의 표준 컬렉션입니다.\n' +
      '* **Penn Tree Bank** (Marcus et al., 1994): 월스트리트 저널 기사에서 파생된 널리 사용되는 NLP 코퍼스.\n' +
      '* **M2D2** (Reid et al., 2022), _S2ORC subset_: Semantic Scholar의 논문 (Lo et al., 2020)은 계층적 학술 필드 범주로 그룹화 됩니다.\n' +
      '* **M2D2** (Reid et al., 2022), _Wiki subset_: Wikipedia ontology에서 계층적 카테고리별로 그룹화된 Wikipedia 기사\n' +
      '* **C4 100 도메인**(Chronopoulou 등, 2022): C4에서 상위 100 도메인의 균형 잡힌 샘플입니다.\n' +
      '* **Gab**(Zannettou et al., 2018): 2016-2018년 데이터: alt-right, free-speech-oriented 소셜 미디어 플랫폼으로, 주류 플랫폼보다 더 많은 혐오 발언을 포함하는 것으로 나타났습니다.\n' +
      '* **ICE**(Greenbaum, 1991): 캐나다, 동아프리카, 홍콩, 인도, 아일랜드, 자메이카, 필리핀, 싱가포르 및 미국을 위한 하위 집합과 함께 현지 전문가가 큐레이션한 전 세계 영어.\n' +
      '* **Twitter AAE** (Blodgett et al., 2016): 아프리카계 미국인 또는 흰색 정렬 영어로 레이블이 지정된 트윗의 균형 잡힌 세트입니다.\n' +
      '* **Manosphere**(Ribeiro 등, 2021): 관련 남성주의 이데올로기 세트가 지난 10년 동안 개발된 9개 포럼의 샘플입니다.\n' +
      '* **4chan**(Papasavva 등, 2020): 2016-2019년 익명 중심 포럼의 정치 하위 섹션의 데이터는 높은 비율의 독성 콘텐츠를 포함하는 것으로 나타났습니다.\n' +
      '\n' +
      '일부 실험에서 우리는 Magnusson 등(2023)에서 공개된 Paloma의 최종 버전을 사용한다. 여기에는 다음 추가 데이터 집합에서 샘플링된 평가 데이터가 포함됩니다.\n' +
      '\n' +
      '* **Dolma** (이 작업), _uniform 샘플_: 모든 하위 집합에 걸쳐 Dolma 코퍼스의 샘플 8,358개 문서(책 13개, Common Crawl 웹 페이지 1,642개, Reddit 제출 4,545개, 과학 기사 450개, 위키피디아 및 위키북 항목 1,708개).\n' +
      '* **RedPajama v1**(Together Computer, 2023): LLaMA 1(Touvron et al., 2023) 사전 훈련 코퍼스의 1조 토큰 복제.\n' +
      '* **Falcon RefinedWeb** (Penedo et al., 2023): 모든 Common Crawl 스크래프에서 2023년 6월까지 샘플링된 영어 코퍼스로 C4 및 mC4-en보다 더 공격적으로 필터링되고 중복 제거되었습니다.\n' +
      '* **Dolma 100 하위 레딧** (이 작업): Dolma Reddit 하위 집합에서 가져온 게시물 수별로 상위 100 하위 레딧의 균형 잡힌 샘플입니다.\n' +
      '* **Dolma 100 프로그래밍 언어** (이 작업): Dolma Stack 하위 집합에서 공급 되는 토큰 수별로 상위 100 프로그래밍 언어의 균형 잡힌 샘플입니다.\n' +
      '\n' +
      '### 다운스트림 평가 스위트\n' +
      '\n' +
      '또한 Catwalk 프레임워크(Groeneveld et al., 2023)를 사용하여 다음과 같은 다운스트림 태스크 데이터 세트에 대한 모델을 평가한다:\n' +
      '\n' +
      '* **AI2 추론 챌린지**(Clark 등, 2018): _easy_ 및 _challenge_ 하위 집합으로 분할된 과학 질문 응답 데이터 세트입니다. 온라인 평가에서는 쉬운 부분 집합만 사용되었습니다. 그러나 챌린지 하위 집합은 오프라인 평가에 포함되었다.\n' +
      '* **BoolQ**(Clark 등, 2019): 자연 발생 예/아니오 부울 질문 및 배경 컨텍스트로 구성된 읽기 이해 데이터 세트입니다.\n' +
      '* **HellaSwag**(Zellers et al., 2019): 상황 이해 및 상식을 테스트하는 객관식 질문 응답 데이터 세트입니다.\n' +
      '* **OpenBookQA**(Mihaylov et al., 2018): 오픈북 과학 시험을 모델링한 객관식 질문 응답 데이터 세트입니다.\n' +
      '* **물리적 상호작용: 질문 응답 (PIQA)** (Bisk 등, 2019): 물리적 상식과 순진한 물리학에 중점을 둔 객관식 질문 응답 데이터 세트입니다.\n' +
      '* **SciQ** (Welbl et al., 2017): 과학의 다른 영역 중에서 물리, 화학 및 생물학에 대한 일상적인 질문으로 구성된 크라우드소싱된 객관식 질문 응답 데이터 세트입니다.\n' +
      '* **WinoGrande**(Sakaguchi et al., 2019): 다양한 형태의 상식을 포함하는 대명사 해결 문제의 데이터 세트입니다. Modeled after the Winograd challenge of Levesque et al.(2012).\n' +
      '\n' +
      '### Olmo-1b의 Training Setup\n' +
      '\n' +
      '올모-1b의 경우 부록 D의 데이터 세트 절제 실험에 대해 설명된 실험 설정을 따르며 다음과 같은 차이점이 있다.\n' +
      '\n' +
      '* 최대 단계 수를 739,328(대략 3.1T 토큰)로 설정합니다.\n' +
      '* 일괄 처리 크기를 \\(2048\\)으로 두 배로 늘리고 최대 256개의 계산 단위(데이터 삭제에 사용한 것을 두 배로 늘림)로 확장합니다.\n' +
      '* LionW 최적화기에서 찾은 불안정성으로 인해 AdamW를 사용하는 것으로 전환했습니다.\n' +
      '\n' +
      '## 포럼 데이터의 대화 스레드 구성 부록 E\n' +
      '\n' +
      '콘텐츠는 Reddit의 데이터 API에서 두 개의 별도의 연결된 형태로 제공됩니다. _submissions_ 및 _comments_. _ 제출_는 외부 콘텐츠(예를 들어, 뉴스 기사, 블로그, 또는 심지어 멀티미디어 콘텐츠)에 대한 "링크 게시물" 또는 "셀프 게시물"(토픽 상의 토론 스레드를 개시하기 위해 의미된 포스터에 의해 작성된 제출물) 중 하나이다. _ Comments_는 개시 포스트(상위 레벨 코멘트) 또는 다른 사용자의 코멘트에 대한 사용자 응답이다. 댓글에 대한 게시물, 최상위 댓글 및 답장은 루트 및 댓글이 여러 가능한 대화 트리로 분기되는 제출 게시물과 중첩된 대화 스레드를 형성한다.\n' +
      '\n' +
      '도 14: 1B 모델 삭제는 Reddit 처리 파이프라인에 대한 것이다. 제출 및 코멘트를 독립적인 문서로 처리(원자 콘텐츠 전략)하면 복잡성(예를 들어, 도 13(a)의 C4) 및 다운스트림 태스크(예를 들어, 도 13(b)의 HellaSwag)에 대한 더 나은 결과가 도출된다.\n' +
      '\n' +
      '레딧 스레드의 트리-유사 구조는 스레드의 다양한 컴포넌트들이 어떻게 조합되는지에 따라 다수의 가능한 데이터 포맷들을 허용한다.\n' +
      '\n' +
      '우리는 LM 사전 훈련 데이터로서의 잠재력에 대해 세 가지 형식을 조사한다.\n' +
      '\n' +
      '* **원자 콘텐츠**. 이 간단한 형식은 모든 주석과 제출을 그들이 등장하는 스레드에 대한 구조나 연결 없이 독립적인 문서로 취급한다.\n' +
      '* **부분 스레드**. 이 형식은 동일한 스레드의 코멘트를 사용자 간의 구조화된 다중 라운드 대화로 결합합니다. 제출은 별도의 문서로 남겨집니다. 어셈블링된 대화 상자는 최대 상위 깊이로 제한되며 결과 문서는 원본 스레드의 조각(여러 문서에 걸쳐 분산됨)일 뿐입니다.\n' +
      '* **전체 스레드**. 이 복잡한 형식은 주어진 제출과 모든 하위 주석을 전체 스레드를 포함하는 단일 문서로 결합합니다. 코드 유사 압흔은 스레드의 계층 구조에서 주석의 깊이를 나타내는 데 사용됩니다.\n' +
      '\n' +
      '우리는 그림 14에서 문서를 조립하기 위한 이러한 전략을 실험적으로 평가했다. 우리는 언어 모델링 목적을 위해 주석과 제출을 원자 단위로 처리하는 것이 부분 스레드 및 전체 스레드에 비해 더 나은 다운스트림 성능을 유도한다는 것을 발견했다. 대화 상자를 처리하는 데 필요한 보다 복잡한 형식이 짧고 반복되는 주석과 같은 언어 모델링에 바람직하지 않은 내용을 도입할 수 있다고 가정한다. 우리는 언어 모델링을 위한 포럼 콘텐츠에 대한 더 나은 포맷팅에 대한 연구를 향후 작업에 맡긴다.\n' +
      '\n' +
      '## 부록 F 토큰화 분석\n' +
      '\n' +
      'LM으로 텍스트를 처리하는 첫 번째 단계는 _tokenization_이며, 즉 해당 입력 임베딩을 갖는 토큰의 시퀀스에 텍스트를 매핑하는 것이다(Sennrich et al., 2016; Kudo, 2018; Kudo and Richardson, 2018). 최근, LM 토큰라이저가 상이한 데이터 소스(예를 들어, 상이한 언어의 데이터; Ahia et al., 2023; Petrov et al., 2023)에 얼마나 잘 부합되는지에 대한 관심이 증가하고 있다. 이러한 새로운 작업 라인에 의해 영감을 받아, Dolma에 적용된 GPTNeoX 토큰라이저(Black et al., 2022)의 탐색적 분석을 수행하며, 이는 Dolma에 의해 구성된 상이한 데이터 소스가 현재의 LM 토큰라이저에 대해 얼마나 도전적인지에 대한 첫 번째 그림을 제공한다.\n' +
      '\n' +
      '토나이저의 돌마에 대한 적합성을 전체적으로 살펴보는 것으로 시작합니다. 토큰라이저 어휘의 토큰 50,280개 중 돌마의 토큰화된 텍스트에는 50,057개가 존재한다. 즉, 223개의 토큰은 결코 사용되지 않으며, 토큰화기 어휘의 대략 0.4%에 달한다. 223개의 토큰은 대부분 공백 문자(예를 들어, "un", 두 개의 뉴라인 문자 다음에 두 개의 공백 문자)의 조합으로 구성된다. Dolma에서 검사 된 토큰 생성기를 사용 하 여 LM을 학습 하는 경우 이러한 토큰에 해당 하는 입력 임베딩은 업데이트 되지 않습니다. 토큰의 카운트 분포 측면에서, ID가 작은 토큰은 돌마에서 더 높은 카운트를 갖는 경향이 있음을 발견한다(그림 14(a) 참조). 이는 또한 (i) 돌마에서 카운트에 기초한 토큰의 순위 및 (ii) 토큰 ID 사이의 강한 스피어맨 상관관계에 의해 반영된다(\\(r=0.638\\), \\(p<0.001\\). 토키나이저가 어떻게 트레이닝되었는지를 고려할 때(Sennrich et al., 2016; Black et al., 2022), 더 작은 ID들은 이전에 병합된 바이트 쌍들에 대응하고 따라서 토큰나이저 트레이닝 데이터에서 더 빈번하게 발생하는 토큰들에 전반적으로, 이러한 결과들은 GPTNeoX 토큰나이저가 돌마에 잘 적합함을 시사한다.\n' +
      '\n' +
      '토나이저는 Dolma에 포함된 모든 데이터 원본에 동일하게 잘 맞습니까? 이 질문을 조사하기 위해 특정 데이터 소스에서 측정된 우리의 경우 토큰나이저(Acs, 2019; Scao 등, 2022)에 의해 생성된 단어당 평균 토큰 수로 정의되는 생식력을 분석한다. 2.45의 상당히 높은 출산율을 갖는 코드 하위 집합을 제외하고, 1.15(대화 포럼 하위 집합)에서 1.28(책 하위 집합) 사이의 대부분의 데이터 소스에서 출산율이 유사하다는 것을 발견했다(그림 14(b) 참조). 이는 코드 서브세트를 프로세싱하는 데 드는 비용, 즉 본질적으로 계산적 또는 재정적(Petrov 등, 2023)이 다른 데이터 소스에 비해 두 배 이상 높다는 것을 의미한다.\n' +
      '\n' +
      '무엇이 이 불일치를 야기하는가? 우리는 코드 서브세트(대부분 코드를 포함하는)에서, 단어들은 종종 공백 문자들 _이 아닌_ 앞에 있다는 것을 발견한다(예를 들어, 뉴라인, 탭, 리턴). 결정적으로, 단어가 해당 단어의 일부로 토큰화되는 동안(예: _I love you_ \\(\\rightarrow\\) "I", " love", " you") 다른 공백 문자는 별도의 토큰(예: _I love_ \\(\\quad\\)_you_ \\(\\rightarrow\\) "I", "lt", "lt", "you")을 생성합니다. 이는 또한 데이터 소스에 의해 공백 문자를 나타내는 토큰의 상대적 빈도를 플로팅함으로써 알 수 있는데, 이는 대부분의 다른 데이터 소스에 비해 더 스택에 대해 한 자릿수 더 높다(도 14(c) 참조). LMs on The Stack(또는 보다 일반적으로 코드)을 트레이닝할 때, 따라서 토큰나이저(예를 들어, "nif"; Hong 등, 2021)에 특별한 토큰을 추가하는 것이 바람직할 수 있다. 이러한 관찰은 "nif"와 같은 토큰이 부족한 경향이 있는 오늘날 사용 중인 대부분의 토큰화기(예를 들어, GPT-4에 의해 사용되는 토큰화기)에 적용된다는 것을 주목하는 것이 중요하다.\n' +
      '\n' +
      '## 부록 G 평가 언어 식별\n' +
      '\n' +
      'FastText 언어 식별 분류기의 영향을 분석하기 위해 세계 9개국의 구어와 문자가 포함된 데이터 세트인 국제 영어 말뭉치(ICE)(커크와 넬슨, 2018)에 대한 외부 감사를 실행했다. ICE 데이터 세트의 모든 문서에 대해 언어 ID 도구를 실행하여 각 지역에서 얼마나 많은 문서가 잘못 필터링되었는지 추정했다. 이 분석의 기본 진리는 모든 문서가 영어로 되어 있고, 그렇게 분류되어야 한다는 것이다. 흥미롭게도, 우리는 상당히 허용되는 임계값(영어에 대해 최소 0.5점 이상의 문서를 보관)에서 ICE의 모든 영어 문서를 지역 출신에 관계없이 영어로 올바르게 식별한다는 것을 발견했다.\n' +
      '\n' +
      '## 부록 H 독성 분류 평가\n' +
      '\n' +
      '직소 독성 분류기의 변증편향을 측정하기 위해 다양한 국가에서 독성으로 사용되는 영어 변이를 예측하기 위한 성향을 분석한다. 필터링되지 않은 레딧 코퍼스로 시작하여 위치 기반 하위 레딧에서 주석 데이터 세트를 생성하고 국가별 하위 레딧을 필터링한다.\n' +
      '\n' +
      '도 15: 토큰화 분석. 토나이저 학습 데이터에서 높은 카운트를 갖는 ID가 작은 토큰도 돌마(a)에서 높은 카운트를 갖는 경향이 있다. 스택은 다른 데이터 소스(b)에 비해 상당히 높은 번식력을 가지며, 이는 "n" 및 "t"와 같은 공백 문자의 더 높은 상대 빈도로 설명될 수 있다(c). 자세한 내용은 텍스트를 참조하십시오.\n' +
      '\n' +
      '댓글은 50K 이상입니다. 이 데이터 세트는 대부분의 주석자가 각 위치에 살고 변이를 말한다고 가정할 때 다른 영어 방언에 대한 조잡한 프록시 역할을 한다. 우리는 또한 이러한 하위 레딧 각각에서 실제로 독성 댓글의 비율이 거의 동일하다고 가정한다. 직소 분류기를 사용하여 이 데이터 세트의 각 댓글에 대한 독성 점수를 계산하고 그림 17에서 서로 다른 분류기 임계값에 대해 독성으로 표시된 댓글의 비율을 보고한다. 모든 임계값에서 두 위치에 대해 독성으로 표시된 댓글의 비율에서 <5% 차이를 발견하여 편향이 거의 또는 전혀 없음을 시사한다. 또한, 각 하위 레딧에서 댓글에 대한 독성 점수의 분포를 도표화하고 댓글에 할당된 점수가 종종 극단(0에 가깝거나 1에 가깝음)에서 떨어짐을 발견하여 독성을 예측하기 위한 합리적인 임계값(0.1에서 0.9 사이)이 유사한 결과로 이어질 것임을 시사한다.\n' +
      '\n' +
      '## 부록 I 코드 파이프라인에 대한 필터 분석\n' +
      '\n' +
      '표 7에서는 스택에 대한 두 필터 그룹이 플래그한 문서 수와 상관 관계를 표시한다. 우리는 RedPajama v1 필터가 대부분의 언어에 대해 StarCoder 필터보다 훨씬 더 많은 문서를 플래그한다는 것을 발견했다. 그러나 자바, 자바스크립트, 파이썬의 경우 스타코더에서 파생된 필터는 매우 많은 수의 문서를 플래그한다. 추가 코드가 포함되어 있기 때문입니다.\n' +
      '\n' +
      '그림 16: fastText 분류기의 예측 영어 점수를 임계화한 결과 비영어로 잘못 식별되는 국제 영어 말뭉치(ICE)(Kirk and Nelson, 2018)의 영어 문서 백분율. 우리는 ICE에 있는 대부분의 영어 문서들이 0.90의 임계값을 가지고도 영어로 식별된다는 것을 발견한다.\n' +
      '\n' +
      '그림 17: 영어 변이에 의해 독성으로 표시된 레딧 댓글의 분포.\n' +
      '\n' +
      '다른 언어에는 사용되지 않는 텍스트 비율 필터입니다. 두 그룹의 필터는 일반적으로 완벽하게 상관 관계가 있는 tkl과 같은 몇 가지 언어를 제외하고 상관 관계가 낮다.\n' +
      '\n' +
      '\\begin{tabular}{l c c c c c c c} \\hline \\hline Language & RPJ \\% & SC \\% & RPJ SC & Language & RPJ \\% & SC \\% & RPJ SC \\\\  & Flag & Flag & Corr. & & Flag & Flag & Corr. \\\\ \\hline abap & 1.4 & 0.0 & N/A & lookml & 0.0 & 0.0 & N/A \\\\ actionscript & 1.3 & 0.0 & N/A & lsl & 3.2 & 1.3 & 0.05 \\\\ ada & 1.5 & 2.6 & -0.02 & lua & 4.6 & 0.0 & N/A \\\\ agda & 25.4 & 0.0 & N/A & m & 35.1 & 0.0 & N/A \\\\ ags-script & 4.7 & 0.0 & N/A & m4 & 2.7 & 0.1 & 0.003 \\\\ alloy & 3.5 & 0.1 & -0.005 & makefile & 2.3 & 0.0 & N/A \\\\ ampl & 24.0 & 0.0 & N/A & mako & 2.3 & 0.7 & -0.013 \\\\ antlr & 6.0 & 0.0 & N/A & maple & 18.2 & 44.2 & -0.414 \\\\ apacheconf & 0.5 & 0.0 & N/A & markdown & 8.0 & 0.0 & N/A \\\\ api-blueprint & 3.8 & 0.0 & N/A & mask & 16.6 & 0.0 & N/A \\\\ apl & 28.2 & 0.0 & N/A & mathematica & 66.3 & 0.0 & N/A \\\\ applescript & 2.1 & 0.0 & N/A & matlab & 94.7 & 0.0 & N/A \\\\ arc & 17.7 & 8.8 & -0.144 & max & 91.2 & 0.1 & -0.033 \\\\ arduino & 2.5 & 0.0 & N/A & maxscript & 4.0 & 0.5 & -0.014 \\\\ asciidoc & 4.0 & 0.0 & N/A & mediawiki & 6.6 & 0.0 & N/A \\\\ asp & 16.4 & 0.1 & -0.01 & metal & 5.4 & 0.0 & N/A \\\\ aspectj & 0.9 & 0.0 & N/A & mirah & 25.3 & 0.0 & N/A \\\\ assembly & 50.1 & 0.0 & N/A & modelica & 10.3 & 0.0 & N/A \\\\ ats & 5.3 & 0.0 & N/A & rms & 3.2 & 0.0 & N/A \\\\ augeas & 7.2 & 4.8 & -0.063 & monkey & 6.5 & 0.0 & N/A \\\\ autohotkey & 4.9 & 0.0 & N/A & moonscript & 5.1 & 0.0 & N/A \\\\ autoit & 3.0 & 0.0 & N/A & mtml & 4.5 & 2.1 & -0.031 \\\\ awk & 36.4 & 0.1 & -0.02 & muf & 18.9 & 0.0 & N/A \\\\ batchfile & 9.8 & 0.0 & N/A & mupad & 13.8 & 1.7 & 0.006 \\\\ befunge & 100.0 & 0.0 & N/A & myghty & 27.3 & 0.0 & N/A \\\\ bison & 2.8 & 0.0 & N/A & nesc & 7.9 & 0.0 & N/A \\\\ bitbake & 0.9 & 0.0 & N/A & netlinx & 15.4 & 0.0 & N/A \\\\ blitzbasic & 56.6 & 0.0 & N/A & netlago & 12.5 & 0.0 & N/A \\\\ blitzmax & 1.2 & 0.0 & N/A & nginx & 0.0 & 0.0 & N/A \\\\ bluespec & 2.8 & 0.0 & N/A & immod & 4.5 & 0.0 & N/A \\\\ boo & 10.3 & 0.3 & 0.136 & ninja & 36.8 & 0.0 & N/A \\\\ brainfuck & 73.8 & 0.3 & -0.003 & nit & 3.4 & 0.0 & N/A \\\\ brightscript & 2.8 & 0.0 & N/A & nix & 1.6 & 0.0 & N/A \\\\ bro & 3.3 & 0.0 & N/A & nsis & 3.0 & 0.0 & N/A \\\\ c & 3.7 & 0.0 & N/A & nu & 15.1 & 0.0 & N/A \\\\ c++ & 5.6 & 0.0 & N/A & numpy & 0.0 & 0.0 & N/A \\\\ c-sharp & 0.5 & 0.0 & N/A & objdump & 77.5 & 0.0 & N/A \\\\ c2hs-haskell & 1.7 & 0.0 & N/A & objective-c++ & 5.6 & 0.1 & 0.023 \\\\ cap’n-proto & 4.7 & 0.0 & N/A & objective-j & 48.7 & 0.0 & N/A \\\\ cartocss & 15.9 & 0.2 & -0.021 & ocaml & 7.8 & 0.0 & N/A \\\\ celylon & 2.1 & 0.0 & N/A & octave & 61.2 & 3.0 & -0.22 \\\\ chapel & 20.4 & 0.0 & N/A & omgrofl & 0.0 & 0.0 & N/A \\\\ chuck & 13.0 & 0.0 & N/A & ooc & 4.3 & 0.0 & N/A \\\\ cirru & 31.0 & 0.0 & N/A & opa & 0.3 & 0.0 & N/A \\\\ clarion & 0.6 & 0.0 & N/A & opal & 11.4 & 1.9 & -0.05 \\\\ clean & 12.0 & 0.5 & -0.026 & opencl & 14.6 & 0.0 & N/A \\\\ click & 17.8 & 0.3 & -0.024 & openscad & 31.4 & 0.0 & N/A \\\\ clips & 13.9 & 0.1 & -0.01 & org & 11.1 & 0.1 & 0.002 \\\\ clojure & 4.7 & 0.0 & N/A & ox & 43.6 & 8.4 & 0.315 \\\\ cmake & 2.0 & 0.0 & N/A & oxygene & 0.0 & 94.5 & N/A \\\\ cool & 9.8 & 0.3 & -0.017 & oz & 8.4 & 0.2 & -0.012 \\\\ coffeescript & 4.0 & 0.0 & N/A & pan & 1.8 & 18.0 & 0.095 \\\\ coldfusion & 2.5 & 1.2 & -0.014 & papyrus & 10.8 & 0.1 & 0.01 \\\\ coldfusion-cfc & 1.1 & 0.0 & N/A & parrot & 20.0 & 0.0 & N/A \\\\ \\hline \\hline \\end{tabular}\n' +
      '\n' +
      'common-lisp 6.4 0.0  N/A  parrot-assembly 6.0 0.0  84.1 0.144  pir 8.4 0.0  N/A  coq 17.5 0.0  N/A  pascal 2.5 0.0  N/A  creole 41.8 0.0  N/A  pawn 13.3 0.1 -0.006  perl 7.8 0.1 0.0  cosund 6.7 3.9 -0.041  perl 6.6 0.0  N/A  piglatin 5.5 0.0  N/A  pike 11.9 0.0  N/A  pogoscript 2.6 0.0  N/A  pogoscript 2.0 0.0  N/A  pod 3.0 0.0 0.0  N/A  cycript 25.3 0.0  N/A  pogoscript 2.2 0.0  N/A  pogoscript 2.0 0.0  N/A\n' +
      '\n' +
      '## Appendix J Data Sheet\n' +
      '\n' +
      '### 데이터 세트 만들기 동기\n' +
      '\n' +
      '**데이터 세트는 왜 만들어졌습니까?**\n' +
      '\n' +
      '돌마는 AI2의 자기 회귀 언어 모델 OLMo를 훈련시키는 것을 주요 목적으로 만들어졌다. 여러 데이터 소스의 문서가 혼합되어 있습니다. 문서는 규칙 기반 및 통계 도구의 조합을 사용하여 텍스트 콘텐츠를 추출하고 레이아웃 정보를 제거하고 영어 콘텐츠에 대한 필터를 사용하여 변환되었다.\n' +
      '\n' +
      '돌마에 다른 도메인에서 가져온 데이터가 포함되어 있습니다. 특히 웹 스크래프에서 얻은 텍스트, 학술 PDF에서 추출한 과학 콘텐츠 및 관련 메타데이터, 다양한 프로그래밍 언어에 대한 코드, 위키피디아와 위키북의 참조 자료, 프로젝트 구텐베르크의 공용 도메인 북이 혼합되어 있다.\n' +
      '\n' +
      '**데이터 세트를 사용할 수 있는 다른 작업은 무엇입니까?**\n' +
      '\n' +
      '이 데이터 세트는 현재 형태 또는 추가 필터링 및 다른 데이터 세트와 결합하여 다른 언어 모델을 훈련하는 데 유용할 것으로 기대한다.\n' +
      '\n' +
      '언어 모델 훈련 외에도 이 데이터 세트는 사전 훈련 말뭉치와 이에 대해 훈련된 모델 간의 상호 작용을 연구하는 데 사용할 수 있다. 예를 들어, 모델에서 세대의 출처를 연구하거나 추가 코퍼스 분석을 수행할 수 있다.\n' +
      '\n' +
      '돌마의 특정 하위 집합은 도메인 특정 모델을 훈련하는 데 사용할 수 있다. 예를 들어, 코드 서브세트는 AI 프로그래밍 어시스턴트를 트레이닝하는 데 사용될 수 있다.\n' +
      '\n' +
      '**사용 하지 않아야 하는 명백한 작업이 있습니까?* *\n' +
      '\n' +
      '데이터 세트를 도출하기 위해 원본 원본 자료에 적용된 무수히 많은 변환으로 인해 원본 콘텐츠를 직접 소비하려는 사용자를 대체하는 데 적합하지 않다고 생각한다. 사용 제한 사항을 자세히 설명하는 HuggingFace Hub huggingface.co/datasets/allenai/dolma의 라이선스 및 용어를 데이터 세트의 사용자에게 참조합니다.\n' +
      '\n' +
      '**데이터 세트가 이미 작업에 사용되었습니까?* *\n' +
      '\n' +
      '이 데이터 세트에 대해 훈련된 모델은 아직 공개적으로 공개되지 않았다.\n' +
      '\n' +
      '**그렇다면 다른 사용자가 비교할 수 있는 결과는 어디에 있습니까?* *\n' +
      '\n' +
      '원고가 곧 나올 것이다.\n' +
      '\n' +
      '**데이터 세트 만들기에 자금을 지원한 사람은 누구입니까?* *\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c c c} lcs & 1.3 & 0.0 & N/A & xtend & 0.3 & 0.0 & N/A \\\\ literate-haskell & 3.8 & 0.0 & N/A & yacc & 17.5 & 0.0 & N/A \\\\ livescript & 12.8 & 0.0 & N/A & yaml & 5.1 & 0.0 & N/A \\\\ llvm & 29.9 & 0.0 & N/A & yang & 0.7 & 0.0 & N/A \\\\ logos & 24.2 & 0.2 & -0.023 & zephir & 0.4 & 0.0 & N/A \\\\ logtalk & 4.3 & 0.0 & N/A & zig & 4.8 & 0.0 & N/A \\\\ lolcode & 14.4 & 4.8 & -0.092 & zimpl & 75.5 & 0.0 & N/A \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 7: **The Stack으로부터의 Dolma의 서브세트에 대한 필터의 상관관계.** RPJ는 RedPajama(Together Computer, 2023c)로부터의 필터이고 SC 필터는 StarCoder(Li et al., 2023; Muennighoff et al., 2023a)로부터의 필터이다. 각 필터 집합(Corr.)에 의해 플래깅된 문서 간의 피어슨 상관 관계를 계산한다. 언어 바로 가기: dcl=digital-command-language, gf=grammatical-framework, gsp=groovy-server-pages, jsp=java-server-pages, lcs=literate-coffescript, owl=web-ontology-language, mms=module-management-system, pir=parrot-internal-representation, pt=python-traceback, rf=robotframework, rrh=ragel-in-ruby-host, rt=restructuredtext, upc=unified-parallel-c 모든 개인은 이 데이터 세트를 담당하는 알렌 인공지능 연구소에서 사용한다. 유사하게, 컴퓨팅 리소스는 AI2에 의해 제공된다.\n' +
      '\n' +
      '**연결 된 부여가 있는 경우 부여 번호를 제공 합니다.* *\n' +
      '\n' +
      'OLMo 프로젝트를 위한 계산은 LUMI 슈퍼컴퓨터의 GPU를 사용하여 AMD와 CSC에 의해 제공된다.\n' +
      '\n' +
      '### Dataset Composition\n' +
      '\n' +
      '**인스턴스는 무엇인가요? 여러 유형의 인스턴스가 있습니까? **\n' +
      '\n' +
      '인스턴스는 영문 텍스트 또는 컴퓨터 코드의 일반 텍스트 스팬입니다. 각 인스턴스는 웹 페이지(뉴스, 문서, 포럼 등을 포함할 수 있음), 학술 기사, GitHub의 컴퓨터 코드, 위키피디아의 백과사전 콘텐츠 또는 프로젝트 구텐베르크 책을 처리하여 얻었다.\n' +
      '\n' +
      '**데이터에서 인스턴스 간의 관계가 명시적으로 만들어졌습니까?* *\n' +
      '\n' +
      '돌마의 서브세트들에 대한 메타데이터는 항목들 간의 관계를 재구성하는데 사용될 수 있다:\n' +
      '\n' +
      '* **일반 크롤** 입니다. 각 문서는 추출된 웹 페이지의 URL을 식별자로 사용하기 때문에 문서 간의 관계를 식별하는 데 사용할 수 있다.\n' +
      '* **C4**. 문서가 추출된 각 웹 페이지의 URL은 메타데이터로 포함되므로 문서 간의 관계를 식별하는 데 사용할 수 있다.\n' +
      '* **Reddit**. 문서의 발신 서브레딧 및 스레드 id는 메타데이터에 포함된다.\n' +
      '* **peS2o**. 각 문서의 id는 해당 원고의 시맨틱 스콜라 코퍼스 ID이다. 각 원고에 대한 메타데이터는 Semantic Scholar API(Kinney et al., 2023)를 이용하여 획득될 수 있다.\n' +
      '* **스택**. 각 문서가 속한 GitHub 리포지토리의 이름은 메타데이터로 포함됩니다.\n' +
      '* **프로젝트 Gutenberg**. 각 책의 제목은 각 문서의 첫 번째 줄로 포함됩니다.\n' +
      '* **위키피디아**, **위키북** 입니다. 양자에 대해, 메타데이터는 페이지 콘텐츠에 대응하는 URL을 포함하는 것으로부터 추출되었다. URL을 통해 문서 간 구조 및 연결을 복구할 수 있습니다.\n' +
      '\n' +
      '**각 유형의 인스턴스는 몇 개입니까?* *\n' +
      '\n' +
      '요약 통계는 표 1에 보고되어 있다.\n' +
      '\n' +
      '**각 인스턴스는 어떤 데이터로 구성되나요? "원시" 데이터(예를 들어, 처리되지 않은 텍스트 또는 이미지)는? Features/attributes.**\n' +
      '\n' +
      '각 원본에 대해 원시 데이터를 직접 사용할 수 없지만 원본별 방법을 사용하여 복구할 수 있습니다.\n' +
      '\n' +
      '* **일반 크롤** 입니다. 2020-05년부터 2023-06년까지 공통 크롤 스냅샷으로부터 데이터를 획득한다. 공통 크롤의 WARC 파일은 Dolma ids와 교차하여 원본 HTML 파일을 복구할 수 있다.\n' +
      '* **C4**. HuggingFace Hub 33에서 이 코퍼스를 얻었다. 그 결과 C4의 문서는 04/2019 공통 크롤 스냅샷에서 파생되었다. C4의 URL은 HTML 파일을 복구하는 데 사용될 수 있다. 각주 33: [https://huggingface.co/datasets/allenai/c4](https://huggingface.co/datasets/allenai/c4)\n' +
      '* **Reddit**. 이 작업에 사용된 전체 월간 데이터 덤프는 푸시시프트에 의해 더 이상 배포되지 않지만, 여전히 급류 및 일부 공개 웹 아카이브를 통해 얻을 수 있다.\n' +
      '* **peS2o**. peS2o는 S2ORC Lo 등(2020)으로부터 유도된다. 원본 파싱된 문서들은 peS2o와 동일한 ID를 공유하는 S2ORC 내의 문서들을 추출함으로써 획득될 수 있다. 또한, S2ORC 내의 메타데이터는 원본 PDF를 획득하는데 사용될 수 있다.\n' +
      '* **스택(중복)**. 메타데이터에서 사용할 수 있는 파일 이름과 리포지토리 이름을 사용하여 원본 파일 내용을 복구할 수 있습니다.\n' +
      '\n' +
      '* **프로젝트 구텐버그.** 각 책의 제목은 각 문서의 첫 번째 줄입니다.\n' +
      '* **위키피디아, 위키북** 입니다. 양자에 대해, 메타데이터는 페이지 콘텐츠에 대응하는 URL을 포함하는 것으로부터 추출되었다. URL을 통해 문서 간 구조 및 연결을 복구할 수 있습니다.\n' +
      '\n' +
      '**인스턴스와 연결된 레이블/대상이 있습니까? 인스턴스가 사람과 관련이 있는 경우 하위 모집단을 식별(예: 연령, 성별 등)하고 분포가 어떻게 되나요?**\n' +
      '\n' +
      '인스턴스와 연관된 레이블이 없습니다. 많은 텍스트 인스턴스가 사람 또는 사람들 그룹에 의해 만들어졌을 가능성이 있지만 대부분의 경우 저자 정보는 하위 모집단 메타데이터는 고사하고 사용할 수 없다. 우리는 이러한 통계의 집계 및 보고를 향후 작업에 맡긴다.\n' +
      '\n' +
      '**모든 항목이 포함 되거나 데이터가 외부 리소스에 의존 하나요? (예: 웹 사이트, 트윗, 데이터 세트) 외부 리소스가 있는 경우 a) 해당 리소스가 존재 하 고 시간이 지남에 따라 일정하게 유지 됩니다. b) 공식 기록 버전이 있습니다. 데이터와 연결된 라이선스, 수수료 또는 권한이 있습니까?**\n' +
      '\n' +
      '데이터는 웹에서 파생되며 원본 리소스는 시간이 지남에 따라 지속되지 않을 수 있다. 그러나 각 원본은 고정되고 사용 가능한 상태로 유지되어야 하는 해당 데이터의 보관 스냅샷을 나타냅니다.\n' +
      '\n' +
      '* **일반 크롤** 입니다. 일반 Crawl 데이터는 Amazon Web Services의 오픈 데이터 스폰서십 프로그램의 일부로 Amazon S3에서 사용할 수 있으며 34를 자유롭게 다운로드할 수 있습니다. 일반 Crawl 사용 약관 35를 따랐습니다. 각주 34: [https://commoncrawl.org/terms-of-use/](https://commoncrawl.org/terms-of-use/) 35. 각주 35: [https://www.reddit.com/r/pushshift/comments/d6luj5/comments/f@ugpqp](https://www.reddit.com/r/pushshift/comments/d6luj5/comment/f@ugpqp) 36. 각주 37: [https://www.semanticscholar.org/product/api](https://www.semanticscholar.org/product/api) 38. 각주 38: [https://huggingface.co/datasets/bigcode/the-stack-dedup](https://huggingface.co/datasets/bigcode/the-stack-dedup)\n' +
      '* **C4**. 이 코퍼스는 HuggingFace Hub 33에서 얻을 수 있으며 ODC-By 1.0(Open Data Commons, 2010)에서 릴리스됩니다. 각주 33: [https://commoncrawl.org/terms-of-use/](https://commoncrawl.org/terms-of-use/) 36. 각주 37: [https://www.reddit.com/r/pushshift/comments/d6luj5/comment/f@ugpqp](https://www.reddit.com/r/pushshift/comments/d6luj5/comment/f@ugpqp) 38. 각주 39: [https://www.semanticscholar.org/product/api](https://www.semanticscholar.org/product/api) 3. 각주 38: [https://huggingface.co/datasets/bigcode/the-stack-dedup](https://huggingface.co/datasets/bigcode/the-stack-dedup) 3. 각주 39: [https://dumps.wikimedia.org](https://dumps.wikimedia.org)\n' +
      '* **Reddit**. Pushshift는 Reddit API 용어의 변경으로 인해 이 데이터 세트를 더 이상 배포하지 않습니다. 비공식 데이터 복사본은 급류 및 일부 공개 웹 아카이브를 통해 사용할 수 있다. Pushshift 데이터 덤프는 컬렉션(2023년 3월) 당시 Reddit API의 사용 약관 36개를 상속합니다. 각주 36: [https://commoncrawl.org/terms-of-use/](https://commoncrawl.org/terms-of-use/) 37. 각주 38: [https://www.reddit.com/r/pushshift/comments/d6luj5/comment/f@ugpqp](https://www.reddit.com/r/pushshift/comments/d6luj5/comment/f@ugpqp) 39. 각주 39: [https://www.semanticscholar.org/product/api](https://www.semanticscholar.org/product/api) 3. 각주 38: [https://huggingface.co/datasets/bigcode/the-stack-dedup](https://huggingface.co/datasets/bigcode/the-stack-dedup) 3. 각주 39: [https://dumps.wikimedia.org](https://dumps.wikimedia.org)\n' +
      '* **peS2o**. peS2o는 S2ORC Lo 등(2020)으로부터 유도된다. S2ORC는 ODC-By 1.0(Open Data Commons, 2010) 하에서 Semantic Scholar Public API 37을 통해 공개된다. 각주 37: [https://www.semanticscholar.org/product/api](https://www.semanticscholar.org/product/api) 3. 각주 38: [https://huggingface.co/datasets/bigcode/the-stack-dedup](https://huggingface.co/datasets/bigcode/the-stack-dedup) 3. 각주 39: [https://dumps.wikimedia.org](https://dumps.wikimedia.org)\n' +
      '* **스택(중복)**. 코퍼스는 포옹페이스 허브 38에서 사용할 수 있으며 다양한 허용 라이센스로 출시된 코드로 구성된다. 코퍼스를 호스팅하거나 공유하기 위한 사용 조건을 포함하는 더 자세한 내용은 위의 링크에서 데이터카드에 제공된다. 각주 38: [https://commoncrawl.org/terms-of-use/](https://commoncrawl.org/terms-of-use/) 39. 각주 39: [https://www.reddit.com/r/pushshift/comments/d6luj5/comment/f@ugpqp](https://www.reddit.com/r/pushshift/comments/d6luj5/comment/f@ugpqp) 3. 각주 39: [https://www.semanticscholar.org/product/api](https://www.semanticscholar.org/product/api) 3. 각주 38: [https://huggingface.co/datasets/bigcode/the-stack-dedup](https://huggingface.co/datasets/bigcode/the-stack-dedup) 3. 각주 39: [https://dumps.wikimedia.org](https://dumps.wikimedia.org)\n' +
      '* **프로젝트 Gutenberg**. 프로젝트 구텐베르크는 미국 저작권법상 보호받지 못하는 책으로 구성되어 있다. 말뭉치는 gutenberg.org에서 구할 수 있다.\n' +
      '* **위키피디아, 위키북** 입니다. 위키미디어 데이터 덤프는 39개를 자유롭게 이용할 수 있으며 CC BY-SA 4.0 라이선스(Creative Commons, 2013)로 출시된다. 각주 39: [https://dumps.wikimedia.org](https://dumps.wikimedia.org)\n' +
      '\n' +
      '**권장 데이터 분할 또는 평가 조치가 있습니까? (예를 들어, 훈련, 개발, 테스트; 정확도/AUC)**\n' +
      '\n' +
      '아니요, 돌마가 오염되지 않은 별도의 평가 스위트룸은 나중에 출시될 예정입니다. 이 데이터 세트의 다운스트림 사용자는 대체 평가 제품군을 사용할 수 있습니다.\n' +
      '\n' +
      '**이 데이터 집합에서 처음 실행 된 실험은 무엇인가요? 이러한 결과를 요약하고 사용 가능한 경우 여기에 더 많은 정보가 포함된 종이에 대한 링크를 제공합니다. **\n' +
      '\n' +
      '다가오는 원고는 이 데이터 세트의 생성을 안내하기 위해 수행된 절제 및 기타 실험에 대해 자세히 설명한다.\n' +
      '\n' +
      '### 데이터 수집 프로세스\n' +
      '\n' +
      '**데이터는 어떻게 수집 되었습니까? (예: 하드웨어 장치/센서, 수동 인간 큐레이션, 소프트웨어 프로그램, 소프트웨어 인터페이스/API; 이러한 구성/측정/방법이 어떻게 검증되었습니까?)**\n' +
      '\n' +
      '각 서브세트에 대한 데이터 획득은 다음과 같이 수행되었다:\n' +
      '\n' +
      '* **일반 크롤** 입니다. snapshots는 cc_net 파이프라인을 사용하여 Common Crawl의 공식 S3 bucket40으로부터 다운로드되었다(Wenzek 등, 2020b). 데이터는 2023년 3월 17일에서 3월 27일 사이에 획득되었다. 각주 40: s3://commoncrawl/\n' +
      '* **C4**. Git-LFS 확장과 함께 Git를 사용하여 HuggingFace Hub33에서 C4를 복제합니다. 리포지토리 복제 2023년 5월 24일. 각주 41: [https://files.pushshift.io/reddit/submissions/](https://files.pushshift.io/reddit/submissions/)\n' +
      '* **Reddit**. Reddit은 Pushshift project4142에 의해 수집 및 배포된 댓글과 제출물의 월별 데이터 덤프 형태로 획득되었다. 우리는 06/2005-03/2023년에 걸쳐 422개의 공개 이용 덤프(208개의 댓글, 214개의 제출물)의 전체 세트를 사용했다. 대부분의 덤프는 2023년 3월에 획득되었고 마지막 덤프는 2023년 5월에 다운로드되었다.\n' +
      '* **peS2o**. Git-LFS 확장과 함께 Git를 사용하여 HuggingFace Hub43에서 peS2o를 복제합니다. 우리는 pes2o V2를 사용합니다. 리포지토리는 2023년 6월 30일에 복제됩니다. 각주 42: [https://files.pushshift.io/reddit/comments/](https://files.pushshift.io/reddit/comments/)\n' +
      '* **스택(중복)**. Git-LFS 확장과 함께 Git를 사용 하 여 HuggingFace Hub38에서 Stack (중복)을 복제 합니다. 리포지토리 복제 2023년 5월 28일. 각주 43: [https://huggingface.co/datasets/allenai/peS2o](https://huggingface.co/datasets/allenai/peS2o)\n' +
      '* **프로젝트 Gutenberg**. 데이터는 gutenberg.org에서 직접 다운로드되었으며, 우리는 책을 추출하기 위해 GutenbergPy(Angelescu, Radu, 2013)를 사용했다. 웹사이트는 2023년 4월 3일에 접속했습니다.\n' +
      '* **위키피디아, 위키북** 입니다. Dumps downloaded from Wikimedia\'s website39. We use the dump from March 20th, 2023. 각주 40: s3://commoncrawl/\n' +
      '\n' +
      '**데이터 수집 프로세스에 누가 참여 했습니까? (예를 들어, 학생, 군중 노동자) 그들은 어떻게 보상을 받았나요? (예를 들어, 군중 노동자들은 얼마를 지불했습니까?)**\n' +
      '\n' +
      '알렌 AI 연구소의 정규직 직원이 데이터를 수집하고 후처리했다. 이 데이터 세트의 인스턴스에 수동으로 주석이 달리지 않았습니다.\n' +
      '\n' +
      '**데이터는 몇 시간 동안 수집되었습니까? 수집 시간 프레임이 생성 시간 프레임과 일치 하나요? **\n' +
      '\n' +
      '위의 목록을 참조하십시오.\n' +
      '\n' +
      '**각 인스턴스와 연결된 데이터는 어떻게 획득되었습니까? 데이터는 피험자(예: 설문 응답)에 의해 보고되거나 다른 데이터(예: 음성 태그의 일부, 연령 또는 언어에 대한 모델 기반 추측)에서 간접적으로 추론/파생될 수 있었는가? 후자의 두 개는 유효성 검사/검증되었으며, 그렇다면 어떻게 되나요?**\n' +
      '\n' +
      '각각의 인스턴스와 연관된 임의의 메타데이터는 각각의 소스로부터 직접 획득되었다.\n' +
      '\n' +
      '**데이터 집합에 가능한 모든 인스턴스가 포함되나요? 또는 예를 들어 더 큰 인스턴스 집합의 샘플 (반드시 무작위는 아님) 인가요? 데이터 집합이 샘플인 경우 모집단은 무엇인가요? 샘플링 전략(예를 들어, 특정 샘플링 확률을 갖는 결정론적, 확률론적)은 무엇이었는가? 표본이 더 큰 집합(예: 지리적 범위)을 나타내나요? 그렇지 않다면, (예를 들어, 보다 다양한 범위의 인스턴스를 커버하기 위해) 왜? 이것이 사용 가능성에 어떻게 영향을 미칩니까?**\n' +
      '\n' +
      '각 하위 집합에 대 한 샘플링은 다음과 같이 수행 되었습니다. * **일반 크롤**. 일반 크롤은 웹의 대표적인 표본이 아닙니다. Common Crawl에 대한 요약 통계는 commoncrawl.github.io/cc-crawl-statistics에서 이용 가능한 cc-crawl-statistics(Common Crawl, 2016) 프로젝트를 통해 보고된다. Dolma는 2020-05년부터 2023-064년까지 Common Crawl 스냅샷을 사용한다. 각주 44: Common Crawl 스냅샷은 명명 규칙을 따르는 xxxx-yy, 여기서 xxxx는 스냅샷이 확정된 연도이고 yy는 01부터 52까지의 주이다.\n' +
      '* **C4**. 우리는 C4 전체를 사용합니다.\n' +
      '* **Reddit**. 우리는 2005년 06/03/2023년부터 사용 가능한 모든 레딧 콘텐츠를 사용합니다.\n' +
      '* **스택(중복)**. 우리는 스택(중복) 전체를 사용합니다.\n' +
      '* **peS2o**. 우리는 전체적으로 pes2o V2를 사용합니다.\n' +
      '* **프로젝트 Gutenberg**. 우리는 모든 구텐베르크 책을 처리합니다.\n' +
      '* **위키피디아**, **위키북** 입니다. 위키피디아와 위키북의 _영어_ 및 _단순_ 하위 집합을 전체로 사용합니다.\n' +
      '\n' +
      '**데이터 집합에서 누락된 정보와 이유가 있습니까? (이는 의도적으로 삭제 된 인스턴스를 포함 하지 않습니다. 예를 들어 수정 된 텍스트, 보류 된 문서를 포함할 수 있습니다.) 사용할 수 없었기 때문에이 데이터가 누락 되었습니까?* *\n' +
      '\n' +
      '커먼 크롤은 우리가 전체적으로 사용하지 않은 유일한 원천이다. 사용 가능한 모든 스냅샷의 약 4분의 1만 사용합니다. 이 양은 우리가 사용할 수 있는 계산량을 감안할 때 OLMo 프로젝트의 목표(최대 700억 매개변수의 자기 회귀 언어 모델 훈련)에 충분한 것으로 간주되었다. 가장 최근의 24개의 커먼 크롤 스냅샷을 사용하기로 결정했습니다.\n' +
      '\n' +
      '**알려진 오류, 노이즈 원본 또는 데이터에 중복이 있습니까?* *\n' +
      '\n' +
      '우리가 알고 있는 것은 아니지만, S3 저장소의 네트워크 문제로 인해 커먼 크롤 데이터의 무시할 수 있는 부분이 손실되었을 수 있다. 공통 크롤에 액세스할 때 재시도 메커니즘을 구현했지만 재시도 한계를 초과하여 복사가 실패할 수 있다.\n' +
      '\n' +
      '### Data Preprocessing\n' +
      '\n' +
      '**어떤 전처리/세척이 수행 되었습니까? (예: 이산화 또는 버킷화, 토큰화, 품사 태깅, SIFT 기능 추출, 인스턴스 제거, 결측값 처리 등)**\n' +
      '\n' +
      '모든 데이터 소스는 영어 임계값이 0.5인 FastText 언어 식별 모델(Joulin et al., 2016, 2016)을 사용하여 필터링된다.\n' +
      '\n' +
      '**일반 크롤** 및 **C4** 하위 집합의 경우 원본 데이터를 실질적으로 수정 하는 다음 필터 (그림 1)를 사용 합니다. 하나 이상의 필터에 의한 제거를 위해 데이터에 태그가 지정될 수 있습니다.\n' +
      '\n' +
      '* _유일한 Common Crawl, 그 배포 파이프라인의 일부로_: 모든 HTML을 일반 텍스트 파일(WET 파일 생성 45)로 선형화합니다. 각주 45: [https://commoncrawl.org/get-started](https://commoncrawl.org/get-started)\n' +
      '* _CCNet 파이프라인의 일부로 Common Crawl만_: 각 스냅샷의 작은 하위 집합에서 반복되는 문단을 식별하여 Common Crawl에서 자주 발생하는 문단을 제거합니다. 이 단계에서는 탐색 헤더와 같은 여러 페이지에 공유되는 헤더를 제거합니다. 제거는 \\(1\\ldots,n,\\ldots,N\\)개의 스냅샷이 주어졌을 때 \\(S=\\{n-k,n\\}\\), \\(S\\)에 있는 단락들의 정확한 중복을 제거한다. 단락은 새 줄로 구분 된 문서 조각으로 정의 되 고 SHA1을 사용 하 여 비교 합니다. 각 집합이 최대 20GB46이 되도록 \\(k\\)을 선택 합니다. (문단 제거_의 약 70%); 각주 46: 원본 CCNet 파이프라인을 약간 수정 했습니다. 여기서 \\(k\\)는 각 집합이 스냅숏의 2%가 되도록 선택 됩니다. 고정 크기는 자원 사용 측면에서 더 예측 가능하기 때문에 오류가 발생하기 쉬운 코드를 생성하기 때문에 코퍼스의 백분율보다는 고정 샤드 크기를 사용하기로 결정했다. 개념적으로 그것은 문단이 발생할 절대 확률에 임계값을 두는 것과 같다.\n' +
      '* _Only Common Crawl, deduplication by URL_: We deduplicate pages by URL(_53% of duplicates removed_); 각주 47: 원본 CCNet 파이프라인의 약간의 수정입니다. 여기서 \\(k\\)는 각 세트가 스냅샷의 2%가 되도록 선택됩니다. 고정 크기는 자원 사용 측면에서 더 예측 가능하기 때문에 오류가 발생하기 쉬운 코드를 생성하기 때문에 코퍼스의 백분율보다는 고정 샤드 크기를 사용하기로 결정했다. 개념적으로 문단이 발생하는 절대 확률에 임계값을 두는 것과 같습니다.* **언어 식별**: FastText 언어 식별 모델(Joulin et al., 2016, 2016)에 의해 결정된 대로 0.5 미만의 영어 점수를 가진 모든 문서를 제거합니다(_removed 61.69% of web pages by size_);\n' +
      '* **품질 필터 47**: 줄의 절반 이상이 ""로 끝나지 않은 문서를 제거합니다. "?", "!", "\'\'. (제거에 태깅된 문자의_22.73%); 각주 47: 문헌에서 널리 사용되는 용어 "품질 필터"는 데이터세트를 필터링한 결과를 적절하게 설명하지 않는다. 품질은 인간이 평가하는 정보성, 포괄성 또는 기타 특성에 대한 논평으로 인식될 수 있다. 그러나, 돌마 및 다른 언어 모델들에서 사용되는 필터들은 본질적으로 이념적인 기준에 따라 텍스트를 선택한다(구루랑간 등, 2022). 각주 48: 바이그램의 경우 임계값 0.20. 트리그램의 경우 0.18. 4그램의 경우 0.16.\n' +
      '* **품질 필터**47: Gopher 규칙을 통과 하지 않는 모든 문서 제거 (Rae 등, 2021) (제거에 태깅 된 문자의 _15.23%_); 각주 48: 5-grams, 0.15. 6-grams, 0.14. 7-grams, 0.13. 8-grams, 0.12. 9-grams, 0.11. 10-grams, 0.10.\n' +
      '\n' +
      '* **품질 필터**47: Gopher 규칙 중 하나를 통과 하지 않는 문서 제거 (Rae 등, 2021) (제거에 태깅 된 문자의 _15.23%_); 각주 47: "품질 필터"라는 용어는 문헌에서 널리 사용 되지만 데이터 세트를 필터링 하는 결과를 적절 하 게 설명 하지 않습니다. 품질은 인간이 평가하는 정보성, 포괄성 또는 기타 특성에 대한 논평으로 인식될 수 있다. 그러나, 돌마 및 다른 언어 모델들에서 사용되는 필터들은 본질적으로 이념적인 기준에 따라 텍스트를 선택한다(구루랑간 등, 2022). 각주 48: 바이그램의 경우 임계값 0.20. 트리그램의 경우 0.18. 4그램의 경우 0.16.\n' +
      '\n' +
      '* 임계값 49 각주 49보다 큰 대부분의 일반 ngram의 문자 비율: 5-gram의 경우 0.15. 6-gram의 경우 0.14. 7-gram의 경우 0.13. 8-gram의 경우 0.12. 9-gram의 경우 0.11. 10-gram의 경우 0.10.\n' +
      '* 임계값 49 각주 49보다 큰 중복 ngram의 문자 비율: 5gram의 경우 0.15. 6gram의 경우 0.14. 7gram의 경우 0.13. 8gram의 경우 0.12. 9gram의 경우 0.11. 10gram의 경우 0.10.\n' +
      '* 50개 미만 또는 100K개 이상의 단어를 포함함\n' +
      '* 중간 단어 길이가 3보다 작거나 10보다 큰\n' +
      '* 기호 대 단어 비율이 0.10보다 큰 경우\n' +
      '* 알파성분이 0.80 미만인 단어의 비율\n' +
      '* 필요한 단어 50 각주 집합의 2개 미만 포함 50: "the", "be", "to", "of", "and", "that", "have", "with" 각주 51: Allenai/gpt-neox-olmo-dolma-v1_5를 사용하여 토큰을 가져옵니다.\n' +
      '* **글렛 포인트가 0.90보다 큰 문서에서 선의 비율**.\n' +
      '* 0.30보다 큰 줄임말로 끝나는 문서에서 행의 분수\n' +
      '* 0.30보다 크게 중복되는 문서 내 선의 비율\n' +
      '* 0.30보다 큰 중복 라인에서 문자의 비율\n' +
      '* **품질 필터**47: 토큰 또는 토큰 시퀀스가 100회 이상 반복되는 문서를 제거합니다(제거에 태깅된 문자의 _0.003%_). 각주 48: 5-gram의 경우 0.15. 6-gram의 경우 0.14. 7-gram의 경우 0.13. 8-gram의 경우 0.12. 9-gram의 경우 0.11. 10-gram의 경우 0.10.\n' +
      '* **콘텐츠 필터**: FastText 분류기에 의해 독성으로 순위가 매겨지는 문장(\\(0.4\\) 이상의 점수)을 제거합니다. 우리는 Jigsaw 데이터세트(cjadams et al., 2017)에서 빅그램 분류기를 트레이닝한다(제거_를 위해 태깅된 데이터의_1.01%); 각주 51: Allenai/gpt-neox-olmo-dolma-v1_5를 사용하여 토큰을 획득한다.\n' +
      '* **콘텐츠 필터**: 이메일, 전화 번호 및 IP 주소를 식별하는 정규식을 사용하는 PII(개인 식별 정보) 마스크; 6개 이상의 PII를 포함하는 페이지는 코퍼스에서 완전히 제거됩니다(마스킹에 대해_0.05% 태깅, 제거에 대해 0.11% 태깅_); 각주 52: 5-gram의 경우 0.15. 6-gram의 경우 0.14. 7-gram의 경우 0.13. 8-gram의 경우 0.12. 9-gram의 경우 0.11. 10-gram의 경우 0.10.\n' +
      '* **정확한 문서 중복 제거**: 동일한 텍스트를 문서를 중복합니다. 구두 부호나 공백이 제거되지 않습니다. 빈 문서는 중복으로 계산됩니다. 제거 태그가 지정된 문서의 _14.9%_.\n' +
      '* _Only Common Crawl, deduplication by paragraph_: Bloom 필터 (제거에 태깅 된 UTF-8 문자의 _19.1%)를 사용 하 여 단락 수준에서 웹 하위 집합을 중복 복제 합니다.\n' +
      '\n' +
      '**Reddit** 하위 집합의 경우 원본 데이터를 실질적으로 줄이는 다음 필터를 사용합니다.\n' +
      '\n' +
      '* **언어 식별**: FastText 언어 식별 모델에 의해 결정된 대로 영어 점수가 0.5 미만인 모든 문서를 제거합니다.\n' +
      '* **품질 필터** 47: 500자 미만의 주석 및 제출을 제거합니다. 각주 47: 세 개 미만의 상향 투표로 사용자 코멘트를 제거한다(Reddit 사용자는 제출 및 코멘트의 품질에 대해 투표한다). 각주 48: 5-그램의 경우 0.15. 6-그램의 경우 0.14. 7-그램의 경우 0.13. 8-그램의 경우 0.12. 9-그램의 경우 0.11. 10-그램의 경우 0.10.\n' +
      '* **품질 필터** 47: 3개 미만의 상향 투표로 사용자 주석을 제거합니다(Reddit 사용자는 제출 및 주석의 품질에 대해 투표합니다). 각주 48: 문헌에서 널리 사용되는 용어 "품질 필터"는 데이터세트를 필터링한 결과를 적절하게 설명하지 않는다. 품질은 인간이 평가하는 정보성, 포괄성 또는 기타 특성에 대한 논평으로 인식될 수 있다. 그러나, 돌마 및 다른 언어 모델들에서 사용되는 필터들은 본질적으로 이념적인 기준에 따라 텍스트를 선택한다(구루랑간 등, 2022). 각주 48: 바이그램의 경우 임계값 0.20. 트리그램의 경우 0.18. 4-그램의 경우 0.16. 4-그램의 경우 0.16. 5-그램의 경우 0.15. 5-그램의 경우 0.15. 6-그램의 경우 0.14. 7-그램의 경우 0.13. 8-그램의 경우 0.12. 9-그램의 경우 0.11. 10-그램의 경우 0.10.\n' +
      '* **콘텐츠 필터**47: FastText 분류기에 의해 독성 또는 hatespeech으로 순위가 매겨지는 문장을 제거합니다 ( \\(0.4\\) 이상의 점수). 각주 48: 5-그램의 경우 0.15. 6-그램의 경우 0.14. 7-그램의 경우 0.13. 8-그램의 경우 0.12. 9-그램의 경우 0.11. 10-그램의 경우 0.10.\n' +
      '* **품질 필터** 47: 금지 된, 독성 또는 NSFW 하위 문서에서 사용자 및 제출을 제거 합니다. 각주 49: 5-그램의 경우 0.15. 6-그램의 경우 0.14. 7-그램의 경우 0.13. 8-그램의 경우 0.12. 9-그램의 경우 0.11. 10-그램의 경우 0.10.\n' +
      '* **콘텐츠 필터**47: 금지 된, 독성 또는 NSFW 하위 기록에서 사용자 및 제출을 제거 합니다. 각주 49: 5-그램의 경우 0.15. 6-그램의 경우 0.14. 7-그램의 경우 0.13. 8-그램의 경우 0.12. 9-그램의 경우 0.11. 10-그램의 경우 0.10.\n' +
      '* **콘텐츠 필터**47: 금지 된, 독성 또는 NSFW 하위 기록에서 사용자 및 제출을 제거 합니다. 각주 50: "the", "be", "to", "of", "and", "that", "have", "with" 각주 51: allenai/gpt-neox-olmo-dolma-v1_5를 사용하여 토큰을 획득한다.\n' +
      '* **콘텐츠 필터**47: 금지 된, 독성 또는 NSFW 하위 기록에서 사용자 및 제출을 제거 합니다. 각주 52: 5-그램의 경우 0.15. 6-그램의 경우 0.14. 7-그램의 경우 0.13. 8-그램의 경우 0.12. 9-그램의 경우 0.11. 10-그램의 경우 0.10.\n' +
      '\n' +
      '* **콘텐츠 필터**: 전자 메일, 전화 번호 및 IP 주소를 식별하는 정규식을 사용하는 PII(개인 식별 정보) 마스크\n' +
      '* **중복 제거**: Bloom 필터를 사용 하 여 단락 수준에서 주석 및 제출을 중복 복제 합니다 (공동).\n' +
      '\n' +
      'The Stack(deduplicated)에서 유도된 코드 서브세트의 경우, 다음 필터들을 사용한다(도 8):\n' +
      '\n' +
      '* **언어 필터**: 다음 프로그래밍 언어와 연결된 파일을 제거합니다.\n' +
      '* 데이터 또는 숫자 콘텐츠: _csv_, _json_, _json5_, _jsonId_, _jsoniq_, _svg_\n' +
      '* 어셈블리 코드: _assembly_\n' +
      '* **품질 필터47**: 문서 프리앰블52에서 코드 파일의 저작권 문을 제거합니다. 각주 52: 코드 라이선스 및 프로버넌스는 여전히 메타데이터에서 추적됩니다.\n' +
      '* **품질 필터 47**: RedPajama v1(Together Computer, 2023c) 코드 필터 중 하나와 일치하는 문서를 제거했습니다 (제거에 태깅된 데이터의_41.49%):\n' +
      '* 최대 줄 길이 > 1000자입니다.\n' +
      '* 평균 줄 길이 > 100자입니다.\n' +
      '* alpha-numeric characters < 0.25의 비율.\n' +
      '* 토큰 수에 대한 알파벳 문자의 비율 < 1.553. 각주 53: 화이트 스페이스 토큰나이저를 이용하여 카운팅된 토큰\n' +
      '* **품질 필터 47**: 다음 Starcoder 필터 중 하나와 일치하는 문서를 제거했습니다 (Li 등, 2023):\n' +
      '* XML 템플릿 코드를 포함합니다.\n' +
      '* HTML code-to-text ratio <= 0.2.\n' +
      '* Java, Javascript, Python 코드 대 주석 비율 <= 0.01 또는 > 0.8.\n' +
      '* **콘텐츠 필터**: 이메일, 전화 번호 및 IP 주소를 식별하는 정규식을 사용하는 PII(개인 식별 정보)를 마스크합니다. 6개 이상의 PII를 포함하는 페이지는 코퍼스에서 완전히 제거됩니다.\n' +
      '\n' +
      '**위키피디아 및 위키북** 하위 집합의 경우 25개 미만의 UTF-8 단어가 포함된 페이지를 제거합니다.\n' +
      '\n' +
      '**Gutenberg** 하위 집합의 경우:\n' +
      '\n' +
      '* **언어 식별**: 각 단락(텍스트의 줄 바꿈으로 정의됨)에 대해 FastText를 사용하여 언어 식별을 수행합니다. 그런 다음 모든 구절에 대한 점수를 평균하여 평균 언어 점수를 계산한다. 문서가 \\(0.5\\)보다 낮은 언어 점수를 갖는 경우, 폐기되고;\n' +
      '* **품질 필터 47**: 25개 미만의 UTF-8 단어가 포함된 페이지를 제거합니다. 각주 47: **품질 필터 47**: 100회 이상 반복되는 토큰 또는 토큰 시퀀스가 포함된 문서를 제거합니다. 각주 52: 코드 라이선스 및 프로버넌스는 메타데이터에서 여전히 추적됩니다.\n' +
      '\n' +
      '**PeS2o** 하위 집합의 경우 토큰 또는 토큰 시퀀스가 100회51 이상 반복되는 모든 문서를 제거합니다.\n' +
      '\n' +
      '각주 53: 화이트 스페이스 토큰나이저를 이용하여 카운팅된 토큰\n' +
      '\n' +
      '돌마 버전 1.0 및 1.5의 경우 돌마의 모든 하위 집합에 대해 오염 제거를 수행한다. 특히, Paloma 평가 제품군 Magnusson 등(2023)에서 문서와 공유되는 단락들을 제거한다. 전반적으로 이 평가 세트의 오염으로 인해 데이터 세트의 0.003%만 제거된다. 돌마 버전 1.6은 오염 제거되지 않았습니다.\n' +
      '\n' +
      '전처리/세척된 데이터 외에 "생" 데이터가 저장되었는가? (예를 들어, 예기치 않은 미래 사용을 지원하기 위해)\n' +
      '\n' +
      '원시 데이터는 공통 크롤을 제외한 모든 하위 집합에 사용할 수 있습니다. 공간 제약으로 인해 위에서 설명한 대로 언어 ID로 필터링된 커먼 크롤 스냅샷의 선형화된 버전만 유지한다.\n' +
      '\n' +
      'AI를 위한 알렌 연구소 밖에서는 원시 데이터를 다운로드할 수 없다. 관심 있는 개인은 원시 데이터에 액세스해야 하는 경우 이 원고의 저자에게 연락할 수 있다.\n' +
      '\n' +
      '**전처리 소프트웨어를 사용할 수 있습니까?**\n' +
      '\n' +
      '예, 모든 전처리 소프트웨어는 github.com/allenai/dolma의 GitHub 및 PyPI54에서 사용할 수 있습니다.\n' +
      '\n' +
      '각주 54: [https://pypi.org/project/dolma/](https://pypi.org/project/dolma/)\n' +
      '\n' +
      '**이 데이터 세트 수집/처리 절차가 이 데이터 시트의 첫 번째 섹션에 설명된 데이터 세트를 만드는 동기를 달성합니까?* *\n' +
      '\n' +
      '네, 그렇습니다\n' +
      '\n' +
      '### Dataset Distribution\n' +
      '\n' +
      '**데이터 세트는 어떻게 배포되나요? (예: 웹 사이트, API 등; 데이터가 DOI를 갖는지; 중복 보관되는지)* *\n' +
      '\n' +
      'Dolma는 HuggingFace Hub를 통해 배포되며, 이 허브는 Git-LFS 확장을 사용하여 데이터 세트(Lhoest 등, 2021) Python 패키지, 직접 다운로드 및 Git를 통해 액세스할 수 있습니다. 또한, 사본은 알렌 인공지능 연구소의 클라우드 스토리지에 저장된다.\n' +
      '\n' +
      '**데이터 세트는 언제 릴리스/처음 배포되나요? (이 데이터 세트에 대한 표준 논문/참조서가 있습니까)**\n' +
      '\n' +
      '데이터 세트를 지금 사용할 수 있습니다. 이 원고는 데이터 세트에 대한 참조 역할을 합니다.\n' +
      '\n' +
      '**어떤 라이선스(있는 경우) 아래에 배포되나요? 데이터에 대한 저작권이 있습니까?**\n' +
      '\n' +
      '돌마와 관련된 라이센스에 대한 정보는 포옹 페이스 허브의 릴리스 페이지에서 확인할 수 있습니다: 포옹 페이스.co/datasets/allenai/dolma.\n' +
      '\n' +
      '**수수료 또는 액세스/수출 제한이 있습니까?* *\n' +
      '\n' +
      '데이터 세트는 무료로 배포됩니다. 사용자는 포옹 페이스 허브의 릴리스 페이지에서 포옹 페이스.co/datasets/allenai/dolma와 같은 제한 사항을 확인해야 합니다.\n' +
      '\n' +
      '### Dataset Maintenance\n' +
      '\n' +
      '**데이터 세트를 지원/호스트/유지 하는 사람은 누구입니까? 데이터 세트의 소유자/큐레이터/관리자(예: 이메일 주소 또는 기타 연락처 정보)와 어떻게 연락합니까?**\n' +
      '\n' +
      '알렌 인공지능 연구소는 데이터 세트를 유지한다. 지원 질문의 경우 사용자는 GitHub55 또는 데이터 세트 페이지56의 커뮤니티 탭(전자가 후자보다 선호됨)에서 문제를 열도록 초대됩니다. 다른 문의 사항은 ai2-info@allenai.org로 전송되어야 합니다.\n' +
      '\n' +
      '각주 55: [https://github.com/allenai/dolma/issues](https://github.com/allenai/dolma/issues)\n' +
      '\n' +
      '**데이터 세트가 업데이트되나요? 얼마나 자주 그리고 누구에 의해? 업데이트/수정본을 문서화 하 고 통신 하는 방법 (예: 메일링 목록, GitHub)은 어떻게 되나요? 오류가 있나요?\n' +
      '\n' +
      '데이터 세트는 알렌 인공지능 연구소의 관리자들이 필요에 따라 업로드할 것이다. 데이터 세트의 최신 버전이 그에 따라 레이블이 지정됩니다. 최신 버전의 데이터 세트와 체인지 로그는 첫 번째 수정에서 시작 하 여 사용할 수 있습니다.\n' +
      '\n' +
      '**데이터 집합이 사용 되지 않는 경우 이것이 어떻게 전달 될까요? 이 데이터 세트를 사용하는 모든 논문/시스템에 연결할 리포지토리가 있습니까? **\n' +
      '\n' +
      '사용자는 사용 중인 데이터 세트의 버전을 추적해야 합니다. 최신 버전의 Dolma에 대한 정보는 HuggingFace Hub의 릴리스 페이지에서 확인할 수 있습니다. huggingface.co/datasets/allenai/dolma. Dolma 사용자는 이 데이터를 사용할 때 이 원고를 인용해야 합니다.\n' +
      '\n' +
      '다른 사람들이 이 데이터 세트에서 확장/확장/빌딩을 원하는 경우 그렇게 하는 메커니즘이 있습니까? 그렇다면 해당 기여의 품질을 추적/평가하는 프로세스가 있습니까? 사용자에게 이러한 기여를 전달/분배하는 과정은 무엇입니까? 파생물의 생성 및 분배는 전술한 바와 같다. 기고자가 향후 돌마 릴리스로 개선을 다시 전달하려면 이 원고의 해당 저자에게 연락해야 한다.\n' +
      '\n' +
      '### 법적 및 윤리적 고려 사항\n' +
      '\n' +
      '**데이터 집합이 사용자 (예: 특성)와 관련 되거나 사용자에 의해 생성 된 경우 데이터 수집에 대 한 정보를 제공 했습니까? (예: 쓰기, 사진, 상호 작용, 트랜잭션 등을 수집하는 데이터 세트)**\n' +
      '\n' +
      '웹 데이터에서 파생된 Dolma의 하위 집합은 사람 또는 사람 그룹에 의해 생성될 수 있지만 저자 정보는 종종 사용할 수 없다.\n' +
      '\n' +
      '저자들은 데이터 수집에 대해 직접 알리지 않았다. 백과사전 및 웹 콘텐츠의 경우 웹 서버의 로그에는 커먼 크롤이 실행하는 거미 기록이 포함됩니다. 학술 내용의 경우 pes2o 하위 집합(솔다이니와 Lo, 2023)은 저자에 의해 허용 배포에 대해 허가된 원고에서 파생된다. 레딧 콘텐츠는 서비스 조건에 맞는 공개 API를 통해 획득했으며 레딧 게시물의 개별 저자는 직접 연락하지 않았다. 마지막으로 알렌 인공지능 연구소는 프로젝트 구텐베르크와 접촉하지 않았다.\n' +
      '\n' +
      '**다른 윤리 보호 대상과 관련이 있는 경우 적절한 의무가 충족되었습니까? (예를 들어, 의료 데이터는 동물에서 수집된 정보를 포함할 수 있음)**\n' +
      '\n' +
      '돌마의 성격과 규모상 어떤 의무가 적절한지 판단할 수 없다.\n' +
      '\n' +
      '**사람과 관련이 있는 경우 윤리적 검토 응용 프로그램/검토/승인이 있습니까? (예: 기관 검토 위원회 응용 프로그램) 사람과 관련 된 경우 데이터 집합이 무엇에 사용 되는지 설명 하 고 동의 했습니까? 인간 커뮤니케이션에서 수집된 데이터에 대해 어떤 공동체 규범이 존재하는가? 만약 동의를 얻었다면, 어떻게? 사람들은 향후 또는 특정 용도로 동의를 취소할 수 있는 메커니즘을 제공 받았습니까? **\n' +
      '\n' +
      'OLMo 프로젝트에는 AI를 위한 앨런 연구소의 내부 및 외부 구성원으로 구성된 윤리 위원회가 포함된다. 돌마 조성 계획을 위원회와 함께 검토하고 권장 사항을 통합했다.\n' +
      '\n' +
      '유사한 노력으로 확립된 관행에 따라 데이터 세트에 표시될 수 있는 개인으로부터 동의가 수집되지 않았다. 데이터 세트에서 제거되기를 원하는 개인을 위해 폼57을 사용할 수 있다.\n' +
      '\n' +
      '각주 57: [https://forms.gle/q4BNUkUxKwKfdT6](https://forms.gle/q4BNUkUxKwKfdT6)\n' +
      '\n' +
      '**사람과 관련이 있는 경우이 데이터 집합이 사람을 해하거나 법적 조치에 노출할 수 있습니까? (예: 재정적 사회적 또는 기타) 위해 가능성을 완화하거나 줄이기 위해 무엇을 했습니까?**\n' +
      '\n' +
      '돌마에는 웹 페이지에서 파생된 텍스트 인스턴스가 있습니다. 웹에서 크롤링된 공통 크롤입니다. 콘텐츠는 개인 정보를 포함한 민감한 정보를 포함하거나 웹의 금융 정보 사용자가 공개적으로 온라인에 게시하기로 선택한 정보를 포함할 수 있다. 이 데이터는 공공장소에서만 수집되므로 웹 브라우징을 통해 동일한 데이터에 액세스하거나 액세스할 수 있습니다. 우리는 다양한 유형의 개인 정보를 측정하고 특정 유형의 민감한 정보를 제거하기 위한 도구를 구축했으며 라이센스를 통해 사용자가 이 데이터로 할 수 있는 것을 제한한다.\n' +
      '\n' +
      '개인에게 정보가 제거되기를 원하는 경우 폼57을 통해 요청을 제출할 것을 권장합니다.\n' +
      '\n' +
      '각주 57: [https://forms.gle/q4BNUkUxKwKfdT6](https://forms.gle/q4BNUkUxKwKfdT6)\n' +
      '\n' +
      '**사람과 관련이 있는 경우 특정 사회 그룹에 부당하게 유리하거나 불리합니까? 어떤 면에서요? 이는 어떻게 완화 되었습니까?* *Dolma는 출처가 없는 대표적인 샘플이 아닙니다. 인터넷에서 일부 커뮤니티를 과소 대표하거나 과대 대표할 수 있으며, 또한 peS2o 하위 집합의 논문은 STEM 분야로 편향되어 있으며, 구텐베르크 도서관의 책은 대부분 공개 영역(출판 당시, 1927년 이전에 출판된 책)에서 비롯되며, 마지막으로 위키백과 위키북의 영어 및 단순 하위 집합은 지구 북부의 사건과 사람들에게 편향될 수 있다.\n' +
      '\n' +
      '우리는 돌마의 사회 집단의 분포를 변경하려고 시도하지 않았다. 대규모 데이터 세트의 사회적 편향을 수정하기 위한 대규모 개입은 여전히 도전적이며 향후 작업에 맡겨져 있다.\n' +
      '\n' +
      '**사람과 관련이 있는 경우 개인 정보 보장이 제공 되었습니까? 그렇다면 어떤 보장과 이러한 보장은 어떻게 보장됩니까?**\n' +
      '\n' +
      '이 데이터 세트에는 웹에서 커먼 크롤에 의해 스크래핑된 웹 페이징에서 파생된 텍스트가 포함되어 있습니다. 그 데이터의 대부분은 저자를 식별할 수 없다. 많은 경우, 창작자들은 의도적으로 익명으로 온라인에 게시하는 것을 선택하므로 작가성을 추론하는 것을 목표로 하는 것은 윤리적으로 어려울 수 있다. 우리는 우리의 데이터에 대한 액세스를 제공하고, 그로부터 또는 그에 대한 데이터가 제거될 가능성이 있는 크리에이터가 연락할 수 있도록 권장합니다.\n' +
      '\n' +
      '**데이터 세트가 EU GDPR(일반 데이터 보호 규정)을 준수합니까? 미국 고용 기회 균등법과 같은 다른 기준을 준수합니까? **\n' +
      '\n' +
      '우리는 개인의 콘텐츠나 정보를 별도로 식별하지 않고 집계로 이 데이터 세트를 만들었다. 우리는 신뢰할 수 있게 탐지할 수 있는 유형의 개인 정보를 제거하기 위해 합리적인 조치를 취했다. 우리는 데이터에 액세스할 수 있는 사용자를 제한하고 차별적으로 간주될 수 있는 사용을 금지하는 라이선스에 따라 이를 공개한다. 또한 코퍼스57에서 텍스트 또는 텍스트가 제거되도록 누구에게나 연락할 수 있는 방법을 제공합니다.\n' +
      '\n' +
      '**데이터 세트에 중요 하거나 기밀로 간주 될 수 있는 정보가 포함 되어 있나요? (예: 개인 식별 정보) 데이터 세트에 부적절하거나 불쾌한 것으로 간주될 수 있는 정보가 포함되어 있습니까?* *\n' +
      '\n' +
      '이 데이터 세트에는 웹에서 커먼 크롤에 의해 스크래핑된 웹 페이징에서 파생된 텍스트가 포함되어 있습니다. 따라서, 인터넷 상의 크리에이터에 의해 공공 웹사이트에 게시된 텍스트를 포함할 수 있다. 저자가 공개적으로 개인 정보 또는 불쾌한 콘텐츠를 게시한 경우 이 데이터 세트에 포함될 수 있습니다. 우리는 신뢰할 수 있게 탐지할 수 있는 유형의 개인 정보를 제거하기 위해 합리적인 조치를 취했다. 독성으로 분류된 문장이 포함된 문서도 제거했다.\n' +
      '\n' +
      '## 부록 K All Raw Ablation 결과\n' +
      '\n' +
      '### Dolma와 다른 Corpora 비교\n' +
      '\n' +
      '도 18: Perplexity results on Paloma (Magnusson et al., 2023); subsets 4chan (Papasavva et al., 2020), WikiText 103 (Merity et al., 2016), and Pile (Gao et al., 2020) (Val).\n' +
      '\n' +
      '도 21: 팔로마(Magnusson et al., 2023); 하위 집합 Manosphere(Ribeiro et al., 2021)에 대한 Perplexity 결과\n' +
      '\n' +
      '도 23: 결과 다운스트림 태스크 OpenBookQA(Mihaylov et al., 2018), ARC-E(Clark et al., 2018), 및 WinoGrande(Sakaguchi et al., 2019)\n' +
      '\n' +
      '도 21: 팔로마(Magnusson et al., 2023); 하위 집합 Manosphere(Ribeiro et al., 2021)에 대한 Perplexity 결과\n' +
      '\n' +
      '도 19: Perplexity results on Paloma (Magnusson et al., 2023); subset C4 100 dom (Chronopoulou et al., 2022), Penn Tree Bank (Marcus et al., 1994), and Gab (Zannettou et al., 2018)\n' +
      '\n' +
      '도 20: 팔로마(Magnusson et al., 2023); 서브셋 ICE(Greenbaum, 1991), M2D2(Reid et al., 2022)(Wiki), 및 트위터 AAE(Blodgett et al., 2016)에 대한 Perplexity 결과\n' +
      '\n' +
      '도 24: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '도 25: 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:64]\n' +
      '\n' +
      '도 31: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '도 32: 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:66]\n' +
      '\n' +
      '도 38: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '도 39: 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:68]\n' +
      '\n' +
      '도 45: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '도 46: 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:70]\n' +
      '\n' +
      '도 53: 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '도 52: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:72]\n' +
      '\n' +
      '도 59: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '도 60 : 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:74]\n' +
      '\n' +
      '도 66: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '도 67: 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:76]\n' +
      '\n' +
      '## 6 Conclusion\n' +
      '\n' +
      '도 73: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:78]\n' +
      '\n' +
      '도 80 : 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '도 79: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:80]\n' +
      '\n' +
      '도 87: 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '도 86: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '[MISSING_PAGE_EMPTY:82]\n' +
      '\n' +
      '도 93: 팔로마(Magnusson et al., 2023); 서브셋 Pile(Gao et al., 2020)(Val), Dolma Books Subset, 및 C4 100 dom(Chronopoulou et al., 2022)에 대한 Perplexity 결과\n' +
      '\n' +
      '도 94: 팔로마(Magnusson et al., 2023); 서브셋 WikiText 103(Merity et al., 2016), 돌마 코드 서브셋, 돌마 웹 서브셋에 대한 Perplexity 결과\n' +
      '\n' +
      '도 95: 결과 다운스트림 태스크 OpenBookQA(Mihaylov et al., 2018), ARC-E(Clark et al., 2018), 및 WinoGrande(Sakaguchi et al., 2019)\n' +
      '\n' +
      '도 97: 트레이닝 크로스 엔트로피\n' +
      '\n' +
      '도 93: 팔로마(Magnusson et al., 2023); 서브셋 Pile(Gao et al., 2020)(Val), Dolma Books Subset, 및 C4 100 dom(Chronopoulou et al., 2022)에 대한 Perplexity 결과\n' +
      '\n' +
      '도 96: 결과 다운스트림 태스크 SciQ(Welbl et al., 2017), HellaSwag(Zellers et al., 2019), 및 PIQA(Bisk et al., 2019)\n' +
      '\n' +
      '도 94: 팔로마(Magnusson et al., 2023); 서브셋 WikiText 103(Merity et al., 2016), 돌마 코드 서브셋, 돌마 웹 서브셋에 대한 Perplexity 결과\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>