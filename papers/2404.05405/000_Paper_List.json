{
    "2404.05405": {
        "paper_id": "2404.05405",
        "abs_url": "https://arxiv.org/abs/2404.05405",
        "pdf_url": "https://arxiv.org/pdf/2404.05405.pdf",
        "supp_url": null,
        "src_website": "ArXiv",
        "download_name": "2404.05405_Physics_of_Language_Models_Part_33_Knowledge_Capacity_Scaling_Laws.pdf",
        "title": "Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws",
        "year": null,
        "paper_venue": null,
        "authors": [
            "Zeyuan Allen-Zhu",
            "Yuanzhi Li"
        ],
        "abstract": ") significantly increases a model's knowledge capacity. Language models can autonomously identify and prioritize domains rich in knowledge, optimizing their storage capacity.",
        "comments": "",
        "official_code_urls": [],
        "pwc_page_url": "https://paperswithcode.com/paper/physics-of-language-models-part-3-3-knowledge",
        "bibtex": "@misc{allenzhu2024physics,\n      title={Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws}, \n      author={Zeyuan Allen-Zhu and Yuanzhi Li},\n      year={2024},\n      eprint={2404.05405},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}"
    }
}