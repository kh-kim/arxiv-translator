<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.14219] Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</title><meta property="og:description" content="We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mix…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.14219">

<!--Generated on Sun May  5 18:06:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Phi-3 Technical Report: 
<br class="ltx_break">A Highly Capable Language Model Locally on Your Phone</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Microsoft
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">3.3조 토큰에 대해 훈련된 38억 개의 매개 변수 언어 모델인 <span class="ltx_text ltx_font_bold" id="id1.id1.1">phi-3-mini</span>을 소개합니다. 전체 성능은 Mixtral 8x7B 및 GPT-3.5와 같은 모델(예: <span class="ltx_text ltx_font_bold" id="id1.id1.2">phi-3-mini</span>)과 비교됩니다. 이 혁신은 전적으로 교육을 위한 데이터 세트에 있으며, 크게 필터링된 웹 데이터와 합성 데이터로 구성된 <span class="ltx_text ltx_font_bold" id="id1.id1.3">phi-2</span>에 사용되는 확장 버전이다. 이 모델은 또한 견고성, 안전성 및 채팅 형식을 위해 추가로 정렬됩니다. 또한 <span class="ltx_text ltx_font_bold" id="id1.id1.4">phi-3-small</span> 및 <span class="ltx_text ltx_font_bold" id="id1.id1.5">phi-3-medium</span>이라고 하는 4.8T 토큰에 대해 훈련된 7B 및 14B 모델을 사용하여 일부 초기 매개변수 크기 조정 결과를 제공합니다.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">지난 몇 년 동안 AI의 놀라운 발전은 전 세계적으로 <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">scaling-up</span>에서 ever-larger 모델 및 데이터 세트에 대한 주요 노력에 크게 기인할 수 있다. 대용량 언어 모델(Large Language Models, LLM)은 불과 5년 전에 불과 10억 개의 파라미터(GPT-2는 15억 개의 파라미터 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx27" title="">RWC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite>)에서 오늘날 조개의 파라미터로 꾸준히 크기가 증가했다. 이 노력에 대한 추진력은 대규모 모델을 훈련하여 얻을 수 있는 예측 가능한 개선, 소위 <span class="ltx_text ltx_font_italic" id="S1.p1.1.2">스케일링 법칙</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx20" title="">KMH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>, <a class="ltx_ref" href="#bib.bibx13" title="">HBM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>, <a class="ltx_ref" href="#bib.bibx24" title="">MRB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>에서 비롯된다. 그러나 이러한 법률은 "고정" 데이터 원본을 가정합니다. 이 가정은 이제 새로운 방식으로 데이터와 상호 작용할 수 있는 프런티어 LLM 자체의 존재로 인해 크게 방해를 받는다. Pi 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx11" title="">GZA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>, <a class="ltx_ref" href="#bib.bibx21" title="">LBE<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>, <a class="ltx_ref" href="#bib.bibx14" title="">JBA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>에 대한 이전 연구에서 웹 데이터의 LLM 기반 필터링과 LLM 생성 합성 데이터의 조합이 일반적으로 훨씬 더 큰 모델에서만 볼 수 있는 더 작은 언어 모델에서 성능을 가능하게 하는 것으로 나타났다. 예를 들어, 이 데이터 레시피에 대해 훈련된 이전 모델 <span class="ltx_text ltx_font_bold" id="S1.p1.1.3">phi-2</span> (2.7B 매개 변수)은 정규 데이터에 대해 훈련된 모델 <math alttext="25" class="ltx_Math" display="inline" id="S1.p1.1.m1.1"><semantics id="S1.p1.1.m1.1a"><mn id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><cn id="S1.p1.1.m1.1.1.cmml" type="integer" xref="S1.p1.1.m1.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">25</annotation></semantics></math> 배의 성능과 일치했다. 이 보고서에서 우리는 <span class="ltx_text ltx_font_bold" id="S1.p1.1.4">phi-3-mini</span> (3.8B 매개 변수)에서 사용된 데이터 세트의 더 크고 고급 버전에서 3.3T 토큰에 대해 훈련된 새로운 모델인 <span class="ltx_text ltx_font_bold" id="S1.p1.1.5">phi-2</span>을 제시한다. 작은 크기로 <span class="ltx_text ltx_font_bold" id="S1.p1.1.6">phi-3-mini</span>은 현대 전화에서 로컬로 쉽게 추론할 수 있지만(그림 <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ Highly capable language model running locally on a cell-phone. ‣ 2 Technical Specifications ‣ Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"><span class="ltx_text ltx_ref_tag">1</span></a> 참조), Mixtral 8x7B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx19" title="">JSR<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>24</a>]</cite> 및 GPT-3.5와 같은 모델로 온파처럼 보이는 품질을 달성합니다.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<svg id="S1.p2.pic1" class="ltx_picture" height="229.36" overflow="visible" version="1.1" width="600"><g transform="translate(0,229.36) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 223.45 C 0 226.72 2.64 229.36 5.91 229.36 L 594.09 229.36 C 597.36 229.36 600 226.72 600 223.45 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 223.45 C 1.97 225.63 3.73 227.39 5.91 227.39 L 594.09 227.39 C 596.27 227.39 598.03 225.63 598.03 223.45 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 12.82 5.91)"><foreignObject width="574.35" height="217.55" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S1.p2.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:415.1pt;">
<span id="S1.p2.pic1.1.1.1.1.1.1" class="ltx_p ltx_minipage ltx_align_top" style="width:429.3pt;"><span id="S1.p2.pic1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">User:</span><span id="S1.p2.pic1.1.1.1.1.1.1.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;"> Explain why it is surprising that one can build a language model small enough to fit on a phone, yet almost as powerful as ChatGPT. Just use one funny sentence.</span></span>
<span id="S1.p2.pic1.1.1.1.1.1.2" class="ltx_p ltx_minipage ltx_align_top" style="width:429.3pt;"><span id="S1.p2.pic1.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">phi-3-mini:</span><span id="S1.p2.pic1.1.1.1.1.1.2.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;"> It’s like fitting a supercomputer in a flip phone, but instead of breaking the phone, it just breaks the internet with its tiny, yet mighty, linguistic prowess!</span></span>
<span id="S1.p2.pic1.1.1.1.1.1.3" class="ltx_p ltx_minipage ltx_align_top" style="width:429.3pt;"><span id="S1.p2.pic1.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">User:</span><span id="S1.p2.pic1.1.1.1.1.1.3.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;"> Okay now more serious answer, and note that this was achieved solely by changing the training data.</span></span>
<span id="S1.p2.pic1.1.1.1.1.1.4" class="ltx_p ltx_minipage ltx_align_top" style="width:429.3pt;"><span id="S1.p2.pic1.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">phi-3-mini:</span><span id="S1.p2.pic1.1.1.1.1.1.4.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;"> The development of a compact language model that rivals the capabilities of ChatGPT, while fitting on a phone, is a testament to the power of data-driven machine learning. By meticulously curating and optimizing the training dataset, researchers can significantly reduce the model’s size without compromising its performance. [...]</span></span>
</span></foreignObject></g></g></svg>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Technical Specifications</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.2"><span class="ltx_text ltx_font_bold" id="S2.p1.2.1">phi-3-mini</span> 모델은 트랜스포머 디코더 아키텍처 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx34" title="">VSP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite>, 디폴트 컨텍스트 길이 <math alttext="4K" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mrow id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mn id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">4</mn><mo id="S2.p1.1.m1.1.1.1" lspace="0em" rspace="0em" xref="S2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><times id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1"></times><cn id="S2.p1.1.m1.1.1.2.cmml" type="integer" xref="S2.p1.1.m1.1.1.2">4</cn><ci id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">4K</annotation></semantics></math>이다. 또한 컨텍스트 길이를 <math alttext="128K" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mn id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">128</mn><mo id="S2.p1.2.m2.1.1.1" lspace="0em" rspace="0em" xref="S2.p1.2.m2.1.1.1.cmml">​</mo><mi id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><times id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1"></times><cn id="S2.p1.2.m2.1.1.2.cmml" type="integer" xref="S2.p1.2.m2.1.1.2">128</cn><ci id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">128K</annotation></semantics></math>로 확장하는 LongRope <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx10" title="">DZZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>24</a>]</cite>를 통해 <span class="ltx_text ltx_font_bold" id="S2.p1.2.2">phi-3-mini-128K</span>이라고 하는 롱 컨텍스트 버전을 소개한다.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p" id="S2.p2.3">오픈 소스 커뮤니티에 가장 좋은 이점을 제공하기 위해 <span class="ltx_text ltx_font_bold" id="S2.p2.3.1">phi-3-mini</span>은 Llama-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx32" title="">TLI<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>와 유사한 블록 구조를 기반으로 하며 32064<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We remove BoS tokens and add some additional tokens for chat template.</span></span></span>의 어휘 크기를 가진 동일한 토큰마이저를 사용합니다. 이는 Llama-2 계열의 모델을 위해 개발된 모든 패키지를 <span class="ltx_text ltx_font_bold" id="S2.p2.3.2">phi-3-mini</span>에 직접 적용할 수 있음을 의미한다. 모델은 <math alttext="3072" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><mn id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">3072</mn><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><cn id="S2.p2.1.m1.1.1.cmml" type="integer" xref="S2.p2.1.m1.1.1">3072</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">3072</annotation></semantics></math> hidden dimension, <math alttext="32" class="ltx_Math" display="inline" id="S2.p2.2.m2.1"><semantics id="S2.p2.2.m2.1a"><mn id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><cn id="S2.p2.2.m2.1.1.cmml" type="integer" xref="S2.p2.2.m2.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">32</annotation></semantics></math> head 및 <math alttext="32" class="ltx_Math" display="inline" id="S2.p2.3.m3.1"><semantics id="S2.p2.3.m3.1a"><mn id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><cn id="S2.p2.3.m3.1.1.cmml" type="integer" xref="S2.p2.3.m3.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">32</annotation></semantics></math> layer를 사용한다. 우리는 총 3.3T 토큰에 대해 bfloat16을 사용하여 훈련했다. 모델은 이미 채팅-핀튜닝되어 있으며, 채팅 템플릿은 다음과 같다:</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<svg id="S2.p3.pic1" class="ltx_picture" height="22.88" overflow="visible" version="1.1" width="600"><g transform="translate(0,22.88) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 16.98 C 0 20.24 2.64 22.88 5.91 22.88 L 594.09 22.88 C 597.36 22.88 600 20.24 600 16.98 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 16.98 C 1.97 19.15 3.73 20.91 5.91 20.91 L 594.09 20.91 C 596.27 20.91 598.03 19.15 598.03 16.98 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 12.82 5.91)"><foreignObject width="574.35" height="11.07" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:415.1pt;">
<span id="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_p"><span id="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">&lt;|user|&gt;<math id="S2.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S2.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="S2.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S2.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S2.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S2.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">\backslash</annotation></semantics></math>n
Question
&lt;|end|&gt;<math id="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mo id="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">\backslash</annotation></semantics></math>n
&lt;|assistant|&gt;</span></span>
</span></foreignObject></g></g></svg>
</div>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p" id="S2.p4.5"><span class="ltx_text ltx_font_bold" id="S2.p4.5.1">phi-3-small</span> 모델 (7B 매개 변수)은 어휘 크기가 100352이고 기본 컨텍스트 길이가 <math alttext="8K" class="ltx_Math" display="inline" id="S2.p4.1.m1.1"><semantics id="S2.p4.1.m1.1a"><mrow id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml"><mn id="S2.p4.1.m1.1.1.2" xref="S2.p4.1.m1.1.1.2.cmml">8</mn><mo id="S2.p4.1.m1.1.1.1" lspace="0em" rspace="0em" xref="S2.p4.1.m1.1.1.1.cmml">​</mo><mi id="S2.p4.1.m1.1.1.3" xref="S2.p4.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><apply id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1"><times id="S2.p4.1.m1.1.1.1.cmml" xref="S2.p4.1.m1.1.1.1"></times><cn id="S2.p4.1.m1.1.1.2.cmml" type="integer" xref="S2.p4.1.m1.1.1.2">8</cn><ci id="S2.p4.1.m1.1.1.3.cmml" xref="S2.p4.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">8K</annotation></semantics></math>인 틱토큰 토큰화기를 활용 합니다. <math alttext="32" class="ltx_Math" display="inline" id="S2.p4.2.m2.1"><semantics id="S2.p4.2.m2.1a"><mn id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.1b"><cn id="S2.p4.2.m2.1.1.cmml" type="integer" xref="S2.p4.2.m2.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.1c">32</annotation></semantics></math> 레이어들 및 <math alttext="4096" class="ltx_Math" display="inline" id="S2.p4.3.m3.1"><semantics id="S2.p4.3.m3.1a"><mn id="S2.p4.3.m3.1.1" xref="S2.p4.3.m3.1.1.cmml">4096</mn><annotation-xml encoding="MathML-Content" id="S2.p4.3.m3.1b"><cn id="S2.p4.3.m3.1.1.cmml" type="integer" xref="S2.p4.3.m3.1.1">4096</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.3.m3.1c">4096</annotation></semantics></math>의 숨겨진 크기를 갖는, 7B 모델 클래스의 표준 디코더 아키텍처를 따른다. KV 캐시 공간을 최소화하기 위해 모델은 또한 <math alttext="4" class="ltx_Math" display="inline" id="S2.p4.4.m4.1"><semantics id="S2.p4.4.m4.1a"><mn id="S2.p4.4.m4.1.1" xref="S2.p4.4.m4.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S2.p4.4.m4.1b"><cn id="S2.p4.4.m4.1.1.cmml" type="integer" xref="S2.p4.4.m4.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.4.m4.1c">4</annotation></semantics></math> 쿼리가 <math alttext="1" class="ltx_Math" display="inline" id="S2.p4.5.m5.1"><semantics id="S2.p4.5.m5.1a"><mn id="S2.p4.5.m5.1.1" xref="S2.p4.5.m5.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p4.5.m5.1b"><cn id="S2.p4.5.m5.1.1.cmml" type="integer" xref="S2.p4.5.m5.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.5.m5.1c">1</annotation></semantics></math> 키를 공유하는 그룹화된 쿼리 주의를 활용한다. 또한 <span class="ltx_text ltx_font_bold" id="S2.p4.5.2">phi-3-small</span>은 긴 컨텍스트 검색 성능을 유지하면서 KV 캐시 절약에 더 최적화하기 위해 밀집 주의와 새로운 블록parse 주의의 대체 계층을 사용합니다. 이 모델에는 추가로 10%의 다국어 데이터도 사용되었다.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Highly capable language model running locally on a cell-phone.</h3>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.2">작은 크기 덕분에 <span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.2.1">phi-3-mini</span>은 4비트로 양자화되어 <math alttext="\approx" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.p1.1.m1.1a"><mo id="S2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.m1.1b"><approx id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.m1.1c">\approx</annotation></semantics></math> 1.8GB의 메모리만 차지할 수 있다. A16 바이오닉 칩이 기본적으로 온-디바이스를 실행하고 완전히 오프라인에서 초당 <math alttext="12" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.2.m2.1"><semantics id="S2.SS0.SSS0.Px1.p1.2.m2.1a"><mn id="S2.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.2.m2.1b"><cn id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" type="integer" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.2.m2.1c">12</annotation></semantics></math> 토큰 이상을 달성하는 아이폰 14에서 <span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.2.2">phi-3-mini</span>을 배포하여 양자화된 모델을 테스트했다.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="https://ar5iv.labs.arxiv.org/html/2404.14219/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="199" height="414" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="https://ar5iv.labs.arxiv.org/html/2404.14219/assets/x2.png" id="S2.F1.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="199" height="414" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="https://ar5iv.labs.arxiv.org/html/2404.14219/assets/x3.png" id="S2.F1.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="199" height="413" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.3.1.1" style="font-size:90%;">그림 1</span>:</span><span class="ltx_text" id="S2.F1.4.2" style="font-size:90%;">4-bit quantized <span class="ltx_text ltx_font_bold" id="S2.F1.4.2.1">phi-3-mini</span> running on a iPhone with A16 Bionic chip, generating over 12 tokens per second. </span></figcaption>
</figure>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Training Methodology.</h3>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">작은 언어 모델의 성능을 향상시키기 위해 고품질 훈련 데이터를 활용하고 표준 <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.1">scaling-laws</span>에서 벗어난 "Textbooks Are All You Need" <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx11" title="">GZA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>에서 시작된 작업 순서를 따른다. 이 연구에서 우리는 이러한 방법이 3.8B 총 매개변수만으로 GPT-3.5 또는 Mixtral과 같은 매우 유능한 모델의 수준에 도달할 수 있음을 보여준다(예를 들어 Mixtral은 45B 총 매개변수를 갖는다). 우리의 학습 데이터는 다양한 오픈 인터넷 소스에서 "교육 수준"에 따라 크게 필터링된 웹 데이터와 합성 LLM 생성 데이터로 구성된다. 사전 훈련은 두 개의 서로 다른 단계와 순차적인 단계로 수행되며, 단계-1은 대부분 모델 일반 지식과 언어 이해를 가르치는 것을 목표로 하는 웹 소스들로 구성된다. Phase-2는 모델 논리적 추론과 다양한 틈새 기술을 가르치는 일부 합성 데이터와 훨씬 더 심하게 필터링된 웹 데이터(Phase-1에서 사용된 하위 집합)를 병합한다.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Data Optimal Regime.</h3>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">"compute optimal regime" <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx13" title="">HBM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite> 또는 "over-train regime"에서 언어 모델을 훈련하는 이전 작업과 달리, 우리는 주로 <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px3.p1.1.1">given scale</span>에 대한 데이터의 품질에 중점을 둡니다. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Just like for “compute optimal regime”, we use the term “optimal” in an aspirational sense for “data optimal regime”. We are not implying that we actually found the provably “optimal” data mixture for a given scale.</span></span></span> 우리는 훈련 데이터를 작은 모델에 대한 "데이터 최적" 체제에 더 가깝게 보정하려고 한다. 특히, 우리는 올바른 수준의 "지식"을 포함하도록 웹 데이터를 필터링하고 모델에 대한 "추론 능력"을 잠재적으로 향상시킬 수 있는 더 많은 웹 페이지를 유지한다. 예를 들어, 특정일의 프리미어 리그에서의 경기 결과는 프론티어 모델에 대한 좋은 훈련 데이터일 수 있지만, 미니 사이즈 모델에 대한 "추론"을 위한 더 많은 모델 용량을 남기기 위해서는 그러한 정보를 제거해야 한다. <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ Data Optimal Regime. ‣ 2 Technical Specifications ‣ Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"><span class="ltx_text ltx_ref_tag">2</span></a>의 Llama-2와 우리의 접근법을 비교한다.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2404.14219/assets/scaling.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="216" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.2.1.1" style="font-size:90%;">그림 2</span>:</span><span class="ltx_text" id="S2.F2.3.2" style="font-size:90%;">Scaling law close the "Data Optimal Regime"(from left to right: phi-1.5, phi-2, phi-3-mini, phi-3-small) versus Llama-2 family of models (7B, 13B, 34B, 70B) is trained on the same fixed data. MLU 오류의 로그 대 모델 크기의 로그를 표시합니다. </span></figcaption>
</figure>
<div id="S2.SS0.SSS0.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">더 큰 크기의 모델에 대한 데이터를 테스트하기 위해 동일한 토큰izer 및 구조를 사용하여 14B 매개 변수를 가진 모델인 <span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px3.p2.1.1">phi-3-medium</span>, <span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px3.p2.1.2">phi-3-mini</span>을 훈련하고 약간 더 많은 epoch에 대해 동일한 데이터에 대해 훈련했다(<span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px3.p2.1.3">phi-3-small</span>에서와 같이 4.8T 토큰 합계). 이 모델은 40개의 헤드와 40개의 레이어를 가지고 있으며 임베딩 차원은 5120이다. 우리는 일부 벤치마크가 3.8B에서 7B로 개선되는 것보다 7B에서 14B로 훨씬 덜 개선된다는 것을 관찰하며, 아마도 우리의 데이터 혼합이 14B 매개변수 모델에 대한 "데이터 최적 체제"에 들어가기 위해 더 많은 작업이 필요함을 나타낸다. 우리는 여전히 이러한 벤치마크 중 일부(HumanEval에 대한 회귀 포함)를 적극적으로 조사하고 있으므로 <span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px3.p2.1.4">phi-3-medium</span>에 대한 숫자를 "미리 보기"로 고려해야 한다.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px4" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Post-training.</h3>

<div id="S2.SS0.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS0.SSS0.Px4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px4.p1.1.1">phi-3-mini</span>은 SFT(supervised finetuning) 및 DPO(direct preference optimization)를 포함한 두 단계를 거쳤다. SFT는 수학, 코딩, 추론, 대화, 모델 ID 및 안전과 같은 다양한 영역에서 고도로 선별된 고품질 데이터를 활용한다. SFT 데이터 믹스는 영어 전용 예제를 사용하는 것으로 시작합니다. DPO 데이터는 채팅 형식 데이터, 추론 및 책임 AI(RAI) 노력을 다룹니다. 이러한 출력을 "거부된" 응답으로 사용하여 DPO를 사용하여 원하지 않는 동작으로부터 모델을 멀리 이동합니다. 수학, 코딩, 추론, 견고성, 안전성의 향상 외에도 사후 훈련은 언어 모델을 사용자가 효율적이고 안전하게 상호 작용할 수 있는 AI 비서로 변환한다.</p>
</div>
<div id="S2.SS0.SSS0.Px4.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS0.SSS0.Px4.p2.1">훈련 후 과정의 일환으로 컨텍스트 길이 제한이 4K 대신 128K로 확대된 <span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px4.p2.1.1">phi-3-mini</span>의 긴 컨텍스트 버전을 개발했다. 전체적으로 128K 모델 품질은 4K 길이 버전과 동등하며 긴 컨텍스트 작업을 처리할 수 있습니다. 긴 컨텍스트 확장은 긴 컨텍스트 중간 훈련과 SFT 및 DPO를 모두 사용한 긴 짧은 혼합 사후 훈련을 포함하여 두 단계로 수행되었다.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Academic benchmarks</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p" id="S3.p1.2">다음 페이지에서 모델의 추론 능력(상식 추론과 논리적 추론 모두)을 측정하는 표준 오픈 소스 벤치마크에서 <span class="ltx_text ltx_font_bold" id="S3.p1.2.1">phi-3-mini</span>에 대한 결과를 보고한다. phi-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx14" title="">JBA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>, Mistral-7b-v0.1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx18" title="">JSM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>, Mixtral-8x7b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx19" title="">JSR<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>24</a>]</cite>, Gemma 7B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx33" title="">TMH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>24</a>]</cite>, Llama-3-instruct-8b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx1" title="">AI23</a>]</cite>, GPT-3.5와 비교한다. 보고된 모든 숫자는 숫자가 비슷하도록 정확히 동일한 파이프라인으로 생성된다. 이러한 숫자는 평가에서 약간 다른 선택으로 인해 게시된 다른 숫자와 다를 수 있다. 현재 표준과 같이 온도 <math alttext="0" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mn id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><cn id="S3.p1.1.m1.1.1.cmml" type="integer" xref="S3.p1.1.m1.1.1">0</cn></annotation-xml></semantics></math>에서 모델을 평가하기 위해 몇 번의 샷 프롬프트를 사용한다. 프롬프트와 샷 수는 언어 모델을 평가하기 위한 Microsoft 내부 도구의 일부이며, 특히 <span class="ltx_text ltx_font_bold" id="S3.p1.2.2">phi-3</span> 모델에 대한 파이프라인에 대한 최적화를 수행하지 않았습니다. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>For example, we found that using ## before the Question can lead to a noticeable improvement to <span class="ltx_text ltx_font_bold" id="footnote3.1">phi-3-mini</span>’s results across many benchmarks, but we did not do such changes in the prompts.</span></span></span> <math alttext="k" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">k</annotation></semantics></math>–shot 예시의 수는 벤치마크 당 나열됩니다. 2-shot 프롬프트의 일례는 부록 <a class="ltx_ref" href="#A1" title="Appendix A Example prompt for benchmarks ‣ Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"><span class="ltx_text ltx_ref_tag">A</span></a>에 기재되어 있다.</p>
</div>
<div id="S3.2.p2" class="ltx_para ltx_noindent ltx_align_center">
<p id="S3.2.p2.1" class="ltx_p"><span id="S3.2.p2.1.1" class="ltx_text ltx_inline-block" style="width:433.6pt;"> <span id="S3.2.p2.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:745.5pt;height:929.8pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;"> <span id="S3.2.p2.1.1.1.1" class="ltx_p"><span id="S3.2.p2.1.1.1.1.1" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.1" class="ltx_td ltx_border_rr"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.2.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.2.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.1.2.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1.2.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Phi-3-mini</span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.2.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.2.2.1.2.1.1" class="ltx_text" style="font-size:80%;">3.8b</span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.1.2.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.3.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.3.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.1.3.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1.3.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Phi-3-small</span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.3.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.3.2.1.2.1.1" class="ltx_text" style="font-size:80%;">7b (preview)</span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.1.3.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.4.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.4.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.1.4.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1.4.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Phi-3-medium</span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.4.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.4.2.1.2.1.1" class="ltx_text" style="font-size:80%;">14b (preview)</span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.1.4.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.5.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.5.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.1.5.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1.5.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Phi-2</span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.5.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.5.2.1.2.1.1" class="ltx_text" style="font-size:80%;">2.7b</span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.1.5.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.6" class="ltx_td ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.6.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.6.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.1.6.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1.6.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Mistral</span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.6.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.6.2.1.2.1.1" class="ltx_text" style="font-size:80%;">7b</span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.1.6.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.7" class="ltx_td ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.7.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.7.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.1.7.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1.7.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Gemma</span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.7.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.7.2.1.2.1.1" class="ltx_text" style="font-size:80%;">7b</span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.1.7.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.8" class="ltx_td ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.8.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.8.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.1.8.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1.8.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Llama-3-In</span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.8.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.8.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.8.2.1.2.1.1" class="ltx_text" style="font-size:80%;">8b</span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.1.8.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.9" class="ltx_td ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.9.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.9.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.1.9.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1.9.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.9.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Mixtral</span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.9.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.9.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.9.2.1.2.1.1" class="ltx_text" style="font-size:80%;">8x7b</span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.1.9.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.10" class="ltx_td ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.10.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.1.10.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.1.10.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.1.10.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.10.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">GPT-3.5</span></span> <span id="S3.2.p2.1.1.1.1.1.1.1.10.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.1.10.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.1.10.2.1.2.1.1" class="ltx_text" style="font-size:80%;">version 1106</span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.1.10.3" class="ltx_text"></span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.2.1" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S3.2.p2.1.1.1.1.1.1.2.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.2.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.2.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.2.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.2.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">MMLU</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.2.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.2.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(5-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">HBK<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.2.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">68.8</span> <span id="S3.2.p2.1.1.1.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">75.3</span> <span id="S3.2.p2.1.1.1.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">78.2</span> <span id="S3.2.p2.1.1.1.1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">56.3</span> <span id="S3.2.p2.1.1.1.1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">61.7</span> <span id="S3.2.p2.1.1.1.1.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t">63.6</span> <span id="S3.2.p2.1.1.1.1.1.1.2.8" class="ltx_td ltx_align_center ltx_border_t">66.0</span> <span id="S3.2.p2.1.1.1.1.1.1.2.9" class="ltx_td ltx_align_center ltx_border_t">68.4</span> <span id="S3.2.p2.1.1.1.1.1.1.2.10" class="ltx_td ltx_align_center ltx_border_t">71.4</span></span> <span id="S3.2.p2.1.1.1.1.1.1.3" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.3.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.3.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.3.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.3.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.3.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.3.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">HellaSwag</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.3.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.3.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(5-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx37" title="" class="ltx_ref">ZHB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.3.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.3.2" class="ltx_td ltx_align_center">76.7</span> <span id="S3.2.p2.1.1.1.1.1.1.3.3" class="ltx_td ltx_align_center">78.7</span> <span id="S3.2.p2.1.1.1.1.1.1.3.4" class="ltx_td ltx_align_center">83.0</span> <span id="S3.2.p2.1.1.1.1.1.1.3.5" class="ltx_td ltx_align_center">53.6</span> <span id="S3.2.p2.1.1.1.1.1.1.3.6" class="ltx_td ltx_align_center">58.5</span> <span id="S3.2.p2.1.1.1.1.1.1.3.7" class="ltx_td ltx_align_center">49.8</span> <span id="S3.2.p2.1.1.1.1.1.1.3.8" class="ltx_td ltx_align_center">69.5</span> <span id="S3.2.p2.1.1.1.1.1.1.3.9" class="ltx_td ltx_align_center">70.4</span> <span id="S3.2.p2.1.1.1.1.1.1.3.10" class="ltx_td ltx_align_center">78.8</span></span> <span id="S3.2.p2.1.1.1.1.1.1.4" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.4.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.4.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.4.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.4.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.4.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.4.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">ANLI</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.4.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.4.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.4.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(7-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">NWD<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.4.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.4.2" class="ltx_td ltx_align_center">52.8</span> <span id="S3.2.p2.1.1.1.1.1.1.4.3" class="ltx_td ltx_align_center">55.0</span> <span id="S3.2.p2.1.1.1.1.1.1.4.4" class="ltx_td ltx_align_center">58.7</span> <span id="S3.2.p2.1.1.1.1.1.1.4.5" class="ltx_td ltx_align_center">42.5</span> <span id="S3.2.p2.1.1.1.1.1.1.4.6" class="ltx_td ltx_align_center">47.1</span> <span id="S3.2.p2.1.1.1.1.1.1.4.7" class="ltx_td ltx_align_center">48.7</span> <span id="S3.2.p2.1.1.1.1.1.1.4.8" class="ltx_td ltx_align_center">54.8</span> <span id="S3.2.p2.1.1.1.1.1.1.4.9" class="ltx_td ltx_align_center">55.2</span> <span id="S3.2.p2.1.1.1.1.1.1.4.10" class="ltx_td ltx_align_center">58.1</span></span> <span id="S3.2.p2.1.1.1.1.1.1.5" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.5.1" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S3.2.p2.1.1.1.1.1.1.5.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.5.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.5.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.5.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.5.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.5.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">GSM-8K</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.5.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.5.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.5.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(0-Shot; CoT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">CKB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.5.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.5.2" class="ltx_td ltx_align_center ltx_border_t">82.5</span> <span id="S3.2.p2.1.1.1.1.1.1.5.3" class="ltx_td ltx_align_center ltx_border_t">88.9</span> <span id="S3.2.p2.1.1.1.1.1.1.5.4" class="ltx_td ltx_align_center ltx_border_t">90.3</span> <span id="S3.2.p2.1.1.1.1.1.1.5.5" class="ltx_td ltx_align_center ltx_border_t">61.1</span> <span id="S3.2.p2.1.1.1.1.1.1.5.6" class="ltx_td ltx_align_center ltx_border_t">46.4</span> <span id="S3.2.p2.1.1.1.1.1.1.5.7" class="ltx_td ltx_align_center ltx_border_t">59.8</span> <span id="S3.2.p2.1.1.1.1.1.1.5.8" class="ltx_td ltx_align_center ltx_border_t">77.4</span> <span id="S3.2.p2.1.1.1.1.1.1.5.9" class="ltx_td ltx_align_center ltx_border_t">64.7</span> <span id="S3.2.p2.1.1.1.1.1.1.5.10" class="ltx_td ltx_align_center ltx_border_t">78.1</span></span> <span id="S3.2.p2.1.1.1.1.1.1.6" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.6.1" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S3.2.p2.1.1.1.1.1.1.6.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.6.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.6.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.6.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.6.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.6.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">MedQA</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.6.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.6.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.6.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(2-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">JPO<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>20</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.6.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.6.2" class="ltx_td ltx_align_center ltx_border_t">53.8</span> <span id="S3.2.p2.1.1.1.1.1.1.6.3" class="ltx_td ltx_align_center ltx_border_t">58.2</span> <span id="S3.2.p2.1.1.1.1.1.1.6.4" class="ltx_td ltx_align_center ltx_border_t">69.4</span> <span id="S3.2.p2.1.1.1.1.1.1.6.5" class="ltx_td ltx_align_center ltx_border_t">40.9</span> <span id="S3.2.p2.1.1.1.1.1.1.6.6" class="ltx_td ltx_align_center ltx_border_t">49.6</span> <span id="S3.2.p2.1.1.1.1.1.1.6.7" class="ltx_td ltx_align_center ltx_border_t">50.0</span> <span id="S3.2.p2.1.1.1.1.1.1.6.8" class="ltx_td ltx_align_center ltx_border_t">58.9</span> <span id="S3.2.p2.1.1.1.1.1.1.6.9" class="ltx_td ltx_align_center ltx_border_t">62.2</span> <span id="S3.2.p2.1.1.1.1.1.1.6.10" class="ltx_td ltx_align_center ltx_border_t">63.4</span></span> <span id="S3.2.p2.1.1.1.1.1.1.7" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.7.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.7.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.7.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.7.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.7.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.7.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.7.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">AGIEval</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.7.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.7.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.7.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(0-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">ZCG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.7.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.7.2" class="ltx_td ltx_align_center">37.5</span> <span id="S3.2.p2.1.1.1.1.1.1.7.3" class="ltx_td ltx_align_center">45.0</span> <span id="S3.2.p2.1.1.1.1.1.1.7.4" class="ltx_td ltx_align_center">48.4</span> <span id="S3.2.p2.1.1.1.1.1.1.7.5" class="ltx_td ltx_align_center">29.8</span> <span id="S3.2.p2.1.1.1.1.1.1.7.6" class="ltx_td ltx_align_center">35.1</span> <span id="S3.2.p2.1.1.1.1.1.1.7.7" class="ltx_td ltx_align_center">42.1</span> <span id="S3.2.p2.1.1.1.1.1.1.7.8" class="ltx_td ltx_align_center">42.0</span> <span id="S3.2.p2.1.1.1.1.1.1.7.9" class="ltx_td ltx_align_center">45.2</span> <span id="S3.2.p2.1.1.1.1.1.1.7.10" class="ltx_td ltx_align_center">48.4</span></span> <span id="S3.2.p2.1.1.1.1.1.1.8" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.8.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.8.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.8.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.8.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.8.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.8.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.8.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">TriviaQA</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.8.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.8.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.8.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(5-Shot)  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">JCWZ17</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.8.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.8.2" class="ltx_td ltx_align_center">64.0</span> <span id="S3.2.p2.1.1.1.1.1.1.8.3" class="ltx_td ltx_align_center">59.1</span> <span id="S3.2.p2.1.1.1.1.1.1.8.4" class="ltx_td ltx_align_center">75.6</span> <span id="S3.2.p2.1.1.1.1.1.1.8.5" class="ltx_td ltx_align_center">45.2</span> <span id="S3.2.p2.1.1.1.1.1.1.8.6" class="ltx_td ltx_align_center">72.3</span> <span id="S3.2.p2.1.1.1.1.1.1.8.7" class="ltx_td ltx_align_center">75.2</span> <span id="S3.2.p2.1.1.1.1.1.1.8.8" class="ltx_td ltx_align_center">73.6</span> <span id="S3.2.p2.1.1.1.1.1.1.8.9" class="ltx_td ltx_align_center">82.2</span> <span id="S3.2.p2.1.1.1.1.1.1.8.10" class="ltx_td ltx_align_center">85.8</span></span> <span id="S3.2.p2.1.1.1.1.1.1.9" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.9.1" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S3.2.p2.1.1.1.1.1.1.9.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.9.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.9.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.9.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.9.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.9.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">Arc-C</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.9.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.9.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.9.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(10-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">CCE<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.9.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.9.2" class="ltx_td ltx_align_center ltx_border_t">84.9</span> <span id="S3.2.p2.1.1.1.1.1.1.9.3" class="ltx_td ltx_align_center ltx_border_t">90.7</span> <span id="S3.2.p2.1.1.1.1.1.1.9.4" class="ltx_td ltx_align_center ltx_border_t">91.0</span> <span id="S3.2.p2.1.1.1.1.1.1.9.5" class="ltx_td ltx_align_center ltx_border_t">75.9</span> <span id="S3.2.p2.1.1.1.1.1.1.9.6" class="ltx_td ltx_align_center ltx_border_t">78.6</span> <span id="S3.2.p2.1.1.1.1.1.1.9.7" class="ltx_td ltx_align_center ltx_border_t">78.3</span> <span id="S3.2.p2.1.1.1.1.1.1.9.8" class="ltx_td ltx_align_center ltx_border_t">80.5</span> <span id="S3.2.p2.1.1.1.1.1.1.9.9" class="ltx_td ltx_align_center ltx_border_t">87.3</span> <span id="S3.2.p2.1.1.1.1.1.1.9.10" class="ltx_td ltx_align_center ltx_border_t">87.4</span></span> <span id="S3.2.p2.1.1.1.1.1.1.10" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.10.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.10.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.10.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.10.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.10.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.10.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.10.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">Arc-E</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.10.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.10.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.10.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(10-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">CCE<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>18</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.10.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.10.2" class="ltx_td ltx_align_center">94.6</span> <span id="S3.2.p2.1.1.1.1.1.1.10.3" class="ltx_td ltx_align_center">97.1</span> <span id="S3.2.p2.1.1.1.1.1.1.10.4" class="ltx_td ltx_align_center">97.8</span> <span id="S3.2.p2.1.1.1.1.1.1.10.5" class="ltx_td ltx_align_center">88.5</span> <span id="S3.2.p2.1.1.1.1.1.1.10.6" class="ltx_td ltx_align_center">90.6</span> <span id="S3.2.p2.1.1.1.1.1.1.10.7" class="ltx_td ltx_align_center">91.4</span> <span id="S3.2.p2.1.1.1.1.1.1.10.8" class="ltx_td ltx_align_center">92.3</span> <span id="S3.2.p2.1.1.1.1.1.1.10.9" class="ltx_td ltx_align_center">95.6</span> <span id="S3.2.p2.1.1.1.1.1.1.10.10" class="ltx_td ltx_align_center">96.3</span></span> <span id="S3.2.p2.1.1.1.1.1.1.11" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.11.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.11.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.11.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.11.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.11.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.11.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.11.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">PIQA</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.11.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.11.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.11.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(5-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">BZGC19</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.11.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.11.2" class="ltx_td ltx_align_center">84.2</span> <span id="S3.2.p2.1.1.1.1.1.1.11.3" class="ltx_td ltx_align_center">87.8</span> <span id="S3.2.p2.1.1.1.1.1.1.11.4" class="ltx_td ltx_align_center">87.7</span> <span id="S3.2.p2.1.1.1.1.1.1.11.5" class="ltx_td ltx_align_center">60.2</span> <span id="S3.2.p2.1.1.1.1.1.1.11.6" class="ltx_td ltx_align_center">77.7</span> <span id="S3.2.p2.1.1.1.1.1.1.11.7" class="ltx_td ltx_align_center">78.1</span> <span id="S3.2.p2.1.1.1.1.1.1.11.8" class="ltx_td ltx_align_center">77.1</span> <span id="S3.2.p2.1.1.1.1.1.1.11.9" class="ltx_td ltx_align_center">86.0</span> <span id="S3.2.p2.1.1.1.1.1.1.11.10" class="ltx_td ltx_align_center">86.6</span></span> <span id="S3.2.p2.1.1.1.1.1.1.12" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.12.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.12.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.12.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.12.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.12.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.12.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.12.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">SociQA</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.12.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.12.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.12.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(5-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">BZGC19</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.12.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.12.2" class="ltx_td ltx_align_center">76.6</span> <span id="S3.2.p2.1.1.1.1.1.1.12.3" class="ltx_td ltx_align_center">79.0</span> <span id="S3.2.p2.1.1.1.1.1.1.12.4" class="ltx_td ltx_align_center">80.2</span> <span id="S3.2.p2.1.1.1.1.1.1.12.5" class="ltx_td ltx_align_center">68.3</span> <span id="S3.2.p2.1.1.1.1.1.1.12.6" class="ltx_td ltx_align_center">74.6</span> <span id="S3.2.p2.1.1.1.1.1.1.12.7" class="ltx_td ltx_align_center">65.5</span> <span id="S3.2.p2.1.1.1.1.1.1.12.8" class="ltx_td ltx_align_center">73.2</span> <span id="S3.2.p2.1.1.1.1.1.1.12.9" class="ltx_td ltx_align_center">75.9</span> <span id="S3.2.p2.1.1.1.1.1.1.12.10" class="ltx_td ltx_align_center">68.3</span></span> <span id="S3.2.p2.1.1.1.1.1.1.13" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.13.1" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S3.2.p2.1.1.1.1.1.1.13.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.13.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.13.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.13.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.13.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.13.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">BigBench-Hard</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.13.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.13.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.13.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(0-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">SRR<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>, <a href="#bib.bibx30" title="" class="ltx_ref">SSS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.13.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.13.2" class="ltx_td ltx_align_center ltx_border_t">71.7</span> <span id="S3.2.p2.1.1.1.1.1.1.13.3" class="ltx_td ltx_align_center ltx_border_t">75.0</span> <span id="S3.2.p2.1.1.1.1.1.1.13.4" class="ltx_td ltx_align_center ltx_border_t">81.3</span> <span id="S3.2.p2.1.1.1.1.1.1.13.5" class="ltx_td ltx_align_center ltx_border_t">59.4</span> <span id="S3.2.p2.1.1.1.1.1.1.13.6" class="ltx_td ltx_align_center ltx_border_t">57.3</span> <span id="S3.2.p2.1.1.1.1.1.1.13.7" class="ltx_td ltx_align_center ltx_border_t">59.6</span> <span id="S3.2.p2.1.1.1.1.1.1.13.8" class="ltx_td ltx_align_center ltx_border_t">68.9</span> <span id="S3.2.p2.1.1.1.1.1.1.13.9" class="ltx_td ltx_align_center ltx_border_t">69.7</span> <span id="S3.2.p2.1.1.1.1.1.1.13.10" class="ltx_td ltx_align_center ltx_border_t">68.32</span></span> <span id="S3.2.p2.1.1.1.1.1.1.14" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.14.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.14.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.14.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.14.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.14.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.14.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.14.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">WinoGrande</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.14.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.14.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.14.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(5-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx28" title="" class="ltx_ref">SLBBC19</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.14.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.14.2" class="ltx_td ltx_align_center">70.8</span> <span id="S3.2.p2.1.1.1.1.1.1.14.3" class="ltx_td ltx_align_center">82.5</span> <span id="S3.2.p2.1.1.1.1.1.1.14.4" class="ltx_td ltx_align_center">81.4</span> <span id="S3.2.p2.1.1.1.1.1.1.14.5" class="ltx_td ltx_align_center">54.7</span> <span id="S3.2.p2.1.1.1.1.1.1.14.6" class="ltx_td ltx_align_center">54.2</span> <span id="S3.2.p2.1.1.1.1.1.1.14.7" class="ltx_td ltx_align_center">55.6</span> <span id="S3.2.p2.1.1.1.1.1.1.14.8" class="ltx_td ltx_align_center">58.0</span> <span id="S3.2.p2.1.1.1.1.1.1.14.9" class="ltx_td ltx_align_center">62.0</span> <span id="S3.2.p2.1.1.1.1.1.1.14.10" class="ltx_td ltx_align_center">68.8</span></span> <span id="S3.2.p2.1.1.1.1.1.1.15" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.15.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.15.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.15.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.15.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.15.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.15.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.15.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">OpenBookQA</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.15.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.15.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.15.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(10-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx23" title="" class="ltx_ref">MCKS18</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.15.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.15.2" class="ltx_td ltx_align_center">83.2</span> <span id="S3.2.p2.1.1.1.1.1.1.15.3" class="ltx_td ltx_align_center">88.4</span> <span id="S3.2.p2.1.1.1.1.1.1.15.4" class="ltx_td ltx_align_center">87.2</span> <span id="S3.2.p2.1.1.1.1.1.1.15.5" class="ltx_td ltx_align_center">73.6</span> <span id="S3.2.p2.1.1.1.1.1.1.15.6" class="ltx_td ltx_align_center">79.8</span> <span id="S3.2.p2.1.1.1.1.1.1.15.7" class="ltx_td ltx_align_center">78.6</span> <span id="S3.2.p2.1.1.1.1.1.1.15.8" class="ltx_td ltx_align_center">81.6</span> <span id="S3.2.p2.1.1.1.1.1.1.15.9" class="ltx_td ltx_align_center">85.8</span> <span id="S3.2.p2.1.1.1.1.1.1.15.10" class="ltx_td ltx_align_center">86.0</span></span> <span id="S3.2.p2.1.1.1.1.1.1.16" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.16.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.16.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.16.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.16.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.16.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.16.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.16.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">BoolQ</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.16.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.16.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.16.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(0-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">CLC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>19</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.16.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.16.2" class="ltx_td ltx_align_center">77.2</span> <span id="S3.2.p2.1.1.1.1.1.1.16.3" class="ltx_td ltx_align_center">82.9</span> <span id="S3.2.p2.1.1.1.1.1.1.16.4" class="ltx_td ltx_align_center">86.6</span> <span id="S3.2.p2.1.1.1.1.1.1.16.5" class="ltx_td ltx_align_center">–</span> <span id="S3.2.p2.1.1.1.1.1.1.16.6" class="ltx_td ltx_align_center">72.2</span> <span id="S3.2.p2.1.1.1.1.1.1.16.7" class="ltx_td ltx_align_center">66.0</span> <span id="S3.2.p2.1.1.1.1.1.1.16.8" class="ltx_td ltx_align_center">78.3</span> <span id="S3.2.p2.1.1.1.1.1.1.16.9" class="ltx_td ltx_align_center">77.6</span> <span id="S3.2.p2.1.1.1.1.1.1.16.10" class="ltx_td ltx_align_center">79.1</span></span> <span id="S3.2.p2.1.1.1.1.1.1.17" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.17.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.17.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.17.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.17.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.17.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.17.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.17.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">CommonSenseQA</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.17.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.17.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.17.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(10-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">THLB19</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.17.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.17.2" class="ltx_td ltx_align_center">80.2</span> <span id="S3.2.p2.1.1.1.1.1.1.17.3" class="ltx_td ltx_align_center">80.3</span> <span id="S3.2.p2.1.1.1.1.1.1.17.4" class="ltx_td ltx_align_center">82.6</span> <span id="S3.2.p2.1.1.1.1.1.1.17.5" class="ltx_td ltx_align_center">69.3</span> <span id="S3.2.p2.1.1.1.1.1.1.17.6" class="ltx_td ltx_align_center">72.6</span> <span id="S3.2.p2.1.1.1.1.1.1.17.7" class="ltx_td ltx_align_center">76.2</span> <span id="S3.2.p2.1.1.1.1.1.1.17.8" class="ltx_td ltx_align_center">73.6</span> <span id="S3.2.p2.1.1.1.1.1.1.17.9" class="ltx_td ltx_align_center">78.1</span> <span id="S3.2.p2.1.1.1.1.1.1.17.10" class="ltx_td ltx_align_center">79.6</span></span> <span id="S3.2.p2.1.1.1.1.1.1.18" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.18.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.18.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.18.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.18.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.18.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.18.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.18.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">TruthfulQA</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.18.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.18.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.18.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(10-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx22" title="" class="ltx_ref">LHE22</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.18.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.18.2" class="ltx_td ltx_align_center">65.0</span> <span id="S3.2.p2.1.1.1.1.1.1.18.3" class="ltx_td ltx_align_center">68.7</span> <span id="S3.2.p2.1.1.1.1.1.1.18.4" class="ltx_td ltx_align_center">75.7</span> <span id="S3.2.p2.1.1.1.1.1.1.18.5" class="ltx_td ltx_align_center">–</span> <span id="S3.2.p2.1.1.1.1.1.1.18.6" class="ltx_td ltx_align_center">52.1</span> <span id="S3.2.p2.1.1.1.1.1.1.18.7" class="ltx_td ltx_align_center">53.0</span> <span id="S3.2.p2.1.1.1.1.1.1.18.8" class="ltx_td ltx_align_center">62.0</span> <span id="S3.2.p2.1.1.1.1.1.1.18.9" class="ltx_td ltx_align_center">60.1</span> <span id="S3.2.p2.1.1.1.1.1.1.18.10" class="ltx_td ltx_align_center">85.8</span></span> <span id="S3.2.p2.1.1.1.1.1.1.19" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.19.1" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S3.2.p2.1.1.1.1.1.1.19.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.19.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.19.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.19.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.19.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.19.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">HumanEval</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.19.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.19.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.19.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(0-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">CTJ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.19.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.19.2" class="ltx_td ltx_align_center ltx_border_t">59.1</span> <span id="S3.2.p2.1.1.1.1.1.1.19.3" class="ltx_td ltx_align_center ltx_border_t">59.1</span> <span id="S3.2.p2.1.1.1.1.1.1.19.4" class="ltx_td ltx_align_center ltx_border_t">55.5</span> <span id="S3.2.p2.1.1.1.1.1.1.19.5" class="ltx_td ltx_align_center ltx_border_t">47.0</span> <span id="S3.2.p2.1.1.1.1.1.1.19.6" class="ltx_td ltx_align_center ltx_border_t">28.0</span> <span id="S3.2.p2.1.1.1.1.1.1.19.7" class="ltx_td ltx_align_center ltx_border_t">34.1</span> <span id="S3.2.p2.1.1.1.1.1.1.19.8" class="ltx_td ltx_align_center ltx_border_t">60.4</span> <span id="S3.2.p2.1.1.1.1.1.1.19.9" class="ltx_td ltx_align_center ltx_border_t">37.8</span> <span id="S3.2.p2.1.1.1.1.1.1.19.10" class="ltx_td ltx_align_center ltx_border_t">62.2</span></span> <span id="S3.2.p2.1.1.1.1.1.1.20" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.20.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.20.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.20.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.20.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.20.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.20.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.20.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">MBPP</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.20.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.20.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.20.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(3-Shot) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">AON<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>21</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.20.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.20.2" class="ltx_td ltx_align_center">70.0</span> <span id="S3.2.p2.1.1.1.1.1.1.20.3" class="ltx_td ltx_align_center">71.4</span> <span id="S3.2.p2.1.1.1.1.1.1.20.4" class="ltx_td ltx_align_center">74.5</span> <span id="S3.2.p2.1.1.1.1.1.1.20.5" class="ltx_td ltx_align_center">60.6</span> <span id="S3.2.p2.1.1.1.1.1.1.20.6" class="ltx_td ltx_align_center">50.8</span> <span id="S3.2.p2.1.1.1.1.1.1.20.7" class="ltx_td ltx_align_center">51.5</span> <span id="S3.2.p2.1.1.1.1.1.1.20.8" class="ltx_td ltx_align_center">65.3</span> <span id="S3.2.p2.1.1.1.1.1.1.20.9" class="ltx_td ltx_align_center">60.2</span> <span id="S3.2.p2.1.1.1.1.1.1.20.10" class="ltx_td ltx_align_center">77.8</span></span> <span id="S3.2.p2.1.1.1.1.1.1.21" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.21.1" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Average</span> <span id="S3.2.p2.1.1.1.1.1.1.21.2" class="ltx_td ltx_align_center ltx_border_t">71.2</span> <span id="S3.2.p2.1.1.1.1.1.1.21.3" class="ltx_td ltx_align_center ltx_border_t">74.9</span> <span id="S3.2.p2.1.1.1.1.1.1.21.4" class="ltx_td ltx_align_center ltx_border_t">78.2</span> <span id="S3.2.p2.1.1.1.1.1.1.21.5" class="ltx_td ltx_align_center ltx_border_t">–</span> <span id="S3.2.p2.1.1.1.1.1.1.21.6" class="ltx_td ltx_align_center ltx_border_t">61.0</span> <span id="S3.2.p2.1.1.1.1.1.1.21.7" class="ltx_td ltx_align_center ltx_border_t">62.0</span> <span id="S3.2.p2.1.1.1.1.1.1.21.8" class="ltx_td ltx_align_center ltx_border_t">68.0</span> <span id="S3.2.p2.1.1.1.1.1.1.21.9" class="ltx_td ltx_align_center ltx_border_t">69.9</span> <span id="S3.2.p2.1.1.1.1.1.1.21.10" class="ltx_td ltx_align_center ltx_border_t">75.3</span></span> <span id="S3.2.p2.1.1.1.1.1.1.22" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.22.1" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S3.2.p2.1.1.1.1.1.1.22.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.22.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.22.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.22.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.22.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.22.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">GPQA</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.22.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.22.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.22.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(2-Shot; CoT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">RHS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.22.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.22.2" class="ltx_td ltx_align_center ltx_border_t">32.8</span> <span id="S3.2.p2.1.1.1.1.1.1.22.3" class="ltx_td ltx_align_center ltx_border_t">34.3</span> <span id="S3.2.p2.1.1.1.1.1.1.22.4" class="ltx_td ltx_align_center ltx_border_t">–</span> <span id="S3.2.p2.1.1.1.1.1.1.22.5" class="ltx_td ltx_align_center ltx_border_t">–</span> <span id="S3.2.p2.1.1.1.1.1.1.22.6" class="ltx_td ltx_align_center ltx_border_t">–</span> <span id="S3.2.p2.1.1.1.1.1.1.22.7" class="ltx_td ltx_align_center ltx_border_t">–</span> <span id="S3.2.p2.1.1.1.1.1.1.22.8" class="ltx_td ltx_align_center ltx_border_t">–</span> <span id="S3.2.p2.1.1.1.1.1.1.22.9" class="ltx_td ltx_align_center ltx_border_t">–</span> <span id="S3.2.p2.1.1.1.1.1.1.22.10" class="ltx_td ltx_align_center ltx_border_t">29.0</span></span> <span id="S3.2.p2.1.1.1.1.1.1.23" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.23.1" class="ltx_td ltx_align_center ltx_border_rr"><span id="S3.2.p2.1.1.1.1.1.1.23.1.1" class="ltx_text"></span> <span id="S3.2.p2.1.1.1.1.1.1.23.1.2" class="ltx_text"> <span id="S3.2.p2.1.1.1.1.1.1.23.1.2.1" class="ltx_tabular ltx_align_middle"> <span id="S3.2.p2.1.1.1.1.1.1.23.1.2.1.1" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.23.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.23.1.2.1.1.1.1" class="ltx_text" style="font-size:120%;">MT Bench</span></span></span> <span id="S3.2.p2.1.1.1.1.1.1.23.1.2.1.2" class="ltx_tr"> <span id="S3.2.p2.1.1.1.1.1.1.23.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.2.p2.1.1.1.1.1.1.23.1.2.1.2.1.1" class="ltx_text" style="font-size:50%;">(2 round ave.) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx36" title="" class="ltx_ref">ZCS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite></span></span></span> </span></span><span id="S3.2.p2.1.1.1.1.1.1.23.1.3" class="ltx_text"></span></span> <span id="S3.2.p2.1.1.1.1.1.1.23.2" class="ltx_td ltx_align_center">8.38</span> <span id="S3.2.p2.1.1.1.1.1.1.23.3" class="ltx_td ltx_align_center">8.70</span> <span id="S3.2.p2.1.1.1.1.1.1.23.4" class="ltx_td ltx_align_center">8.91</span> <span id="S3.2.p2.1.1.1.1.1.1.23.5" class="ltx_td ltx_align_center">–</span> <span id="S3.2.p2.1.1.1.1.1.1.23.6" class="ltx_td ltx_align_center">–</span> <span id="S3.2.p2.1.1.1.1.1.1.23.7" class="ltx_td ltx_align_center">–</span> <span id="S3.2.p2.1.1.1.1.1.1.23.8" class="ltx_td ltx_align_center">–</span> <span id="S3.2.p2.1.1.1.1.1.1.23.9" class="ltx_td ltx_align_center">–</span> <span id="S3.2.p2.1.1.1.1.1.1.23.10" class="ltx_td ltx_align_center">8.35</span></span> </span></span></span> </span></span></span></p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Safety</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.p1.1.1">Phi-3-mini</span>은 Microsoft의 책임 AI 원칙에 따라 개발되었습니다. 전반적인 접근 방식은 수십 개의 RAI 피해 범주에 걸쳐 사후 훈련, 레드 팀, 자동화된 테스트 및 평가의 안전 정렬로 구성되었다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx4" title="">BSA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>24</a>]</cite>에서 영감을 받은 수정으로 도움 및 무해 선호도 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx3" title="">BJN<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>22</a>, <a class="ltx_ref" href="#bib.bibx16" title="">JLD<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>와 여러 사내 생성 데이터 세트를 활용하여 안전 사후 훈련에서 RAI 손상 범주를 해결했다. Microsoft의 독립적인 레드 팀은 훈련 후 프로세스 동안 개선 영역을 추가로 식별하기 위해 <span class="ltx_text ltx_font_bold" id="S4.p1.1.2">phi-3-mini</span>을 반복적으로 검사했습니다. 피드백을 기반으로 인사이트에 맞게 조정된 추가 데이터 세트를 선별하여 훈련 후 데이터 세트를 정제했다. 이 과정은 그림 <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4 Safety ‣ Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"><span class="ltx_text ltx_ref_tag">3</span></a>와 같이 유해 반응률의 현저한 감소를 가져왔다.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2404.14219/assets/with_without_safety_training.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="269" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.4.1.1" style="font-size:90%;">그림 3</span>:</span><span class="ltx_text" id="S4.F3.5.2" style="font-size:90%;">Microsoft AI Red Team에 의한 유해 응답 백분율 비교 <span class="ltx_text ltx_font_bold" id="S4.F3.5.2.1">phi-3-mini</span> 안전 정렬 전후. 빨간색 팀이 다중 회전 대화를 통해 유해한 응답을 생성하기 위해 적대적인 방식으로 <span class="ltx_text ltx_font_bold" id="S4.F3.5.2.2">phi-3-mini</span>을 유도하려고 시도함에 따라 이 차트의 유해한 응답 백분율은 부풀려진 숫자입니다. </span></figcaption>
</figure>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p" id="S4.p2.2">표 <a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ 4 Safety ‣ Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"><span class="ltx_text ltx_ref_tag">1</span></a>는 <span class="ltx_text ltx_font_bold" id="S4.p2.2.1">phi-3-mini-4k</span> 및 <span class="ltx_text ltx_font_bold" id="S4.p2.2.2">phi-3-mini-128k</span> 대비 phi-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx14" title="">JBA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>, Mistral-7b-v0.1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx18" title="">JSM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>23</a>]</cite>, Gemma 7b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx33" title="">TMH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>24</a>]</cite>, Llama-3-instruct-8b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bibx1" title="">AI23</a>]</cite>에 대한 사내 RAI 벤치마크 결과를 보여준다. 이 벤치마크는 GPT-4를 사용하여 5가지 범주에서 다중 회전 대화를 시뮬레이션하고 모델 응답을 평가했다. 응답의 정보가 지정된 프롬프트를 기반으로 하는 경우 0(완전히 접지됨)과 4(접지되지 않음) 사이의 접지되지 않은 정도를 측정합니다. 다른 범주에서 반응은 0(해롭지 않음)에서 7(극한 해악)까지의 유해성의 심각도로 평가되었고 결함률(DR-<math alttext="x" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">x</annotation></semantics></math>)은 심각도 점수가 <math alttext="x" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><mi id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><ci id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">x</annotation></semantics></math> 이상인 샘플의 백분율로 계산되었다.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.2" class="ltx_logical-block ltx_pruned_first">
<div id="S4.T1.2.p2" class="ltx_para ltx_noindent ltx_align_center">
<p id="S4.T1.2.p2.1" class="ltx_p"><span id="S4.T1.2.p2.1.1" class="ltx_text ltx_inline-block" style="width:433.6pt;"> <span id="S4.T1.2.p2.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:610.2pt;height:132.4pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;"> <span id="S4.T1.2.p2.1.1.1.1" class="ltx_p"><span id="S4.T1.2.p2.1.1.1.1.1" class="ltx_text">  <span id="S4.T1.2.p2.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.1" class="ltx_td ltx_border_rr"></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.2.1" class="ltx_text"></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.2.2" class="ltx_text"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.2.2.1" class="ltx_tabular ltx_align_middle"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.2.2.1.1" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Phi-3-Mini-4k</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.2.2.1.2" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.2.2.1.2.1.1" class="ltx_text" style="font-size:80%;">3.8b</span></span></span> </span></span><span id="S4.T1.2.p2.1.1.1.1.1.1.1.2.3" class="ltx_text"></span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.3.1" class="ltx_text"></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.3.2" class="ltx_text"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.3.2.1" class="ltx_tabular ltx_align_middle"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.3.2.1.1" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Phi-3-Mini-128k</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.3.2.1.2" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.3.2.1.2.1.1" class="ltx_text" style="font-size:80%;">3.8b</span></span></span> </span></span><span id="S4.T1.2.p2.1.1.1.1.1.1.1.3.3" class="ltx_text"></span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.4.1" class="ltx_text"></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.4.2" class="ltx_text"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.4.2.1" class="ltx_tabular ltx_align_middle"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.4.2.1.1" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Phi-2</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.4.2.1.2" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.4.2.1.2.1.1" class="ltx_text" style="font-size:80%;">2.7b</span></span></span> </span></span><span id="S4.T1.2.p2.1.1.1.1.1.1.1.4.3" class="ltx_text"></span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.5" class="ltx_td ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.5.1" class="ltx_text"></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.5.2" class="ltx_text"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.5.2.1" class="ltx_tabular ltx_align_middle"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.5.2.1.1" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Mistral</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.5.2.1.2" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.5.2.1.2.1.1" class="ltx_text" style="font-size:80%;">7b</span></span></span> </span></span><span id="S4.T1.2.p2.1.1.1.1.1.1.1.5.3" class="ltx_text"></span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.6" class="ltx_td ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.6.1" class="ltx_text"></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.6.2" class="ltx_text"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.6.2.1" class="ltx_tabular ltx_align_middle"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.6.2.1.1" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Gemma</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.6.2.1.2" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.6.2.1.2.1.1" class="ltx_text" style="font-size:80%;">7b</span></span></span> </span></span><span id="S4.T1.2.p2.1.1.1.1.1.1.1.6.3" class="ltx_text"></span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.7" class="ltx_td ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.7.1" class="ltx_text"></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.7.2" class="ltx_text"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.7.2.1" class="ltx_tabular ltx_align_middle"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.7.2.1.1" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Llama-3-In</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.7.2.1.2" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.1.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.p2.1.1.1.1.1.1.1.7.2.1.2.1.1" class="ltx_text" style="font-size:80%;">8b</span></span></span> </span></span><span id="S4.T1.2.p2.1.1.1.1.1.1.1.7.3" class="ltx_text"></span></span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.2" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.2.1" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Ungroundedness</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">0.603</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">0.637</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">1.481</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">0.935</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">0.679</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t">0.328</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.3" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.3.1" class="ltx_td ltx_align_center ltx_border_rr">Intellectual Property (DR-1)</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.3.2" class="ltx_td ltx_align_center">23.95%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.3.3" class="ltx_td ltx_align_center">21.50%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.3.4" class="ltx_td ltx_align_center">24.00%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.3.5" class="ltx_td ltx_align_center">56.20%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.3.6" class="ltx_td ltx_align_center">38.33%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.3.7" class="ltx_td ltx_align_center">37.30%</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.4" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.4.1" class="ltx_td ltx_align_center ltx_border_rr">Harmful Content Continuation (DR-3)</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.4.2" class="ltx_td ltx_align_center">0.75%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.4.3" class="ltx_td ltx_align_center">1.08%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.4.4" class="ltx_td ltx_align_center">2.93%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.4.5" class="ltx_td ltx_align_center">2.58%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.4.6" class="ltx_td ltx_align_center">1.28%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.4.7" class="ltx_td ltx_align_center">1.30%</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.5" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.5.1" class="ltx_td ltx_align_center ltx_border_rr">Harmful Content Summarization (DR-3)</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.5.2" class="ltx_td ltx_align_center">10.00%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.5.3" class="ltx_td ltx_align_center">10.20%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.5.4" class="ltx_td ltx_align_center">14.35%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.5.5" class="ltx_td ltx_align_center">22.33%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.5.6" class="ltx_td ltx_align_center">10.33%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.5.7" class="ltx_td ltx_align_center">8.20%</span></span> <span id="S4.T1.2.p2.1.1.1.1.1.1.6" class="ltx_tr"> <span id="S4.T1.2.p2.1.1.1.1.1.1.6.1" class="ltx_td ltx_align_center ltx_border_rr">Jailbreak (DR-1)</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.6.2" class="ltx_td ltx_align_center">12.29%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.6.3" class="ltx_td ltx_align_center">12.57%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.6.4" class="ltx_td ltx_align_center">15.00%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.6.5" class="ltx_td ltx_align_center">15.57%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.6.6" class="ltx_td ltx_align_center">11.43%</span> <span id="S4.T1.2.p2.1.1.1.1.1.1.6.7" class="ltx_td ltx_align_center">13.00%</span></span> </span></span></span> </span></span></span></p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.5.1.1" style="font-size:90%;">Table 1</span>:</span><span class="ltx_text" id="S4.T1.6.2" style="font-size:90%;">Comparison of Microsoft internal multi-turn conversation RAI benchmark results of <span class="ltx_text ltx_font_bold" id="S4.T1.6.2.1">phi-3-mini</span> and other models. 낮은 값은 테이블의 모든 메트릭에 대해 더 나은 성능을 나타냅니다. </span></figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Weakness</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p" id="S5.p1.1">LLM 능력 측면에서 <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S5.p1.1.1">phi-3-mini</span> 모델은 훨씬 더 큰 모델만큼 유사한 수준의 언어 이해 및 추론 능력을 달성하지만, 여전히 특정 작업에 대한 크기에 의해 근본적으로 제한된다. 이 모델은 단순히 "사실적 지식"을 너무 많이 저장할 수 있는 능력이 없으며, 이는 예를 들어 트리비아QA에서 낮은 성능으로 볼 수 있다. 그러나 이러한 약점은 검색 엔진을 통한 증강을 통해 해결할 수 있다고 생각한다. 그림 <a class="ltx_ref" href="#S5.F4" title="Figure 4 ‣ 5 Weakness ‣ Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"><span class="ltx_text ltx_ref_tag">4</span></a>에서 <span class="ltx_text ltx_font_bold" id="S5.p1.1.2">phi-3-mini</span>이 있는 HuggingFace default Chat-UI를 사용한 예를 보여 줍니다. 모델의 용량과 관련된 또 다른 약점은 우리가 언어를 대부분 영어로 제한했다는 것이다. 작은 언어 모델에 대한 다국어 능력 탐색은 더 많은 다국어 데이터를 포함함으로써 <span class="ltx_text ltx_font_bold" id="S5.p1.1.3">phi-3-small</span>에 대한 초기 유망한 결과와 함께 중요한 다음 단계이다.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p" id="S5.p2.1">우리의 부지런한 RAI 노력에도 불구하고 대부분의 LLM과 마찬가지로 사실상의 부정확성(또는 환각), 편향의 복제 또는 증폭, 부적절한 콘텐츠 생성 및 안전 문제에 대한 과제가 남아 있다. 신중하게 선별된 훈련 데이터와 표적화된 사후 훈련 및 레드 티밍 통찰력의 개선은 모든 차원에 걸쳐 이러한 문제를 크게 완화한다. 그러나 이러한 문제를 완전히 해결하기 위한 중요한 작업이 앞으로 있다.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="https://ar5iv.labs.arxiv.org/html/2404.14219/assets/without_search.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="255" height="405" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="https://ar5iv.labs.arxiv.org/html/2404.14219/assets/with_search.png" id="S5.F4.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="335" height="404" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.4.1.1" style="font-size:90%;">그림 4</span>:</span><span class="ltx_text" id="S5.F4.5.2" style="font-size:90%;">Left:<span class="ltx_text ltx_font_bold" id="S5.F4.5.2.1">phi-3-mini</span>’s completion without search. 오른쪽: [span class="ltx_text ltx_font_bold" id="S5.F4.5.2.2">phi-3-mini</span>’s completion with search, using the default HuggingFace Chat-UI search ability. </span></figcaption>
</figure>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[AI23]</span>
<span class="ltx_bibblock">
Meta AI.

</span>
<span class="ltx_bibblock">Introducing meta llama 3: The most capable openly available llm to
date, 2023.

</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[AON<sup id="bib.bibx2.4.4.1" class="ltx_sup"><span id="bib.bibx2.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski,
David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles
Sutton.

</span>
<span class="ltx_bibblock">Program synthesis with large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx2.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2108.07732</span>, 2021.

</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BJN<sup id="bib.bibx3.4.4.1" class="ltx_sup"><span id="bib.bibx3.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph,
Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage,
Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna
Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown,
Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan.

</span>
<span class="ltx_bibblock">Training a helpful and harmless assistant with reinforcement learning
from human feedback, 2022.

</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BSA<sup id="bib.bibx4.4.4.1" class="ltx_sup"><span id="bib.bibx4.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>24]</span>
<span class="ltx_bibblock">
Federico Bianchi, Mirac Suzgun, Giuseppe Attanasio, Paul Röttger, Dan
Jurafsky, Tatsunori Hashimoto, and James Zou.

</span>
<span class="ltx_bibblock">Safety-tuned llamas: Lessons from improving the safety of large
language models that follow instructions, 2024.

</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BZGC19]</span>
<span class="ltx_bibblock">
Yonatan Bisk, Rowan Zellers, Jianfeng Gao, and Yejin Choi.

</span>
<span class="ltx_bibblock">Piqa: Reasoning about physical commonsense in natural language.

</span>
<span class="ltx_bibblock"><span id="bib.bibx5.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1911.11641</span>, 2019.

</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CCE<sup id="bib.bibx6.4.4.1" class="ltx_sup"><span id="bib.bibx6.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>18]</span>
<span class="ltx_bibblock">
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa
Schoenick, and Oyvind Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the ai2 reasoning
challenge, 2018.

</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CKB<sup id="bib.bibx7.4.4.1" class="ltx_sup"><span id="bib.bibx7.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz
Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,
Christopher Hesse, and John Schulman.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems.

</span>
<span class="ltx_bibblock"><span id="bib.bibx7.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2110.14168</span>, 2021.

</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CLC<sup id="bib.bibx8.4.4.1" class="ltx_sup"><span id="bib.bibx8.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael
Collins, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Boolq: Exploring the surprising difficulty of natural yes/no
questions.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx8.7.1" class="ltx_text ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</span>, pages 2924–2936, 2019.

</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CTJ<sup id="bib.bibx9.4.4.1" class="ltx_sup"><span id="bib.bibx9.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique&nbsp;Ponde
de&nbsp;Oliveira&nbsp;Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy
Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder,
Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens
Winter, Philippe Tillet, Felipe&nbsp;Petroski Such, Dave Cummings, Matthias
Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss,
William&nbsp;Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor
Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher
Hesse, Andrew&nbsp;N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa,
Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter
Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
Wojciech Zaremba.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code, 2021.

</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DZZ<sup id="bib.bibx10.4.4.1" class="ltx_sup"><span id="bib.bibx10.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>24]</span>
<span class="ltx_bibblock">
Yiran Ding, Li&nbsp;Lyna Zhang, Chengruidong Zhang, Yuanyuan Xu, Ning Shang, Jiahang
Xu, Fan Yang, and Mao Yang.

</span>
<span class="ltx_bibblock">Longrope: Extending llm context window beyond 2 million tokens, 2024.

</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GZA<sup id="bib.bibx11.4.4.1" class="ltx_sup"><span id="bib.bibx11.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Suriya Gunasekar, Yi&nbsp;Zhang, Jyoti Aneja, Caio César&nbsp;Teodoro Mendes, Allie&nbsp;Del
Giorno, Sivakanth Gopi, Mojan Javaheripi, Gustavo de&nbsp;Rosa Piero&nbsp;Kauffmann,
Olli Saarikivia, Adil Salim, Shital Shah, Harkirat&nbsp;Singh Behl, Xin Wang,
Sébastien Bubeck, Ronen Eldan, Adam&nbsp;Tauman Kalai, Yin&nbsp;Tat Lee, and Yuanzhi
Li.

</span>
<span class="ltx_bibblock">Textbooks are all you need.

</span>
<span class="ltx_bibblock"><span id="bib.bibx11.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.11644</span>, 2023.

</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HBK<sup id="bib.bibx12.4.4.1" class="ltx_sup"><span id="bib.bibx12.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>21]</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric
Tang, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring mathematical problem solving with the MATH dataset, 2021.

</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HBM<sup id="bib.bibx13.4.4.1" class="ltx_sup"><span id="bib.bibx13.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya,
Eliza&nbsp;Rutherford Trevor&nbsp;Cai, Diego de&nbsp;Las&nbsp;Casas, Lisa&nbsp;Anne Hendricks,
Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican,
George van&nbsp;den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen
Simonyan, Erich Elsen, Jack&nbsp;W. Rae, Oriol Vinyals, and Laurent Sifre.

</span>
<span class="ltx_bibblock">Training compute-optimal large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx13.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2203.15556</span>, 2022.

</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JBA<sup id="bib.bibx14.4.4.1" class="ltx_sup"><span id="bib.bibx14.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Mojan Javaheripi, Sébastien Bubeck, Marah Abdin, Jyoti Aneja, Caio César
Teodoro&nbsp;Mendes, Weizhu Chen, Allie Del&nbsp;Giorno, Ronen Eldan, Sivakanth Gopi,
Suriya Gunasekar, Piero Kauffmann, Yin&nbsp;Tat Lee, Yuanzhi Li, Anh Nguyen,
Gustavo&nbsp;de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Michael Santacroce,
Harkirat Singh&nbsp;Behl, Adam Taumann&nbsp;Kalai, Xin Wang, Rachel Ward, Philipp
Witte, Cyril Zhang, and Yi&nbsp;Zhang.

</span>
<span class="ltx_bibblock">Phi-2: The surprising power of small language models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx14.7.1" class="ltx_text ltx_font_italic">Microsoft Research Blog</span>, 2023.

</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JCWZ17]</span>
<span class="ltx_bibblock">
Mandar Joshi, Eunsol Choi, Daniel&nbsp;S. Weld, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Triviaqa: A large scale distantly supervised challenge dataset for
reading comprehension, 2017.

</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JLD<sup id="bib.bibx16.4.4.1" class="ltx_sup"><span id="bib.bibx16.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Jiaming Ji, Mickel Liu, Juntao Dai, Xuehai Pan, Chi Zhang, Ce&nbsp;Bian, Chi Zhang,
Ruiyang Sun, Yizhou Wang, and Yaodong Yang.

</span>
<span class="ltx_bibblock">Beavertails: Towards improved safety alignment of llm via a
human-preference dataset, 2023.

</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JPO<sup id="bib.bibx17.4.4.1" class="ltx_sup"><span id="bib.bibx17.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Di&nbsp;Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter
Szolovits.

</span>
<span class="ltx_bibblock">What disease does this patient have? a large-scale open domain
question answering dataset from medical exams, 2020.

</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JSM<sup id="bib.bibx18.4.4.1" class="ltx_sup"><span id="bib.bibx18.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel,
Guillaume Lample, Lucile Saulnier, Lélio&nbsp;Renard Lavaud, Marie-Anne Lachaux,
Pierre Stock, Teven&nbsp;Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix,
and William&nbsp;El Sayed.

</span>
<span class="ltx_bibblock">Mistral 7b, 2023.

</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JSR<sup id="bib.bibx19.4.4.1" class="ltx_sup"><span id="bib.bibx19.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>24]</span>
<span class="ltx_bibblock">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche
Savary, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Emma&nbsp;Bou
Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample,
Lélio&nbsp;Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock,
Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven&nbsp;Le Scao, Théophile
Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William&nbsp;El Sayed.

</span>
<span class="ltx_bibblock">Mixtral of experts, 2024.

</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KMH<sup id="bib.bibx20.4.4.1" class="ltx_sup"><span id="bib.bibx20.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom&nbsp;B Brown, Benjamin Chess, Rewon
Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.

</span>
<span class="ltx_bibblock">Scaling laws for neural language models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx20.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2001.08361</span>, 2020.

</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LBE<sup id="bib.bibx21.4.4.1" class="ltx_sup"><span id="bib.bibx21.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Allie Del&nbsp;Giorno, Suriya
Gunasekar, and Yin&nbsp;Tat Lee.

</span>
<span class="ltx_bibblock">Textbooks are all you need ii: phi-1.5 technical report.

</span>
<span class="ltx_bibblock"><span id="bib.bibx21.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2309.05463</span>, 2023.

</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[LHE22]</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">Truthfulqa: Measuring how models mimic human falsehoods, 2022.

</span>
</li>
<li id="bib.bibx23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MCKS18]</span>
<span class="ltx_bibblock">
Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">Can a suit of armor conduct electricity? a new dataset for open book
question answering, 2018.

</span>
</li>
<li id="bib.bibx24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MRB<sup id="bib.bibx24.4.4.1" class="ltx_sup"><span id="bib.bibx24.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Niklas Muennighoff, Alexander&nbsp;M Rush, Boaz Barak, Teven&nbsp;Le Scao, Aleksandra
Piktus, Nouamane Tazi, Sampo Pyysalo, Thomas Wolf, and Colin Raffel.

</span>
<span class="ltx_bibblock">Scaling data-constrained language models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx24.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.16264</span>, 2023.

</span>
</li>
<li id="bib.bibx25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[NWD<sup id="bib.bibx25.4.4.1" class="ltx_sup"><span id="bib.bibx25.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>20]</span>
<span class="ltx_bibblock">
Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe
Kiela.

</span>
<span class="ltx_bibblock">Adversarial nli: A new benchmark for natural language understanding,
2020.

</span>
</li>
<li id="bib.bibx26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RHS<sup id="bib.bibx26.4.4.1" class="ltx_sup"><span id="bib.bibx26.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
David Rein, Betty&nbsp;Li Hou, Asa&nbsp;Cooper Stickland, Jackson Petty, Richard&nbsp;Yuanzhe
Pang, Julien Dirani, Julian Michael, and Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">Gpqa: A graduate-level google-proof q&amp;a benchmark, 2023.

</span>
</li>
<li id="bib.bibx27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[RWC<sup id="bib.bibx27.4.4.1" class="ltx_sup"><span id="bib.bibx27.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><span id="bib.bibx27.7.1" class="ltx_text ltx_font_italic">OpenAI blog</span>, 1(8):9, 2019.

</span>
</li>
<li id="bib.bibx28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SLBBC19]</span>
<span class="ltx_bibblock">
Keisuke Sakaguchi, Ronan Le&nbsp;Bras, Chandra Bhagavatula, and Yejin Choi.

</span>
<span class="ltx_bibblock">Winogrande: An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><span id="bib.bibx28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1907.10641</span>, 2019.

</span>
</li>
<li id="bib.bibx29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SRR<sup id="bib.bibx29.4.4.1" class="ltx_sup"><span id="bib.bibx29.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal&nbsp;Md Shoeb, Abubakar
Abid, Adam Fisch, Adam&nbsp;R Brown, Adam Santoro, Aditya Gupta, Adrià
Garriga-Alonso, et&nbsp;al.

</span>
<span class="ltx_bibblock">Beyond the imitation game: Quantifying and extrapolating the
capabilities of language models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx29.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2206.04615</span>, 2022.

</span>
</li>
<li id="bib.bibx30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SSS<sup id="bib.bibx30.4.4.1" class="ltx_sup"><span id="bib.bibx30.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>22]</span>
<span class="ltx_bibblock">
Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi&nbsp;Tay,
Hyung&nbsp;Won Chung, Aakanksha Chowdhery, Quoc&nbsp;V. Le, Ed&nbsp;H. Chi, Denny Zhou, and
Jason Wei.

</span>
<span class="ltx_bibblock">Challenging big-bench tasks and whether chain-of-thought can solve
them, 2022.

</span>
</li>
<li id="bib.bibx31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[THLB19]</span>
<span class="ltx_bibblock">
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant.

</span>
<span class="ltx_bibblock">Commonsenseqa: A question answering challenge targeting commonsense
knowledge, 2019.

</span>
</li>
<li id="bib.bibx32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TLI<sup id="bib.bibx32.4.4.1" class="ltx_sup"><span id="bib.bibx32.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and
Guillaume Lample.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><span id="bib.bibx32.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.13971</span>, 2023.

</span>
</li>
<li id="bib.bibx33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TMH<sup id="bib.bibx33.4.4.1" class="ltx_sup"><span id="bib.bibx33.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>24]</span>
<span class="ltx_bibblock">
Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju,
Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir&nbsp;Sanjay Kale, Juliette
Love, et&nbsp;al.

</span>
<span class="ltx_bibblock">Gemma: Open models based on gemini research and technology, 2024.

</span>
</li>
<li id="bib.bibx34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[VSP<sup id="bib.bibx34.4.4.1" class="ltx_sup"><span id="bib.bibx34.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan&nbsp;N Gomez, Ł&nbsp;ukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx34.7.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>,
volume&nbsp;30, 2017.

</span>
</li>
<li id="bib.bibx35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZCG<sup id="bib.bibx35.4.4.1" class="ltx_sup"><span id="bib.bibx35.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin
Saied, Weizhu Chen, and Nan Duan.

</span>
<span class="ltx_bibblock">Agieval: A human-centric benchmark for evaluating foundation models,
2023.

</span>
</li>
<li id="bib.bibx36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZCS<sup id="bib.bibx36.4.4.1" class="ltx_sup"><span id="bib.bibx36.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>23]</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao
Zhuang, Zi&nbsp;Lin, Zhuohan Li, Dacheng Li, Eric Xing, et&nbsp;al.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><span id="bib.bibx36.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.05685</span>, 2023.

</span>
</li>
<li id="bib.bibx37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZHB<sup id="bib.bibx37.4.4.1" class="ltx_sup"><span id="bib.bibx37.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>19]</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.

</span>
<span class="ltx_bibblock">Hellaswag: Can a machine really finish your sentence?

</span>
<span class="ltx_bibblock">In <span id="bib.bibx37.7.1" class="ltx_text ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association for
Computational Linguistics</span>, pages 4791–4800, 2019.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Example prompt for benchmarks</h2>

<div id="A1.p1" class="ltx_para ltx_noindent">
<svg id="A1.p1.pic1" class="ltx_picture" height="69.19" overflow="visible" version="1.1" width="600"><g transform="translate(0,69.19) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 63.28 C 0 66.54 2.64 69.19 5.91 69.19 L 594.09 69.19 C 597.36 69.19 600 66.54 600 63.28 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 63.28 C 1.97 65.46 3.73 67.22 5.91 67.22 L 594.09 67.22 C 596.27 67.22 598.03 65.46 598.03 63.28 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 12.82 5.91)"><foreignObject width="574.35" height="57.38" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:415.1pt;">
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.7" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.7.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Question:</span></span>
<span id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_p"><span id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Solve for <math id="A1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="A1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="A1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="A1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="A1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">x</annotation></semantics></math>: <math id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2" class="ltx_Math" alttext="(-\frac{1}{3})(-4-3x)=\frac{1}{2}" display="inline"><semantics id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2a"><mrow id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.cmml"><mrow id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.cmml"><mrow id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.cmml"><mo id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1a" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.cmml">−</mo><mfrac id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.cmml"><mn id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.2.cmml">1</mn><mn id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.3" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.3.cmml">3</mn></mfrac></mrow><mo stretchy="false" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.3" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.3" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.3.cmml">​</mo><mrow id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.cmml"><mo stretchy="false" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.cmml">(</mo><mrow id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.cmml"><mrow id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2.cmml"><mo id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2a" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2.cmml">−</mo><mn id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2.2.cmml">4</mn></mrow><mo id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.1" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.1.cmml">−</mo><mrow id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.cmml"><mn id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.1" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.1.cmml">​</mo><mi id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.3" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.3.cmml">x</mi></mrow></mrow><mo stretchy="false" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.3" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.3" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.3.cmml">=</mo><mfrac id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.cmml"><mn id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.2" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.2.cmml">1</mn><mn id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.3" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.3.cmml">2</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2b"><apply id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2"><eq id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.3.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.3"></eq><apply id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2"><times id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.3.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.3"></times><apply id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1"><minus id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.1.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1"></minus><apply id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2"><divide id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.1.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2"></divide><cn type="integer" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.2.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.2">1</cn><cn type="integer" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.3.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.1.1.1.2.3">3</cn></apply></apply><apply id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1"><minus id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.1.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.1"></minus><apply id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2"><minus id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2.1.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2"></minus><cn type="integer" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2.2.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.2.2">4</cn></apply><apply id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3"><times id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.1.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.1"></times><cn type="integer" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.2.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.2">3</cn><ci id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.3.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.2.2.1.1.3.3">𝑥</ci></apply></apply></apply><apply id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4"><divide id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.1.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4"></divide><cn type="integer" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.2.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.2">1</cn><cn type="integer" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.3.cmml" xref="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2.2.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.2c">(-\frac{1}{3})(-4-3x)=\frac{1}{2}</annotation></semantics></math></span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.8" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.8.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Options:</span></span>
<span id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_p"><span id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">A. <math id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="-\frac{5}{6}" display="inline"><semantics id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1a"><mrow id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.cmml"><mo id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1a" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.cmml">−</mo><mfrac id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.cmml"><mn id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.2" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.2.cmml">5</mn><mn id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.3" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.3.cmml">6</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1b"><apply id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.cmml" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1"><minus id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.1.cmml" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1"></minus><apply id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.cmml" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2"><divide id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.1.cmml" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2"></divide><cn type="integer" id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.2.cmml" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.2">5</cn><cn type="integer" id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.3.cmml" xref="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1.1.2.3">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.m1.1c">-\frac{5}{6}</annotation></semantics></math></span></span>
<span id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4" class="ltx_p"><span id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">B. <math id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\frac{7}{6}" display="inline"><semantics id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1a"><mfrac id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1" xref="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.cmml"><mn id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.2" xref="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.2.cmml">7</mn><mn id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.3" xref="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.3.cmml">6</mn></mfrac><annotation-xml encoding="MathML-Content" id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1b"><apply id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.cmml" xref="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1"><divide id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.1.cmml" xref="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1"></divide><cn type="integer" id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.2.cmml" xref="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.2">7</cn><cn type="integer" id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.3.cmml" xref="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.m1.1c">\frac{7}{6}</annotation></semantics></math></span></span>
<span id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5" class="ltx_p"><span id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">C. <math id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\frac{5}{3}" display="inline"><semantics id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1a"><mfrac id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1" xref="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.cmml"><mn id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.2" xref="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.2.cmml">5</mn><mn id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.3" xref="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1b"><apply id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.cmml" xref="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1"><divide id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.1.cmml" xref="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1"></divide><cn type="integer" id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.2.cmml" xref="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.2">5</cn><cn type="integer" id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.3.cmml" xref="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.m1.1c">\frac{5}{3}</annotation></semantics></math></span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">D. <math id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\frac{1}{6}" display="inline"><semantics id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1a"><mfrac id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1" xref="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.cmml"><mn id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.2" xref="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.2.cmml">1</mn><mn id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.3" xref="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.3.cmml">6</mn></mfrac><annotation-xml encoding="MathML-Content" id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1b"><apply id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.cmml" xref="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1"><divide id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.1.cmml" xref="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1"></divide><cn type="integer" id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.2.cmml" xref="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.2">1</cn><cn type="integer" id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.3.cmml" xref="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.1.m1.1c">\frac{1}{6}</annotation></semantics></math></span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.9" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.9.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Answer: A</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.10" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.10.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Question:</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.11" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.11.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Which of the following is the body cavity that contains the pituitary gland?</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.12" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.12.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Options:</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.13" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.13.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">A. Abdominal</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.14" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.14.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">B. Cranial</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.15" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.15.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">C. Pleural</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.16" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.16.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">D. Spinal</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.17" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.17.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Answer: B</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.18" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.18.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Question:</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.19" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.19.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Where was the most famous site of the mystery cults in Greece?</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.20" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.20.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Options:</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.21" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.21.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">A. Ephesus</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.22" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.22.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">B. Corinth</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.23" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.23.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">C. Athens</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.24" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.24.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">D. Eleusis</span></span>
<span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.25" class="ltx_p"><span id="A1.p1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.25.1" class="ltx_text ltx_font_typewriter" style="font-size:80%;">Answer:</span></span>
</span></foreignObject></g></g></svg>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Authors</h2>

<div id="A2.p1" class="ltx_para">
<table id="A2.p1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="A2.p1.1.1" class="ltx_tr">
<td id="A2.p1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.1.1.1.1" class="ltx_p" style="width:142.3pt;">Marah Abdin</span>
</span>
</td>
<td id="A2.p1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.1.2.1.1" class="ltx_p" style="width:142.3pt;">Russell J. Hewett</span>
</span>
</td>
<td id="A2.p1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.1.3.1.1" class="ltx_p" style="width:142.3pt;">Olatunji Ruwase</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.2" class="ltx_tr">
<td id="A2.p1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.2.1.1.1" class="ltx_p" style="width:142.3pt;">Sam Ade Jacobs</span>
</span>
</td>
<td id="A2.p1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.2.2.1.1" class="ltx_p" style="width:142.3pt;">Jamie Huynh</span>
</span>
</td>
<td id="A2.p1.1.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.2.3.1.1" class="ltx_p" style="width:142.3pt;">Olli Saarikivi</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.3" class="ltx_tr">
<td id="A2.p1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.3.1.1.1" class="ltx_p" style="width:142.3pt;">Ammar Ahmad Awan</span>
</span>
</td>
<td id="A2.p1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.3.2.1.1" class="ltx_p" style="width:142.3pt;">Mojan Javaheripi</span>
</span>
</td>
<td id="A2.p1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.3.3.1.1" class="ltx_p" style="width:142.3pt;">Amin Saied</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.4" class="ltx_tr">
<td id="A2.p1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.4.1.1.1" class="ltx_p" style="width:142.3pt;">Jyoti Aneja</span>
</span>
</td>
<td id="A2.p1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.4.2.1.1" class="ltx_p" style="width:142.3pt;">Xin Jin</span>
</span>
</td>
<td id="A2.p1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.4.3.1.1" class="ltx_p" style="width:142.3pt;">Adil Salim</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.5" class="ltx_tr">
<td id="A2.p1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.5.1.1.1" class="ltx_p" style="width:142.3pt;">Ahmed Awadallah</span>
</span>
</td>
<td id="A2.p1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.5.2.1.1" class="ltx_p" style="width:142.3pt;">Piero Kauffmann</span>
</span>
</td>
<td id="A2.p1.1.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.5.3.1.1" class="ltx_p" style="width:142.3pt;">Michael Santacroce</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.6" class="ltx_tr">
<td id="A2.p1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.6.1.1.1" class="ltx_p" style="width:142.3pt;">Hany Awadalla</span>
</span>
</td>
<td id="A2.p1.1.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.6.2.1.1" class="ltx_p" style="width:142.3pt;">Nikos Karampatziakis</span>
</span>
</td>
<td id="A2.p1.1.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.6.3.1.1" class="ltx_p" style="width:142.3pt;">Shital Shah</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.7" class="ltx_tr">
<td id="A2.p1.1.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.7.1.1.1" class="ltx_p" style="width:142.3pt;">Nguyen Bach</span>
</span>
</td>
<td id="A2.p1.1.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.7.2.1.1" class="ltx_p" style="width:142.3pt;">Dongwoo Kim</span>
</span>
</td>
<td id="A2.p1.1.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.7.3.1.1" class="ltx_p" style="width:142.3pt;">Ning Shang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.8" class="ltx_tr">
<td id="A2.p1.1.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.8.1.1.1" class="ltx_p" style="width:142.3pt;">Amit Bahree</span>
</span>
</td>
<td id="A2.p1.1.8.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.8.2.1.1" class="ltx_p" style="width:142.3pt;">Mahmoud Khademi</span>
</span>
</td>
<td id="A2.p1.1.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.8.3.1.1" class="ltx_p" style="width:142.3pt;">Hiteshi Sharma</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.9" class="ltx_tr">
<td id="A2.p1.1.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.9.1.1.1" class="ltx_p" style="width:142.3pt;">Arash Bakhtiari</span>
</span>
</td>
<td id="A2.p1.1.9.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.9.2.1.1" class="ltx_p" style="width:142.3pt;">Lev Kurilenko</span>
</span>
</td>
<td id="A2.p1.1.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.9.3.1.1" class="ltx_p" style="width:142.3pt;">Xia Song</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.10" class="ltx_tr">
<td id="A2.p1.1.10.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.10.1.1.1" class="ltx_p" style="width:142.3pt;">Harkirat Behl</span>
</span>
</td>
<td id="A2.p1.1.10.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.10.2.1.1" class="ltx_p" style="width:142.3pt;">James R. Lee</span>
</span>
</td>
<td id="A2.p1.1.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.10.3.1.1" class="ltx_p" style="width:142.3pt;">Masahiro Tanaka</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.11" class="ltx_tr">
<td id="A2.p1.1.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.11.1.1.1" class="ltx_p" style="width:142.3pt;">Alon Benhaim</span>
</span>
</td>
<td id="A2.p1.1.11.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.11.2.1.1" class="ltx_p" style="width:142.3pt;">Yin Tat Lee</span>
</span>
</td>
<td id="A2.p1.1.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.11.3.1.1" class="ltx_p" style="width:142.3pt;">Xin Wang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.12" class="ltx_tr">
<td id="A2.p1.1.12.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.12.1.1.1" class="ltx_p" style="width:142.3pt;">Misha Bilenko</span>
</span>
</td>
<td id="A2.p1.1.12.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.12.2.1.1" class="ltx_p" style="width:142.3pt;">Yuanzhi Li</span>
</span>
</td>
<td id="A2.p1.1.12.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.12.3.1.1" class="ltx_p" style="width:142.3pt;">Rachel Ward</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.13" class="ltx_tr">
<td id="A2.p1.1.13.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.13.1.1.1" class="ltx_p" style="width:142.3pt;">Johan Bjorck</span>
</span>
</td>
<td id="A2.p1.1.13.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.13.2.1.1" class="ltx_p" style="width:142.3pt;">Chen Liang</span>
</span>
</td>
<td id="A2.p1.1.13.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.13.3.1.1" class="ltx_p" style="width:142.3pt;">Guanhua Wang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.14" class="ltx_tr">
<td id="A2.p1.1.14.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.14.1.1.1" class="ltx_p" style="width:142.3pt;">Sébastien Bubeck</span>
</span>
</td>
<td id="A2.p1.1.14.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.14.2.1.1" class="ltx_p" style="width:142.3pt;">Weishung Liu</span>
</span>
</td>
<td id="A2.p1.1.14.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.14.3.1.1" class="ltx_p" style="width:142.3pt;">Philipp Witte</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.15" class="ltx_tr">
<td id="A2.p1.1.15.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.15.1.1.1" class="ltx_p" style="width:142.3pt;">Martin Cai</span>
</span>
</td>
<td id="A2.p1.1.15.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.15.2.1.1" class="ltx_p" style="width:142.3pt;">Eric Lin</span>
</span>
</td>
<td id="A2.p1.1.15.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.15.3.1.1" class="ltx_p" style="width:142.3pt;">Michael Wyatt</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.16" class="ltx_tr">
<td id="A2.p1.1.16.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.16.1.1.1" class="ltx_p" style="width:142.3pt;">Caio César Teodoro Mendes</span>
</span>
</td>
<td id="A2.p1.1.16.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.16.2.1.1" class="ltx_p" style="width:142.3pt;">Zeqi Lin</span>
</span>
</td>
<td id="A2.p1.1.16.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.16.3.1.1" class="ltx_p" style="width:142.3pt;">Jiahang Xu</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.17" class="ltx_tr">
<td id="A2.p1.1.17.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.17.1.1.1" class="ltx_p" style="width:142.3pt;">Weizhu Chen</span>
</span>
</td>
<td id="A2.p1.1.17.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.17.2.1.1" class="ltx_p" style="width:142.3pt;">Piyush Madan</span>
</span>
</td>
<td id="A2.p1.1.17.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.17.3.1.1" class="ltx_p" style="width:142.3pt;">Can Xu</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.18" class="ltx_tr">
<td id="A2.p1.1.18.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.18.1.1.1" class="ltx_p" style="width:142.3pt;">Vishrav Chaudhary</span>
</span>
</td>
<td id="A2.p1.1.18.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.18.2.1.1" class="ltx_p" style="width:142.3pt;">Arindam Mitra</span>
</span>
</td>
<td id="A2.p1.1.18.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.18.3.1.1" class="ltx_p" style="width:142.3pt;">Sonali Yadav</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.19" class="ltx_tr">
<td id="A2.p1.1.19.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.19.1.1.1" class="ltx_p" style="width:142.3pt;">Parul Chopra</span>
</span>
</td>
<td id="A2.p1.1.19.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.19.2.1.1" class="ltx_p" style="width:142.3pt;">Hardik Modi</span>
</span>
</td>
<td id="A2.p1.1.19.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.19.3.1.1" class="ltx_p" style="width:142.3pt;">Fan Yang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.20" class="ltx_tr">
<td id="A2.p1.1.20.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.20.1.1.1" class="ltx_p" style="width:142.3pt;">Allie Del Giorno</span>
</span>
</td>
<td id="A2.p1.1.20.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.20.2.1.1" class="ltx_p" style="width:142.3pt;">Brandon Norick</span>
</span>
</td>
<td id="A2.p1.1.20.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.20.3.1.1" class="ltx_p" style="width:142.3pt;">Ziyi Yang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.21" class="ltx_tr">
<td id="A2.p1.1.21.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.21.1.1.1" class="ltx_p" style="width:142.3pt;">Gustavo de Rosa</span>
</span>
</td>
<td id="A2.p1.1.21.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.21.2.1.1" class="ltx_p" style="width:142.3pt;">Anh Nguyen</span>
</span>
</td>
<td id="A2.p1.1.21.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.21.3.1.1" class="ltx_p" style="width:142.3pt;">Donghan Yu</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.22" class="ltx_tr">
<td id="A2.p1.1.22.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.22.1.1.1" class="ltx_p" style="width:142.3pt;">Matthew Dixon</span>
</span>
</td>
<td id="A2.p1.1.22.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.22.2.1.1" class="ltx_p" style="width:142.3pt;">Barun Patra</span>
</span>
</td>
<td id="A2.p1.1.22.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.22.3.1.1" class="ltx_p" style="width:142.3pt;">Chengruidong Zhang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.23" class="ltx_tr">
<td id="A2.p1.1.23.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.23.1.1.1" class="ltx_p" style="width:142.3pt;">Ronen Eldan</span>
</span>
</td>
<td id="A2.p1.1.23.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.23.2.1.1" class="ltx_p" style="width:142.3pt;">Daniel Perez-Becker</span>
</span>
</td>
<td id="A2.p1.1.23.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.23.3.1.1" class="ltx_p" style="width:142.3pt;">Cyril Zhang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.24" class="ltx_tr">
<td id="A2.p1.1.24.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.24.1.1.1" class="ltx_p" style="width:142.3pt;">Dan Iter</span>
</span>
</td>
<td id="A2.p1.1.24.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.24.2.1.1" class="ltx_p" style="width:142.3pt;">Heyang Qin</span>
</span>
</td>
<td id="A2.p1.1.24.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.24.3.1.1" class="ltx_p" style="width:142.3pt;">Jianwen Zhang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.25" class="ltx_tr">
<td id="A2.p1.1.25.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.25.1.1.1" class="ltx_p" style="width:142.3pt;">Amit Garg</span>
</span>
</td>
<td id="A2.p1.1.25.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.25.2.1.1" class="ltx_p" style="width:142.3pt;">Thomas Portet</span>
</span>
</td>
<td id="A2.p1.1.25.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.25.3.1.1" class="ltx_p" style="width:142.3pt;">Li Lyna Zhang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.26" class="ltx_tr">
<td id="A2.p1.1.26.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.26.1.1.1" class="ltx_p" style="width:142.3pt;">Abhishek Goswami</span>
</span>
</td>
<td id="A2.p1.1.26.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.26.2.1.1" class="ltx_p" style="width:142.3pt;">Reid Pryzant</span>
</span>
</td>
<td id="A2.p1.1.26.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.26.3.1.1" class="ltx_p" style="width:142.3pt;">Yi Zhang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.27" class="ltx_tr">
<td id="A2.p1.1.27.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.27.1.1.1" class="ltx_p" style="width:142.3pt;">Suriya Gunasekar</span>
</span>
</td>
<td id="A2.p1.1.27.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.27.2.1.1" class="ltx_p" style="width:142.3pt;">Sambuddha Roy</span>
</span>
</td>
<td id="A2.p1.1.27.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.27.3.1.1" class="ltx_p" style="width:142.3pt;">Yue Zhang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.28" class="ltx_tr">
<td id="A2.p1.1.28.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.28.1.1.1" class="ltx_p" style="width:142.3pt;">Emman Haider</span>
</span>
</td>
<td id="A2.p1.1.28.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.28.2.1.1" class="ltx_p" style="width:142.3pt;">Marko Radmilac</span>
</span>
</td>
<td id="A2.p1.1.28.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.28.3.1.1" class="ltx_p" style="width:142.3pt;">Yunan Zhang</span>
</span>
</td>
</tr>
<tr id="A2.p1.1.29" class="ltx_tr">
<td id="A2.p1.1.29.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.29.1.1.1" class="ltx_p" style="width:142.3pt;">Junheng Hao</span>
</span>
</td>
<td id="A2.p1.1.29.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.29.2.1.1" class="ltx_p" style="width:142.3pt;">Corby Rosset</span>
</span>
</td>
<td id="A2.p1.1.29.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A2.p1.1.29.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.p1.1.29.3.1.1" class="ltx_p" style="width:142.3pt;">Xiren Zhou</span>
</span>
</td>
</tr>
</tbody></table>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2404.14218" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2404.14219" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2404.14219">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.14219" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2404.14220" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 18:06:42 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>