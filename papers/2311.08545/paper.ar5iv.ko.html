<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2311.08545] Efficient Continual Pre-training for Building Domain Specific Large Language Models</title><meta property="og:description" content="Large language models (LLMs) have demonstrated remarkable open-domain capabilities. Traditionally, LLMs tailored for a domain are trained from scratch to excel at handling domain-specific tasks. In this work, we explor…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Efficient Continual Pre-training for Building Domain Specific Large Language Models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Efficient Continual Pre-training for Building Domain Specific Large Language Models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2311.08545">

<!--Generated on Tue Feb 27 19:10:49 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Efficient Continual Pre-training for Building Domain Specific Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yong Xie<sup id="id3.3.id1" class="ltx_sup"><span id="id3.3.id1.1" class="ltx_text ltx_font_italic">‡</span></sup>
<br class="ltx_break">UIUC 
<br class="ltx_break"><span id="id4.4.id2" class="ltx_text ltx_font_typewriter">yongxie2@illinois.edu</span>
&amp;Karan Aggarwal<sup id="id5.5.id3" class="ltx_sup"><span id="id5.5.id3.1" class="ltx_text ltx_font_italic">‡</span></sup> 
<br class="ltx_break">Amazon 
<br class="ltx_break"><span id="id6.6.id4" class="ltx_text ltx_font_typewriter">kagg@amazon.com</span>
&amp;Aitzaz Ahmad 
<br class="ltx_break">Amazon 
<br class="ltx_break"><span id="id7.7.id5" class="ltx_text ltx_font_typewriter">aitzaza@amazon.com</span>
</span><span class="ltx_author_notes">This work was done during Yong’s internship at Amazon</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id8.id1">대규모 언어 모델(LLM)은 주목할 만한 오픈 도메인 기능을 입증했다. 전통적으로 도메인에 맞게 조정된 LLM은 도메인별 작업을 처리하는 데 있어 처음부터 탁월하도록 훈련됩니다. 이 연구에서는 영역별 LLM을 개발하기 위한 수단으로 지속적인 사전 훈련의 대안 전략을 탐색한다. 금융 도메인에서 도메인 적응형 연속 사전 훈련을 통해 개발된 <span class="ltx_text ltx_font_italic" id="id8.id1.1">FinPythia-6.9B</span>을 소개한다. 지속적으로 사전 훈련된 핀피티아는 원래의 기초 모델보다 재정 과제에 대한 일관된 개선을 보여준다. 지속적인 사전 교육을 위한 단순하지만 효과적인 데이터 선택 전략을 추가로 탐구한다. 우리의 데이터 선택 전략은 오픈 도메인 표준 작업에서 성능 저하 없이 말뭉치 크기와 비용의 10%만으로 바닐라 연속 사전 훈련의 성능을 능가한다. 본 연구는 비용 효율적인 방식으로 도메인별 LLM을 처음부터 구축하는 대안 솔루션을 제안한다.</p>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">‡</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‡</sup><span class="ltx_note_type">footnotetext: </span>These authors contributed equally to this work</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">LLM(Large Language Models)은 자연어(Natural Language)에 대한 깊은 이해를 보여주며, <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite> 태스크의 배열에서 성능을 향상시켰다. 개방형 웹 데이터를 사용하는 것은 광범위한 기능을 가진 범용 LLM을 만드는 데 도움이 되었다. 그러나 범용 LLM은 "전문가"가 아니다; 예를 들어, LLM은 좋은 뉴스 기사를 쓸 수 있지만 전문 법률 문서를 작성하는 것은 힘들 것이다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">전문가 또는 도메인별 LLM을 만들기 위해서는 도메인 데이터에 대해 훈련해야 한다. 도메인별 LLM을 구축하기 위한 접근법은 처음부터 도메인별 LLM을 훈련하거나 도메인 데이터와 함께 기존 LLM을 지속적으로 사전 훈련하는 두 가지 범주로 분류할 수 있다. 대부분의 연구자들은 처음부터 영역별 LLM을 구축하는 첫 번째 접근법을 취했다. 의료 영역의 경우 Med-PaLM 계열 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>, <a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite>, 과학 논문의 경우 Galactica <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>, 금융의 경우 BloombergGPT <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>가 눈에 띈다. 훨씬 저렴한 대안임에도 불구하고 도메인 적응형 연속 사전 훈련을 사용하여 도메인별 LLM을 구축하는 데 거의 관심을 기울이지 않았다. 특히, PMC-LLaMA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>, 의학 논문에서 LLaMA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite>의 지속적인 사전 훈련을 통해 의학 LLM을 훈련하였다. 지속적인 사전 훈련은 진화하는 환경에서 최신 지식으로 LLM을 업데이트하는 데에도 사용할 수 있다.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.1">이 연구에서 우리는 다음과 같은 것을 탐구한다: 1) 도메인-적응적 연속 사전 훈련이 도메인-특정 LLMs를 구축하는 데 도움이 되는가? 2) 보다 효과적인 도메인 적응형 연속 사전 훈련을 위해 데이터 선택 전략을 채택할 수 있는가? 그리고 3) 도메인 적응형 지속적인 사전훈련이 LLM의 오픈 도메인 역량에 부정적인 영향을 미치는가? Pythia<cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>]</cite> 위에 구축된 지속적으로 사전 훈련된 모델 FinPythia를 훈련하여 이러한 질문에 금융 영역의 제약에서 답한다.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1">우리는 첫 번째 질문에 대한 대답으로 피티아가 훈련받은 것의 8% 크기의 도메인 데이터에 대한 지속적인 사전 훈련 후 재무 벤치마크 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>에 대한 증가를 보고한다. 우리는 또한 질적 분석 동안 핀피티아의 최신 금융 영역 지식 습득의 증거를 관찰한다. 두 번째 질문에 답하기 위해 두 가지 간단한 데이터 선택 기술인 작업 인식 <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">Efficient Task-Similar Domain-Adaptive Continual Pre-training</em> (ETS-DACP) 및 <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">Efficient Task-Agnostic Domain-Adaptive Continual Pre-training</em> (ETA-DACP)을 제안한다. 이러한 방법은 선택된 도메인 데이터의 10% 또는 피티아의 훈련 코퍼스의 0.8%만으로 도메인 적응형 연속 사전 훈련의 성능을 능가한다. 우리는 데이터 선택을 위해 유사성, 복잡성 및 토큰 유형 엔트로피의 세 가지 메트릭을 사용한다. 유사성은 시드로서 태스크 데이터를 필요로 하지만, 후자의 두 메트릭은 태스크-불가지론적이다. 세 번째 질문에 답하기 위해 MMLU 및 TruthfulQA와 같은 4개의 개방형 도메인 표준 작업에 대해 이러한 사전 훈련된 모델을 지속적으로 벤치마킹한다. 우리는 LLM이 도메인에 적응하면서 일반적인 기능을 유지한다는 것을 나타내는 유의미한 성능 변화를 관찰하지 못한다.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p" id="S1.p5.1">이 논문의 주요 기여는 세 가지이다. 먼저, 금융 데이터 세트에서 가져온 160억 개의 단어로 구성된 대규모 금융 코퍼스를 선별한다. 둘째, 지속적인 사전 훈련을 통해 도메인별 LLM을 구축하고, 더 작은 언어 모델 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite>에서 얻은 결과를 검증하고 확장하는 가능성을 보여준다. 이 발견은 처음부터 값비싼 사전 훈련의 대안으로 더 저렴한 비용으로 도메인별 LLM을 구축하는 통찰력을 제공한다. 본 연구의 결과는 지속적인 사전학습이 기존 기초모델과 동일한 오픈도메인 성능을 유지함을 보여준다. 마지막으로, 바닐라 연속 사전 훈련에 대한 보다 효율적인 접근 방법으로 두 가지 효율적인 도메인 적응형 연속 사전 훈련 방법을 제안한다. 우리의 새로운 접근법은 도메인 적응형 연속 사전 훈련 비용의 일부를 사용하여 더 나은 성능을 달성할 수 있는 데이터 선택 전략을 전개한다.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.1">이 섹션에서는 연속 사전 훈련에 사용된 재정 코퍼스, 도메인 적응형 연속 사전 훈련, 태스크 적응형 연속 사전 훈련 및 제안된 태스크 인식 도메인 적응형 연속 사전 훈련의 큐레이션에 대해 설명한다.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Financial Corpus Curation</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p1.1">데이터 소스에 대한 평가에서 우리는 공공 가용성, 라이선스 및 규모의 세 가지 차원을 고려한다. 우리는 금융 코퍼스에 두 가지 데이터 소스를 사용한다: 금융 뉴스 공통 크롤링과 증권거래위원회 파일이다. 금융 뉴스 커먼크롤은 공공 커먼크롤 데이터에서 금융 뉴스를 걸러냄으로써 선별된다. 피티아 제품군 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>]</cite>의 중복 제거 절차를 따라 중복 학습 데이터를 제거한다. <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>, <a class="ltx_ref" href="#bib.bib14" title="">14</a>]</cite>의 성능을 해치는 중복에 대한 상반된 증거가 있지만, 학습 데이터에서 중복의 이점에 대한 증거는 없다. 따라서 보다 효율적인 학습을 위해 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>]</cite>에 이어 de-duplication을 사용한다. 이 두 소스를 사용하여 239억 토큰(165억 단어)의 결합된 데이터 세트를 만듭니다. 큐레이션 단계에 대한 자세한 내용은 부록 <a class="ltx_ref" href="#A5" title="Appendix E Financial Dataset Curation ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">E</span></a>에서 확인할 수 있다.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2311.08545/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="184" height="147" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">그림 1</span>:</span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">Labeled task data, task-similar domain data and domain corpus in a manifold space. </span></figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Domain-adaptive Continual Pre-training (DACP)</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p1.1">일반적으로 도메인별 LLM은 방대한 양의 도메인 데이터를 사용하여 모델을 처음부터 학습하여 구축됩니다. 이 절차는 비용이 많이 들고 훨씬 더 많은 양의 도메인 데이터가 필요하며, 이는 매우 전문화되고 기밀 데이터가 있는 금융과 같은 더 낮은 데이터 도메인에서는 실현 가능하지 않다는 두 가지 단점이 있다. 도메인 적응형 연속 사전 훈련(Domain-adaptive Continual Pre-training, DACP)은 처음부터 구축하는 간단한 대안이며, 도메인별 레이블이 지정되지 않은 데이터의 대규모 코퍼스에서 범용 LLM을 지속적으로 사전 훈련한다. 도메인 적응 연속 사전 훈련은 도메인 내 분포 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib32" title="">32</a>, <a class="ltx_ref" href="#bib.bib21" title="">21</a>]</cite>에 더 잘 맞도록 언어 모델을 적응시키는 능력을 보여주었다. 그들은 또한 모델을 처음부터 훈련하는 대신 새로운 데이터가 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib11" title="">11</a>, <a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>로 나타나므로 대규모 언어 모델이 새로운 지식을 습득할 수 있도록 한다. 우리는 DACP의 이점을 벤치마킹하기 위해 실험에서 DACP를 사용한다.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Task-Adaptive Continual Pre-training (TACP)</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p1.1">TACP(Task-adaptive Continual Pre-training)는 목표된 태스크에 대한 성능 향상을 목표로 하는 지속적인 사전 훈련을 의미한다. TACP는 태스크 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite>에서 레이블이 지정된 데이터와 레이블이 지정되지 않은 데이터에 대해 언어 모델을 사전 훈련하여 태스크에 대한 개선 사항을 보여줌으로써 BERT와 같은 더 작은 언어 모델의 맥락에서 연구되었다. 작업 데이터는 일반적으로 상당히 제한적이지만 TACP는 BERT와 같은 더 작은 언어 모델에 상당한 영향을 미친다. 우리는 네 가지 재무 평가 과제에 대해 TACP를 벤치마킹한다.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Towards an Efficient Domain-adaptive Continual Pre-training</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS4.p1.1">TACP의 주요 한계는 훈련을 위해 레이블이 지정되지 않은 작업 데이터를 단독으로 사용하기 때문에 기초 LLM 대신 작업별 LLM을 구성하는 데 중점을 둔다. DACP는 훨씬 더 큰 도메인 코퍼스를 사용하지만 엄청나게 비싸다. 이러한 한계를 해결하기 위해 <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.1">Efficient Task-Similar Domain-Adaptive Continual Pre-training</span> (ETS-DACP) 및 <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.2">Efficient Task-Agnostic Domain-Adaptive Continual Pre-training</span> (ETA-DACP) 두 가지 접근 방식을 제안한다. ETS-DACP는 이러한 작업의 중요성을 강조하기 위해 DACP를 맞춤화하여 일련의 작업에 대한 기반 LLM을 구축하는 것을 목표로 하지만, ETA-DACP는 보다 일반적이며 지속적인 사전 훈련을 위해 도메인 코퍼스에서 가장 유익한 샘플을 선택한다.</p>
</div>
<section id="S2.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Formulation</h5>

<div id="S2.SS4.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS0.Px1.p1.7">우리는 먼저 문제를 공식화한다. 그림 <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2.1 Financial Corpus Curation ‣ 2 Methodology ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>에서 녹색 영역으로 표시된 레이블이 지정되지 않은 도메인 사전 훈련 말뭉치 <math alttext="\pazocal{U}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS4.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS4.SSS0.Px1.p1.1.m1.1.1" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.1.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS4.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.1.m1.1.1">U</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.1.m1.1c">\pazocal{U}</annotation></semantics></math>가 주어진다. 다음으로 레이블이 지정되지 않은 태스크 코퍼스의 부재 또는 존재라는 두 가지 시나리오를 취할 수 있습니다. 단일 또는 그룹의 태스크일 수 있는 태스크 코퍼스의 존재의 첫 번째 시나리오인 <math alttext="\pazocal{T}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.2.m2.1"><semantics id="S2.SS4.SSS0.Px1.p1.2.m2.1a"><mi id="S2.SS4.SSS0.Px1.p1.2.m2.1.1" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.2.m2.1b"><ci id="S2.SS4.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.2.m2.1.1">T</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.2.m2.1c">\pazocal{T}</annotation></semantics></math>는 그림 <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2.1 Financial Corpus Curation ‣ 2 Methodology ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>에서 빨간색 영역으로 묘사되어 있다. 전형적으로, 태스크 코퍼스는 도메인 코퍼스, <math alttext="\pazocal{T}\subset\pazocal{U}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.3.m3.1"><semantics id="S2.SS4.SSS0.Px1.p1.3.m3.1a"><mrow id="S2.SS4.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS4.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.3.m3.1.1.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.3.m3.1.1.2.cmml">T</mi><mo id="S2.SS4.SSS0.Px1.p1.3.m3.1.1.1" xref="S2.SS4.SSS0.Px1.p1.3.m3.1.1.1.cmml">⊂</mo><mi id="S2.SS4.SSS0.Px1.p1.3.m3.1.1.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.3.m3.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.3.m3.1b"><apply id="S2.SS4.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.3.m3.1.1"><subset id="S2.SS4.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.3.m3.1.1.1"></subset><ci id="S2.SS4.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.3.m3.1.1.2">T</ci><ci id="S2.SS4.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.3.m3.1.1.3">U</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.3.m3.1c">\pazocal{T}\subset\pazocal{U}</annotation></semantics></math>, <math alttext="|\pazocal{U}|&gt;&gt;|\pazocal{T}|" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.4.m4.2"><semantics id="S2.SS4.SSS0.Px1.p1.4.m4.2a"><mrow id="S2.SS4.SSS0.Px1.p1.4.m4.2.3" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.cmml"><mrow id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.2" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.1.cmml"><mo id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.2.1" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.1.1.cmml">|</mo><mi id="S2.SS4.SSS0.Px1.p1.4.m4.1.1" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.4.m4.1.1.cmml">U</mi><mo id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.2.2" rspace="0.111em" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.1.1.cmml">|</mo></mrow><mo id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.1" rspace="0.278em" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.1.cmml">&gt;&gt;</mo><mrow id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.2" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.1.cmml"><mo id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.2.1" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.1.1.cmml">|</mo><mi id="S2.SS4.SSS0.Px1.p1.4.m4.2.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.2.cmml">T</mi><mo id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.2.2" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.1.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.4.m4.2b"><apply id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.cmml" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3"><csymbol cd="latexml" id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.1">much-greater-than</csymbol><apply id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.1.cmml" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.2"><abs id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.2.2.1"></abs><ci id="S2.SS4.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.4.m4.1.1">U</ci></apply><apply id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.2"><abs id="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.3.3.2.1"></abs><ci id="S2.SS4.SSS0.Px1.p1.4.m4.2.2.cmml" xref="S2.SS4.SSS0.Px1.p1.4.m4.2.2">T</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.4.m4.2c">|\pazocal{U}|&gt;&gt;|\pazocal{T}|</annotation></semantics></math>의 서브세트이다. 데이터 선택의 목표는 LLM 모델을 사전 훈련하는 데 가장 도움이 되는 하위 집합 <math alttext="\pazocal{D}\subset\pazocal{U}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.5.m5.1"><semantics id="S2.SS4.SSS0.Px1.p1.5.m5.1a"><mrow id="S2.SS4.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS4.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.5.m5.1.1.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.5.m5.1.1.2.cmml">D</mi><mo id="S2.SS4.SSS0.Px1.p1.5.m5.1.1.1" xref="S2.SS4.SSS0.Px1.p1.5.m5.1.1.1.cmml">⊂</mo><mi id="S2.SS4.SSS0.Px1.p1.5.m5.1.1.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.5.m5.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.5.m5.1b"><apply id="S2.SS4.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.5.m5.1.1"><subset id="S2.SS4.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.5.m5.1.1.1"></subset><ci id="S2.SS4.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.5.m5.1.1.2">D</ci><ci id="S2.SS4.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.5.m5.1.1.3">U</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.5.m5.1c">\pazocal{D}\subset\pazocal{U}</annotation></semantics></math>를 선택하는 것이다. 우리는 또한 선택된 도메인 코퍼스 서브세트가 전형적인 경우와 같이 태스크 코퍼스, <math alttext="|\pazocal{D}|&gt;&gt;|\pazocal{T}|" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.6.m6.2"><semantics id="S2.SS4.SSS0.Px1.p1.6.m6.2a"><mrow id="S2.SS4.SSS0.Px1.p1.6.m6.2.3" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.cmml"><mrow id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.2" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.1.cmml"><mo id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.2.1" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.1.1.cmml">|</mo><mi id="S2.SS4.SSS0.Px1.p1.6.m6.1.1" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.6.m6.1.1.cmml">D</mi><mo id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.2.2" rspace="0.111em" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.1.1.cmml">|</mo></mrow><mo id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.1" rspace="0.278em" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.1.cmml">&gt;&gt;</mo><mrow id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.2" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.1.cmml"><mo id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.2.1" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.1.1.cmml">|</mo><mi id="S2.SS4.SSS0.Px1.p1.6.m6.2.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.2.cmml">T</mi><mo id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.2.2" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.1.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.6.m6.2b"><apply id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.cmml" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3"><csymbol cd="latexml" id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.1">much-greater-than</csymbol><apply id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.1.cmml" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.2"><abs id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.2.2.1"></abs><ci id="S2.SS4.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.6.m6.1.1">D</ci></apply><apply id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.2"><abs id="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.3.3.2.1"></abs><ci id="S2.SS4.SSS0.Px1.p1.6.m6.2.2.cmml" xref="S2.SS4.SSS0.Px1.p1.6.m6.2.2">T</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.6.m6.2c">|\pazocal{D}|&gt;&gt;|\pazocal{T}|</annotation></semantics></math>보다 훨씬 크다고 가정한다. 데이터 선택 문제는 최적 <math alttext="\pazocal{D}^{*}\subset U" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.7.m7.1"><semantics id="S2.SS4.SSS0.Px1.p1.7.m7.1a"><mrow id="S2.SS4.SSS0.Px1.p1.7.m7.1.1" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.cmml"><msup id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.cmml"><mi id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.2.cmml">D</mi><mo id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.3" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.3.cmml">∗</mo></msup><mo id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.1" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.1.cmml">⊂</mo><mi id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.7.m7.1b"><apply id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1"><subset id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.1"></subset><apply id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.1.cmml" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2">superscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.2.cmml" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.2">D</ci><times id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.3.cmml" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.2.3"></times></apply><ci id="S2.SS4.SSS0.Px1.p1.7.m7.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.7.m7.1.1.3">U</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.7.m7.1c">\pazocal{D}^{*}\subset U</annotation></semantics></math>의 선택으로 형식적으로 정의될 수 있다:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\pazocal{D}^{*}=\underset{\pazocal{D}^{*}\subset\pazocal{U}}{\mathrm{argmin}}~{}\mathbb{E}_{x\in\pazocal{T}}[\pazocal{L}_{t}(y|f(\theta^{*};x))]" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><msup id="S2.E1.m1.2.2.3" xref="S2.E1.m1.2.2.3.cmml"><mi mathvariant="normal" id="S2.E1.m1.2.2.3.2" xref="S2.E1.m1.2.2.3.2.cmml">D</mi><mo id="S2.E1.m1.2.2.3.3" xref="S2.E1.m1.2.2.3.3.cmml">∗</mo></msup><mo id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml">=</mo><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.cmml"><munder accentunder="true" id="S2.E1.m1.2.2.1.3" xref="S2.E1.m1.2.2.1.3.cmml"><mi id="S2.E1.m1.2.2.1.3.2" xref="S2.E1.m1.2.2.1.3.2.cmml">argmin</mi><mrow id="S2.E1.m1.2.2.1.3.1" xref="S2.E1.m1.2.2.1.3.1.cmml"><msup id="S2.E1.m1.2.2.1.3.1.2" xref="S2.E1.m1.2.2.1.3.1.2.cmml"><mi mathvariant="normal" id="S2.E1.m1.2.2.1.3.1.2.2" xref="S2.E1.m1.2.2.1.3.1.2.2.cmml">D</mi><mo id="S2.E1.m1.2.2.1.3.1.2.3" xref="S2.E1.m1.2.2.1.3.1.2.3.cmml">∗</mo></msup><mo id="S2.E1.m1.2.2.1.3.1.1" xref="S2.E1.m1.2.2.1.3.1.1.cmml">⊂</mo><mi mathvariant="normal" id="S2.E1.m1.2.2.1.3.1.3" xref="S2.E1.m1.2.2.1.3.1.3.cmml">U</mi></mrow></munder><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.2.cmml">​</mo><msub id="S2.E1.m1.2.2.1.4" xref="S2.E1.m1.2.2.1.4.cmml"><mi id="S2.E1.m1.2.2.1.4.2" xref="S2.E1.m1.2.2.1.4.2.cmml">𝔼</mi><mrow id="S2.E1.m1.2.2.1.4.3" xref="S2.E1.m1.2.2.1.4.3.cmml"><mi mathvariant="normal" id="S2.E1.m1.2.2.1.4.3.2" xref="S2.E1.m1.2.2.1.4.3.2.cmml">x</mi><mo id="S2.E1.m1.2.2.1.4.3.1" xref="S2.E1.m1.2.2.1.4.3.1.cmml">∈</mo><mi mathvariant="normal" id="S2.E1.m1.2.2.1.4.3.3" xref="S2.E1.m1.2.2.1.4.3.3.cmml">T</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.2a" xref="S2.E1.m1.2.2.1.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1" xref="S2.E1.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.2" xref="S2.E1.m1.2.2.1.1.2.1.cmml">[</mo><mrow id="S2.E1.m1.2.2.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.cmml"><msub id="S2.E1.m1.2.2.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S2.E1.m1.2.2.1.1.1.1.3.2" xref="S2.E1.m1.2.2.1.1.1.1.3.2.cmml">L</mi><mi mathvariant="normal" id="S2.E1.m1.2.2.1.1.1.1.3.3" xref="S2.E1.m1.2.2.1.1.1.1.3.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.3.cmml">y</mi><mo fence="false" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msup id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">θ</mi><mo id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">∗</mo></msup><mo id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">;</mo><mi mathvariant="normal" id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.4" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.3" xref="S2.E1.m1.2.2.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2"><eq id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"></eq><apply id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.3.1.cmml" xref="S2.E1.m1.2.2.3">superscript</csymbol><ci id="S2.E1.m1.2.2.3.2.cmml" xref="S2.E1.m1.2.2.3.2">D</ci><times id="S2.E1.m1.2.2.3.3.cmml" xref="S2.E1.m1.2.2.3.3"></times></apply><apply id="S2.E1.m1.2.2.1.cmml" xref="S2.E1.m1.2.2.1"><times id="S2.E1.m1.2.2.1.2.cmml" xref="S2.E1.m1.2.2.1.2"></times><apply id="S2.E1.m1.2.2.1.3.cmml" xref="S2.E1.m1.2.2.1.3"><apply id="S2.E1.m1.2.2.1.3.1.cmml" xref="S2.E1.m1.2.2.1.3.1"><subset id="S2.E1.m1.2.2.1.3.1.1.cmml" xref="S2.E1.m1.2.2.1.3.1.1"></subset><apply id="S2.E1.m1.2.2.1.3.1.2.cmml" xref="S2.E1.m1.2.2.1.3.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.3.1.2.1.cmml" xref="S2.E1.m1.2.2.1.3.1.2">superscript</csymbol><ci id="S2.E1.m1.2.2.1.3.1.2.2.cmml" xref="S2.E1.m1.2.2.1.3.1.2.2">D</ci><times id="S2.E1.m1.2.2.1.3.1.2.3.cmml" xref="S2.E1.m1.2.2.1.3.1.2.3"></times></apply><ci id="S2.E1.m1.2.2.1.3.1.3.cmml" xref="S2.E1.m1.2.2.1.3.1.3">U</ci></apply><ci id="S2.E1.m1.2.2.1.3.2.cmml" xref="S2.E1.m1.2.2.1.3.2">argmin</ci></apply><apply id="S2.E1.m1.2.2.1.4.cmml" xref="S2.E1.m1.2.2.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.4.1.cmml" xref="S2.E1.m1.2.2.1.4">subscript</csymbol><ci id="S2.E1.m1.2.2.1.4.2.cmml" xref="S2.E1.m1.2.2.1.4.2">𝔼</ci><apply id="S2.E1.m1.2.2.1.4.3.cmml" xref="S2.E1.m1.2.2.1.4.3"><in id="S2.E1.m1.2.2.1.4.3.1.cmml" xref="S2.E1.m1.2.2.1.4.3.1"></in><ci id="S2.E1.m1.2.2.1.4.3.2.cmml" xref="S2.E1.m1.2.2.1.4.3.2">x</ci><ci id="S2.E1.m1.2.2.1.4.3.3.cmml" xref="S2.E1.m1.2.2.1.4.3.3">T</ci></apply></apply><apply id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.2.2.1.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.1.2">delimited-[]</csymbol><apply id="S2.E1.m1.2.2.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1"><times id="S2.E1.m1.2.2.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2"></times><apply id="S2.E1.m1.2.2.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.3.2">L</ci><ci id="S2.E1.m1.2.2.1.1.1.1.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.3.3">t</ci></apply><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.2">conditional</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.3">y</ci><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1"><times id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.2"></times><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.3">f</ci><list id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1"><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">𝜃</ci><times id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"></times></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">x</ci></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\pazocal{D}^{*}=\underset{\pazocal{D}^{*}\subset\pazocal{U}}{\mathrm{argmin}}~{}\mathbb{E}_{x\in\pazocal{T}}[\pazocal{L}_{t}(y|f(\theta^{*};x))]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS4.SSS0.Px1.p1.17" class="ltx_p">where, <math id="S2.SS4.SSS0.Px1.p1.8.m1.2" class="ltx_Math" alttext="f(\theta;\cdot)" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.8.m1.2a"><mrow id="S2.SS4.SSS0.Px1.p1.8.m1.2.3" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.cmml"><mi id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.2" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.1" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.1.cmml">​</mo><mrow id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.2" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.2.1" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.1.cmml">(</mo><mi id="S2.SS4.SSS0.Px1.p1.8.m1.1.1" xref="S2.SS4.SSS0.Px1.p1.8.m1.1.1.cmml">θ</mi><mo rspace="0em" id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.2.2" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.1.cmml">;</mo><mo lspace="0em" rspace="0em" id="S2.SS4.SSS0.Px1.p1.8.m1.2.2" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.2.cmml">⋅</mo><mo stretchy="false" id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.2.3" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.8.m1.2b"><apply id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.cmml" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3"><times id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.1"></times><ci id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.2.cmml" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.2">𝑓</ci><list id="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.3.3.2"><ci id="S2.SS4.SSS0.Px1.p1.8.m1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.8.m1.1.1">𝜃</ci><ci id="S2.SS4.SSS0.Px1.p1.8.m1.2.2.cmml" xref="S2.SS4.SSS0.Px1.p1.8.m1.2.2">⋅</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.8.m1.2c">f(\theta;\cdot)</annotation></semantics></math> is a LLM with parameters <math id="S2.SS4.SSS0.Px1.p1.9.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.9.m2.1a"><mi id="S2.SS4.SSS0.Px1.p1.9.m2.1.1" xref="S2.SS4.SSS0.Px1.p1.9.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.9.m2.1b"><ci id="S2.SS4.SSS0.Px1.p1.9.m2.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.9.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.9.m2.1c">\theta</annotation></semantics></math>, <math id="S2.SS4.SSS0.Px1.p1.10.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.10.m3.1a"><mi id="S2.SS4.SSS0.Px1.p1.10.m3.1.1" xref="S2.SS4.SSS0.Px1.p1.10.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.10.m3.1b"><ci id="S2.SS4.SSS0.Px1.p1.10.m3.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.10.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.10.m3.1c">y</annotation></semantics></math> is the task output, <math id="S2.SS4.SSS0.Px1.p1.11.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.11.m4.1a"><mi id="S2.SS4.SSS0.Px1.p1.11.m4.1.1" xref="S2.SS4.SSS0.Px1.p1.11.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.11.m4.1b"><ci id="S2.SS4.SSS0.Px1.p1.11.m4.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.11.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.11.m4.1c">x</annotation></semantics></math> is an input in target task data <math id="S2.SS4.SSS0.Px1.p1.12.m5.1" class="ltx_Math" alttext="\pazocal{T}" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.12.m5.1a"><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.12.m5.1.1" xref="S2.SS4.SSS0.Px1.p1.12.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.12.m5.1b"><ci id="S2.SS4.SSS0.Px1.p1.12.m5.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.12.m5.1.1">T</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.12.m5.1c">\pazocal{T}</annotation></semantics></math>, and <math id="S2.SS4.SSS0.Px1.p1.13.m6.1" class="ltx_Math" alttext="\pazocal{L}_{t}" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.13.m6.1a"><msub id="S2.SS4.SSS0.Px1.p1.13.m6.1.1" xref="S2.SS4.SSS0.Px1.p1.13.m6.1.1.cmml"><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.13.m6.1.1.2" xref="S2.SS4.SSS0.Px1.p1.13.m6.1.1.2.cmml">L</mi><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.13.m6.1.1.3" xref="S2.SS4.SSS0.Px1.p1.13.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.13.m6.1b"><apply id="S2.SS4.SSS0.Px1.p1.13.m6.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.13.m6.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.13.m6.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.13.m6.1.1">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.13.m6.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.13.m6.1.1.2">L</ci><ci id="S2.SS4.SSS0.Px1.p1.13.m6.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.13.m6.1.1.3">t</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.13.m6.1c">\pazocal{L}_{t}</annotation></semantics></math> is the target task loss or metric. <math id="S2.SS4.SSS0.Px1.p1.14.m7.1" class="ltx_Math" alttext="\theta^{*}" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.14.m7.1a"><msup id="S2.SS4.SSS0.Px1.p1.14.m7.1.1" xref="S2.SS4.SSS0.Px1.p1.14.m7.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.14.m7.1.1.2" xref="S2.SS4.SSS0.Px1.p1.14.m7.1.1.2.cmml">θ</mi><mo id="S2.SS4.SSS0.Px1.p1.14.m7.1.1.3" xref="S2.SS4.SSS0.Px1.p1.14.m7.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.14.m7.1b"><apply id="S2.SS4.SSS0.Px1.p1.14.m7.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.14.m7.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.14.m7.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.14.m7.1.1">superscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.14.m7.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.14.m7.1.1.2">𝜃</ci><times id="S2.SS4.SSS0.Px1.p1.14.m7.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.14.m7.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.14.m7.1c">\theta^{*}</annotation></semantics></math> is computed on pre-training task with <math id="S2.SS4.SSS0.Px1.p1.15.m8.1" class="ltx_Math" alttext="\pazocal{L}_{\mathrm{pre-train}}" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.15.m8.1a"><msub id="S2.SS4.SSS0.Px1.p1.15.m8.1.1" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.cmml"><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.2" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.2.cmml">L</mi><mrow id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.cmml"><mi id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.2" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.2.cmml">pre</mi><mo id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.1" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.1.cmml">−</mo><mi id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.3" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.3.cmml">train</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.15.m8.1b"><apply id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.2">L</ci><apply id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3"><minus id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.1"></minus><ci id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.2.cmml" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.2">pre</ci><ci id="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.3.cmml" xref="S2.SS4.SSS0.Px1.p1.15.m8.1.1.3.3">train</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.15.m8.1c">\pazocal{L}_{\mathrm{pre-train}}</annotation></semantics></math> as the pre-training loss, and <math id="S2.SS4.SSS0.Px1.p1.16.m9.1" class="ltx_Math" alttext="x_{u}" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.16.m9.1a"><msub id="S2.SS4.SSS0.Px1.p1.16.m9.1.1" xref="S2.SS4.SSS0.Px1.p1.16.m9.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.16.m9.1.1.2" xref="S2.SS4.SSS0.Px1.p1.16.m9.1.1.2.cmml">x</mi><mi id="S2.SS4.SSS0.Px1.p1.16.m9.1.1.3" xref="S2.SS4.SSS0.Px1.p1.16.m9.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.16.m9.1b"><apply id="S2.SS4.SSS0.Px1.p1.16.m9.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.16.m9.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.16.m9.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.16.m9.1.1">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.16.m9.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.16.m9.1.1.2">𝑥</ci><ci id="S2.SS4.SSS0.Px1.p1.16.m9.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.16.m9.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.16.m9.1c">x_{u}</annotation></semantics></math> as the unlabeled sample in <math id="S2.SS4.SSS0.Px1.p1.17.m10.1" class="ltx_Math" alttext="\pazocal{D}" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.17.m10.1a"><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.17.m10.1.1" xref="S2.SS4.SSS0.Px1.p1.17.m10.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.17.m10.1b"><ci id="S2.SS4.SSS0.Px1.p1.17.m10.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.17.m10.1.1">D</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.17.m10.1c">\pazocal{D}</annotation></semantics></math>:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.2" class="ltx_Math" alttext="\theta^{*}=\underset{\theta}{\mathrm{argmin}}~{}\mathbb{E}_{x_{u}\in\pazocal{D}}[\pazocal{L}_{\mathrm{pre-train}}(f(\theta;x_{u}))]" display="block"><semantics id="S2.E2.m1.2a"><mrow id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml"><msup id="S2.E2.m1.2.2.3" xref="S2.E2.m1.2.2.3.cmml"><mi id="S2.E2.m1.2.2.3.2" xref="S2.E2.m1.2.2.3.2.cmml">θ</mi><mo id="S2.E2.m1.2.2.3.3" xref="S2.E2.m1.2.2.3.3.cmml">∗</mo></msup><mo id="S2.E2.m1.2.2.2" xref="S2.E2.m1.2.2.2.cmml">=</mo><mrow id="S2.E2.m1.2.2.1" xref="S2.E2.m1.2.2.1.cmml"><munder accentunder="true" id="S2.E2.m1.2.2.1.3" xref="S2.E2.m1.2.2.1.3.cmml"><mi id="S2.E2.m1.2.2.1.3.2" xref="S2.E2.m1.2.2.1.3.2.cmml">argmin</mi><mo id="S2.E2.m1.2.2.1.3.1" xref="S2.E2.m1.2.2.1.3.1.cmml">𝜃</mo></munder><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.1.2" xref="S2.E2.m1.2.2.1.2.cmml">​</mo><msub id="S2.E2.m1.2.2.1.4" xref="S2.E2.m1.2.2.1.4.cmml"><mi id="S2.E2.m1.2.2.1.4.2" xref="S2.E2.m1.2.2.1.4.2.cmml">𝔼</mi><mrow id="S2.E2.m1.2.2.1.4.3" xref="S2.E2.m1.2.2.1.4.3.cmml"><msub id="S2.E2.m1.2.2.1.4.3.2" xref="S2.E2.m1.2.2.1.4.3.2.cmml"><mi id="S2.E2.m1.2.2.1.4.3.2.2" xref="S2.E2.m1.2.2.1.4.3.2.2.cmml">x</mi><mi id="S2.E2.m1.2.2.1.4.3.2.3" xref="S2.E2.m1.2.2.1.4.3.2.3.cmml">u</mi></msub><mo id="S2.E2.m1.2.2.1.4.3.1" xref="S2.E2.m1.2.2.1.4.3.1.cmml">∈</mo><mi mathvariant="normal" id="S2.E2.m1.2.2.1.4.3.3" xref="S2.E2.m1.2.2.1.4.3.3.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.1.2a" xref="S2.E2.m1.2.2.1.2.cmml">​</mo><mrow id="S2.E2.m1.2.2.1.1.1" xref="S2.E2.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.2" xref="S2.E2.m1.2.2.1.1.2.1.cmml">[</mo><mrow id="S2.E2.m1.2.2.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.cmml"><msub id="S2.E2.m1.2.2.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S2.E2.m1.2.2.1.1.1.1.3.2" xref="S2.E2.m1.2.2.1.1.1.1.3.2.cmml">L</mi><mrow id="S2.E2.m1.2.2.1.1.1.1.3.3" xref="S2.E2.m1.2.2.1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.3.3.2" xref="S2.E2.m1.2.2.1.1.1.1.3.3.2.cmml">pre</mi><mo id="S2.E2.m1.2.2.1.1.1.1.3.3.1" xref="S2.E2.m1.2.2.1.1.1.1.3.3.1.cmml">−</mo><mi id="S2.E2.m1.2.2.1.1.1.1.3.3.3" xref="S2.E2.m1.2.2.1.1.1.1.3.3.3.cmml">train</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.2.2.1.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.2.2.1.1.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">θ</mi><mo id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">;</mo><msub id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi mathvariant="normal" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml">u</mi></msub><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.4" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E2.m1.2.2.1.1.1.3" xref="S2.E2.m1.2.2.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.2b"><apply id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2"><eq id="S2.E2.m1.2.2.2.cmml" xref="S2.E2.m1.2.2.2"></eq><apply id="S2.E2.m1.2.2.3.cmml" xref="S2.E2.m1.2.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.3.1.cmml" xref="S2.E2.m1.2.2.3">superscript</csymbol><ci id="S2.E2.m1.2.2.3.2.cmml" xref="S2.E2.m1.2.2.3.2">𝜃</ci><times id="S2.E2.m1.2.2.3.3.cmml" xref="S2.E2.m1.2.2.3.3"></times></apply><apply id="S2.E2.m1.2.2.1.cmml" xref="S2.E2.m1.2.2.1"><times id="S2.E2.m1.2.2.1.2.cmml" xref="S2.E2.m1.2.2.1.2"></times><apply id="S2.E2.m1.2.2.1.3.cmml" xref="S2.E2.m1.2.2.1.3"><ci id="S2.E2.m1.2.2.1.3.1.cmml" xref="S2.E2.m1.2.2.1.3.1">𝜃</ci><ci id="S2.E2.m1.2.2.1.3.2.cmml" xref="S2.E2.m1.2.2.1.3.2">argmin</ci></apply><apply id="S2.E2.m1.2.2.1.4.cmml" xref="S2.E2.m1.2.2.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.4.1.cmml" xref="S2.E2.m1.2.2.1.4">subscript</csymbol><ci id="S2.E2.m1.2.2.1.4.2.cmml" xref="S2.E2.m1.2.2.1.4.2">𝔼</ci><apply id="S2.E2.m1.2.2.1.4.3.cmml" xref="S2.E2.m1.2.2.1.4.3"><in id="S2.E2.m1.2.2.1.4.3.1.cmml" xref="S2.E2.m1.2.2.1.4.3.1"></in><apply id="S2.E2.m1.2.2.1.4.3.2.cmml" xref="S2.E2.m1.2.2.1.4.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.4.3.2.1.cmml" xref="S2.E2.m1.2.2.1.4.3.2">subscript</csymbol><ci id="S2.E2.m1.2.2.1.4.3.2.2.cmml" xref="S2.E2.m1.2.2.1.4.3.2.2">𝑥</ci><ci id="S2.E2.m1.2.2.1.4.3.2.3.cmml" xref="S2.E2.m1.2.2.1.4.3.2.3">𝑢</ci></apply><ci id="S2.E2.m1.2.2.1.4.3.3.cmml" xref="S2.E2.m1.2.2.1.4.3.3">D</ci></apply></apply><apply id="S2.E2.m1.2.2.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.2.2.1.1.2.1.cmml" xref="S2.E2.m1.2.2.1.1.1.2">delimited-[]</csymbol><apply id="S2.E2.m1.2.2.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1"><times id="S2.E2.m1.2.2.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.2"></times><apply id="S2.E2.m1.2.2.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.3.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.3.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.2">L</ci><apply id="S2.E2.m1.2.2.1.1.1.1.3.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.3"><minus id="S2.E2.m1.2.2.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.3.1"></minus><ci id="S2.E2.m1.2.2.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.3.2">pre</ci><ci id="S2.E2.m1.2.2.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.3.3.3">train</ci></apply></apply><apply id="S2.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1"><times id="S2.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.2"></times><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.3">f</ci><list id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1"><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">𝜃</ci><apply id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2">x</ci><ci id="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3">u</ci></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.2c">\theta^{*}=\underset{\theta}{\mathrm{argmin}}~{}\mathbb{E}_{x_{u}\in\pazocal{D}}[\pazocal{L}_{\mathrm{pre-train}}(f(\theta;x_{u}))]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS4.SSS0.Px1.p1.23">우리의 도메인 적응형 연속 사전 훈련은 감독되지 않은 도메인 적응 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>]</cite>의 렌즈에서 볼 수 있다. 우리의 소스 데이터는 대규모 비감독 도메인 코퍼스이고, 타겟 데이터는 타겟 태스크 데이터이다. 사전 트레이닝을 통해, 우리는 태스크 트레이닝 데이터 자체와의 정렬을 제어할 수 없다; 우리의 아이디어는 사전 트레이닝 동안 도메인과 정렬함으로써, 우리는 LLM을 태스크와 정렬할 수 있다는 것이다. 이러한 직관은 오픈 도메인 태스크에 대한 수행을 돕는 LLM 사전 훈련의 증거에 의해 뒷받침된다. 우리의 문제는 감독되지 않은 도메인 적응과 유사하기 때문에 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite>로부터 일반화 한계를 사용한다. <math alttext="f\in\pazocal{H}_{p}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.19.m2.1"><semantics id="S2.SS4.SSS0.Px1.p1.19.m2.1a"><mrow id="S2.SS4.SSS0.Px1.p1.19.m2.1.1" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.2" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.2.cmml">f</mi><mo id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.1" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.1.cmml">∈</mo><msub id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.cmml"><mi id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.2.cmml">H</mi><mi id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.3.cmml">p</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.19.m2.1b"><apply id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1"><in id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.1"></in><ci id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.2">𝑓</ci><apply id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.2.cmml" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.2">H</ci><ci id="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.3.cmml" xref="S2.SS4.SSS0.Px1.p1.19.m2.1.1.3.3">p</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.19.m2.1c">f\in\pazocal{H}_{p}</annotation></semantics></math>로 가설 공간 <math alttext="\pazocal{H}_{p}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.18.m1.1"><semantics id="S2.SS4.SSS0.Px1.p1.18.m1.1a"><msub id="S2.SS4.SSS0.Px1.p1.18.m1.1.1" xref="S2.SS4.SSS0.Px1.p1.18.m1.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.18.m1.1.1.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.18.m1.1.1.2.cmml">H</mi><mi id="S2.SS4.SSS0.Px1.p1.18.m1.1.1.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.18.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.18.m1.1b"><apply id="S2.SS4.SSS0.Px1.p1.18.m1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.18.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.18.m1.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.18.m1.1.1">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.18.m1.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.18.m1.1.1.2">H</ci><ci id="S2.SS4.SSS0.Px1.p1.18.m1.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.18.m1.1.1.3">p</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.18.m1.1c">\pazocal{H}_{p}</annotation></semantics></math>를 고려하고; 소스 <math alttext="\pazocal{D}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.20.m3.1"><semantics id="S2.SS4.SSS0.Px1.p1.20.m3.1a"><mi id="S2.SS4.SSS0.Px1.p1.20.m3.1.1" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.20.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.20.m3.1b"><ci id="S2.SS4.SSS0.Px1.p1.20.m3.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.20.m3.1.1">D</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.20.m3.1c">\pazocal{D}</annotation></semantics></math> 및 태스크 데이터 <math alttext="\pazocal{T}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.21.m4.1"><semantics id="S2.SS4.SSS0.Px1.p1.21.m4.1a"><mi id="S2.SS4.SSS0.Px1.p1.21.m4.1.1" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.21.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.21.m4.1b"><ci id="S2.SS4.SSS0.Px1.p1.21.m4.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.21.m4.1.1">T</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.21.m4.1c">\pazocal{T}</annotation></semantics></math>로 각각 <math alttext="\epsilon_{\pazocal{D}}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.22.m5.1"><semantics id="S2.SS4.SSS0.Px1.p1.22.m5.1a"><msub id="S2.SS4.SSS0.Px1.p1.22.m5.1.1" xref="S2.SS4.SSS0.Px1.p1.22.m5.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.22.m5.1.1.2" xref="S2.SS4.SSS0.Px1.p1.22.m5.1.1.2.cmml">ϵ</mi><mi id="S2.SS4.SSS0.Px1.p1.22.m5.1.1.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.22.m5.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.22.m5.1b"><apply id="S2.SS4.SSS0.Px1.p1.22.m5.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.22.m5.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.22.m5.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.22.m5.1.1">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.22.m5.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.22.m5.1.1.2">italic-ϵ</ci><ci id="S2.SS4.SSS0.Px1.p1.22.m5.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.22.m5.1.1.3">D</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.22.m5.1c">\epsilon_{\pazocal{D}}</annotation></semantics></math> 및 <math alttext="\epsilon_{\pazocal{T}}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.23.m6.1"><semantics id="S2.SS4.SSS0.Px1.p1.23.m6.1a"><msub id="S2.SS4.SSS0.Px1.p1.23.m6.1.1" xref="S2.SS4.SSS0.Px1.p1.23.m6.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.23.m6.1.1.2" xref="S2.SS4.SSS0.Px1.p1.23.m6.1.1.2.cmml">ϵ</mi><mi id="S2.SS4.SSS0.Px1.p1.23.m6.1.1.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.23.m6.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.23.m6.1b"><apply id="S2.SS4.SSS0.Px1.p1.23.m6.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.23.m6.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.23.m6.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.23.m6.1.1">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.23.m6.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.23.m6.1.1.2">italic-ϵ</ci><ci id="S2.SS4.SSS0.Px1.p1.23.m6.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.23.m6.1.1.3">T</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.23.m6.1c">\epsilon_{\pazocal{T}}</annotation></semantics></math>를 고려한다. 일반화 바운드는 주어질 수 있다:</p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.4" class="ltx_Math" alttext="\epsilon_{\pazocal{T}}(f)\leq\epsilon_{\pazocal{D}}(f)+\frac{1}{2}d_{\pazocal{H}_{p}\Delta\pazocal{H}_{p}}(\pazocal{D},\pazocal{T})+\pazocal{C}" display="block"><semantics id="S2.E3.m1.4a"><mrow id="S2.E3.m1.4.5" xref="S2.E3.m1.4.5.cmml"><mrow id="S2.E3.m1.4.5.2" xref="S2.E3.m1.4.5.2.cmml"><msub id="S2.E3.m1.4.5.2.2" xref="S2.E3.m1.4.5.2.2.cmml"><mi id="S2.E3.m1.4.5.2.2.2" xref="S2.E3.m1.4.5.2.2.2.cmml">ϵ</mi><mi mathvariant="normal" id="S2.E3.m1.4.5.2.2.3" xref="S2.E3.m1.4.5.2.2.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.5.2.1" xref="S2.E3.m1.4.5.2.1.cmml">​</mo><mrow id="S2.E3.m1.4.5.2.3.2" xref="S2.E3.m1.4.5.2.cmml"><mo stretchy="false" id="S2.E3.m1.4.5.2.3.2.1" xref="S2.E3.m1.4.5.2.cmml">(</mo><mi id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml">f</mi><mo stretchy="false" id="S2.E3.m1.4.5.2.3.2.2" xref="S2.E3.m1.4.5.2.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.5.1" xref="S2.E3.m1.4.5.1.cmml">≤</mo><mrow id="S2.E3.m1.4.5.3" xref="S2.E3.m1.4.5.3.cmml"><mrow id="S2.E3.m1.4.5.3.2" xref="S2.E3.m1.4.5.3.2.cmml"><msub id="S2.E3.m1.4.5.3.2.2" xref="S2.E3.m1.4.5.3.2.2.cmml"><mi id="S2.E3.m1.4.5.3.2.2.2" xref="S2.E3.m1.4.5.3.2.2.2.cmml">ϵ</mi><mi mathvariant="normal" id="S2.E3.m1.4.5.3.2.2.3" xref="S2.E3.m1.4.5.3.2.2.3.cmml">D</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.5.3.2.1" xref="S2.E3.m1.4.5.3.2.1.cmml">​</mo><mrow id="S2.E3.m1.4.5.3.2.3.2" xref="S2.E3.m1.4.5.3.2.cmml"><mo stretchy="false" id="S2.E3.m1.4.5.3.2.3.2.1" xref="S2.E3.m1.4.5.3.2.cmml">(</mo><mi id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml">f</mi><mo stretchy="false" id="S2.E3.m1.4.5.3.2.3.2.2" xref="S2.E3.m1.4.5.3.2.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.5.3.1" xref="S2.E3.m1.4.5.3.1.cmml">+</mo><mrow id="S2.E3.m1.4.5.3.3" xref="S2.E3.m1.4.5.3.3.cmml"><mfrac id="S2.E3.m1.4.5.3.3.2" xref="S2.E3.m1.4.5.3.3.2.cmml"><mn id="S2.E3.m1.4.5.3.3.2.2" xref="S2.E3.m1.4.5.3.3.2.2.cmml">1</mn><mn id="S2.E3.m1.4.5.3.3.2.3" xref="S2.E3.m1.4.5.3.3.2.3.cmml">2</mn></mfrac><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.5.3.3.1" xref="S2.E3.m1.4.5.3.3.1.cmml">​</mo><msub id="S2.E3.m1.4.5.3.3.3" xref="S2.E3.m1.4.5.3.3.3.cmml"><mi id="S2.E3.m1.4.5.3.3.3.2" xref="S2.E3.m1.4.5.3.3.3.2.cmml">d</mi><mrow id="S2.E3.m1.4.5.3.3.3.3" xref="S2.E3.m1.4.5.3.3.3.3.cmml"><msub id="S2.E3.m1.4.5.3.3.3.3.2" xref="S2.E3.m1.4.5.3.3.3.3.2.cmml"><mi mathvariant="normal" id="S2.E3.m1.4.5.3.3.3.3.2.2" xref="S2.E3.m1.4.5.3.3.3.3.2.2.cmml">H</mi><mi mathvariant="normal" id="S2.E3.m1.4.5.3.3.3.3.2.3" xref="S2.E3.m1.4.5.3.3.3.3.2.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.5.3.3.3.3.1" xref="S2.E3.m1.4.5.3.3.3.3.1.cmml">​</mo><mi mathvariant="normal" id="S2.E3.m1.4.5.3.3.3.3.3" xref="S2.E3.m1.4.5.3.3.3.3.3.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.5.3.3.3.3.1a" xref="S2.E3.m1.4.5.3.3.3.3.1.cmml">​</mo><msub id="S2.E3.m1.4.5.3.3.3.3.4" xref="S2.E3.m1.4.5.3.3.3.3.4.cmml"><mi mathvariant="normal" id="S2.E3.m1.4.5.3.3.3.3.4.2" xref="S2.E3.m1.4.5.3.3.3.3.4.2.cmml">H</mi><mi mathvariant="normal" id="S2.E3.m1.4.5.3.3.3.3.4.3" xref="S2.E3.m1.4.5.3.3.3.3.4.3.cmml">p</mi></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.5.3.3.1a" xref="S2.E3.m1.4.5.3.3.1.cmml">​</mo><mrow id="S2.E3.m1.4.5.3.3.4.2" xref="S2.E3.m1.4.5.3.3.4.1.cmml"><mo stretchy="false" id="S2.E3.m1.4.5.3.3.4.2.1" xref="S2.E3.m1.4.5.3.3.4.1.cmml">(</mo><mi mathvariant="normal" id="S2.E3.m1.3.3" xref="S2.E3.m1.3.3.cmml">D</mi><mo id="S2.E3.m1.4.5.3.3.4.2.2" xref="S2.E3.m1.4.5.3.3.4.1.cmml">,</mo><mi mathvariant="normal" id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml">T</mi><mo stretchy="false" id="S2.E3.m1.4.5.3.3.4.2.3" xref="S2.E3.m1.4.5.3.3.4.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.5.3.1a" xref="S2.E3.m1.4.5.3.1.cmml">+</mo><mi mathvariant="normal" id="S2.E3.m1.4.5.3.4" xref="S2.E3.m1.4.5.3.4.cmml">C</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.4b"><apply id="S2.E3.m1.4.5.cmml" xref="S2.E3.m1.4.5"><leq id="S2.E3.m1.4.5.1.cmml" xref="S2.E3.m1.4.5.1"></leq><apply id="S2.E3.m1.4.5.2.cmml" xref="S2.E3.m1.4.5.2"><times id="S2.E3.m1.4.5.2.1.cmml" xref="S2.E3.m1.4.5.2.1"></times><apply id="S2.E3.m1.4.5.2.2.cmml" xref="S2.E3.m1.4.5.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.5.2.2.1.cmml" xref="S2.E3.m1.4.5.2.2">subscript</csymbol><ci id="S2.E3.m1.4.5.2.2.2.cmml" xref="S2.E3.m1.4.5.2.2.2">italic-ϵ</ci><ci id="S2.E3.m1.4.5.2.2.3.cmml" xref="S2.E3.m1.4.5.2.2.3">T</ci></apply><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">𝑓</ci></apply><apply id="S2.E3.m1.4.5.3.cmml" xref="S2.E3.m1.4.5.3"><plus id="S2.E3.m1.4.5.3.1.cmml" xref="S2.E3.m1.4.5.3.1"></plus><apply id="S2.E3.m1.4.5.3.2.cmml" xref="S2.E3.m1.4.5.3.2"><times id="S2.E3.m1.4.5.3.2.1.cmml" xref="S2.E3.m1.4.5.3.2.1"></times><apply id="S2.E3.m1.4.5.3.2.2.cmml" xref="S2.E3.m1.4.5.3.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.5.3.2.2.1.cmml" xref="S2.E3.m1.4.5.3.2.2">subscript</csymbol><ci id="S2.E3.m1.4.5.3.2.2.2.cmml" xref="S2.E3.m1.4.5.3.2.2.2">italic-ϵ</ci><ci id="S2.E3.m1.4.5.3.2.2.3.cmml" xref="S2.E3.m1.4.5.3.2.2.3">D</ci></apply><ci id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2">𝑓</ci></apply><apply id="S2.E3.m1.4.5.3.3.cmml" xref="S2.E3.m1.4.5.3.3"><times id="S2.E3.m1.4.5.3.3.1.cmml" xref="S2.E3.m1.4.5.3.3.1"></times><apply id="S2.E3.m1.4.5.3.3.2.cmml" xref="S2.E3.m1.4.5.3.3.2"><divide id="S2.E3.m1.4.5.3.3.2.1.cmml" xref="S2.E3.m1.4.5.3.3.2"></divide><cn type="integer" id="S2.E3.m1.4.5.3.3.2.2.cmml" xref="S2.E3.m1.4.5.3.3.2.2">1</cn><cn type="integer" id="S2.E3.m1.4.5.3.3.2.3.cmml" xref="S2.E3.m1.4.5.3.3.2.3">2</cn></apply><apply id="S2.E3.m1.4.5.3.3.3.cmml" xref="S2.E3.m1.4.5.3.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.5.3.3.3.1.cmml" xref="S2.E3.m1.4.5.3.3.3">subscript</csymbol><ci id="S2.E3.m1.4.5.3.3.3.2.cmml" xref="S2.E3.m1.4.5.3.3.3.2">𝑑</ci><apply id="S2.E3.m1.4.5.3.3.3.3.cmml" xref="S2.E3.m1.4.5.3.3.3.3"><times id="S2.E3.m1.4.5.3.3.3.3.1.cmml" xref="S2.E3.m1.4.5.3.3.3.3.1"></times><apply id="S2.E3.m1.4.5.3.3.3.3.2.cmml" xref="S2.E3.m1.4.5.3.3.3.3.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.5.3.3.3.3.2.1.cmml" xref="S2.E3.m1.4.5.3.3.3.3.2">subscript</csymbol><ci id="S2.E3.m1.4.5.3.3.3.3.2.2.cmml" xref="S2.E3.m1.4.5.3.3.3.3.2.2">H</ci><ci id="S2.E3.m1.4.5.3.3.3.3.2.3.cmml" xref="S2.E3.m1.4.5.3.3.3.3.2.3">p</ci></apply><ci id="S2.E3.m1.4.5.3.3.3.3.3.cmml" xref="S2.E3.m1.4.5.3.3.3.3.3">Δ</ci><apply id="S2.E3.m1.4.5.3.3.3.3.4.cmml" xref="S2.E3.m1.4.5.3.3.3.3.4"><csymbol cd="ambiguous" id="S2.E3.m1.4.5.3.3.3.3.4.1.cmml" xref="S2.E3.m1.4.5.3.3.3.3.4">subscript</csymbol><ci id="S2.E3.m1.4.5.3.3.3.3.4.2.cmml" xref="S2.E3.m1.4.5.3.3.3.3.4.2">H</ci><ci id="S2.E3.m1.4.5.3.3.3.3.4.3.cmml" xref="S2.E3.m1.4.5.3.3.3.3.4.3">p</ci></apply></apply></apply><interval closure="open" id="S2.E3.m1.4.5.3.3.4.1.cmml" xref="S2.E3.m1.4.5.3.3.4.2"><ci id="S2.E3.m1.3.3.cmml" xref="S2.E3.m1.3.3">D</ci><ci id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.4.4">T</ci></interval></apply><ci id="S2.E3.m1.4.5.3.4.cmml" xref="S2.E3.m1.4.5.3.4">C</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.4c">\epsilon_{\pazocal{T}}(f)\leq\epsilon_{\pazocal{D}}(f)+\frac{1}{2}d_{\pazocal{H}_{p}\Delta\pazocal{H}_{p}}(\pazocal{D},\pazocal{T})+\pazocal{C}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS4.SSS0.Px1.p1.26" class="ltx_p">where, <math id="S2.SS4.SSS0.Px1.p1.24.m1.1" class="ltx_Math" alttext="d_{\pazocal{H}_{p}\Delta\pazocal{H}_{p}}" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.24.m1.1a"><msub id="S2.SS4.SSS0.Px1.p1.24.m1.1.1" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.2" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.2.cmml">d</mi><mrow id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.cmml"><msub id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.cmml"><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.2" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.2.cmml">H</mi><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.3" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.1" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.1.cmml">​</mo><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.3" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.3.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.1a" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.1.cmml">​</mo><msub id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.cmml"><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.2" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.2.cmml">H</mi><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.3" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.3.cmml">p</mi></msub></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.24.m1.1b"><apply id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.2">𝑑</ci><apply id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3"><times id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.1"></times><apply id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.1.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.2.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.2">H</ci><ci id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.3.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.2.3">p</ci></apply><ci id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.3.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.3">Δ</ci><apply id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.1.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.2.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.2">H</ci><ci id="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.3.cmml" xref="S2.SS4.SSS0.Px1.p1.24.m1.1.1.3.4.3">p</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.24.m1.1c">d_{\pazocal{H}_{p}\Delta\pazocal{H}_{p}}</annotation></semantics></math> is the distribution discrepancy distance between <math id="S2.SS4.SSS0.Px1.p1.25.m2.1" class="ltx_Math" alttext="\pazocal{D}" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.25.m2.1a"><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.25.m2.1.1" xref="S2.SS4.SSS0.Px1.p1.25.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.25.m2.1b"><ci id="S2.SS4.SSS0.Px1.p1.25.m2.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.25.m2.1.1">D</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.25.m2.1c">\pazocal{D}</annotation></semantics></math> and <math id="S2.SS4.SSS0.Px1.p1.26.m3.1" class="ltx_Math" alttext="\pazocal{T}" display="inline"><semantics id="S2.SS4.SSS0.Px1.p1.26.m3.1a"><mi mathvariant="normal" id="S2.SS4.SSS0.Px1.p1.26.m3.1.1" xref="S2.SS4.SSS0.Px1.p1.26.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.26.m3.1b"><ci id="S2.SS4.SSS0.Px1.p1.26.m3.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.26.m3.1.1">T</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.26.m3.1c">\pazocal{T}</annotation></semantics></math> that is bounded by&nbsp;<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>:</p>
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.12" class="ltx_Math" alttext="d_{\pazocal{H}_{p}\Delta\pazocal{H}_{p}}(\pazocal{D},\pazocal{T})=\underset{f,f^{\prime}\in\pazocal{H}_{p}}{\mathrm{sup}}|\mathbb{E}_{x\in\pazocal{D}}[f(x)\neq f^{\prime}(x)]-\mathbb{E}_{x\in\pazocal{T}}[f(x)\neq f^{\prime}(x)]|\leq 2\underset{\alpha(h)\in\pazocal{H}_{d}}{\mathrm{sup}}[\alpha(h)-1]" display="block"><semantics id="S2.E4.m1.12a"><mrow id="S2.E4.m1.12.12" xref="S2.E4.m1.12.12.cmml"><mrow id="S2.E4.m1.12.12.4" xref="S2.E4.m1.12.12.4.cmml"><msub id="S2.E4.m1.12.12.4.2" xref="S2.E4.m1.12.12.4.2.cmml"><mi id="S2.E4.m1.12.12.4.2.2" xref="S2.E4.m1.12.12.4.2.2.cmml">d</mi><mrow id="S2.E4.m1.12.12.4.2.3" xref="S2.E4.m1.12.12.4.2.3.cmml"><msub id="S2.E4.m1.12.12.4.2.3.2" xref="S2.E4.m1.12.12.4.2.3.2.cmml"><mi mathvariant="normal" id="S2.E4.m1.12.12.4.2.3.2.2" xref="S2.E4.m1.12.12.4.2.3.2.2.cmml">H</mi><mi mathvariant="normal" id="S2.E4.m1.12.12.4.2.3.2.3" xref="S2.E4.m1.12.12.4.2.3.2.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.12.12.4.2.3.1" xref="S2.E4.m1.12.12.4.2.3.1.cmml">​</mo><mi mathvariant="normal" id="S2.E4.m1.12.12.4.2.3.3" xref="S2.E4.m1.12.12.4.2.3.3.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.12.12.4.2.3.1a" xref="S2.E4.m1.12.12.4.2.3.1.cmml">​</mo><msub id="S2.E4.m1.12.12.4.2.3.4" xref="S2.E4.m1.12.12.4.2.3.4.cmml"><mi mathvariant="normal" id="S2.E4.m1.12.12.4.2.3.4.2" xref="S2.E4.m1.12.12.4.2.3.4.2.cmml">H</mi><mi mathvariant="normal" id="S2.E4.m1.12.12.4.2.3.4.3" xref="S2.E4.m1.12.12.4.2.3.4.3.cmml">p</mi></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.12.12.4.1" xref="S2.E4.m1.12.12.4.1.cmml">​</mo><mrow id="S2.E4.m1.12.12.4.3.2" xref="S2.E4.m1.12.12.4.3.1.cmml"><mo stretchy="false" id="S2.E4.m1.12.12.4.3.2.1" xref="S2.E4.m1.12.12.4.3.1.cmml">(</mo><mi mathvariant="normal" id="S2.E4.m1.4.4" xref="S2.E4.m1.4.4.cmml">D</mi><mo id="S2.E4.m1.12.12.4.3.2.2" xref="S2.E4.m1.12.12.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.E4.m1.5.5" xref="S2.E4.m1.5.5.cmml">T</mi><mo stretchy="false" id="S2.E4.m1.12.12.4.3.2.3" xref="S2.E4.m1.12.12.4.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.12.12.5" xref="S2.E4.m1.12.12.5.cmml">=</mo><mrow id="S2.E4.m1.11.11.1" xref="S2.E4.m1.11.11.1.cmml"><munder accentunder="true" id="S2.E4.m1.2.2" xref="S2.E4.m1.2.2.cmml"><mi id="S2.E4.m1.2.2.3" xref="S2.E4.m1.2.2.3.cmml">sup</mi><mrow id="S2.E4.m1.2.2.2" xref="S2.E4.m1.2.2.2.cmml"><mrow id="S2.E4.m1.2.2.2.2.1" xref="S2.E4.m1.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml">f</mi><mo id="S2.E4.m1.2.2.2.2.1.2" xref="S2.E4.m1.2.2.2.2.2.cmml">,</mo><msup id="S2.E4.m1.2.2.2.2.1.1" xref="S2.E4.m1.2.2.2.2.1.1.cmml"><mi mathvariant="normal" id="S2.E4.m1.2.2.2.2.1.1.2" xref="S2.E4.m1.2.2.2.2.1.1.2.cmml">f</mi><mo id="S2.E4.m1.2.2.2.2.1.1.3" xref="S2.E4.m1.2.2.2.2.1.1.3.cmml">′</mo></msup></mrow><mo id="S2.E4.m1.2.2.2.3" xref="S2.E4.m1.2.2.2.3.cmml">∈</mo><msub id="S2.E4.m1.2.2.2.4" xref="S2.E4.m1.2.2.2.4.cmml"><mi mathvariant="normal" id="S2.E4.m1.2.2.2.4.2" xref="S2.E4.m1.2.2.2.4.2.cmml">H</mi><mi mathvariant="normal" id="S2.E4.m1.2.2.2.4.3" xref="S2.E4.m1.2.2.2.4.3.cmml">p</mi></msub></mrow></munder><mo lspace="0em" rspace="0em" id="S2.E4.m1.11.11.1.2" xref="S2.E4.m1.11.11.1.2.cmml">​</mo><mrow id="S2.E4.m1.11.11.1.1.1" xref="S2.E4.m1.11.11.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.2" xref="S2.E4.m1.11.11.1.1.2.1.cmml">|</mo><mrow id="S2.E4.m1.11.11.1.1.1.1" xref="S2.E4.m1.11.11.1.1.1.1.cmml"><mrow id="S2.E4.m1.11.11.1.1.1.1.1" xref="S2.E4.m1.11.11.1.1.1.1.1.cmml"><msub id="S2.E4.m1.11.11.1.1.1.1.1.3" xref="S2.E4.m1.11.11.1.1.1.1.1.3.cmml"><mi id="S2.E4.m1.11.11.1.1.1.1.1.3.2" xref="S2.E4.m1.11.11.1.1.1.1.1.3.2.cmml">𝔼</mi><mrow id="S2.E4.m1.11.11.1.1.1.1.1.3.3" xref="S2.E4.m1.11.11.1.1.1.1.1.3.3.cmml"><mi mathvariant="normal" id="S2.E4.m1.11.11.1.1.1.1.1.3.3.2" xref="S2.E4.m1.11.11.1.1.1.1.1.3.3.2.cmml">x</mi><mo id="S2.E4.m1.11.11.1.1.1.1.1.3.3.1" xref="S2.E4.m1.11.11.1.1.1.1.1.3.3.1.cmml">∈</mo><mi mathvariant="normal" id="S2.E4.m1.11.11.1.1.1.1.1.3.3.3" xref="S2.E4.m1.11.11.1.1.1.1.1.3.3.3.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.11.11.1.1.1.1.1.2" xref="S2.E4.m1.11.11.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.1.1.1" xref="S2.E4.m1.11.11.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.2" xref="S2.E4.m1.11.11.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.cmml"><mi mathvariant="normal" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.2" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.1" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.3.2" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.3.2.1" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.cmml">(</mo><mi mathvariant="normal" id="S2.E4.m1.6.6" xref="S2.E4.m1.6.6.cmml">x</mi><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.3.2.2" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.1.cmml">≠</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.cmml"><msup id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.cmml"><mi mathvariant="normal" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.2" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.2.cmml">f</mi><mo id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.3" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.3.cmml">′</mo></msup><mo lspace="0em" rspace="0em" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.1" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.3.2" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.3.2.1" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.cmml">(</mo><mi mathvariant="normal" id="S2.E4.m1.7.7" xref="S2.E4.m1.7.7.cmml">x</mi><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.3.2.2" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.3" xref="S2.E4.m1.11.11.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E4.m1.11.11.1.1.1.1.3" xref="S2.E4.m1.11.11.1.1.1.1.3.cmml">−</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.2" xref="S2.E4.m1.11.11.1.1.1.1.2.cmml"><msub id="S2.E4.m1.11.11.1.1.1.1.2.3" xref="S2.E4.m1.11.11.1.1.1.1.2.3.cmml"><mi id="S2.E4.m1.11.11.1.1.1.1.2.3.2" xref="S2.E4.m1.11.11.1.1.1.1.2.3.2.cmml">𝔼</mi><mrow id="S2.E4.m1.11.11.1.1.1.1.2.3.3" xref="S2.E4.m1.11.11.1.1.1.1.2.3.3.cmml"><mi mathvariant="normal" id="S2.E4.m1.11.11.1.1.1.1.2.3.3.2" xref="S2.E4.m1.11.11.1.1.1.1.2.3.3.2.cmml">x</mi><mo id="S2.E4.m1.11.11.1.1.1.1.2.3.3.1" xref="S2.E4.m1.11.11.1.1.1.1.2.3.3.1.cmml">∈</mo><mi mathvariant="normal" id="S2.E4.m1.11.11.1.1.1.1.2.3.3.3" xref="S2.E4.m1.11.11.1.1.1.1.2.3.3.3.cmml">T</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.11.11.1.1.1.1.2.2" xref="S2.E4.m1.11.11.1.1.1.1.2.2.cmml">​</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.2.1.1" xref="S2.E4.m1.11.11.1.1.1.1.2.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.2" xref="S2.E4.m1.11.11.1.1.1.1.2.1.2.1.cmml">[</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.cmml"><mrow id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.cmml"><mi mathvariant="normal" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.2" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.1" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.1.cmml">​</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.3.2" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.3.2.1" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.cmml">(</mo><mi mathvariant="normal" id="S2.E4.m1.8.8" xref="S2.E4.m1.8.8.cmml">x</mi><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.3.2.2" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.1" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.1.cmml">≠</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.cmml"><msup id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.cmml"><mi mathvariant="normal" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.2" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.2.cmml">f</mi><mo id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.3" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.3.cmml">′</mo></msup><mo lspace="0em" rspace="0em" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.1" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.1.cmml">​</mo><mrow id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.3.2" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.cmml"><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.3.2.1" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.cmml">(</mo><mi mathvariant="normal" id="S2.E4.m1.9.9" xref="S2.E4.m1.9.9.cmml">x</mi><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.3.2.2" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.3" xref="S2.E4.m1.11.11.1.1.1.1.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E4.m1.11.11.1.1.1.3" xref="S2.E4.m1.11.11.1.1.2.1.cmml">|</mo></mrow></mrow><mo id="S2.E4.m1.12.12.6" xref="S2.E4.m1.12.12.6.cmml">≤</mo><mrow id="S2.E4.m1.12.12.2" xref="S2.E4.m1.12.12.2.cmml"><mn id="S2.E4.m1.12.12.2.3" xref="S2.E4.m1.12.12.2.3.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.E4.m1.12.12.2.2" xref="S2.E4.m1.12.12.2.2.cmml">​</mo><munder accentunder="true" id="S2.E4.m1.3.3" xref="S2.E4.m1.3.3.cmml"><mi id="S2.E4.m1.3.3.2" xref="S2.E4.m1.3.3.2.cmml">sup</mi><mrow id="S2.E4.m1.3.3.1" xref="S2.E4.m1.3.3.1.cmml"><mrow id="S2.E4.m1.3.3.1.3" xref="S2.E4.m1.3.3.1.3.cmml"><mi id="S2.E4.m1.3.3.1.3.2" xref="S2.E4.m1.3.3.1.3.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.3.3.1.3.1" xref="S2.E4.m1.3.3.1.3.1.cmml">​</mo><mrow id="S2.E4.m1.3.3.1.3.3.2" xref="S2.E4.m1.3.3.1.3.cmml"><mo stretchy="false" id="S2.E4.m1.3.3.1.3.3.2.1" xref="S2.E4.m1.3.3.1.3.cmml">(</mo><mi mathvariant="normal" id="S2.E4.m1.3.3.1.1" xref="S2.E4.m1.3.3.1.1.cmml">h</mi><mo stretchy="false" id="S2.E4.m1.3.3.1.3.3.2.2" xref="S2.E4.m1.3.3.1.3.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.3.3.1.2" xref="S2.E4.m1.3.3.1.2.cmml">∈</mo><msub id="S2.E4.m1.3.3.1.4" xref="S2.E4.m1.3.3.1.4.cmml"><mi mathvariant="normal" id="S2.E4.m1.3.3.1.4.2" xref="S2.E4.m1.3.3.1.4.2.cmml">H</mi><mi mathvariant="normal" id="S2.E4.m1.3.3.1.4.3" xref="S2.E4.m1.3.3.1.4.3.cmml">d</mi></msub></mrow></munder><mo lspace="0em" rspace="0em" id="S2.E4.m1.12.12.2.2a" xref="S2.E4.m1.12.12.2.2.cmml">​</mo><mrow id="S2.E4.m1.12.12.2.1.1" xref="S2.E4.m1.12.12.2.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.12.12.2.1.1.2" xref="S2.E4.m1.12.12.2.1.2.1.cmml">[</mo><mrow id="S2.E4.m1.12.12.2.1.1.1" xref="S2.E4.m1.12.12.2.1.1.1.cmml"><mrow id="S2.E4.m1.12.12.2.1.1.1.2" xref="S2.E4.m1.12.12.2.1.1.1.2.cmml"><mi id="S2.E4.m1.12.12.2.1.1.1.2.2" xref="S2.E4.m1.12.12.2.1.1.1.2.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.12.12.2.1.1.1.2.1" xref="S2.E4.m1.12.12.2.1.1.1.2.1.cmml">​</mo><mrow id="S2.E4.m1.12.12.2.1.1.1.2.3.2" xref="S2.E4.m1.12.12.2.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.12.12.2.1.1.1.2.3.2.1" xref="S2.E4.m1.12.12.2.1.1.1.2.cmml">(</mo><mi mathvariant="normal" id="S2.E4.m1.10.10" xref="S2.E4.m1.10.10.cmml">h</mi><mo stretchy="false" id="S2.E4.m1.12.12.2.1.1.1.2.3.2.2" xref="S2.E4.m1.12.12.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.12.12.2.1.1.1.1" xref="S2.E4.m1.12.12.2.1.1.1.1.cmml">−</mo><mn id="S2.E4.m1.12.12.2.1.1.1.3" xref="S2.E4.m1.12.12.2.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.E4.m1.12.12.2.1.1.3" xref="S2.E4.m1.12.12.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.12b"><apply id="S2.E4.m1.12.12.cmml" xref="S2.E4.m1.12.12"><and id="S2.E4.m1.12.12a.cmml" xref="S2.E4.m1.12.12"></and><apply id="S2.E4.m1.12.12b.cmml" xref="S2.E4.m1.12.12"><eq id="S2.E4.m1.12.12.5.cmml" xref="S2.E4.m1.12.12.5"></eq><apply id="S2.E4.m1.12.12.4.cmml" xref="S2.E4.m1.12.12.4"><times id="S2.E4.m1.12.12.4.1.cmml" xref="S2.E4.m1.12.12.4.1"></times><apply id="S2.E4.m1.12.12.4.2.cmml" xref="S2.E4.m1.12.12.4.2"><csymbol cd="ambiguous" id="S2.E4.m1.12.12.4.2.1.cmml" xref="S2.E4.m1.12.12.4.2">subscript</csymbol><ci id="S2.E4.m1.12.12.4.2.2.cmml" xref="S2.E4.m1.12.12.4.2.2">𝑑</ci><apply id="S2.E4.m1.12.12.4.2.3.cmml" xref="S2.E4.m1.12.12.4.2.3"><times id="S2.E4.m1.12.12.4.2.3.1.cmml" xref="S2.E4.m1.12.12.4.2.3.1"></times><apply id="S2.E4.m1.12.12.4.2.3.2.cmml" xref="S2.E4.m1.12.12.4.2.3.2"><csymbol cd="ambiguous" id="S2.E4.m1.12.12.4.2.3.2.1.cmml" xref="S2.E4.m1.12.12.4.2.3.2">subscript</csymbol><ci id="S2.E4.m1.12.12.4.2.3.2.2.cmml" xref="S2.E4.m1.12.12.4.2.3.2.2">H</ci><ci id="S2.E4.m1.12.12.4.2.3.2.3.cmml" xref="S2.E4.m1.12.12.4.2.3.2.3">p</ci></apply><ci id="S2.E4.m1.12.12.4.2.3.3.cmml" xref="S2.E4.m1.12.12.4.2.3.3">Δ</ci><apply id="S2.E4.m1.12.12.4.2.3.4.cmml" xref="S2.E4.m1.12.12.4.2.3.4"><csymbol cd="ambiguous" id="S2.E4.m1.12.12.4.2.3.4.1.cmml" xref="S2.E4.m1.12.12.4.2.3.4">subscript</csymbol><ci id="S2.E4.m1.12.12.4.2.3.4.2.cmml" xref="S2.E4.m1.12.12.4.2.3.4.2">H</ci><ci id="S2.E4.m1.12.12.4.2.3.4.3.cmml" xref="S2.E4.m1.12.12.4.2.3.4.3">p</ci></apply></apply></apply><interval closure="open" id="S2.E4.m1.12.12.4.3.1.cmml" xref="S2.E4.m1.12.12.4.3.2"><ci id="S2.E4.m1.4.4.cmml" xref="S2.E4.m1.4.4">D</ci><ci id="S2.E4.m1.5.5.cmml" xref="S2.E4.m1.5.5">T</ci></interval></apply><apply id="S2.E4.m1.11.11.1.cmml" xref="S2.E4.m1.11.11.1"><times id="S2.E4.m1.11.11.1.2.cmml" xref="S2.E4.m1.11.11.1.2"></times><apply id="S2.E4.m1.2.2.cmml" xref="S2.E4.m1.2.2"><apply id="S2.E4.m1.2.2.2.cmml" xref="S2.E4.m1.2.2.2"><in id="S2.E4.m1.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.3"></in><list id="S2.E4.m1.2.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2.1"><ci id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1">f</ci><apply id="S2.E4.m1.2.2.2.2.1.1.cmml" xref="S2.E4.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.1.1.1.cmml" xref="S2.E4.m1.2.2.2.2.1.1">superscript</csymbol><ci id="S2.E4.m1.2.2.2.2.1.1.2.cmml" xref="S2.E4.m1.2.2.2.2.1.1.2">f</ci><ci id="S2.E4.m1.2.2.2.2.1.1.3.cmml" xref="S2.E4.m1.2.2.2.2.1.1.3">′</ci></apply></list><apply id="S2.E4.m1.2.2.2.4.cmml" xref="S2.E4.m1.2.2.2.4"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.4.1.cmml" xref="S2.E4.m1.2.2.2.4">subscript</csymbol><ci id="S2.E4.m1.2.2.2.4.2.cmml" xref="S2.E4.m1.2.2.2.4.2">H</ci><ci id="S2.E4.m1.2.2.2.4.3.cmml" xref="S2.E4.m1.2.2.2.4.3">p</ci></apply></apply><ci id="S2.E4.m1.2.2.3.cmml" xref="S2.E4.m1.2.2.3">sup</ci></apply><apply id="S2.E4.m1.11.11.1.1.2.cmml" xref="S2.E4.m1.11.11.1.1.1"><abs id="S2.E4.m1.11.11.1.1.2.1.cmml" xref="S2.E4.m1.11.11.1.1.1.2"></abs><apply id="S2.E4.m1.11.11.1.1.1.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1"><minus id="S2.E4.m1.11.11.1.1.1.1.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.3"></minus><apply id="S2.E4.m1.11.11.1.1.1.1.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1"><times id="S2.E4.m1.11.11.1.1.1.1.1.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.2"></times><apply id="S2.E4.m1.11.11.1.1.1.1.1.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.11.11.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.11.11.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.3.2">𝔼</ci><apply id="S2.E4.m1.11.11.1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.3.3"><in id="S2.E4.m1.11.11.1.1.1.1.1.3.3.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.3.3.1"></in><ci id="S2.E4.m1.11.11.1.1.1.1.1.3.3.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.3.3.2">x</ci><ci id="S2.E4.m1.11.11.1.1.1.1.1.3.3.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.3.3.3">D</ci></apply></apply><apply id="S2.E4.m1.11.11.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.11.11.1.1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1"><neq id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.1"></neq><apply id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2"><times id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.1"></times><ci id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.2.2">f</ci><ci id="S2.E4.m1.6.6.cmml" xref="S2.E4.m1.6.6">x</ci></apply><apply id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3"><times id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.1"></times><apply id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2">superscript</csymbol><ci id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.2">f</ci><ci id="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.1.1.1.1.3.2.3">′</ci></apply><ci id="S2.E4.m1.7.7.cmml" xref="S2.E4.m1.7.7">x</ci></apply></apply></apply></apply><apply id="S2.E4.m1.11.11.1.1.1.1.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2"><times id="S2.E4.m1.11.11.1.1.1.1.2.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.2"></times><apply id="S2.E4.m1.11.11.1.1.1.1.2.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E4.m1.11.11.1.1.1.1.2.3.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E4.m1.11.11.1.1.1.1.2.3.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.3.2">𝔼</ci><apply id="S2.E4.m1.11.11.1.1.1.1.2.3.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.3.3"><in id="S2.E4.m1.11.11.1.1.1.1.2.3.3.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.3.3.1"></in><ci id="S2.E4.m1.11.11.1.1.1.1.2.3.3.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.3.3.2">x</ci><ci id="S2.E4.m1.11.11.1.1.1.1.2.3.3.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.3.3.3">T</ci></apply></apply><apply id="S2.E4.m1.11.11.1.1.1.1.2.1.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1"><csymbol cd="latexml" id="S2.E4.m1.11.11.1.1.1.1.2.1.2.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.2">delimited-[]</csymbol><apply id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1"><neq id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.1"></neq><apply id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2"><times id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.1"></times><ci id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.2.2">f</ci><ci id="S2.E4.m1.8.8.cmml" xref="S2.E4.m1.8.8">x</ci></apply><apply id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3"><times id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.1"></times><apply id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.1.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2">superscript</csymbol><ci id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.2.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.2">f</ci><ci id="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.3.cmml" xref="S2.E4.m1.11.11.1.1.1.1.2.1.1.1.3.2.3">′</ci></apply><ci id="S2.E4.m1.9.9.cmml" xref="S2.E4.m1.9.9">x</ci></apply></apply></apply></apply></apply></apply></apply></apply><apply id="S2.E4.m1.12.12c.cmml" xref="S2.E4.m1.12.12"><leq id="S2.E4.m1.12.12.6.cmml" xref="S2.E4.m1.12.12.6"></leq><share href="#S2.E4.m1.11.11.1.cmml" id="S2.E4.m1.12.12d.cmml" xref="S2.E4.m1.12.12"></share><apply id="S2.E4.m1.12.12.2.cmml" xref="S2.E4.m1.12.12.2"><times id="S2.E4.m1.12.12.2.2.cmml" xref="S2.E4.m1.12.12.2.2"></times><cn type="integer" id="S2.E4.m1.12.12.2.3.cmml" xref="S2.E4.m1.12.12.2.3">2</cn><apply id="S2.E4.m1.3.3.cmml" xref="S2.E4.m1.3.3"><apply id="S2.E4.m1.3.3.1.cmml" xref="S2.E4.m1.3.3.1"><in id="S2.E4.m1.3.3.1.2.cmml" xref="S2.E4.m1.3.3.1.2"></in><apply id="S2.E4.m1.3.3.1.3.cmml" xref="S2.E4.m1.3.3.1.3"><times id="S2.E4.m1.3.3.1.3.1.cmml" xref="S2.E4.m1.3.3.1.3.1"></times><ci id="S2.E4.m1.3.3.1.3.2.cmml" xref="S2.E4.m1.3.3.1.3.2">𝛼</ci><ci id="S2.E4.m1.3.3.1.1.cmml" xref="S2.E4.m1.3.3.1.1">h</ci></apply><apply id="S2.E4.m1.3.3.1.4.cmml" xref="S2.E4.m1.3.3.1.4"><csymbol cd="ambiguous" id="S2.E4.m1.3.3.1.4.1.cmml" xref="S2.E4.m1.3.3.1.4">subscript</csymbol><ci id="S2.E4.m1.3.3.1.4.2.cmml" xref="S2.E4.m1.3.3.1.4.2">H</ci><ci id="S2.E4.m1.3.3.1.4.3.cmml" xref="S2.E4.m1.3.3.1.4.3">d</ci></apply></apply><ci id="S2.E4.m1.3.3.2.cmml" xref="S2.E4.m1.3.3.2">sup</ci></apply><apply id="S2.E4.m1.12.12.2.1.2.cmml" xref="S2.E4.m1.12.12.2.1.1"><csymbol cd="latexml" id="S2.E4.m1.12.12.2.1.2.1.cmml" xref="S2.E4.m1.12.12.2.1.1.2">delimited-[]</csymbol><apply id="S2.E4.m1.12.12.2.1.1.1.cmml" xref="S2.E4.m1.12.12.2.1.1.1"><minus id="S2.E4.m1.12.12.2.1.1.1.1.cmml" xref="S2.E4.m1.12.12.2.1.1.1.1"></minus><apply id="S2.E4.m1.12.12.2.1.1.1.2.cmml" xref="S2.E4.m1.12.12.2.1.1.1.2"><times id="S2.E4.m1.12.12.2.1.1.1.2.1.cmml" xref="S2.E4.m1.12.12.2.1.1.1.2.1"></times><ci id="S2.E4.m1.12.12.2.1.1.1.2.2.cmml" xref="S2.E4.m1.12.12.2.1.1.1.2.2">𝛼</ci><ci id="S2.E4.m1.10.10.cmml" xref="S2.E4.m1.10.10">h</ci></apply><cn type="integer" id="S2.E4.m1.12.12.2.1.1.1.3.cmml" xref="S2.E4.m1.12.12.2.1.1.1.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.12c">d_{\pazocal{H}_{p}\Delta\pazocal{H}_{p}}(\pazocal{D},\pazocal{T})=\underset{f,f^{\prime}\in\pazocal{H}_{p}}{\mathrm{sup}}|\mathbb{E}_{x\in\pazocal{D}}[f(x)\neq f^{\prime}(x)]-\mathbb{E}_{x\in\pazocal{T}}[f(x)\neq f^{\prime}(x)]|\leq 2\underset{\alpha(h)\in\pazocal{H}_{d}}{\mathrm{sup}}[\alpha(h)-1]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS4.SSS0.Px1.p1.30">여기서, <math alttext="\alpha(h)" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.27.m1.1"><semantics id="S2.SS4.SSS0.Px1.p1.27.m1.1a"><mrow id="S2.SS4.SSS0.Px1.p1.27.m1.1.2" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.2.cmml"><mi id="S2.SS4.SSS0.Px1.p1.27.m1.1.2.2" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.2.2.cmml">α</mi><mo id="S2.SS4.SSS0.Px1.p1.27.m1.1.2.1" lspace="0em" rspace="0em" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.2.1.cmml">​</mo><mrow id="S2.SS4.SSS0.Px1.p1.27.m1.1.2.3.2" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.2.cmml"><mo id="S2.SS4.SSS0.Px1.p1.27.m1.1.2.3.2.1" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.2.cmml">(</mo><mi id="S2.SS4.SSS0.Px1.p1.27.m1.1.1" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.1.cmml">h</mi><mo id="S2.SS4.SSS0.Px1.p1.27.m1.1.2.3.2.2" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.27.m1.1b"><apply id="S2.SS4.SSS0.Px1.p1.27.m1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.2"><times id="S2.SS4.SSS0.Px1.p1.27.m1.1.2.1.cmml" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.2.1"></times><ci id="S2.SS4.SSS0.Px1.p1.27.m1.1.2.2.cmml" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.2.2">𝛼</ci><ci id="S2.SS4.SSS0.Px1.p1.27.m1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.27.m1.1.1">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.27.m1.1c">\alpha(h)</annotation></semantics></math>는 최적의 도메인 분류기이고, <math alttext="\pazocal{H}_{d}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.28.m2.1"><semantics id="S2.SS4.SSS0.Px1.p1.28.m2.1a"><msub id="S2.SS4.SSS0.Px1.p1.28.m2.1.1" xref="S2.SS4.SSS0.Px1.p1.28.m2.1.1.cmml"><mi id="S2.SS4.SSS0.Px1.p1.28.m2.1.1.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.28.m2.1.1.2.cmml">H</mi><mi id="S2.SS4.SSS0.Px1.p1.28.m2.1.1.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.28.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.28.m2.1b"><apply id="S2.SS4.SSS0.Px1.p1.28.m2.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.28.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.28.m2.1.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.28.m2.1.1">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.28.m2.1.1.2.cmml" xref="S2.SS4.SSS0.Px1.p1.28.m2.1.1.2">H</ci><ci id="S2.SS4.SSS0.Px1.p1.28.m2.1.1.3.cmml" xref="S2.SS4.SSS0.Px1.p1.28.m2.1.1.3">d</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.28.m2.1c">\pazocal{H}_{d}</annotation></semantics></math>는 도메인 분류기의 가설 공간이다. Zhao et al <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite>는 최소 불일치 거리의 최적 상태 <math alttext="d_{\pazocal{H}_{p}\Delta\pazocal{H}_{p}}(\pazocal{D},\pazocal{T})" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.29.m3.2"><semantics id="S2.SS4.SSS0.Px1.p1.29.m3.2a"><mrow id="S2.SS4.SSS0.Px1.p1.29.m3.2.3" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.cmml"><msub id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.cmml"><mi id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.2" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.2.cmml">d</mi><mrow id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.cmml"><msub id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.cmml"><mi id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.2.cmml">H</mi><mi id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.3.cmml">p</mi></msub><mo id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.1" lspace="0em" rspace="0em" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.1.cmml">​</mo><mi id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.3.cmml">Δ</mi><mo id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.1a" lspace="0em" rspace="0em" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.1.cmml">​</mo><msub id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.cmml"><mi id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.2.cmml">H</mi><mi id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.3" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.3.cmml">p</mi></msub></mrow></msub><mo id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.1" lspace="0em" rspace="0em" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.1.cmml">​</mo><mrow id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.2" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.1.cmml"><mo id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.2.1" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.1.cmml">(</mo><mi id="S2.SS4.SSS0.Px1.p1.29.m3.1.1" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.29.m3.1.1.cmml">D</mi><mo id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.2.2" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.1.cmml">,</mo><mi id="S2.SS4.SSS0.Px1.p1.29.m3.2.2" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.2.cmml">T</mi><mo id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.2.3" stretchy="false" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.29.m3.2b"><apply id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3"><times id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.1"></times><apply id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.1.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.2.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.2">𝑑</ci><apply id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3"><times id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.1"></times><apply id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.1.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.2.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.2">H</ci><ci id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.3.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.2.3">p</ci></apply><ci id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.3.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.3">Δ</ci><apply id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4"><csymbol cd="ambiguous" id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.1.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4">subscript</csymbol><ci id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.2.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.2">H</ci><ci id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.3.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.2.3.4.3">p</ci></apply></apply></apply><interval closure="open" id="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.1.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.3.3.2"><ci id="S2.SS4.SSS0.Px1.p1.29.m3.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.1.1">D</ci><ci id="S2.SS4.SSS0.Px1.p1.29.m3.2.2.cmml" xref="S2.SS4.SSS0.Px1.p1.29.m3.2.2">T</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.29.m3.2c">d_{\pazocal{H}_{p}\Delta\pazocal{H}_{p}}(\pazocal{D},\pazocal{T})</annotation></semantics></math>가 도메인 분류기가 가장 높은 엔트로피 상태를 달성하는 무작위 예측을 가질 때임을 증명한다. 우리는 두 도메인의 샘플에 대한 표현이 가장 유사하여 두 데이터 세트 분포를 구별할 수 없는 무작위 도메인 분류기로 이어질 때 달성된다고 주장한다. 이러한 직관에 의해 동기화된, 우리는 태스크 데이터세트 <math alttext="\pazocal{T}" class="ltx_Math" display="inline" id="S2.SS4.SSS0.Px1.p1.30.m4.1"><semantics id="S2.SS4.SSS0.Px1.p1.30.m4.1a"><mi id="S2.SS4.SSS0.Px1.p1.30.m4.1.1" mathvariant="normal" xref="S2.SS4.SSS0.Px1.p1.30.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS0.Px1.p1.30.m4.1b"><ci id="S2.SS4.SSS0.Px1.p1.30.m4.1.1.cmml" xref="S2.SS4.SSS0.Px1.p1.30.m4.1.1">T</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS0.Px1.p1.30.m4.1c">\pazocal{T}</annotation></semantics></math>와 가장 유사한 표현들을 갖는 샘플들을 선택하는 것에 기초한 전략을 사용할 수 있다. 대용량 말뭉치의 경우 최적의 표현을 얻는 것이 비실용적이기 때문에 데이터세트 유사도의 대용치로 임베딩 유사도를 사용한다.</p>
</div>
</section>
<section id="S2.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.1 </span>Efficient Task-Similar Domain-adaptive Continual Pre-training</h4>

<div id="S2.SS4.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS1.p1.1">우리는 이전의 직관에 기초하여 청색 영역에 의해 주어진 태스크 데이터(적색)에 훨씬 더 가까운 도메인 데이터의 일부를 선택함으로써 최적의 세트 <math alttext="\pazocal{D}^{*}" class="ltx_Math" display="inline" id="S2.SS4.SSS1.p1.1.m1.1"><semantics id="S2.SS4.SSS1.p1.1.m1.1a"><msup id="S2.SS4.SSS1.p1.1.m1.1.1" xref="S2.SS4.SSS1.p1.1.m1.1.1.cmml"><mi id="S2.SS4.SSS1.p1.1.m1.1.1.2" mathvariant="normal" xref="S2.SS4.SSS1.p1.1.m1.1.1.2.cmml">D</mi><mo id="S2.SS4.SSS1.p1.1.m1.1.1.3" xref="S2.SS4.SSS1.p1.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p1.1.m1.1b"><apply id="S2.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p1.1.m1.1.1.1.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1">superscript</csymbol><ci id="S2.SS4.SSS1.p1.1.m1.1.1.2.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1.2">D</ci><times id="S2.SS4.SSS1.p1.1.m1.1.1.3.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p1.1.m1.1c">\pazocal{D}^{*}</annotation></semantics></math>를 형성할 수 있다고 규정한다. 이를 <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS1.p1.1.1">Efficient Task-Similar Domain-adaptive Continual Pre-training</span> (ETS-DACP)라고 한다. 미세 조정 LLM은 많은 양의 지침을 취할 수 있으며, 이는 만드는 데 상당한 비용이 든다. ETS-DACP는 상대적으로 제한된 레이블이 지정되지 않은 작업 데이터를 사용하여 사전 훈련 도메인 코퍼스의 더 큰 풀에서 유사한 샘플을 샘플링함으로써 이러한 상황을 직접 해결한다. 목표 도메인 및 태스크와 밀접하게 일치하는 토큰에 대한 감독되지 않은 훈련이 향상된 성능 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite>로 이어질 수 있음을 보여주는 선행 연구에 동기 부여된다. 따라서 레이블이 지정되지 않은 태스크 데이터에 대해 LLM을 지속적으로 사전 훈련하는 것이 태스크 토큰의 분포에 모델을 적응시키기 때문에 목표 태스크 수행에 도움이 될 수 있다고 가정한다.</p>
</div>
<div id="S2.SS4.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS1.p2.1">우리는 데이터 선택을 수행하기 위해 태스크 데이터의 임베딩과 도메인 코퍼스 샘플 사이의 유사성을 사용한다. 이를 통해 작업 데이터의 분포와 매우 유사한 도메인 말뭉치에서 하위 집합을 선택할 수 있다. 문서 수준의 작업 유사도를 정량화하기 위해 문서 임베딩과 작업 데이터 임베딩 사이의 코사인 유사도를 사용한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>와 같은 이전 작업은 레이블이 지정되지 않은 샘플에 대해 언어 모델(RoBERTa)에서 임베딩을 두 번 계산하므로 LLM에는 실용적이지 않다. 전체 코퍼스에 대해 LLM을 사용하여 임베딩을 계산하는 데 전진 패스가 필요하거나 전체 코퍼스에 대해 LLM을 사전 훈련하는 데 사용하는 계산의 25%가 필요하다. <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS1.p2.1.1">Spacy</span> 모델 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite>를 사용하여 임베딩을 계산합니다. 이 접근법을 통해 작업별 정보와 재무 코퍼스 간의 정렬을 비용 효율적으로 측정할 수 있어 보다 집중되고 목표화된 사전 훈련이 가능하다.</p>
</div>
</section>
<section id="S2.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.2 </span>Efficient Task-Agnostic Domain-adaptive Continual Pre-training</h4>

<div id="S2.SS4.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS2.p1.1">이전 사례에서는 작업 데이터가 제공되는 시나리오를 다루었지만 이 방법에서는 작업 데이터가 없는 시나리오를 탐색합니다. 이 방법은 또한 LLM이 더 넓은 도메인 대신 태스크 데이터에 너무 동조되도록 만드는 ETS-DACP의 한계를 극복한다. 사전 훈련 도메인 데이터의 하위 집합에서 도메인 정보를 얻으려면 두 가지 차원이 중요하다고 규정합니다. <span class="ltx_text ltx_font_bold" id="S2.SS4.SSS2.p1.1.1">novelty</span> 및 <span class="ltx_text ltx_font_bold" id="S2.SS4.SSS2.p1.1.2">diversity</span>입니다.</p>
</div>
<div id="S2.SS4.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS4.SSS2.p2.1.1">Novelty</span>은 이전에 LLM에 의해 보이지 않았던 정보를 참조합니다. LLM에서 기록한 <span class="ltx_text ltx_font_bold" id="S2.SS4.SSS2.p2.1.2">perplexity</span>을 기반으로 문서의 새로움 수준을 측정합니다. 더 높은 복잡도를 갖는 문서들은 원래의 트레이닝 코퍼스에서 덜 표현되고, 따라서 모델에 대한 새로운 지식을 포함할 가능성이 더 높다. 이러한 샘플도 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib3" title="">3</a>]</cite>를 학습하기가 더 어려운 것으로 보고 있다. 따라서 이러한 샘플은 모델이 새로운 정보를 획득하는 데 도움이 되는 지속적인 사전 훈련에 유용할 수 있다.</p>
</div>
<div id="S2.SS4.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS2.p3.1">벤치마크 모델에 대한 복잡성을 직접 평가하면 추론에 훈련 계산의 약 25%가 필요하기 때문에 상당한 비용이 발생한다. 이 비용을 최소화하기 위해, 우리는 문서 복잡도를 계산하기 위한 대리 모델로 피티아-70m를 사용한다. 샘플 데이터 세트를 사용한 예비 실험은 피티아-1B와 피티아-70m에서 얻은 복잡도 사이에 0.97의 강한 상관 관계를 보여준다. 이 높은 상관 관계는 신뢰할 수 있는 대리인으로서 더 작은 모델의 사용을 정당화하여 복잡성을 기반으로 보다 비용 효율적인 샘플링을 가능하게 한다.</p>
</div>
<div id="S2.SS4.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS4.SSS2.p4.1.1">Diversity</span> capture the diversity of distributions of token types in the domain corpus. 다양성은 언어 모델링 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>, <a class="ltx_ref" href="#bib.bib21" title="">21</a>]</cite>에서 교육과정 학습에 관한 관련 연구에서 효과적인 특징으로 나타났다. 토큰 유형을 얻기 위해 품사 태깅(POS)을 사용한다. 엔트로피는 다양성의 가장 좋은 척도 중 하나인 것으로 나타났기 때문에 다양성 척도로 <span class="ltx_text ltx_font_bold" id="S2.SS4.SSS2.p4.1.2">entropy</span> of POS tags <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>를 사용한다.</p>
</div>
</section>
<section id="S2.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.3 </span>Data Sampling Strategy</h4>

<div id="S2.SS4.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS3.p1.1">우리는 관련 샘플의 적극적인 선택을 통해 사전 훈련 데이터를 정제하여 바닐라 DACP를 향상시키기 위해 ETS-DACP와 ETA-DACP를 제안했다. 우리는 두 가지 방법으로 데이터를 선택할 수 있다:</p>
</div>
<section id="S2.SS4.SSS3.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Hard Sampling:</h5>

<div id="S2.SS4.SSS3.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS3.Px1.p1.1">도메인 말뭉치의 샘플을 선택 척도로 순위를 매긴다. 메트릭(들)을 기반으로 도메인 말뭉치에서 상위 k개의 샘플을 선택하며, 여기서 <math alttext="k" class="ltx_Math" display="inline" id="S2.SS4.SSS3.Px1.p1.1.m1.1"><semantics id="S2.SS4.SSS3.Px1.p1.1.m1.1a"><mi id="S2.SS4.SSS3.Px1.p1.1.m1.1.1" xref="S2.SS4.SSS3.Px1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS3.Px1.p1.1.m1.1b"><ci id="S2.SS4.SSS3.Px1.p1.1.m1.1.1.cmml" xref="S2.SS4.SSS3.Px1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS3.Px1.p1.1.m1.1c">k</annotation></semantics></math>는 지속적인 사전 훈련을 위해 사전 결정된 토큰 버짓에 도달하는 데 필요한 샘플 수이다.</p>
</div>
</section>
<section id="S2.SS4.SSS3.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Soft Sampling:</h5>

<div id="S2.SS4.SSS3.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS3.Px2.p1.1">이 경우 말뭉치에 있는 다른 예제를 모두 생략하여 이진 가중치를 부여하는 대신 거리 메트릭을 기반으로 소프트 가중치를 부여한다. 이것은 연속적인 사전 트레이닝이 그림 <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2.1 Financial Corpus Curation ‣ 2 Methodology ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>에서 파란색 영역 밖의 샘플도 볼 수 있게 하여 사전 트레이닝 데이터에 약간의 다양성을 추가한다.</p>
</div>
<div id="S2.SS4.SSS3.Px2.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS4.SSS3.Px2.p2.1">샘플을 선택하기 위해 태스크 데이터와의 유사성(ETS-DACP), 신규성에 대한 프록시로서의 복잡성(ETA-DACP), 토큰 유형 엔트로피(ETA-DACP)로 측정된 다양성(다양성)의 세 가지 차원을 사용한다. 메트릭 값을 샘플링 확률로 변환하기 위해 분위수 범위에 기반한 방법을 제안한다. 이를 위해 먼저 학습 데이터 내의 각 메트릭에 대한 0-100 분위수를 계산한다. 100개의 분위 값을 사용하여 범위를 100개의 구간으로 분할함으로써, 문서들은 그 다음에 그들이 속하는 구간에 대응하는 확률들을 할당받는다. 이 접근 방식은 메트릭을 효과적으로 정규화하여 다양한 메트릭 유형의 집계를 허용합니다.</p>
</div>
</section>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Setup</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Evaluation tasks</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p1.1">본 논문에서는 도메인 적응형 연속 사전 훈련의 효율성을 평가하기 위해 재정 과제에 대한 모델을 평가한다. 우리는 모델을 평가하기 위해 <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">FLARE</span> 프레임워크 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>를 채택한다. FLARE는 다양한 금융 업무를 포함하여 LLM 평가 프레임워크 <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2">lm-evaluation-harness<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">‡</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‡</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote1.1.1.1">‡</span></span><span class="ltx_text ltx_font_upright" id="footnote1.5">https://github.com/EleutherAI/lm-evaluation-harness</span></span></span></span></span>을 확장한다. 우리는 비교를 위해 명령 프롬프트, 데이터 분할 및 메트릭 계산을 따릅니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>, <a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>에서 사용되는 다음 4가지 작업을 고려합니다. (1) <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.3">Financial Phrase Bank</span>. FPB는 금융 뉴스 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib19" title="">19</a>]</cite>에 대한 감정 분류 작업이다. 그 심리는 그 뉴스가 투자자들에 의해 긍정적/중립적/부정적으로 여겨지는지를 반영한다. (2) <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.4">FiQA SA. </span> 금융 뉴스 및 헤드라인 기반의 애스펙트 기반 감정 분류 태스크 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>]</cite>. (3) <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.5">Headline. </span> 금융 개체의 헤드라인에 특정 정보가 포함되어 있는지 여부에 대한 이진 분류 작업 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite>. 각각의 뉴스 기사는 “가격인지 아닌지”, “가격 인상”, “가격 인하”, “가격 안정”, “과거 가격”, “자산”과 같은 9개의 태그와 연관된다. (4) <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.6">NER. </span> Financial named entity extraction task is based on credit risk assessment section of SEC report. 이 작업의 단어에는 PER, LOC, ORG 및 MISC가 주석이 달려 있다.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Training Setup and Infrastructure</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p1.1">벤치마크 사전 훈련된 LLM 모델의 경우 피티아 제품군 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>]</cite>에서 1B 및 6.9B 매개변수 모델을 선택한다. 피티아 모델 제품군은 7천만에서 120억 개의 매개변수에 이르는 다양한 모델 크기를 제공합니다. 지속적인 사전 트레이닝 구성은 피티아의 트레이닝 셋업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>]</cite>로부터 맞춤화된다. 구체적으로, 핀피티아-6.9B의 경우 1.2e-05의 학습률을, <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">FinPythia-1B</span>의 경우 3e-05의 학습률을 설정하였는데, 이는 원래 일정에서 가장 적은 학습률이다. 우리는 재앙적인 망각을 완화하기 위해 작은 학습률을 사용한다. 효율적인 사전 교육을 위해 과정 내내 일정하게 유지합니다. 우리는 피티아에서 사용되는 fp16이 아닌 bf16의 정밀도를 사용한다. 원래 배치 크기의 절반을 512로 줄였습니다.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2311.08545/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="166" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>:</span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Training loss of FinPythia-6.9B. FinPythia-6.9B는 파일 손실을 약간 희생시키면서 재무 코퍼스의 상당한 손실 감소를 달성한다. </span></figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p2.1">우리는 AWS SageMaker를 통해 하나의 P4d.24xlarge 인스턴스에 대해 지속적인 사전 훈련 작업을 실행합니다. 모델 크기가 중간이므로 활성화 체크포인팅이 활성화된 DeepSpeed ZeRO Stage 2 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>를 통한 데이터 병렬성만 사용합니다. 핀피티아-6.9B는 사전 훈련까지 18일, 핀피티아-1B는 240억 토큰으로 사전 훈련까지 3일이 걸린다.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results and Analysis</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Domain-adaptive Continual Pre-training</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1">사전 훈련 과정을 모니터링하기 위해 재무 코퍼스의 0.1%를 재무 테스트 데이터 세트로 무작위로 샘플링한다. 모델은 파일 테스트 데이터 세트에서도 평가됩니다. FinPythia-6.9B에 대한 손실 궤적은 그림 <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3.2 Training Setup and Infrastructure ‣ 3 Experimental Setup ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에 보고되어 있다. 훈련 손실은 50개의 최적화 단계의 이동 평균을 사용하여 평활화된다. 지속적인 사전 훈련의 초기 단계에서 파이낸셜 테스트(Fin 테스트) 손실의 급격한 감소를 관찰하며, 진행은 스크래치 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>, <a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite>로부터 훈련의 손실 궤적과 유사하게 점진적으로 포화된다. 손실 로그는 도메인 적응형 연속 사전 훈련이 파일 손실의 경미한 증가를 희생시키면서 금융 도메인에 피티아를 채택하는 데 성공한다는 것을 시사한다.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:105.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-79.0pt,19.2pt) scale(0.732842987139534,0.732842987139534) ;">
<table id="S4.T1.5.5" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.5.5.6.1" class="ltx_tr">
<td id="S4.T1.5.5.6.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S4.T1.5.5.6.1.2" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S4.T1.5.5.6.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T1.5.5.6.1.3.1" class="ltx_text ltx_font_bold">BloombergGPT</span></td>
<td id="S4.T1.5.5.6.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.5.5.6.1.4.1" class="ltx_text ltx_font_bold">OPT 7B</span></td>
<td id="S4.T1.5.5.6.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.5.5.6.1.5.1" class="ltx_text ltx_font_bold">BLOOM 7B</span></td>
<td id="S4.T1.5.5.6.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T1.5.5.6.1.6.1" class="ltx_text ltx_font_bold">GPT-J-6B</span></td>
<td id="S4.T1.5.5.6.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.5.5.6.1.7.1" class="ltx_text ltx_font_bold">Pythia 1B</span></td>
<td id="S4.T1.5.5.6.1.8" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.5.5.6.1.8.1" class="ltx_text ltx_font_bold">Pythia 7B</span></td>
<td id="S4.T1.5.5.6.1.9" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.5.5.6.1.9.1" class="ltx_text ltx_font_bold">FinPythia 1B</span></td>
<td id="S4.T1.5.5.6.1.10" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.5.5.6.1.10.1" class="ltx_text ltx_font_bold">FinPythia 7B</span></td>
</tr>
<tr id="S4.T1.5.5.7.2" class="ltx_tr">
<td id="S4.T1.5.5.7.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.5.5.7.2.1.1" class="ltx_text ltx_font_bold">FPB</span></td>
<td id="S4.T1.5.5.7.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Acc</td>
<td id="S4.T1.5.5.7.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S4.T1.5.5.7.2.4" class="ltx_td ltx_align_center ltx_border_t">57.22</td>
<td id="S4.T1.5.5.7.2.5" class="ltx_td ltx_align_center ltx_border_t">52.68</td>
<td id="S4.T1.5.5.7.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50.21</td>
<td id="S4.T1.5.5.7.2.7" class="ltx_td ltx_align_center ltx_border_t">42.85</td>
<td id="S4.T1.5.5.7.2.8" class="ltx_td ltx_align_center ltx_border_t">54.64</td>
<td id="S4.T1.5.5.7.2.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.5.5.7.2.9.1" class="ltx_text ltx_framed ltx_framed_underline">47.14</span></td>
<td id="S4.T1.5.5.7.2.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.5.5.7.2.10.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">59.90</span></td>
</tr>
<tr id="S4.T1.1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.2" class="ltx_td"></td>
<td id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r">F1</td>
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r">51.07<sup id="S4.T1.1.1.1.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S4.T1.1.1.1.4" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.1.4.1" class="ltx_text ltx_font_bold">65.77</span></td>
<td id="S4.T1.1.1.1.5" class="ltx_td ltx_align_center">52.11</td>
<td id="S4.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r">49.31</td>
<td id="S4.T1.1.1.1.7" class="ltx_td ltx_align_center">4.394</td>
<td id="S4.T1.1.1.1.8" class="ltx_td ltx_align_center">55.79</td>
<td id="S4.T1.1.1.1.9" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.1.9.1" class="ltx_text ltx_framed ltx_framed_underline">46.52</span></td>
<td id="S4.T1.1.1.1.10" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.1.10.1" class="ltx_text ltx_framed ltx_framed_underline">64.43</span></td>
</tr>
<tr id="S4.T1.5.5.8.3" class="ltx_tr">
<td id="S4.T1.5.5.8.3.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.5.5.8.3.1.1" class="ltx_text ltx_font_bold">FiQA SA</span></td>
<td id="S4.T1.5.5.8.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Acc</td>
<td id="S4.T1.5.5.8.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S4.T1.5.5.8.3.4" class="ltx_td ltx_align_center ltx_border_t">40.43</td>
<td id="S4.T1.5.5.8.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.5.5.8.3.5.1" class="ltx_text ltx_font_bold">70.21</span></td>
<td id="S4.T1.5.5.8.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.42</td>
<td id="S4.T1.5.5.8.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.5.5.8.3.7.1" class="ltx_text ltx_framed ltx_framed_underline">54.51</span></td>
<td id="S4.T1.5.5.8.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.5.5.8.3.8.1" class="ltx_text ltx_framed ltx_framed_underline">60.85</span></td>
<td id="S4.T1.5.5.8.3.9" class="ltx_td ltx_align_center ltx_border_t">46.13</td>
<td id="S4.T1.5.5.8.3.10" class="ltx_td ltx_align_center ltx_border_t">52.34</td>
</tr>
<tr id="S4.T1.2.2.2" class="ltx_tr">
<td id="S4.T1.2.2.2.2" class="ltx_td"></td>
<td id="S4.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r">F1</td>
<td id="S4.T1.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r">75.07<sup id="S4.T1.2.2.2.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S4.T1.2.2.2.4" class="ltx_td ltx_align_center">31.29</td>
<td id="S4.T1.2.2.2.5" class="ltx_td ltx_align_center"><span id="S4.T1.2.2.2.5.1" class="ltx_text ltx_font_bold">74.11</span></td>
<td id="S4.T1.2.2.2.6" class="ltx_td ltx_align_center ltx_border_r">62.14</td>
<td id="S4.T1.2.2.2.7" class="ltx_td ltx_align_center"><span id="S4.T1.2.2.2.7.1" class="ltx_text ltx_framed ltx_framed_underline">56.29</span></td>
<td id="S4.T1.2.2.2.8" class="ltx_td ltx_align_center"><span id="S4.T1.2.2.2.8.1" class="ltx_text ltx_framed ltx_framed_underline">61.33</span></td>
<td id="S4.T1.2.2.2.9" class="ltx_td ltx_align_center">44.53</td>
<td id="S4.T1.2.2.2.10" class="ltx_td ltx_align_center">53.04</td>
</tr>
<tr id="S4.T1.3.3.3" class="ltx_tr">
<td id="S4.T1.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.3.3.2.1" class="ltx_text ltx_font_bold">Headline</span></td>
<td id="S4.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">F1</td>
<td id="S4.T1.3.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">82.20<sup id="S4.T1.3.3.3.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S4.T1.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.3.3.4.1" class="ltx_text ltx_font_bold">62.62</span></td>
<td id="S4.T1.3.3.3.5" class="ltx_td ltx_align_center ltx_border_t">42.68</td>
<td id="S4.T1.3.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">45.54</td>
<td id="S4.T1.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t">44.73</td>
<td id="S4.T1.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t">43.83</td>
<td id="S4.T1.3.3.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.3.3.9.1" class="ltx_text ltx_framed ltx_framed_underline">53.02</span></td>
<td id="S4.T1.3.3.3.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.3.3.10.1" class="ltx_text ltx_framed ltx_framed_underline">54.14</span></td>
</tr>
<tr id="S4.T1.4.4.4" class="ltx_tr">
<td id="S4.T1.4.4.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.4.4.2.1" class="ltx_text ltx_font_bold">NER</span></td>
<td id="S4.T1.4.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">F1</td>
<td id="S4.T1.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.82<sup id="S4.T1.4.4.4.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S4.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">41.91</td>
<td id="S4.T1.4.4.4.5" class="ltx_td ltx_align_center ltx_border_t">18.97</td>
<td id="S4.T1.4.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">35.87</td>
<td id="S4.T1.4.4.4.7" class="ltx_td ltx_align_center ltx_border_t">49.15</td>
<td id="S4.T1.4.4.4.8" class="ltx_td ltx_align_center ltx_border_t">41.60</td>
<td id="S4.T1.4.4.4.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.4.4.9.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">55.51</span></td>
<td id="S4.T1.4.4.4.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.4.4.10.1" class="ltx_text ltx_framed ltx_framed_underline">48.42</span></td>
</tr>
<tr id="S4.T1.5.5.5" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S4.T1.5.5.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T1.5.5.5.2.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">Average</span></td>
<td id="S4.T1.5.5.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S4.T1.5.5.5.3.1" class="ltx_text" style="background-color:#E6E6E6;">F1</span></td>
<td id="S4.T1.5.5.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S4.T1.5.5.5.1.1" class="ltx_text" style="background-color:#E6E6E6;">67.29<sup id="S4.T1.5.5.5.1.1.1" class="ltx_sup">∗</sup></span></td>
<td id="S4.T1.5.5.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T1.5.5.5.4.1" class="ltx_text" style="background-color:#E6E6E6;">50.40</span></td>
<td id="S4.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T1.5.5.5.5.1" class="ltx_text" style="background-color:#E6E6E6;">46.97</span></td>
<td id="S4.T1.5.5.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S4.T1.5.5.5.6.1" class="ltx_text" style="background-color:#E6E6E6;">48.22</span></td>
<td id="S4.T1.5.5.5.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T1.5.5.5.7.1" class="ltx_text" style="background-color:#E6E6E6;">48.53</span></td>
<td id="S4.T1.5.5.5.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T1.5.5.5.8.1" class="ltx_text" style="background-color:#E6E6E6;">50.64</span></td>
<td id="S4.T1.5.5.5.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T1.5.5.5.9.1" class="ltx_text ltx_framed ltx_framed_underline" style="background-color:#E6E6E6;">49.90</span></td>
<td id="S4.T1.5.5.5.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T1.5.5.5.10.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="background-color:#E6E6E6;">54.83</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.11.2.1" style="font-size:90%;">Table 1</span>:</span><span class="ltx_text" id="S4.T1.7.1" style="font-size:90%;">5-shot results on financial tasks from domain adaptive continual pre-training. <math alttext="*" class="ltx_Math" display="inline" id="S4.T1.7.1.m1.1"><semantics id="S4.T1.7.1.m1.1b"><mo id="S4.T1.7.1.m1.1.1" xref="S4.T1.7.1.m1.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.1.m1.1c"><times id="S4.T1.7.1.m1.1.1.cmml" xref="S4.T1.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.1.m1.1d">*</annotation></semantics></math>는 BloombergGPT <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>로부터 결과가 보고됨을 나타내며, 이는 서로 다른 프롬프트 및 데이터 분할로 평가되었기 때문에 비교할 수 없다. 이 값은 다른 값과 직접 비교할 수 없습니다. <span class="ltx_text ltx_font_bold" id="S4.T1.7.1.1">Bold</span>은 BloombergGPT를 제외한 모든 평가 모델 중 가장 좋은 결과를 나타낸다. <span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.7.1.2">Underline</span>은 동일한 크기의 FinPythia와 Pythia 사이의 더 나은 결과를 나타낸다. </span></figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p2.1">재무 영역 과제를 평가하기 위해 핀피티아를 유사한 크기의 피티아 및 기타 오픈 소스 모델과 비교한다. 벤치마크 모델로는 OPT-7B <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>, BLOOM-7B <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>, GPT-J-6B <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>]</cite>가 있다. 오픈 소스 모델의 결과를 보고하지만 주요 통찰력은 피티아와 핀피티아의 비교에서 얻는데, 그 차이는 도메인 적응 연속 사전 훈련의 효과를 반영하기 때문이다. 모델은 각 작업에 대해 5샷 설정으로 평가됩니다. 샷은 FLARE <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite> 벤치마크에 이어 각 테스트 인스턴스에 대한 태스크의 훈련 데이터 세트에서 무작위로 샘플링된다.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p3.1">결과는 표 <a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ 4.1 Domain-adaptive Continual Pre-training ‣ 4 Results and Analysis ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>에 보고되어 있다. FinPythia-6.9B와 FinPythia-1B는 FPB, Headline, NER 과제에서 우수한 성능을 보인 반면, FiQA SA 과제에서는 피티아에 비해 상대적으로 낮은 결과를 보였다. DACP는 1B 모델의 경우 평균 업무 성과를 2.8%, 6.9B 모델의 경우 8.3% 향상시킨다. 이러한 결과는 도메인 적응적인 지속적인 사전 훈련이 도메인 내 작업 수행 향상에 미치는 영향을 직접적으로 입증한다. 또한 피티아-6.9B는 평균적으로 OPT-7B, BLOOM-7B, GPT-J-6B를 능가한다.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p4.1"><em class="ltx_emph ltx_font_italic" id="S4.SS1.p4.1.1">Comparison with BloombergGPT</em>: The results reported on FLARE are not directly comparable to the results reported in BloombergGPT <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite> on the same tasks, as the data splits are not public. <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>에 의해 보고된 OPT-66B 또는 GPT-NeoX와 같은 공개적으로 사용 가능한 모델의 성능을 네 가지 작업 모두에서 일치시킬 수 없었다. 부록 <a class="ltx_ref" href="#A1" title="Appendix A Benchmark BloombergGPT’s Performance ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">A</span></a>의 결과들 간의 상세한 비교를 참조한다.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.2.1.1" class="ltx_tr">
<td id="S4.T2.2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T2.2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.1.1.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Question:</span><span id="S4.T2.2.1.1.1.1.1.2" class="ltx_text" style="font-size:80%;"> What is a SPAC?</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.2.2" class="ltx_tr">
<td id="S4.T2.2.2.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.2.2.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Pythia6.9B:</span><span id="S4.T2.2.2.2.1.1.1.2" class="ltx_text" style="font-size:80%;"> Spac is an acronym for Space. It is defined as either (1) above, just beneath, below, above, or through a port in the body of a planet, Moon, or other heavenly body; or (2) beyond a star’s sphere of influence, usually in interplanetary space or interstellar space; also, (3) outside the limits of the Milky Way Galaxy.</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.3.3" class="ltx_tr">
<td id="S4.T2.2.3.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.3.3.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.3.3.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">FinPythia-6.9B:</span><span id="S4.T2.2.3.3.1.1.1.2" class="ltx_text" style="font-size:80%;"> A SPAC is a type of merger and acquisition vehicle that is used to raise money from investors, use that money to identify a company that could be valuable to an interested party, then merge with the company and take it public. The use of the SPAC is to give investors a piece of the upside in the acquired company and allows the company to issue shares that may give investors a piece of the upside of the company as well.</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.4.4" class="ltx_tr">
<td id="S4.T2.2.4.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.4.4.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.4.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Question:</span><span id="S4.T2.2.4.4.1.1.1.2" class="ltx_text" style="font-size:80%;"> Who is Cathie Wood?</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.5.5" class="ltx_tr">
<td id="S4.T2.2.5.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.5.5.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.5.5.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Pythia-6.9B:</span><span id="S4.T2.2.5.5.1.1.1.2" class="ltx_text" style="font-size:80%;"> Cathie Wood is the founder of All Things Organic, an organic marketing company that she founded in 2000. In addition to being an organic marketer, Cathie is also a Certified Coach, foodie, cook, a past lover of yoga, a certified teacher, mother and wife to three gorgeous children.</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.6.6" class="ltx_tr">
<td id="S4.T2.2.6.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.6.6.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.6.6.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">FinPythia-6.9B:</span><span id="S4.T2.2.6.6.1.1.1.2" class="ltx_text" style="font-size:80%;"> Cathie Wood is an American investor and advisor, the founder and chief executive officer of Ark Investment Management.</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.7.7" class="ltx_tr">
<td id="S4.T2.2.7.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.7.7.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.7.7.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Question:</span><span id="S4.T2.2.7.7.1.1.1.2" class="ltx_text" style="font-size:80%;"> How do you like Fed’s latest policy to fight inflation?</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.8.8" class="ltx_tr">
<td id="S4.T2.2.8.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.8.8.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.8.8.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Pythia6.9B:</span><span id="S4.T2.2.8.8.1.1.1.2" class="ltx_text" style="font-size:80%;"> I like Fed’s latest policy to fight inflation, which was reported by Tyler. Fed’s latest policy was reported in a meeting on September 12 and it was named as SOMO, which stood for Standardized Open Market Operations. According to the policy, the U.S. central bank could buy $40 billion worth of financial instruments if the price of the instruments reach 6 percent.</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.9.9" class="ltx_tr">
<td id="S4.T2.2.9.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.9.9.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.9.9.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">FinPythia-6.9B:</span><span id="S4.T2.2.9.9.1.1.1.2" class="ltx_text" style="font-size:80%;"> There is a big confusion about Fed’s new policy to fight inflation. They are following a new policy from September 2022 called the fastest quarter-percentage point rate hikes in two decades to fight the ”costly” inflation which is the 8.5 percent rate of increase in food and energy prices that may aggravate inflation and lead to recession in the near future.</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.10.10" class="ltx_tr">
<td id="S4.T2.2.10.10.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.10.10.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.10.10.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Question:</span><span id="S4.T2.2.10.10.1.1.1.2" class="ltx_text" style="font-size:80%;"> What is the difference between bond and stock in terms of risk profile?</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.11.11" class="ltx_tr">
<td id="S4.T2.2.11.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.2.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.11.11.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.11.11.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Pythia-6.9B: </span><span id="S4.T2.2.11.11.1.1.1.2" class="ltx_text" style="font-size:80%;"> Stock is less risky (you can liquidate your shares anytime) but bond is more risky (you can’t liquidate).</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.2.12.12" class="ltx_tr">
<td id="S4.T2.2.12.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T2.2.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.12.12.1.1.1" class="ltx_p" style="width:416.3pt;"><span id="S4.T2.2.12.12.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">FinPythia-6.9B: </span><span id="S4.T2.2.12.12.1.1.1.2" class="ltx_text" style="font-size:80%;"> When you buy a bond, you receive a set of fixed payments from the issuer at a regular interval over a fixed term. You take on the full risk of the coupon payments not being made, so a bond is always considered to be a lower risk debt instrument than a stock. However, a stock is a more liquid investment than a bond. When buying a stock, you are buying shares in the company that the bond represents and you hold on to the stock until you want to cash out, and it can be used as collateral to borrow money.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.5.1.1" style="font-size:113%;">Table 2</span>:</span><span class="ltx_text" id="S4.T2.6.2" style="font-size:113%;">Generation examples from Pythia-6.9B and FinPythia-6.9B. 우리는 핀피티아의 2021년 이후 업데이트된 금융 사건 지식을 관찰하여 마지막 예에서와 같이 추론과 함께 사실적 답변을 제공한다. </span></figcaption>
</figure>
<div id="S4.SS1.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p5.1"><em class="ltx_emph ltx_font_italic" id="S4.SS1.p5.1.1">Qualitative Evaluation</em>: Pythia-6.9B 및 FinPythia-6.9B에 의해 생성된 정성적 예들이 표 <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4.1 Domain-adaptive Continual Pre-training ‣ 4 Results and Analysis ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에 제시되어 있다. 조사 결과, 핀피티아-6.9B는 금융 관련 질문에 대해 더 적절하고 상세한 응답을 생성한다는 것을 관찰한다. 지속적인 사전 교육을 통해 2021년 이후 금융 이벤트 지식을 습득했습니다. 이러한 결과는 DACP가 핀피티아-6.9B가 도메인 내 지식을 습득하는 데 도움이 된다는 것을 시사한다.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Efficient Domain-adaptive Continual Pre-training</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p1.1">FLARE는 전체 훈련 데이터에 대해 5-shot in-context 성능, <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.1">i.e.,</span> 각 모델을 평가하는 동안 각 테스트 예제는 서로 다른 열차 예제를 봅니다. 이것은 또한 각 테스트 예가 모델에 걸쳐 완전히 다른 5개의 훈련 예를 보기 때문에 다른 모델을 비교하는 것을 더 어렵게 만든다. 이러한 무작위성을 극복하고 비교를 더 공정하게 만들기 위해 각 작업에 대한 훈련 데이터 세트에서 50개의 레이블이 지정된 데이터 샘플 풀을 “샷 풀”이라고 한다. 나머지 훈련 샘플의 경우 레이블을 제거하고 레이블이 지정되지 않은 태스크 데이터로 활용하며, 이는 태스크 데이터를 활용한 데이터 선택 전략에 사용된다. 이 특정 구성은 TACP의 효능을 평가하기 위해 레이블이 지정되지 않은 작업 데이터에 액세스할 수 없기 때문에 채택된다. 이 설정을 사용하여 레이블이 지정된 데이터가 부족한 제약 조건도 시뮬레이션합니다. 이 접근법은 TACP에 대한 레이블이 지정되지 않은 작업 데이터를 생성하지만 크기가 너무 작아서 4개의 작업에서 0.24만 토큰만 포함한다.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p2.1">효율적인 DACP 방법을 사용하여 각 방법에 대해 재무 코퍼스의 10% 부분 집합을 선택한다. 또한 <span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">ETS-DACP-com</span>이라는 다른 버전의 ETS-DACP를 만듭니다. 과적합을 완화하기 위해, TACP 및 Efficient DACP 방법은 모두 공정한 비교를 보장하기 위해 DACP와 동일한 사전 트레이닝 구성을 사용하여 단일 에포크에 대해 실행된다. 계산 예산으로 인해 이러한 실험을 피티아-1B로 실행합니다. 우리는 서로 다른 랜덤 시드를 사용하여 평가를 10회 수행하고 4개의 재무 과제 각각에 대한 평균 성능을 보고한다.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p3.1">평가 결과는 표 <a class="ltx_ref" href="#S4.T3" title="Table 3 ‣ 4.2 Efficient Domain-adaptive Continual Pre-training ‣ 4 Results and Analysis ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>에 제시되어 있다. TACP는 원래 Pythia-1B에 비해 모델 성능이 크게 향상되지만 평균 작업 성능 측면에서 DACP, TACP 및 효율적인 DACP 방법 중 ETS-DACP가 최고 성능 접근법으로 눈에 띈다. 이러한 향상된 성능은 동일한 토큰의 양을 가진 DACP가 열등한 결과를 낳기 때문에 토큰의 수 증가에만 기인할 수 없다. 결과는 다른 모델 유형 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite>에서 관찰된 결과와 일치하여 레이블이 지정되지 않은 작업 데이터에 대한 작업 적응형 및 도메인 연속 사전 훈련 LLM의 효능을 강조한다.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p4.1">1) 10%의 데이터로 훈련된 ETS-DACP가 100%의 데이터로 훈련된 DACP보다 성능이 우수하고, 2) ETS-DACP가 3개의 메트릭의 조합과 동등하며, 3) 10%의 코퍼스로 훈련된 ETA-DACP-ent는 태스크 데이터에 대한 접근이 없음에도 불구하고, 100% 데이터로 훈련된 DACP를 쉽게 능가하고, 4) 하드 샘플링을 사용한 효율적인 DACP 방법이 소프트 샘플링을 사용한 방법보다 성능이 우수하다.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:184.5pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-122.7pt,52.0pt) scale(0.63858817993497,0.63858817993497) ;">
<table id="S4.T3.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.2.1.1.1" class="ltx_tr">
<th id="S4.T3.2.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S4.T3.2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.2.1.1.1.2.1" class="ltx_text ltx_font_bold">Tokens</span></td>
<td id="S4.T3.2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T3.2.1.1.1.3.1" class="ltx_text ltx_font_bold">FPB</span></td>
<td id="S4.T3.2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T3.2.1.1.1.4.1" class="ltx_text ltx_font_bold">FiQA SA</span></td>
<td id="S4.T3.2.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.2.1.1.1.5.1" class="ltx_text ltx_font_bold">Headline</span></td>
<td id="S4.T3.2.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.2.1.1.1.6.1" class="ltx_text ltx_font_bold">NER</span></td>
<td id="S4.T3.2.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.1.1.7.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">Average</span></td>
<td id="S4.T3.2.1.1.1.8" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.1.1.8.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">Win Rate (%)</span></td>
</tr>
<tr id="S4.T3.2.1.2.2" class="ltx_tr">
<th id="S4.T3.2.1.2.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T3.2.1.2.2.2" class="ltx_td"></td>
<td id="S4.T3.2.1.2.2.3" class="ltx_td ltx_align_center">Acc</td>
<td id="S4.T3.2.1.2.2.4" class="ltx_td ltx_align_center">F1</td>
<td id="S4.T3.2.1.2.2.5" class="ltx_td ltx_align_center">Acc</td>
<td id="S4.T3.2.1.2.2.6" class="ltx_td ltx_align_center">F1</td>
<td id="S4.T3.2.1.2.2.7" class="ltx_td ltx_align_center">F1</td>
<td id="S4.T3.2.1.2.2.8" class="ltx_td ltx_align_center">F1</td>
<td id="S4.T3.2.1.2.2.9" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.2.2.9.1" class="ltx_text" style="background-color:#E6E6E6;">F1</span></td>
<td id="S4.T3.2.1.2.2.10" class="ltx_td"></td>
</tr>
<tr id="S4.T3.2.1.3.3" class="ltx_tr">
<th id="S4.T3.2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T3.2.1.3.3.1.1" class="ltx_text ltx_font_bold">Pythia 1B</span></th>
<td id="S4.T3.2.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">0</td>
<td id="S4.T3.2.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">41.89 (15.8)</td>
<td id="S4.T3.2.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">52.84 (15.5)</td>
<td id="S4.T3.2.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.2.1.3.3.5.1" class="ltx_text ltx_framed ltx_framed_underline">59.66</span> (10.3)</td>
<td id="S4.T3.2.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">65.32 (13.7)</td>
<td id="S4.T3.2.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">45.61 (10.0)</td>
<td id="S4.T3.2.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">48.77 (13.7)</td>
<td id="S4.T3.2.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.3.3.9.1" class="ltx_text" style="background-color:#E6E6E6;">53.14 (7.5)</span></td>
<td id="S4.T3.2.1.3.3.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.3.3.10.1" class="ltx_text" style="background-color:#E6E6E6;">45.5</span></td>
</tr>
<tr id="S4.T3.2.1.4.4" class="ltx_tr">
<th id="S4.T3.2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T3.2.1.4.4.1.1" class="ltx_text ltx_font_bold">DACP</span></th>
<td id="S4.T3.2.1.4.4.2" class="ltx_td ltx_align_center ltx_border_t">2.39B (10%)</td>
<td id="S4.T3.2.1.4.4.3" class="ltx_td ltx_align_center ltx_border_t">58.06 (8.6)</td>
<td id="S4.T3.2.1.4.4.4" class="ltx_td ltx_align_center ltx_border_t">64.77 (10.4)</td>
<td id="S4.T3.2.1.4.4.5" class="ltx_td ltx_align_center ltx_border_t">53.83 (16.3)</td>
<td id="S4.T3.2.1.4.4.6" class="ltx_td ltx_align_center ltx_border_t">59.85 (19.0)</td>
<td id="S4.T3.2.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t">41.41 (6.5)</td>
<td id="S4.T3.2.1.4.4.8" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.2.1.4.4.8.1" class="ltx_text ltx_framed ltx_framed_underline">51.32</span> (7.6)</td>
<td id="S4.T3.2.1.4.4.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.4.4.9.1" class="ltx_text" style="background-color:#E6E6E6;">54.34 (8.9)</span></td>
<td id="S4.T3.2.1.4.4.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.4.4.10.1" class="ltx_text" style="background-color:#E6E6E6;">59.1</span></td>
</tr>
<tr id="S4.T3.2.1.5.5" class="ltx_tr">
<th id="S4.T3.2.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T3.2.1.5.5.1.1" class="ltx_text ltx_font_bold">DACP</span></th>
<td id="S4.T3.2.1.5.5.2" class="ltx_td ltx_align_center">23.9B (100%)</td>
<td id="S4.T3.2.1.5.5.3" class="ltx_td ltx_align_center">50.86 (14.5)</td>
<td id="S4.T3.2.1.5.5.4" class="ltx_td ltx_align_center">59.16 (12.1)</td>
<td id="S4.T3.2.1.5.5.5" class="ltx_td ltx_align_center">50.17 (17.0)</td>
<td id="S4.T3.2.1.5.5.6" class="ltx_td ltx_align_center">52.84 (18.1)</td>
<td id="S4.T3.2.1.5.5.7" class="ltx_td ltx_align_center">53.34 (9.4)</td>
<td id="S4.T3.2.1.5.5.8" class="ltx_td ltx_align_center">
<span id="S4.T3.2.1.5.5.8.1" class="ltx_text ltx_font_bold">55.20</span> (5.8)</td>
<td id="S4.T3.2.1.5.5.9" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.5.5.9.1" class="ltx_text" style="background-color:#E6E6E6;">55.14 (2.5)</span></td>
<td id="S4.T3.2.1.5.5.10" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.5.5.10.1" class="ltx_text" style="background-color:#E6E6E6;">52.3</span></td>
</tr>
<tr id="S4.T3.2.1.6.6" class="ltx_tr">
<th id="S4.T3.2.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T3.2.1.6.6.1.1" class="ltx_text ltx_font_bold">TACP</span></th>
<td id="S4.T3.2.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t">0.24M</td>
<td id="S4.T3.2.1.6.6.3" class="ltx_td ltx_align_center ltx_border_t">56.94 (.094)</td>
<td id="S4.T3.2.1.6.6.4" class="ltx_td ltx_align_center ltx_border_t">66.80 (10.5)</td>
<td id="S4.T3.2.1.6.6.5" class="ltx_td ltx_align_center ltx_border_t">62.43 (3.2)</td>
<td id="S4.T3.2.1.6.6.6" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.2.1.6.6.6.1" class="ltx_text ltx_framed ltx_framed_underline">72.27</span> (2.2)</td>
<td id="S4.T3.2.1.6.6.7" class="ltx_td ltx_align_center ltx_border_t">38.91 (1.5)</td>
<td id="S4.T3.2.1.6.6.8" class="ltx_td ltx_align_center ltx_border_t">50.55 (11.7)</td>
<td id="S4.T3.2.1.6.6.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.6.6.9.1" class="ltx_text" style="background-color:#E6E6E6;">57.13 (13.2)</span></td>
<td id="S4.T3.2.1.6.6.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.6.6.10.1" class="ltx_text" style="background-color:#E6E6E6;">56.8</span></td>
</tr>
<tr id="S4.T3.2.1.7.7" class="ltx_tr">
<th id="S4.T3.2.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="S4.T3.2.1.7.7.1.1" class="ltx_text ltx_font_bold">Hard Sampling</span></th>
<td id="S4.T3.2.1.7.7.2" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S4.T3.2.1.8.8" class="ltx_tr">
<th id="S4.T3.2.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T3.2.1.8.8.1.1" class="ltx_text ltx_font_bold">ETS-DACP</span></th>
<td id="S4.T3.2.1.8.8.2" class="ltx_td ltx_align_center ltx_border_t">2.39B (10%)</td>
<td id="S4.T3.2.1.8.8.3" class="ltx_td ltx_align_center ltx_border_t">59.93 (6.2)</td>
<td id="S4.T3.2.1.8.8.4" class="ltx_td ltx_align_center ltx_border_t">67.11 (9.6)</td>
<td id="S4.T3.2.1.8.8.5" class="ltx_td ltx_align_center ltx_border_t">46.26 (19.6)</td>
<td id="S4.T3.2.1.8.8.6" class="ltx_td ltx_align_center ltx_border_t">50.84 (21.9)</td>
<td id="S4.T3.2.1.8.8.7" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.2.1.8.8.7.1" class="ltx_text ltx_font_bold">71.56</span> (7.1)</td>
<td id="S4.T3.2.1.8.8.8" class="ltx_td ltx_align_center ltx_border_t">49.52 (8.4)</td>
<td id="S4.T3.2.1.8.8.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;">
<span id="S4.T3.2.1.8.8.9.1" class="ltx_text ltx_font_bold" style="color:#0000FF;background-color:#E6E6E6;">59.76</span><span id="S4.T3.2.1.8.8.9.2" class="ltx_text" style="background-color:#E6E6E6;"> (9.7)</span>
</td>
<td id="S4.T3.2.1.8.8.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.8.8.10.1" class="ltx_text ltx_font_bold" style="color:#0000FF;background-color:#E6E6E6;">63.6</span></td>
</tr>
<tr id="S4.T3.2.1.9.9" class="ltx_tr">
<th id="S4.T3.2.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T3.2.1.9.9.1.1" class="ltx_text ltx_font_bold">ETA-DACP-ppl</span></th>
<td id="S4.T3.2.1.9.9.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S4.T3.2.1.9.9.3" class="ltx_td ltx_align_center">
<span id="S4.T3.2.1.9.9.3.1" class="ltx_text ltx_font_bold">62.73</span> (3.5)</td>
<td id="S4.T3.2.1.9.9.4" class="ltx_td ltx_align_center">
<span id="S4.T3.2.1.9.9.4.1" class="ltx_text ltx_font_bold">73.66</span> (1.9)</td>
<td id="S4.T3.2.1.9.9.5" class="ltx_td ltx_align_center">42.12 (22.3)</td>
<td id="S4.T3.2.1.9.9.6" class="ltx_td ltx_align_center">45.86 (24.9)</td>
<td id="S4.T3.2.1.9.9.7" class="ltx_td ltx_align_center">39.11 (2.0)</td>
<td id="S4.T3.2.1.9.9.8" class="ltx_td ltx_align_center">48.69 (8.5)</td>
<td id="S4.T3.2.1.9.9.9" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.9.9.9.1" class="ltx_text" style="background-color:#E6E6E6;">51.83 (13.1)</span></td>
<td id="S4.T3.2.1.9.9.10" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.9.9.10.1" class="ltx_text" style="background-color:#E6E6E6;">40.9</span></td>
</tr>
<tr id="S4.T3.2.1.10.10" class="ltx_tr">
<th id="S4.T3.2.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T3.2.1.10.10.1.1" class="ltx_text ltx_font_bold">ETA-DACP-ent</span></th>
<td id="S4.T3.2.1.10.10.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S4.T3.2.1.10.10.3" class="ltx_td ltx_align_center">59.18 (5.5)</td>
<td id="S4.T3.2.1.10.10.4" class="ltx_td ltx_align_center">69.58 (8.4)</td>
<td id="S4.T3.2.1.10.10.5" class="ltx_td ltx_align_center">53.19 (14.4)</td>
<td id="S4.T3.2.1.10.10.6" class="ltx_td ltx_align_center">58.14 (19.1)</td>
<td id="S4.T3.2.1.10.10.7" class="ltx_td ltx_align_center">59.83 (11.1)</td>
<td id="S4.T3.2.1.10.10.8" class="ltx_td ltx_align_center">46.18 (15.7)</td>
<td id="S4.T3.2.1.10.10.9" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.10.10.9.1" class="ltx_text" style="background-color:#E6E6E6;">58.43 (8.3)</span></td>
<td id="S4.T3.2.1.10.10.10" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.10.10.10.1" class="ltx_text ltx_framed ltx_framed_underline" style="background-color:#E6E6E6;">61.4</span></td>
</tr>
<tr id="S4.T3.2.1.11.11" class="ltx_tr">
<th id="S4.T3.2.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T3.2.1.11.11.1.1" class="ltx_text ltx_font_bold">ETS-DACP-com</span></th>
<td id="S4.T3.2.1.11.11.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S4.T3.2.1.11.11.3" class="ltx_td ltx_align_center">55.41 (11.7)</td>
<td id="S4.T3.2.1.11.11.4" class="ltx_td ltx_align_center">62.58 (14.7)</td>
<td id="S4.T3.2.1.11.11.5" class="ltx_td ltx_align_center">
<span id="S4.T3.2.1.11.11.5.1" class="ltx_text ltx_font_bold">62.55</span> (3.6)</td>
<td id="S4.T3.2.1.11.11.6" class="ltx_td ltx_align_center">
<span id="S4.T3.2.1.11.11.6.1" class="ltx_text ltx_font_bold">72.83</span> (1.8)</td>
<td id="S4.T3.2.1.11.11.7" class="ltx_td ltx_align_center">53.91 (11.6)</td>
<td id="S4.T3.2.1.11.11.8" class="ltx_td ltx_align_center">48.34 (15.9)</td>
<td id="S4.T3.2.1.11.11.9" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;">
<span id="S4.T3.2.1.11.11.9.1" class="ltx_text ltx_framed ltx_framed_underline" style="background-color:#E6E6E6;">59.41</span><span id="S4.T3.2.1.11.11.9.2" class="ltx_text" style="background-color:#E6E6E6;"> (9.3)</span>
</td>
<td id="S4.T3.2.1.11.11.10" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.11.11.10.1" class="ltx_text ltx_framed ltx_framed_underline" style="background-color:#E6E6E6;">61.4</span></td>
</tr>
<tr id="S4.T3.2.1.12.12" class="ltx_tr">
<th id="S4.T3.2.1.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="S4.T3.2.1.12.12.1.1" class="ltx_text ltx_font_bold">Soft Sampling</span></th>
<td id="S4.T3.2.1.12.12.2" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S4.T3.2.1.13.13" class="ltx_tr">
<th id="S4.T3.2.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T3.2.1.13.13.1.1" class="ltx_text ltx_font_bold">ETS-DACP</span></th>
<td id="S4.T3.2.1.13.13.2" class="ltx_td ltx_align_center ltx_border_t">2.39B (10%)</td>
<td id="S4.T3.2.1.13.13.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.2.1.13.13.3.1" class="ltx_text ltx_framed ltx_framed_underline">61.47</span> (2.6)</td>
<td id="S4.T3.2.1.13.13.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.2.1.13.13.4.1" class="ltx_text ltx_framed ltx_framed_underline">72.45</span> (3.4)</td>
<td id="S4.T3.2.1.13.13.5" class="ltx_td ltx_align_center ltx_border_t">43.83 (17.3)</td>
<td id="S4.T3.2.1.13.13.6" class="ltx_td ltx_align_center ltx_border_t">47.08 (18.1)</td>
<td id="S4.T3.2.1.13.13.7" class="ltx_td ltx_align_center ltx_border_t">40.82 (7.9)</td>
<td id="S4.T3.2.1.13.13.8" class="ltx_td ltx_align_center ltx_border_t">46.16 (15.1)</td>
<td id="S4.T3.2.1.13.13.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.13.13.9.1" class="ltx_text" style="background-color:#E6E6E6;">51.63 (12.3)</span></td>
<td id="S4.T3.2.1.13.13.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.13.13.10.1" class="ltx_text" style="background-color:#E6E6E6;">34.1</span></td>
</tr>
<tr id="S4.T3.2.1.14.14" class="ltx_tr">
<th id="S4.T3.2.1.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T3.2.1.14.14.1.1" class="ltx_text ltx_font_bold">ETA-DACP-ppl</span></th>
<td id="S4.T3.2.1.14.14.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S4.T3.2.1.14.14.3" class="ltx_td ltx_align_center">53.90 (14.1)</td>
<td id="S4.T3.2.1.14.14.4" class="ltx_td ltx_align_center">61.44 (18.4)</td>
<td id="S4.T3.2.1.14.14.5" class="ltx_td ltx_align_center">46.04 (15.6)</td>
<td id="S4.T3.2.1.14.14.6" class="ltx_td ltx_align_center">52.44 (13.6)</td>
<td id="S4.T3.2.1.14.14.7" class="ltx_td ltx_align_center">41.00 (5.6)</td>
<td id="S4.T3.2.1.14.14.8" class="ltx_td ltx_align_center">43.80 (13.7)</td>
<td id="S4.T3.2.1.14.14.9" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.14.14.9.1" class="ltx_text" style="background-color:#E6E6E6;">49.67 (8.0)</span></td>
<td id="S4.T3.2.1.14.14.10" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.14.14.10.1" class="ltx_text" style="background-color:#E6E6E6;">20.5</span></td>
</tr>
<tr id="S4.T3.2.1.15.15" class="ltx_tr">
<th id="S4.T3.2.1.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T3.2.1.15.15.1.1" class="ltx_text ltx_font_bold">ETA-DACP-ent</span></th>
<td id="S4.T3.2.1.15.15.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S4.T3.2.1.15.15.3" class="ltx_td ltx_align_center">59.49 (9.2)</td>
<td id="S4.T3.2.1.15.15.4" class="ltx_td ltx_align_center">68.20 (9.5)</td>
<td id="S4.T3.2.1.15.15.5" class="ltx_td ltx_align_center">48.85 (16.7)</td>
<td id="S4.T3.2.1.15.15.6" class="ltx_td ltx_align_center">57.00 (22.5)</td>
<td id="S4.T3.2.1.15.15.7" class="ltx_td ltx_align_center">
<span id="S4.T3.2.1.15.15.7.1" class="ltx_text ltx_framed ltx_framed_underline">62.06</span> (11.4)</td>
<td id="S4.T3.2.1.15.15.8" class="ltx_td ltx_align_center">38.00 (19.6)</td>
<td id="S4.T3.2.1.15.15.9" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.15.15.9.1" class="ltx_text" style="background-color:#E6E6E6;">56.31 (11.3)</span></td>
<td id="S4.T3.2.1.15.15.10" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.15.15.10.1" class="ltx_text" style="background-color:#E6E6E6;">52.3</span></td>
</tr>
<tr id="S4.T3.2.1.16.16" class="ltx_tr">
<th id="S4.T3.2.1.16.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T3.2.1.16.16.1.1" class="ltx_text ltx_font_bold">ETS-DACP-com</span></th>
<td id="S4.T3.2.1.16.16.2" class="ltx_td ltx_align_center ltx_border_bb">2.29B (10%)</td>
<td id="S4.T3.2.1.16.16.3" class="ltx_td ltx_align_center ltx_border_bb">57.07 (10.5)</td>
<td id="S4.T3.2.1.16.16.4" class="ltx_td ltx_align_center ltx_border_bb">64.41 (11.0)</td>
<td id="S4.T3.2.1.16.16.5" class="ltx_td ltx_align_center ltx_border_bb">59.06 (6.0)</td>
<td id="S4.T3.2.1.16.16.6" class="ltx_td ltx_align_center ltx_border_bb">67.97 (9.2)</td>
<td id="S4.T3.2.1.16.16.7" class="ltx_td ltx_align_center ltx_border_bb">51.22 (12.5)</td>
<td id="S4.T3.2.1.16.16.8" class="ltx_td ltx_align_center ltx_border_bb">47.68 (13.8)</td>
<td id="S4.T3.2.1.16.16.9" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.16.16.9.1" class="ltx_text" style="background-color:#E6E6E6;">57.82 (8.6)</span></td>
<td id="S4.T3.2.1.16.16.10" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6E6;"><span id="S4.T3.2.1.16.16.10.1" class="ltx_text" style="background-color:#E6E6E6;">52.3</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.5.1.1" style="font-size:90%;">Table 3</span>:</span><span class="ltx_text" id="S4.T3.6.2" style="font-size:90%;">Pythia-1B 모델 클래스에 대한 재무 작업에 대한 5-shot 설정에서 측정된 TACP 및 효율적인 DACP의 효과. 보고된 것은 10회 실행의 평균 및 표준 편차(괄호 안의)이다. ETA-DACP-ppl은 복잡도 측도를 갖는 ETA-DACP이고, ETA-DACP-ent는 엔트로피 측도를 갖는다. ETS-DACP-com은 복잡성, 유사성 및 엔트로피의 세 가지 메트릭 모두를 평균화하여 데이터 선택과 유사한 태스크 DACP이다. 승률은 쌍별 비교 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib15" title="">15</a>]</cite>에서 모델이 다른 모델보다 더 정확한 백분율이다. <span class="ltx_text ltx_font_bold" id="S4.T3.6.2.1">Bold</span>은 최상의 결과를 나타내고 <span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.6.2.2">underline</span>은 작업당 두 번째로 좋은 결과를 나타냅니다. </span></figcaption>
</figure>
<div id="S4.SS2.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p5.1">이러한 결과는 <em class="ltx_emph ltx_font_italic" id="S4.SS2.p5.1.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p5.1.1.1">모든 데이터가 연속 사전 훈련에 대해 동일하지 않음</span></em>을 명확하게 보여준다. 사실, 효율적인 DACP 방법들(10%)에서 사용되는 모든 데이터는 DACP에서의 데이터의 서브세트이다. DACP의 (100%) 성능이 ETS-DACP/ETA-DACP-ent보다 낮기 때문에, 매우 유사하거나 높은 엔트로피 데이터 위에 더 많은 데이터를 추가하는 것은 실제로 성능을 해친다. 하드 샘플링과 소프트 샘플링 간의 결과 차이는 이 관찰에 더 많은 증거를 추가한다. 작업에 따라 다양성이 있지만 평균적으로 메트릭의 상위 10분위 외부에서 예를 추가하면 세 가지 메트릭 모두의 조합인 ETS-DACP-com을 제외하고 성능이 손상됩니다. 따라서 모든 도메인 연속 사전 훈련에 대한 데이터를 신중하게 선별해야 한다.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p6.1">참고, 도메인 데이터(2.39B)의 10%는 원래 피티아가 학습한 3,000억 토큰 중 1% 미만으로 변환됩니다. 이러한 결과는 지속적인 사전 훈련을 위한 데이터 큐레이션 과정에서 선택적이면 적은 비용으로 도메인 성능에 큰 영향을 미칠 수 있음을 보여준다.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p7.1">이러한 결과는 영역 및 과제(하위 영역)에 대한 지속적인 사전 훈련의 효과를 입증한다. 이 연습에서 발생하는 자연스러운 질문은 <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S4.SS2.p7.1.1">LLM이 좁은 도메인에서 추가로 조정되어 일반성을 상실하는지 여부입니다. </em>요컨대, LLM은 일반론자가 되는 것을 희생하고 전문가가 되는 것인가? 우리는 피티아가 평가된 도메인 외 작업에 대해 지속적으로 사전 훈련된 LLM 변이체의 성능을 측정하여 이 질문에 답한다. 표 <a class="ltx_ref" href="#S5.T4" title="Table 4 ‣ Domain specific large language models. ‣ 5 Related Work ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>는 표준 4개의 비금융 태스크에 대한 성능을 보여준다. 100% 데이터를 사용하는 DACP를 제외하고 4개의 도메인 외 태스크에 대한 성능에는 큰 변화가 없다. 따라서 <em class="ltx_emph ltx_font_italic" id="S4.SS2.p7.1.2">는 지속적인 사전 훈련에 사용할 데이터에 대해 선택적이므로 도메인 성능을 향상시키면서 LLM의 원래 기능을 그대로 유지할 수 있다. </em></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>

<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Domain specific large language models.</h5>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">출시된 LLM의 대부분은 범용 모델이지만 도메인별 LLM은 귀중한 대응물로 부상했다. 의료 도메인 말뭉치로 훈련된 구글의 MedPaLM과 MedPaLM-2는 의료 벤치마크 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>, <a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite>에서 최첨단 결과를 달성했다. Bloomberg는 금융 코퍼스 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>에 대한 교육을 통해 최초의 금융 LLM을 처음부터 개발했으며 Galactica는 과학 영역 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>에 대해 개발되었다. 지속적인 사전 훈련은 처음부터 도메인별 LLM을 구축하는 대안적인 접근법을 제시한다. Wu et al <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite> build medical LLMs through continual pre-training LLaMA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite> on medical papers. 그러나, 그들은 비미세 조정 설정에서 모델의 정량적 성능을 평가하지 않는다. 본 연구에서는 인맥락 학습 환경에서 모델의 성능을 측정하여 지속적인 사전 훈련의 분명한 이점을 보여준다.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<div id="S5.T4.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:211pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-80.1pt,38.9pt) scale(0.730203699495374,0.730203699495374) ;">
<table id="S5.T4.2.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T4.2.1.1.1" class="ltx_tr">
<td id="S5.T4.2.1.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S5.T4.2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">Tokens</td>
<td id="S5.T4.2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T4.2.1.1.1.3.1" class="ltx_text ltx_font_bold">ARC</span></td>
<td id="S5.T4.2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T4.2.1.1.1.4.1" class="ltx_text ltx_font_bold">MMLU</span></td>
<td id="S5.T4.2.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T4.2.1.1.1.5.1" class="ltx_text ltx_font_bold">TruthfulQA</span></td>
<td id="S5.T4.2.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T4.2.1.1.1.6.1" class="ltx_text ltx_font_bold">HellaSwag</span></td>
<td id="S5.T4.2.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T4.2.1.1.1.7.1" class="ltx_text ltx_font_bold">Average</span></td>
</tr>
<tr id="S5.T4.2.1.2.2" class="ltx_tr">
<td id="S5.T4.2.1.2.2.1" class="ltx_td"></td>
<td id="S5.T4.2.1.2.2.2" class="ltx_td"></td>
<td id="S5.T4.2.1.2.2.3" class="ltx_td ltx_align_center">Acc</td>
<td id="S5.T4.2.1.2.2.4" class="ltx_td ltx_align_center">Acc Norm</td>
<td id="S5.T4.2.1.2.2.5" class="ltx_td ltx_align_center">Acc</td>
<td id="S5.T4.2.1.2.2.6" class="ltx_td ltx_align_center">Acc Norm</td>
<td id="S5.T4.2.1.2.2.7" class="ltx_td ltx_align_center">MC1</td>
<td id="S5.T4.2.1.2.2.8" class="ltx_td ltx_align_center">MC2</td>
<td id="S5.T4.2.1.2.2.9" class="ltx_td ltx_align_center">Acc</td>
<td id="S5.T4.2.1.2.2.10" class="ltx_td ltx_align_center">Acc Norm</td>
<td id="S5.T4.2.1.2.2.11" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.2.2.11.1" class="ltx_text" style="background-color:#E6E6E6;">Acc</span></td>
<td id="S5.T4.2.1.2.2.12" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.2.2.12.1" class="ltx_text" style="background-color:#E6E6E6;">Acc Norm</span></td>
</tr>
<tr id="S5.T4.2.1.3.3" class="ltx_tr">
<td id="S5.T4.2.1.3.3.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.3.3.1.1" class="ltx_text ltx_font_bold">Pythia 1B</span></td>
<td id="S5.T4.2.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">0</td>
<td id="S5.T4.2.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">25.94</td>
<td id="S5.T4.2.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">29.27</td>
<td id="S5.T4.2.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">26.29</td>
<td id="S5.T4.2.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">26.29</td>
<td id="S5.T4.2.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">23.62</td>
<td id="S5.T4.2.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">40.47</td>
<td id="S5.T4.2.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.3.3.9.1" class="ltx_text ltx_font_bold">37.65</span></td>
<td id="S5.T4.2.1.3.3.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.3.3.10.1" class="ltx_text ltx_font_bold">47.83</span></td>
<td id="S5.T4.2.1.3.3.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.3.3.11.1" class="ltx_text" style="background-color:#E6E6E6;">28.38</span></td>
<td id="S5.T4.2.1.3.3.12" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.3.3.12.1" class="ltx_text ltx_font_bold" style="color:#0000FF;background-color:#E6E6E6;">35.96</span></td>
</tr>
<tr id="S5.T4.2.1.4.4" class="ltx_tr">
<td id="S5.T4.2.1.4.4.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.4.4.1.1" class="ltx_text ltx_font_bold">DACP</span></td>
<td id="S5.T4.2.1.4.4.2" class="ltx_td ltx_align_center ltx_border_t">2.39B (10%)</td>
<td id="S5.T4.2.1.4.4.3" class="ltx_td ltx_align_center ltx_border_t">26.28</td>
<td id="S5.T4.2.1.4.4.4" class="ltx_td ltx_align_center ltx_border_t">29.44</td>
<td id="S5.T4.2.1.4.4.5" class="ltx_td ltx_align_center ltx_border_t">26.43</td>
<td id="S5.T4.2.1.4.4.6" class="ltx_td ltx_align_center ltx_border_t">26.43</td>
<td id="S5.T4.2.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t">24.48</td>
<td id="S5.T4.2.1.4.4.8" class="ltx_td ltx_align_center ltx_border_t">42.26</td>
<td id="S5.T4.2.1.4.4.9" class="ltx_td ltx_align_center ltx_border_t">36.83</td>
<td id="S5.T4.2.1.4.4.10" class="ltx_td ltx_align_center ltx_border_t">45.34</td>
<td id="S5.T4.2.1.4.4.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.4.4.11.1" class="ltx_text" style="background-color:#E6E6E6;">28.50</span></td>
<td id="S5.T4.2.1.4.4.12" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.4.4.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.87</span></td>
</tr>
<tr id="S5.T4.2.1.5.5" class="ltx_tr">
<td id="S5.T4.2.1.5.5.1" class="ltx_td ltx_align_center"><span id="S5.T4.2.1.5.5.1.1" class="ltx_text ltx_font_bold">DACP</span></td>
<td id="S5.T4.2.1.5.5.2" class="ltx_td ltx_align_center">23.9B (100%)</td>
<td id="S5.T4.2.1.5.5.3" class="ltx_td ltx_align_center">24.32</td>
<td id="S5.T4.2.1.5.5.4" class="ltx_td ltx_align_center">27.47</td>
<td id="S5.T4.2.1.5.5.5" class="ltx_td ltx_align_center">26.09</td>
<td id="S5.T4.2.1.5.5.6" class="ltx_td ltx_align_center">26.09</td>
<td id="S5.T4.2.1.5.5.7" class="ltx_td ltx_align_center">24.60</td>
<td id="S5.T4.2.1.5.5.8" class="ltx_td ltx_align_center">42.05</td>
<td id="S5.T4.2.1.5.5.9" class="ltx_td ltx_align_center">35.34</td>
<td id="S5.T4.2.1.5.5.10" class="ltx_td ltx_align_center">42.45</td>
<td id="S5.T4.2.1.5.5.11" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.5.5.11.1" class="ltx_text" style="background-color:#E6E6E6;">27.59</span></td>
<td id="S5.T4.2.1.5.5.12" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.5.5.12.1" class="ltx_text" style="background-color:#E6E6E6;">34.52</span></td>
</tr>
<tr id="S5.T4.2.1.6.6" class="ltx_tr">
<td id="S5.T4.2.1.6.6.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.6.6.1.1" class="ltx_text ltx_font_bold">TACP</span></td>
<td id="S5.T4.2.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t">0.24M</td>
<td id="S5.T4.2.1.6.6.3" class="ltx_td ltx_align_center ltx_border_t">25.34</td>
<td id="S5.T4.2.1.6.6.4" class="ltx_td ltx_align_center ltx_border_t">28.41</td>
<td id="S5.T4.2.1.6.6.5" class="ltx_td ltx_align_center ltx_border_t">24.93</td>
<td id="S5.T4.2.1.6.6.6" class="ltx_td ltx_align_center ltx_border_t">24.93</td>
<td id="S5.T4.2.1.6.6.7" class="ltx_td ltx_align_center ltx_border_t">24.48</td>
<td id="S5.T4.2.1.6.6.8" class="ltx_td ltx_align_center ltx_border_t">41.95</td>
<td id="S5.T4.2.1.6.6.9" class="ltx_td ltx_align_center ltx_border_t">37.03</td>
<td id="S5.T4.2.1.6.6.10" class="ltx_td ltx_align_center ltx_border_t">47.27</td>
<td id="S5.T4.2.1.6.6.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.6.6.11.1" class="ltx_text" style="background-color:#E6E6E6;">27.95</span></td>
<td id="S5.T4.2.1.6.6.12" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.6.6.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.64</span></td>
</tr>
<tr id="S5.T4.2.1.7.7" class="ltx_tr">
<td id="S5.T4.2.1.7.7.1" class="ltx_td ltx_align_center ltx_border_t" colspan="12"><span id="S5.T4.2.1.7.7.1.1" class="ltx_text ltx_font_bold">Hard Sampling</span></td>
</tr>
<tr id="S5.T4.2.1.8.8" class="ltx_tr">
<td id="S5.T4.2.1.8.8.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.8.8.1.1" class="ltx_text ltx_font_bold">ETS-DACP</span></td>
<td id="S5.T4.2.1.8.8.2" class="ltx_td ltx_align_center ltx_border_t">2.39B (10%)</td>
<td id="S5.T4.2.1.8.8.3" class="ltx_td ltx_align_center ltx_border_t">24.74</td>
<td id="S5.T4.2.1.8.8.4" class="ltx_td ltx_align_center ltx_border_t">28.07</td>
<td id="S5.T4.2.1.8.8.5" class="ltx_td ltx_align_center ltx_border_t">25.99</td>
<td id="S5.T4.2.1.8.8.6" class="ltx_td ltx_align_center ltx_border_t">25.99</td>
<td id="S5.T4.2.1.8.8.7" class="ltx_td ltx_align_center ltx_border_t">23.26</td>
<td id="S5.T4.2.1.8.8.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.8.8.8.1" class="ltx_text ltx_font_bold">43.85</span></td>
<td id="S5.T4.2.1.8.8.9" class="ltx_td ltx_align_center ltx_border_t">36.31</td>
<td id="S5.T4.2.1.8.8.10" class="ltx_td ltx_align_center ltx_border_t">44.79</td>
<td id="S5.T4.2.1.8.8.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.8.8.11.1" class="ltx_text" style="background-color:#E6E6E6;">27.57</span></td>
<td id="S5.T4.2.1.8.8.12" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.8.8.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.68</span></td>
</tr>
<tr id="S5.T4.2.1.9.9" class="ltx_tr">
<td id="S5.T4.2.1.9.9.1" class="ltx_td ltx_align_center"><span id="S5.T4.2.1.9.9.1.1" class="ltx_text ltx_font_bold">ETA-DACP-ppl</span></td>
<td id="S5.T4.2.1.9.9.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S5.T4.2.1.9.9.3" class="ltx_td ltx_align_center"><span id="S5.T4.2.1.9.9.3.1" class="ltx_text ltx_font_bold">26.71</span></td>
<td id="S5.T4.2.1.9.9.4" class="ltx_td ltx_align_center">28.41</td>
<td id="S5.T4.2.1.9.9.5" class="ltx_td ltx_align_center">26.31</td>
<td id="S5.T4.2.1.9.9.6" class="ltx_td ltx_align_center">26.31</td>
<td id="S5.T4.2.1.9.9.7" class="ltx_td ltx_align_center">24.97</td>
<td id="S5.T4.2.1.9.9.8" class="ltx_td ltx_align_center">41.42</td>
<td id="S5.T4.2.1.9.9.9" class="ltx_td ltx_align_center">36.70</td>
<td id="S5.T4.2.1.9.9.10" class="ltx_td ltx_align_center">44.89</td>
<td id="S5.T4.2.1.9.9.11" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.9.9.11.1" class="ltx_text ltx_font_bold" style="color:#0000FF;background-color:#E6E6E6;">28.67</span></td>
<td id="S5.T4.2.1.9.9.12" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.9.9.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.26</span></td>
</tr>
<tr id="S5.T4.2.1.10.10" class="ltx_tr">
<td id="S5.T4.2.1.10.10.1" class="ltx_td ltx_align_center"><span id="S5.T4.2.1.10.10.1.1" class="ltx_text ltx_font_bold">ETA-DACP-ent</span></td>
<td id="S5.T4.2.1.10.10.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S5.T4.2.1.10.10.3" class="ltx_td ltx_align_center">25.34</td>
<td id="S5.T4.2.1.10.10.4" class="ltx_td ltx_align_center">27.99</td>
<td id="S5.T4.2.1.10.10.5" class="ltx_td ltx_align_center">24.60</td>
<td id="S5.T4.2.1.10.10.6" class="ltx_td ltx_align_center">24.60</td>
<td id="S5.T4.2.1.10.10.7" class="ltx_td ltx_align_center">24.11</td>
<td id="S5.T4.2.1.10.10.8" class="ltx_td ltx_align_center">41.38</td>
<td id="S5.T4.2.1.10.10.9" class="ltx_td ltx_align_center">36.92</td>
<td id="S5.T4.2.1.10.10.10" class="ltx_td ltx_align_center">44.98</td>
<td id="S5.T4.2.1.10.10.11" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.10.10.11.1" class="ltx_text" style="background-color:#E6E6E6;">27.75</span></td>
<td id="S5.T4.2.1.10.10.12" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.10.10.12.1" class="ltx_text" style="background-color:#E6E6E6;">34.74</span></td>
</tr>
<tr id="S5.T4.2.1.11.11" class="ltx_tr">
<td id="S5.T4.2.1.11.11.1" class="ltx_td ltx_align_center"><span id="S5.T4.2.1.11.11.1.1" class="ltx_text ltx_font_bold">ETS-DACP-com</span></td>
<td id="S5.T4.2.1.11.11.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S5.T4.2.1.11.11.3" class="ltx_td ltx_align_center">26.37</td>
<td id="S5.T4.2.1.11.11.4" class="ltx_td ltx_align_center">29.35</td>
<td id="S5.T4.2.1.11.11.5" class="ltx_td ltx_align_center">26.58</td>
<td id="S5.T4.2.1.11.11.6" class="ltx_td ltx_align_center">26.58</td>
<td id="S5.T4.2.1.11.11.7" class="ltx_td ltx_align_center">24.48</td>
<td id="S5.T4.2.1.11.11.8" class="ltx_td ltx_align_center">41.51</td>
<td id="S5.T4.2.1.11.11.9" class="ltx_td ltx_align_center">36.61</td>
<td id="S5.T4.2.1.11.11.10" class="ltx_td ltx_align_center">44.97</td>
<td id="S5.T4.2.1.11.11.11" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.11.11.11.1" class="ltx_text" style="background-color:#E6E6E6;">28.51</span></td>
<td id="S5.T4.2.1.11.11.12" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.11.11.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.60</span></td>
</tr>
<tr id="S5.T4.2.1.12.12" class="ltx_tr">
<td id="S5.T4.2.1.12.12.1" class="ltx_td ltx_align_center ltx_border_t" colspan="12"><span id="S5.T4.2.1.12.12.1.1" class="ltx_text ltx_font_bold">Soft Sampling</span></td>
</tr>
<tr id="S5.T4.2.1.13.13" class="ltx_tr">
<td id="S5.T4.2.1.13.13.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.13.13.1.1" class="ltx_text ltx_font_bold">ETS-DACP</span></td>
<td id="S5.T4.2.1.13.13.2" class="ltx_td ltx_align_center ltx_border_t">2.39B (10%)</td>
<td id="S5.T4.2.1.13.13.3" class="ltx_td ltx_align_center ltx_border_t">26.45</td>
<td id="S5.T4.2.1.13.13.4" class="ltx_td ltx_align_center ltx_border_t">28.33</td>
<td id="S5.T4.2.1.13.13.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.13.13.5.1" class="ltx_text ltx_font_bold">27.10</span></td>
<td id="S5.T4.2.1.13.13.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.2.1.13.13.6.1" class="ltx_text ltx_font_bold">27.10</span></td>
<td id="S5.T4.2.1.13.13.7" class="ltx_td ltx_align_center ltx_border_t">24.60</td>
<td id="S5.T4.2.1.13.13.8" class="ltx_td ltx_align_center ltx_border_t">41.73</td>
<td id="S5.T4.2.1.13.13.9" class="ltx_td ltx_align_center ltx_border_t">36.24</td>
<td id="S5.T4.2.1.13.13.10" class="ltx_td ltx_align_center ltx_border_t">44.49</td>
<td id="S5.T4.2.1.13.13.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.13.13.11.1" class="ltx_text" style="background-color:#E6E6E6;">28.60</span></td>
<td id="S5.T4.2.1.13.13.12" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.13.13.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.41</span></td>
</tr>
<tr id="S5.T4.2.1.14.14" class="ltx_tr">
<td id="S5.T4.2.1.14.14.1" class="ltx_td ltx_align_center"><span id="S5.T4.2.1.14.14.1.1" class="ltx_text ltx_font_bold">ETA-DACP-ppl</span></td>
<td id="S5.T4.2.1.14.14.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S5.T4.2.1.14.14.3" class="ltx_td ltx_align_center">25.85</td>
<td id="S5.T4.2.1.14.14.4" class="ltx_td ltx_align_center"><span id="S5.T4.2.1.14.14.4.1" class="ltx_text ltx_font_bold">29.69</span></td>
<td id="S5.T4.2.1.14.14.5" class="ltx_td ltx_align_center">26.59</td>
<td id="S5.T4.2.1.14.14.6" class="ltx_td ltx_align_center">26.59</td>
<td id="S5.T4.2.1.14.14.7" class="ltx_td ltx_align_center">24.85</td>
<td id="S5.T4.2.1.14.14.8" class="ltx_td ltx_align_center">42.17</td>
<td id="S5.T4.2.1.14.14.9" class="ltx_td ltx_align_center">36.55</td>
<td id="S5.T4.2.1.14.14.10" class="ltx_td ltx_align_center">44.71</td>
<td id="S5.T4.2.1.14.14.11" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.14.14.11.1" class="ltx_text" style="background-color:#E6E6E6;">28.46</span></td>
<td id="S5.T4.2.1.14.14.12" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.14.14.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.79</span></td>
</tr>
<tr id="S5.T4.2.1.15.15" class="ltx_tr">
<td id="S5.T4.2.1.15.15.1" class="ltx_td ltx_align_center"><span id="S5.T4.2.1.15.15.1.1" class="ltx_text ltx_font_bold">ETA-DACP-ent</span></td>
<td id="S5.T4.2.1.15.15.2" class="ltx_td ltx_align_center">2.39B (10%)</td>
<td id="S5.T4.2.1.15.15.3" class="ltx_td ltx_align_center">25.94</td>
<td id="S5.T4.2.1.15.15.4" class="ltx_td ltx_align_center">29.10</td>
<td id="S5.T4.2.1.15.15.5" class="ltx_td ltx_align_center">25.61</td>
<td id="S5.T4.2.1.15.15.6" class="ltx_td ltx_align_center">25.61</td>
<td id="S5.T4.2.1.15.15.7" class="ltx_td ltx_align_center">24.60</td>
<td id="S5.T4.2.1.15.15.8" class="ltx_td ltx_align_center">41.64</td>
<td id="S5.T4.2.1.15.15.9" class="ltx_td ltx_align_center">36.78</td>
<td id="S5.T4.2.1.15.15.10" class="ltx_td ltx_align_center">45.20</td>
<td id="S5.T4.2.1.15.15.11" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.15.15.11.1" class="ltx_text" style="background-color:#E6E6E6;">28.23</span></td>
<td id="S5.T4.2.1.15.15.12" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.15.15.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.39</span></td>
</tr>
<tr id="S5.T4.2.1.16.16" class="ltx_tr">
<td id="S5.T4.2.1.16.16.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.2.1.16.16.1.1" class="ltx_text ltx_font_bold">ETS-DACP-com</span></td>
<td id="S5.T4.2.1.16.16.2" class="ltx_td ltx_align_center ltx_border_bb">2.39B (10%)</td>
<td id="S5.T4.2.1.16.16.3" class="ltx_td ltx_align_center ltx_border_bb">25.77</td>
<td id="S5.T4.2.1.16.16.4" class="ltx_td ltx_align_center ltx_border_bb">27.47</td>
<td id="S5.T4.2.1.16.16.5" class="ltx_td ltx_align_center ltx_border_bb">27.05</td>
<td id="S5.T4.2.1.16.16.6" class="ltx_td ltx_align_center ltx_border_bb">27.05</td>
<td id="S5.T4.2.1.16.16.7" class="ltx_td ltx_align_center ltx_border_bb">24.24</td>
<td id="S5.T4.2.1.16.16.8" class="ltx_td ltx_align_center ltx_border_bb">41.82</td>
<td id="S5.T4.2.1.16.16.9" class="ltx_td ltx_align_center ltx_border_bb">36.93</td>
<td id="S5.T4.2.1.16.16.10" class="ltx_td ltx_align_center ltx_border_bb">44.62</td>
<td id="S5.T4.2.1.16.16.11" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.16.16.11.1" class="ltx_text" style="background-color:#E6E6E6;">28.50</span></td>
<td id="S5.T4.2.1.16.16.12" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6E6;"><span id="S5.T4.2.1.16.16.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.24</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T4.4.1.1" style="font-size:90%;">Table 4</span>:</span><span class="ltx_text" id="S5.T4.5.2" style="font-size:90%;">Evaluation on standard tasks <span class="ltx_text ltx_font_bold" id="S5.T4.5.2.1">Bold</span> indicates the best value for a column We follow the evaluation practice used to create HuggingFace Open LLM leaderboard. </span></figcaption>
</figure>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task-adaptive pre-training.</h5>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">주어진 작업에 대한 레이블이 지정되지 않은 데이터에 대한 언어 모델의 지속적인 사전 훈련은 최종 작업 성능 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>를 향상시키는 데 유익한 것으로 입증되었다. 도메인 이동을 포함하는 시나리오에서, 도메인-적응적 사전-훈련은 태스크-적응적 사전-훈련과 어느 정도 유사성을 갖는다. Aharoni et al <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite>는 유사한 도메인에서 모델을 지속적으로 사전 훈련하는 것이 목표 도메인에서 향상된 작업 성능에 기여한다는 것을 문서화했다. 특히, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite>는 유사도에 기초하여 도메인 내 코퍼스에서 샘플링된 언라벨 작업 데이터와 증강된 언라벨 작업 데이터 모두에 대한 언어 모델의 지속적인 사전 훈련을 보여준다. 이러한 작업들은 태스크 데이터를 사용하지만, 또한 태스크 유사도가 LLMs에 대해 엄청나게 비싸기 때문에 태스크 불가지론적인 방법인 ETA-DACP를 제안한다.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data selection.</h5>

<div id="S5.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px3.p1.1">지속적인 사전 훈련에서 데이터 선택은 훈련 프로세스에 가장 가치 있는 데이터 샘플을 선택하는 데 중요한 역할을 한다. 특정 도메인 또는 태스크와 독립적인 다양한 분산 및 언어적 특징은 데이터 선택 및 학습 커리큘럼 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib21" title="">21</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite> 구성에 유익한 것으로 나타났다. LLM의 맥락에서, 지속적인 사전 훈련은 말할 것도 없고 사전 훈련을 위해 데이터를 큐레이팅하는 방법에 대한 이해가 제한적이다. <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.1">우리가 아는 한, 우리 작업은 LLM의 컨텍스트에서 데이터 선택을 시도하여 보다 효과적인 연속 사전 훈련을 하는 첫 번째 작업이다. </em></p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p" id="S6.p1.1">본 논문에서는 도메인 특화 LLM 개발을 위한 도메인 적응형 연속 사전 훈련의 효과를 입증한다. 재정 영역에서 우리의 결과는 도메인 적응형 연속 사전 훈련이 재정 작업에 대한 LLM의 성능을 향상시킨다는 것을 보여준다. 도메인 적응형 연속 사전 훈련을 통해 LLM은 훨씬 저렴한 비용으로 금융 도메인에서 새로운 지식을 습득할 수 있다.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p class="ltx_p" id="S6.p2.1">또한, ETS-DACP와 ETA-DACP의 효율적인 도메인 적응형 연속 사전 훈련 방법을 제안하여 연속 사전 훈련의 효율성을 높인다. 훈련 데이터 큐레이션을 선택함으로써, 우리의 방법은 연속 사전 훈련을 개선하며, 바닐라 연속 사전 훈련의 데이터와 비용의 10%만으로 훨씬 더 나은 결과를 산출한다. 엔트로피와 같은 작업 불가지론적 척도에 기초한 데이터 선택을 갖는 ETA-DACP는 작업 인식 데이터 선택 전략과 거의 동등하게 작동한다. 이 발견은 작업 데이터가 없는 경우에도 지속적인 사전 훈련을 위한 데이터 선택을 구축하는 데 사용할 수 있다. 또한 오픈 도메인 표준 작업에서 성능 저하가 관찰되지 않았으며, 이는 도메인 적응형 연속 사전 훈련이 오픈 도메인 기능에 해를 끼치지 않는다는 것을 의미한다.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p class="ltx_p" id="S6.p3.1">우리의 연구 결과는 도메인 특정 LLM을 처음부터 구축하는 강력한 대안으로 도메인 연속 사전 훈련을 배치한다. 지속적인 사전 훈련을 위한 데이터 선택에 대해 더 똑똑해짐으로써, 우리는 비용의 일부에서 바닐라 연속 사전 훈련을 능가할 수 있다. 전반적으로, 우리의 작업은 광범위한 응용 프로그램에 대한 의미와 함께 감소된 비용으로 도메인별 LLM을 개발할 수 있는 길을 열어준다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Roee Aharoni and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Unsupervised domain clusters in pretrained language models.

</span>
<span class="ltx_bibblock">In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel&nbsp;R. Tetreault,
editors, <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for
Computational Linguistics, ACL 2020, Online, July 5-10, 2020</span>, pages
7747–7763. Association for Computational Linguistics, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
Jennifer&nbsp;Wortman Vaughan.

</span>
<span class="ltx_bibblock">A theory of learning from different domains.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Machine learning</span>, 79:151–175, 2010.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Yoshua Bengio, Jérôme Louradour, Ronan Collobert, and Jason Weston.

</span>
<span class="ltx_bibblock">Curriculum learning.

</span>
<span class="ltx_bibblock">In Andrea&nbsp;Pohoreckyj Danyluk, Léon Bottou, and Michael&nbsp;L.
Littman, editors, <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Proceedings of the 26th Annual International
Conference on Machine Learning, ICML 2009, Montreal, Quebec, Canada, June
14-18, 2009</span>, volume 382 of <span id="bib.bib3.2.2" class="ltx_text ltx_font_italic">ACM International Conference Proceeding
Series</span>, pages 41–48. ACM, 2009.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Stella Biderman, Hailey Schoelkopf, Quentin&nbsp;Gregory Anthony, Herbie Bradley,
Kyle O’Brien, Eric Hallahan, Mohammad&nbsp;Aflah Khan, Shivanshu Purohit,
USVSN&nbsp;Sai Prashanth, Edward Raff, et&nbsp;al.

</span>
<span class="ltx_bibblock">Pythia: A suite for analyzing large language models across training
and scaling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
2397–2430. PMLR, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>,
33:1877–1901, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Xiang Dai, Sarvnaz Karimi, Ben Hachey, and Cécile Paris.

</span>
<span class="ltx_bibblock">Using similarity measures to select pretraining data for NER.

</span>
<span class="ltx_bibblock">In Jill Burstein, Christy Doran, and Thamar Solorio, editors, <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies,
NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and
Short Papers)</span>, pages 1460–1470. Association for Computational Linguistics,
2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
Larochelle, François Laviolette, Mario Marchand, and Victor&nbsp;S.
Lempitsky.

</span>
<span class="ltx_bibblock">Domain-adversarial training of neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">J. Mach. Learn. Res.</span>, 17:59:1–59:35, 2016.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz&nbsp;Beltagy,
Doug Downey, and Noah&nbsp;A. Smith.

</span>
<span class="ltx_bibblock">Don’t stop pretraining: Adapt language models to domains and tasks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for
Computational Linguistics</span>, pages 8342–8360, Online, July 2020. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Matthew Honnibal and Ines Montani.

</span>
<span class="ltx_bibblock">spaCy 2: Natural language understanding with Bloom embeddings,
convolutional neural networks and incremental parsing.

</span>
<span class="ltx_bibblock">To appear, 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Joel Jang, Seonghyeon Ye, Changho Lee, Sohee Yang, Joongbo Shin, Janghoon Han,
Gyeonghun Kim, and Minjoon Seo.

</span>
<span class="ltx_bibblock">Temporalwiki: A lifelong benchmark for training and evaluating
ever-evolving language models.

</span>
<span class="ltx_bibblock">In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language
Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11,
2022</span>, pages 6237–6250. Association for Computational Linguistics, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun
Kim, Stanley&nbsp;Jungkyu Choi, and Minjoon Seo.

</span>
<span class="ltx_bibblock">Towards continual knowledge learning of language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">The Tenth International Conference on Learning
Representations, ICLR 2022, Virtual Event, April 25-29, 2022</span>.
OpenReview.net, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Xisen Jin, Dejiao Zhang, Henghui Zhu, Wei Xiao, Shang-Wen Li, Xiaokai Wei,
Andrew&nbsp;O. Arnold, and Xiang Ren.

</span>
<span class="ltx_bibblock">Lifelong pretraining: Continually adapting language models to
emerging corpora.

</span>
<span class="ltx_bibblock">In Marine Carpuat, Marie-Catherine de&nbsp;Marneffe, and Iván
Vladimir&nbsp;Meza Ruíz, editors, <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2022 Conference
of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA, United
States, July 10-15, 2022</span>, pages 4764–4780. Association for Computational
Linguistics, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Zixuan Ke, Yijia Shao, Haowei Lin, Tatsuya Konishi, Gyuhak Kim, and Bing Liu.

</span>
<span class="ltx_bibblock">Continual pre-training of language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">The Twelfth International Conference on Learning
Representations</span>, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck,
Chris Callison-Burch, and Nicholas Carlini.

</span>
<span class="ltx_bibblock">Deduplicating training data makes language models better.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers)</span>, pages 8424–8445, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu,
Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Holistic evaluation of language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.09110</span>, 2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Hong Liu, Sang&nbsp;Michael Xie, Zhiyuan Li, and Tengyu Ma.

</span>
<span class="ltx_bibblock">Same pre-training loss, better downstream: Implicit bias matters for
language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
22188–22214. PMLR, 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Lefteris Loukas, Manos Fergadiotis, Ion Androutsopoulos, and Prodromos
Malakasiotis.

</span>
<span class="ltx_bibblock">EDGAR-CORPUS: billions of tokens make the world go round.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2109.14394, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Macedo Maia, Siegfried Handschuh, André Freitas, Brian Davis, Ross
McDermott, Manel Zarrouk, and Alexandra Balahur.

</span>
<span class="ltx_bibblock">Www’18 open challenge: Financial opinion mining and question
answering.

</span>
<span class="ltx_bibblock">In Pierre-Antoine Champin, Fabien Gandon, Mounia Lalmas, and
Panagiotis&nbsp;G. Ipeirotis, editors, <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Companion of the The Web Conference
2018 on The Web Conference 2018, WWW 2018, Lyon , France, April 23-27,
2018</span>, pages 1941–1942. ACM, 2018.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Pekka Malo, Ankur Sinha, Pekka&nbsp;J. Korhonen, Jyrki Wallenius, and Pyry Takala.

</span>
<span class="ltx_bibblock">Good debt or bad debt: Detecting semantic orientations in economic
texts.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">J. Assoc. Inf. Sci. Technol.</span>, 65(4):782–796, 2014.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He.

</span>
<span class="ltx_bibblock">Deepspeed: System optimizations enable training deep learning models
with over 100 billion parameters.

</span>
<span class="ltx_bibblock">In Rajesh Gupta, Yan Liu, Jiliang Tang, and B.&nbsp;Aditya Prakash,
editors, <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">KDD ’20: The 26th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining, Virtual Event, CA, USA, August 23-27, 2020</span>, pages
3505–3506. ACM, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Sebastian Ruder and Barbara Plank.

</span>
<span class="ltx_bibblock">Learning to select data for transfer learning with bayesian
optimization.

</span>
<span class="ltx_bibblock">In Martha Palmer, Rebecca Hwa, and Sebastian Riedel, editors, <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in Natural Language
Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017</span>, pages
372–382. Association for Computational Linguistics, 2017.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic,
Daniel Hesslow, Roman Castagné, Alexandra&nbsp;Sasha Luccioni,
François Yvon, Matthias Gallé, Jonathan Tow, Alexander&nbsp;M. Rush,
Stella Biderman, Albert Webson, Pawan&nbsp;Sasanka Ammanamanchi, Thomas Wang,
Benoît Sagot, Niklas Muennighoff, Albert&nbsp;Villanova del Moral, Olatunji
Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major, Iz&nbsp;Beltagy,
Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro&nbsp;Ortiz Suarez, Victor Sanh,
Hugo Laurençon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin
Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa, Alham&nbsp;Fikri Aji, Amit
Alfassy, Anna Rogers, Ariel&nbsp;Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris
Emezue, Christopher Klamm, Colin Leong, Daniel van Strien, David&nbsp;Ifeoluwa
Adelani, and et&nbsp;al.

</span>
<span class="ltx_bibblock">BLOOM: A 176b-parameter open-access multilingual language model.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2211.05100, 2022.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Karan Singhal, Shekoofeh Azizi, Tao Tu, S.&nbsp;Sara Mahdavi, Jason Wei, Hyung&nbsp;Won
Chung, Nathan Scales, Ajay&nbsp;Kumar Tanwani, Heather Cole-Lewis, Stephen
Pfohl, Perry Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Nathaneal
Schärli, Aakanksha Chowdhery, Philip&nbsp;Andrew Mansfield,
Blaise&nbsp;Agüera y&nbsp;Arcas, Dale&nbsp;R. Webster, Gregory&nbsp;S. Corrado, Yossi
Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev, Yun Liu, Alvin
Rajkomar, Joelle&nbsp;K. Barral, Christopher Semturs, Alan Karthikesalingam, and
Vivek Natarajan.

</span>
<span class="ltx_bibblock">Large language models encode clinical knowledge.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2212.13138, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le&nbsp;Hou,
Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, Mike
Schaekermann, Amy Wang, Mohamed Amin, Sami Lachgar, Philip&nbsp;Andrew Mansfield,
Sushant Prakash, Bradley Green, Ewa Dominowska, Blaise&nbsp;Agüera y&nbsp;Arcas,
Nenad Tomasev, Yun Liu, Renee Wong, Christopher Semturs, S.&nbsp;Sara Mahdavi,
Joelle&nbsp;K. Barral, Dale&nbsp;R. Webster, Gregory&nbsp;S. Corrado, Yossi Matias,
Shekoofeh Azizi, Alan Karthikesalingam, and Vivek Natarajan.

</span>
<span class="ltx_bibblock">Towards expert-level medical question answering with large language
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2305.09617, 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Ankur Sinha and Tanmay Khandait.

</span>
<span class="ltx_bibblock">Impact of news on the commodity market: Dataset and results.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2009.04202, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony
Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic.

</span>
<span class="ltx_bibblock">Galactica: A large language model for science.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2211.09085, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave,
and Guillaume Lample.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2302.13971, 2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Yulia Tsvetkov, Manaal Faruqui, Wang Ling, Brian MacWhinney, and Chris Dyer.

</span>
<span class="ltx_bibblock">Learning the curriculum with bayesian optimization for task-specific
word representation learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Proceedings of the 54th Annual Meeting of the Association for
Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany,
Volume 1: Long Papers</span>. The Association for Computer Linguistics, 2016.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Ben Wang and Aran Komatsuzaki.

</span>
<span class="ltx_bibblock">GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/kingoflolz/mesh-transformer-jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kingoflolz/mesh-transformer-jax</a>, May 2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Chaoyi Wu, Xiaoman Zhang, Ya&nbsp;Zhang, Yanfeng Wang, and Weidi Xie.

</span>
<span class="ltx_bibblock">Pmc-llama: Further finetuning llama on medical papers.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2304.14454, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian
Gehrmann, Prabhanjan Kambadur, David&nbsp;S. Rosenberg, and Gideon Mann.

</span>
<span class="ltx_bibblock">Bloomberggpt: A large language model for finance.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2303.17564, 2023.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Tongtong Wu, Massimo Caccia, Zhuang Li, Yuan-Fang Li, Guilin Qi, and
Gholamreza Haffari.

</span>
<span class="ltx_bibblock">Pretrained language model in continual learning: A comparative
study.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">The Tenth International Conference on Learning
Representations, ICLR 2022, Virtual Event, April 25-29, 2022</span>.
OpenReview.net, 2022.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, Alejandro
Lopez-Lira, and Jimin Huang.

</span>
<span class="ltx_bibblock">PIXIU: A large language model, instruction data and evaluation
benchmark for finance.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2306.05443, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
Chen, Christopher Dewan, Mona&nbsp;T. Diab, Xian Li, Xi&nbsp;Victoria Lin, Todor
Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit&nbsp;Singh
Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">OPT: open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2205.01068, 2022.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Mingmin Zhao, Shichao Yue, Dina Katabi, Tommi&nbsp;S Jaakkola, and Matt&nbsp;T Bianchi.

</span>
<span class="ltx_bibblock">Learning sleep stages from radio signals: A conditional adversarial
architecture.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
4100–4109. PMLR, 2017.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Benchmark BloombergGPT’s Performance</h2>

<div id="A1.p1" class="ltx_para">
<p class="ltx_p" id="A1.p1.1">BloombergGPT는 사내 데이터 분할을 사용하여 평가되고 보고된 메트릭의 계산 세부 정보가 동일하지 않을 수 있으므로 결과를 우리와 직접 비교할 수 없다. 지속적인 사전 훈련의 효과를 적절하게 평가하기 위해 FLARE 프레임워크에 대해 블룸버그GPT의 성능을 벤치마킹한다. 여기에는 FLARE에서 얻은 OPT-66B 및 GPT-NeoX-20B의 성능을 평가하고 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>에 보고된 결과와 비교하는 작업이 포함된다. 이 엄격한 벤치마킹은 공정하고 포괄적인 평가를 보장하여 처음부터 훈련된 재무 LLM과 관련하여 지속적인 사전 훈련 접근법의 효과에 대한 귀중한 통찰력을 제공한다.</p>
</div>
<figure id="A1.T5" class="ltx_table">
<div id="A1.T5.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:303.5pt;height:121.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-5.7pt,2.3pt) scale(0.963849345169969,0.963849345169969) ;">
<table id="A1.T5.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T5.2.1.1.1" class="ltx_tr">
<th id="A1.T5.2.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt"></th>
<th id="A1.T5.2.1.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="A1.T5.2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" colspan="2">FLARE</th>
<th id="A1.T5.2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2">BloombergGPT</th>
</tr>
<tr id="A1.T5.2.1.2.2" class="ltx_tr">
<th id="A1.T5.2.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_t"></th>
<th id="A1.T5.2.1.2.2.2" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t"></th>
<th id="A1.T5.2.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t">GPT-NeoX</th>
<th id="A1.T5.2.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">OPT-66B</th>
<th id="A1.T5.2.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t">GPT-NeoX</th>
<th id="A1.T5.2.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">OPT-66B</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T5.2.1.3.1" class="ltx_tr">
<th id="A1.T5.2.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">FPB</th>
<td id="A1.T5.2.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">F1</td>
<th id="A1.T5.2.1.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">46.75</th>
<td id="A1.T5.2.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.00</td>
<th id="A1.T5.2.1.3.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">44.64</th>
<td id="A1.T5.2.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">48.67</td>
</tr>
<tr id="A1.T5.2.1.4.2" class="ltx_tr">
<th id="A1.T5.2.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">FiQA SA</th>
<td id="A1.T5.2.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r">F1</td>
<th id="A1.T5.2.1.4.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">73.86</th>
<td id="A1.T5.2.1.4.2.4" class="ltx_td ltx_align_center ltx_border_r">37.36</td>
<th id="A1.T5.2.1.4.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">50.59</th>
<td id="A1.T5.2.1.4.2.6" class="ltx_td ltx_align_center">51.60</td>
</tr>
<tr id="A1.T5.2.1.5.3" class="ltx_tr">
<th id="A1.T5.2.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Headline</th>
<td id="A1.T5.2.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r">F1</td>
<th id="A1.T5.2.1.5.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">62.62</th>
<td id="A1.T5.2.1.5.3.4" class="ltx_td ltx_align_center ltx_border_r">61.36</td>
<th id="A1.T5.2.1.5.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">73.22</th>
<td id="A1.T5.2.1.5.3.6" class="ltx_td ltx_align_center">79.41</td>
</tr>
<tr id="A1.T5.2.1.6.4" class="ltx_tr">
<th id="A1.T5.2.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">NER</th>
<td id="A1.T5.2.1.6.4.2" class="ltx_td ltx_align_center ltx_border_r">F1</td>
<th id="A1.T5.2.1.6.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">47.03</th>
<td id="A1.T5.2.1.6.4.4" class="ltx_td ltx_align_center ltx_border_r">52.24</td>
<th id="A1.T5.2.1.6.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">60.98</th>
<td id="A1.T5.2.1.6.4.6" class="ltx_td ltx_align_center">57.49</td>
</tr>
<tr id="A1.T5.2.1.7.5" class="ltx_tr">
<th id="A1.T5.2.1.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t">Average</th>
<td id="A1.T5.2.1.7.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">F1</td>
<th id="A1.T5.2.1.7.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t">57.57</th>
<td id="A1.T5.2.1.7.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">47.74</td>
<th id="A1.T5.2.1.7.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t">57.36</th>
<td id="A1.T5.2.1.7.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">59.29</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T5.3.1.1" style="font-size:90%;">Table 5</span>:</span><span class="ltx_text" id="A1.T5.4.2" style="font-size:90%;">Evaluation results obtained on FLARE benchmark versus BloombergGPT <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite> for two public models: GPT-NeoX and OPT-66B. </span></figcaption>
</figure>
<div id="A1.p2" class="ltx_para">
<p class="ltx_p" id="A1.p2.1">표 <a class="ltx_ref" href="#A1.T5" title="Table 5 ‣ Appendix A Benchmark BloombergGPT’s Performance ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>는 비교 결과를 보고한다. GPT-NeoX는 두 가지 평가 프레임워크에서 유사한 평균 작업 성능을 보고하지만 개별 작업에 대한 성능은 다르다. 예를 들어, FLARE에서 얻은 FiQA SA의 F1 점수는 블룸버그GPT의 평가보다 46% 높은 반면 헤드라인 및 NER에 대한 F1 점수는 더 낮다. 더욱이 OPT-66B는 4개 과제 모두에 대한 BloombergGPT의 평가보다 FLARE에 근거한 열등한 결과를 보고하며, 평균 과제 수행률은 20% 낮다. 이러한 결과는 BloombergGPT의 평가 결과가 FLARE와 비교하여 부풀려졌음을 시사한다. 블룸버그GPT가 FLARE에서 벤치마킹되거나 블룸버그GPT의 평가 구성이 공개되지 않는 한 비교는 여전히 결정적이지 않다.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Perplexity, Similarity and Diversity</h2>

<div id="A2.p1" class="ltx_para">
<p class="ltx_p" id="A2.p1.1">이 섹션에서는 재무 말뭉치 내의 복잡성, 유사성 및 다양성의 분포에 대한 심층 분석을 제시한다. 우리의 연구 결과는 세 가지 메트릭 모두 고도로 왜곡된 분포를 나타낸다는 것을 보여준다. 구체적으로, 그림 <a class="ltx_ref" href="#A2.F3" title="Figure 3 ‣ Appendix B Perplexity, Similarity and Diversity ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>의 맨 위 행에 예시된 바와 같이, 유사성 메트릭은 잠재적으로 재무 코퍼스 내에 두 개의 별개의 소스의 존재에 기인하는 두 개의 모달 패턴을 보여준다.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p class="ltx_p" id="A2.p2.1"><a class="ltx_ref" href="#A2.F4" title="Figure 4 ‣ Appendix B Perplexity, Similarity and Diversity ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>는 세 가지 메트릭 모두의 Spearman의 순위 상관 관계를 보여준다. 우리는 세 가지 메트릭이 낮은 상관 관계를 나타냄을 알 수 있다. 이는 이 세 가지 메트릭에 걸쳐 순위를 지정하여 선택한 데이터의 하위 집합이 중복 정도가 높지 않음을 시사한다. 이를 통해 우리는 세 가지 메트릭을 함께 결합하여 세 가지 다른 차원의 균형을 맞추는 ETS-DACP-com 방법을 만들 수 있었다. 그림 <a class="ltx_ref" href="#A3.F5" title="Figure 5 ‣ Appendix C ETS-DACP-com vs ETS-DACP ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>는 하드 샘플링이 있는 효율적인 DACP 방법 각각에 대해 선택된 하위 집합에 대한 세 가지 메트릭의 분위수 분포를 보여준다.</p>
</div>
<figure id="A2.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2311.08545/assets/x3.png" id="A2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="273" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F3.2.1.1" style="font-size:90%;">Figure 3</span>:</span><span class="ltx_text" id="A2.F3.3.2" style="font-size:90%;">Distribution of perplexity, similarity and diversity. </span></figcaption>
</figure>
<figure id="A2.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2311.08545/assets/x4.png" id="A2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="183" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F4.2.1.1" style="font-size:90%;">그림 4</span>:</span><span class="ltx_text" id="A2.F4.3.2" style="font-size:90%;">Spearman's rank correlation heatmap between perplexity, similarity, and entropy measures. </span></figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>ETS-DACP-com vs ETS-DACP</h2>

<div id="A3.p1" class="ltx_para">
<p class="ltx_p" id="A3.p1.1">ETS-DACP-com은 도메인별 LLM과 작업별 LLM 구성 사이의 균형을 효과적으로 달성한다. 그 효능을 입증하기 위해 유사성, 지식 신규성 및 다양성의 평균 분위수를 샘플링 가중치로 활용한다. 이러한 가중치를 적용하여 학습 데이터를 구성하기 위해 교체 없이 재무 코퍼스의 10%와 20%를 선택하는 가중치 샘플링을 수행한다.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p class="ltx_p" id="A3.p2.1">금융 코퍼스의 다양한 부분 집합에 대한 평균 표본 분위수는 그림 <a class="ltx_ref" href="#A3.F5" title="Figure 5 ‣ Appendix C ETS-DACP-com vs ETS-DACP ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>에 예시되어 있다. 우리는 세 가지 메트릭에 대한 분위수의 단순 평균을 사용하면 세 차원 간의 균형이 잘 달성된다고 주장하는데, 세 차원에 대한 평균 분위수는 각 하위 집합에 대해 유사한 대구에 있다. 대조적으로, ETS-DACP의 하위 집합은 더 높은 복잡성과 더 낮거나 중간 엔트로피를 나타내며, 이는 레이블이 지정되지 않은 태스크 데이터가 새로운 지식을 포함하지만 덜 다양함을 시사한다. ETA-DACP-ppl 및 ETA-DACP-ent의 경우 샘플은 다른 두 차원에 걸쳐 균일하다.</p>
</div>
<figure id="A3.F5" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2311.08545/assets/x5.png" id="A3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="161" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F5.3.1.1" style="font-size:90%;">그림 5</span>:</span><span class="ltx_text" id="A3.F5.4.2" style="font-size:90%;color:#000000;">ETS-DACP-com and ETS-DACP에서 사용되는 금융 코퍼스의 하위 집합의 평균 샘플 분위수. <span class="ltx_text" id="A3.F5.4.2.1" style="color:#000000;"></span></span></figcaption>
</figure>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Train and Test Loss of Efficient DACP Methods</h2>

<div id="A4.p1" class="ltx_para">
<p class="ltx_p" id="A4.p1.1">우리는 그림 <a class="ltx_ref" href="#A4.F6" title="Figure 6 ‣ Appendix D Train and Test Loss of Efficient DACP Methods ‣ Efficient Continual Pre-training for Building Domain Specific Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>에서 효율적인 DACP 방법을 위한 파이낸스 도메인 손실(Fin Test)과 오픈 도메인 손실(Pile Loss)의 플롯을 보여준다. ETS-DACP-com(Hard sampling)은 태스크 지식을 모두 사용하고 더 큰 재무 더미에서 높은 엔트로피/복잡도 샘플을 사용하기 때문에 핀 테스트 손실에 대한 손실이 가장 낮다. 모든 방법은 샘플링을 위해 전체 재무 말뭉치 공간을 샘플링할 때 소프트 샘플링에 대해 유사한 핀 테스트 손실을 갖는다.</p>
</div>
<figure id="A4.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2311.08545/assets/x6.png" id="A4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="350" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A4.F6.2.1.1" style="font-size:90%;">Figure 6</span>:</span><span class="ltx_text" id="A4.F6.3.2" style="font-size:90%;">Loss curves: in domain loss (Fin Test loss) on left and general domain loss (Pile loss) on right for our Efficient DACP class of methods. </span></figcaption>
</figure>
<div id="A4.p2" class="ltx_para">
<p class="ltx_p" id="A4.p2.1">ETS-DACP는 오픈 도메인 파일 손실에 대해 가장 높은 손실을 갖는다. 그러나 ETS-DACP를 사용한 오픈 도메인 태스크에서는 성능 저하가 관찰되지 않았다. 놀랍게도, ETS-DACP-ent와 ETS-DACP-ppl의 손실 사이에는 밀접한 상관관계가 있는 반면, ETS-DACP-ppl은 우리의 작업에서 ETS-DACP-ent보다 일관되고 상당히 나쁩니다. 이러한 관찰은 실제 우리의 작업 성능과 손실 곡선 사이에 좋은 상관관계가 없음을 시사한다. 라벨이 지정되지 않은 데이터와 함께 유효성 검사/테스트 손실을 사용하는 것은 이 도메인에서 최소한 작업 성능에 대한 좋은 프록시가 아닙니다. 이것은 작업 수행과 사전 훈련 손실 사이의 낮은 상관 관계에 대한 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite>의 관찰에 의해 지원된다.</p>
</div>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Financial Dataset Curation</h2>

<div id="A5.p1" class="ltx_para">
<p class="ltx_p" id="A5.p1.1">우리는 도메인 코퍼스를 선별하기 위한 두 가지 데이터 소스인 파이낸셜 뉴스 커먼크롤과 SEC 파일에 대해 설명한다.</p>
</div>
<section id="A5.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Financial News CommonCrawl [13.2B words, 83.5%]</h5>

<div id="A5.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="A5.SS0.SSS0.Px1.p1.1">2016년부터 2022년까지 AWS S3<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">‡</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‡</sup><span class="ltx_tag ltx_tag_note">‡</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="s3://commoncrawl" title="">s3://commoncrawl</a></span></span></span>에 호스팅된 공개 뉴스 CommonCrawl 덤프를 전처리하여 영어 금융 뉴스 데이터 세트를 선별한다. 방대한 뉴스 CommonCrawl 덤프 모음에서 금융 뉴스 기사를 식별하기 위해 도메인 필터와 URL 키워드 필터의 두 가지 필터링 메커니즘을 사용한다. 먼저, CNBC와 같은 금융, 경제 및 비즈니스 뉴스에 주로 초점을 맞춘 평판이 좋은 뉴스에 해당하는 웹 도메인의 포괄적인 포트폴리오를 구축한다. 우리는 금융 코퍼스의 상당 부분을 구성하는 이러한 금융 뉴스 도메인에서 특별히 조달된 뉴스 기사를 보유한다.</p>
</div>
<div id="A5.SS0.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p" id="A5.SS0.SSS0.Px1.p2.1">둘째, 일반 뉴스 매체의 금융 기사를 캡처하기 위해 폭스 비즈니스와 같이 비즈니스, 경제 또는 금융 뉴스의 전용 섹션 또는 하위 영역을 지정하는 경우가 많다. 이러한 금융 기사를 효과적으로 식별하기 위해 일반 뉴스 매체 내의 금융 섹션 및 하위 영역을 대상으로 하는 단순하지만 효과적인 키워드 기반 접근법을 구현한다. 필터링 프로세스는 금융 도메인에서 지속적인 사전 훈련에 적합한 금융 코퍼스의 선택을 보장한다.</p>
</div>
<figure id="A5.F7" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2311.08545/assets/x7.png" id="A5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="147" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A5.F7.2.1.1" style="font-size:90%;">Figure 7</span>:</span><span class="ltx_text" id="A5.F7.3.2" style="font-size:90%;">Financial news size by month</span></figcaption>
</figure>
</section>
<section id="A5.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">SEC Filing [3.3B words, 16.5%]</h5>

<div id="A5.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="A5.SS0.SSS0.Px2.p1.1">미국의 공기업은 법적으로 정기적으로 재무제표를 제출해야 한다. 증권 거래 위원회(SEC)는 1993년부터 이용 가능한 전자 데이터 수집, 분석 및 검색 시스템(EDGAR)을 통해 이러한 파일에 대한 대중의 접근을 용이하게 한다. 이 시스템은 평균적으로 연간 약 40,000개의 새로운 파일을 수용한다. 재무 코퍼스를 강화하기 위해 1993년부터 2022년까지 10K 파일링을 포함합니다. 데이터의 정확성과 일관성을 보장하기 위해 이러한 파일링은 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib17" title="">17</a>]</cite>에 자세히 설명된 패키지를 사용하여 구문 분석 및 사전 처리됩니다. 또한 20개 미만의 단어가 포함된 보고서 섹션을 제거하여 가짜 사례를 제거함으로써 말뭉치의 품질을 최적화한다.</p>
</div>
</section>
<section id="A5.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">List of Domains used to Filter Financial News</h5>

<div id="A5.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="A5.SS0.SSS0.Px3.p1.1">우리는 경제, 시장, 금융, 돈, 부, 투자, 비즈니스, 산업이라는 하위 도메인과 URL을 식별하기 위해 다음 키워드를 사용합니다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2311.08544" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2311.08545" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2311.08545">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2311.08545" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2311.08546" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 19:10:49 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>