[MISSING_PAGE_EMPTY:1]

그리고 예측을 한다; 그리고 (3) 개별 예측을 집계된 예측으로 앙상블하는 집계. 각 단계는 LM 또는 LM의 컬렉션(메시지가 표시되거나 미세 조정됨)을 사용합니다(그림 1).

우리의 시스템을 최적화하고 평가하기 위해 우리는 5개의 경쟁 예측 플랫폼에서 많은 예측 질문 데이터 세트를 수집한다. 테스트 세트는 2023년 6월 1일 이후에 발표된 (이진) 질문으로만 구성된다. 이것은 우리 모델의 지식 컷오프 날짜 이후이기 때문에 사전 훈련에서 유출되는 것을 방지한다. 열차 세트에는 2023년 6월 1일 이전의 질문이 포함되어 있으며, 하이퍼파라미터 검색 및 시스템 미세 조정에 사용됩니다.

우리는 정확한 예측과 설명적 이유를 만들기 위해 LM을 미세 조정하기 위해 자기 감독 접근법을 사용한다. 먼저 훈련 세트의 질문에 대한 예측을 이끌어내기 위해 다양한 스크래치 패드로 기본 LM을 프롬프트합니다. 그런 다음 군중을 능가하는 출력에 대해 새로운 LM을 미세 조정하며, 이는 주어진 컨텍스트에서 어떤 추론 방법을 적용할지 모델을 가르치고 예측 성능을 향상시킨다. 초매개 변수 검색을 위해 검색 및 LM 프롬프트 전략을 포함한 시스템 구성을 식별하여 최상의 종단 간 성능을 제공합니다.

우리의 최적화된 시스템은 예측의 표준 메트릭인 Brier 점수로 측정한 테스트 세트에 대한 집계된 인간 예측의 성능에 접근한다. 우리가 아는 한, 이것은 일반적으로 개별 인간 예측가보다 강한 인간 군중 수준에 가까운 예측 능력을 가진 최초의 자동화 시스템이다(섹션 3.1). 또한 LM의 강점을 기반으로 휴리스틱을 사용하여 주어진 질문과 날짜에 대한 예측 제출 여부를 결정하는 선택적 설정을 고려한다. 이 환경에서 우리 시스템은 인간 군중을 능가합니다.

우리의 주요 공헌을 요약하자면

1. 자동화된 예측 시스템을 평가하고 최적화하기 위해 현재까지 실세계 예측 질문의 가장 큰 최신 데이터 세트를 선별한다.
2. 기준선을 크게 개선하고 경쟁 예측 플랫폼에서 인간 군중 성능에 접근하는 검색 강화 LM 시스템을 구축한다.
3. 우리는 예측 작업에 대한 추론에서 LM의 능력을 향상시키기 위해 자기 지도 미세 조정 방법을 제안하고 적용한다.

## 2 관련 작업

**이벤트 예측.** 정확하고 자동화된 예측을 수행하는 기계 학습 시스템은 인간의 의사 결정을 알리는 데 도움이 될 수 있습니다(Hendrycks et al., 2021). Jin et al.(2021) provided ForecastQA, the first dataset

그림 1: **검색 및 추론 시스템의 개요**. 본 논문의 검색 시스템은 요약된 새로운 논문들을 검색하여 추론 시스템에 입력함으로써 최종 예측으로 집계되는 추론 및 예측을 위한 LMs를 유도한다.

이 작업에는 뉴스 기사의 이벤트를 기반으로 크라우드 워커가 만든 질문이 포함되어 있습니다. Zou et al.(2022)은 2022년까지 예측 경쟁 질문에서 컴파일된 벤치마크 데이터 세트인 Autocast를 도입했다. 큰 상금 풀을 가진 경쟁에서, 어떤 기계 학습 시스템도 Autocast에 대한 인간 예측가의 성능에 접근할 수 없었다(Zou et al., 2022). LLM의 지식 컷오프는 2022년 이전으로 이동하여 보다 최근의 데이터가 필요하다. 이 작업에서는 2023-2024년에 질문을 출제하여 최근 LM을 적용할 수 있다.

Yan et al.(2024)은 오토캐스트에서 향상된 정확도를 제공하는 검색 시스템을 구축했다. 그들은 Fusion-in-Decoder 모델을 학습하여 최종(이진) 해상도(Izacard and Grave, 2021)를 직접 예측하고 정확도를 보고한 반면, LMs에서 설명 추론과 확률 예측을 모두 도출하고 표준 브라이어 점수 메트릭으로 성능을 측정한다.

Schoenegger and Park (2023); Abolhasemi et al. (2023)은 예측 토너먼트에서 GPT-4 및 기타 LLMs를 평가하고 인간 군중보다 성능이 낮다는 것을 발견했다. 이 관찰은 섹션 3.4의 우리의 관찰과 일치한다. 우리와 달리 그들은 예측에 대해 이러한 LMs를 개선하려는 노력을 거의 또는 전혀 하지 않는다.

마지막으로, 통계적 시계열 예측을 위해 변압기 모델들 또는 LMs들을 사용하는 것에 대한 최근 연구가 있다(Nie et al., 2023; Gruver et al., 2023; Dooley et al., 2023; Rasul et al., 2023; Jin et al., 2024; Das et al., 2024; Woo et al., 2024). 그러나 이것은 판단 예측에서의 우리의 초점과 구별된다.

**정보 검색(IR).** IR은 LMs의 질의 응답 기능을 향상시킬 수 있습니다(Lewis et al., 2020; Shuster et al., 2021; Nakano et al., 2021). 사건 예측에 있어서, 다양하고 최신의 정보에 대한 접근이 중요하다(Tetlock and Gardner, 2015). 따라서, 본 시스템의 핵심 구성 요소는 질의 확장, 관련성 순위 및 요약에 LMs을 사용하여 추론 모델에 뉴스 기사를 제공하는 IR 아키텍처이다. 우리의 설정 외에도, IR에 대한 LMs를 사용하는 것은 활발한 연구 주제이다(Zhu et al., 2024).

**보정.** 보정은 정확한 예측을 위해 중요합니다(Tetlock and Gardner, 2015). 따라서, 경쟁 예측 토너먼트에서, 예측자들은 교정(Gneiting and Raftery, 2007)을 장려하는 Brier 점수(Brier, 1950)와 같은 적절한 채점 규칙들에 의해 평가된다. 딥러닝에서 교정에 관한 방대한 문헌이 있다; Gawlikowski et al.(2021); Wang(2023)을 참조하여 조사를 한다.

## 3 Preliminaries: Data, Models and Baseline

### Dataset

**데이터 형식**. 메타쿨루스, 좋은 판단 열기, INFER, 폴리마켓 및 매니폴드와 같은 예측 플랫폼은 질문 결과에 확률을 할당하여 참가자를 초대하여 미래의 이벤트를 예측합니다. 각 질문은 _배경 설명_, _해결 기준_ 및 3개의 타임스탬프로 구성됩니다. 질문이 게시되었을 때 _시작 날짜_, 더 이상 예측을 제출할 수 없는 경우 _닫힌 날짜_ 및 결과가 결정되었을 때 (최종적으로) _해결 날짜_입니다. 시작 날짜와 최소(해결 날짜, 종료 날짜) 사이에 예보를 제출할 수 있습니다. 이러한 주요 필드에 대한 예제 질문은 표 1을 참조하십시오.

**군중 예측** 특정 질문에 대해 개별 예측이 제출될 때 예측 플랫폼은 지속적으로 군중 예측으로 집계합니다. 집계에 대한 자세한 내용은 섹션 A.3을 참조하세요.

\begin{table}
\begin{tabular}{l l|c} \hline \hline
**Field** & **Content** \\ \hline Question & Will Starship achieve liftoff before Monday, May 1st, 2023? \\ Background & On April 14th, SpaceX received a launch license for its Starship spacecraft. A launch scheduled for April 17th was scrubbed due to a frozen valve. SpaceX CEO Elon Musk tweeted: “Learned a lot today, now offloading propellant, retrying in a few days...” \\ Resolution Criteria & This question resolves Yes if Starship leaves the launchpad intact and under its own power before 11:59pm ET on Sunday, April 30th. \\ Key Dates & Begin Date: 2023-04-17 \(|\) & Close Date: 2023-04-30 \(|\) & Resolve Date: 2023-04-20 \\ \hline \hline \end{tabular}
\end{table}
표 1: 배경, 해상도 기준 및 키 날짜가 포함된 **샘플 질문** 입니다. 그 문제는 (예의 최종 결의로) 일찍 해결되었다. 전체 표본점은 표 12를 참조하십시오.

메커니즘. 군중 예측은 경쟁하기에 강력한 벤치마크이다. 예를 들어, 메타쿨루스(2023)는 모든 예보관들의 앙상블이 상위 5, 10,..., 30개의 베스트 예보관들(과거 점수 기준)만을 사용하여 일관되게 우월함을 보여준다. 이 작업에서는 시스템 성능을 군중 집계와 비교한다.

**원시 데이터.** 위에서 언급한 5개 플랫폼에서 예측 질문을 원본으로 합니다. 이는 2015년부터 2024년까지 총 48,754개의 질문과 7,174,607개의 사용자 예측을 산출한다. 데이터 세트에는 33,664개의 이진 질문, 9,725개의 객관식 질문, 4,019개의 숫자 질문, 기타 유형의 1,346개의 질문이 포함된다. 질문은 전 세계적으로 광범위한 주제를 다룬다(그림 10).

원시 데이터 세트에는 잘못 정의되거나 지나치게 개인적이거나 틈새 관심사가 있는 질문이 포함되어 있습니다. 또한 최근 질문은 2023년 6월 1일 이후 80% 이상의 질문이 매니폴드와 폴리마켓에서 나오는 등 매우 불균형적이다.

**데이터 큐레이션.** 위의 문제를 해결하기 위해 잘못 정의된 질문을 필터링하고 매니폴드 및 폴리마켓에서 예측 또는 거래량이 거의 받지 않은 질문을 제거하여 하위 집합을 큐레이션합니다. 우리는 이항질문을 예측하는 것에 초점을 맞추고 객관식 질문을 이항질문으로 나눈다.

LMs의 사전 훈련으로부터 잠재적인 누출을 방지하기 위해, 우리는 우리가 사용하는 모델들에 대한 지식 컷오프 후에 나타나는 질문들만을 테스트 세트에 포함한다(2024년 6월 1일). 모든 테스트 세트 질문은 날짜 후에 열렸고 모든 기차 및 유효성 검사 질문은 이전에 해결되었다. 날짜에 걸쳐 있는 질문은 삭제됩니다.

이는 훈련용 3,762개, 검증용 840개, 테스트용 914개를 포함하여 5,516개의 이진 질문 세트를 산출한다(표 1(a)). 큐레이션 프로세스에 대한 자세한 내용은 샘플 데이터 포인트와 부록 C는 표 12를 참조하십시오.

### Evaluation

**검색 일정** 모델이 컷오프 날짜까지만 훈련된다는 사실을 활용하여 미래 예측을 시뮬레이션할 수 있습니다(Zou 등, 2022). 해결된 질문에 대한 예측을 시뮬레이션하기 위해 과거 뉴스 코퍼스를 쿼리하여 질문 시작 날짜와 지정된 _검색 날짜_ 사이에서 기사를 검색합니다(Zou 등, 2022; Yan 등, 2024). 우리는 모델이 그 날짜에 접근할 수 있었던 정보를 모방하고 있기 때문에 검색 날짜는 예측의 "시뮬레이션된 날짜"로 볼 수 있다.

각 질문에 대한 검색 날짜 집합을 생성하기 위해 열림 날짜와 닫힘 날짜 사이의 기하학적으로 증가하는 시점을 사용한다. 우리는 두 가지 이유로 이 일정을 선택합니다: (1) 질문이 열린 직후 가장 활발하게 열리는 경우가 많고, (2) 질문이 해결된 후 한참이 지난 지나치게 보수적인 마감 날짜가 있는 질문도 있습니다. 우리는 질문당 \(n=5\)개의 검색 날짜를 사용하며, \(k\)번째 검색 날짜는 다음과 같이 계산된다.

\[\text{retrieval\_date}_{k}=\text{date}_{\text{begin}}}+(\text{date}_{ \text{close}}-\text{date}_{\text{begin}}-1)^{k/n}. \tag{1}\]

\begin{table}

\end{table}
표 2: **(a) 5개의 예측 플랫폼 모두에 대한 열차, 유효성 검사 및 테스트 세트의 분포입니다.* * 중요한 것은 테스트 세트의 모든 질문은 2023년 6월 1일 이후, 기본 LM의 훈련 차단 후부터입니다. 한편, 열차 및 검증 세트의 모든 질문은 2023년 6월 1일 이전에 해결되어 튜닝 과정에서 누출되지 않았다. **(b) 테스트 세트에 대한 사전 훈련된 모델의 기준 성능** - 1 표준 오차(SE)(표 7의 전체 결과를 참조)입니다. 무작위 기준선: 0.250, 인간 군중: 0.149. 결과는 모델이 자연스럽게 예측을 잘하지 못한다는 것을 강조한다.

닫기 전에 해결되는 질문의 경우, 질문이 해결된 후 발생하는 모든 날짜를 제외합니다. 이 기하학적 검색 스케줄 하에서, 우리는 모든 질문에 걸쳐 평균 86%의 검색 날짜를 유지한다(그림 10(b)). 말뭉치의 평균 질문 창은 약 70일이고, 분해능까지의 평균 시간은 42일이다.

데이터 세트에서 질문은 공식 종료 날짜 훨씬 전에 해결될 수 있습니다. 이것은 "윌 \(\langle event\rangle\)이 \(\langle date\rangle\)에 의해 발생 하는 것과 같은 질문에 대해 발생 합니다. 여기서 일찍 해결 하면 이벤트가 발생 했음을 나타냅니다 (예제는 표 1 참조). 열린 날짜와 해결 날짜 사이의 기하학적 간격으로 검색하여 각 질문이 동일한 수의 검색 날짜를 받을 수 있도록 해결 날짜에 대해 검색 날짜를 선택하는 것이 유혹적이다. 그러나 검색 날짜는 이제 해결 날짜에 따라 달라지기 때문에 정보가 유출될 것이며, 이는 우리가 설명한 대로 해결과 상관 관계가 있다.

**메트릭.** 이 연구는 이진 질문에 초점을 맞추고 Brier 점수를 성능 메트릭으로 사용하며, 여기서 \((f-o)^{2}\)로 정의되며, 여기서 \(f\in[0,1]\)는 확률적 예측이고 \(o\in\{0,1\}\)는 결과입니다. Brier 점수는 엄격한 적절한 점수 규칙이다: \(o=1\)이 \(p\)일 때의 참 확률을 가정하면 최적 전략은 \(f=p\)를 보고하는 것이다. 부적절한 채점 규칙은 왜곡된 확률을 보고하도록 장려하기 때문에 이것은 바람직하다. 기준선으로서, 0.5의 (숙련되지 않은) 예측은 0.25의 브라이어 점수를 달성한다.

최종 브라이어 점수를 계산하기 위해 먼저 각 질문에 대한 검색 날짜에 걸쳐 브라이어 점수를 평균한 다음 질문에 걸쳐 평균을 낸다. 또한 표준 오차를 보고하지만 표준 오차 계산은 데이터가 i.i.d인 반면 데이터는 실제로 시계열이므로 실제 오류를 과소평가할 가능성이 있다. 마지막으로 RMS(root mean square) 보정 오차를 이용하여 보정을 수행한다.

### Models

우리는 14개의 명령어 조정 LMs: GPT-3.5-Turbo, GPT-3.5-Turbo-1106 (Brown et al., 2020); GPT-4, GPT-4-1106-Preview (OpenAI, 2023); Llama-2-7B, Llama-2-13B, Llama-2-70B (Touvron et al., 2023); Mistral-7B-Instruct, Mistral-8x7B-Instruct (Jiang et al., 2024), Nous Hermes 2 Mistral-8x7B-DPO, Yi-34B-Chat, Claude-2, Claude-2.1 (Anthropic, 2023), 및 Gemini-Pro (Gemini Team, 2023); 자세한 내용은 섹션 A.1을 참조한다.

### 모델은 예측에 능숙하지 않습니다.

기준선으로서, 우리는 추가 정보 검색 없이 14개의 LMs 모두를 평가한다. 우리는 제로샷 프롬프트와 스크래치패드 프롬프트를 사용한다(Nye et al., 2021). 각 프롬프트 전략에 대해 후보 프롬프트를 만들고 검증 세트에서 최상의 프롬프트를 선택하고 테스트 세트에 브라이어 점수를 보고한다. 결과는 표 2(b)에 나와 있으며 각 시리즈에서 최상의 모델을 보고하며 전체 통계는 표 7을 참조하십시오. 신속한 선택은 그림 5와 그림 6에 나타나며 자세한 내용은 부록 B에 나와 있다.

어떤 모델도 자연스레 예측을 잘하지 못한다. 대부분의 모델들의 점수는 무작위 추측(.25)보다 주변이거나 더 나쁘다. GPT-4와 Claude-2 시리즈만이 비숙련 기준선을 큰 마진(\(>.02\))으로 이겼다. 또한 GPT-4-1106-Preview는 가장 낮은 브라이어 점수 0.208을 달성하지만 인간 군중 성능 0.149보다 크게 뒤처진다.

## 4 Our System

표 2(b)에서 관찰된 바와 같이 모든 모델은 기준선 설정에서 성능이 좋지 않다. 우리는 모델이 정확한 예측을 하기 위해 상세한 컨텍스트와 최신 정보가 필요하다는 것을 직감한다. 이 시스템은 뉴스 검색을 통해 이 문제를 해결하고 최적화된 프롬프트 전략과 미세 조정을 통해 더 나은 추론을 이끌어낸다.

### Retrieval

우리의 검색 시스템은 검색 질의 생성, 뉴스 검색, 관련성 필터링 및 재순위화, 텍스트 요약의 4단계로 구성된다(그림 0(a)).

먼저, 뉴스 API를 호출하여 과거 기사를 검색하는 데 사용되는 검색 쿼리를 생성한다. 우리는 처음에 간단한 쿼리 확장 프롬프트(그림 0(a))를 구현하며, 모델에 질문 및 배경에 기초하여 쿼리를 생성하도록 지시한다. 그러나, 우리는 이것이 종종 정확한 예측에 기여하는 하위 고려를 간과한다는 것을 발견한다. 더 넓은 범위를 달성하기 위해, 우리는 예측 질문을 하위 질문으로 분해하고 각각을 사용하여 검색 쿼리를 생성하도록 모델을 프롬프트한다(Min 등, 2019); 프롬프트에 대해 도 11(b)를 참조한다. 예를 들어, 선거 결과를 예측할 때 첫 번째 접근법은 투표 데이터를 직접 검색하는 반면, 후자는 캠페인 재정, 경제 지표 및 지정학적 사건을 다루는 하위 질문을 생성한다. 포괄적인 보장을 위해 두 가지 접근 방식을 결합합니다.

다음으로, 시스템은 LM-생성된 검색 쿼리들을 사용하여 뉴스 API들로부터 기사들을 검색한다. 검색된 기사의 관련성에 대해 5개의 API를 평가하고 NewsCatcher1 및 Google News(섹션 E.2)를 선택한다.

각주 1: [https://www.newscatcherapi.com/](https://www.newscatcherapi.com/)

우리의 초기 검색은 일부 관련 없는 기사를 얻는 비용으로 광범위한 범위를 제공한다. 추론 단계에서 모델을 오도하지 않도록 GPT-3.5-터보가 모든 기사의 관련성을 평가하고 점수가 낮은 기사를 걸러내도록 촉구한다(그림 14). 이 절차는 런타임과 예산에서 비용이 많이 들기 때문에 문맥에서 기사의 제목과 처음 250개의 단어만 모델에 제시한다. 우리는 이 접근법이 70% 비용을 절약하면서 높은 재현율과 정밀도를 달성한다는 것을 검증한다(대안적인 방법 및 결과는 섹션 E.3 참조).

LM은 컨텍스트 창에 의해 제한되기 때문에 기사를 요약한다. 특히 GPT-3.5-터보가 예측 질문과 관련하여 각 기사에서 가장 관련된 세부 사항을 증류하도록 촉구한다(그림 13). 마지막으로, 관련성에 따라 정렬된 상위 \(k\) 기사 요약을 LM에 제시한다. 검증 세트에 대해 종단 간 Brier 점수를 기반으로 순위 기준, 기사 수 \(k\) 및 요약 프롬프트를 선택하며 하이퍼파라미터 스윕 절차는 섹션 5.2를 참조하십시오.

### Reasoning

예측에서의 이전 작업은 근거를 요구하지 않고 모델로부터 예측을 이끌어내는 것에 초점을 맞추었다(Zou et al., 2022; Yan et al., 2024). 그러나, 미래를 정확하게 예측하는 것은 종종 하나의 순방향 패스를 넘어 계산을 필요로 하는 어려운 작업이다. 모델이 추론을 외부화하는 것은 또한 예측에 대한 설명을 이해하고 그에 따라 개선할 수 있도록 한다.

우리는 모델의 추론 경로를 구조화하기 위해 개방형 스크래치 패드를 사용한다. 이 프롬프트는 질문을 제기하고 설명을 제공하고 해결 기준과 주요 날짜를 지정하는 것으로 시작하여 상위 \(k\) 관련 요약(그림 16)이 이어진다. 예측 질문에 대한 추론에 대한 모델을 안내하기 위해, 섹션 5.2에서 식별된 바와 같이 최적의 스크래치패드 프롬프트(그림 15)는 또한 4개의 추가 구성요소를 통합한다:

* 먼저 모델이 질문을 이해하는지 확인하기 위해 질문을 다시 말하도록 촉구합니다. 또한 추가 정보를 제공하기 위해 자신의 지식으로 질문을 확장하도록 지시한다. 직관적으로, 질문에 대한 보다 상세하고 정확한 표현은 더 나은 반응을 이끌어낸다(Deng et al., 2023).

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline
**Criteria** & \multicolumn{3}{c}{**Brier Score \(\downarrow\)**} & \multicolumn{3}{c}{**\% Accuracy \(\uparrow\)**} & \multicolumn{2}{c}{**\% Data Retained \(\uparrow\)**} \\ \cline{2-7}  & **Ours** & **Crowd** & **Aggregate** & **Ours** & **Crowd** & **Aggregate** & **Forecasts** & **Questions** \\ \hline
**모든 질문** &.179,003 &.149,003 & **.146,002** & 71.5 & 77.0 & **77.8,6** & 100\% & 100\% \\
**크라우드 불확실성** & **.238,004** &.240,003 & **.233,002** & 58.1 & **583,3** & **60.2,12** & 51\% & 56\% \\
**조기 검색** &.186,003 &.162,004 & **.159,003** & 70.0 & 74.4 & **75.0,8** & 84\% & 100\% \\
**5+ Articles** &.175,003 &.142,003 & **.140,002** & 72.3 & 77.7 & **78.7,7** & 84\% & 94\% \\ \hline
**All Criteria** & **.240,005** &.247,004 & **.237,003** & **58.0,17** & 54.2,17 & **56.6,17** & 22\% & 43\% \\ \hline \hline \end{tabular}
\end{table}
표 3: **테스트 세트의 시스템 성능**. “모든 질문”은 전체 테스트 세트에서 브라이어 점수를 보여준다. 다른 행은 지정된 기준을 충족할 때 선택적 평가를 보여 자격 질문 및 검색 날짜에 대해 평균을 낸다. "군중 불확실성"은 군중 예측이 0.3-0.7 사이에 있는 질문을 지칭한다. "조기 검색"은 처음 3개의 검색 날짜를 지칭한다. "5+ 기사"는 적어도 5개의 관련 기사가 검색될 때 예측하는 것을 의미한다. 마지막으로 "All Criteria"는 3가지 기준을 공동으로 충족할 때 예측하는 것을 말한다. 특히, 모든 설정에서 우리 시스템과 군중 예측의 집계(평균)가 가장 좋습니다. 첨자 번호는 1 표준 오차를 나타낸다. 크라우드 집계를 능가하는 과감한 항목과 각 범주에서 가장 좋은 항목을 강조 표시합니다.*** 예측에는 가능성에 대한 전체적인 고려가 필요합니다(테틀록 및 가드너, 2015). 다음으로 모델이 검색된 정보와 사전 훈련 지식을 활용하여 결과가 발생할 수 있거나 발생하지 않을 수 있는 이유에 대한 주장을 생성하도록 촉구한다.
* 모델은 잠재적으로 약한 인수를 생성할 수 있습니다. 모든 고려 사항을 동등하게 취급하지 않기 위해 중요도별로 무게를 측정하고 그에 따라 초기 예측으로 집계하도록 지시한다.
* 마지막으로 잠재적인 편향 및 오보정을 방지하기 위해 모델이 과대 또는 과소 자신 있는지 확인하고 과거 기준 비율(Tetlock and Gardner, 2015)을 고려하도록 요청하여 그에 따라 예측을 보정하고 수정합니다.

**기본 모델.** GPT-4-1106-미리 보기를 테스트하는 LM 중 가장 낮은 Brier 점수를 일관되게 제공하기 때문에 최상의 스크래치 패드(하이퍼파라미터 스윕을 통해 발견됨)로 프롬프트합니다(추론에 대한 섹션 5.2 참조).

**미세 조정 모델** 또한 정확한 예측으로 추론을 생성하도록 훈련된 GPT-4의 미세 조정 버전을 프롬프트합니다(섹션 5.1). 미세 조정된 모델은 처방적인 지시 없이 추론하도록 훈련되기 때문에 질문의 기본 정보(스크래치패드 지시 없음)로만 프롬프트한다.

### Ensembling

예측의 집합은 일반적으로 개별 예측(Tetlock and Gardner, 2015)보다 우수하기 때문에 기본 및 미세 조정된 모델에서 여러 예측을 도출한다.

우리는 GPT-4-1106-Preview를 최적 스크래치패드 프롬프트(그림 15)로 프롬프트하고 섹션 5.2에서 식별된 2개의 다음 베스트 스크래치패드 프롬프트로 프롬프트한다. 미세 조정된 모델의 경우 온도 \(T=0.5\)를 설정하고 3회 프롬프트하여 3개의 추가 예측을 샘플링한다. 이것은 총 6개의 예측을 제공합니다: 기본 모델에서 3개, 미세 조정된 모델에서 3개입니다. 이러한 예측을 감안할 때 시스템은 트리밍된 평균을 취하여 최종 예측으로 앙상블하며, 이는 우리가 구현하는 앙상블 방법 중 검증 세트에 가장 잘 수행되기 때문이다(앙상블에 대한 섹션 5.2 참조).

우리는 하이퍼파라미터 및 프롬프트 디자인을 포함하여 부록 D의 시스템에 대한 추가 세부 정보를 제공한다.

## 5 시스템 최적화

우리는 이제 검색 및 추론 시스템을 최적화하기 위한 절차와 얻은 결과를 설명한다.

### 추론 모델 미세 조정

우리는 정확한 예측으로 이어지는 추론을 생성하기 위해 LM을 미세 조정한다. 미세 조정을 위한 데이터를 생성하기 위해, (1) 열차 집합에 대한 대규모 예측 집합을 수집하고, (2) 모델이 인간 군중보다 우수한 부분 집합을 선택한다.

그림 2: **자가 지도 학습을 위한 데이터 생성 절차입니다. 각 질문에 대해 이 방법은 여러 후보 추론-예측 쌍을 생성하고 미세 조정을 위해 인간 집합보다 성능이 우수한 것을 선택합니다.**

**미세 조정 데이터 수집** 예비 데이터를 생성하려면 검색 일정의 각 검색 날짜와 기차 세트의 각 질문에 아래에 설명된 16가지 구성을 곱하여 시스템을 실행합니다.

먼저, 데이터 증강의 한 형태로서, 우리는 2개의 (별개) 검색 구성(그림 2, 왼쪽)을 샘플링하여 각 질문에 대해 2개의 기사 세트를 검색한다. 구체적으로, 검색 프롬프트, 쿼리 수 및 쿼리당 기사를 두 번 샘플링하고(섹션 4), 섹션 4.1에 설명된 프로세스에 따라 관련성 필터링 및 요약을 수행한다. 이는 질문당 추론 모델에 대해 각각 동일한 질문을 갖지만 다른 기사 세트를 갖는 2개의 입력을 초래한다.

군중을 능가하는 예측을 달성할 가능성을 높이기 위해 서로 다른 스크래치 패드 프롬프트를 시도하여 입력당 4개의 후보 출력(질문당 총 8개)을 생성한다. 첫 번째는 5.2절(그림 15)에서 찾은 최적 프롬프트를 사용한다. 그런 다음 검증 세트에서 Brier 점수에 반비례하는 확률로 3개의 다른 스크래치패드 프롬프트를 샘플링한다. 일부 질문에서 Claude-2.1이 더 낫다는 것을 발견하기 때문에 Claude-2.1과 GPT-4-Preview를 모두 표시합니다. 이것은 질문당 총 16개의 후보 예측을 제공합니다.

**미세 조정 데이터 선택** 강력한 예측에서 모델을 미세 조정하려고 합니다. 데이터를 선택하기 위해 크라우드보다 낮은 브라이어 점수를 제공하는 출력만 유지하지만, 이는 실수로 미세 조정된 모델에 대한 과신을 유발할 수 있다. 이를 완화하기 위해 군집 예측에서 예측이 0.15 이상 벗어나는 쌍을 폐기하고 목표 출력을 구성할 때 군집 예측과 예측을 평균화한다.

결과적인 미세 조정 데이터는 다음의 구조를 갖는다(도 2, 우측):

* 모델에 대 한 **입력** 은 질문, 설명 및 해결 기준으로 구성 된 다음 요약 된 문서로 구성 됩니다.
* **대상 출력** 은 추론 및 예측으로 구성 됩니다.

중요한 것은 미세 조정 입력이 스크래치 패드 지침을 제외한다는 것이다. 이를 통해 주어진 맥락에서 적용할 추론 모델을 직접 가르친다.

총 73,632개의 추론이 생성되며, 이로부터 13,253개가 위의 데시데라타를 충족한다. 마지막으로, 예산 제약(그림 2, 오른쪽)으로 인해 2개의 에포크에 대한 6,000개의 가장 최근의 포인트에서 GPT-4-06132를 미세 조정한다.

각주 2: 더 최근의 GPT-4-1106-Preview는 2년의 더 최근의 지식을 가지고 있지만, 미세 조정에는 사용할 수 없었다.

### Hyperparameter Sweep

초매개 변수 스윕은 프롬프트 및 제시된 기사 수와 같은 이산 선택 세트에 대해 (중간) 메트릭을 최적화합니다. 우리는 아래 주요 결과와 부록 E에서 더 자세한 내용을 공유한다.

**방법론.** 하이퍼 매개 변수를 1-2 그룹으로 나누고 반복적으로 최적화합니다. 각 그룹에 대해 효율성을 위해 프록시 메트릭을 사용하는 검색 쿼리 생성을 제외하고 유효성 검사 세트에서 평균 Brier 점수를 기반으로 최상의 구성을 선택한다.

우리는 현재 그룹을 스위핑하면서 이전 그룹의 최적 구성을 고정하면서 그룹을 순차적으로 최적화한다. 아직 스윕될 하이퍼파라미터들은 각각의 입력 질문에 대해 독립적으로 랜덤화된다.

**검색.** 검색은 검색 쿼리 생성, 관련성 등급 및 요약에 LM을 사용합니다. 검색 쿼리 생성 및 요약에 대한 신속한 선택을 독립적으로 최적화합니다. 관련성 평가 프롬프트는 우리 시스템에서 고정된다(그림 14).

검색 질의 생성을 위해 생성된 질의로 기사를 검색하고 두 가지 메트릭을 조사하여 프롬프트를 평가한다: (1) 검색된 모든 기사에 대한 평균 관련성 점수, (2) 6점 척도에서 4의 관련성 임계값을 초과하는 기사의 평균 관련성 점수. 두 개의 고득점 프롬프트는 두 메트릭 모두에서 유사하게 수행되며 중복이 거의 없는 쿼리를 생성합니다. 결과적으로 두 프롬프트(그림 12)를 모두 사용하여 쿼리를 생성하고 유니온을 취합니다.

요약하기 위해, 우리는 시스템 엔드 투 엔드(end-to-end)를 실행하고 브라이어 점수와 관련하여 상위 1 프롬프트(그림 13)를 선택한다.

**추론** 추론 시스템은 문서 요약의 순위가 매겨진 목록을 가져오고 LMs가 예측을 하도록 프롬프트합니다. 우리는 (1) 요약의 순서 기준(관련성 또는 최근성에 따라), (2) LMs에 제시된 기사 요약의 수 \(k\), (3) 예측을 이끌어내기 위한 스크래치패드 지침의 선택을 최적화한다.

효율성을 위해 2개의 독립적인 단계로 최적화합니다.

* 첫 번째 단계에서는 (1)과 (2)를 공동으로 최적화합니다. 관련성 및 설정에 따른 순위 \(k=15\)는 가장 낮은 평균 Brier 점수를 달성한다.
* 두 번째 단계에서는 (3) 추론 프롬프트를 최적화합니다. 우리는 시스템의 기본 모델에서 3개의 예측을 이끌어내기 위해 15개의 후보 중 상위 3개의 프롬프트를 식별하며, 가장 좋은 것은 그림 15를 참조한다.

추론 시스템을 최적화하기 위해 Claude-2.1과 GPT-4-1106-Preview를 모두 예측 생성을 위한 후보 모델로 테스트한다. GPT-4-1106-미리보기는 일관되게 0.01-0.03 더 낮은 브라이어 점수를 산출한다. 따라서 최종 시스템은 GPT-4-1106-미리보기와 미세 조정된 GPT-4-0613에서 예측을 도출한다.

**Ensembling.** 평균, 중앙값, 기하 평균, 트리밍 평균 및 범용 자기 일치성의 변형을 포함한 5가지 앙상블 방법을 구현합니다(USC; Chen 등(2023)). 트리밍된 평균은 평가에서 가장 우수합니다. 자세한 내용은 섹션 E.1을 참조하십시오.

**보정.** 흥미롭게도 우리 시스템은 자연적으로 잘 보정되어 있습니다(그림 2(b)), 비닝 또는 등장 회귀와 같은 표준 보정 방법이 성능을 향상시키지 않는다는 것을 발견했습니다.

## 6 Evaluations

우리는 테스트 세트에서 최적화된 시스템을 평가하고 그것이 인간 군중 성능에 가깝다는 것을 발견한다(섹션 6.1). 다음으로, 우리는 그것의 장단점을 분석한다(섹션 6.2). 관찰에 동기 부여되어, 우리는 시스템이 (식별된 강점을 고려하여) 선택적으로 예측을 할 수 있는 완화된 설정을 도입하고, 우리 시스템이 군중 집계(섹션 6.3)를 능가한다는 것을 발견한다. 마지막으로, 우리는 시스템이 집계된 인간 예측을 보완하는 데 어떻게 사용될 수 있는지 보여준다(섹션 6.4).

### 인간 성능에 가까운 시스템

우리는 먼저 테스트 세트에서 엔드 투 엔드 시스템의 브라이어 점수를 평가한다. 모든 하이퍼파라미터는 검증 세트를 기반으로 선택되었으며 모든 테스트 세트 질문은 검증 질문 후에 시간적으로 나타나 실시간 예측 경쟁의 설정을 반영한다는 점에 유의한다. 브라이어 점수 외에도 과거 작업과 비교하기 위한 정확도도 보고한다(Zou et al., 2022; Yan et al., 2024).

그 결과, 평균 브라이어 점수는 평균 0.179점, 군중은 평균 0.149점으로 차이가 났다. 테스트 세트에 대한 정확도는 71.5%인 반면 커뮤니티 점수는 77.0%로 차이가 났다.

그림 3: **우리 시스템은 (b) 유효성 검사 및 (c) 테스트 모두에서 자연적으로 잘 보정됩니다. 군중은 또한 Zou et al.(2022)의 발견과 일치하여 잘 조정되었다. 대조적으로, 제로 샷 설정(a)의 기본 모델은 보정이 덜 됩니다(섹션 3.4).**5.5%입니다. 기준선 평가(섹션 3.4)와 비교하여, 우리 시스템의 Brier 점수(.179)는 최상의 기준선 모델(.208 with GPT-4-1106-Preview)을 상당히 능가한다.

이전 연구에서 Zou 등(2022)은 우리가 사용하는 플랫폼 중 메타쿨루스, INFER 및 GJOpen의 3개 질문으로 구성된 예측 데이터 세트 Autocast에서 시스템을 평가했다. 그들은 92.8%의 커뮤니티 기준선과 비교하여 65.4%의 정확도를 달성했다. Yan 등(2024)은 이후 이를 67.9%로 개선하였다. 우리의 결과(표 4)는 우리가 자동 예측에서 이룬 상당한 진전을 강조하는데, 특히 우리가 고려하는 질문이 더 어렵더라도 더 나은 정확도(71.5%)를 달성한다(매우 낮은 군중 정확도: 77.0%).

다양한 플랫폼 및 카테고리에 걸친 더 자세한 결과는 표 4에서 찾을 수 있다. 카테고리 전반에 걸쳐, 우리 시스템은 눈에 띄는 변화를 보여준다: 스포츠에서, 우리 시스템은 군중 집계와 거의 일치하고, 환경 & 에너지에서는 훨씬 뒤처진다. 그러나 표본 크기가 더 작고 노이즈로 인한 변동이 있을 수 있으므로 하위 범주에서 강력한 결론을 도출하는 것에 주의한다.

마지막으로 테스트 세트에서 RMS 교정 오차.42(인간 군중:.38)로 시스템이 잘 교정되었음을 다시 관찰한다(그림 2(c)). 흥미로운 사실은 기준선 평가(섹션 3.4)에서는 그렇지 않으며, 여기서 모델은 제로 샷 설정에서 잘 보정되지 않는다(그림 2(a)). 미세 조정 및 앙상블을 통해, 본 시스템은 캘리브레이션을 위한 특정 트레이닝을 거치지 않고 기본 모델들의 캘리브레이션을 개선한다.

### 시스템 강도 및 약점

다음으로 우리 시스템의 장단점을 이해하려고 합니다. 우리는 검증 세트에서 이러한 정보를 조사하고 나중에 이러한 통찰력을 사용하여 테스트 세트(섹션 6.3)의 성능을 향상시킬 것이다.

본 논문에서 제안하는 시스템은 (1) 군중이 신뢰도가 낮은 경우, (2) 초기 검색 날짜, (3) 많은 기사를 검색할 때 검증 세트에서 군중보다 성능이 우수함을 알 수 있다. 또한, 시스템이 잘 보정되어 있음을 알 수 있습니다.

첫째, 군중의 예측이 높은 불확실성을 나타낼 때 우리 시스템은 군중보다 훨씬 우수하다. 특히, 군중의 예측이 0.3에서 0.7 사이일 때, 우리의 브라이어 점수는 군중의 0.246에 비해 0.199이다. 그러나, 우리의 시스템은 낮은 확률을 거의 출력하지 않기 때문에 매우 확실한 질문에서 군중보다 성능이 낮다(그림 3(b)). 우리는 이것이 안전 훈련으로 인해 예측을 헤지하려는 우리 모델의 경향에서 비롯되었다고 가정한다(질적 예는 그림 17 참조). 이를 뒷받침하는 우리 시스템은 군중의 예측이 0 또는 1의 0.05 이내인 질문에 대해 7% 더 높은 정확도를 달성하지만 브라이어 점수는 0.04만큼 더 나쁘다.

다음으로, 본 시스템은 초기 검색 날짜(1, 2, 3)에서 군중보다 성능이 우수하지만 이후 검색 날짜(4, 5)에서는 성능이 우수하지 않다. 관중들에 비해, 우리의 브리어 점수는 질문들이 그들의 쪽으로 이동함에 따라 더 느린 속도로 향상된다.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline \multirow{2}{*}{**Category**} & \multicolumn{2}{c}{**Brier Score \(\downarrow\)**} & \multicolumn{2}{c}{**Accuracy \(\uparrow\)**} \\ \cline{2-5}  & **Ours** & **Crowd** & **Ours** & **Crowd** \\ \hline Science \& Tech &.143.01 &.114.011 & 82.22.7 & 84.32.6 \\ Healthcare \& Biology &.074.015 &.063.020 & 93.84.3 & 90.65.2 \\ Economics \& Business &.198.007 &.147.009 & 68.82.1 & 78.31.9 \\ Politics \& Governance &.172.006 &.145.007 & 72.61.4 & 78.21.3 \\ Education \& Research &.163.024 &.129.04 & 80.66.7 & 77.80.7 \\ Arts \& Recreation &.221.01 &.146.010 & 62.42.5 & 76.92.2 \\ Security \& Defenses &.174.086 &.129.009 & 71.01.2 & 78.41.9 \\ Sports &.175.004 &.171.005 & 73.01.3 & 73.11.3 \\ \hline
**All Categories** & **.179.003** & **.149.003** & **71.5.7** & **77.0.7** \\ \hline \hline \end{tabular}
\end{table}
표 4: 범주 **(왼쪽)** 및 플랫폼 **(오른쪽)** 별 **시스템 평가 결과** 입니다. 첨자 번호는 1 표준 오차입니다. 모든 검색 날짜에 걸쳐 평균을 낸 우리의 최적 시스템은 섹션 4에 설명된 대로 브라이어 점수(인간 군중:.149) 및 정확도.715(인간 군중:.770)를 달성한다.

해상도(도 3(c)). 이것은 앞서 언급한 문제 때문일 수 있다: 증거가 더 결정적이더라도 우리의 모델 헤지는 그렇다.

검색과 관련하여, 본 시스템은 적어도 5개의 관련 기사가 있을 때 군중의 성능에 근접한다. 우리는 또한 기사 수가 증가함에 따라 브라이어 점수가 향상되어 군중의 점수를 능가한다는 것을 관찰한다(그림 3(a)). 직관적으로, 우리 시스템은 고품질 검색에 의존하며, 더 많은 기사를 조건으로 할 때 더 나은 성능을 발휘한다.

우리의 시스템은 검증 세트에서 잘 보정되며, 대부분의 보정 오류는 시스템의 과소 신뢰에서 비롯된다: 0에 가까운 예측은 예상보다 덜 자주 발생하는 것으로 관찰되며, 유사하게 1에 가까운 예측을 가진 이벤트도 모델이 제안하는 것보다 더 높은 속도로 발생한다(그림 2(b)).

### 선택적 설정에서 시스템 군중 제거

실시간 예측 경쟁에서 예측가들은 가능한 모든 날짜에 플랫폼의 모든 질문에 대해 예측할 필요가 없다. 대신에, 그들은 일반적으로 전문 지식이나 관심이 있는 질문과 때때로 그들이 선택하는 질문에 대해 예측을 한다. 따라서 본 논문에서 제안한 시스템의 장단점을 활용하여 질의에 대한 검색일(k)을 예측해야 하는지 여부를 결정하는 것은 당연하다.

섹션 6.2의 통찰력을 활용하여 선별적인 예측을 통해 군중을 능가합니다. 구체적으로, 섹션 6.2에서 확인된 조건에서만 예측했을 때의 성능을 보고한다:

1. _군중 예측이 \(.3\)와 \(.7\) 사이에 있을 때 질문만 예측합니다._ 여기서, 본 시스템은 \(.238\) (군중 집계: \(.240\))의 Brier 점수를 획득하였다. 이것은 예측의 51%와 질문의 56%로 구성된다.
2. _이전 검색 날짜(1, 2 및 3)에만 예측). 이 설정에서 시스템의 Brier 점수는 \(.185\)(군중 집계: \(.161\))입니다. 이것은 예측의 66%와 질문의 100%로 구성된다.
3. _검색 시스템이 적어도 \(5\) 관련 기사를 제공하는 경우에만 예측합니다._ 이 조건에서 우리 시스템의 Brier 점수는 \(.175\)(군중 집계: \(.143\))이다. 이는 예측의 84%, 질문의 94%를 구성한다.
4. 세 가지 조건 모두 Brier score \(.240\) (crowd aggregate: \(.247\))에 도달하였다. 이것은 예측의 22%와 질문의 43%로 구성된다.

우리 시스템과 군중 사이의 브라이어 점수 차이는 세 번째(표 3)를 제외하고 각 휴리스틱 하에서 축소된다. 첫 번째 휴리스틱 하에서, 우리는 군중보다 작은 마진(\(.238\) vs. \ (.240\)). 이게.

그림 4: **시스템 강점**. 유효성 검사 세트를 평가하면 다음과 같습니다. (a) 관련 기사를 충분히 제공하면 시스템이 군중을 능가합니다. (b) 군중이 불확실한 질문( \(.3\)과 \(.7\) 사이의 예측)에 대해서는 Brier score \(.199\) vs. \ (.246\)). 그러나, 크라우드는 \(.05\) 미만의 예측과 같은 매우 자신 있는 질문에서 우리 시스템을 능가한다. (c) 우리 시스템의 브라이어 점수는 초기 검색 날짜에서 더 좋다. 마지막으로, 우리의 시스템은 잘 보정되어 있다(c.f. 그림 2(b)).**

우리의 시스템은 불확실성이 더 클 때 군중의 예측을 보완하는 데 사용할 수 있기 때문에 가치가 있다. 세 가지 조건이 모두 공동으로 충족될 때, 우리 시스템은 (브라이어 점수와 정확도 모두에서 1.5 이상의 표준 오차로) 군중을 크게 능가한다.

### 시스템 완료 군중

마지막으로, 우리는 군중 예측과 함께 시스템의 집합이 단독으로 둘 중 하나를 능가한다는 것을 보여준다.

시스템의 예측과 군중을 가중 평균을 사용하여 군중과 결합하면, 검증 세트에서 최적을 찾습니다. 전체 테스트 세트에서 전체 브라이어 점수가 0.149에서 0.146으로 개선됩니다(표 3, 맨 위 행).

게다가, 우리의 시스템은 특정 기준(섹션 6.2)에서 뛰어나다. 이러한 경우 군중 예측을 보완하는 것이 특히 유용하다. 우리는 위의 가중 평균 대신 비가중 평균을 사용하여 표 3에서도 이러한 결과를 보고한다. 이것은 모든 경우에 군중 예측을 능가한다: 예를 들어, 군중 브라이어 점수는 예측이.3과.7 사이일 때.24인 반면, 시스템은.237을 달성한다.

마지막으로, 우리의 시스템은 직접적인 점수 개선을 넘어 LM 사전 훈련 지식으로부터 도출된 추론에서 효과적인 뉴스 검색과 새로운 관점을 제공함으로써 잠재적으로 인간 예측가를 도울 수 있다. 우리 시스템이 어떻게 인간 예측가를 대화식으로 도울 수 있는지 탐구하는 미래의 방향으로 남겨둔다.

## 7 Ablations

우리는 3개의 절제 연구를 수행합니다. 첫 번째는 GPT-4의 성능만으로 인한 것이 아님을 검증한다. 마지막 두 번째는 검색 및 미세 조정 방법의 이점을 보여준다.

**성능이 낮은 모델을 미세 조정 합니다.* * 시스템의 성능이 기본 모델의 성능에 영향을 주지 않는다는 것을 입증 하기 위해 모든 미세 조정 데이터 (예: GPT-4)에서 GPT-3.5를 미세 조정 합니다 (13,253 샘플).

우리는 시스템에서 미세 조정된 GPT-4를 미세 조정된 GPT-3.5로 대체하고 섹션 6.1과 동일한 방법론을 사용하여 평가한다. 여기서 우리의 브라이어 점수가 이전 점수인.179에 비해 약간 더 나쁘다는 것을 발견했다.

**미세 조정 없음** 미세 조정으로 인한 이득을 입증하기 위해(섹션 5.1) 기본 GPT-4-미리 보기-1106만 추론 모델로 사용하는 것을 제외하고 최적 시스템을 평가합니다.

이 설정에서 절제된 시스템은 원래 점수보다 0.007 증가한 0.186의 찔레 점수를 달성한다.

결과적으로 추론 모델을 미세 조정하면 시스템의 성능이 크게 향상됨을 알 수 있다.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline
**Criteria** & \multicolumn{2}{c}{**Brier Score \(\downarrow\)**} & \multicolumn{2}{c}{**\% Accuracy \(\uparrow\)**} \\ \cline{2-5}  & **Ours** & **Aggregate** & **Ours** & **Aggregate** \\ \hline
**전체 시스템** &.179\({}_{.003}\) &.146\({}_{.002}\) & 71.5\({}_{.7}\) & **77.8\({}_{.6}\)** \\
**미세 조정 GPT-4-0613** &.182\({}_{.002}\) & **.146\({}_{.002}\)** & 70.7\({}_{.7}\) & **77.4\({}_{.6}\)** \\
**미세 조정 GPT-3.5 \& Base GPT-4** &.181\({}_{.002}\) & **.147\({}_{.002}\)** & 70.9\({}_{.7}\) & **77.4\({}_{.6}\)** \\
**Fine-tuned GPT-3.5** &.183\({}_{.002}\) & **.146\({}_{.002}\)** & 71.5\({}_{.7}\) & **77.4\({}_{.6}\)** \\
**기본 GPT-4** &.186\({}_{.002}\) & **.148\({}_{.002}\)** & 70.6\({}_{.7}\) & **77.1\({}_{.6}\)** \\
**Base GPT-4; no IR** &.206\({}_{.002}\) &.150\({}_{.002}\) & 66.6\({}_{.7}\) & 76.9\({}_{.6}\) \\ \hline \hline \end{tabular}
\end{table}
표 5: **절제 연구 결과.** 크라우드 브리어 점수와 정확도는 각각.146%와 77.0%입니다. "집계"는 군중 예측과 함께 시스템의 가중 평균을 나타낸다. 전체 시스템은 미세 조정 된 GPT-4-0613 및 기본 GPT-4-1106 미리 보기 **(행 1)** 를 사용 합니다. 시스템은 미세 조정된 GPT-3.5 **(행 3-4)** 에서 유사한 성능을 제공합니다. 우리 시스템은 미세 조정 추론 모델 **(행 5)** 없이 더 낮은 성능을 나타내며 검색이나 미세 조정 추론 모델 **(행 6)** 없이 추가로 감소한다. 첨자 번호는 하나의 표준 오차를 나타낸다. 우리는 군중 총합을 능가하는 과감한 출품작이다.

**미세 조정 및 검색 없음** 뉴스 검색 없이 기본 GPT-4-1106-미리 보기 모델을 사용하여 최적의 시스템을 평가합니다. 절제된 시스템은 브라이어 스코어.206에 도달한다.

우리의 기준선 평가(섹션 3.4)에서 모든 모델에 의해 달성된 가장 낮은 브라이어 점수는.208이라는 것을 상기하라. 우리의 절제된 시스템은 본질적으로 이 기준선 수준으로 악화된다. 실제로, 어떠한 미세 조정 또는 검색도 없이, 기준 평가 설정보다 본 시스템의 유일한 예상되는 이점은 후보 프롬프트들의 세트를 검색함으로써 발견된 추론 프롬프트이다(섹션 5). 실험은 이것이 상당히 약간의 개선을 제공한다는 것을 암시한다.

## 8 Conclusion

우리의 연구는 거의 인간 수준에서 예측할 수 있는 최초의 ML 시스템을 제시한다. 우리는 LM을 사용하여 어떤 정보를 출처하고 그 관련성을 평가하는 방법을 결정하는 새로운 검색 메커니즘을 개발한다. 또한 정확한 예측으로 추론을 생성하기 위해 자기 지도 미세 조정 방법을 제공한다.

추가 연구를 용이하게 하기 위해 5개의 실제 예측 경쟁에서 컴파일된 가장 크고 최신 예측 데이터 세트인 데이터 세트를 공개한다. 우리는 이러한 시스템을 더 개선할 수 있는 몇 가지 기회에 대해 논의한다.

**반복적 자기 감독.** 더 큰 훈련 말뭉치를 사용하면 자체 감독 미세 조정 접근법을 반복적 자기 개선에 사용할 수 있습니다. 구체적으로, 이전의 최적 예측 및 추론에 대한 모델을 미세 조정한 후, 동일한 모델을 다시 사용하여 더 많은 미세 조정 데이터를 생성할 수 있으며, 이는 훈련 데이터가 소진될 때까지 반복될 수 있다.

**데이터.** 예측 벤치마크는 시스템을 훈련하는 데 좋은 초기 코퍼스이지만 나중에 훈련 컷오프와 함께 LM을 사용하여 이전 LM을 가르치는 것이 가능하다고 믿습니다. 이것은 나중에 LM을 사용하여 답을 알고 있지만 이전 LM은 그렇지 않은(사후) 질문을 생성함으로써 수행할 수 있다. 또한 예측 플랫폼에서 질문을 출제하는 동안 야생에서 과거 데이터를 수집하고 예측 질문으로 재구성하여 더 큰 훈련 세트로 이어질 수 있다.

**도메인 적응 훈련.** 섹션 B.3에서 기준 평가에서 범주의 브라이어 점수가 모델의 사전 훈련 지식과 상관 관계가 있음을 관찰합니다. 이것은 우리가 모델을 도메인 지식에 대해 미세 조정함으로써 특정 관심 분야에 전문화할 수 있음을 시사한다.

**LMs는 자연스럽게 예측을 더 잘합니다.* * LMs가 향상되면 자연스럽게 예측도 더 잘합니다. 특히 섹션 3.4에서 우리는 새로운 세대의 모델이 오래된 모델보다 더 잘 예측한다는 것을 볼 수 있다. 예를 들어, 2023년에 출시된 GPT-4-1106은 2021년에 출시된 GPT-4-0613보다 브라이어 스코어에 대해 0.02만큼 성능이 우수하다. 만약 우리가 더 최근의 모델을 미세 조정했다면, 우리는 더 나은 성능을 기대할 것이다.

높은 수준에서 우리의 결과는 가까운 미래에 LM 기반 시스템이 경쟁력 있는 인간 예측가 수준에서 정확한 예측을 생성할 수 있음을 시사한다. 우리의 작업이 제도적 의사 결정에 도움이 될 수 있는 자동적이고 확장 가능한 예측의 길을 열어주기를 바랍니다.

## Acknowledgments

우리는 도움이 되는 토론을 위해 장-스타니슬라스 데닌, 에릭 존스, 에즈라 카거, 제이콥 파우, 루이치 중에게 감사하고, 논문의 초기 초안에 대한 논평과 피드백을 위해 장-스타니슬라스 데닌, 오웬 에반스, 댄 헨드릭스, 호레스 허, 앤디 주에게 감사한다. DH는 C3.ai 디지털 변환 연구소의 상으로 지원되었다. FZ는 NSF 상 CCF-2311648에 의해 지원되었고 JS는 국립 과학 재단 SaTC CORE 상 제1804794호 및 시몬스 재단에 의해 지원되었다.

## References

* Abolghasemi 등 (2023) Abolghasemi, M., Ganbold, O., and Rotaru, K. (2023). 인간 대 대형 언어 모델: 고급 AI 시대의 판단력 예측 _ arXiv preprint arXiv:2312.06941_.
* Adam (2020) Adam, D. (2020). 특별 보고서: 시뮬레이션은 COVID-19에 대한 세계의 대응을 주도합니다. _Nature_, 580(7802):316-319.
* Abolghasemi et al. (2019)* Anthropic (2023) Anthropic (2023). Claude 모델에 대한 모델 카드 및 평가 [https://www-cdn.anthropic.com/files/4zrzovbb/website/5c49cc247484cecf107c699baf29250302e5da70.pdf] (https://www-cdn.anthropic.com/files/4zrzovbb/website/5c49cc247484cecf107c699baf29250302e5da70.pdf).
* Armstrong (2001) Armstrong, J. S. (2001). _ 예보의 원리: 연구자와 실무자를 위한 지침서_. 스프링거
* Brier (1950) Brier, G. W. (1950). 확률로 표현된 예측의 검증 _ 월별 기상 검토_, 78(1):1-3.
* Brown et al.(2020) Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. (2020). 언어 모델은 샷이 적은 학습자입니다. 신경 정보 처리 시스템(NeurIPS)의 발전에서.
* Chen et al.(2023) Chen, X., Aksitov, R., Alon, U., Ren, J., Xiao, K., Yin, P., Prakash, S., Sutton, C., Wang, X., and Zhou, D. (2023). 대규모 언어 모델 생성을 위한 유니버설 자체 일관성 _ arXiv preprint arXiv:2311.17311_.
* Das et al.(2024) Das, A., Kong, W., Sen, R., and Zhou, Y. (2024). 시계열 예측을 위한 디코더 전용 기초 모델입니다. _ arXiv preprint arXiv:2310.10688_.
* Deng et al. (2023) Deng, Y., Zhang, W., Chen, Z., and Gu, Q. (2023). 다시 설명 및 응답: 대규모 언어 모델이 스스로 더 나은 질문을 하도록 합니다. _ arXiv preprint arXiv:2311.04205_.
* Dooley et al.(2023) Dooley, S., Khurana, G. S., Mohapatra, C., Naidu, S. V., and White, C. (2023). 예측 PFN: 합성 훈련된 제로 샷 예측. 신경 정보 처리 시스템(NeurIPS)의 고급화).
* Gawlikowski et al. (2021) Gawlikowski, J., Tassi, C. R. N., Ali, M., Lee, J., Humt, M., Feng, J., Kruspe, A., Triebel, R., Jung, P., Roscher, R., Shahzad, M., Yang, W., Bamler, R., and Zhu, X. X. (2021). 심층 신경망의 불확실성에 대한 조사 _ arXiv preprint arXiv:2107.03342_.
* Gemini Team (2023) Gemini Team (2023). 제미니: 매우 유능한 멀티모달 모델 가족입니다. _ arXiv preprint arXiv:2312.11805_.
* Gneiting and Raftery (2007) Gneiting, T. 및 Raftery, A. E. (2007). 정확하게 적절한 채점 규칙, 예측 및 추정입니다. _ Journal of the American Statistical Association_, 102(477):359-378.
* Gruver 등(2023) Gruver, N., Finzi, M. A., Qiu, S., and Wilson, A. G. (2023). 대형 언어 모델은 제로샷 시계열 예측가입니다. 신경 정보 처리 시스템(NeurIPS)의 고급화).
* Hanson (2007) Hanson, R. (2007). 로그 시장은 모듈식 조합 정보 집계에 대한 규칙을 코어링합니다. _ The Journal of Prediction Markets_, 1(1):3-15.
* Hendrycks 등(2021) Hendrycks, D., Carlini, N., Schulman, J., and Steinhardt, J. (2021). ML 안전에서 해결되지 않은 문제 _ arXiv preprint arXiv:2109.13916_.
* Izacard and Grave (2021) Izacard, G. and Grave, E. (2021). 개방형 도메인 질문 응답을 위해 생성 모델을 사용하여 통과 검색을 활용합니다. <제16차 유럽 컴퓨터 언어학 협회(EACL) 총회의 회보>에서.
* Jiang et al.(2024) Jiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C., Chaplot, D. S., de las Casas, D., Hanna, E. B., Bressand, F., Lengyel, G., Bour, G., Lample, G., Lavaud, L. R., Saulnier, L., Lachaux, M. - A., Stock, P., Subramanian, S., Yang, S., Antoniak, S., Scao, T. L., Gervet, T., Lavril, T., Wang, T., Lacroix, T., and Sayed, W. E. (2024). 전문가들의 실수죠 arXiv preprint arXiv:2401.04088_.
* Jin et al. (2024) Jin, M., Wang, S., Ma, L., Chu, Z., Zhang, J. Y., Shi, X., Chen, P.-Y., Liang, Y., Li, Y. - F., Pan, S., and Wen, Q. (2024). Time-LLM: 대규모 언어 모델을 재프로그래밍하여 시계열 예측. International Conference on Learning Representations (ICLR)_에서.
* Jin et al. (2021) Jin, W., Khanna, R., Kim, S., Lee, D.-H., Morstatter, F., Galstyan, A., and Ren, X. (2021). 예측 QA: 시간 텍스트 데이터를 사용한 이벤트 예측을 위한 질문 응답 도전. 제59차 전산언어학회 연차총회 및 제11차 자연어처리(ACL) 국제공동회의 회보_에서.
* Jin et al. (2020)Lewis, P. S. H., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Kuttler, H., Lewis, M., Yih, W., Rocktaschel, T., Riedel, S., and Kiela, D. (2020). 지식 집약적인 NLP 작업을 위한 검색 강화 생성 신경 정보 처리 시스템(NeurIPS)의 발전에서.
* Manifold (2022) Manifold (2022). Maniswap. [https://manifoldmarkets.notion.site/manifoldmarkets/Maniswap-ce406e1e897d417cbd491071ea8a0c39] (https://manifoldmarkets.notion.site/manifoldmarkets/Maniswap-ce406e1e897d417cbd491071ea8a0c39).
* Metaculus (2023) Metaculus (2023). 관중의 지혜 대. 최고 중의 최고. [https://www.metaculus.com/notebooks/15760/wisdom-of-the-crowd-vs-the-best-of-the-best] (https://www.metaculus.com/notebooks/15760/wisdom-of-the-crowd-vs-the-best-of-the-best).
* Min et al.(2019) Min, S., Zhong, V., Zettlemoyer, L., and Hajishirzi, H. (2019). 질문 분해 및 재조정을 통한 멀티홉 읽기 이해. [계산 언어학 협회(ACL) 제57차 연례 회의]_에서.
* Nakano 등(2021) Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., Jiang, X., Cobbe, K., Eloundou, T., Krueger, G., Button, K., Knight, M., Chess, B., and Schulman, J. (2021). WebGPT: 브라우저를 통해 인간 피드백을 통한 질의 응답입니다. _ arXiv preprint arXiv:2112.09332_.
* Nie et al. (2023) Nie, Y., Nguyen, N. H., Sinthong, P., and Kalagnanam, J. (2023). 시계열은 64단어의 가치가 있다: 변압기를 이용한 장기 예측. International Conference on Learning Representations (ICLR)_에서.
* Nye et al. (2021) Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., Sutton, C., and Odena, A. (2021). 작업 표시: 언어 모델을 사용하여 중간 계산을 위한 스크래치 패드 _ arXiv preprint arXiv:2112.00114_.
* OpenAI (2023) OpenAI (2023). GPT-4 기술 보고서입니다. _ arXiv preprint arXiv:2303.08774_.
* 폴리마켓(2023) 폴리마켓(2023). Polymarket/poly-market-maker: Market Maker Keeper for the polymarket CLOB. [https://github.com/Polymarket/poly-market-maker] (https://github.com/Polymarket/poly-market-maker).
* Rasul et al. (2023) Rasul, K., Ashok, A., Williams, A. R., Khorasani, A., Adamopoulos, G., Bhagwatkar, R., Bilos, M., Ghonia, H., Hassen, N. V., Schneider, A., Garg, S., Drouin, A., Chapados, N., Nevmyvaka, Y., and Rish, I. (2023). Lag-Llama: 시계열 예측을 위한 기초 모델을 지향합니다. _ arXiv preprint arXiv:2310.08278_.
* Schoenegger and Park (2023) Schoenegger, P. and Park, P. S. (2023). 대규모 언어 모델 예측 기능: 실제 예측 토너먼트의 증거입니다. _ arXiv preprint arXiv:2310.13014_.
* Shuster et al. (2021) Shuster, K., Poff, S., Chen, M., Kiela, D., and Weston, J. (2021). 검색 확대는 대화에서 환각을 줄여줍니다. 계산 언어학 협회의 발견(EMNLP의 발견)_에서.
* Tetlock and Gardner (2015) Tetlock, P. E. and Gardner, D. (2015). _ 초예측: 예측의 예술과 과학_. 크라운
* Touvron et al. (2023) Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esibou, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S., Lachaux, M. - A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Schelten, A., Silva, R., Smith, E. M., Subramanian, R., Tan, X. E., Tang, B., Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and Scialom, T. (2023). 라마 2: 오픈 파운데이션과 미세 조정된 채팅 모델입니다. _ arXiv preprint arXiv:2307.09288_.
* Wang (2023) Wang, C. (2023). 딥러닝의 보정: 최신 기술에 대한 조사입니다. _ arXiv preprint arXiv:2308.01222_.
* Woo et al.(2024) Woo, G., Liu, C., Kumar, A., Xiong, C., Savarese, S., and Sahoo, D. (2024). 보편적 시계열 예측 변압기의 통합 훈련 _ arXiv preprint arXiv:2402.02592_.

얀, Q., 세라지, R., He, J., 멍, L., 및 실뱅, T. (2024). Autocast++: 제로 샷 랭킹 기반 컨텍스트 검색으로 세계 이벤트 예측을 향상시킵니다. International Conference on Learning Representations (ICLR)_에서.
* Zhang et al.(2018) Zhang, Y., Chen, X., and Park, D. (2018). 불변 제품(xy=k) 시장 메이커 모델의 공식 사양 및 구현 _ 백서_.
* Zhu et al. (2024) Zhu, Y., Yuan, H., Wang, S., Liu, J., Liu, W., Deng, C., Dou, Z., and Wen, J.-R. (2024). 정보 검색을 위한 대형 언어 모델: 설문 조사입니다. _ arXiv preprint arXiv:2308.07107_.
* Zou et al. (2022) Zou, A., Xiao, T., Jia, R., Kwon, J., Mazeika, M., Li, R., Song, D., Steinhardt, J., Evans, O., and Hendrycks, D. (2022). 신경망을 사용하여 미래의 세계 이벤트를 예측합니다. 신경 정보 처리 시스템(NeurIPS)의 발전에서.

모델 및 지식 정확도에 대한 세부 정보

### Models

아래에서 사용하는 모델의 자세한 정보 목록을 제공합니다. 개방형 모델의 가중치는 휴징 페이스에서 공개적으로 사용할 수 있으며 주로 AI의 서빙 API를 사용하여 액세스합니다. 모든 컷오프는 공식 성명을 기반으로 합니다.

### Post-training에서 잠재적 누출 테스트

GPT-4-1106-Preview와 GPT-3.5-Turbo-1106은 2023년 11월에 출시되었다. 우리는 훈련 후 단계가 지식 차단(2023년 4월, 2021년 1월) 이후 추가 정보가 유출된다는 증거를 찾지 못했다. 테스트로 2023년 6월~2023년 9월 2023년 9월 20개 주요 이벤트에 대해 모델을 수동으로 쿼리합니다. 예를 들어 "2023년 터키 대통령 선거에서 누가 승리했는가?"입니다. 20개의 모든 질문에 대해 두 모델 모두 지식이 없거나 단순히 환각을 주장한다.

각주 3: [https://www.onthisday.com/events/date/2023/](https://www.onthisday.com/events/date/2023/)에서 원본입니다.

정신을 점검하기 위해 GPT-4-1106-Preview가 2022년 11월부터 2023년 1월까지의 이벤트에 대한 또 다른 20가지 질문에 답하도록 촉구합니다. "2022년 FIFA 월드컵 결승전에서 어떤 팀이 이겼는가?"와 같은 지식 차단에 앞서 말이죠. 모델이 모두 올바르게 응답합니다.

### Crowd Predictions

주어진 질문에 대해 각 플랫폼은 모든 개별 예측을 집계하는 커뮤니티 예측을 계산합니다. 예측은 예측들이 이루어짐에 따라 동적으로 업데이트되고 기록된다. 우리는 (개별 예측을 사용하여 처음부터 계산하는 대신) 플랫폼에서 직접 기록을 수집합니다. 이진 질문의 경우 집계 메커니즘에 대한 자세한 내용은 다음과 같습니다.

* 메타쿨루스에서는 주어진 질문에 대해 예측자의 각 예측은 초기 예측에서 최신 예측으로 \(t\)(1부터 시작)로 표시됩니다. 플랫폼은 가중 중위수에 의해 질문의 군중 예측을 계산한다. 개별 예보관으로부터의 \(t\) 번째 예보의 가중치는 \(e^{\sqrt{t}}}\이므로 보다 최근

\begin{table}
\begin{tabular}{l l l l r} \hline \hline
**Model** & **Source** & **Open Weights** & **Knowledge Cut-off** & **Evaluation Cost** \\ \hline GPT-4-1106-Preview & OpenAI & No & Apr 2023 & \$0.01/1K tokens \\ GPT-4 (GPT-4-0613) & OpenAI & No & Sep 2021 & \$0.03/1K tokens \\ GPT-3.5-Turbo-Instruct & OpenAI & No & Sep 2021 & \$0.0015/1K tokens \\ GPT-3.5-Turbo-1106 & OpenAI & No & Sep 2021 & \$0.001/1K tokens \\ Claude-1 & Anthropic & No & Dec 2022 & \$0.024/1K tokens \\ Claude-2 & Anthropic & No & Dec 2022 & \$0.024/1K tokens \\ Claude-2.1 & Anthropic & No & Dec 2022 & \$0.024/1K tokens \\ Llama-2-7B-Chat & Meta & Yes & Sep 2022 & \$0.0002/1K tokens \\ Llama-2-13B-Chat & Meta & Yes & Sep 2022 & \$0.00025/1K tokens \\ Llama-2-70B-Chat & Meta & Yes & Sep 2022 & \$0.0009/1K tokens \\ Mistral-7B-Instruct & Mistral AI & Yes & _Unknown_ & \$0.0002/1K tokens \\ Mistral-8x7B-Instruct & Mistral AI & Yes & _Unknown_ & \$0.0002/1K tokens \\ Mistral-8x7B-DPO & NousResearch & Yes & _Unknown_ & \$0.0002/1K tokens \\ YI-34B-Chat & 01.AI & Yes & June 2023 & \$0.000776/1K tokens \\ Gemini-Pro & Google & No & Early 2023 & \$0.0005/1K characters \\ \hline \hline \end{tabular}
\end{table}
표 6: **평가하는 LM의 개요**: 원본, 가중치 가용성, 지식 컷오프 날짜 및 평가 비용을 포함하여 연구에 사용된 LM의 분류입니다. 개방형 가중치 모델의 평가 비용은 투게더 AI의 가격을 기반으로 한다. Gemini-Pro의 지식 단절은 2023년(\(\sim\) 4월) 초라고 주장된다. 우리는 미스트랄 시리즈가 공개적으로 보고되지 않았기 때문에 미스트랄 시리즈의 정확한 지식 컷오프를 알지 못한다.

예보는 더 높은 가중치를 받는다. 우리는 플랫폼이 "메타쿨루스 예측"(본 논문에서 사용하거나 비교하지 않음)이라고 하는 또 다른 집계된 예측도 게시한다고 지적한다. 이는 위에서 설명한 군중 예측과 다르며 독점 알고리즘을 통해 계산된다.
* GJOpen은 각 예측자의 예측 중 가장 최근 40%의 평균으로 군중 예측을 계산합니다.
* INFER는 군중 예측을 모든 개별 예측의 평균으로 초기화합니다. 질문이 진행됨에 따라 예를 들어 "최고의 실적을 가진 개인의 예측에 더 많은 가중치를 둡니다."4 집계 메커니즘에 대한 정확한 세부 정보는 웹사이트에서 찾을 수 없습니다. 각주 4: [https://www.infer-pub.com/frequently-asked-questions](https://www.infer-pub.com/frequently-asked-questions)
* 매니폴드 및 폴리마켓은 커뮤니티 예측이 가격(0에서 1 사이)인 예측 시장입니다. 베팅이 이루어짐에 따라 가격은 자동화된 시장 형성자에 의해 조정됩니다. 상기 메커니즘들은 불변-제품 시장 메이커들의 변형들(Hanson, 2007; Zhang et al., 2018); 폴리마켓(2023); 매니폴드(2022)를 참조하여 보다 상세하게 설명된다.

## 부록 B 기본 평가에 대한 세부 정보

이 섹션에서는 기본 평가에 대한 실험 세부 정보를 제공한다(섹션 3.4).

### Evaluation Method

제로샷 프롬프트와 스크래치패드 프롬프트 모두에 대해 5개의 후보 제로샷 프롬프트와 4개의 후보 스크래치패드 프롬프트를 크래프팅하여 기본 프롬프트 최적화를 수행한다. 우리는 Brier 점수를 비교하여 검증 세트의 각 프롬프트를 평가한다. 구체적으로, 우리는 검증 세트에서 무작위로 200개의 질문을 선택하고 고려 중인 14개의 LMs에 걸쳐 평균 브라이어 점수를 계산한다.

* 최상의 제로 샷 프롬프트는 평균 브라이어 점수 0.246을 달성하여 각각 0.261, 0.276, 0.279 및 0.252의 다른 점수를 능가합니다.
* 스크래치 패드의 경우 모든 프롬프트에서 유사한 브라이어 점수를 제공합니다. 우리는 잠재적으로 안전 교육으로 인해 모델이 단순히 "몰라"라고 주장함으로써 예측 질문에 대답하는 것을 거부할 수 있음을 관찰한다. 따라서 우리는 "답변 거부" 응답의 수를 결정 메트릭으로 사용한다. 승리한 스크래치 패드는 평균 88개의 "응답 거부" 응답을 프롬프트하는 반면, 나머지는 각각 평균 106개, 93개 및 94개이다.

최상의 제로 샷 및 스크래치패드 프롬프트는 도 5 및 도 6에 도시된다. 프롬프트 스타일 둘 다에서, 모델들은 질문, 배경, 해상도 기준, 및 질문의 개방 및 폐쇄 날짜들(date_begin 및 date_end)만을 제공한다. 모든 데이터는 예측 플랫폼에서 조달되며 질문 페이지에서 인간 예측가에게 공개적으로 제공됩니다. 우리는 추가적인 뉴스 검색을 하지 않는다.

마지막으로, 테스트 세트의 각 질문에 대한 예측을 위해 각 프롬프트 전략의 최상의 프롬프트를 사용한다. 섹션 3.4에서, 우리는 어떤 모델도 자연스레 예측에 능숙하지 않다는 것을 발견한다. 다음 섹션 B.2에서 전체 결과를 제공합니다.

[MISSING_PAGE_FAIL:19]

[MISSING_PAGE_FAIL:20]

[MISSING_PAGE_EMPTY:21]

데이터 세트: 큐레이션 및 추가 분석

### 데이터 수집 및 큐레이션

**스크래핑** 예측 플랫폼에서 데이터 세트를 컴파일하려면 API를 쿼리하거나 초기 데이터 수집을 위해 질문의 웹 페이지를 긁어냅니다. 메타쿨루스의 경우, 먼저 API를 통해 기본 정보를 추출하고 웹 페이지에서 해상도 기준을 긁어낸다. INFER (CSET) 및 Good Judgment Open 데이터는 웹 스크래핑을 통해 수집되는데, 이는 어떤 API도 우리가 필요로 하는 전체 데이터를 제공하지 않기 때문이다. 커뮤니티 예측을 제외한 폴리마켓의 데이터는 API에서 얻는다. API를 통해 매니폴드의 데이터를 완전히 긁어냅니다.

**범주 할당** 플랫폼 전반에 걸쳐 예측 질문에 대한 표준적이고 균일한 분류가 없습니다. GPT-3.5-터보가 각 질문에 11개 범주 중 하나를 할당하도록 촉구한다. 범주 집합 및 사용 프롬프트는 그림 8을 참조하십시오.

**선별 및 큐레이션** 수동 검사에서 초기 데이터 세트에는 모호하게 공식화되거나 지나치게 개인적인 질문이 포함되어 있음을 알 수 있습니다. 예비 스크리닝 단계에서 GPT-3.5가 이러한 질문을 식별하고 제외하도록 촉구한다. 불확실한 질문을 탐지하기 위한 프롬프트는 그림 9를 참조하며, 여기서 몇 개의 샷 예제를 제공합니다.

그림 8: **제공된 옵션에 따라 질문을 분류하기 위한 프롬프트**. 프롬프트는 11개의 후보 카테고리 선택과 함께 예측 질문을 제시하고, 질문을 카테고리 중 하나로 분류하도록 모델을 프롬프트한다.

이전 예측 데이터 세트의 품질을 평가하려고 합니다.

다음은 데이터 세트의 예측 질문입니다. {질문}.

이진 예측 질문처럼 들리지 않는 질문은 "깃발"을 출력하여 깃발을 달아주세요. 합리적인 질문처럼 들리면 "OK"를 출력하세요.

플래그가 지정되어야 하는 문자열의 예:

* 오늘 밤 숙제를 끝낼까요?
* 메타큘러스 파티 2023
지옥이 얼어붙을까?
* Heads 또는 tails
* 이 비디오가 EOD에 의해 100k 뷰에 도달합니까?

플래그가 지정되지 않아야 하는 문자열의 예:

메건 마클과 해리 왕자는 연말까지 아기를 낳을까요?
* 뇌보존재단의 대형 포유류 보존상은 2017년 2월 9일까지 수상하나요?
* 2015년보다 2016년에 FDA 승인을 받은 새로운 신약이 더 많을까요?

질문이 이미 해결되었다고 해서 플래그가 지정되어야 하는 것은 아닙니다. 의심스러울 때는 "OK"라고 표시하세요.

응답은 다음과 같은 구조를 취해야 합니다.

삽입 사고: {{ insert your concise thoughts here }}

분류: {{ insert "flag" or "ok" }}

그런 다음 낮은 품질의 모든 질문을 제거하기 위해 수동으로 검사합니다. 여기에는 매니폴드 및 폴리마켓과 같은 플랫폼에서 커뮤니티 예측 또는 거래 참여가 거의 없는 질문과 GPT-3.5가 초기 스크리닝 동안 식별할 수 없는 잘못 정의된 질문이 포함된다.

### 추가 통계 및 샘플

데이터에 대한 자세한 통계 및 도표 목록을 제공합니다.

* 그림 10은 전체 데이터 세트의 모든 질문에 위치 언급을 시각화합니다.
* 표 11은 전체 데이터 세트의 플랫폼 전반에 걸친 질문 및 예측 분포를 제공합니다.
* 표 12는 큐레이트된 세트의 전체 데이터 샘플을 보여줍니다.
* 표 13은 시간이 지남에 따라 커뮤니티 예측이 이동하는 방법에 대한 질문 목록을 보여줍니다.
* 그림 10(a)는 전체 데이터 세트에서 질문의 시작 날짜를 보여줍니다.
* 그림 10(b)는 인덱스 \(k=1,2,3,4,5\)에서 검색 날짜를 받는 질문의 백분율을 보여줍니다.

그림 9: 데이터 세트에서 **잘못 정의된 예측 질문을 플래깅하기 위한 프롬프트** 입니다. 프롬프트에는 질문이 잘못 정의된 몇 개의 샷 예제가 포함되어 있습니다. LM은 유사한 성격의 질문을 필터링하라는 프롬프트가 표시됩니다.

그림 11: **질문 게시 시간 분포 및 검색 날짜** 입니다.

그림 10: **전체 데이터 세트의 모든 이진 질문에서 위치가 언급됩니다* *. 우리는 세계 지도의 전체 데이터 세트에서 모든 위치 언급을 시각화합니다. 이것은 데이터 세트가 전 세계적으로 주제에 대한 다양한 범위를 제공한다는 것을 보여준다.

\begin{table}
\begin{tabular}{l r r r r r} \hline \hline Platform & Questions (All) & Predictions (All) & Questions (Binary) & Predictions (Binary) & Brier Score (Binary) \\ \hline Metaculus & \(8,881\) & \(638,590\) & \(4,862\) & \(387,488\) & \(.130\) \\ INFER & \(308\) & \(73,778\) & \(192\) & \(47,918\) & \(.079\) \\ GJOpen & \(2,592\) & \(743,671\) & \(1,168\) & \(342,216\) & \(.134\) \\ Manifold & \(24,284\) & \(1,997,928\) & \(20,319\) & \(1,387,668\) & \(.155\) \\ Polymarket & \(12,689\) & \(3,720,640\) & \(7,123\) & \(1,879,035\) & \(.158\) \\ \hline \hline \end{tabular}
\end{table}
표 11: **플랫폼 간 원시 데이터 세트 통계** 입니다. 브라이어 점수는 플랫폼이 까마귀 집합체를 제공하는 모든 시점에 걸쳐 평균을 내어 계산된다.

\begin{table}
\begin{tabular}{l l} \hline \hline
**Field** & **Information** \\ \hline
**질문** & Will Stanship이 2023년 5월 1일 월요일 전에 이륙을 달성합니까? \\
**시작 날짜** & 2023-04-17 \\
**종료 날짜** & 2023-04-30 \\
**해결 날짜** & 2023-04-20 \\
**범주** & Science \& Technology \\
**플랫폼** 및 Metaculus \\
**해결 방법** & 1.0 \\
**URL** & [https://www.metaculus.com/api2/questions/15973/](https://www.metaculus.com/api2/questions/15973/) \\
**배경** & 4월 14일 스페이스X는 스타쉽 우주선에 대한 발사 허가를 받았습니다. 4월 17일로 예정되어 있던 발사가 동결 밸브로 인해 스크러빙되었습니다. 스페이스엑스 CEO 블론 머스크는 트위터에 “오늘 많은 것을 배웠고, 이제 추진체를 오프로딩하고, 며칠 안에 재시도합니다.” \\
**해결 기준** & 이 질문은 4월 30일 일요일 오후 11시 59분 ET 전에 스타쉽이 발사대를 그대로 유지하고 자체 전력으로 떠나는 경우 예로 해결됩니다. \\ 2023-04-17, 0.725), (2023-04-17, 0.793), (2023-04-17, 0.71), (2023-04-17, 0.704), (2023-04-17, 0.722), \\ & (2023-04-18, 0.774), (2023-04-18, 0.747), (2023-04-18, 0.776), (2023-04-18, 0.636), (2023-04-18, 0.636), (2023-04-18, 0.667), (2023-04-18, 0.686), (2023-04-18, 0.658), (2023-04-18, 0.685), (2023-04-18, 0.664), \\ & (2023-04-18, 0.671), (2023-04-18, 0.685), (2023-04-18, 0.69), \\ & (2023-04-18, 0.689), \\ & (2023-04-18, 0.689), (2023-04-18,
**Community Predictions** & (2023-04-18, 0.701), (2023-04-18, 0.689), (2023-04-18, 0.689), (2023-04-18, 0.686), (2023-04-18, 0.688), \\ & (2023-04-18, 0.686), (2023-04-18, 0.684), (2023-04-19, 0.688), (2023-04-19, 0.688), \\ & (2023-04-19, 0.688)

\begin{table}
\begin{tabular}{l l l l l l l l l l} \hline \hline
**Sample Question** & **Category** & **Start** & **Close** & **Resolution** & **25\%** & **50\%** & **90\%** & **Answer** \\  & & **Date** & **Date** & **Date** & **Date** & & & & \\ \hline \hline \end{tabular}
\begin{tabular}{l l} Will AI doctors replace human doctors by & Science & 2023-07-27 & 2023-12-31 & 2023-12-30 & 0.073 & 0.087 & 0.102 & No \\ the end of 2023? & & & & & & & & \\ Will US CDC classify a SARS-CoV-2 & Healthcare & 2021-07-31 & 2021-11-01 & 2022-08-02 & 0.39 & 0.408 & 0.412 & No \\ variant as "high consequence" by August & \& Biology & & & & & \\ Will Conbase file for bankruptcy in 2022? & Economics & 2022-05-12 & 2022-12-31 & 2023-01-01 & 0.08 & 0.079 & 0.072 & No \\  & & & & & & & \\ Will COP26 finalize the "Paris Rulebook" & Environment & 2021-08-26 & 2021-11-13 & 2021-11-14 & 0.063 & 0.074 & 0.13 & Yes \\ by November 16, 2021? & \& Energy & & & & & \\ Will Bonbong Marcos win the 2022 & Politics & 2021-12-20 & 2022-05-08 & 2022-05-26 & 0.759 & 0.752 & 0.759 & Yes \\ Philippine Presidential Election? & \& Governance & & & & & \\ Will UC Berkeley be primarily in-person & Education & 2021-01-22 & 2021-08-01 & 2021-08-26 & 0.723 & 0.74 & 0.765 & Yes \\ for Fall 2021? & \& Research & & & & & \\ Will Trump issue another NFT Collection & Arts & 2023-11-01 & 2023-12-12 & 2023-12-12 & 0.484 & 0.585 & 0.556 & Yes \\ before the 2024 Presidential Election? & \& Recreation & & & & & \\ Will a nuclear weapon be detonated in 2023 & Security & 2022-12-09 & 2023-12-31 & 2024-01-01 & 0.28 & 0.32 & 0.304 & No \\ (including tests and accidents)? & \& Defense & & & & & \\ Will Charlotte Hornets beat Detroit & Sports & 2023-10-16 & 2023-10-28 & 2023-10-28 & 0.46 & 0.513 & 0.337 & No \\ Pistons on Oct 27, 2023, in the NBA? & & & & & & & \\ Will flight 1111 from Munich to Zurich on 2023-08-29 arrive on time or with more than & & & & & & \\ \hline \hline \end{tabular}
\end{table}
표 13: 다른 예측 날짜(시작 날짜부터 해결 날짜까지 25%, 50% 및 90%)에서 커뮤니티의 예측과 함께 **각 범주에서 하나의 샘플 질문** 입니다. 질문이 해결 날짜에 접근함에 따라 결과에 대한 군중의 자신감은 일반적으로 증가하며, 이는 새로운 정보의 영향을 반영한다.

우리 시스템의 세부 정보

우리는 섹션 4에서 높은 수준에서 설명한 시스템에 대한 세부 정보를 제공한다. 우리는 (최적화된) 설정에서 사용되는 하이퍼파라미터를 지정한다. 그들 중 일부는 하이퍼파라미터 스윕(섹션 5.2)에 의해 발견된다.

### Retrieval System

제안하는 검색 시스템은 4단계로 구성된다. 우리는 아래에 각각에 대한 추가 세부 정보를 제공합니다.

**1단계: 검색 쿼리 생성** 그림 12에 나열된 하이퍼파라미터 스윕 절차에서 검색 쿼리를 생성하기 위해 두 개의 좋은 프롬프트를 식별합니다. 질문이 주어지면 GPT-4-미리 보기-1106에 두 프롬프트(0 온도에서)를 모두 사용하여 6개의 검색 쿼리를 생성하도록 요청합니다. 우리는 뉴스 API를 쿼리하기 위해 질문 그 자체와 함께 모든 결과 검색 쿼리의 조합을 취한다.

**2단계: 뉴스 검색** 각 뉴스 API 및 각 검색 쿼리에서 시스템은 주어진 검색 날짜 범위 내에서 게시된 상위 10개의 기사를 검색하도록 설정됩니다. 각 API의 기본 순위를 사용하고 영어 기사만 검색합니다.

질문의 배경 설명이 웹페이지에 대한 링크를 포함하는 경우, 본 시스템은 이를 스크래핑하고, 클린 텍스트를 파싱하고, 요약들을 추론 모델에 제시한다. 검색 범위를 벗어나는 정보가 누출되지 않도록 조치를 취합니다. 첫째, 타임스탬프된 기사를 게시하고 화이트리스트에서만 검색하는 뉴스 웹사이트의 화이트리스트를 유지합니다. 둘째, 본 시스템은 각 기사의 발행일자를 확인하고, 사용가능하지 않거나 검색범위를 벗어나는 경우 폐기한다.

**3단계: 관련성 순위** GPT-3.5-터보를 사용하여 0 온도에서 질문에 대한 문서의 관련성을 평가합니다. 프롬프트는 그림 14에 나와 있습니다.

본 논문에서 제안하는 검색 시스템은 관련성 필터링 이전에 초기 단계에서 많은 수의 텍스트(예: \(>50\) 논문)를 검색할 수 있다. 실행 시간을 개선하고 비용을 절약하기 위해 관련도 평가를 위해 컨텍스트에서 기사의 제목과 첫 번째 250개 단어만 모델에 제시한다. 섹션 E.3에서 우리는 이것이 전체 텍스트를 제공한 결과와 잘 근사한다는 것을 테스트한다.

시스템은 1-6의 척도로 검색된 각 기사의 관련성을 평가한다. \(\leq 3\)의 등급을 받는 모든 기사는 폐기된다. 우리는 이 임계값이나 여기서 신속한 선택을 최적화하려는 시도를 하지 않는다.

**4단계: 요약** GPT-3.5-터보를 사용하여 관련 문서를 요약합니다. 온도는 0.2로 설정됩니다. 기사 길이가 컨텍스트 창을 초과하는 경우 창 크기에 맞게 잘라냅니다. 우리는 프롬프트(그림 13)에 질문과 배경 설명도 포함되어 있으며 모델에 질문에 답하는 것과 관련된 모든 정보를 기사에 보관하도록 지시되어 있다고 지적한다. 그림 13은 유효성 검사 세트(섹션 5.2)에서 하이퍼파라미터 스윕을 통해 발견된 최상의 프롬프트를 보여준다.

### Reasoning System

우리는 GPT-4-1106-미리보기와 미세 조정된 GPT-4를 모두 사용하여 예측을 생성합니다. 우리는 그림 15를 포함한 상위 3개의 추론 프롬프트로 전자를 프롬프트한다. 다른 프롬프트도 검색된 정보 섹션에 따라 다른 스크래치패드 추론 지침을 사용하지만 그림 16과 같은 기본 템플릿을 따른다. 미세 조정된 모델에는 자세한 스크래치 패드 지침이 필요하지 않습니다(섹션 5.1). 따라서 그림 16은 그 이유를 도출하기 위해 미세 조정된 모델에 대한 전체 프롬프트 구조이다.

또한 섹션 5.1에서 언급한 바와 같이 Claude-2.1은 미세 조정을 위한 추론-예측 쌍을 생성하도록 프롬프트되었다. 그러나, 그것은 우리 시스템에서 추론에 직접적으로 사용되지 않는다.

그림 16: **모든 스크래치 패드 프롬프트는 질문의 기본 정보로 시작 하 고 검색 합니다.* * 미세 조정 된 모델은이 정보만 사용 하 고 추가 지침이 필요 하지 않습니다.

나는 당신에게 예측 질문과 그 질문에 대한 배경 정보를 제공할 것이다.

Question: {question}

Background: {background}

Task:

- 예보에 영향을 줄 수 있는 Google의 정보를 수집 하기 위해 간략 한 검색 쿼리 (각각 {max_words} 단어)를 생성 합니다.

이 정확한 쿼리 양을 생성해야 합니다. {num_keywords}

응답은 다음과 같은 구조를 취해야 합니다. 생각: {{ Insert your thinking here. }}

검색 쿼리: {{ Insert the queries here. Use semicolons to separate the queries. }}

(a) 스트레이포워드 검색 쿼리 확장 프롬프트

나는 당신에게 예측 질문과 그 질문에 대한 배경 정보를 제공할 것이다. 그런 다음 질문에 답하는 데 도움이 되는 Google News의 기사를 찾는 데 사용할 짧은 검색 쿼리(각각 {max_words} 단어)를 생성하도록 요청합니다.

Question: {question}

Background: {background}

이 정확한 쿼리 양을 생성해야 합니다. {num_keywords}

하위 질문을 적는 것으로 시작하세요. 그런 다음 하위 질문을 사용하여 생성하는 검색 쿼리를 조정합니다.

응답은 다음과 같은 구조를 취해야 합니다. 생각: {{ Insert your thinking here. }}

검색 쿼리: {{ Insert the queries here. Use semicolons to separate the queries. }}

(b) 두 번째 검색 쿼리 프롬프트를 사용합니다. 먼저 모델에 하위 질문을 고려하고 이를 사용하여 출력을 조정하도록 요청합니다.

그림 12: 질문의 데이터를 기반으로 **검색 쿼리를 생성하라는 프롬프트** 입니다.

그림 13: **검색 시스템에서 사용하는 요약 프롬프트**. 프롬프트는 질문, 배경 및 관련 기사를 제공합니다. 그것은 LM에게 예측 질문과 관련된 어떤 정보도 제거하지 않고 기사를 응축하도록 요청한다.

다음 예측 질문과 그 배경 정보를 고려하십시오. 그 후, 저는 당신에게 뉴스 기사를 제공하고 예측 문제와 관련하여 그 관련성을 평가하도록 요청할 것입니다.

Question: {question}

Question Background:{background}

Resolution Criteria:{resolution_criteria}

Article: {article}

기사와 질문의 관련성을 1-6의 척도로 평가해 주세요.

1 - 무관함

2 - 약간 관련됨

3 - 어느 정도 관련성 있음

4 - 관련

5 - 관련성이 높음

6 - 가장 관련성 있는 것

Guidelines:

- 외부 소스에 액세스할 필요가 없습니다. 제공된 정보를 고려하십시오.

- 제목이 아닌 기사 내용에 초점을 맞춥니다.

- 텍스트 콘텐츠가 JavaScript, 유료 월, 쿠키 또는 기타 기술적 문제에 대한 오류 메시지인 경우 1의 점수를 출력합니다.

귀하의 응답은 다음과 같습니다.

 생각: {{ Insert your thinking }}

 등급: {{ Insert answer here }}

그림 14: **질문에 대한 문서의 관련성을 평가하는 데 사용되는 프롬프트**. 프롬프트는 LM에게 1-6 척도의 질문과 관련하여 기사의 관련성을 평가하도록 요청한다. 우리는 "등급:" 다음 수치를 추출한다.

[MISSING_PAGE_EMPTY:30]

우리 시스템의 최적화에 관한 세부사항

### Hyperparameter Sweep

실험 내내, 우리는 질문의 열린 날짜와 해결 날짜 사이의 중간 포인트로 검색 날짜를 설정했다. 이 시점에서 군중 집합은 검증 세트의 모든 질문에 대해 평균을 낸 0.160 브라이어 점수를 달성한다.

아래 모든 하이퍼모수 스윕은 유효성 검사 세트의 모든 질문을 평가합니다.

**검색 쿼리 프롬프트** 검색 쿼리를 생성하기 위해 6개의 후보 프롬프트를 스윕합니다. 상위 2개의 프롬프트는 평균 관련성 등급이 3.08 및 3.09인 검색된 기사들로 이어지는 반면, 다른 프롬프트는 3.04 미만이다. 적어도 4개의 등급을 갖는 모든 기사들 중에서, 평균 등급은 상위 2개의 검색 쿼리 프롬프트들을 통해 4.37 및 4.38이며, 이는 또한 모든 후보들 중에서 가장 높다.

**요약 프롬프트** 요약을 위해 5개의 후보 프롬프트를 스윕하고 결과 브라이어 점수를 평가합니다. 최상의 요약 프롬프트는 0.193의 Brier 점수를 제공하고 두 번째는 0.201의 Brier 점수를 제공한다. 하이퍼파라미터 검색의 이 단계에서는 혼동을 피하기 위해 요약, 기사 수 및 추론 프롬프트의 순서를 각 질문에 대해 무작위로 선택한다.

**기사 순서 및 개수** 이 단계에서는 기사 순서(최근 또는 관련성에 따라)와 \(k\in[5,10,15,20,30]\)의 5개 후보 선택을 모두 스윕합니다. 유효성 검사 세트의 모든 질문에 대해 전체 시스템을 실행합니다. 15개의 기사 요약을 제시하고 관련성별로 정렬하면 GPT-4-1106-미리 보기에서 가장 낮은 브라이어 점수가 0.177이다. 20개의 기사 요약을 제시하면 유사한 성과를 얻을 수 있다.

**추론 프롬프트** 예측 및 추론을 이끌어내기 위한 15개의 프롬프트를 수작업으로 만듭니다. 최상의 프롬프트(도 15)는 (상기 최적화 스테이지들에 의해 발견되는 최적의 하이퍼파라미터 선택들을 고정하는 동안) 검증 세트 상에서 0.167의 브리어 스코어를 달성한다. 두 개의 다른 상위 프롬프트는 0.170과 0.174를 얻는다. 최상의 프롬프트는 그림 15에 나와 있다.

**앙상블링** 평균, 중앙값, 기하 평균, 트리밍된 평균 및 USC(universal self-consistency)의 변형을 포함하여 5개의 앙상블링 방법을 구현합니다(Chen 등, 2023). 마지막 두 가지 접근법은 다음과 같이 정의된다:

* 트리밍된 평균의 경우 입력 예측에 대해 균일한 가중치를 할당하고 중앙값에서 가장 먼 예측의 가중치를 절반으로 줄이고 절반 가중치를 다른 예측으로 균일하게 재분배한 다음 최종적으로 가중 평균을 출력합니다. 우리는 이것이 트리밍된 평균의 표준 구현이 아니며 시스템에서 적은 수(즉, 6개)의 예측만 집계하기 때문에 이러한 방식으로 설정된다고 지적한다.
* USC의 경우 (외부) 추론-예측 쌍을 최종 LM에 표시 하 고 집계 된 예측을 형성 하도록 프롬프트 합니다. 이 하이퍼파라미터 스윕에서 GPT-4-1106-미리 보기를 집계기 모델로 사용한다.

우리는 최적의 시스템 설정을 사용하여 앙상블에 대한 6개의 기본 이유를 생성함으로써 검증 세트에 대한 이러한 모든 방법을 평가한다. 트리밍된 평균은 가장 낮은 브라이어 점수를 달성하며, 결과는 표 14를 참조하십시오. 대조적으로, USC 방법은 기준선보다 개선을 입증하지 않는다.

### News API 평가

우리는 뉴스 API의 선택을 정당화하고, 우선 검색 날짜 범위를 허용하는 뉴스 코퍼스에 대해 5개의 적합한 API를 실험하며, 이는 우리의 목적을 위해 유출을 방지하기 위해 지정되어야 한다. 특히,

\begin{table}
\begin{tabular}{l c} \hline \hline Ensemble Method & Brier Score \\ \hline Mean & 0.1656 \\ Median & 0.1651 \\ Geometric Mean & 0.1655 \\
**Trimmed Mean** & **0.1649** \\ USC (Chen et al., 2023) & 0.1691 \\ \hline Baseline (No Ensemble) & 0.1676 \\ \hline Human Crowd & 0.1600 \\ \hline \hline \end{tabular}
\end{table}
표 14: **유효성 검사 세트의 다양한 앙상블 방법에 대한 장벽 점수**. "기준선"은 기본 예측의 평균 브라이어 점수(즉, 앙상블에 대한 입력)를 나타냅니다.* * Google News(파이썬 오픈 소스 패키지 gnews를 통해 액세스), NewsCatcher, Newsdata.io, Aylien 및 NewsAPI.org를 평가합니다.

검색의 품질을 평가하기 위해 먼저 24개의 해결되지 않은 예측 질문을 취한다. 다음으로 GPT-4-1106-Preview를 프롬프트하여 검색 시스템의 첫 번째 단계(섹션 4)와 유사한 24개 질문 각각에 대해 두 개의 검색 쿼리를 생성합니다. 이러한 쿼리를 사용하여 5개의 모든 API를 통해 기사를 검색하여 검색 범위를 지난 24시간으로 제한한다.

마지막으로 GPT-4가 원래 질문에 대한 기사의 관련성을 평가하도록 촉구한다. 점수가 높을수록 관련성이 더 크다는 것을 나타낸다. 각 API 옵션에 대해 검색된 모든 문서의 점수 합계를 계산합니다. 그 결과 뉴스캐처와 구글뉴스가 각각 35점과 39점으로 가장 높은 점수를 달성했다. 다른 세 가지 API인 Newsdata.io, Aylien 및 NewsAPI.org는 점수 16.5, 30.5 및 23.5이다.

### 적절성 평가 근사값

우리는 GPT-3.5 터보에게 질문과 관련하여 검색된 모든 기사(구글 뉴스 및 뉴스 캐처로부터)의 관련성을 점수화하도록 촉구한다. 우리의 프롬프트는 그림 14에 의해 제공되며, 여기서 질문의 메타데이터와 기사 텍스트가 컨텍스트에서 모델에 제공된다. 프롬프트는 LM에게 주어진 질문에 대한 기사의 관련성을 1-6의 척도로 평가하도록 요청하며, 여기서 6은 "가장 관련이 있는" 것으로 간주되고 1은 "관련 없는" 것으로 간주된다. 우리 시스템에서는 평점이 4 미만인 기사를 걸러냅니다.

**방법.** 비용 제약 조건으로 인해 전체 문서 텍스트를 사용하여 관련성 점수를 평가할 여유가 없습니다. 우리는 대략적인 전체 텍스트 기반 평가를 위해 세 가지 비용 절감 대안을 실험적으로 탐구한다.

1. 제목 전용. 관련성 등급에 대한 모델에는 기사 제목만 제공합니다. 불행히도 수동 검사를 통해 웹 스크래퍼5가 일반적으로 렌더링 오류 또는 유료 월로 인해 기사 페이지의 전체 텍스트를 로드하지 못하는 경우가 있음을 발견한다. 이러한 경우, 기사 콘텐츠는 불완전하거나 단순히 오류 메시지일 수 있는 반면, 제목은 검색되고 관련성이 있는 것으로 보인다. 결과적으로, 모델은 제목에 의해 오도될 수 있다 따라서, 우리는 이 접근법이 생존할 수 없다고 믿는다. 각주 5: [https://pypi.org/project/newspaper4k/](https://pypi.org/project/newspaper4k/)
2. 제목 + 처음 250단어. 우리는 등급에 대한 모델에 기사 제목과 처음 250개의 단어를 부여한다.
3. 임베딩 유사성. 문서 텍스트와 질문 텍스트 메타데이터를 삽입하고 코사인 유사도를 계산한다. 유사도를 기준으로 기사를 필터링합니다.

**실험.** 위의 (ii) 및 (iii) 접근법으로 실험합니다. (ii)의 경우 GPT-3.5-터보 및 Mixtral-8x7B-DPO에 동일한 프롬프트 템플릿을 사용하여 관련성 등급을 프롬프트한다(그림 14). (iii)의 경우 OpenAI의 text-embedding-3-large를 임베딩 모델로 사용한다.

원시 기사를 생성하기 위해 검증 세트에서 15개의 질문을 무작위로 샘플링하고 검색 시스템을 관련 등급까지 실행하고 총 169개의 기사를 수집한다.

GPT-4(금 라벨로 간주)를 통해 전체 텍스트의 관련성 점수를 평가하고 위에서 설명한 근사치와 비교한다. 글의 등급이 GPT-4를 통한 전체 텍스트 쿼리로부터 최소 4인 경우 해당 글과 관련이 있다고 한다. 우리는 근사 방법의 재현율과 정밀도를 다음과 같이 계산한다.

* 4의 임계값에서 GPT-3.5-터보를 통해 제목 + 처음 250개의 단어는 재현율 0.73, 정밀도 0.65를 제공한다.
* 임계값 3에서 Mixtral-8x7B-DPO를 통해 제목 + 처음 250개의 단어는 재현율 0.70 및 정밀도 0.63을 제공한다.
* 0.48의 임계값에서 코사인 유사성 방법은 재현율이 0.73이고 정밀도가 0.54입니다.

요약하면, 재현율을 70% 이상으로 고정하고, 제목 + 처음 250개의 단어로 GPT-3.5-터보를 쿼리하는 것이 가장 높은 정밀도에 도달한다. 기사의 평균 토큰 길이는 1087.6이다. 따라서, 처음 250 단어(또는 대략 330 토큰)를 사용하는 방법은 비용의 약 70%를 절약한다.

Example Outputs

테스트 세트에 대한 미세 조정된 GPT-4 모델의 5가지 정성적 예제 출력을 제공한다.

1. 개진 및 확장 질문: 케빈 맥카시 전 하원의장이 2023년 11월 30일 말 이전에 미국 하원에서 출발했음을 나타내는 신뢰할 수 있는 소식통에 의해 공식 발표하거나 사임을 보고할 가능성이 있습니까? 이 질문은 현재의 정치적 분위기, 맥카시의 최근 의장직 상실, 재선을 모색하지 않는 고려, 공화당 및 캘리포니아 20구역에 대한 그의 결정의 잠재적 영향을 고려한다. 이 시장의 해결은 매카시가 지정된 기간 내에 자리를 비우겠다는 의사를 공식적으로 선언할지에 달려 있다.
2. 대답이 '아니오'일 수 있는 이유:

- 맥카시는 최종 결정을 내리지 않았고 의회에서 자신의 미래에 대한 불확실성을 표명했는데, 이는 그가 여전히 자신의 선택권을 저울질하고 있고 주어진 기간 내에 사임을 선택하지 않을 수 있음을 의미할 수 있다. (강도: 강함)

- 기사는 사직에 대한 추측과 고려가 있지만 임박한 사임을 나타내는 명확한 성명이나 조치가 없음을 시사한다. (강도: 강함)

매카시는 정치적 지형이 어떻게 변하는지 보거나 가족과 상의한 후 결정을 내릴지 기다리고 있을 수 있습니다 11월 30일 마감일을 넘길 수도 있죠 (강도 : Moderate)

강력한 재정적 지원과 정치적 영향력의 역사를 고려할 때 매카시는 정치 과정에 남아서 영향력을 행사해야 한다고 느낄 수 있습니다 특히 다가오는 2024년 선거에서요 (강도 : Moderate)

3. 대답이 예일 수 있는 이유:

맥카시 본인이 사임을 고려하고 있다는 보도와 힌트가 있어요 "당장 나가라"고 할 수도 있고 조기 출발 가능성을 시사할 수도 있죠 (강도 : Moderate)

- 정치적 반대자들의 압력과 최근 의장직의 상실은 특히 그의 영향력이 줄어들고 있다고 느낀다면 사임 결정에 기여할 수 있다. (강도 : Moderate)

특별 선거가 소집될 가능성은 통제된 권력 전환의 기회를 제공할 수 있고 이는 맥카시에게 매력적일 수 있습니다 (강도: 약함)

4. 골재 고려사항:

매카시의 사임 가능성에 대한 추측과 일부 시사적인 언급이 있지만, 그가 정해진 날짜까지 사임할 것이라는 구체적인 증거나 발표는 없다. 자금 모금과 정치적 영향력의 역사는 물론 그의 미래에 대한 확실한 진술의 부족은 11월 30일까지의 사퇴가 확실하지 않다는 것을 암시한다.

5. 초기확률:

위의 고려 사항을 감안할 때 맥카시가 11월 30일까지 사임할 초기 확률은 낮은 것으로 판단된다.

6. 조정된 확률 고려사항:

- 계산된 확률은 McCarthy 자신이 표현한 불확실성으로 인해 어느 방향으로도 과도하게 확신해서는 안 된다.

- 불확실성에 직면하여 이러한 세간의 이목을 끄는 사퇴의 기준금리가 잘 확립되어 있지 않아 이 사건을 예측하는 데 어려움을 가중시킨다.

- 직관적으로, 정치인들은 종종 그들의 선택지를 신중하게 평가하며, 특히 명확한 전략적 이유 없이 사임 결정은 일반적으로 서두르지 않는다.

7. 최종 답변: *0.20*

그림 17: "케빈 맥카시가 11월 30일까지 하원에서 사임할 것인가?" (해결된 NO)라는 질문에 대한 미세 조정된 모델의 응답입니다. 원래 프롬프트(여기에 표시되지 않음)를 조사한 결과, 우리는 우리의 검색 시스템이 11월 30일에 발행된 기사를 제시한다는 것을 알게 되는데, 이는 케빈 맥카시의 잠재적인 사퇴에 대한 공식적인 발표가 아직 이루어지지 않았음을 분명히 보여준다. 11월 30일, 커뮤니티 예측은 1%로 떨어졌지만, 우리 시스템은 20%를 주장하며 헤지를 합니다.

1. 레딧이 2023년 7월 1일 이전에 가격 구조의 변경 또는 현재 개발자에게 더 높은 사용량에 대해 요금을 부과하기로 설정된 API(Application Programming Interface)의 요금 구현 지연에 대해 공식 발표합니까? 이 질문은 Reddit이 현재 1K API 호출당 $0.24와 다른 가격 책정 모델, 무료 API 사용 임계값에 대한 조정, 2023년 7월 1일 이후 구현 날짜 지연 또는 개별 조직과의 특정 요금 협상이 포함되지 않는 변경 사항 중 하나를 전달하면 긍정적으로 해결됩니다. 이 질문의 해결은 메타쿨루스에 의해 결정되며, 발표가 불분명하거나 명시된 기준을 충족하지 않으면 질문이 무효화될 수 있다. 2. 대답이 아니오일 수 있는 이유: - 레딧의 CEO인 스티브 허프만은 API 변경에 대해 일관되게 확고한 입장을 보여 왔으며 기업이 수익성과 지속 가능성을 보장하기 위해 새로운 가격 구조를 추진할 필요성을 강조했습니다. 이러한 단호한 입장은 발표된 API 요금 가격의 변화가 거의 없음을 시사한다. - 수천 개의 레딧 커뮤니티의 상당한 반발과 조정된 시위에도 불구하고, 레딧의 내부 통신이나 공개 진술에서 API 요금 가격 책정 또는 구현 시간표를 변경하는 것을 고려하고 있다는 표시는 없었다. - 레딧 CEO의 내부 메모에서 그는 시위가 *통과할 것"이고 시위로 인한 큰 수익 영향이 없다고 언급했으며, 이는 회사가 불만을 극복하고 계획대로 변화를 진행할 준비가 되어 있을 수 있음을 나타냅니다. 3. 답변이 예일 수 있는 이유: - 광범위한 시위와 많은 커뮤니티가 어두워지면 잠재적으로 상당한 사용자 및 개발자 이탈로 이어질 수 있으며, 이는 레딧이 플랫폼의 활동과 콘텐츠에 상당한 부정적인 영향을 피하기 위해 입장을 재고하도록 강요할 수 있습니다. - 다른 요금에 대한 개별 조직과의 협상에 대한 구체적인 언급은 레딧이 특정 당사자의 가격 조정에 열려 있다는 신호일 수 있으며, 이는 시위가 계속되거나 주요 개발자가 앱을 종료하겠다고 위협할 경우 더 광범위한 변경으로 이어질 수 있다. - 부정적인 홍보와 사용자 불만은 회사가 브랜드와 커뮤니티에 대한 장기적인 손해가 단기적인 재정적 이익의 가치가 없다고 판단하여 API 수수료 가격 정책에 변화를 초래할 수 있는 정점에 도달할 수 있습니다. 4. 각 이유의 강도를 평가합니다. - 일관된 공개 진술과 회사의 광범위한 재무 전략을 기반으로 하기 때문에 레딧 CEO의 단호한 입장의 강도가 높습니다. - 구현 날짜에 대한 근접성과 달리 제안하는 현재 통신 부족을 고려할 때 API 요금 가격 책정에서 잠재적인 변경 표시의 부족도 강력한 이유입니다. - 시위 및 수익 영향 부족에 대한 내부 메모의 무시적인 어조는 회사의 현재 태도를 반영하지만 증가하는 압력에 대한 변화를 배제하지 않기 때문에 온건한 이유이다. - 사용자 및 개발자 이탈 가능성은 투기적이며 아직 완전히 실현되지 않은 시위의 실제 영향에 달려 있기 때문에 적당한 이유이다. - 개별 조직과의 협상에 대한 언급은 모든 개발자에 대한 정책을 반드시 변경하려는 의지를 나타내는 것은 아니기 때문에 광범위한 변경의 약한 이유이다. - 불확실한 단기적인 재정적 이익보다 레딧이 장기적인 브랜드와 커뮤니티를 우선시할 것이라는 가정에 기반하기 때문에 부정적인 퍼블리시티로 인한 티핑 포인트의 가능성은 적당한 이유입니다. 5. 고려 사항 수집: 레딧의 리더십의 강력하고 일관된 입장, 변경의 공개 표시 부족 및 시위가 수익에 미치는 영향을 기각하는 것을 고려할 때, 레딧이 2023년 7월 1일 이전에 API 요금 가격 변경 사항을 발표할 가능성은 거의 없어 보입니다. 그러나 부정적인 퍼블리시티의 가능성과 시위가 플랫폼 활동에 미치는 영향을 완전히 기각할 수 없으며, 이는 예측에 약간의 불확실성을 도입합니다. 6. 답변 출력: 사용 가능한 정보와 위의 고려 사항을 감안할 때, 레딧이 2023년 7월 1일 이전에 제안된 API 요금 가격 변경 또는 지연을 발표할 가능성은 낮습니다. 따라서 내 대답은 다음과 같습니다. *0.2*

그림 18: "Reddit이 2023년 7월 1일 이전에 제안된 API 요금 가격에 대한 변경 사항 또는 지연을 발표할 것인가?"라는 질문에 대한 미세 조정된 모델의 응답(해결된 NO). 질문이 열린 지 하루 만인 2023년 6월 14일 회수일에 예보가 내려졌다. 당시 커뮤니티는 40%의 예측치를 제시했는데, 이 응답은 20%를 시사하며, 이는 결의안에 더 가까운 것으로 나타났다.

1. 다시 발표되고 확장된 질문: 현재의 지정학적 긴장과 최근의 역사적 사건을 고려할 때, 이스라엘 국가는 이란 국경 내에서 적어도 5명의 이란 국민을 사망에 이르게 하는 군사 작전을 수행할 가능성이 있으며, 이후 공개적으로 이 조치의 책임을 주장하거나 신뢰할 수 있는 출처가 모두 2023년 말 이전에 이스라엘에 공격을 명확하게 귀속시킬 수 있는 명확하고 명백한 방식으로 작전을 수행할 가능성이 있습니까?
2. 결정 트리 개요:

- 예 결과:

이스라엘은 이란에 대한 군사 작전을 수행합니다

이 작전은 명백히 이스라엘의 소행입니다

이스라엘은 이 작전을 공개적으로 인정하고 인정합니다

이 수술로 24시간 내에 이란인 사망자는 최소 5명입니다

- 결과 없음:

이스라엘은 이란에 대한 군사 작전을 수행하지 않습니다

이스라엘은 작전을 수행하지만 은밀하고 귀책 사유가 아닙니다

이스라엘은 작전을 수행하지만 공개적으로 인정하지 않습니다

이 수술로 24시간 내에 이란인 사망자는 최소 5명이 아니다.

3. 분기 확률 분석:

- 예 결과:

최근 긴장의 고조와 역사적 전례를 고려할 때 이스라엘이 이란에 대한 군사 작전을 수행할 가능성은 무시할 수 없다.

- 이스라엘이 그러한 작전을 공개적으로 인정할 가능성은 종종 그럴듯한 부인 가능성을 유지하기 때문에 더 낮다.

- 최소 5명의 이란 사망을 초래하는 작전의 확률은 불확실하며 작전의 규모와 특성에 따라 달라진다.

- 결과 없음:

- 은밀한 행동에 대한 이스라엘의 역사적 선호와 국제적 반발 가능성을 고려할 때 군사 작전이나 은밀한 작전이 없을 확률은 더 높다.

- 이스라엘이 작전을 인정하지 않을 가능성도 높은데, 이는 직접적인 갈등과 국제적 압력을 피하기 위한 일반적인 관행이기 때문이다.

- 특히 수술이 제한적이거나 수술적으로 설계되는 경우 사망 임계치를 충족하지 못하는 수술의 기회도 가능하다.

4. 와일드카드에 대한 토론:

- 이란으로 인한 이스라엘 토양에 대한 직접적인 공격과 같이 이스라엘과 이란 간의 갈등이 크게 확대되면 '예' 결과가 나올 확률이 높아질 수 있다.

- 국제 외교적 노력이나 이스라엘에 대한 대폭적인 축소 압박은 '예' 결과가 나올 확률을 낮출 수 있다.

- 주요 테러 공격 또는 두 국가의 갑작스러운 리더십 변화와 같은 예측할 수 없는 사건도 예측에 영향을 미칠 수 있습니다.

5. 초기 확률(Prediction):

현재 정보와 요약된 결정 트리를 감안할 때 '예' 결과의 초기 확률은 낮지만 불가능한 것은 아니다. 약 0.20으로 추정됩니다.

6. 조정된 확률 사상:

- 중동의 불안정한 특성과 군사 교전의 예측 불가능성을 고려할 때 계산된 확률은 너무 자신만만할 수 있습니다.

최근 이스라엘의 공습으로 이란 장군이 사망하면서 긴장이 고조돼 '예스' 결과가 나올 가능성이 높아질 수 있다.

10월 7일 하마스 공격과 이란을 연결하는 직접적인 증거가 부족하고 은밀한 작전 가능성이 있으면 '예스' 결과가 나올 가능성이 낮아질 수 있다.

7. 최종 답변: *0.15*

그림 19: "이스라엘이 2024년 이전에 이란에 대한 치명적인 공격을 수행하고 명시적으로 인정할 것인가?"라는 질문에 대한 우리의 미세 조정된 모델의 답변(해결된 NO). 미세 조정 단계에서 강력한 추론을 생성하기 위해 사용하는 프롬프트 중 하나는 모델에 결정 트리를 구축하고 확률을 할당하도록 요청한다. 미세 조정된 모델은 (그렇게 하도록 명시적으로 프롬프트되지 않고) 추론 경로를 학습한다.

1. 개진 및 확장 질문: 도널드 J. 트럼프 전 대통령이 2023년 8월 23일 열릴 예정인 2024년 선거 주기 출범 공화당 전국위원회(RNC) 대통령 경선 토론에 참석하여 적극적으로 참여하는 것이 확인되는가? 토론 중 한 번 이상 발언하고 토론 진행자에게 인정받는 것이 참여 기준이다. 이것은 그가 원격으로 토론에 참여하더라도 적용된다. 이 문제의 해결은 토론이 여러 날에 걸쳐 확산되는 경우 토론의 모든 부분을 고려할 것이다. 그러나 2023년 9월 30일을 넘어 토론이 연기되면 시장은 ‘아니오’로 결의한다. 결의는 주로 신뢰할 수 있는 뉴스 보도의 합의에 의해 보완된 실제 토론 영상에 기초할 것이다.
2. 답변이 아닐 수 있는 이유: - 트럼프는 전략적 이점을 유지하거나 다른 후보와의 조기 대립을 피하기 위해 토론을 생략하는 것을 선택할 수 있다.

자신의 브랜드나 메시지를 희석시킬 수 있는 덜 중요하다고 생각하는 후보들과 무대를 공유하고 싶지 않을 수도 있습니다

- 토론 형식이나 중재자의 선택에 대한 우려가 있을 수 있으며, 이는 참여하지 않기로 결정할 수 있다.

3. 대답이 예일 수 있는 이유:

토론회에 참여하면 트럼프에게 자신의 정책과 비전을 개괄할 수 있는 플랫폼이 마련돼 선거 운동에 도움이 될 수 있다.

상대와 직접 맞붙고 상대에게 도전할 수 있어 잠재적으로 자신의 입지를 강화할 수 있죠

트럼프는 1차 시즌의 첫 번째 주요 행사에 참석함으로써 리더십과 자신감을 보여주고 싶어할 수 있다.

4. 각 이유의 강도를 평가하는 단계:

- 토론을 건너뛰는 전략적 이점: 중도. 트럼프는 파격적인 캠페인 전략의 역사를 가지고 있지만, 첫 번째 토론을 건너뛰는 것은 위험한 조치이다.

- 스테이지를 공유 하지 않음: 중간. 트럼프의 브랜드는 강하지만 여러 상대에게 무색하거나 도전받는 위험을 감수하고 싶지 않을 수도 있다.

- 형식 또는 조정자에 대한 우려: 중간에서 높음입니다. 트럼프는 이전에 그의 결정에 영향을 미칠 수 있는 토론 준비에 불만을 표명했다.

- 정책 개요의 이점: 높음. 토론은 많은 청중에게 다가가 그의 출마를 입증할 수 있는 중요한 기회이다.

- 상대와 교전 중: 하이. 트럼프는 토론 환경에서 유리하게 작용할 수 있는 대결 스타일로 유명합니다.

- 리더십 발휘: 높음. 트럼프 대통령은 전직 대통령으로서 처음부터 공화당 분야에서 자신의 지배력을 주장하고 싶어할 수도 있다.

5. 고려 사항을 집계합니다.

그 이유와 강점을 고려할 때 트럼프 대통령의 참여 여부에 영향을 미칠 수 있는 요인들이 균형 잡힌 세트인 것으로 보인다. 그의 파격적인 전술과 토론 준비에 대한 우려의 역사는 ‘아니오’로 이어질 수 있고, 정책 추진, 반대파 참여, 리더십 발휘 측면에서 잠재적 이익은 ‘예’로 이어질 수 있다. 트럼프의 참여의 전략적 가치에 대한 평가와 토론 날짜에 더 가까운 구체적인 상황에 따라 결정될 가능성이 높다.

6. 답변 출력: 균형 잡힌 고려 사항과 트럼프의 캠페인 전략의 예측할 수 없는 특성을 고려할 때, 나는 그것이 제공하는 높은 혜택으로 인해 참여에 약간 기울지만 그에 대한 잠재적인 전략적 고려 사항으로 인해 압도적으로 기울지 않는 확률을 할당할 것이다. *0.55*

그림 20: “트럼프가 첫 RNC 토론에 참석할 것인가?” (2023년 8월 23일 NO를 해결함) 질문에 대한 우리의 미세 조정된 모델의 답변입니다. 질문이 열린 지 2일 후인 2023년 6월 15일 회수 지수 1에서 예보가 이루어졌다. 당시 커뮤니티는 이 응답으로 인한 우리 모델의 예상치인 55%에 가까운 60%를 예측했다.

1. 요약 및 확장 질문: 영화 '바비'가 개봉 주말 동안 '오펜하이머'가 벌어들일 금액의 최소 두 배인 국내 흥행 총액을 달성할 것이라고 말하는 것이 정확한가? 이 비교는 박스오피스 모조에 기록된 바와 같이 미국에서 3일간의 개막 주말(7월 21일-23일)에 대한 최종 보고된 수치를 기반으로 할 것이다. 결과는 '바비'와 '오펜하이머'의 "국내 주말" 총수익을 비교하여 결정되며, '바비의 총수익이 '오펜하이머'의 최소 2배라면 시장은 '예'에 찬성하여 해결된다. 2023년 7월 31일까지 최종 데이터를 사용할 수 없다면 시장을 해결하기 위해 신뢰할 수 있는 대체 소스를 사용할 것이다.
2. 대답이 '아니오'일 수 있는 이유:

- '오펜하이머'는 기대 이상의 성능을 가질 수 있어 두 영화의 총수익 간의 비율을 줄일 수 있다. (강도: 약함, 현재 예측 및 보고서를 감안할 때)

- '오펜하이머'의 특정 인구 통계학적 매력에 대한 상당한 과소 평가가 있을 수 있습니다. (강도: 약함, 현재 데이터는 이를 지원하지 않기 때문이다.)

- 예상치 못한 이벤트는 극장의 논란이나 광범위한 기술 문제와 같은 '바비의 참석'에 부정적인 영향을 미칠 수 있다. (강도: 약함, 그러한 이벤트들의 표시가 없기 때문에)

3. 대답이 예일 수 있는 이유:

- '바비'는 이미 개막 주말 총수익이 '오펜하이머'보다 훨씬 높은 것으로 보고돼 2배 선을 넘어선 수치다. (강도: 강함, 다수의 보고에 기초함.)

'바비'는 '오펜하이머'보다 더 많은 극장에서 공연하고 있는데, 이는 더 높은 총수익에 기여할 수 있다. (강도: 중간, 스크린 카운트가 흥행 성과에 영향을 미칠 수 있음)

- '바비'는 더 넓은 매력을 가지고 있으며 가족과 젊은 청중을 포함하여 더 넓은 인구 통계를 대상으로 하며, 이는 더 높은 출석으로 이어질 수 있다. (강점: 인구통계학적 매력이 흥행에서 중요한 요소이기 때문에 적당히)

4. 고려 사항을 종합합니다. 제공된 정보를 고려할 때, '바비'는 개봉 주말 총액에서 '오펜하이머'에 대한 강한 우위를 가지고 있으며, 여러 보고서에서 이미 '오펜하이머'의 총액의 두 배 이상을 달성했음을 나타냅니다. '바비'의 광범위한 공개 및 인구 통계학적 매력은 '오펜하이머'에 대한 총액에서 최소 2배 선두를 유지할 가능성을 더욱 뒷받침합니다. '오펜하이머'가 '바비'의 총액을 두 배로 늘리는 것을 방지할 만큼 격차를 크게 줄일 것이라고 제안하는 증거는 거의 없습니다.

5. 초기 확률(예측): '바비'가 '오펜하이머의 총량'을 두 배로 늘리는 것에 유리한 강력한 증거가 주어지면, 초기 확률은 높다.

6. 계산된 확률이 과도하게 자신 있는지 또는 충분히 자신 있지 않은지를 평가한다: 계산된 확률은 자신 있어 보이지만, 그것은 신뢰할 수 있는 소스로부터의 구체적인 데이터 및 보고서에 기초한다. 그러나 최종 결과에 영향을 미칠 수 있는 예측하지 못한 요인의 가능성을 고려하는 것이 중요하다. 확률은 높지만 잠재적인 불확실성을 설명하는 것은 절대적이어서는 안 된다.

7. 최종 예측 출력: *0.95*

그림 21: "바비'가 오프닝 주말에 '오펜하이머'보다 총 2배 더 많을 것인가?"라는 질문에 대한 우리의 미세 조정된 모델의 반응입니다. 질문은 2023년 7월 24일 NO를 해결했으며, 2023년 7월 20일 커뮤니티는 73%를, 위의 응답은 95%를 제공했다. 원래의 프롬프트(여기에 표시되지 않음)에서, 우리의 뉴스 검색은 바비가 흥행에서 오펜하이머를 능가할 것이라는 예측을 제공한다. 그러나, 모델은 그것들을 사실로 환각(“[...] 수치들이 2배 마크를 초과함”)하여 과신을 초래한다.
