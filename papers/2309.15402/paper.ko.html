<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 사고추론의 사슬에 대한 조사: 진보, 개척, 미래\n' +
      '\n' +
      ' 정추\\({}^{1}\\), 징창천\\({}^{1}\\), 치앙롱천\\({}^{2}\\), 위장유\\({}^{2}\\), 도허\\({}^{1}\\)\n' +
      '\n' +
      '**하오톈왕\\({}^{1}\\), 위화펑\\({}^{2}\\), 명류\\({}^{1\\dagger}\\), 빙친\\({}^{1}\\), 탁류\\({}^{1}\\)\n' +
      '\n' +
      '중국 하얼빈 공대\n' +
      '\n' +
      '중국 선전 화웨이\n' +
      '\n' +
      '{zchu, jcchen, the, mliu\\({}^{\\dagger}\\), qinb, tliu}@ir.hit.edu.cn\n' +
      '\n' +
      '{chenqianglong.ai, wanght1998, Weijiangyu8, pengwh.hit}@gmail.com\n' +
      '\n' +
      ' 교신 작성자\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '인간의 지능에 기초하는 인지 과정인 연쇄 사고 추론은 인공 지능과 자연 언어 처리의 영역에서 상당한 주목을 받았다. 그러나, 이 경기장에 대한 종합적인 조사는 여전히 부족하다. 이를 위해 첫발을 내딛고 이 연구 분야에 대한 철저한 조사를 신중하고 폭넓게 제시한다. 우리는 X-of-Thought을 넓은 의미에서 Chain-of-Thought을 지칭하기 위해 사용한다. 세부적으로, 우리는 XoT 구성, XoT 구조 변형 및 향상된 XoT를 포함한 방법의 분류학에 따라 현재 연구를 체계적으로 정리한다. 또한 계획, 도구 사용 및 증류를 다루는 프런티어 애플리케이션이 있는 XoT에 대해 설명합니다. 또한, 우리는 도전을 다루고 충실성, 멀티모달 및 이론을 포함한 몇 가지 향후 방향에 대해 논의한다. 우리는 이 조사가 사고 연쇄 추론1의 영역 내에서 혁신을 추구하는 연구자들에게 귀중한 자원이 되기를 바란다.\n' +
      '\n' +
      '각주 1: 리소스는 [https://github.com/zchuz/CoT-Reasoning-Survey](https://github.com/zchuz/CoT-Reasoning-Survey)에서 사용할 수 있습니다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '사전 훈련된 언어 모델(PLM)은 레이블이 지정되지 않은 텍스트로부터 일반 표현을 자동으로 학습하고 다운스트림 태스크에 대한 미세 조정을 통해 우수한 성능을 달성할 수 있다. Devlin et al.(2019); Raffel et al.(2020); Radford and Narasimhan(2018). 최근 언어 모델을 확장하면 성능이 크게 향상되며 새로운 능력인 Wei 등(2022); Schaeffer 등(2023)과 같은 많은 놀라움을 불러온다. 따라서 자연어 처리의 패러다임이 미세 조정을 통한 사전 학습에서 인맥 학습을 통한 사전 학습으로 전환되고 있다. 그러나, 현재, 대규모 언어 모델들(LLMs)은 여전히 수학적 추론 Cobbe 등(2021); Patel 등(2021), 상식 추론 Talmor 등(2021); Mihaylov 등(2018) 등과 같은 복잡한 추론 과제들에 대해 상당한 개선의 여지가 있다.\n' +
      '\n' +
      'LLM을 활용하여 복잡한 추론 작업을 다루기 위해 Wei et al.(2022)은 단계별 추론 프로세스를 사용하여 인-컨텍스트 학습을 확장하며, 먼저 CoT(Chain-of-thought) 프롬프트 개념을 도입한다. Kojima et al.(2022)은 프롬프트에서 단순히 매직 구절 _차근차근 생각해보자_ 를 추가하면 LLM이 사람의 주석 없이 제로샷 연쇄 사상 추론을 수행할 수 있음을 발견한다. 이러한 연구들은 복잡한 추론에 대한 모델의 능력을 향상시키고 추론 및 계획 능력을 향상시키는 데 있어 연쇄적 사고의 중요성을 강조했다.\n' +
      '\n' +
      '그 후, 자동 XoT 구축 Kojima et al. (2022); Zhang et al. (2023); Xu et al. (2023), XoT 구조 변형 Chen et al. (2022); Ning et al. (2023); Lei et al. (2023); Yao et al. (2023) 등과 같은 NLP 커뮤니티에서 비가 내린 후 버섯과 같이 XoT에 대한 상당한 연구가 나타난다. 원시 CoT와 구별하기 위해 우리는 XoT를 사용하여 넓은 의미에서 CoT를 지칭하는데, 이는 단계별 추론 방법의 사용을 총칭하는 용어이다.\n' +
      '\n' +
      '그러나, 이러한 방법 및 데이터 세트는 아직 체계적인 검토 및 분석을 거치지 않았다. 이러한 공백을 메우기 위해 XoT 패밀리에 대한 포괄적이고 상세한 분석을 수행하는 이 작업을 제안한다. 사슬적 사고에 대한 몇몇 연구가 있었지만, 이는 프롬프트 Qiao 등(2023)을 사용한 LLM 추론 및 사슬적 사고 프롬프트 전략 Yu 등(2023)과 같은 특정 측면에 국한된다. 대조적으로, 우리의 조사는 그들이 이미 다룬 주제에 대한 보다 철저하고 포괄적인 토론을 제공할 뿐만 아니라 XoT 구축, XoT 구조적 변형 및 프론티어 애플리케이션 등과 같은 추가 주제 및 토론을 포함한다. 구체적으로, 본 논문에서는 먼저 관련 배경과 예비(SS2)를 소개한다. 또한 XoT 시리즈 작업을 여러 관점에서 신중하게 분류하고 XoT 구축 방법(SS4.1), XoT 구조 변형(SS4.2) 및 XoT 향상 방법(SS4.3)을 포함한 심층 분석(SS4)을 완료한다. 그런 다음 프론티어 필드(SS5)에서 XoT의 실제 응용을 제공한다. XoT의 후속 작업에 영감을 주기 위해 이 분야의 향후 연구를 위한 잠재적인 방법에 대한 통찰력을 제공한다(SS6). 마지막으로, 기존 방법(SS7)을 비교 및 논의한다.\n' +
      '\n' +
      '## 2 백그라운드 및 예비\n' +
      '\n' +
      '### Background\n' +
      '\n' +
      '최근 몇 년 동안, 컴퓨팅 파워의 지속적인 확장과 함께, 대규모 언어 모델들이 Brown 등(2020); OpenAI(2023); Touvron 등(2023); Scao 등(2022); Touvron 등(2023); Zhao 등(2023), 모델 사이즈가 계속 성장함에 따라, 인-컨텍스트 학습 및 연쇄-사상 추론 Brown 등(2020); Wei 등(2022); Baa; Schaefer 등(2023)과 같은 많은 새로운 능력들이 출현하였다.\n' +
      '\n' +
      'Brown et al.(2020)은 대규모 언어 모델들이 인컨텍스트 학습(in-context learning, ICL) 능력이 우수하다는 것을 발견한다. ICL은 입력-출력 데모를 프롬프트 텍스트에 통합한다. ICL을 사용하면 추가 미세 조정 없이 기성 LLM을 사용할 수 있으며 유사한 성능을 얻을 수 있다. 그럼에도 불구하고 이러한 종단 간 접근은 복잡한 추론 과제에 직면했을 때 성능이 떨어지는 경향이 있다.\n' +
      '\n' +
      'Wei et al. (2022)은 LLMs의 추론 능력이 단계적 추론 과정을 데모에 추가함으로써 향상될 수 있음을 발견했는데, 이는 연쇄적 사고 프롬프트라고 알려져 있다. CoT 프롬프트를 통해 모델은 질문의 복잡성과 추론 과정 모두에 대한 보다 정확한 이해를 얻을 수 있다. 또한, 모델은 일련의 추론 단계를 생성하며, 이는 모델의 인지 과정에 대한 투명한 관점을 제공하여 해석 가능성을 더욱 향상시킨다.\n' +
      '\n' +
      '### Preliminary\n' +
      '\n' +
      '이 절에서는 LLMs를 이용한 예비 연쇄 사상 추론을 소개하고 Qiao et al.(2023)의 공식 정의를 참조한다. 질문 \\(\\mathcal{Q}\\), 프롬프트 \\(\\mathcal{T}\\) 및 확률적 언어 모델 \\(P_{LM}\\)이 있다고 가정하자. 이 모델은 질문과 프롬프트를 입력으로 하여 이론적 근거 \\(\\mathcal{R}\\)와 답 \\(\\mathcal{A}\\)를 제공한다. 우리는 먼저 시연이 추론 사슬을 포함하지 않는 상황 내 시나리오를 고려한다. 우리는 식 (1,2)와 같이 정답 \\(\\mathcal{A}\\)의 가능성을 최대화할 필요가 있다.\n' +
      '\n' +
      '\\[p(\\mathcal{A}\\mid\\mathcal{T},\\mathcal{Q})=\\prod_{i=1}^{| \\mathcal{A}|}p_{LM}(a_{i}\\mid\\mathcal{T},\\mathcal{Q},a_{<i}) \\tag{1}\\] \\[\\mathcal{T}_{ICL}=\\{I,(x_{1},y_{1}),\\cdots,(x_{n},y_{n})\\} \\tag{2}\\]\n' +
      '\n' +
      '시연이 추론 과정을 포함하는 연쇄적 사고 추론 시나리오에서 식 (3,4,5,6)과 같이 정답 \\(\\mathcal{A}\\)과 근거 \\(\\mathcal{R}\\)의 가능성을 최대화해야 한다.\n' +
      '\n' +
      '\\mathcal{Q},\\mathcal{R})=\\prod_{i=1}^{| \\mathcal{R}|}p_{LM}(r_{i}\\mid\\mathcal{T},\\mathcal{Q},\\mathcal{R})=\\prod_{j=1}^{ |\\mathcal{A}|\\mathcal{T},\\mathcal{Q},\\mathcal{R})=p(\\mathcal{A}\\mid\\mathcal{T},\\mathcal{Q},\\mathcal{R},a_{<j})\\] (5) \\[\\mathcal{T}_{\\text{CoT}}=\\{I,(x_{1},e_{1},y_{1}),\\cdots,(x_{n},e_{n},y_{n})\\} \\tag{6}\\]\n' +
      '\n' +
      '## 3 Benchmarks\n' +
      '\n' +
      '### Mathematical Reasoning\n' +
      '\n' +
      '수학적 추론은 모델의 추론력을 측정하는 데 자주 사용된다. 초기 벤치마크는 간단한 산술연산 Hosseini 등(2014), Koncel-Kedziorski 등(2015), Roy and Roth 등(2015), Koncel-Kedziorski 등(2016)을 포함한다. Ling 등(2017)은 자연어 형태로 추론 과정을 레이블링하고, Amini 등(2019)은 프로그램 형태로 추론 과정을 레이블링하여 AQUA를 구축한다. 이후 벤치마크인 Miao et al.(2020); Patel et al.(2021); Cobbe et al.(2021); Gao et al.(2023)은 보다 복잡하고 다양한 질문을 포함하고 있다. Zhu et al.(2021); Chen et al.(2021); Chen et al.(2022)은 테이블 내용에 기반한 추론을 요구한다. 또한 일반적인 벤치마크인 Hendrycks et al. (2021); Mishra et al. (2022); Baa et al. (2022) 및 독해 형태 벤치마크인 Dua et al. (2019); Chen et al. (2023). 최근 Yu et al.(2021)은 계층적 추론과 지식을 이용하여 수학적 추론 능력을 사전에 훈련한 모델을 부여하였다.\n' +
      '\n' +
      '### Commonsense Reasoning\n' +
      '\n' +
      '상식 추론은 일상 세계에서 일반적으로 알려져 있고 일반적으로 인식되는 지식을 바탕으로 추론, 판단, 이해를 하는 과정이다. 상식적인 지식을 습득하고 이해하는 방법\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:3]\n' +
      '\n' +
      '2020; Wu et al., 2021; Xiao et al., 2021; Li et al., 2022; Gupta and Gupta, 2022)는 시각적 멀티모달 추론에 비해 추가적인 시간 정보를 도입하기 때문에 더 어렵다.\n' +
      '\n' +
      '### Metrics\n' +
      '\n' +
      '정확도는 분류 작업에 대한 모델의 능력을 평가하는 데 사용되며 일반적으로 다중 선택 Ling 등(2017); Mihaylov 등(2018); Liu 등(2020); Lu 등(2022) 및 yes/no Talmor 등(2021); Geva 등(2021); Han 등(2022) 작업에 사용됩니다.\n' +
      '\n' +
      '\\[\\mathrm{Accuracy}=\\frac{\\mathrm{N}_{\\mathrm{correct}}}{\\mathrm{N}_{\\mathrm{ total}}} \\tag{7}\\]\n' +
      '\n' +
      'EM 및 F1EM 및 F1은 자유 형태 Mishra 등(2022); Wang 등(2019); Yi 등(2020) 및 span extraction Dua 등(2019); Zhu 등(2021); Mishra 등(2022) 태스크를 평가하기 위해 사용되는 메트릭이다. 둘 다 토큰 수준에서 계산됩니다.\n' +
      '\n' +
      '\\[\\mathrm{F1}=\\frac{2\\cdot\\mathrm{P}\\cdot\\mathrm{R}}{\\mathrm{P}+ \\mathrm{R}} \\tag{8}\\] \\[\\mathrm{EM}=\\frac{\\sum\\mathbb{I}[A=A^{\\prime}]}{\\mathrm{N}_{ \\mathrm{total}}} \\tag{9}\\]\n' +
      '\n' +
      '여기서 P와 R은 정밀도와 재현도를 나타내며, EM은 정확히 같은 예측과 답의 비율을 계산한다.\n' +
      '\n' +
      '## 4 Methods\n' +
      '\n' +
      '이 절에서는 X-of-thought의 구성(SS4.1), X-of-thought의 구조적 변형(SS4.2), X-of-thought의 향상된 방법(SS4.3)의 세 가지 다른 범주화를 통해 X-of-thought 추론을 탐구한다.\n' +
      '\n' +
      '### Construction Approach\n' +
      '\n' +
      '철저한 분석 후, 우리는 X-of-thought의 구성을 다음과 같이 설명하는 1) Manual XoT, 2) Automatic XoT, 3) Semi-automatic XoT의 세 가지 범주로 나눈다.\n' +
      '\n' +
      '#### 4.1.1 Manual XoT\n' +
      '\n' +
      '대형 언어 모델은 프롬프트를 통해 적은 샷의 인컨텍스트 학습을 수행하지만, 여전히 추론 작업에 한계가 있다. 대형 언어 모델의 잠재적인 추론 능력을 탐구하기 위해 한 가지 표준 접근 방식은 시연에서 다양한 형태의 생각을 제공하는 것이다.\n' +
      '\n' +
      'Wei et al.(2022)은 먼저 시연에 대한 자연어 형태의 근거를 수동으로 제공함으로써 연쇄적 사고 프롬프트(Few-shot CoT)를 제안한다. 추론 과정에서 확실성을 더 보장하고 추론 경로와 답변 간의 불일치를 줄이기 위해 PAL Gao 등(2023), PoT Chen 등(2022) 및 NLEP Zhang 등(2023)은 프로그래밍 언어를 주석이 달린 근거로서 활용하며, 이는 문제 해결을 실행 가능한 파이썬 프로그램으로 변환한다. 한편, 자연어와 프로그래밍 언어의 장점을 모두 취하고 추론 출력의 신뢰도를 높이기 위해 MathPromter Imani et al.(2023)은 제로샷 사고 연쇄 프롬프트(zero-shot chain-of-thought prompting)를 사용하여 다수의 대수식 또는 파이썬 함수를 생성함으로써 서로 검증하고 결과의 신뢰성을 향상시킬 수 있다. 또한, 더 많은 추론 단계를 가진 체인과 같은 시연에서 샘플의 추론 복잡도는 성능 향상을 가져오기 때문에 Fu et al.(2023)은 복잡도 기반 프롬프트를 제안하며, 여기서 고복잡도 논리 중 투표를 수행하여 최종 답을 얻는다.\n' +
      '\n' +
      '수동으로 구성된 X-of-thought 방법은 다양한 유형의 단계별 중간 추론 과정을 데모에 추가하여 인-컨텍스트 학습을 확장한다. 그들은 LLM들이 추론 경로들을 모방하고 생성할 수 있게 한다. 수동 XoT 방법은 복잡한 작업, 즉 수학적 추론, 상식 추론, 상징 추론 등에 대한 인간의 이해와 성능에 대한 신뢰성뿐만 아니라 더 큰 해석 가능성을 제공하지만, 근거의 수동 주석은 상당한 비용을 수반하고 시연 선택 및 작업 일반화의 어려움과 같은 단점을 겪는다. 구체적으로, 다른 작업들은 다른 방식의 데모를 필요로 한다. 따라서, 다른 작업들은 SS4.1.2에서 논의된 바와 같이 추론 경로를 자동으로 구성하려고 시도한다.\n' +
      '\n' +
      '#### 4.1.2 Automatic XoT\n' +
      '\n' +
      'Chain-of-thought 프롬프트 Wei et al.(2022)는 몇 번의 샷 설정에서 태스크별 예시를 가진 LLMs의 복잡한 추론 능력을 도출하여 확장성과 일반화를 제한한다. Kojima et al.(2022)은 손으로 만든 몇 개의 샷 예제 비용을 줄이기 위해 질문 후 매직 문구 _차근차근 생각해보자_ 를 도입하여 제로 샷 CoT를 제안하며, 이를 통해 LLM이 제로 샷 방식으로 추론 체인을 생성할 수 있다. 그러나 제로샷 CoT는 많은 실수를 수반하며 품질이 좋지 않은 추론 경로를 겪는다. 시연의 다양성은 추론 체인 생성에 중요한 역할을 하기 때문에 Auto-CoT Zhang et al. (2023)2023f는 클러스터링과 대표적인 예제 선택을 통해 자동으로 시연을 생성하며, 이는 다양성을 향상시키고 Few-shot CoT의 성능과 일관되게 일치하거나 초과한다. COSP(Wan et al., 2023)는 증명 선택을 돕기 위해 질문의 결과 엔트로피를 소개한다. Xu et al. (2023)은 깁스 샘플링을 반복적으로 사용하여 효과적인 CoT 프롬프트를 찾기 위한 Repropting을 제안한다. 한편, Wang et al.(2023f)은 Zero-shot CoT를 Plan-and-Solve(PS)로 확장하여 전체 태스크를 더 작은 세부 태스크로 분할하고 세부 태스크를 계획에 따라 수행하는 계획을 고안하여 보다 자세한 지침을 제공한다. LogCoT(Zhao et al., 2023c)는 제로-샷 추론 프로세스를 검증하기 위해 심볼릭 로직을 사용하며, 따라서 추론의 오류를 감소시킨다. 또한 PoT (Chen 등, 2022a)는 Codex와 같은 언어 모델을 탐색 하 여 실행 가능한 Python 프로그램을 생성 하 여 0 샷 설정에서 수학 문제를 해결 하기 위해 _Python 프로그램을 단계별로 작성 합니다* * 를 추가 하 여 실행 가능한 Python 프로그램을 생성 합니다._ 중급 추론 단계에서 오류를 완화합니다. 일부 작업에서는 추론 문제를 해결하기 위해 에이전트를 도입합니다. 예를 들어, 에이전트 명령어(Crispino et al., 2023a)는 에이전트를 활용하여 태스크 관련 정보적 명령어를 생성하며, 이는 LLM이 제로 샷 추론을 수행하도록 안내한다.\n' +
      '\n' +
      '수동 XoT와 달리 제로 샷 프롬프트 엔지니어링 또는 샘플링을 사용하는 자동 XoT는 확장 가능하며 인간의 개입 없이 도메인 간에 일반화될 수 있다. 그러나 인간의 정렬 부족으로 인해 자동으로 생성된 연쇄적 사고는 열악한 품질, 환각 및 사실 불일치와 같은 문제에 직면한다. 따라서, 반자동 방식으로 XoT를 구축하는 것이 필요하며, 이는 SS4.1.3에 도입된다.\n' +
      '\n' +
      '#### 4.1.3 반자동 XoT\n' +
      '\n' +
      '반자동 XoT 방법은 수동 및 자동 구축 방법 모두의 장점을 통합한다. Shao et al.(2023)은 합성 프롬프팅을 제안하는데, 합성 프롬프팅은 몇 개의 인간 주석이 달린 예를 활용하여 모델을 프롬프트하여 교체된 전후진 프로세스를 통해 더 많은 예를 생성하고 더 나은 추론을 이끌어내기 위해 효과적인 데모를 선택하여 부족을 완화한다.\n' +
      '\n' +
      '그림 1: XoT 방법, 프론티어 애플리케이션, 미래 방향 및 벤치마크.\n' +
      '\n' +
      'AutoCoT에서 인간 정렬의 경우. 이전 작업은 수동 주석의 문제를 해결했지만 데모 선택도 성능에 상당한 영향을 미칠 수 있다. Automate-CoT(Shum et al., 2023)는 블랙 박스 언어 모델에서 각 예의 유의성을 추정하기 위해 분산 감소 정책 기울기 전략을 갖는 강화 학습을 채용하여, 더 나은 데모 선택을 유도한다. 마찬가지로 Lu et al.(2023)은 정책 기울기를 활용하여 표식 추론에서 데모를 선택하는 방법을 학습하는 PromptPG를 제안한다. Ye and Durrett(2023)은 처음에 두 개의 프록시 메트릭을 사용하여 각 예를 평가한 다음 예를 검색하여 은 라벨 개발 세트에서 최상의 성능을 제공하는 데모를 찾습니다. 한편, Pitis et al.(2023)은 성능 향상을 위한 프롬프트 앙상블 방식인 Boosted Promptg를 제안하는데, 이는 현재 시연이 다루기 어려운 문제에 직면했을 때 예를 반복적으로 확장한다. Zou et al.(2023)은 질문 카테고리에 따라 데모를 자동으로 선택하는 Meta-CoT를 도입하여 태스크별 프롬프트 설계가 필요 없게 하였다.\n' +
      '\n' +
      '반자동 XoT 방법은 추론 능력과 안정성을 향상시키기 위해 인간 정렬 신호와 시연 선택 전략을 도입하면서 수동 라벨링의 작업 부하를 줄인다. 또한 비용 효율적인 도메인 일반화를 가능하게 합니다. 그러나 실증 선정 문제는 완전히 해결되지 않았고 더 많은 노력과 연구가 필요하다.\n' +
      '\n' +
      '### XoT 구조 변형\n' +
      '\n' +
      '가장 원시적인 연쇄적 사고는 자연어로 중간추론 단계를 기술하는 연쇄 구조이다. 이 섹션에서는 체인 구조 변형, 트리 구조 변형 및 그래프 구조 변형을 포함하여 원래 체인 구조를 수정하는 구조 변형을 소개한다.\n' +
      '\n' +
      'Chain StructurePAL(Gao et al., 2023) 및 PoT(Chen et al., 2022)는 프로그래밍 언어를 도입하여 추론 과정을 기술함으로써, 추론 문제를 실행 가능한 프로그램의 구현으로 변환하여 최종 답변을 얻는다. 프로그램 실행은 결정적이고, 산술 연산을 정확하게 수행하기 때문에, 이 접근법은 수학적 추론에서 우수한 성능을 보인다. 게다가, 기호 시퀀스는 또 다른 유형의 사고 표현이다. Chain-of-Symbol (Hu et al., 2023)은 계획 중에 응축된 심볼 체인 표현들을 갖는 복잡한 환경들을 나타내며, 이는 시뮬레이션 환경의 복잡성을 감소시킨다. 체인 구조 변형은 그림 2(c,d) 사유의 알고리즘(Sel et al., 2023)이 알고리즘에 알고리즘 능력을 주입하고, 알고리즘을 기반으로 예를 추가함으로써 모델의 추론을 더 논리적으로 만든다. 트리 탐색의 거대한 탐색 공간의 부재(Long, 2023; Yao et al., 2023)는 계산 자원을 절약하고 우수한 성능을 달성한다.\n' +
      '\n' +
      '나무 구조 원래 사슬 구조는 본질적으로 탐사의 범위를 제한한다. 트리 구조와 트리 탐색 알고리즘의 통합을 통해 모델은 그림 2(e)와 같이 추론 과정(Long, 2023; Yao et al., 2023) 동안 효율적으로 탐색하고 역추적할 수 있는 능력을 얻는다. 중간 생각에 대한 자체 평가와 결합하여 모델은 글로벌 최적 솔루션을 달성할 수 있습니다. ToT의 추론 과정은 불확실성을 수반하며, 이는 잠재적으로 계단식 오류로 이어질 수 있다. TouT(Mo and Xin, 2023)는 불확실성을 고려하여 몬테카를로 드롭아웃을 추론에 도입한다. Yu et al. (2023)은 LLMs의 복잡한 추론 능력을 높이기 위해 그들의 솔루션을 활용하여 유사한 문제를 탐구한다. 이러한 유사한 문제들은 나무와 같은 구조를 보이며, 궁극적으로 주요 문제를 해결하기 위해 수렴한다. 그러나 현재의 사고 트리는 작업 선택에 상당한 한계가 있으며 각 작업에 대한 구체적인 신속한 설계가 요구되어 광범위한 적용을 방해한다. SoT(Ning et al., 2023)는 트리 구조의 또 다른 변형으로서, 문제를 병렬로 처리하고 동시에 해결할 수 있는 하위 문제로 분해하여 추론의 속도를 높인다. 그러나 그 효용성은 병렬 분해 가능한 문제로 제한되며 복잡한 추론 작업에는 적합하지 않다.\n' +
      '\n' +
      '그래프 구조는 나무에 비해 고리와 고리를 도입하여 그림 2(f)와 같이 더 복잡한 위상 관계를 가져오고 더 복잡한 추론을 모델링할 수 있다. GoT(Besta et al., 2023; Lei et al., 2023)는 중간 사고를 그래프 내의 노드로 간주하고, 탐색 및 역추적 연산을 결합하고, 추가로 사고 트리와 비교하여 집계 및 정제 연산을 도입한다. 추가 연산, 집계 및 개선은 복잡한 작업에서 더 나은 추론을 이끌어낸다. 그럼에도 불구하고, 그것은 사고의 나무와 동일한 딜레마, 즉 과제 제한과 열악한 일반화 가능성에 직면해 있다. 게다가 추론 비용이 증가했습니다. 사고 그래프를 명시적으로 구성하는 GoT와 달리 ResPrompt Jiang et al.(2023)은 사고 간의 잔차 연결을 프롬프트 텍스트에 도입하여 서로 다른 단계의 추론이 상호 작용할 수 있도록 한다.\n' +
      '\n' +
      '모델이 선형 사슬에서 계층적 트리 및 복잡한 그래프로 전환됨에 따라 생각의 상호 작용은 점진적으로 더 복잡해지며, 이에 따라 복잡한 문제를 해결할 수 있는 능력이 점차 향상된다. 그러나 토폴로지의 복잡도가 증가함에 따라 관련 방법은 태스크 선택에 더 많은 제약을 가하여 일반화 가능성을 크게 감소시키고 응용을 어렵게 만든다. 복잡한 토폴로지 구조 기반 방법을 일반 영역으로 확장하는 것은 향후 연구의 주요 과제이다.\n' +
      '\n' +
      '### XoT Enhancement Methods\n' +
      '\n' +
      '본 절에서는 XoT 향상 방법을 제시한다. 전체적으로 검증 및 정제(SS4.3.1), 질문 분해(SS4.3.2), 외부 지식 활용(SS4.3.3), 투표 및 순위화(SS4.3.4), 효율성 향상(SS4.3.5)의 5가지 범주에 대한 개요를 제공할 것이다.\n' +
      '\n' +
      '#### 4.3.1 Verify and Refine\n' +
      '\n' +
      '연쇄 사고 추론은 종종 환각이 되어 잘못된 추론 단계를 생성하는 경향이 있다. 중간 추론 단계의 오류는 차례로 일련의 오류를 유발할 수 있다. 피드백을 얻기 위해 검증을 통합하고 후속적으로 이 피드백을 기반으로 추론 과정을 정제하는 것은 인간의 성찰 과정과 유사한 이 현상을 완화하는 매우 효과적인 전략이 될 수 있다. 그림 3은 검증 및 개선의 개요를 보여준다.\n' +
      '\n' +
      'VerifyCoT Ling et al. (2023)은 모델이 정확한 추론 단계를 생성할 수 있도록 하는 연역적 추론 형식인 Natural Program을 고안하고, 각 후속 단계는 이전 단계를 엄격하게 기반으로 한다. DiVeRSe Li 등(2022)은 투표 메커니즘을 활용하여 오답을 제거한 후, 각 추론 단계를 독립적으로 세밀하게 검증한다. SCREWSShridhar et al. (2023)은 수정 후 결과가 반드시 원점보다 우수하지 않을 수 있다고 생각하므로 원점과 수정 중 더 나은 결과를 선택하기 위해 선택 모듈을 도입한다. 지식 집약적인 작업을 용이하게 하기 위해 Verify-and-Edit Zhao et al.(2023)은 불확실한 예제를 재추론하기 위해 외부 지식을 통합하여 추론의 사실적 실수를 줄입니다. 일부 연구 노력은 모델의 내부 지식을 밝히려고 시도한다. 일부 연구 노력은 모델의 내부 지식을 밝히려고 시도한다. 사실적 오류를 해결하기 위해 일부\n' +
      '\n' +
      '그림 3: 검증 및 개선은 추론에서 계단식 오류를 줄인다.\n' +
      '\n' +
      '그림 2: 직접적인 I/O에서 사슬 구조로, 그 다음 트리 및 그래프 구조로 추론의 진화.\n' +
      '\n' +
      '본 연구는 LLMs의 내재적 지식을 밝히고자 한다. 그들은 질문에 답하기 전에 모델로부터 지식을 획득한다(Dhuliawala et al., 2023; Zheng et al., 2023). Ji et al.(2023)은 내재적 지식의 정확성을 더욱 검증하고, Liu et al.(2023)은 강화학습을 통해 내재적 지식 습득의 정확성을 높인다.\n' +
      '\n' +
      '비일관성은 추론의 또 다른 주요 과제이며, Dua 등(2022)은 모델이 일관된 답변을 제공할 때까지 이전 추론 결과를 프롬프트로 반복적으로 사용한다. Paul et al.(2023)은 추론 과정에 대한 구조화된 피드백을 제공하기 위해 비평가 모델을 훈련시킨다. Self-Refine(Madaan et al., 2023)은 반복적인 Self-feedback과 refinement을 수행하여 추론의 오류를 완화한다. Self-Refine과 비교할 때, Reflexion(Shinn et al., 2023)은 성찰을 위한 강화 학습을 도입하며, 이는 추가적으로 의사 결정 능력을 가져온다. 한편, 일부 연구에서는 검증을 위해 역방향 추론(Yu et al., 2023)을 소개하고 있다. RCoT(Xue et al., 2023)는 추론 체인들에 따라 질문을 재구성하고, 원래의 질문과의 불일치는 추론 과정에서 오류를 노출한다. FOBAR(Jiang et al., 2023) 및 Self Verification(Weng et al., 2022)은 답변으로부터 질문 내의 조건을 추론하여 검증을 수행한다. FOBAR은 질문의 변수를 추론하고, Self Verification은 질문의 조건을 추론한다. 그러나 Huang et al.(2023)은 LLMs가 외부 피드백 없이 스스로 수정하기 위해 고군분투하고, 성능 저하로 이어질 수 있음을 발견한다.\n' +
      '\n' +
      'LLM 추론은 중간 추론 단계의 피드백 신호가 추론을 개선하는 데 중요한 역할을 하는 감독되지 않은 과정이다. 피드백 신호로부터의 안내는 추론에서 환각 현상을 효과적으로 감소시킬 수 있다. 적절한 피드백을 얻고 그 피드백을 기반으로 정확한 보정을 할 수 있는 상당한 연구 공간이 여전히 있다.\n' +
      '\n' +
      '#### 4.3.2 질문 분해\n' +
      '\n' +
      'X-of-thought 추론의 본질은 단계적 문제 해결에 있다. 그러나, 독창적인 연쇄적 사고 추론 접근법은 단계적 추론 과정을 명시적으로 제거하지 않고 여전히 1단계 생성을 사용한다. 본 절에서는 질문을 단계별로 명시적으로 해결하는 질문 분해 접근법에 대해 논의한다. 개요는 그림 4에 나와 있다.\n' +
      '\n' +
      'Wang et al.(2022)은 반복적으로 모델로부터 지식을 획득하여 멀티홉 QA에서 진전을 이루고 있다. Zhou et al.(2023)은 Least-to-Most Prompting(Least-to-Most Prompting)을 제안하는데, 이는 처음에 질문을 하향식으로 하위 질문으로 분해한 후, 한 번에 하나씩 하위 질문을 해결하고 그 솔루션을 활용하여 후속 하위 질문을 용이하게 한다. Successive Prompting(Dua et al., 2022)은 Least-to-Most Prompting과 유사한 접근법을 취하며, 차이점은 2단계 분해가 아닌 인터리빙된 하위 질문과 답변을 갖는 분해를 취한다는 것이다. 위의 방법은 다양한 하위 문제에 대한 맞춤형 솔루션을 공식화하지 않는다. Decomposed Prompting (Khot et al., 2023)은 모듈형 공유 라이브러리를 설계하는데, 각각은 서브-문제들의 클래스에 전용되며, 이는 서브-문제들의 상이한 클래스들에 더 효과적인 솔루션들을 맞춤화할 수 있다. 일반적인 작업과 별도로, 일부 작업은 표식 추론에 대한 질문 분해에 초점을 맞춘다. BINDER(Cheng et al., 2023)는 추론( reasoning)을 신경기호(neural-symbolic) 방식으로 프로그램에 매핑하고 파이썬(Python)이나 SQL과 같은 프로그램 실행기를 통해 최종 답변을 얻는다. Ye et al.(2023)은 큰 테이블을 작은 테이블로, 복잡한 질문을 단순한 테이블로 분해하는 DATER를 소개한다. 전자는 무관한 정보를 감소시키는 반면, 후자는 추론의 복잡성을 감소시킨다.\n' +
      '\n' +
      '복잡한 질문에 대한 직접적인 답변을 제공하는 것은 어려울 수 있다. 질문을 간단한 하위 문항으로 분해하여 단계적으로 해결함으로써 난이도를 줄인다. 더욱이, 각각의 하위 질문은 특정 추론 단계로 역추적될 수 있어 추론 프로세스를 보다 투명하고 설명할 수 있게 한다. 현재 작업은 대부분 하향식 분해 전략을 사용하는 반면, 역방향 추론에 기반한 상향식 분해 전략은 향후 작업에서 탐구해야 한다.\n' +
      '\n' +
      '그림 4: 질문 분해는 간단한 하위 질문을 풀어서 복잡한 질문을 점진적으로 해결한다.\n' +
      '\n' +
      '#### 4.3.3 External Knowledge\n' +
      '\n' +
      '모델 내에서 매개 변수화된 지식은 제한적이고 구식입니다. 따라서 지식 집약적인 작업에 직면할 때 사실상의 실수가 종종 발생한다. 외부 지식을 도입하면 그림 5와 같이 이러한 현상을 완화할 수 있다.\n' +
      '\n' +
      'Lu et al. (2023)은 기계 번역을 향상시키기 위해 프롬프트에 다국어 사전을 도입한다. Li et al. (2023)은 지식-유도 추론을 수행하기 위해 질의 생성기를 통해 지식 베이스로부터 구조화된 지식을 획득하는 CoK-Li(Chain-of-knowledge)를 제안한다. Wang et al.(2023)(CoK-Wang)은 또한 KB로부터 구조화된 지식을 검색한다. 또한, 사실성과 충실성 측면에서 추론 사슬을 추정하고 모델이 신뢰할 수 없는 추론에 대해 다시 생각하게 하여 CoK-Li의 지식 검색 오류를 완화한다. KD-CoT Wang et al.(2023)은 멀티턴 QA 접근법을 통해 사실적 추론 문제를 다룬다. 그들은 추론 과정을 보정하기 위해 QA의 각 라운드에서 관련 외부 지식을 검색하기 위한 피드백 강화 리트리버를 설계한다. 다른 연구들은 모델 자신의 기억을 외적 지식으로 사용하고 있다. 예를 들어, Memory-of-Think Li and Qiu (2023)는 먼저 높은 자신감의 생각을 외부 기억으로 저장하기 위해 사전 사고를 수행하고 추론하는 동안 LLM이 추론을 돕기 위해 관련 기억을 회상하도록 한다.\n' +
      '\n' +
      '모델에서 매개변수화된 지식은 사전 훈련이 끝날 때 고정되어 있어 지식 용량 및 지식 업데이트 측면에서 단점이 있다. 외부의 지식을 도입하는 것은 이를 어느 정도 완화시킬 수 있지만 여전히 불완전한 해결책으로 남아 있다. 이 문제를 근본적으로 해결하기 위해, Lange et al. (2022); Wang et al. (2023)은 미래의 연구 노력을 위한 유망한 길로 서 있다.\n' +
      '\n' +
      '#### 4.3.4 투표 및 랭크\n' +
      '\n' +
      '생성 과정에서 내재된 확률성으로 인해 LLM 추론은 무작위성과 불확실성의 요소를 나타낸다. 이 문제는 그림 6과 같이 다중 샘플링 전략을 통해 효과적으로 완화될 수 있다.\n' +
      '\n' +
      '일부 방법은 Cobbe 등(2021)과 같은 순위를 채택하는데, 이는 순위를 통해 높은 신뢰 추론 체인을 선택하도록 검증자를 훈련시킨다. 한편, 다른 방법들은 투표 메커니즘을 통해 추론 체인들을 선택한다. Self-consistency Wang et al.(2023)은 최종 답변을 기반으로 샘플링된 추론 체인 중 다수결 투표에 의해 가장 일관된 답변을 선택한다. 또한 Fu et al.(2023)은 복잡도 기반 투표 전략을 사용하여 복잡한 추론 체인에 의해 생성된 답변을 선택하는 복잡도 기반 투표 전략을 제안한다. 그러나 답변 기반 투표 메커니즘은 추론 사슬의 정확성을 고려하지 않는다. Miao et al. (2023)은 투표 시 추론 단계를 고려하며, 이는 일관된 답변과 신뢰할 수 있는 추론 과정을 동시에 얻을 수 있다. 또한, 사슬 간의 중간 단계 사이의 관계를 고려하기 위해 Yoran et al. (2023)은 추론 사슬 간의 정보를 혼합하고 다중 추론 사슬에 대한 메타 추론을 수행하기 위해 가장 적절한 사실을 선택한다. GRACE Khalifa et al.(2023)은 대조적 학습을 통해 판별기를 훈련시키고, 이 판별기를 이용하여 각 중간 추론 단계의 순위를 매긴다. 기존의 방법들은 확률 분포를 기반으로 표본을 추출하는 반면, Diversity-of-Thought Naik et al.(2023)은 서로 다른 명령어로 프롬프트함으로써 다중 추론 경로를 얻는다.\n' +
      '\n' +
      '앙상블 학습에서 영감을 끌어내어 다중 샘플링으로 투표하고 순위를 매기는 관행은 불확실성을 줄이는 역할을 한다. 게다가, 그것은 상당한 성과를 보여주었다.\n' +
      '\n' +
      '그림 5: 외부 지식을 도입하면 추론의 사실적 오류가 줄어든다.\n' +
      '\n' +
      '그림 6: 투표와 순위는 여러 표본에서 최종 답변을 선택하여 불일치를 줄인다.\n' +
      '\n' +
      '단일 표본 접근법에 비해 개선되었습니다. 투표와 함께 다중 샘플링은 현재 X-of-thought 연구에서 일반적인 기술이 되었다. 추론 사슬을 투표에 통합하는 것은 미래를 위한 중요한 연구 영역으로 남아 있다.\n' +
      '\n' +
      '#### 4.3.5 Efficiency\n' +
      '\n' +
      'LLM 추론 및 수동으로 주석이 달린 추론 체인은 비싼 오버헤드를 부과한다. Aggarwal et al.(2023)은 샘플 수를 동적으로 조정함으로써 자기 일관성을 향상시키며, 이는 한계 성능 저하와 함께 추론 비용을 크게 감소시킬 수 있다. Ning et al.(2023)은 질문을 병렬적으로 분해하고 동시에 처리함으로써 추론 시간 오버헤드를 줄였다. 그러나 그것은 복잡한 질문들을 다룰 수 없다. Zhang et al.(2023)은 일부 중간층을 선택적으로 건너뛰어 추론을 가속화한 후 다른 전진 패스에서 드래프트를 검증한다. Diao et al.(2023)은 불확실성이 높은 예제에 주석을 달기 위해 능동적 학습에서 아이디어를 차용하여 인간의 주석 비용을 줄인다.\n' +
      '\n' +
      '대규모 언어 모델은 엄청난 능력을 보여주었지만 상당한 오버헤드를 수반하기도 한다. 성과와 오버헤드 사이의 균형을 맞추려면 향후 연구 노력에 상당한 주의가 필요할 수 있다.\n' +
      '\n' +
      '## 5 프런트 엔드 애플리케이션\n' +
      '\n' +
      '### Tool Use\n' +
      '\n' +
      'LLM이 보여주는 광범위한 지식에도 불구하고 몇 가지 문제가 수반된다. 여기에는 최신 뉴스에 액세스할 수 없는 능력, 영역 외 지식과 관련된 쿼리에 응답할 때 환각에 대한 성향, 수학적 계산이나 상징적 추론과 같은 정교한 추론 능력의 부재가 포함된다. LLMs에게 외부 도구를 사용할 수 있는 능력을 부여함으로써 모델의 추론 능력을 증강하고 외부 지식을 동화하여 정보 검색 및 환경 상호 작용에 참여할 수 있게 된다.\n' +
      '\n' +
      'MRKL Karpas 등(2022)은 확장 가능한 모듈(전문가라고 함)과 라우터로 구성된 새로운 프레임워크를 소개한다. 이러한 전문가들은 신경망이나 기호의 형태를 취할 수 있다. 그러나 본 연구는 다른 모듈 콘텐츠를 구현하지 않고 수학적 계산을 위한 LLM을 개념화하고 훈련하는 데 중점을 둔다. TALM Parisi et al.(2022)와 Toolformer Schick et al.(2023)은 텍스트 중심 방법론과 보조 도구를 통합하여 언어 모델의 능력을 향상시킨다. 그들은 제한된 툴팁 세트로 시작하여 성능 향상을 시작하기 위해 자체 감독 메커니즘을 사용한다. 유사한 맥락에서 HuggingGPT Shen et al. (2023)은 시각 및 음성 모델을 활용하여 다양한 양식에서 정보를 처리함으로써 LLM이 다중 양식 이해와 생성을 가능하게 한다. 또 다른 질문은 적절한 도구를 선택하는 방법이다. LATM Cai et al. (2023)은 LLMs의 도구 제작 능력이 다양한 작업에 걸쳐 일반화된 API를 만들 수 있도록 하고 GEAR Lu et al. (2023)은 도구 접지 및 실행을 위임하기 위해 더 작은 모델을 사용하여 도구 사용의 효율성을 고려한다.\n' +
      '\n' +
      '그러나 사용자 요청을 API 형식으로 변환하는 것은 간단하지 않은 경우가 많습니다. 위에서 언급한 기존 접근법은 도구의 여러 호출을 촉진하고 쿼리 오류를 수정하는 데 한계가 있다. 이 문제를 해결하기 위해 ReAct Yao et al.(2023)은 추론과 행동의 장점을 통합하여 서로를 강화하고 보완하여 문제 해결 능력을 상호 보완한다. ART Paranjape et al. (2023)은 태스크 라이브러리를 사용하여 관련 도구 사용 및 추론 체인을 선택한다. MM-REACT Yang et al.(2023)은 비전 전문가를 더 활용하여 멀티모달 추론과 행동을 가능하게 한다.\n' +
      '\n' +
      '앞서 언급한 연구는 다양한 영역에서 LLM의 기능을 향상시키기 위한 도구(또는 API)를 설계하는 데 중점을 둔다. XoT와 도구를 결합하면 LLM이 직면한 문제를 효과적으로 해결할 수 있습니다. X-of-thought 추론은 모델들이 예외들을 관리하면서 액션 플랜들을 효과적으로 이끌어내고, 추적하고, 업데이트할 수 있게 한다. 동시에 액션 연산은 모델의 지식 베이스 및 환경과 같은 외부 소스와의 상호 작용을 촉진하여 추가 정보를 수집할 수 있게 한다. 도구의 숙련도를 평가하기 위해 APIBank Li 등(2023)과 MetaTool Huang 등(2023)은 포괄적인 벤치마크를 도입하여 도구 증강 LLM의 성능과 효율성을 평가할 수 있는 강력한 기반을 제공한다.\n' +
      '\n' +
      '### Planning\n' +
      '\n' +
      'LLM은 복잡한 문제에 대해 직접 정확한 응답을 제공하는 데 어려움이 있어 순차적인 단계와 하위 작업으로 분해할 필요가 있다. CoT는 계획에 대한 간단한 접근법을 제공하지만 매우 복잡한 문제를 해결하는 데 부족하고 역추적을 통해 오류를 평가하고 수정하는 능력이 부족하다.\n' +
      '\n' +
      '수많은 연구가 계획 능력을 더욱 향상시키기 위해 사고 사슬의 틀을 다양한 형식으로 확장했다. 트리-오브-사고(Yao et al., 2023)는 LLM들이 트리에서 다수의 추론 경로들을 고려하고 다음 행동 코스를 결정하기 위해 자기-평가할 수 있게 한다. 글로벌 결정이 필요한 경우 ToT는 심층 우선 탐색 또는 너비 우선 탐색과 같은 기술을 통해 전진 또는 후진 탐색을 허용한다. 계획(RAP)을 통한 추론(Hao et al., 2023)은 또한 문제를 트리로 나누고 몬토 카를로 트리 탐색 알고리즘에 의해 탐색하며, LLMs을 월드 모델 및 추론 에이전트로 사용한다. 또 다른 방법인, GoT(Graph of Thought)(Yao et al., 2023)는 개인 생각을 표현하기 위해 그래프 노드를 채용하고 조직화를 위해 외부 그래프 신경망을 채용한다. LLM+P(Liu et al., 2023) 및 LLM+DP(Dagan et al., 2023)는 LLM에 의한 계획 도메인 정의 언어(PDDL)(Gerevini, 2020)의 생성을 용이하게 한다. PDDL은 LLM 처리를 위해 결과를 자연어로 변환하기 전에 복잡한 문제를 분해하고 계획을 위한 특수 모델을 활용하는 데 도움이 된다. 그러나 이러한 방법은 트리/그래프/PDDL 노드를 사용하여 생각을 표현하는데, 이는 표현 형태에 제한이 있고 특정 계획 문제만 처리할 수 있다는 점에 유의해야 한다.\n' +
      '\n' +
      '또 다른 기법은 모델의 오류를 수정하고 역사적 경험을 요약하는 능력을 향상시키는 것이다. Self-Refine(Madaan et al., 2023)은 모델에 의해 생성된 출력이 평가되고 동일한 모델을 사용하여 피드백이 제공되는 독특한 접근법을 채용한다. 반사(Shinn et al., 2023)는 모델이 이전의 액션들에서 이루어진 에러들을 반성하고 교정할 수 있게 하고, 텍스트 형식의 강화 학습과 유사하며, 메모리를 장단기 컴포넌트들로 분할하는 것을 포함한다. 그러나 계획 외 오류가 발생할 경우 반사는 계획을 업데이트할 수 없습니다. AdaPlanner(Sun et al., 2023)는 적응적 폐루프 계획 정제(adaptive closed-loop plan refinement)를 도입하는데, 이는 환경의 피드백에 기초하여 태스크 계획을 반복적으로 정제한다. ISR-LLM(Zhou et al., 2023)은 Long-horizon 순차 작업에서 더 나은 성공률을 달성하기 위해 Self-Refine과 PDDL을 결합한다. 한편, LATS(Zhou et al., 2023)는 보다 유연한 계획 절차를 위해 LM-기반 몬테카를로 트리 탐색을 이용한다.\n' +
      '\n' +
      '계획은 추론 능력을 풍부하게 하기 위해 도구(Ruan 등, 2023) 또는 에이전트(Crispino 등, 2023)와 유연하게 결합될 수 있다. ToRA(Gou et al., 2023)는 외부 도구를 사용하여 수학적 전문 에이전트를 설계하며, AutoUI(Zhang and Zhang, 2023)는 시각적 입력을 텍스트로 변환하는 대신 멀티모달 환경과 직접 상호작용하여 추론 효율을 높이고 오류 전파를 감소시킨다.\n' +
      '\n' +
      '계획 증강 접근법은 검색 기반, 그래프 기반 및 정의 언어 기반 방법을 도입하여 기존의 순차 계획을 발전시켰다. 반면에 일부 방법은 액션, 계획, 반영 또는 도구를 통합하여 LLM의 장기 계획 및 오류 복원력 기능을 향상시키는 것을 목표로 한다.\n' +
      '\n' +
      '### CoT Distillation\n' +
      '\n' +
      'LLM은 복잡한 문제를 해결하기 위해 추론 단계를 증류함으로써 자체 개선될 수 있다. Huang et al.(2022)은 레이블이 지정되지 않은 데이터로부터 추론 체인을 생성하기 위해 자기 일관성을 갖는 LLM을 사용한다. 이러한 체인은 이후에 모델을 미세 조정하는 데 활용되어 일반화된 추론 능력을 향상시킨다. Zelikman et al.(2022)은 자기 루프 부트스트랩 전략을 사용하여 LM의 추론 능력을 향상시키기 위한 소수 샷 학습 접근법인 STaR을 제안한다. SECToR (Zhang and Parkes, 2023)은 산술적 해답을 얻기 위해 연쇄 사상(chain-of-thought)을 사용하고, 그 다음 모델을 미세 조정함으로써 CoT 없이 직접 해답을 생성한다.\n' +
      '\n' +
      'CoT는 소형 모델에서 제한된 발전과 함께 LLM에서 주로 관찰되는 새로운 능력이다. 그러나 증류와 같은 기술을 통해 소형 모델의 CoT 능력을 향상시키는 것을 생각할 수 있다. Magister et al.(2023)은 더 큰 교사 모델에 의해 생성된 추론 체인으로 T5를 미세 조정하고 답변 해결을 위해 외부 계산기를 사용하는 것이 다양한 데이터 세트에 걸쳐 작업 성능을 실질적으로 향상시킬 수 있음을 보여준다. Ho et al.(2023)은 다양성을 풍부하게 하기 위해 다수의 추론 경로를 생성하고 필터링한다.\n' +
      '\n' +
      '자기-일관성을 이용함으로써 주석이 없는(또는 매우 적은 주석이 달린) 데이터를 사용하여 인적 비용을 감소시키기 위해 수많은 노력이 수행될 수 있다(Wang et al., 2023). Hsieh et al. (2023)은 훨씬 적은 수의 라벨링된/라벨링되지 않은 데이터로부터 답변을 생성하기 위해 프롬프트를 사용하고, 이어서 주어진 답변에 대한 추론을 제공하기 위해 언어 모델을 프롬프트하는 근거의 생성을 사용한다. SCoTD (Li et al., 2023)는 교사들로부터 인스턴스당 다수의 추론 체인들을 샘플링하는 것이 학생들의 능력을 향상시키는데 가장 중요하다는 것을 발견한다. SCOTT Wang et al. (2023)은 교사 모델에 대한 근거 생성 동안 대조 디코딩 Li et al. (2022); O\'Brien and Lewis (2023)을 활용한다. 또한, 바로가기 문제를 해결하기 위해 학생 모델을 훈련하는 동안 반사실적 추론 목표를 사용한다. DialCoT Han et al. (2023)은 추론 단계를 다중 라운드 대화로 분해하고 PPO 알고리즘을 사용하여 올바른 경로를 선택한다. Jie et al.(2023); Wang et al.(2023)은 수학 문제에 특별한 토큰을 추가한다. 이러한 높은 수준의 정보는 추론 단계의 일관성을 향상시킨다.\n' +
      '\n' +
      '위의 연구들은 우수한 추론 능력을 가진 LLM을 통해 추론 체인이 생성되는 공유 패러다임을 채택한다. 그런 다음 이러한 추론 사슬을 더 작은 모델로 증류한다. 증류 공정의 유효성은 예를 들어, 다수의 샘플링 경로, 일관성 또는 대조적 디코딩의 활용을 통해 더 큰 모델로부터 샘플링 전략을 증대시킴으로써 개선되며, 이는 생성된 추론 체인에서 향상된 다양성 및 정확성으로 이어져 궁극적으로 증류 공정을 더 작은 모델에 유리하게 한다. 언어 모델이 다차원 기능과 관련된 복잡한 절충안과 복잡한 균형을 가지고 있다는 점은 주목할 만하다. Fu et al. (2023)은 증류를 통해 태스크 특정 사고 연쇄 기능을 증가시키는 것도 일반화된 문제를 해결하는 데 있어 모델의 성능에 부정적인 영향을 미칠 수 있음을 강조한다.\n' +
      '\n' +
      '## 6 미래 방향\n' +
      '\n' +
      '연쇄적 사고 추론은 수많은 과제에서 놀라운 성과를 보여주었지만 일부 과제는 여전히 추가 탐구가 필요하다. 이 절에서는 향후 연구를 위한 세 가지 유망한 방법, 즉 다중 모드 X-사상 추론(SS6.1), 충실한 X-사상 추론(SS6.2), X-사상 추론 이론(SS6.3)에 대한 간략한 개요를 제공한다.\n' +
      '\n' +
      '### Multi-modal CoT\n' +
      '\n' +
      '텍스트 유니모달에서 비전 텍스트 멀티모달로의 전환은 더 풍부한 정보를 도입하면서 더 많은 도전을 가져온다. 일부 연구에서는 고품질 사고 사슬을 생성하기 위해 다중 모드 모델을 미세 조정함으로써 다중 모드 시나리오에서 사고 X-of-사고 추론을 탐구하려고 시도했다.\n' +
      '\n' +
      'Multimodal-CoT Zhang et al. (2023)은 먼저 다중 모달 모델을 미세 조정하여 연쇄 사상(chain-of-thoughts)을 생성한 다음 최종 답을 얻기 위한 근거에 대한 이유를 생성한다. 그러나 추론 과정의 선형성의 한계를 가지고 있으며, 서로 다른 양식의 상호 작용에는 어려움이 있다. Multimodal-CoT가 직면하는 도전들을 완화하기 위해, Yao 등(2023)은 사고 프로세스들을 그래프로 모델링하는 GoT(Graph-of-Think)를 제안한다. 추론 사슬을 사고 그래프로 파싱하여 비순차적인 정보 상호 작용을 포착하여 사고 과정을 보다 사실적으로 표현할 수 있게 한다. 이 측정은 그래픽 구조를 통해 선형 구조의 한계를 깨고 성능을 더욱 향상시킨다. 또한, Yao et al. (2023)은 사고 그래프를 하이퍼그래프로 대체하여 고차 다중 홉 추론 및 다중 모드 비교 판단 능력이 더 우수한 모델을 가능하게 하는 Hypergraph-of-Think(HoT)를 제안한다. 한편, 일부 작업은 지식 증류에 기반한 접근법을 취한다. T-SciQ Wang et al. (2023)은 미세 조정 신호로서 LLMs로부터 고품질 CoT 근거를 생성하고 다양한 질문에 대한 효과적인 샘플을 생성하기 위한 새로운 데이터 혼합 전략을 도입한다.\n' +
      '\n' +
      '앞서 언급한 연구들은 작은 모형과 미세 조정 시나리오에서 다중 모달 추론을 탐구하는데, 이는 다중 모달 사고 연쇄 추론의 영역에서 초기 시도라고 간주한다. 우리는 맥락 내 학습과 결합된 비디오 멀티모달 추론이 향후 연구의 초점이 되어야 한다고 생각한다. 한편으로 비디오는 이미지에 비해 타고난 연쇄 관계를 가진 추가적인 시간 정보를 도입한다. 연쇄적 사고 추론을 통해 서로 다른 프레임 내의 정보가 자연스럽게 연결되어 시간 관계를 명시적으로 모델링할 수 있으며, 이는 비디오 멀티모달 추론에 적합하다. 반면에 소형 모델은 용량이 제한적이며 연쇄적 사고 능력을 얻기 위해 미세 조정이 필요하다. 더 나쁜 것은 다중 모드 추론 사슬을 얻기 어렵고, 이는 도전을 더욱 악화시킨다. 이에 비해, 현대 비전-언어 기반 모델(VLMs) Alayrac et al. (2022); Li et al. (2023); Wang et al. (2022); Huang et al. (2023); Peng et al. (2023); Yu et al. (2021)은 강력한 비전-언어 이해를 가지며 이미 인터리브된 텍스트 및 이미지로 인-컨텍스트 학습이 가능하다. 그들은 맥락 내 학습으로 사고 연쇄 추론을 위한 견고한 기반을 제공한다. 비디오 추론을 위해 연쇄적 사고를 활용하는 것은 몇 가지 연구만 있는 미개척 영역으로 남아 있다. CoMT(Hu et al., 2023)는 비디오 추론에서 빠른 사고와 느린 사고를 결합하고 계획을 위한 트리 탐색 전략을 도입하는데, 이는 먼저 비디오 멀티모달 추론에서 CoT를 적용한다.\n' +
      '\n' +
      '일부 작업은 연쇄 사고 추론을 활용하고 다중 모드 추론 작업을 해결하기 시작했지만 이전 작업은 고품질 미세 조정 데이터를 구성하는 방법에만 초점을 맞추고 있으며 여전히 몇 가지 과제가 남아 있다.\n' +
      '\n' +
      '* 시각적 및 언어 기능을 통합하여 보다 나은 다중 모드 이해를 유도하는 방법.\n' +
      '* 미세 조정 없이 연쇄 사상 추론을 위해 VLMs를 사용하는 방법.\n' +
      '* 이미지 멀티모달 추론을 비디오 멀티모달 추론에 적용하는 방법.\n' +
      '\n' +
      '### Faithfulness\n' +
      '\n' +
      '광범위한 연구는 사고 연쇄 추론이 사실적 실수 및 맥락적 불일치와 같은 환각 현상을 유발할 수 있음을 나타낸다. 언어 모델은 근본적으로 통계적 모델에 속하며, 데이터 노이즈, 지식 망각 등의 요인으로 인해 환각 현상이 불가피하다.\n' +
      '\n' +
      '일부 작업은 사실상의 실수를 완화하는 데 중점을 둡니다. He et al. (2023)은 추론 체인을 평가하기 위해 외부 지식을 도입하고 사실적 실수를 포함하는 체인을 걸러내기 위해 표를 도입하지만 이를 수정하지 않고 Wang et al. (2023)은 유사한 방식을 채택하며, 저점수의 추론을 수정하기 위해 반영 메커니즘을 추가로 도입한다는 차이점이 있다. Zhao et al. (2023)은 일관성에 의해 저신뢰 추론을 필터링하고 관련 외부 지식을 기반으로 모델을 재추론하도록 안내한다. 앞서 언급한 방법은 지식 집약적인 작업에서 잘 작동하지만 맥락적 불일치의 문제를 해결하는 데 부족한다. Zhang et al. (2023)은 추론 과정에서 환각 눈덩이 현상을 탐구한다. 다른 사람들은 불일치 문제를 해결하는 것을 목표로 한다. Radhakrishnan et al.(2023)은 모델이 간단한 질문을 다룰 때 더 충실하다는 것을 관찰한다. 따라서 질문 분해를 통해 충실성을 향상시킵니다. Faithful CoT(Lyu et al., 2023)는 초기에 기호 추론 체인을 생성하고 나중에 결정론적으로 기호 함수를 실행하여 추론 불일치를 완화한다. Lanham et al.(2023)은 충성에 영향을 미치는 요인을 탐색하여 경험적 관점을 제공한다. 그것은 충실성이 다른 작업에 따라 다르며 모델 크기가 증가함에 따라 감소한다는 것을 발견한다. CoNLI(Lei et al., 2023)는 환각을 줄이기 위한 사후 편집 전략을 제안한다. SynTra(Jones et al., 2023)는 환각을 쉽게 이끌어낼 수 있도록 설계된 합성 데이터 세트에 대해 접두사 조정을 수행한 다음, 이 기능을 실제 작업에 전달한다.\n' +
      '\n' +
      '큰 언어 모델에서 환각 문제를 해결하기 위한 수많은 노력에도 불구하고 이러한 작업은 문제를 어느 정도 완화했을 뿐이다. 대형 언어 모델의 충실성을 완전히 높이려면 아직 갈 길이 멀다. 향후 방향을 정리하면 다음과 같다.\n' +
      '\n' +
      '* 추론 과정에서 환각 현상을 인식하는 능력 향상.\n' +
      '* 외부 지식 검색 및 활용의 정확성을 향상시켜 사실상의 실수를 줄입니다.\n' +
      '* 상황별 불일치 및 논리적 오류를 인식하고 수정하는 기능 향상은 더 어렵습니다.\n' +
      '* 선택적 사전 훈련과 같은 대체 접근 방식에서 환각 현상을 근본적으로 제거하는 방법.\n' +
      '\n' +
      '### CoT Theory\n' +
      '\n' +
      '연쇄적 사고 추론의 인상적인 능력에도 불구하고, 지시에 따라 연쇄적 사고를 생성하는 능력은 여전히 포괄적인 설명이 부족하다.\n' +
      '\n' +
      '일부는 경험적 관점에서 다루며 실질적인 가이드 역할을 할 수 있다. Madaan과 Yazdanbakhsh(2022)는 프롬프트를 기호, 패턴, 텍스트의 세 가지 구성요소로 분해하여 반사실적 프롬프트를 통해 CoT의 영향을 탐구한다. Wang et al.(2023)은 실증선정의 영향을 분석한다. 그들은 추론 사슬의 정확성은 무시할 수 있는 영향을 미치는 반면 질문과 올바른 추론 순서와의 관련성은 중요하다는 것을 발견했다. Tang et al.(2023)은 의미론의 역할을 탐구한다. 그들은 연쇄적 사고 추론이 사전 훈련 동안 도입된 의미적 지식에 크게 의존하고 상징적 추론에서 제대로 수행되지 않는다는 것을 발견했다.\n' +
      '\n' +
      '다른 사람들은 근본적인 원리와 내부 메커니즘을 탐구하면서 이론적으로 분석한다. Li et al. (2023)은 연쇄 사상 추론을 다단계 조합 함수로 재구성한다. 그들은 생각의 연쇄가 복잡한 질문을 다루기 위한 맥락 내 학습의 복잡성을 감소시킨다는 것을 보여준다. Feng et al. (2023)은 고정 크기 트랜스포머가 연쇄 사상(chain-of-thought)을 갖는 계산 작업 및 동적 계획에 충분하다는 것을 이론적으로 증명한다. 메릴과 사바왈(Merrill and Sabharwal,2023)은 중간 추론 단계의 수가 증가함에 따라 개선 정도가 증가하는 사고 연쇄가 추론 능력을 향상시킬 수 있음을 관찰한다. Wu 등(2023)은 기울기 기반 특징 속성 방법을 활용하여 산출물에 대한 사고 연쇄의 영향을 탐구한다. 결과는 사고 사슬이 질문의 섭동 및 변화에 대한 견고성을 나타낸다는 것을 나타낸다. 또한, 연쇄 사상 능력이 사전 훈련 단계(Madaan et al., 2022; Zhang et al., 2023c) 동안 코드 데이터에서 비롯되었다는 일부 주장이 있지만, 현재 이 의견을 입증하기 위한 체계적인 작업은 없다.\n' +
      '\n' +
      '현재 연쇄 사상 이론에 대한 연구는 아직 초기 탐구 단계에 있다. 향후 연구 방향을 정리하면 다음과 같다.\n' +
      '\n' +
      '* CoT 추론의 목표 된 개선을 달성 하는 연쇄 사상 능력의 원본을 탐색 합니다.\n' +
      '* 상황 내 학습보다 사고 연쇄의 이점을 이론적으로 분석하고 기능의 경계를 탐색합니다.\n' +
      '\n' +
      '## 7 Discussion\n' +
      '\n' +
      '### XoT 구성 비교\n' +
      '\n' +
      '기존 메서드에 대한 X-of-thought를 구성하는 세 가지 주요 방법이 있습니다. (1) **수동** 레이블링 추론 체인입니다. (2) 모델별 추론 체인을 **자동** 생성합니다. (3) 소수의 수동으로 레이블이 지정된 추론 체인에서 자동 확장을 사용하는 **반자동** 생성입니다.\n' +
      '\n' +
      '수동 구성 방법(Wei et al., 2022b; Gao et al., 2023)이 인-컨텍스트 학습, 즉 데모 선택, 명령 포맷팅 등과 유사한 도전에 직면함을 관찰한다(Dong et al., 2023). 이는 그 적용에 많은 어려움을 야기하고 다른 업무들에 걸친 전이 능력을 방해한다. 자동 구축 방법(Zhang 등, 2023f; Chen 등, 2022a; Xu 등, 2023)은 고품질 주석의 지침이 부족하여 성능 결함을 초래한다. 수동 주석들에 의해 가져온 신호들로부터 이득을 얻는, 반-자동 방법들(Shum et al., 2023; Shao et al., 2023)은 자기-부트스트래핑 및 유사한 기술들을 통해 고품질 추론 체인들을 생성할 수 있어, 이전의 접근법들에 의해 직면한 도전들을 효과적으로 해결한다. 뛰어난 성능을 달성하면서도 다양한 작업에 쉽게 이동할 수 있습니다.\n' +
      '\n' +
      '검증/정제 및 계획 비교\n' +
      '\n' +
      '계획 방법과 검증/정제 기반 방법 사이에는 수많은 병렬이 존재하며, 둘 다 동작을 조정하고 정제하기 위해 중간 프로세스의 피드백에 의존하기 때문이다. 차이점은 계획 방법이 의사 결정을 포함하는 반면 검증/정제 기반 방법은 상위 수준의 인지 과정을 탐구하지 않고 중간 오류만 해결한다는 사실에 있다.\n' +
      '\n' +
      'LLM 추론 과정은 종종 환각적이어서 사실적이고 논리적인 실수를 일으킨다. 기반 방법을 검증하고 편집한다(Ling et al., 2023; Zhao et al., 2023a; Madaan et al., 2023; Shinn et al., 2023). 추론 과정의 정확성을 검증하고 환각을 유발할 수 있는 추론 단계를 정제한다. 검증 및 정교화를 통해 추론 과정에서의 계단식 오류와 환각 현상을 현저히 감소시킨다.\n' +
      '\n' +
      '계획 방법(Long, 2023; Yao et al., 2023b,c; Liu et al., 2023a; Shinn et al., 2023)은 추론에서 의사 결정 프로세스를 도입한다. 그들은 피드백을 얻기 위해 중간 추론 단계를 평가하고 피드백을 기반으로 글로벌 수준에서 우수한 솔루션을 달성하기 위해 탐색 및 역추적에 참여한다. 그들의 전문화는 복잡한 문제를 처리하는 데 있으며, 특히 복잡한 다중 홉 추론 및 계획 작업에 직면할 때 놀라운 성능을 달성할 수 있도록 한다.\n' +
      '\n' +
      '### Innate 약점에 대 한 보상\n' +
      '\n' +
      'LLM은 외부 정보에 접근할 수 없는 점, 산술 오류, 일관성 없는 추론 등 추론에 있어 내재적 한계가 많다. 이러한 문제는 특정 책임을 전담 모듈이나 모델에 맡김으로써 교묘하게 회피할 수 있다.\n' +
      '\n' +
      '외부 정보에 액세스하는 모델들의 제한에 응답하여, (Li et al., 2023d; Wang et al., 2023b; Lu et al., 2023a; Schick et al., 2023; Karpas et al., 2022; Yoran et al., 2023) 지식 베이스, 검색 엔진들, 및 오픈-도메인 질의-응답 시스템들과 같은 외부 지식 자원들을 이용한다. 일부 작업은 산술 오류를 해결하기 위해 계산기를 도입한다(Schick et al.,2023; Karpas et al., 2022; Parisi et al., 2022). 코드 실행은 결정론적이며, 특정 작업은 코드 실행자 Gao 등(2023); Chen 등(2022); Bi 등(2023); Imani 등(2023)을 도입하여 추론 과정의 일관성을 향상시킨다. 본 연구에서는 LLMs을 중앙계획과 추론을 위한 에이전트로 사용하는 것이 향후 Wang et al.(2023)과 Xi et al.(2023)의 복잡한 시나리오에서 큰 모델을 적용할 수 있는 잠재적인 방법이라고 생각한다.\n' +
      '\n' +
      '### Other Work\n' +
      '\n' +
      '이 장에서는 연쇄 사고 추론에 대한 초기 시도를 나타내거나 특정 영역을 위해 설계된 다른 작업을 나열할 것이다.\n' +
      '\n' +
      'Katz et al.(2022); Zhang et al.(2022)은 벤치마크 및 리소스를 제공한다. Lampinen et al. (2022); Ye and Durrett (2022); Arora et al. (2023) and Shi et al. (2023)은 다언어적 CoT 추론을 탐구한다. 다른 작업은 기계 번역 He 등(2023), 감정 분석 Fei 등(2023), 문장 임베딩 Zhang 등(2023), 요약 Wang 등(2023), 산술 Lee와 Kim(2023), 표식 추론 Chen(2023); Jin과 Lu(2023) 등과 같은 특정 도메인에 초점을 맞춘다. 또한, 일부 연구는 수학적 추론 Lewkowycz 등(2022), Zhao 등(2022)과 같은 특정 능력을 향상시키기 위해 특정 사전 훈련을 활용한다.\n' +
      '\n' +
      '## 8 Conclusion\n' +
      '\n' +
      '본 논문에서는 X-of-thought 추론에 대한 기존 연구에 대한 광범위한 조사를 수행하여 해당 분야에 대한 포괄적인 검토를 제공한다. 일반화된 연쇄 사상(X-of-thought) 개념을 소개하고, X-of-thought 추론의 발전을 다각도로 살펴본다. 또한, 첨단 도메인에서 X-of-thought의 응용을 조사한다. 또한 본 연구가 직면한 당면 과제를 조명하고 향후 전망을 제시한다. 우리가 아는 한, 이 조사는 연쇄 사고 추론의 첫 번째 체계적인 탐색을 나타낸다. 우리의 목표는 이 조사가 이 분야의 추가 연구를 촉진할 것이라는 희망과 함께 철저한 개요와 함께 연쇄 사고 추론에 관심이 있는 연구자에게 제공하는 것이다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* A. A. Aggarwal, A. Madaan, Y. 양명민 (2023) 단계별로 표본을 추출해 보자: lms를 이용한 효율적인 추론을 위한 적응-일관성. CoRRabs/2305.11860. 인용: SS1.\n' +
      '* J. A. Alayrac, J. Donahue, P. Luc, A. M. Miesch, I. Barr, Y. 하손경 Lenc A Mensch, K. 밀리칸 레이놀즈 링 에 러더포드 카비티 한종호 공성 사만구애 몬테이루 J. L. 메닉 Borgeaud, A. Brock, A. Nematzadeh, S. 샤리프자데 빈코스키 바레이라 Vinyals, A. Zisserman, and K. Simonyan(2022)Flamingo: 소수의 샷 학습을 위한 시각적 언어 모델. NeurIPS에서 인용: SS1.\n' +
      '* A. Amini, S. 가브리엘 린락 콘셀케지어스키 Choi, and H. Hajishirzi (2019)MathQA: toward interpretable math word problem solving with operation-based formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1(Long and Short Papers), pp. 2357-2367. External Links: Link, Document Cited by: SS1.\n' +
      '* S. Arora, A. Narayan, M. F. Chen, L. J. Orr, N. 구하경 Bhatia, I. Chami, C. Re (2023) 무엇이든 물어보세요: 언어 모델을 자극하기 위한 간단한 전략입니다. 제11차 국제학술대회에서, ICLR 2023, Kigali, Rwanda, May 1-5, 2023, pp. 외부 링크: 링크, SS1에 의해 인용된 문서.\n' +
      '* M. 베스타 Blach, A. Kubicek, R. 거스텐버거, L. 지아니나치 J. 가즈다 레만 Podstawski, H. Niewiadomski, P. Nyczyk, and T. Hoefler (2023)Graph of thoughts: 정교한 문제를 큰 언어 모델로 푸는 것. CoRRabs/2308.09687. External Links: Link, 2308.09687 인용: SS1.\n' +
      '* S. Bhakthavatsalam, D. Khashabi, T. Khot B. Dalvi Mishra Richardson, A. Sabharwal, C. Schoenick, O. 타피오르드, P. 클라크(2021년) 당신은 직접 답 질문을 풀었다고 생각하나요? 직접 응답 AI2 추론 챌린지인 arc-da를 시도하십시오. CoRRabs/2102.03315. External Links: Link, 2102.03315 인용: SS1.\n' +
      '* Z. 비남 장영 장성 Deng, G. Zheng, H. Chen (2023) 프로그램은 언제 추론을 위해 작동합니까? 외부 링크: 링크, 2308.09687 인용: SS1.\n' +
      '* Y. 비스크 젤러스, R. L. Bras, J. Gao, 그리고 Y. 최(2020)PIQA: 자연어의 물리적 상식에 대한 추론. The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020_, pages 7432-7439. AAAI Press.\n' +
      '* Brown 등(2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Illya Sutskever, Dario Amodei. 2020. 언어 모델은 샷이 적은 학습자입니다. *신경 정보 처리 시스템의 발전 33: 신경 정보 처리 시스템에 대한 연례 회의 2020, NeurIPS 2020, 12월 6-12, 2020, 가상_.\n' +
      '* Cai et al. (2023) Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. 2023. 도구 제작자로서의 대형 언어 모델.\n' +
      '* Chen (2023) Wenhu Chen. 2023. Large language models is few(1)-shot table 추론기. 계산 언어학 협회의 _Findings of the Association for Computational Linguistics: EACL 2023, Dubrovnik, Croatia, May 2-6, 2023_, pages 1090-1100. Computational Linguistics.\n' +
      '* Chen et al.(2022a) Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. 코헨 2022a. 생각 프롬프트 프로그램: 수치 추론 작업에 대한 추론에서 계산을 분리합니다. _ CoRR_, abs/2211.12588.\n' +
      '* Chen et al. (2023) Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueang Ma, Jianyu Xu, Xinyi Wang, and Tony Xia. 2023. 정리: 정리 기반 질문 응답 데이터 세트입니다. _ CoRR_, abs/2305.12524.\n' +
      '* Chen et al.(2021) Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan R. 루틀리지, 윌리엄 양 왕 2021. Finqa: 재무 데이터에 대한 수치 추론의 데이터 세트. In _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event/ Punta Cana, Dominican Republic, 2021. 11. 7-11, 2021_, pages 3697-3711. Association for Computational Linguistics.\n' +
      '* Chen et al.(2022) Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena Shah, and William Yang. 2022b. Convfnqa: 회화 금융 질문 답변에서 숫자 추론의 연쇄를 탐구한다. "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 6279-6292. Computational Linguistics.\n' +
      '* Cheng et al. (2023) Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, and Tao Yu. 2023. 심볼릭 언어로 된 바인딩 언어 모델. <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '* Cobbe 등(2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. 수학 단어 문제를 푸는 훈련 검증기. _ CoRR_, abs/2110.14168.\n' +
      '* Crispino 등(2023a) Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2023a. 에이전트는 대규모 언어 모델에 일반적인 제로 샷 추론기를 사용하도록 지시합니다. _ arXiv preprint arXiv:2310.03710_.\n' +
      '* Crispino 등(2023b) Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2023b. 에이전트는 대규모 언어 모델에 일반적인 제로 샷 추론기를 사용하도록 지시합니다. _ arXiv preprint arXiv:2310.03710_.\n' +
      '* Crispino 등(2023b) Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2023b. 에이전트는 대규모 언어 모델에 일반적인 제로 샷 추론기를 지시합니다.\n' +
      '* Dagan et al.(2023) Gautier Dagan, Frank Keller, and Alex Lascarides. 2023. llm을 이용한 동적 계획. _ ArXiv_, abs/2308.06391.\n' +
      '* Devlin 등(2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: 언어 이해를 위한 딥 양방향 트랜스포머의 사전 훈련. <Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, June 2-7, Volume 1(Long and Short Papers)_, pages 4171-4186. Association for Computational Linguistics.\n' +
      '* Dhuliawala et al. (2023) Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. 2023. 연쇄 검증은 대형 언어 모델에서 환각을 감소시킵니다. _ arXiv preprint arXiv:2309.11495_.\n' +
      '* Diao et al.(2023) Shizhe Diao, Pengcheng Wang, Yong Lin, and Tong Zhang. 2023. 대규모 언어 모델에 대한 사고 연쇄를 통한 능동적 프롬프트. _ CoRR_, abs/2302.12246.\n' +
      '* Dong et al. (2023) Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. 2023. A survey for in-context learning. _ CoRR_, abs/2301.00234.\n' +
      '* Dong et al. (2022) Qingxiu Dong, Ziwei Qin, Heming Xia, Tian Feng, Shoujie Tong, Haoran Meng, Lin Xu, Zhongyu Wei, Weidong Zhan, Baobao Chang, Sujian Li, Tianyu Liu, and Zifang Sui. 2022. Premise-based multimodal reasoning: Conditional inference on joint textual and visual clues. [제60회 컴퓨터 언어학 협회 연례 회의(제1권: Long Papers), ACL 2022, 아일랜드 더블린, 2022년 5월 22-27일_, 페이지 932-946에서. 컴퓨터 언어학 협회.\n' +
      '\n' +
      '디에루 두아, 시반슈 굽타 사미르 싱, 맷 가드너 2022. 복잡한 질문을 분해하는 연속 프롬프트. "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 1251-1265. Computational Linguistics.\n' +
      '* Dua 등(2019) Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. 2019. DROP: 단락에 대한 이산 추론이 필요한 읽기 이해 벤치마크. <프로시빙스 오브 2019 북미 컴퓨터 언어학 협회 회의: 인간 언어 기술, 제1권(장문 및 단문)_, 2368-2378페이지, 미네소타주 미니애폴리스. 계산 언어학 협회\n' +
      '* Fei et al. (2023) Hao Fei, Bobo Li, Qian Liu, Lidong Bing, Fei Li, and Tat-Seng Chua. 2023. 연쇄적 사고 프롬프트로 암묵적 감성을 추론하는 단계. 전산 언어학 협회 제61차 연차 회의(제2권: 짧은 논문), ACL 2023, 캐나다 토론토, 7월 9-14, 2023_, 페이지 1171-1182에서. 전산 언어학 협회.\n' +
      '* Feng 등(2023) Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, and Liwei Wang. 2023. 사유의 사슬 뒤에 숨겨진 미스터리를 밝히기 위해: 이론적 관점입니다. _ CoRR_, abs/2305.15408.\n' +
      '* Fu et al.(2023a) Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2023a. 다단계 추론을 위한 복잡성 기반 프롬프트 <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '* Fu et al.(2023b) Yao Fu, Hao-Chun Peng, Litu Ou, Ashish Sabharwal, and Tushar Khot. 2023b. 다단계 추론을 위해 더 작은 언어 모델을 전문화합니다. "머신 러닝에 관한 국제 회의"에서.\n' +
      '* Gao et al.(2023) Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023. PAL: 프로그램 지원 언어 모델. "Proceedings of the 40th International Conference on Machine Learning_, Volume 202 of _Proceedings of Machine Learning Research_, pages 10764-10799. PMLR.\n' +
      '* Gerevini (2020) Alfonso Emilio Gerevini. 2020. PDDL(계획 도메인 정의 언어) 소개: 독후감 _ 아티프 Intell._ , 280:103221.\n' +
      '* Geva et al.(2021) Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021년 아리스토텔레스는 노트북을 사용했나요? 암묵적 추론 전략을 사용한 질문 답변 벤치마크입니다. _ 트랜스젠더 Assoc. 컴퓨팅. Linguistics_, 9:346-361.\n' +
      '* Gou et al.(2023) Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang, Nan Duan, and Weizhu Chen. 2023. 토라: 수학 문제 해결을 위한 도구 통합 추론 에이전트.\n' +
      '* 제26회 Pacific-Asia Conference, PAKDD 2022, Chengdu, China, May 16-19, 2022, Proceedings, Part III_, Volume 13282 of _Lecture Notes in Computer Science_, pages 3-15. Springer.\n' +
      '* Han et al. (2023) Chenghengg Han, Xiaowei Du, Che Zhang, Yixin Lian, Xiang Li, Ming Gao, and Baoyuan Wang. 2023. Dialoc meets ppo: Decomposing and exploring reasoning paths in smaller language models.\n' +
      '* Han et al.(2022) Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell, David Peng, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Shafiq R. 알렉산더 조티 파브리, 보지에크 크라이신스키, 시 빅토리아 린, 카임징 시옹, 드라고미르 라데프. 2022. FOLO: 1차 논리를 갖는 자연어 추론. _ CoRR_, abs/2209.00840.\n' +
      '* Hao et al. (2023) Shibo Hao, Yilan Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhiting Hu. 2023. 언어 모델을 추론하는 것은 세계 모델을 계획하는 것입니다. _ ArXiv_, abs/2305.14992.\n' +
      '* He et al.(2023a) Hangfeng He, Hongming Zhang, and Dan Roth. 2023a. 검색으로 다시 생각하는 것: 믿음직한 대규모 언어 모델 추론. _ CoRR_, abs/2301.00303.\n' +
      '* He et al.(2023b) Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, and Xing Wang. 2023b. 대용량 언어 모델을 사용하여 인간과 유사한 번역 전략을 탐색합니다. _ CoRR_, abs/2305.04118.\n' +
      '* Hendrycks 등(2021) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. MATH 데이터 세트를 사용하여 수학적 문제 해결을 측정합니다. 데이터 세트 및 벤치마크 1, NeurIPS 데이터 세트 및 벤치마크 2021, 2021년 12월, _신경 정보 처리 시스템의 진행률 추적_ 에서 가상_ 입니다.\n' +
      '* Ho et al.(2023) Namgyu Ho, Laura Schmid, and Se-Young Yun. 2023. 대규모 언어 모델은 추론 교사입니다. 전산 언어학 협회 제61차 연차 회의(제1권: Long Papers), ACL 2023, 캐나다 토론토, 7월 9-14, 2023_, 페이지 14852-14882에서.\n' +
      '* Hosseini et al.(2014) Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. 동사 범주화로 산술 단어 문제를 해결하는 학습. "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL_, pages 523-533. ACL.\n' +
      '* Hosseini et al. (2015)Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhias Fujii, Alexander J. Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023, 단계별 증류! 더 적은 훈련 데이터와 더 작은 모델 크기로 더 큰 언어 모델을 수행하는 것을 능가합니다. _ ArXiv_, abs/2305.02301.\n' +
      '* Hu et al.(2023a) Hanxu Hu, Hongyuan Lu, Huajian Zhang, Wai Lam, and Yue Zhang. 2023a. 기호 사슬 프롬프트는 대형 랑게이지 모델에서 계획을 도출합니다. _ CoRR_, abs/2305.10276.\n' +
      '* Hu et al.(2023b) Pengbo Hu, Ji Qi, Xingyu Li, Hong Li, Xinqi Wang, Bing Quan, Ruiyu Wang, and Yi Zhou. 2023b. Tree-of-mixed-thought: 멀티 홉 시각적 추론을 위해 빠르고 느린 사고를 결합합니다. _ CoRR_, abs/2308.09658.\n' +
      '* Huang et al.(2022) Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2022. 대규모 언어 모델은 자체 개선할 수 있습니다. _ CoRR_, abs/2210.11610.\n' +
      '*황 등(2023a) Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, and Denny Zhou. 2023a. 대규모 언어 모델은 아직 스스로 추론을 수정할 수 없습니다. _ arXiv preprint arXiv:2310.01798_.\n' +
      '* Huang et al.(2019) Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2019. Cosmos QA: 상황적 상식 추론을 통한 기계 독해력. "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019_, pages 2391-2401. Association for Computational Linguistics.\n' +
      '*황 등(2023b) 샤오한황, 리동, 원후이왕, 야루하오, 삭샴싱할, 슈밍 마, 텡차오 Lv, 레이추이, 오와이스 칸 모하메드, 바룬 파트라, 치앙 류, 크리티트 아가르왈, 주웬치, 요한 비요르크, 비슈라브 차우다리, 수호지트 솜, 샤송, 후루 웨이. 2023b. 언어가 필요한 것은 아닙니다. 지각과 언어 모델을 정렬합니다. _ CoRR_, abs/2302.14045.\n' +
      '*황 등(2023c) Yue Huang, Jiawen Shi, Yuan Li, Chenrui Fan, Siyuan Wu, Giihui Zhang, Yixin Liu, Pan Zhou, Yao Wan, Neil Zhenqiang Gong, and Lichao Sun. 2023c. 메타툴 벤치마크: 도구 사용 여부 및 사용 대상 결정\n' +
      '* Imani et al. (2023) Shima Imani, Liang Du, and Harsh Shrivastava. 2023. Mathprompter: 대형 언어 모델을 이용한 수학적 추론. <프로시빙스 오브 더 61th Annual Meeting of the Association of the Computational Linguistics: Industry Track, ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 37-42. Computational Linguistics.\n' +
      '* Ji et al. (2023) Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Ishii, and Pascale Fung. 2023. 자기 반성을 통해 큰 언어 모델에서 환각을 완화하기 위해. _ arXiv preprint arXiv:2310.06271_.\n' +
      '*장 등(2023a) 송장, 자하라 샤케리, 아론 찬, 마지아르 산자비, 하메드 피루즈, 잉룽 샤, 부그라 아키일디즈, 이저우 선, 진차오 리, 치판 왕, 등 2023a. Resprorupt: 잔차 연결 프롬프트는 대규모 언어 모델에서 다단계 추론을 향상시킵니다. _ arXiv preprint arXiv:2310.04743_.\n' +
      '* 장 등(2023b) Weisen Jang, Han Shi, Longhui Yu, Zhengying Liu, Yu Zhang, Zhenguo Li, and James T. 곽 2023b. 확인을 위해 대규모 언어 모델에서 전후진 추론을 수행합니다. _ CoRR_, abs/2308.07758.\n' +
      '* Jie et al. (2023) Zhanming Jie, Trung Quoc Luong, Xinbo Zhang, Xiaoran Jin, and Hang Li. 2023. Design of the chain-of-thought in math problem solving.\n' +
      '* Jin and Lu (2023) Ziqi Jin and Wei Lu. 2023. Tab-cot: Zero-shot tabular chain of thought. 계산 언어학 협회의 _Findings of the Association for Computational Linguistics: ACL 2023, Toronto, July 9-14, 2023_, pages 10259-10277. Computational Linguistics.\n' +
      '* Jones 등(2023) Erik Jones, Hamid Palangi, Clarisse Simoes, Varun Chandrasekaran, Subhabrata Mukherjee, Arindam Mitra, Ahmed Awadallah, and Ece Kamar. 2023. 언어 모델을 교육하여 합성 작업으로 환각을 덜 보게 합니다. _ arXiv preprint arXiv:2310.06827_.\n' +
      '* Karpas 등 (2022) Ehud D. Karpas, Omri Abend, Yoatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhl-gay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, Amnon Shashua, and Moshe Tenenholtz. 2022년입니다 미스터! 시스템: 대규모 언어 모델, 외부 지식 소스 및 이산 추론을 결합하는 모듈식 신경 기호 아키텍처입니다. _ ArXiv_, abs/2205.00445.\n' +
      '* Katz et al.(2022) Uri Katz, Mor Geva, and Jonathan Berant. 2022. 언어 모델과 함께 복잡한 질문에서 암묵적 관계를 추론합니다. 계산 언어학 협회의 _Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 2548-2566. Computational Linguistics.\n' +
      '* Khalifa 등(2023) Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, and Lu Wang. 2023. Discriminator-Guided Multi-step reasoning with language models. _ arXiv preprint arXiv:2305.14934_.\n' +
      '* Khot et al. (2023) Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. 2023. 분해 프롬프트: 복잡한 작업을 해결하기 위한 모듈식 접근법. <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '* Kojima et al.(2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. 대형 언어 모델은 제로 샷 추론기입니다. NeurIPS에서.\n' +
      '* Koncel-Kedziorski et al.(2021) Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena Dumas Ang.\n' +
      '\n' +
      '2015) 대수적 단어 문제를 방정식으로 파싱합니다. _ 계산 언어학 협회의 트랜잭션_, 3:585-597.\n' +
      '* Koncel-Kedziorski et al.(2016) Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016. MAWPS: 수학 단어 문제 저장소. _NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association of the Computational Linguistics: Human Language Technologies, San Diego California, USA, June 12-17, 2016_, pages 1152-1157. The Association for Computational Linguistics.\n' +
      '* Lampinen et al.(2022) Andrew K. 람피넨, 이시타 다스굽타, 스테파니 C. Y. 찬, 코리 W. 매튜슨, 엠 테슬러, 안토니아 크레스웰, 제임스 L. 맥클랜드, 제인 왕 펠릭스 힐 2022. 언어 모델은 문맥에서 설명을 통해 배울 수 있습니까? 계산 언어학 협회의 _Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 537-563. Computational Linguistics.\n' +
      '* De Lange 등(2022) Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory G. Slabaugh, and Tinne Tuytelaars. 2022. 지속적인 학습 조사: 분류 작업에서 잊어버림 방지 _ IEEE Trans. Pattern Anal. 마흐 Intell._ , 44(7):3366-3385.\n' +
      '* Lanham 등(2023) Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamile Lukositte, Karina Nguyen, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch, Robin Larson, Sam McCandlish, Sandipan Kundu, Saurav Kadavath, Shannon Yang, Thomas Henighan, Timothy Maxwell, Timothy Telleleen-Lawton, Tristan Hume, Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel R. 보우먼과 이선 페레즈 2023. 연쇄 사고 추론에 대한 충실도를 측정하는 것. _ CoRR_, abs/2307.13702.\n' +
      '* Lee and Kim (2023) 수찬 Lee and Gunhee Kim. 2023. 사고의 재귀: 언어 모델을 사용한 다중 맥락 추론에 대한 분할 정복 접근법. 계산 언어학 협회의 _Findings of the Association for Computational Linguistics: ACL 2023, Toronto, July 9-14, 2023_, pages 623-658. Computational Linguistics.\n' +
      '* Lei et al.(2023a) Bin Lei, Pei-Hung Lin, Chunhua Liao, and Caiwen Ding. 2023a. 새로운 프레임워크를 통해 대규모 언어 모델에서 논리적 추론을 강화합니다. 사상의 그래프 _ CoRR_, abs/2308.08614.\n' +
      '* Lei 등(2023b) Deren Lei, Yaxi Li, Mingyu Wang, Vincent Yun, Emily Ching, Eslam Kamal, et al. 2023b. 대규모 언어 모델의 근거 없는 환각을 줄이기 위한 자연어 추론 체인_ arXiv preprint arXiv:2310.03951_.\n' +
      '* Lei et al.(2020) Jie Lei, Licheng Yu, Tamara L. 버그와 모히트 밴살 2020년 다음엔 뭐가 더 일어날까요? 비디오 및 언어 미래 이벤트 예측. "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020_, pages 8769-8784. Association for Computational Linguistics.\n' +
      '* Lewkowycz et al. (2022) Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay V. 라마세시, 앰브로즈 슬론, 젬 아닐, 이마놀 슐락, 테오 굿만 솔로, 유화이 우, 베남 네이샤부르, 가이 구르아리, 베단트 미즈라. 2022. 언어 모델로 정량적 추론 문제를 해결합니다. NeurIPS에서.\n' +
      '*Li et al.(2022a) Jiangtong Li, Li Niu, Liqing Zhang. 2022a. 표현에서 추론에 이르기까지: 비디오 질의응답을 위한 증거와 상식 추론을 모두 지향한다. IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022_, pages 21241-21250. IEEE.\n' +
      '*Li 등(2023a) Junnan Li, Dongxu Li, Silvio Savarese, and Steven C. H. Hoi. 2023a. BLIP-2: 부트스트래핑 언어-동결된 이미지 인코더 및 대형 언어 모델을 사용한 이미지 사전 트레이닝. International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA_, Volume 202 of _Proceedings of Machine Learning Research_, pages 19730-19742. PMLR.\n' +
      '* Li et al.(2023b) Liunian Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, and Yejin Choi. 2023b. 상징적인 사고 연쇄 증류: 작은 모델도 단계적으로 "생각"할 수 있습니다. 전산언어학협회 제61차 연차총회(제1권: Long Papers), ACL 2023, 캐나다 토론토, 7월 9일-14일, 2023_, 2665-2679페이지에서.\n' +
      '* Li et al.(2023c) Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. 2023c. Apibank: 도구 증강 llms의 벤치마크입니다. _ ArXiv_, abs/2304.08244.\n' +
      '* Li et al.(2022b) Xiang Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori Hashimoto, Luke Zettlemoyer, and Mike Lewis. 2022b. 대비 디코딩: 최적화로서 개방형 텍스트 생성. [계산 언어학 협회 연례 회의]에서\n' +
      '* Li and Qiu (2023) Xiaonan Li and Xipeng Qiu. 2023. Mot: 사전 사고와 회상을 통해 채팅이 생각의 기억으로 스스로 개선되도록 합니다. _ CoRR_, abs/2305.05181.\n' +
      '* Li et al.(2023d) Xingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng Ding, Lidong Bing, Shafiq R. 조티, 소야냐 포리아 2023d. 지식 사슬: 구조화된 지식 기반과 함께 대규모 언어 모델을 기반으로 하는 프레임워크입니다. _ CoRR_, abs/2305.13269.\n' +
      '* Li et al.(2022c) Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, B. Chen, Jian-Guang Lou, and Weizhu Chen. 2022c. 단계 인식 검증기를 사용하여 언어 모델을 더 나은 추론자로 만듭니다. [계산 언어학 협회 연례 회의]에서\n' +
      '\n' +
      '* Li et al. (2023) Yingcong Li, Kartik Sreenivasan, Angeliki Giannou, Dimitris S. 파파일로풀로스와 사멧 오이막 2023e. 해부 연쇄 사상: mlps의 구성적 맥락 내 학습에 관한 연구 _ CoRR_, abs/2305.18869.\n' +
      '* August 4, Volume 1: Long Papers_, pages 158-167. Association for Computational Linguistics.\n' +
      '* Ling 등(2023) Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland Memisevic, and Hao Su. 2023. 연쇄적 사고 추론의 연역적 검증. _ CoRR_, abs/2306.03872.\n' +
      '* Liu et al.(2023a) Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone. 2023a. Llm+p: 최적의 계획 능력을 갖춘 대형 언어 모델 임파워링.\n' +
      '* Liu et al.(2023b) Jiacheng Liu, Ramakanth Pasunuru, Hannaneh Hajishirzi, Yejin Choi, and Asli Celikyilmaz. 2023b. 결정: 자기피드백으로 강화된 내성적인 추론자들. _ arXiv preprint arXiv:2310.04921_.\n' +
      '* Liu et al.(2020) Jian Liu, Leyang Cui, Hanmeng Liu, 단단황, Yile Wang, and Yue Zhang. 2020. Logiqa: 논리적 추론으로 기계 읽기 이해를 위한 챌린지 데이터 세트. <Proceedings of the 20-9th International Joint Conference on Artificial Intelligence, IJCAI 2020>, 3622-3628 페이지. ijcai.org.\n' +
      '* Long (2023) Jieyi Long. 2023. Large language model guided tree-of-thought. _ CoRR_, abs/2305.08291.\n' +
      '* Lu et al.(2023a) Hongyuan Lu, Haoyang Huang, Dongdong Zhang, Haoran Yang, Wai Lam, and Furu Wei. 2023a. 사전 연쇄 프롬프트는 대규모 언어 모델에서 번역을 유도합니다. _ CoRR_, abs/2305.06575.\n' +
      '* Lu et al.(2022) Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. 2022. 설명하기 학습: 과학 질문 응답을 위한 사고 사슬을 통한 멀티모달 추론. NeurIPS에서.\n' +
      '* Lu et al.(2023b) Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, and Ashwin Kalyan. 2023b. 반구조화된 수학적 추론을 위한 정책 기울기를 통한 동적 프롬프트 학습 <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '* Lu et al.(2023c) Yining Lu, Haoping Yu, and Daniel Khashabi. 2023c. 기어: 일반화 가능하고 효율적인 도구 분해능으로 언어 모델을 확장합니다.\n' +
      '* Lyu et al.(2023) Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and Chris Callison-Burch. 2023. 믿음직한 사고 연쇄 추론. _ CoRR_, abs/2301.13379.\n' +
      '* Madaan 등(2022) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean Welleck, Bhisattwa Prasad Majumder, Shashank Gupta, Amir Yazdanbakhsh, and Peter Clark. 2023. Self-refine: Self-feedback을 이용한 반복적 정제. _ CoRR_, abs/2303.17651.\n' +
      '* Madaan and Yazdanbakhsh (2022) Aman Madaan and Amir Yazdanbakhsh. 2022. 텍스트 및 패턴: 효과적인 사고 사슬을 위해서는 탱고에 두 개가 필요합니다. _ CoRR_, abs/2209.07686.\n' +
      '* Madaan et al.(2022) Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, and Graham Neubig. 2022. 코드의 언어 모델은 소수의 상식적인 학습자들이다. "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 1384-1403. Computational Linguistics.\n' +
      '* Magister 등(2023) Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, and Aliaksei Severyn. 2023. 이성에 대한 작은 언어 모델을 가르칩니다. 전산 언어학 협회의 제61차 연차 회의(제2권: 짧은 논문), ACL 2023, 캐나다 토론토, 7월 9일-14일, 2023_, 1773-1781페이지에서.\n' +
      '* 메릴 및 사바왈(2023) 윌리엄 메릴 및 애쉬 사바왈. 2023. 사상의 사슬을 가진 변압기의 표현력.\n' +
      '* Miao et al.(2023) Ning Miao, Yee Whye Teh, and Tom Rainforth. 2023. Selfcheck: lms를 사용하여 제로샷으로 자신의 단계별 추론을 확인합니다. _ arXiv preprint arXiv:2308.00436_.\n' +
      '* Miao et al.(2020) Shen-yun Miao, Chao-Chun Liang, and Keh-Yih Su. 2020. 영어 수학 단어 문제 풀이기 평가 및 개발을 위한 다양한 코퍼스. [컴퓨팅 언어학 협회 제58차 연례 회의]에서 975-984 페이지, 온라인. 계산 언어학 협회\n' +
      '* Mihaylov et al. (2018) Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. 2018. 갑옷이 전기를 통할 수 있습니까? 오픈 북 질문 응답을 위한 새 데이터 세트 《2018 자연 언어 처리 실증 방법에 관한 회의》에서 벨기에 브뤼셀의 2381-2391쪽이다. 계산 언어학 협회\n' +
      '* Mishra et al.(2022a) Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, and Ashwin Kalyan. 2022a. 수학 추론을 위한 통일된 벤치마크 "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 5807-5832. Computational Linguistics.\n' +
      '* Madaan 등(2022b)Swaroop Mishra, Arindam Mitra, Neeraj Varshney, Bhavedeep Singh Sachdeva, Peter Clark, Chitta Baral, and Ashwin Kalyan. 2022b. 넘글루: 근본적이면서도 도전적인 수학적 추론 과제의 집합입니다. [제60회 컴퓨터 언어학 협회 연례 회의(제1권: Long Papers), ACL 2022, 아일랜드 더블린, 2022년 5월 22-27일_, 3505-3523페이지에서. 컴퓨터 언어학 협회.\n' +
      '* Mo and Xin (2023) Shentong Mo and Miao Xin. 2023. 큰 언어 모델에 대한 불확실한 생각 추론 트리. _ CoRR_, abs/2309.07694.\n' +
      '* Naik 등(2023) Ranjita Naik, Varun Chandrasekaran, Mert Yuksekgonul, Hamid Palangi, and Besmira Nushi. 2023. 사고의 다양성은 큰 언어 모델의 추론 능력을 향상시킵니다. _ arXiv preprint arXiv:2310.07088_.\n' +
      '* Ning 등(2023) Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, and Yu Wang. 2023. Skeleton-of-thought: Large language models can do parallel decoding. _ CoRR_, abs/2307.15337.\n' +
      '* O\'Brien and Lewis (2023) Sean O\'Brien and Mike Lewis. 2023. 대조 디코딩은 대형 언어 모델에서 추론을 개선합니다. _ ArXiv_, abs/2309.09117.\n' +
      '* OpenAI (2023) OpenAI. 2023. GPT-4 기술 보고서. _ CoRR_, abs/2303.08774.\n' +
      '* Paranjape 등(2023) Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. 2023. Art: Automatic multi-step reasoning and tool-use for large language models.\n' +
      '* Parisi et al.(2022a) Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022a. Talm: 도구 확장 언어 모델입니다. _ ArXiv_, abs/2205.12255.\n' +
      '* Parisi et al.(2022b) Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022b. TALM: 도구 확장 언어 모델입니다. _ CoRR_, abs/2205.12255.\n' +
      '* ECCV 2020\n' +
      '- 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part V_, volume 12350 of _Lecture Notes in Computer Science_, pages 508-524. Springer.\n' +
      '* Patel 등 (2021) Arkil Patel, Satwik Bhattacharya, and Navin Goyal. 2021. NLP 모델은 정말 간단한 수학 단어 문제를 해결할 수 있나요? <Proceedings of the 2021 Conference of the North American Chapter of the Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021_, pages 2080-2094. Association for Computational Linguistics.\n' +
      '* Paul et al. (2023) Debjit Paul, Mete Ismayilkada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, Robert West, and Boi Faltings. 2023. REFINER: reasoning feedback on intermediate representation. _ CoRR_, abs/2304.01904.\n' +
      '* Peng 등(2023) Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, and Furu Wei. 2023. Kosmos-2: 멀티모달 대형 언어 모델을 세계에 접지합니다. _ CoRR_, abs/2306.14824.\n' +
      '* Pitis et al. (2023) Silviu Pitis, Michael R. 장, 앤드루 왕 지미 바 2023. 대규모 언어 모델을 위한 프롬프트 앙상블을 활성화합니다. _ CoRR_, abs/2304.05970.\n' +
      '* Qiao et al. (2023) Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, and Huajun Chen. 2023. 언어 모델 추론 프롬프트: 설문조사. [제61회 컴퓨터 언어학 협회 연례 회의(제1권: Long Papers), ACL 2023, 캐나다 토론토, 7월 9-14일, 2023_, 페이지 5368-5393]에서. 컴퓨터 언어학 협회.\n' +
      '* Radford and Narasimhan (2018) Alec Radford and Karthik Narasimhan. 2018. 생성적 사전 훈련에 의한 언어 이해력 향상.\n' +
      '* Radhakrishnan 등(2023) Ansh Radhakrishnan, Karina Nguyen, Anna Chen, Carol Chen, Carson Denison, Danny Hernandez, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamille Lukositute, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch, Sam McCandlish, Sheer El Showk, Tamera Lanham, Tim Maxwell, Venkatesa Chandrasekaran, Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel R. 보우먼과 이선 페레즈 2023. 질문 분해는 모델 생성 추론의 충실성을 향상시킵니다. _ CoRR_, abs/2307.11768.\n' +
      '* Raffel 등(2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. 통합 텍스트 대 텍스트 변환기를 사용 하 여 전이 학습의 한계를 탐색 합니다. _ J 마흐 배워요 Res._ , 21(1).\n' +
      '* Rashkin et al.(2018) Hannah Rashkin, Maarten Sap, Emily Allaway, Noah A. Smith, and Yejin Choi. 2018. EventZmind: 이벤트, 의도 및 반응에 대한 상식 추론. "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers_, pages 463-473. Association for Computational Linguistics.\n' +
      '* Roy and Roth (2015) Subhro Roy and Dan Roth. 2015. 일반 산술 단어 문제 해결. "2015년 자연 언어 처리 실증 방법에 관한 회의 회보"에서 포르투갈 리스본의 1743-1752쪽입니다. 계산 언어학 협회\n' +
      '* Ruan 등(2023) Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hanyu Mao, Xingyu Zeng, and Rui Zhao. 2023. Tptu: 대규모 언어 모델 기반 AI 에이전트의 작업 계획 및 도구 사용.\n' +
      '* 사파로프 및 He (2023) Aulhair Saparov and He He. 2023. 언어 모델은 탐욕스러운 추론자: 연쇄적 사고의 체계적인 공식 분석입니다. <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '* Raffel et al.(2020)* Le Scao et al.(2023) Teven Le Scao, Angela Fan, Christopher Akiki, Elie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagne, Alexandra Sasha Luccioni, Francois Yvon, Matthias Galle, Jonathan Tow, Alexander M. Rush, Stella Biderman, Albert Webson, Pawan Sasanka Ammanmananchi, Thomas Wang, Benoit Sagot, Huu Nguyen, Lucile Saulnier, Niklas Muennighoff, Albert Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major, Iz Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro Ortiz Suarez, Victor Sanh, Hugo Laurencon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa, Alham Fikri Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue, Christopher Klamm, Colin Leong, Daniel van Strien, David Ifeolu CoRR_, abs/2211.05100.\n' +
      '* Schaeffer et al.(2023) Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. 2023. 대형 언어 모델의 새로운 능력은 신기루인가? _ CoRR_, abs/2304.15004.\n' +
      '* Schick 등(2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. 툴포머: 언어 모델은 스스로 도구를 사용하도록 가르칠 수 있습니다. _ CoRR_, abs/2302.04761.\n' +
      '* Sel et al. (2023) Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Lu Wang, Ruoxi Jia, and Ming Jin. 2023. 생각의 알고리즘: 대규모 언어 모델에서 아이디어 탐구를 향상시킵니다. _ CoRR_, abs/2308.10379.\n' +
      '* Shao et al. (2023) Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen. 2023. 합성 프롬프트: 대형 언어 모델에 대한 사고 연쇄 데모를 생성합니다. _ CoRR_, abs/2302.00618.\n' +
      '* Shen et al. (2023) Yongliang Shen, Kaitao Song, Xu Tan, Dong Sheng Li, Weiming Lu, and Yue Ting Zhuang. 2023. Huggingpt: 채팅챗과 그 친구들과 포옹하는 얼굴로 AI 작업을 해결합니다. _ ArXiv_, abs/2303.17580.\n' +
      '* Shi et al. (2023) Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. 2023. 언어 모델은 다국어 연쇄 사상 추론자이다. <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '* Shinn et al. (2023) Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023. 반사: 언어 강화 학습을 갖는 언어 에이전트.\n' +
      '* Shridhar et al. (2023) Kumar Shridhar, Harsh Jhamtani, Hao Fang, Benjamin Van Durme, Jason Eisner, and Patrick Xia. 2023. 나사: 수정이 있는 추론을 위한 모듈식 프레임워크입니다. _ arXiv preprint arXiv:2309.13075_.\n' +
      '* Shum et al. (2023) Kashun Shum, Shizhe Diao, and Tong Zhang. 2023. 레이블이 지정된 데이터의 연쇄를 사용하여 자동 프롬프트 확대 및 선택 _ CoRR_, abs/2302.12822.\n' +
      '* Srivastava et al. (2019) Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adria Garriga-Alonso, Agnieszka Kluka, Aitor Lewkowycz, Akshat Agarwal, Allethea Power, Alex Ray, Alex Warstadt, Alexander W. 코쿠렉, 알리 사파야, 알리 차라브, 앨리스 샹, 알리시아 파리시, 앨런 니, 아만 후사인, 아만다 아스켈, 아만다 드수자, 아밋 라하네, 아난타라만 S. Iyer, Anders Andreassen, Andrea Santilli, Andreas Stuhlmuller, Andrew M. 다이, 앤드루 라, 앤드루 K Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas 및 et al. 2022. 모방 게임을 넘어: 언어 모델의 능력을 정량화하고 외삽합니다. _ CoRR_, abs/2206.04615.\n' +
      '* Sun et al.(2023) Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, and Chao Zhang. 2023. Adaplanner: Adaptive planning from feedback with language models. _ ArXiv_, abs/2305.16653.\n' +
      '* Suzgun et al. (2023) Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. 르, 에드 치, 데니 저우, 제이슨 웨이 2023년, 큰 벤치 과제들 그리고 사고 연쇄가 그것들을 해결할 수 있는지 여부. "Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 13003-13051. The Association for Computational Linguistics.\n' +
      '* Tafjord et al.(2021) Oyvind Tafjord, Bhavana Dalvi, and Peter Clark. 2021. 프롭라이터: 자연어에 대한 함축, 증명 및 귀납적 진술을 생성합니다. Computational Linguistics Association of the _Findings of the Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021_, Volume ACL/IJCNLP 2021 of _Findings of ACL_, pages 3621-3634. Association for Computational Linguistics.\n' +
      '* Talmor 등(2019) Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. Commonsenseqa: 상식 지식을 대상으로 하는 질문 응답 챌린지. <Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, June 2-7, Volume 1(Long and Short Papers)_, pages 4149-4158. Association for Computational Linguistics.\n' +
      '* Talmor 등(2021) Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and Jonathan Berant. 2021. Commonsenseqa 2.0: 게이미피케이션을 통한 AI의 한계 노출. 데이터 세트 및 벤치마크 1, NeurIPS 데이터 세트 및 벤치마크 2021, 2021년 12월, _신경 정보 처리 시스템의 진행률 추적_ 에서 가상_ 입니다.\n' +
      '* Tang et al. (2023) Xiaojuan Tang, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. 2023. 대규모 언어 모델은 상징적 추론기보다는 문맥 내 의미론적 추론기입니다. _ CoRR_, abs/2305.14825.\n' +
      '* Touvron 등(2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothete Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a. 라마: 개방적이고 효율적인 기초 언어 모델입니다. _ CoRR_, abs/2302.13971.\n' +
      '* 투브론 등(2023a) 휴고 투브론, 루이 마틴, 케빈 스톤, 피터 알버트, 암자드 알마하리, 야스민 바베이, 니콜라 바슐리코프, 수미 바트라, 크리스티안 칸톤 페러, 모야 첸, 기예름 쿠쿠룰, 다비드 에시오부, 주드 페르난데스, 제레미 푸, 웨닌 푸, 브라이언 풀러, 신시아 가오, 제레미 푸, 베다누즈 고세이니, 루이 호우, 하칸 이난, 마르신 카다스, 빅토르 케르케즈, 마디안 코레네시, 이사벨 콜루만, 아템 코레네시, 푸니 싱 구라, 마리-안네 라흐로프, 티보트 라브릴, 제냐 리,아나 리스코비치, 잉하이 루, 윤잉 마오, 사보트 라브릴, 제냐 리, 아나 리스코비치, 유닌 슐텐, 루안 실바, 에릭 마이클 스미스, 란잔 수브라만안, 샤오칭 엘렌 탄, 빈 탕, 로스 테일러, 아디나 윌리엄 2023b. 라마 2: 오픈 파운데이션과 미세 조정된 채팅 모델입니다. _ CoRR_, abs/2307.09288.\n' +
      '* Wan et al.(2023) Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan O. 아릭, 토마스 피스터 2023. self-adaptive prompting으로 제로샷 추론이 더 좋습니다. 계산 언어학 협회의 _Findings of the Association for Computational Linguistics: ACL 2023, Toronto, July 9-14, 2023_, pages 3493-3514. Computational Linguistics.\n' +
      '* Wang et al.(2022a) Boshi Wang, Xiang Deng, and Huan Sun. 2022a. 사상의 사슬을 위해 사전 훈련된 언어 모델을 반복적으로 촉진합니다. "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022_, pages 2714-2730. Computational Linguistics.\n' +
      '* Wang et al.(2023a) Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, and Huan Sun. 2023a. 연쇄적 사고를 이해하는 것은 무엇이 중요한지에 대한 실증적 연구이다. 전산언어학협회 제61차 연차총회(제1권: Long Papers), ACL 2023, 캐나다 토론토, 7월 9일-14일, 2023_, 2717-2739페이지에서.\n' +
      '* Wang et al. (2019) Cunxiang Wang, Shuailong Liang, Yue Zhang, Xiaonan Li, and Tian Gao. 2019년, 말이 돼? 그리고 왜? 감각적 제작과 설명을 위한 예비 연구 [계산 언어학 협회 제57차 연례 회의]에서 이탈리아 피렌체 4020-4026쪽. 계산 언어학 협회\n' +
      '* Wang et al.(2023b) Jianing Wang, Qiushi Sun, Nuo Chen, Xiang Li, and Ming Gao. 2023b. 지식 연쇄 프롬프트를 사용하여 언어 모델을 추론하는 기능을 강화합니다. _ CoRR_, abs/2306.06427.\n' +
      '* Wang et al.(2022c) Keheng Wang, Feiyu Duan, Sirui Wang, Peiguang Li, Yunsen Xian, Chuantao Yin, Wenge Rong, and Zhang Xiong. 2023c. 지식 중심 코트: 지식 집약적인 질문 응답을 위한 충실한 추론 탐구.\n' +
      '* Wang et al.(2023d) Lei Wang, Yi Hu, Jiabang He, Xing Xu, Ning Liu, Hui Liu, and Heng Tao Shen. 2023d. T-sciq: 과학 질문 응답을 위한 큰 언어 모델 신호를 통해 멀티모달 사고 연쇄 추론 가르치기 _ CoRR_, abs/2305.03453.\n' +
      '* Wang et al.(2023e) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Ji-Rong Wen. 2023e. 대형 언어 모델 기반 자율 에이전트에 대한 조사입니다. _ CoRR_, abs/2308.11432.\n' +
      '* Wang et al.(2023f) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim. 2023f. 계획 및 해결 프롬프트: 대규모 언어 모델에 의한 제로 샷 사고 연쇄 추론 개선 전산 언어학 협회 제61차 연차 회의(제1권: Long Papers), ACL 2023, 캐나다 토론토, 7월 9-14, 2023_, 페이지 2609-2634에서.\n' +
      '* Wang et al.(2023g) Liyuan Wang, Xingxing Zhang, Hang Su, and Jun Zhu. 2023g. 지속적인 학습에 대한 포괄적인 조사: 이론, 방법 및 적용. _ CoRR_, abs/2302.00487.\n' +
      '* Wang et al.(2023h) Peifeng Wang, Zhengyang Wang, Zheng Li, Yifan Gao, Bing Yin, and Xiang Ren. 2023h. 스콧: 자기 일관성 있는 생각의 사슬 증류. [계산 언어학 협회 연례 회의]에서\n' +
      '* Wang et al.(2022b) Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, Furu Wei. 2022b. 외국어로서의 이미지: 모든 비전 및 비전 언어 작업에 대해 사전 교육을 받으십시오. _ CoRR_, abs/2208.10442.\n' +
      '* Wang et al.(2023i) Xinyi Wang, Lucas Caccia, Oleksiy Ostapenko, Xingdi Yuan, and Alessandro Sordoni. 2023i. 토큰을 계획하는 언어 모델 추론 안내\n' +
      '\n' +
      '왕쉐지, 제이슨 웨이, 데일 슈어만스, 콕 V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou. 2023j. 자기일관성은 언어 모델에서 사고 추론의 사슬을 개선한다. <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '* Wang et al.(2023) Yiming Wang, Zhuosheng Zhang, and Rui Wang. 2023k. 대용량 언어 모델을 사용한 요소 인식 요약: 전문가 정렬 평가 및 사고 연쇄 방법. 전산 언어학 협회 제61차 연차 회의(제1권: Long Papers), ACL 2023, 캐나다 토론토, 7월 9-14일, 2023_, 페이지 8640-8665에서. 전산 언어학 협회.\n' +
      '* Wei et al.(2022a) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a. 대형 언어 모델의 최신 능력입니다. _ 트랜스젠더 마흐 배워요 Res._ 2022년\n' +
      '* Wei et al.(2022b) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. 레, 데니 저우 2022b. 사고 연쇄 프롬프트는 대규모 언어 모델에서 추론을 이끌어낸다. NeurIPS에서.\n' +
      '* Weng et al.(2022) Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu, and Jun Zhao. 2022. Large language models is inferred with self-verification. _ arXiv preprint arXiv:2212.09561_.\n' +
      '* Wu et al.(2021) Bo Wu, Shoubin Yu, Zhenfang Chen, Josh Tenenbaum, and Chuang Gan. 2021. STAR: 실제 비디오에서 상황 추론의 벤치마크. 데이터 세트 및 벤치마크 1, NeurIPS 데이터 세트 및 벤치마크 2021, 2021년 12월, _신경 정보 처리 시스템의 진행률 추적_ 에서 가상_ 입니다.\n' +
      '* Wu et al. (2023) Skyler Wu, Eric Meng Shen, Charumathi Badrinath, Jiaqi Ma, and Himabidu Lakkaraju. 2023. 그래디언트 기반 특징 속성을 통해 대규모 언어 모델에서 프롬프트하는 연쇄를 분석합니다. _ CoRR_, abs/2307.13339.\n' +
      '* Xi et al. (2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qizhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Suanjing Huan, and Tao Gui. 2023. 대규모 언어 모델 기반 에이전트의 부상 및 잠재력: 조사 _ CoRR_, abs/2309.07864.\n' +
      '* Xiao et al.(2021) Junbin Xiao, Xindi Shang, Angela Yao, and Tat-Seng Chua. 2021. Next-qa: 시간 행위를 설명하는 질문-응답의 다음 단계. *IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021_, pages 9777-9786. Computer Vision Foundation/IEEE.\n' +
      '* Xu 등 (2023) Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jojic. 2023. Reprompting: Automated chain-of-thought prompt inference through gibbs sampling.\n' +
      '*Xue et al. (2023) Tianc Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, and Heng Ji. 2023. RCOT: 사고 사슬을 역전시켜 추론에서 사실적 불일치를 탐지하고 교정합니다. _ CoRR_, abs/2305.11499.\n' +
      '* Yang et al. (2023) Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, and Lijuan Wang. 2023. MMEAACT: prompteding chatgpt for multimodal reasoning and action. _ CoRR_, abs/2303.11381.\n' +
      '* Yang et al.(2022) Zonglin Yang, Li Dong, Xinya Du, Hao Cheng, Erik Cambria, Xiaodong Liu, Jianfeng Gao, and Furu Wei. 2022. 언어 모델은 귀납적 추론자입니다. _ CoRR_, abs/2212.10923.\n' +
      '*Yao et al.(2023a) Fanglong Yao, Changyuan Tian, Jintao Liu, Zequn Zhang, Qing Liu, Li Jin, Shuchao Li, Xiaoyu Li, and Xian Sun. 2023a. 전문가처럼 생각하는 것: 기초 모달들을 향상시키기 위한 멀티모달 하이퍼그래프-of-thought (hot) 추론.\n' +
      '* Yao et al. (2023b) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. 그리피스, 원조 카르티크 나라심한 2023b. 사고의 나무: 큰 언어 모델을 사용하여 문제 해결을 숙고합니다. _ CoRR_, abs/2305.10601.\n' +
      '* Yao et al. (2023c) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. 나라심한과 원조 2023c. 반응: 언어 모델에서 추론과 행동을 활성화합니다. <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '*Yao et al.(2023d) Yao Yao, Zuchao Li, and Hai Zhao. 2023d. 사상 연쇄를 넘어 대규모 언어 모델에서 효과적인 사상 그래프 추론입니다. _ CoRR_, abs/2305.16582.\n' +
      '* Ye and Durrett (2022) Xi Ye and Greg Durrett. 2022. The unreliability of explanation in few-shot in-context learning. _ CoRR_, abs/2205.03401.\n' +
      '* Ye and Durrett (2023) Xi Ye and Greg Durrett. 2023. unlabeled data using in-context learning. _ CoRR_, abs/2302.04813.\n' +
      '* Ye et al. (2023) Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, and Yongbin Li. 2023. 대형 언어 모델은 다재다능한 분해자: 테이블 기반 추론을 위한 증거 및 질문을 분해한다. "Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023_, pages 174-184. ACM.\n' +
      '* Yi et al.(2020) Kexin Yi, Chang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, and Joshua B. Tenenbaum. 2020. CLEVRER: 충돌 이벤트 for video representation and reasoning. 제8회 국제학술대회에서, ICLR 2020, 에티오피아 아디스아바바, 2020년 4월 26일부터 30일까지. OpenReview.net.\n' +
      '* Yoran et al.(2023) Ori Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel Deutch, and Jonathan Berant. 2023. 여러 사고 사슬에 대한 메타 추론으로 질문에 답합니다. _ CoRR_, abs/2304.13007.\n' +
      '* Yu et al.(2023a) Fei Yu, Hongbo Zhang, and Benyou Wang. 2023a. 자연 언어 추론, 설문 조사. _ CoRR_, abs/2303.14725.\n' +
      '* Yu et al.(2023b) Junchi Yu, Ran He, and Rex Ying. 2023b. 사고 전파: 대규모 언어 모델을 사용한 복잡한 추론에 대한 유추적 접근법 _ arXiv preprint arXiv:2310.03965_.\n' +
      '* Yu et al.(2020) Weihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi Feng. 2020. Reclor: 논리적 추론이 필요한 읽기 이해 데이터 세트. 제8회 국제학술대회에서, ICLR 2020, 에티오피아 아디스아바바, 2020년 4월 26일부터 30일까지. OpenReview.net.\n' +
      '* Yu et al.(2021a) Weijiang Yu, Yingpeng Wen, Fudan Zheng, and Nong Xiao. 2021a. 사전 훈련된 지식과 계층적 추론을 통해 수학 단어 문제를 개선한다. 도미니카 공화국의 온라인 및 푼타 가나 3384-3394 페이지 _자연어 처리 실증 방법에 관한 2021년 회의 회보_에서. 계산 언어학 협회\n' +
      '* Yu et al.(2021b) Weijiang Yu, Haoteng Zheng, Mengfei Li, Lei Ji, Lijun Wu, Nong Xiao, and Nan Duan. 2021b. 내부 학습: 비디오 질문 응답을 위한 자체 구동 시아마 샘플링 및 추론입니다. _ Advances in Neural Information Processing Systems_, 34:26462-26474.\n' +
      '* Yu et al.(2023c) Zihan Yu, Liang He, Zhen Wu, Xinyu Dai, and Jiajun Chen. 2023c. 더 나은 연쇄적 사고를 위한 전략: 설문조사.\n' +
      '* Zelikman et al.(2022) Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D. Goodman. 2022년 스타: 추론과 함께 부트스트랩 추론. NeurIPS에서.\n' +
      '* Zellers et al.(2019) Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. From recognition to cognition: Visual commonsense reasoning. In _IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019_, pages 6720-6731. Computer Vision Foundation/IEEE.\n' +
      '* Zhang 등(2023a) Bowen Zhang, Kehua Chang, and Chunping Li. 2023a. Cot-bert: 생각의 사슬을 통해 감독되지 않은 문장 표현을 향상시킵니다. _ CoRR_, abs/2309.11143.\n' +
      '* Zhang and Parkes (2023) Hugh Zhang and David C. Parkes. 2023. 연쇄 사고 추론은 정책 개선 운영자이다.\n' +
      '* Zhang et al. (2023b) Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, and Sharad Mehrotra. 2023b. 초안 및 확인: 자기 추측 디코딩을 통한 무손실 대형 언어 모델 가속. _ arXiv preprint arXiv:2309.08168_.\n' +
      '* Zhang 등(2023c) Li Zhang, Liam Dugan, Hainiu Xu, and Chris Callison-Burch. 2023c. 코드 프롬프트의 호기심 있는 경우를 탐색합니다. _ CoRR_, abs/2304.13250.\n' +
      '* Zhang 등(2023d) Muru Zhang, Ofir Press, William Merrill, Alisa Liu, and Noah A. Smith. 2023d. 언어 모델 환각이 눈덩이처럼 불어날 수 있는 방법. _ CoRR_, abs/2305.13534.\n' +
      '* Zhang et al.(2022) Sarah J. Zhang, Reece Shuttleworth, Derek Austin, Yann Hicke, Leonard Tang, Sathwik Karnik, Darnell Granberry, and Iddo Drori. 2022. 자동 응답 및 기계 학습 기말고사 생성을 위한 데이터 세트 및 벤치마크. _ CoRR_, abs/2206.05442.\n' +
      '*Zhang et al.(2023e) Tianhua Zhang, Jiaxin Ge, Hongyin Luo, Yung-Sung Chuang, Mingye Gao, Yuan Gong, Xixin Wu, Yoon Kim, Helen Meng, and James Glass. 2023e. 하이브리드 언어 기호 추론을 위한 자연어 내장 프로그램_ arXiv preprint arXiv:2309.10814_.\n' +
      '* Zhang and Zhang (2023) Zhuosheng Zhang and Aston Zhang. 2023. 화면만 볼 수 있습니다. 멀티모달 연쇄 작용제입니다.\n' +
      '* Zhang et al.(2023) Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2023f. 대형 언어 모델에서 자동 사고 연쇄 프롬프트 <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '* Zhang et al.(2023g) Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. 2023g. 언어 모델에서 다중 모드 사고 연쇄 추론 _ CoRR_, abs/2302.00923.\n' +
      '* Zhao et al.(2023a) Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, and Lidong Bing. 2023a. 검증 및 편집: 지식 강화 사고 사슬 프레임워크. [제61회 컴퓨터 언어학 협회 연례 회의(제1권: Long Papers), ACL 2023, 캐나다 토론토, 7월 9-14일, 2023_, 페이지 5823-5840]에서 컴퓨터 언어학 협회.\n' +
      '* 18, 2022_, pages 4571-4581. ACM.\n' +
      '* Zhao et al.(2023b) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023b. 대형 언어 모델에 대한 조사입니다. _ CoRR_, abs/2303.18223.\n' +
      '\n' +
      '쉬펑 자오, 멍디 리, 원하오 루, 코닐리어스 베버, 이재희, 쿤추, 스테판 웜터. 2023c. 논리를 통해 대규모 언어 모델에서 제로샷 사고 연쇄 추론을 향상시킵니다. _ CoRR_, abs/2309.13339.\n' +
      '* [Zheng et al.2023] Huaixiu Steven Zheng, Swaroop Mishra, Shinun Chen, Heng-Tze Cheng, Ed H Chi, Quoc V Le, and Denny Zhou. 2023. 한 걸음 물러서십시오: 대규모 언어 모델에서 추상화를 통해 추론을 불러일으킵니다. _ arXiv preprint arXiv:2310.06117_.\n' +
      '* [Zhou et al.2023a] Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang. 2023a. 언어 에이전트 트리 검색은 언어 모델에서 추론 행위와 계획을 통합합니다.\n' +
      '* [Zhou et al.2019] Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth. 2019. "여행"은 "산책"보다 시간이 더 오래 걸립니다. 시간적 상식적 이해에 대한 연구입니다. <Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019_, pages 3361-3367. Computational Linguistics.\n' +
      '* [Zhou et al.2023b] Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V. 레, 에드 치 2023b. 최소한의 프롬프트는 대규모 언어 모델에서 복잡한 추론을 가능하게 한다. <제11차 국제학술대회>에서, ICLR 2023, 키갈리, 르완다, 5월 1-5일, 2023. OpenReview.net.\n' +
      '* [Zhou et al.2023c] Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, and Lei Ma. 2023c. Isr-llm: 긴 수평 순차 작업 계획을 위한 반복적인 자체 정제된 대형 언어 모델.\n' +
      '* [Zhu et al.2021] Fengbin Zhu, Wenqiang Lei, Ycheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. 2021. TAT-QA: 금융에서 표와 텍스트 콘텐츠의 하이브리드에 대한 질의 응답 벤치마크. 제59차 전산언어학회 연차총회 및 제11차 자연어처리 국제공동회의, ACL/IJCNLP 2021, (제1권: 장문), 가상사건, 2021년 8월 1-6일_, 3277-3287페이지에서. 전산언어학회.\n' +
      '* [Zou et al.2023] Anni Zou, Zhuosheng Zhang, Hai Zhao, and Xiangru Tang. 2023. 메타-코트: 대규모 언어 모델을 사용 하는 혼합 작업 시나리오에서 일반화 가능한 사고 연쇄 프롬프트입니다. _ arXiv preprint arXiv:2310.06692_.\n' +
      '* [Zhou et al.2023c]\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>