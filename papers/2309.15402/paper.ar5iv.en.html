<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2309.15402] A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future</title><meta property="og:description" content="Chain-of-thought reasoning, a cognitive process fundamental to human intelligence, has garnered significant attention in the realm of artificial intelligence and natural language processing.
However, there still remain…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2309.15402">

<!--Generated on Wed Feb 28 04:09:45 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Zheng Chu<sup id="15.15.6" class="ltx_sup"><span id="15.15.6.1" class="ltx_text ltx_font_italic">1</span></sup><span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>,
Jingchang Chen<sup id="16.16.7" class="ltx_sup"><span id="16.16.7.1" class="ltx_text ltx_font_italic">1</span></sup><span id="footnotex2" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>,
Qianglong Chen<sup id="17.17.8" class="ltx_sup"><span id="17.17.8.1" class="ltx_text ltx_font_italic">2</span></sup>,
Weijiang Yu<sup id="18.18.9" class="ltx_sup"><span id="18.18.9.1" class="ltx_text ltx_font_italic">2</span></sup>,
Tao He<sup id="19.19.10" class="ltx_sup"><span id="19.19.10.1" class="ltx_text ltx_font_italic">1</span></sup>
<br class="ltx_break"><span id="id11.11.5" class="ltx_text ltx_font_bold">
Haotian Wang<sup id="id11.11.5.1" class="ltx_sup"><span id="id11.11.5.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Weihua Peng<sup id="id11.11.5.2" class="ltx_sup"><span id="id11.11.5.2.1" class="ltx_text ltx_font_medium ltx_font_italic">2</span></sup>, Ming Liu<sup id="id11.11.5.3" class="ltx_sup"><span id="id11.11.5.3.1" class="ltx_text ltx_font_medium ltx_font_italic">1†</span></sup>, Bing Qin<sup id="id11.11.5.4" class="ltx_sup"><span id="id11.11.5.4.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Ting Liu<sup id="id11.11.5.5" class="ltx_sup"><span id="id11.11.5.5.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>
</span> 
<br class="ltx_break"><sup id="20.20.11" class="ltx_sup"><span id="20.20.11.1" class="ltx_text ltx_font_italic">1</span></sup>Harbin Institute of Technology, Harbin, China 
<br class="ltx_break"><sup id="21.21.12" class="ltx_sup"><span id="21.21.12.1" class="ltx_text ltx_font_italic">2</span></sup>Huawei Inc., Shenzhen, China 
<br class="ltx_break"><span id="22.22.13" class="ltx_text ltx_font_typewriter">{zchu, jcchen, the, mliu , qinb, tliu}@ir.hit.edu.cn </span> 
<br class="ltx_break"><span id="23.23.14" class="ltx_text ltx_font_typewriter">{chenqianglong.ai, wanght1998, weijiangyu8, pengwh.hit}@gmail.com</span>
</span><span class="ltx_author_notes">&nbsp;&nbsp;&nbsp; Equal Contribution.<span id="24.24.1" class="ltx_text ltx_font_typewriter">&nbsp;&nbsp;&nbsp;</span><span id="25.25.2" class="ltx_text ltx_font_typewriter"> Corresponding Author.</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="26.1" class="ltx_p">Chain-of-thought reasoning, a cognitive process fundamental to human intelligence, has garnered significant attention in the realm of artificial intelligence and natural language processing.
However, there still remains a lack of a comprehensive survey for this arena.
To this end, we take the first step and present a thorough survey of this research field carefully and widely.
We use X-of-Thought to refer to Chain-of-Thought in a broad sense.
In detail, we systematically organize the current research according to the taxonomies of methods, including XoT construction, XoT structure variants, and enhanced XoT.
Additionally, we describe XoT with frontier applications, covering planning, tool use, and distillation.
Furthermore, we address challenges and discuss some future directions, including faithfulness, multi-modal, and theory.
We hope this survey serves as a valuable resource for researchers seeking to innovate within the domain of chain-of-thought reasoning<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Resources are available at <a target="_blank" href="https://github.com/zchuz/CoT-Reasoning-Survey" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/zchuz/CoT-Reasoning-Survey</a></span></span></span>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span id="S1.p1.1.1" class="ltx_text" style="color:#000000;">Pre-trained language models (PLMs) can automatically learn general representations from unlabeled text and achieve excellent performance through fine-tuning on downstream tasks.&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Devlin et&nbsp;al., <a href="#bib.bib21" title="" class="ltx_ref">2019</a>; Raffel et&nbsp;al., <a href="#bib.bib121" title="" class="ltx_ref">2020</a>; Radford and Narasimhan, <a href="#bib.bib119" title="" class="ltx_ref">2018</a>)</cite>.
Recently, scaling up language models significantly improves performance and brings many surprises, such as emergent abilities&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a href="#bib.bib160" title="" class="ltx_ref">2022a</a>; Schaeffer et&nbsp;al., <a href="#bib.bib127" title="" class="ltx_ref">2023</a>)</cite>.
Therefore, the paradigm of natural language processing is shifting from pre-training with fine-tuning to pre-training with in-context learning.
However, as of now, large-scale language models (LLMs) still have considerable room for improvement on complex reasoning tasks, such as mathematical reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Cobbe et&nbsp;al., <a href="#bib.bib17" title="" class="ltx_ref">2021</a>; Patel et&nbsp;al., <a href="#bib.bib114" title="" class="ltx_ref">2021</a>)</cite>, commonsense reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Talmor et&nbsp;al., <a href="#bib.bib141" title="" class="ltx_ref">2021</a>; Mihaylov et&nbsp;al., <a href="#bib.bib102" title="" class="ltx_ref">2018</a>)</cite>, etc.</span></p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To leverage LLMs for addressing complex reasoning tasks, <cite class="ltx_cite ltx_citemacro_citet">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite> extends in-context learning with step-by-step reasoning processes, first introducing the concept of chain-of-thought (CoT) prompting.
<cite class="ltx_cite ltx_citemacro_citet">Kojima et&nbsp;al. (<a href="#bib.bib64" title="" class="ltx_ref">2022</a>)</cite> finds that simply adding a magic phrase <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">Let’s think step by step</span> in prompts enables LLMs to perform zero-shot chain-of-thought reasoning without any human annotation.
These studies have highlighted the significance of chain-of-thought in enhancing the model’s capability for complex reasoning and improving its reasoning and planning abilities.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Subsequently, a substantial of works about X-of-thought (XoT) emerges like mushrooms after the rain in the NLP community, such as automatic XoT construction&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kojima et&nbsp;al., <a href="#bib.bib64" title="" class="ltx_ref">2022</a>; Zhang et&nbsp;al., <a href="#bib.bib196" title="" class="ltx_ref">2023f</a>; Xu et&nbsp;al., <a href="#bib.bib167" title="" class="ltx_ref">2023</a>)</cite>, XoT structural variants&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2022a</a>; Ning et&nbsp;al., <a href="#bib.bib107" title="" class="ltx_ref">2023</a>; Lei et&nbsp;al., <a href="#bib.bib71" title="" class="ltx_ref">2023a</a>; Yao et&nbsp;al., <a href="#bib.bib172" title="" class="ltx_ref">2023b</a>)</cite>, etc.
Note that to distinguish it from primitive CoT, we use XoT to refer to CoT in a broad sense, which is a collective term for the use of step-by-step reasoning methods.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">However, these methods and datasets have not yet undergone systematic review and analysis. To fill this gap, we propose this work to conduct a comprehensive and detailed analysis of the XoT family.
Even though there have been some surveys discussing chain-of-thought, they are limited to specific aspects, such as LLM reasoning with prompts&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Qiao et&nbsp;al., <a href="#bib.bib118" title="" class="ltx_ref">2023</a>)</cite> and chain-of-thought prompt strategies&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al., <a href="#bib.bib185" title="" class="ltx_ref">2023c</a>)</cite>.
In contrast, our survey not only provides a more thorough and comprehensive discussion of the topics they’ve already covered, but also includes additional topics and discussions, such as XoT construction, XoT structural variants and frontier application, etc.
Concretely, in this paper, we first introduce the relevant background and preliminary&nbsp;(§<a href="#S2" title="2 Background and Preliminary ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
Furthermore, we carefully classify the XoT series of work from multiple perspectives and complete an in-depth analysis&nbsp;(§<a href="#S4" title="4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>), including XoT construction methods&nbsp;(§<a href="#S4.SS1" title="4.1 Construction Approach ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>),
XoT structure variants&nbsp;(§<a href="#S4.SS2" title="4.2 XoT Structural Variants ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>)
and XoT enhancement methods&nbsp;(§<a href="#S4.SS3" title="4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).
Then, we provide practical applications of the XoT in the frontier fields&nbsp;(§<a href="#S5" title="5 Frontier Application ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).
In order to inspire the follow-up work of XoT, we offer insights into potential avenues for future research in this area&nbsp;(§<a href="#S6" title="6 Future Directions ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>).
Finally, we compare and discuss existing methods&nbsp;(§<a href="#S7" title="7 Discussion ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>).</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Preliminary</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Background </h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In recent years, with the continuous expansion of computing power, large-scale language models have sprung up &nbsp;<cite class="ltx_cite ltx_citemacro_cite">Brown et&nbsp;al. (<a href="#bib.bib9" title="" class="ltx_ref">2020</a>); OpenAI (<a href="#bib.bib109" title="" class="ltx_ref">2023</a>); Touvron et&nbsp;al. (<a href="#bib.bib143" title="" class="ltx_ref">2023a</a>); Scao et&nbsp;al. (<a href="#bib.bib126" title="" class="ltx_ref">2022</a>); Touvron et&nbsp;al. (<a href="#bib.bib144" title="" class="ltx_ref">2023b</a>); Zhao et&nbsp;al. (<a href="#bib.bib200" title="" class="ltx_ref">2023b</a>)</cite>, and as the model size continues to grow, many new capabilities have emerged, such as in-context learning and chain-of-thought reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Brown et&nbsp;al. (<a href="#bib.bib9" title="" class="ltx_ref">2020</a>); Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>, <a href="#bib.bib160" title="" class="ltx_ref">a</a>); Schaeffer et&nbsp;al. (<a href="#bib.bib127" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Brown et&nbsp;al. (<a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite> finds that large-scale language models have excellent in-context learning (ICL) ability.
ICL incorporates input-output demonstrations into the prompt text.
With ICL, off-the-shelf LLMs can be employed without additional fine-tuning
while achieving comparable performance.
Nevertheless, this end-to-end approach tends to underperform when faced with complex reasoning tasks.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite> finds that the reasoning ability of LLMs can be improved by adding step-by-step reasoning processes to the demonstration, which is known as chain-of-thought prompting.
CoT prompting enables the model to gain a more precise understanding of both the question’s intricacies and the reasoning process.
Furthermore, the model generates a sequence of reasoning steps, which grants us a transparent view of the model’s cognitive process, further enhancing interpretability.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Preliminary </h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.6" class="ltx_p">In this section, we introduce the preliminary chain-of-thought reasoning with LLMs, and we refer to the formula definition in <cite class="ltx_cite ltx_citemacro_citep">(Qiao et&nbsp;al., <a href="#bib.bib118" title="" class="ltx_ref">2023</a>)</cite>.
Suppose there is a question <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">\mathcal{Q}</annotation></semantics></math>, a prompt <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">𝒯</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">𝒯</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">\mathcal{T}</annotation></semantics></math> and a probabilistic language model <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="P_{LM}" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><msub id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">P</mi><mrow id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml"><mi id="S2.SS2.p1.3.m3.1.1.3.2" xref="S2.SS2.p1.3.m3.1.1.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.3.m3.1.1.3.1" xref="S2.SS2.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S2.SS2.p1.3.m3.1.1.3.3" xref="S2.SS2.p1.3.m3.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">𝑃</ci><apply id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3"><times id="S2.SS2.p1.3.m3.1.1.3.1.cmml" xref="S2.SS2.p1.3.m3.1.1.3.1"></times><ci id="S2.SS2.p1.3.m3.1.1.3.2.cmml" xref="S2.SS2.p1.3.m3.1.1.3.2">𝐿</ci><ci id="S2.SS2.p1.3.m3.1.1.3.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">P_{LM}</annotation></semantics></math>. The model takes the question and prompt as inputs to give the rationale <math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><ci id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">\mathcal{R}</annotation></semantics></math> and answer <math id="S2.SS2.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S2.SS2.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><ci id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">\mathcal{A}</annotation></semantics></math>.
We first consider in-context scenarios where the demonstrations do not contain reasoning chains. We need to maximize the likelihood of Answer <math id="S2.SS2.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S2.SS2.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.6.m6.1.1" xref="S2.SS2.p1.6.m6.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m6.1b"><ci id="S2.SS2.p1.6.m6.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m6.1c">\mathcal{A}</annotation></semantics></math>, as shown in Equ&nbsp;(<a href="#S2.E1" title="In 2.2 Preliminary ‣ 2 Background and Preliminary ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,<a href="#S2.E2" title="In 2.2 Preliminary ‣ 2 Background and Preliminary ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
<table id="S8.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E1.m2.7" class="ltx_Math" alttext="\displaystyle p(\mathcal{A}~{}|~{}\mathcal{T,Q})=\prod_{i=1}^{|\mathcal{A}|}p_{LM}(a_{i}~{}|~{}\mathcal{T,Q},a_{<i})" display="inline"><semantics id="S2.E1.m2.7a"><mrow id="S2.E1.m2.7.7" xref="S2.E1.m2.7.7.cmml"><mrow id="S2.E1.m2.6.6.1" xref="S2.E1.m2.6.6.1.cmml"><mi id="S2.E1.m2.6.6.1.3" xref="S2.E1.m2.6.6.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E1.m2.6.6.1.2" xref="S2.E1.m2.6.6.1.2.cmml">​</mo><mrow id="S2.E1.m2.6.6.1.1.1" xref="S2.E1.m2.6.6.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m2.6.6.1.1.1.2" xref="S2.E1.m2.6.6.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m2.6.6.1.1.1.1" xref="S2.E1.m2.6.6.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m2.6.6.1.1.1.1.2" xref="S2.E1.m2.6.6.1.1.1.1.2.cmml">𝒜</mi><mo fence="false" lspace="0.608em" rspace="0.608em" id="S2.E1.m2.6.6.1.1.1.1.1" xref="S2.E1.m2.6.6.1.1.1.1.1.cmml">|</mo><mrow id="S2.E1.m2.6.6.1.1.1.1.3.2" xref="S2.E1.m2.6.6.1.1.1.1.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m2.2.2" xref="S2.E1.m2.2.2.cmml">𝒯</mi><mo id="S2.E1.m2.6.6.1.1.1.1.3.2.1" xref="S2.E1.m2.6.6.1.1.1.1.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m2.3.3" xref="S2.E1.m2.3.3.cmml">𝒬</mi></mrow></mrow><mo stretchy="false" id="S2.E1.m2.6.6.1.1.1.3" xref="S2.E1.m2.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m2.7.7.3" xref="S2.E1.m2.7.7.3.cmml">=</mo><mrow id="S2.E1.m2.7.7.2" xref="S2.E1.m2.7.7.2.cmml"><mstyle displaystyle="true" id="S2.E1.m2.7.7.2.2" xref="S2.E1.m2.7.7.2.2.cmml"><munderover id="S2.E1.m2.7.7.2.2a" xref="S2.E1.m2.7.7.2.2.cmml"><mo movablelimits="false" id="S2.E1.m2.7.7.2.2.2.2" xref="S2.E1.m2.7.7.2.2.2.2.cmml">∏</mo><mrow id="S2.E1.m2.7.7.2.2.2.3" xref="S2.E1.m2.7.7.2.2.2.3.cmml"><mi id="S2.E1.m2.7.7.2.2.2.3.2" xref="S2.E1.m2.7.7.2.2.2.3.2.cmml">i</mi><mo id="S2.E1.m2.7.7.2.2.2.3.1" xref="S2.E1.m2.7.7.2.2.2.3.1.cmml">=</mo><mn id="S2.E1.m2.7.7.2.2.2.3.3" xref="S2.E1.m2.7.7.2.2.2.3.3.cmml">1</mn></mrow><mrow id="S2.E1.m2.1.1.1.3" xref="S2.E1.m2.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m2.1.1.1.3.1" xref="S2.E1.m2.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m2.1.1.1.1" xref="S2.E1.m2.1.1.1.1.cmml">𝒜</mi><mo stretchy="false" id="S2.E1.m2.1.1.1.3.2" xref="S2.E1.m2.1.1.1.2.1.cmml">|</mo></mrow></munderover></mstyle><mrow id="S2.E1.m2.7.7.2.1" xref="S2.E1.m2.7.7.2.1.cmml"><msub id="S2.E1.m2.7.7.2.1.3" xref="S2.E1.m2.7.7.2.1.3.cmml"><mi id="S2.E1.m2.7.7.2.1.3.2" xref="S2.E1.m2.7.7.2.1.3.2.cmml">p</mi><mrow id="S2.E1.m2.7.7.2.1.3.3" xref="S2.E1.m2.7.7.2.1.3.3.cmml"><mi id="S2.E1.m2.7.7.2.1.3.3.2" xref="S2.E1.m2.7.7.2.1.3.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E1.m2.7.7.2.1.3.3.1" xref="S2.E1.m2.7.7.2.1.3.3.1.cmml">​</mo><mi id="S2.E1.m2.7.7.2.1.3.3.3" xref="S2.E1.m2.7.7.2.1.3.3.3.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E1.m2.7.7.2.1.2" xref="S2.E1.m2.7.7.2.1.2.cmml">​</mo><mrow id="S2.E1.m2.7.7.2.1.1.1" xref="S2.E1.m2.7.7.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m2.7.7.2.1.1.1.2" xref="S2.E1.m2.7.7.2.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m2.7.7.2.1.1.1.1" xref="S2.E1.m2.7.7.2.1.1.1.1.cmml"><msub id="S2.E1.m2.7.7.2.1.1.1.1.3" xref="S2.E1.m2.7.7.2.1.1.1.1.3.cmml"><mi id="S2.E1.m2.7.7.2.1.1.1.1.3.2" xref="S2.E1.m2.7.7.2.1.1.1.1.3.2.cmml">a</mi><mi id="S2.E1.m2.7.7.2.1.1.1.1.3.3" xref="S2.E1.m2.7.7.2.1.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" rspace="0.608em" id="S2.E1.m2.7.7.2.1.1.1.1.2" xref="S2.E1.m2.7.7.2.1.1.1.1.2.cmml">|</mo><mrow id="S2.E1.m2.7.7.2.1.1.1.1.1.1" xref="S2.E1.m2.7.7.2.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m2.4.4" xref="S2.E1.m2.4.4.cmml">𝒯</mi><mo id="S2.E1.m2.7.7.2.1.1.1.1.1.1.2" xref="S2.E1.m2.7.7.2.1.1.1.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m2.5.5" xref="S2.E1.m2.5.5.cmml">𝒬</mi><mo id="S2.E1.m2.7.7.2.1.1.1.1.1.1.3" xref="S2.E1.m2.7.7.2.1.1.1.1.1.2.cmml">,</mo><msub id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.2" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.2.cmml">a</mi><mrow id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.2" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.1" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.3" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.3.cmml">i</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S2.E1.m2.7.7.2.1.1.1.3" xref="S2.E1.m2.7.7.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m2.7b"><apply id="S2.E1.m2.7.7.cmml" xref="S2.E1.m2.7.7"><eq id="S2.E1.m2.7.7.3.cmml" xref="S2.E1.m2.7.7.3"></eq><apply id="S2.E1.m2.6.6.1.cmml" xref="S2.E1.m2.6.6.1"><times id="S2.E1.m2.6.6.1.2.cmml" xref="S2.E1.m2.6.6.1.2"></times><ci id="S2.E1.m2.6.6.1.3.cmml" xref="S2.E1.m2.6.6.1.3">𝑝</ci><apply id="S2.E1.m2.6.6.1.1.1.1.cmml" xref="S2.E1.m2.6.6.1.1.1"><csymbol cd="latexml" id="S2.E1.m2.6.6.1.1.1.1.1.cmml" xref="S2.E1.m2.6.6.1.1.1.1.1">conditional</csymbol><ci id="S2.E1.m2.6.6.1.1.1.1.2.cmml" xref="S2.E1.m2.6.6.1.1.1.1.2">𝒜</ci><list id="S2.E1.m2.6.6.1.1.1.1.3.1.cmml" xref="S2.E1.m2.6.6.1.1.1.1.3.2"><ci id="S2.E1.m2.2.2.cmml" xref="S2.E1.m2.2.2">𝒯</ci><ci id="S2.E1.m2.3.3.cmml" xref="S2.E1.m2.3.3">𝒬</ci></list></apply></apply><apply id="S2.E1.m2.7.7.2.cmml" xref="S2.E1.m2.7.7.2"><apply id="S2.E1.m2.7.7.2.2.cmml" xref="S2.E1.m2.7.7.2.2"><csymbol cd="ambiguous" id="S2.E1.m2.7.7.2.2.1.cmml" xref="S2.E1.m2.7.7.2.2">superscript</csymbol><apply id="S2.E1.m2.7.7.2.2.2.cmml" xref="S2.E1.m2.7.7.2.2"><csymbol cd="ambiguous" id="S2.E1.m2.7.7.2.2.2.1.cmml" xref="S2.E1.m2.7.7.2.2">subscript</csymbol><csymbol cd="latexml" id="S2.E1.m2.7.7.2.2.2.2.cmml" xref="S2.E1.m2.7.7.2.2.2.2">product</csymbol><apply id="S2.E1.m2.7.7.2.2.2.3.cmml" xref="S2.E1.m2.7.7.2.2.2.3"><eq id="S2.E1.m2.7.7.2.2.2.3.1.cmml" xref="S2.E1.m2.7.7.2.2.2.3.1"></eq><ci id="S2.E1.m2.7.7.2.2.2.3.2.cmml" xref="S2.E1.m2.7.7.2.2.2.3.2">𝑖</ci><cn type="integer" id="S2.E1.m2.7.7.2.2.2.3.3.cmml" xref="S2.E1.m2.7.7.2.2.2.3.3">1</cn></apply></apply><apply id="S2.E1.m2.1.1.1.2.cmml" xref="S2.E1.m2.1.1.1.3"><abs id="S2.E1.m2.1.1.1.2.1.cmml" xref="S2.E1.m2.1.1.1.3.1"></abs><ci id="S2.E1.m2.1.1.1.1.cmml" xref="S2.E1.m2.1.1.1.1">𝒜</ci></apply></apply><apply id="S2.E1.m2.7.7.2.1.cmml" xref="S2.E1.m2.7.7.2.1"><times id="S2.E1.m2.7.7.2.1.2.cmml" xref="S2.E1.m2.7.7.2.1.2"></times><apply id="S2.E1.m2.7.7.2.1.3.cmml" xref="S2.E1.m2.7.7.2.1.3"><csymbol cd="ambiguous" id="S2.E1.m2.7.7.2.1.3.1.cmml" xref="S2.E1.m2.7.7.2.1.3">subscript</csymbol><ci id="S2.E1.m2.7.7.2.1.3.2.cmml" xref="S2.E1.m2.7.7.2.1.3.2">𝑝</ci><apply id="S2.E1.m2.7.7.2.1.3.3.cmml" xref="S2.E1.m2.7.7.2.1.3.3"><times id="S2.E1.m2.7.7.2.1.3.3.1.cmml" xref="S2.E1.m2.7.7.2.1.3.3.1"></times><ci id="S2.E1.m2.7.7.2.1.3.3.2.cmml" xref="S2.E1.m2.7.7.2.1.3.3.2">𝐿</ci><ci id="S2.E1.m2.7.7.2.1.3.3.3.cmml" xref="S2.E1.m2.7.7.2.1.3.3.3">𝑀</ci></apply></apply><apply id="S2.E1.m2.7.7.2.1.1.1.1.cmml" xref="S2.E1.m2.7.7.2.1.1.1"><csymbol cd="latexml" id="S2.E1.m2.7.7.2.1.1.1.1.2.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.2">conditional</csymbol><apply id="S2.E1.m2.7.7.2.1.1.1.1.3.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m2.7.7.2.1.1.1.1.3.1.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m2.7.7.2.1.1.1.1.3.2.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.3.2">𝑎</ci><ci id="S2.E1.m2.7.7.2.1.1.1.1.3.3.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.3.3">𝑖</ci></apply><list id="S2.E1.m2.7.7.2.1.1.1.1.1.2.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1"><ci id="S2.E1.m2.4.4.cmml" xref="S2.E1.m2.4.4">𝒯</ci><ci id="S2.E1.m2.5.5.cmml" xref="S2.E1.m2.5.5">𝒬</ci><apply id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.2">𝑎</ci><apply id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3"><lt id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m2.7.7.2.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m2.7c">\displaystyle p(\mathcal{A}~{}|~{}\mathcal{T,Q})=\prod_{i=1}^{|\mathcal{A}|}p_{LM}(a_{i}~{}|~{}\mathcal{T,Q},a_{&lt;i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E2.m1.4" class="ltx_Math" alttext="\displaystyle\mathcal{T}_{ICL}=\{I,(x_{1},y_{1}),\cdots,(x_{n},y_{n})\}" display="inline"><semantics id="S2.E2.m1.4a"><mrow id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml"><msub id="S2.E2.m1.4.4.4" xref="S2.E2.m1.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.4.2" xref="S2.E2.m1.4.4.4.2.cmml">𝒯</mi><mrow id="S2.E2.m1.4.4.4.3" xref="S2.E2.m1.4.4.4.3.cmml"><mi id="S2.E2.m1.4.4.4.3.2" xref="S2.E2.m1.4.4.4.3.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.4.4.4.3.1" xref="S2.E2.m1.4.4.4.3.1.cmml">​</mo><mi id="S2.E2.m1.4.4.4.3.3" xref="S2.E2.m1.4.4.4.3.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.4.4.4.3.1a" xref="S2.E2.m1.4.4.4.3.1.cmml">​</mo><mi id="S2.E2.m1.4.4.4.3.4" xref="S2.E2.m1.4.4.4.3.4.cmml">L</mi></mrow></msub><mo id="S2.E2.m1.4.4.3" xref="S2.E2.m1.4.4.3.cmml">=</mo><mrow id="S2.E2.m1.4.4.2.2" xref="S2.E2.m1.4.4.2.3.cmml"><mo stretchy="false" id="S2.E2.m1.4.4.2.2.3" xref="S2.E2.m1.4.4.2.3.cmml">{</mo><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">I</mi><mo id="S2.E2.m1.4.4.2.2.4" xref="S2.E2.m1.4.4.2.3.cmml">,</mo><mrow id="S2.E2.m1.3.3.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.3.cmml"><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.2.3" xref="S2.E2.m1.3.3.1.1.1.3.cmml">(</mo><msub id="S2.E2.m1.3.3.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.2.cmml">x</mi><mn id="S2.E2.m1.3.3.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E2.m1.3.3.1.1.1.2.4" xref="S2.E2.m1.3.3.1.1.1.3.cmml">,</mo><msub id="S2.E2.m1.3.3.1.1.1.2.2" xref="S2.E2.m1.3.3.1.1.1.2.2.cmml"><mi id="S2.E2.m1.3.3.1.1.1.2.2.2" xref="S2.E2.m1.3.3.1.1.1.2.2.2.cmml">y</mi><mn id="S2.E2.m1.3.3.1.1.1.2.2.3" xref="S2.E2.m1.3.3.1.1.1.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.2.5" xref="S2.E2.m1.3.3.1.1.1.3.cmml">)</mo></mrow><mo id="S2.E2.m1.4.4.2.2.5" xref="S2.E2.m1.4.4.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">⋯</mi><mo id="S2.E2.m1.4.4.2.2.6" xref="S2.E2.m1.4.4.2.3.cmml">,</mo><mrow id="S2.E2.m1.4.4.2.2.2.2" xref="S2.E2.m1.4.4.2.2.2.3.cmml"><mo stretchy="false" id="S2.E2.m1.4.4.2.2.2.2.3" xref="S2.E2.m1.4.4.2.2.2.3.cmml">(</mo><msub id="S2.E2.m1.4.4.2.2.2.1.1" xref="S2.E2.m1.4.4.2.2.2.1.1.cmml"><mi id="S2.E2.m1.4.4.2.2.2.1.1.2" xref="S2.E2.m1.4.4.2.2.2.1.1.2.cmml">x</mi><mi id="S2.E2.m1.4.4.2.2.2.1.1.3" xref="S2.E2.m1.4.4.2.2.2.1.1.3.cmml">n</mi></msub><mo id="S2.E2.m1.4.4.2.2.2.2.4" xref="S2.E2.m1.4.4.2.2.2.3.cmml">,</mo><msub id="S2.E2.m1.4.4.2.2.2.2.2" xref="S2.E2.m1.4.4.2.2.2.2.2.cmml"><mi id="S2.E2.m1.4.4.2.2.2.2.2.2" xref="S2.E2.m1.4.4.2.2.2.2.2.2.cmml">y</mi><mi id="S2.E2.m1.4.4.2.2.2.2.2.3" xref="S2.E2.m1.4.4.2.2.2.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S2.E2.m1.4.4.2.2.2.2.5" xref="S2.E2.m1.4.4.2.2.2.3.cmml">)</mo></mrow><mo stretchy="false" id="S2.E2.m1.4.4.2.2.7" xref="S2.E2.m1.4.4.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.4b"><apply id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4"><eq id="S2.E2.m1.4.4.3.cmml" xref="S2.E2.m1.4.4.3"></eq><apply id="S2.E2.m1.4.4.4.cmml" xref="S2.E2.m1.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.4.1.cmml" xref="S2.E2.m1.4.4.4">subscript</csymbol><ci id="S2.E2.m1.4.4.4.2.cmml" xref="S2.E2.m1.4.4.4.2">𝒯</ci><apply id="S2.E2.m1.4.4.4.3.cmml" xref="S2.E2.m1.4.4.4.3"><times id="S2.E2.m1.4.4.4.3.1.cmml" xref="S2.E2.m1.4.4.4.3.1"></times><ci id="S2.E2.m1.4.4.4.3.2.cmml" xref="S2.E2.m1.4.4.4.3.2">𝐼</ci><ci id="S2.E2.m1.4.4.4.3.3.cmml" xref="S2.E2.m1.4.4.4.3.3">𝐶</ci><ci id="S2.E2.m1.4.4.4.3.4.cmml" xref="S2.E2.m1.4.4.4.3.4">𝐿</ci></apply></apply><set id="S2.E2.m1.4.4.2.3.cmml" xref="S2.E2.m1.4.4.2.2"><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">𝐼</ci><interval closure="open" id="S2.E2.m1.3.3.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.2"><apply id="S2.E2.m1.3.3.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S2.E2.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3">1</cn></apply><apply id="S2.E2.m1.3.3.1.1.1.2.2.cmml" xref="S2.E2.m1.3.3.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.2.2.1.cmml" xref="S2.E2.m1.3.3.1.1.1.2.2">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.1.2.2.2">𝑦</ci><cn type="integer" id="S2.E2.m1.3.3.1.1.1.2.2.3.cmml" xref="S2.E2.m1.3.3.1.1.1.2.2.3">1</cn></apply></interval><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">⋯</ci><interval closure="open" id="S2.E2.m1.4.4.2.2.2.3.cmml" xref="S2.E2.m1.4.4.2.2.2.2"><apply id="S2.E2.m1.4.4.2.2.2.1.1.cmml" xref="S2.E2.m1.4.4.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.2.2.2.1.1.1.cmml" xref="S2.E2.m1.4.4.2.2.2.1.1">subscript</csymbol><ci id="S2.E2.m1.4.4.2.2.2.1.1.2.cmml" xref="S2.E2.m1.4.4.2.2.2.1.1.2">𝑥</ci><ci id="S2.E2.m1.4.4.2.2.2.1.1.3.cmml" xref="S2.E2.m1.4.4.2.2.2.1.1.3">𝑛</ci></apply><apply id="S2.E2.m1.4.4.2.2.2.2.2.cmml" xref="S2.E2.m1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.2.2.2.2.2.1.cmml" xref="S2.E2.m1.4.4.2.2.2.2.2">subscript</csymbol><ci id="S2.E2.m1.4.4.2.2.2.2.2.2.cmml" xref="S2.E2.m1.4.4.2.2.2.2.2.2">𝑦</ci><ci id="S2.E2.m1.4.4.2.2.2.2.2.3.cmml" xref="S2.E2.m1.4.4.2.2.2.2.2.3">𝑛</ci></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.4c">\displaystyle\mathcal{T}_{ICL}=\{I,(x_{1},y_{1}),\cdots,(x_{n},y_{n})\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.2" class="ltx_p">In the chain-of-thought reasoning scenario, where the demonstrations contain reasoning process, we need to maximize the likelihood of Answer <math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">\mathcal{A}</annotation></semantics></math> and rationale <math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><ci id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">\mathcal{R}</annotation></semantics></math>, as shown in Equ&nbsp;(<a href="#S2.E3" title="In 2.2 Preliminary ‣ 2 Background and Preliminary ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>,<a href="#S2.E4" title="In 2.2 Preliminary ‣ 2 Background and Preliminary ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>,<a href="#S2.E5" title="In 2.2 Preliminary ‣ 2 Background and Preliminary ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>,<a href="#S2.E6" title="In 2.2 Preliminary ‣ 2 Background and Preliminary ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>).</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<table id="S8.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E3.m2.10" class="ltx_Math" alttext="\displaystyle p(\mathcal{A}~{}|~{}\mathcal{T,Q})=p(\mathcal{A}~{}|~{}\mathcal{T,Q,R})p(\mathcal{R}~{}|~{}\mathcal{T,Q})" display="inline"><semantics id="S2.E3.m2.10a"><mrow id="S2.E3.m2.10.10" xref="S2.E3.m2.10.10.cmml"><mrow id="S2.E3.m2.8.8.1" xref="S2.E3.m2.8.8.1.cmml"><mi id="S2.E3.m2.8.8.1.3" xref="S2.E3.m2.8.8.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m2.8.8.1.2" xref="S2.E3.m2.8.8.1.2.cmml">​</mo><mrow id="S2.E3.m2.8.8.1.1.1" xref="S2.E3.m2.8.8.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m2.8.8.1.1.1.2" xref="S2.E3.m2.8.8.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m2.8.8.1.1.1.1" xref="S2.E3.m2.8.8.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.8.8.1.1.1.1.2" xref="S2.E3.m2.8.8.1.1.1.1.2.cmml">𝒜</mi><mo fence="false" lspace="0.608em" rspace="0.608em" id="S2.E3.m2.8.8.1.1.1.1.1" xref="S2.E3.m2.8.8.1.1.1.1.1.cmml">|</mo><mrow id="S2.E3.m2.8.8.1.1.1.1.3.2" xref="S2.E3.m2.8.8.1.1.1.1.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.1.1" xref="S2.E3.m2.1.1.cmml">𝒯</mi><mo id="S2.E3.m2.8.8.1.1.1.1.3.2.1" xref="S2.E3.m2.8.8.1.1.1.1.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.2.2" xref="S2.E3.m2.2.2.cmml">𝒬</mi></mrow></mrow><mo stretchy="false" id="S2.E3.m2.8.8.1.1.1.3" xref="S2.E3.m2.8.8.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m2.10.10.4" xref="S2.E3.m2.10.10.4.cmml">=</mo><mrow id="S2.E3.m2.10.10.3" xref="S2.E3.m2.10.10.3.cmml"><mi id="S2.E3.m2.10.10.3.4" xref="S2.E3.m2.10.10.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m2.10.10.3.3" xref="S2.E3.m2.10.10.3.3.cmml">​</mo><mrow id="S2.E3.m2.9.9.2.1.1" xref="S2.E3.m2.9.9.2.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m2.9.9.2.1.1.2" xref="S2.E3.m2.9.9.2.1.1.1.cmml">(</mo><mrow id="S2.E3.m2.9.9.2.1.1.1" xref="S2.E3.m2.9.9.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.9.9.2.1.1.1.2" xref="S2.E3.m2.9.9.2.1.1.1.2.cmml">𝒜</mi><mo fence="false" lspace="0.608em" rspace="0.608em" id="S2.E3.m2.9.9.2.1.1.1.1" xref="S2.E3.m2.9.9.2.1.1.1.1.cmml">|</mo><mrow id="S2.E3.m2.9.9.2.1.1.1.3.2" xref="S2.E3.m2.9.9.2.1.1.1.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.3.3" xref="S2.E3.m2.3.3.cmml">𝒯</mi><mo id="S2.E3.m2.9.9.2.1.1.1.3.2.1" xref="S2.E3.m2.9.9.2.1.1.1.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.4.4" xref="S2.E3.m2.4.4.cmml">𝒬</mi><mo id="S2.E3.m2.9.9.2.1.1.1.3.2.2" xref="S2.E3.m2.9.9.2.1.1.1.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.5.5" xref="S2.E3.m2.5.5.cmml">ℛ</mi></mrow></mrow><mo stretchy="false" id="S2.E3.m2.9.9.2.1.1.3" xref="S2.E3.m2.9.9.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E3.m2.10.10.3.3a" xref="S2.E3.m2.10.10.3.3.cmml">​</mo><mi id="S2.E3.m2.10.10.3.5" xref="S2.E3.m2.10.10.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m2.10.10.3.3b" xref="S2.E3.m2.10.10.3.3.cmml">​</mo><mrow id="S2.E3.m2.10.10.3.2.1" xref="S2.E3.m2.10.10.3.2.1.1.cmml"><mo stretchy="false" id="S2.E3.m2.10.10.3.2.1.2" xref="S2.E3.m2.10.10.3.2.1.1.cmml">(</mo><mrow id="S2.E3.m2.10.10.3.2.1.1" xref="S2.E3.m2.10.10.3.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.10.10.3.2.1.1.2" xref="S2.E3.m2.10.10.3.2.1.1.2.cmml">ℛ</mi><mo fence="false" lspace="0.608em" rspace="0.608em" id="S2.E3.m2.10.10.3.2.1.1.1" xref="S2.E3.m2.10.10.3.2.1.1.1.cmml">|</mo><mrow id="S2.E3.m2.10.10.3.2.1.1.3.2" xref="S2.E3.m2.10.10.3.2.1.1.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.6.6" xref="S2.E3.m2.6.6.cmml">𝒯</mi><mo id="S2.E3.m2.10.10.3.2.1.1.3.2.1" xref="S2.E3.m2.10.10.3.2.1.1.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3.m2.7.7" xref="S2.E3.m2.7.7.cmml">𝒬</mi></mrow></mrow><mo stretchy="false" id="S2.E3.m2.10.10.3.2.1.3" xref="S2.E3.m2.10.10.3.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m2.10b"><apply id="S2.E3.m2.10.10.cmml" xref="S2.E3.m2.10.10"><eq id="S2.E3.m2.10.10.4.cmml" xref="S2.E3.m2.10.10.4"></eq><apply id="S2.E3.m2.8.8.1.cmml" xref="S2.E3.m2.8.8.1"><times id="S2.E3.m2.8.8.1.2.cmml" xref="S2.E3.m2.8.8.1.2"></times><ci id="S2.E3.m2.8.8.1.3.cmml" xref="S2.E3.m2.8.8.1.3">𝑝</ci><apply id="S2.E3.m2.8.8.1.1.1.1.cmml" xref="S2.E3.m2.8.8.1.1.1"><csymbol cd="latexml" id="S2.E3.m2.8.8.1.1.1.1.1.cmml" xref="S2.E3.m2.8.8.1.1.1.1.1">conditional</csymbol><ci id="S2.E3.m2.8.8.1.1.1.1.2.cmml" xref="S2.E3.m2.8.8.1.1.1.1.2">𝒜</ci><list id="S2.E3.m2.8.8.1.1.1.1.3.1.cmml" xref="S2.E3.m2.8.8.1.1.1.1.3.2"><ci id="S2.E3.m2.1.1.cmml" xref="S2.E3.m2.1.1">𝒯</ci><ci id="S2.E3.m2.2.2.cmml" xref="S2.E3.m2.2.2">𝒬</ci></list></apply></apply><apply id="S2.E3.m2.10.10.3.cmml" xref="S2.E3.m2.10.10.3"><times id="S2.E3.m2.10.10.3.3.cmml" xref="S2.E3.m2.10.10.3.3"></times><ci id="S2.E3.m2.10.10.3.4.cmml" xref="S2.E3.m2.10.10.3.4">𝑝</ci><apply id="S2.E3.m2.9.9.2.1.1.1.cmml" xref="S2.E3.m2.9.9.2.1.1"><csymbol cd="latexml" id="S2.E3.m2.9.9.2.1.1.1.1.cmml" xref="S2.E3.m2.9.9.2.1.1.1.1">conditional</csymbol><ci id="S2.E3.m2.9.9.2.1.1.1.2.cmml" xref="S2.E3.m2.9.9.2.1.1.1.2">𝒜</ci><list id="S2.E3.m2.9.9.2.1.1.1.3.1.cmml" xref="S2.E3.m2.9.9.2.1.1.1.3.2"><ci id="S2.E3.m2.3.3.cmml" xref="S2.E3.m2.3.3">𝒯</ci><ci id="S2.E3.m2.4.4.cmml" xref="S2.E3.m2.4.4">𝒬</ci><ci id="S2.E3.m2.5.5.cmml" xref="S2.E3.m2.5.5">ℛ</ci></list></apply><ci id="S2.E3.m2.10.10.3.5.cmml" xref="S2.E3.m2.10.10.3.5">𝑝</ci><apply id="S2.E3.m2.10.10.3.2.1.1.cmml" xref="S2.E3.m2.10.10.3.2.1"><csymbol cd="latexml" id="S2.E3.m2.10.10.3.2.1.1.1.cmml" xref="S2.E3.m2.10.10.3.2.1.1.1">conditional</csymbol><ci id="S2.E3.m2.10.10.3.2.1.1.2.cmml" xref="S2.E3.m2.10.10.3.2.1.1.2">ℛ</ci><list id="S2.E3.m2.10.10.3.2.1.1.3.1.cmml" xref="S2.E3.m2.10.10.3.2.1.1.3.2"><ci id="S2.E3.m2.6.6.cmml" xref="S2.E3.m2.6.6">𝒯</ci><ci id="S2.E3.m2.7.7.cmml" xref="S2.E3.m2.7.7">𝒬</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m2.10c">\displaystyle p(\mathcal{A}~{}|~{}\mathcal{T,Q})=p(\mathcal{A}~{}|~{}\mathcal{T,Q,R})p(\mathcal{R}~{}|~{}\mathcal{T,Q})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
<tbody id="S2.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E4.m1.7" class="ltx_Math" alttext="\displaystyle p(\mathcal{R}~{}|~{}\mathcal{T,Q})=\prod_{i=1}^{|\mathcal{R}|}p_{LM}(r_{i}~{}|~{}\mathcal{T,Q},r_{<i})" display="inline"><semantics id="S2.E4.m1.7a"><mrow id="S2.E4.m1.7.7" xref="S2.E4.m1.7.7.cmml"><mrow id="S2.E4.m1.6.6.1" xref="S2.E4.m1.6.6.1.cmml"><mi id="S2.E4.m1.6.6.1.3" xref="S2.E4.m1.6.6.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.6.6.1.2" xref="S2.E4.m1.6.6.1.2.cmml">​</mo><mrow id="S2.E4.m1.6.6.1.1.1" xref="S2.E4.m1.6.6.1.1.1.1.cmml"><mo stretchy="false" id="S2.E4.m1.6.6.1.1.1.2" xref="S2.E4.m1.6.6.1.1.1.1.cmml">(</mo><mrow id="S2.E4.m1.6.6.1.1.1.1" xref="S2.E4.m1.6.6.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.6.6.1.1.1.1.2" xref="S2.E4.m1.6.6.1.1.1.1.2.cmml">ℛ</mi><mo fence="false" lspace="0.608em" rspace="0.608em" id="S2.E4.m1.6.6.1.1.1.1.1" xref="S2.E4.m1.6.6.1.1.1.1.1.cmml">|</mo><mrow id="S2.E4.m1.6.6.1.1.1.1.3.2" xref="S2.E4.m1.6.6.1.1.1.1.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.2.2" xref="S2.E4.m1.2.2.cmml">𝒯</mi><mo id="S2.E4.m1.6.6.1.1.1.1.3.2.1" xref="S2.E4.m1.6.6.1.1.1.1.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.3.3" xref="S2.E4.m1.3.3.cmml">𝒬</mi></mrow></mrow><mo stretchy="false" id="S2.E4.m1.6.6.1.1.1.3" xref="S2.E4.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.7.7.3" xref="S2.E4.m1.7.7.3.cmml">=</mo><mrow id="S2.E4.m1.7.7.2" xref="S2.E4.m1.7.7.2.cmml"><mstyle displaystyle="true" id="S2.E4.m1.7.7.2.2" xref="S2.E4.m1.7.7.2.2.cmml"><munderover id="S2.E4.m1.7.7.2.2a" xref="S2.E4.m1.7.7.2.2.cmml"><mo movablelimits="false" id="S2.E4.m1.7.7.2.2.2.2" xref="S2.E4.m1.7.7.2.2.2.2.cmml">∏</mo><mrow id="S2.E4.m1.7.7.2.2.2.3" xref="S2.E4.m1.7.7.2.2.2.3.cmml"><mi id="S2.E4.m1.7.7.2.2.2.3.2" xref="S2.E4.m1.7.7.2.2.2.3.2.cmml">i</mi><mo id="S2.E4.m1.7.7.2.2.2.3.1" xref="S2.E4.m1.7.7.2.2.2.3.1.cmml">=</mo><mn id="S2.E4.m1.7.7.2.2.2.3.3" xref="S2.E4.m1.7.7.2.2.2.3.3.cmml">1</mn></mrow><mrow id="S2.E4.m1.1.1.1.3" xref="S2.E4.m1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.1.1.1.3.1" xref="S2.E4.m1.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml">ℛ</mi><mo stretchy="false" id="S2.E4.m1.1.1.1.3.2" xref="S2.E4.m1.1.1.1.2.1.cmml">|</mo></mrow></munderover></mstyle><mrow id="S2.E4.m1.7.7.2.1" xref="S2.E4.m1.7.7.2.1.cmml"><msub id="S2.E4.m1.7.7.2.1.3" xref="S2.E4.m1.7.7.2.1.3.cmml"><mi id="S2.E4.m1.7.7.2.1.3.2" xref="S2.E4.m1.7.7.2.1.3.2.cmml">p</mi><mrow id="S2.E4.m1.7.7.2.1.3.3" xref="S2.E4.m1.7.7.2.1.3.3.cmml"><mi id="S2.E4.m1.7.7.2.1.3.3.2" xref="S2.E4.m1.7.7.2.1.3.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.7.7.2.1.3.3.1" xref="S2.E4.m1.7.7.2.1.3.3.1.cmml">​</mo><mi id="S2.E4.m1.7.7.2.1.3.3.3" xref="S2.E4.m1.7.7.2.1.3.3.3.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.7.7.2.1.2" xref="S2.E4.m1.7.7.2.1.2.cmml">​</mo><mrow id="S2.E4.m1.7.7.2.1.1.1" xref="S2.E4.m1.7.7.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.E4.m1.7.7.2.1.1.1.2" xref="S2.E4.m1.7.7.2.1.1.1.1.cmml">(</mo><mrow id="S2.E4.m1.7.7.2.1.1.1.1" xref="S2.E4.m1.7.7.2.1.1.1.1.cmml"><msub id="S2.E4.m1.7.7.2.1.1.1.1.3" xref="S2.E4.m1.7.7.2.1.1.1.1.3.cmml"><mi id="S2.E4.m1.7.7.2.1.1.1.1.3.2" xref="S2.E4.m1.7.7.2.1.1.1.1.3.2.cmml">r</mi><mi id="S2.E4.m1.7.7.2.1.1.1.1.3.3" xref="S2.E4.m1.7.7.2.1.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" rspace="0.608em" id="S2.E4.m1.7.7.2.1.1.1.1.2" xref="S2.E4.m1.7.7.2.1.1.1.1.2.cmml">|</mo><mrow id="S2.E4.m1.7.7.2.1.1.1.1.1.1" xref="S2.E4.m1.7.7.2.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.4.4" xref="S2.E4.m1.4.4.cmml">𝒯</mi><mo id="S2.E4.m1.7.7.2.1.1.1.1.1.1.2" xref="S2.E4.m1.7.7.2.1.1.1.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.5.5" xref="S2.E4.m1.5.5.cmml">𝒬</mi><mo id="S2.E4.m1.7.7.2.1.1.1.1.1.1.3" xref="S2.E4.m1.7.7.2.1.1.1.1.1.2.cmml">,</mo><msub id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.2" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.2.cmml">r</mi><mrow id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.2" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.1" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.3" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.3.cmml">i</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S2.E4.m1.7.7.2.1.1.1.3" xref="S2.E4.m1.7.7.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.7b"><apply id="S2.E4.m1.7.7.cmml" xref="S2.E4.m1.7.7"><eq id="S2.E4.m1.7.7.3.cmml" xref="S2.E4.m1.7.7.3"></eq><apply id="S2.E4.m1.6.6.1.cmml" xref="S2.E4.m1.6.6.1"><times id="S2.E4.m1.6.6.1.2.cmml" xref="S2.E4.m1.6.6.1.2"></times><ci id="S2.E4.m1.6.6.1.3.cmml" xref="S2.E4.m1.6.6.1.3">𝑝</ci><apply id="S2.E4.m1.6.6.1.1.1.1.cmml" xref="S2.E4.m1.6.6.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.6.6.1.1.1.1.1.cmml" xref="S2.E4.m1.6.6.1.1.1.1.1">conditional</csymbol><ci id="S2.E4.m1.6.6.1.1.1.1.2.cmml" xref="S2.E4.m1.6.6.1.1.1.1.2">ℛ</ci><list id="S2.E4.m1.6.6.1.1.1.1.3.1.cmml" xref="S2.E4.m1.6.6.1.1.1.1.3.2"><ci id="S2.E4.m1.2.2.cmml" xref="S2.E4.m1.2.2">𝒯</ci><ci id="S2.E4.m1.3.3.cmml" xref="S2.E4.m1.3.3">𝒬</ci></list></apply></apply><apply id="S2.E4.m1.7.7.2.cmml" xref="S2.E4.m1.7.7.2"><apply id="S2.E4.m1.7.7.2.2.cmml" xref="S2.E4.m1.7.7.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.2.2.1.cmml" xref="S2.E4.m1.7.7.2.2">superscript</csymbol><apply id="S2.E4.m1.7.7.2.2.2.cmml" xref="S2.E4.m1.7.7.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.2.2.2.1.cmml" xref="S2.E4.m1.7.7.2.2">subscript</csymbol><csymbol cd="latexml" id="S2.E4.m1.7.7.2.2.2.2.cmml" xref="S2.E4.m1.7.7.2.2.2.2">product</csymbol><apply id="S2.E4.m1.7.7.2.2.2.3.cmml" xref="S2.E4.m1.7.7.2.2.2.3"><eq id="S2.E4.m1.7.7.2.2.2.3.1.cmml" xref="S2.E4.m1.7.7.2.2.2.3.1"></eq><ci id="S2.E4.m1.7.7.2.2.2.3.2.cmml" xref="S2.E4.m1.7.7.2.2.2.3.2">𝑖</ci><cn type="integer" id="S2.E4.m1.7.7.2.2.2.3.3.cmml" xref="S2.E4.m1.7.7.2.2.2.3.3">1</cn></apply></apply><apply id="S2.E4.m1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.3"><abs id="S2.E4.m1.1.1.1.2.1.cmml" xref="S2.E4.m1.1.1.1.3.1"></abs><ci id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1">ℛ</ci></apply></apply><apply id="S2.E4.m1.7.7.2.1.cmml" xref="S2.E4.m1.7.7.2.1"><times id="S2.E4.m1.7.7.2.1.2.cmml" xref="S2.E4.m1.7.7.2.1.2"></times><apply id="S2.E4.m1.7.7.2.1.3.cmml" xref="S2.E4.m1.7.7.2.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.2.1.3.1.cmml" xref="S2.E4.m1.7.7.2.1.3">subscript</csymbol><ci id="S2.E4.m1.7.7.2.1.3.2.cmml" xref="S2.E4.m1.7.7.2.1.3.2">𝑝</ci><apply id="S2.E4.m1.7.7.2.1.3.3.cmml" xref="S2.E4.m1.7.7.2.1.3.3"><times id="S2.E4.m1.7.7.2.1.3.3.1.cmml" xref="S2.E4.m1.7.7.2.1.3.3.1"></times><ci id="S2.E4.m1.7.7.2.1.3.3.2.cmml" xref="S2.E4.m1.7.7.2.1.3.3.2">𝐿</ci><ci id="S2.E4.m1.7.7.2.1.3.3.3.cmml" xref="S2.E4.m1.7.7.2.1.3.3.3">𝑀</ci></apply></apply><apply id="S2.E4.m1.7.7.2.1.1.1.1.cmml" xref="S2.E4.m1.7.7.2.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.7.7.2.1.1.1.1.2.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.2">conditional</csymbol><apply id="S2.E4.m1.7.7.2.1.1.1.1.3.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.2.1.1.1.1.3.1.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.7.7.2.1.1.1.1.3.2.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.3.2">𝑟</ci><ci id="S2.E4.m1.7.7.2.1.1.1.1.3.3.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.3.3">𝑖</ci></apply><list id="S2.E4.m1.7.7.2.1.1.1.1.1.2.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1"><ci id="S2.E4.m1.4.4.cmml" xref="S2.E4.m1.4.4">𝒯</ci><ci id="S2.E4.m1.5.5.cmml" xref="S2.E4.m1.5.5">𝒬</ci><apply id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.2">𝑟</ci><apply id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3"><lt id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.7.7.2.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.7c">\displaystyle p(\mathcal{R}~{}|~{}\mathcal{T,Q})=\prod_{i=1}^{|\mathcal{R}|}p_{LM}(r_{i}~{}|~{}\mathcal{T,Q},r_{&lt;i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
<tbody id="S2.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E5.m1.9" class="ltx_Math" alttext="\displaystyle p(\mathcal{A}|\mathcal{T,Q,R})=\prod_{j=1}^{|\mathcal{A}|}p_{LM}(a_{i}|\mathcal{T,Q,R},a_{<j})" display="inline"><semantics id="S2.E5.m1.9a"><mrow id="S2.E5.m1.9.9" xref="S2.E5.m1.9.9.cmml"><mrow id="S2.E5.m1.8.8.1" xref="S2.E5.m1.8.8.1.cmml"><mi id="S2.E5.m1.8.8.1.3" xref="S2.E5.m1.8.8.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.8.8.1.2" xref="S2.E5.m1.8.8.1.2.cmml">​</mo><mrow id="S2.E5.m1.8.8.1.1.1" xref="S2.E5.m1.8.8.1.1.1.1.cmml"><mo stretchy="false" id="S2.E5.m1.8.8.1.1.1.2" xref="S2.E5.m1.8.8.1.1.1.1.cmml">(</mo><mrow id="S2.E5.m1.8.8.1.1.1.1" xref="S2.E5.m1.8.8.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E5.m1.8.8.1.1.1.1.2" xref="S2.E5.m1.8.8.1.1.1.1.2.cmml">𝒜</mi><mo fence="false" id="S2.E5.m1.8.8.1.1.1.1.1" xref="S2.E5.m1.8.8.1.1.1.1.1.cmml">|</mo><mrow id="S2.E5.m1.8.8.1.1.1.1.3.2" xref="S2.E5.m1.8.8.1.1.1.1.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E5.m1.2.2" xref="S2.E5.m1.2.2.cmml">𝒯</mi><mo id="S2.E5.m1.8.8.1.1.1.1.3.2.1" xref="S2.E5.m1.8.8.1.1.1.1.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E5.m1.3.3" xref="S2.E5.m1.3.3.cmml">𝒬</mi><mo id="S2.E5.m1.8.8.1.1.1.1.3.2.2" xref="S2.E5.m1.8.8.1.1.1.1.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E5.m1.4.4" xref="S2.E5.m1.4.4.cmml">ℛ</mi></mrow></mrow><mo stretchy="false" id="S2.E5.m1.8.8.1.1.1.3" xref="S2.E5.m1.8.8.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E5.m1.9.9.3" xref="S2.E5.m1.9.9.3.cmml">=</mo><mrow id="S2.E5.m1.9.9.2" xref="S2.E5.m1.9.9.2.cmml"><mstyle displaystyle="true" id="S2.E5.m1.9.9.2.2" xref="S2.E5.m1.9.9.2.2.cmml"><munderover id="S2.E5.m1.9.9.2.2a" xref="S2.E5.m1.9.9.2.2.cmml"><mo movablelimits="false" id="S2.E5.m1.9.9.2.2.2.2" xref="S2.E5.m1.9.9.2.2.2.2.cmml">∏</mo><mrow id="S2.E5.m1.9.9.2.2.2.3" xref="S2.E5.m1.9.9.2.2.2.3.cmml"><mi id="S2.E5.m1.9.9.2.2.2.3.2" xref="S2.E5.m1.9.9.2.2.2.3.2.cmml">j</mi><mo id="S2.E5.m1.9.9.2.2.2.3.1" xref="S2.E5.m1.9.9.2.2.2.3.1.cmml">=</mo><mn id="S2.E5.m1.9.9.2.2.2.3.3" xref="S2.E5.m1.9.9.2.2.2.3.3.cmml">1</mn></mrow><mrow id="S2.E5.m1.1.1.1.3" xref="S2.E5.m1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E5.m1.1.1.1.3.1" xref="S2.E5.m1.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S2.E5.m1.1.1.1.1" xref="S2.E5.m1.1.1.1.1.cmml">𝒜</mi><mo stretchy="false" id="S2.E5.m1.1.1.1.3.2" xref="S2.E5.m1.1.1.1.2.1.cmml">|</mo></mrow></munderover></mstyle><mrow id="S2.E5.m1.9.9.2.1" xref="S2.E5.m1.9.9.2.1.cmml"><msub id="S2.E5.m1.9.9.2.1.3" xref="S2.E5.m1.9.9.2.1.3.cmml"><mi id="S2.E5.m1.9.9.2.1.3.2" xref="S2.E5.m1.9.9.2.1.3.2.cmml">p</mi><mrow id="S2.E5.m1.9.9.2.1.3.3" xref="S2.E5.m1.9.9.2.1.3.3.cmml"><mi id="S2.E5.m1.9.9.2.1.3.3.2" xref="S2.E5.m1.9.9.2.1.3.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.9.9.2.1.3.3.1" xref="S2.E5.m1.9.9.2.1.3.3.1.cmml">​</mo><mi id="S2.E5.m1.9.9.2.1.3.3.3" xref="S2.E5.m1.9.9.2.1.3.3.3.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E5.m1.9.9.2.1.2" xref="S2.E5.m1.9.9.2.1.2.cmml">​</mo><mrow id="S2.E5.m1.9.9.2.1.1.1" xref="S2.E5.m1.9.9.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.E5.m1.9.9.2.1.1.1.2" xref="S2.E5.m1.9.9.2.1.1.1.1.cmml">(</mo><mrow id="S2.E5.m1.9.9.2.1.1.1.1" xref="S2.E5.m1.9.9.2.1.1.1.1.cmml"><msub id="S2.E5.m1.9.9.2.1.1.1.1.3" xref="S2.E5.m1.9.9.2.1.1.1.1.3.cmml"><mi id="S2.E5.m1.9.9.2.1.1.1.1.3.2" xref="S2.E5.m1.9.9.2.1.1.1.1.3.2.cmml">a</mi><mi id="S2.E5.m1.9.9.2.1.1.1.1.3.3" xref="S2.E5.m1.9.9.2.1.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" id="S2.E5.m1.9.9.2.1.1.1.1.2" xref="S2.E5.m1.9.9.2.1.1.1.1.2.cmml">|</mo><mrow id="S2.E5.m1.9.9.2.1.1.1.1.1.1" xref="S2.E5.m1.9.9.2.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E5.m1.5.5" xref="S2.E5.m1.5.5.cmml">𝒯</mi><mo id="S2.E5.m1.9.9.2.1.1.1.1.1.1.2" xref="S2.E5.m1.9.9.2.1.1.1.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E5.m1.6.6" xref="S2.E5.m1.6.6.cmml">𝒬</mi><mo id="S2.E5.m1.9.9.2.1.1.1.1.1.1.3" xref="S2.E5.m1.9.9.2.1.1.1.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E5.m1.7.7" xref="S2.E5.m1.7.7.cmml">ℛ</mi><mo id="S2.E5.m1.9.9.2.1.1.1.1.1.1.4" xref="S2.E5.m1.9.9.2.1.1.1.1.1.2.cmml">,</mo><msub id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.2" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.2.cmml">a</mi><mrow id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.2" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.1" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.3" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.3.cmml">j</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S2.E5.m1.9.9.2.1.1.1.3" xref="S2.E5.m1.9.9.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.9b"><apply id="S2.E5.m1.9.9.cmml" xref="S2.E5.m1.9.9"><eq id="S2.E5.m1.9.9.3.cmml" xref="S2.E5.m1.9.9.3"></eq><apply id="S2.E5.m1.8.8.1.cmml" xref="S2.E5.m1.8.8.1"><times id="S2.E5.m1.8.8.1.2.cmml" xref="S2.E5.m1.8.8.1.2"></times><ci id="S2.E5.m1.8.8.1.3.cmml" xref="S2.E5.m1.8.8.1.3">𝑝</ci><apply id="S2.E5.m1.8.8.1.1.1.1.cmml" xref="S2.E5.m1.8.8.1.1.1"><csymbol cd="latexml" id="S2.E5.m1.8.8.1.1.1.1.1.cmml" xref="S2.E5.m1.8.8.1.1.1.1.1">conditional</csymbol><ci id="S2.E5.m1.8.8.1.1.1.1.2.cmml" xref="S2.E5.m1.8.8.1.1.1.1.2">𝒜</ci><list id="S2.E5.m1.8.8.1.1.1.1.3.1.cmml" xref="S2.E5.m1.8.8.1.1.1.1.3.2"><ci id="S2.E5.m1.2.2.cmml" xref="S2.E5.m1.2.2">𝒯</ci><ci id="S2.E5.m1.3.3.cmml" xref="S2.E5.m1.3.3">𝒬</ci><ci id="S2.E5.m1.4.4.cmml" xref="S2.E5.m1.4.4">ℛ</ci></list></apply></apply><apply id="S2.E5.m1.9.9.2.cmml" xref="S2.E5.m1.9.9.2"><apply id="S2.E5.m1.9.9.2.2.cmml" xref="S2.E5.m1.9.9.2.2"><csymbol cd="ambiguous" id="S2.E5.m1.9.9.2.2.1.cmml" xref="S2.E5.m1.9.9.2.2">superscript</csymbol><apply id="S2.E5.m1.9.9.2.2.2.cmml" xref="S2.E5.m1.9.9.2.2"><csymbol cd="ambiguous" id="S2.E5.m1.9.9.2.2.2.1.cmml" xref="S2.E5.m1.9.9.2.2">subscript</csymbol><csymbol cd="latexml" id="S2.E5.m1.9.9.2.2.2.2.cmml" xref="S2.E5.m1.9.9.2.2.2.2">product</csymbol><apply id="S2.E5.m1.9.9.2.2.2.3.cmml" xref="S2.E5.m1.9.9.2.2.2.3"><eq id="S2.E5.m1.9.9.2.2.2.3.1.cmml" xref="S2.E5.m1.9.9.2.2.2.3.1"></eq><ci id="S2.E5.m1.9.9.2.2.2.3.2.cmml" xref="S2.E5.m1.9.9.2.2.2.3.2">𝑗</ci><cn type="integer" id="S2.E5.m1.9.9.2.2.2.3.3.cmml" xref="S2.E5.m1.9.9.2.2.2.3.3">1</cn></apply></apply><apply id="S2.E5.m1.1.1.1.2.cmml" xref="S2.E5.m1.1.1.1.3"><abs id="S2.E5.m1.1.1.1.2.1.cmml" xref="S2.E5.m1.1.1.1.3.1"></abs><ci id="S2.E5.m1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1.1">𝒜</ci></apply></apply><apply id="S2.E5.m1.9.9.2.1.cmml" xref="S2.E5.m1.9.9.2.1"><times id="S2.E5.m1.9.9.2.1.2.cmml" xref="S2.E5.m1.9.9.2.1.2"></times><apply id="S2.E5.m1.9.9.2.1.3.cmml" xref="S2.E5.m1.9.9.2.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.9.9.2.1.3.1.cmml" xref="S2.E5.m1.9.9.2.1.3">subscript</csymbol><ci id="S2.E5.m1.9.9.2.1.3.2.cmml" xref="S2.E5.m1.9.9.2.1.3.2">𝑝</ci><apply id="S2.E5.m1.9.9.2.1.3.3.cmml" xref="S2.E5.m1.9.9.2.1.3.3"><times id="S2.E5.m1.9.9.2.1.3.3.1.cmml" xref="S2.E5.m1.9.9.2.1.3.3.1"></times><ci id="S2.E5.m1.9.9.2.1.3.3.2.cmml" xref="S2.E5.m1.9.9.2.1.3.3.2">𝐿</ci><ci id="S2.E5.m1.9.9.2.1.3.3.3.cmml" xref="S2.E5.m1.9.9.2.1.3.3.3">𝑀</ci></apply></apply><apply id="S2.E5.m1.9.9.2.1.1.1.1.cmml" xref="S2.E5.m1.9.9.2.1.1.1"><csymbol cd="latexml" id="S2.E5.m1.9.9.2.1.1.1.1.2.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.2">conditional</csymbol><apply id="S2.E5.m1.9.9.2.1.1.1.1.3.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.9.9.2.1.1.1.1.3.1.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.3">subscript</csymbol><ci id="S2.E5.m1.9.9.2.1.1.1.1.3.2.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.3.2">𝑎</ci><ci id="S2.E5.m1.9.9.2.1.1.1.1.3.3.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.3.3">𝑖</ci></apply><list id="S2.E5.m1.9.9.2.1.1.1.1.1.2.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1"><ci id="S2.E5.m1.5.5.cmml" xref="S2.E5.m1.5.5">𝒯</ci><ci id="S2.E5.m1.6.6.cmml" xref="S2.E5.m1.6.6">𝒬</ci><ci id="S2.E5.m1.7.7.cmml" xref="S2.E5.m1.7.7">ℛ</ci><apply id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.2">𝑎</ci><apply id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3"><lt id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E5.m1.9.9.2.1.1.1.1.1.1.1.3.3">𝑗</ci></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.9c">\displaystyle p(\mathcal{A}|\mathcal{T,Q,R})=\prod_{j=1}^{|\mathcal{A}|}p_{LM}(a_{i}|\mathcal{T,Q,R},a_{&lt;j})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
<tbody id="S2.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E6.m2.4" class="ltx_Math" alttext="\displaystyle\mathcal{T}_{\mathrm{CoT}}=\{I,(x_{1},e_{1},y_{1}),\cdots,(x_{n},e_{n},y_{n})\}" display="inline"><semantics id="S2.E6.m2.4a"><mrow id="S2.E6.m2.4.4" xref="S2.E6.m2.4.4.cmml"><msub id="S2.E6.m2.4.4.4" xref="S2.E6.m2.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E6.m2.4.4.4.2" xref="S2.E6.m2.4.4.4.2.cmml">𝒯</mi><mi id="S2.E6.m2.4.4.4.3" xref="S2.E6.m2.4.4.4.3.cmml">CoT</mi></msub><mo id="S2.E6.m2.4.4.3" xref="S2.E6.m2.4.4.3.cmml">=</mo><mrow id="S2.E6.m2.4.4.2.2" xref="S2.E6.m2.4.4.2.3.cmml"><mo stretchy="false" id="S2.E6.m2.4.4.2.2.3" xref="S2.E6.m2.4.4.2.3.cmml">{</mo><mi id="S2.E6.m2.1.1" xref="S2.E6.m2.1.1.cmml">I</mi><mo id="S2.E6.m2.4.4.2.2.4" xref="S2.E6.m2.4.4.2.3.cmml">,</mo><mrow id="S2.E6.m2.3.3.1.1.1.3" xref="S2.E6.m2.3.3.1.1.1.4.cmml"><mo stretchy="false" id="S2.E6.m2.3.3.1.1.1.3.4" xref="S2.E6.m2.3.3.1.1.1.4.cmml">(</mo><msub id="S2.E6.m2.3.3.1.1.1.1.1" xref="S2.E6.m2.3.3.1.1.1.1.1.cmml"><mi id="S2.E6.m2.3.3.1.1.1.1.1.2" xref="S2.E6.m2.3.3.1.1.1.1.1.2.cmml">x</mi><mn id="S2.E6.m2.3.3.1.1.1.1.1.3" xref="S2.E6.m2.3.3.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E6.m2.3.3.1.1.1.3.5" xref="S2.E6.m2.3.3.1.1.1.4.cmml">,</mo><msub id="S2.E6.m2.3.3.1.1.1.2.2" xref="S2.E6.m2.3.3.1.1.1.2.2.cmml"><mi id="S2.E6.m2.3.3.1.1.1.2.2.2" xref="S2.E6.m2.3.3.1.1.1.2.2.2.cmml">e</mi><mn id="S2.E6.m2.3.3.1.1.1.2.2.3" xref="S2.E6.m2.3.3.1.1.1.2.2.3.cmml">1</mn></msub><mo id="S2.E6.m2.3.3.1.1.1.3.6" xref="S2.E6.m2.3.3.1.1.1.4.cmml">,</mo><msub id="S2.E6.m2.3.3.1.1.1.3.3" xref="S2.E6.m2.3.3.1.1.1.3.3.cmml"><mi id="S2.E6.m2.3.3.1.1.1.3.3.2" xref="S2.E6.m2.3.3.1.1.1.3.3.2.cmml">y</mi><mn id="S2.E6.m2.3.3.1.1.1.3.3.3" xref="S2.E6.m2.3.3.1.1.1.3.3.3.cmml">1</mn></msub><mo stretchy="false" id="S2.E6.m2.3.3.1.1.1.3.7" xref="S2.E6.m2.3.3.1.1.1.4.cmml">)</mo></mrow><mo id="S2.E6.m2.4.4.2.2.5" xref="S2.E6.m2.4.4.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.E6.m2.2.2" xref="S2.E6.m2.2.2.cmml">⋯</mi><mo id="S2.E6.m2.4.4.2.2.6" xref="S2.E6.m2.4.4.2.3.cmml">,</mo><mrow id="S2.E6.m2.4.4.2.2.2.3" xref="S2.E6.m2.4.4.2.2.2.4.cmml"><mo stretchy="false" id="S2.E6.m2.4.4.2.2.2.3.4" xref="S2.E6.m2.4.4.2.2.2.4.cmml">(</mo><msub id="S2.E6.m2.4.4.2.2.2.1.1" xref="S2.E6.m2.4.4.2.2.2.1.1.cmml"><mi id="S2.E6.m2.4.4.2.2.2.1.1.2" xref="S2.E6.m2.4.4.2.2.2.1.1.2.cmml">x</mi><mi id="S2.E6.m2.4.4.2.2.2.1.1.3" xref="S2.E6.m2.4.4.2.2.2.1.1.3.cmml">n</mi></msub><mo id="S2.E6.m2.4.4.2.2.2.3.5" xref="S2.E6.m2.4.4.2.2.2.4.cmml">,</mo><msub id="S2.E6.m2.4.4.2.2.2.2.2" xref="S2.E6.m2.4.4.2.2.2.2.2.cmml"><mi id="S2.E6.m2.4.4.2.2.2.2.2.2" xref="S2.E6.m2.4.4.2.2.2.2.2.2.cmml">e</mi><mi id="S2.E6.m2.4.4.2.2.2.2.2.3" xref="S2.E6.m2.4.4.2.2.2.2.2.3.cmml">n</mi></msub><mo id="S2.E6.m2.4.4.2.2.2.3.6" xref="S2.E6.m2.4.4.2.2.2.4.cmml">,</mo><msub id="S2.E6.m2.4.4.2.2.2.3.3" xref="S2.E6.m2.4.4.2.2.2.3.3.cmml"><mi id="S2.E6.m2.4.4.2.2.2.3.3.2" xref="S2.E6.m2.4.4.2.2.2.3.3.2.cmml">y</mi><mi id="S2.E6.m2.4.4.2.2.2.3.3.3" xref="S2.E6.m2.4.4.2.2.2.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="S2.E6.m2.4.4.2.2.2.3.7" xref="S2.E6.m2.4.4.2.2.2.4.cmml">)</mo></mrow><mo stretchy="false" id="S2.E6.m2.4.4.2.2.7" xref="S2.E6.m2.4.4.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m2.4b"><apply id="S2.E6.m2.4.4.cmml" xref="S2.E6.m2.4.4"><eq id="S2.E6.m2.4.4.3.cmml" xref="S2.E6.m2.4.4.3"></eq><apply id="S2.E6.m2.4.4.4.cmml" xref="S2.E6.m2.4.4.4"><csymbol cd="ambiguous" id="S2.E6.m2.4.4.4.1.cmml" xref="S2.E6.m2.4.4.4">subscript</csymbol><ci id="S2.E6.m2.4.4.4.2.cmml" xref="S2.E6.m2.4.4.4.2">𝒯</ci><ci id="S2.E6.m2.4.4.4.3.cmml" xref="S2.E6.m2.4.4.4.3">CoT</ci></apply><set id="S2.E6.m2.4.4.2.3.cmml" xref="S2.E6.m2.4.4.2.2"><ci id="S2.E6.m2.1.1.cmml" xref="S2.E6.m2.1.1">𝐼</ci><vector id="S2.E6.m2.3.3.1.1.1.4.cmml" xref="S2.E6.m2.3.3.1.1.1.3"><apply id="S2.E6.m2.3.3.1.1.1.1.1.cmml" xref="S2.E6.m2.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E6.m2.3.3.1.1.1.1.1.1.cmml" xref="S2.E6.m2.3.3.1.1.1.1.1">subscript</csymbol><ci id="S2.E6.m2.3.3.1.1.1.1.1.2.cmml" xref="S2.E6.m2.3.3.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S2.E6.m2.3.3.1.1.1.1.1.3.cmml" xref="S2.E6.m2.3.3.1.1.1.1.1.3">1</cn></apply><apply id="S2.E6.m2.3.3.1.1.1.2.2.cmml" xref="S2.E6.m2.3.3.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E6.m2.3.3.1.1.1.2.2.1.cmml" xref="S2.E6.m2.3.3.1.1.1.2.2">subscript</csymbol><ci id="S2.E6.m2.3.3.1.1.1.2.2.2.cmml" xref="S2.E6.m2.3.3.1.1.1.2.2.2">𝑒</ci><cn type="integer" id="S2.E6.m2.3.3.1.1.1.2.2.3.cmml" xref="S2.E6.m2.3.3.1.1.1.2.2.3">1</cn></apply><apply id="S2.E6.m2.3.3.1.1.1.3.3.cmml" xref="S2.E6.m2.3.3.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E6.m2.3.3.1.1.1.3.3.1.cmml" xref="S2.E6.m2.3.3.1.1.1.3.3">subscript</csymbol><ci id="S2.E6.m2.3.3.1.1.1.3.3.2.cmml" xref="S2.E6.m2.3.3.1.1.1.3.3.2">𝑦</ci><cn type="integer" id="S2.E6.m2.3.3.1.1.1.3.3.3.cmml" xref="S2.E6.m2.3.3.1.1.1.3.3.3">1</cn></apply></vector><ci id="S2.E6.m2.2.2.cmml" xref="S2.E6.m2.2.2">⋯</ci><vector id="S2.E6.m2.4.4.2.2.2.4.cmml" xref="S2.E6.m2.4.4.2.2.2.3"><apply id="S2.E6.m2.4.4.2.2.2.1.1.cmml" xref="S2.E6.m2.4.4.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E6.m2.4.4.2.2.2.1.1.1.cmml" xref="S2.E6.m2.4.4.2.2.2.1.1">subscript</csymbol><ci id="S2.E6.m2.4.4.2.2.2.1.1.2.cmml" xref="S2.E6.m2.4.4.2.2.2.1.1.2">𝑥</ci><ci id="S2.E6.m2.4.4.2.2.2.1.1.3.cmml" xref="S2.E6.m2.4.4.2.2.2.1.1.3">𝑛</ci></apply><apply id="S2.E6.m2.4.4.2.2.2.2.2.cmml" xref="S2.E6.m2.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E6.m2.4.4.2.2.2.2.2.1.cmml" xref="S2.E6.m2.4.4.2.2.2.2.2">subscript</csymbol><ci id="S2.E6.m2.4.4.2.2.2.2.2.2.cmml" xref="S2.E6.m2.4.4.2.2.2.2.2.2">𝑒</ci><ci id="S2.E6.m2.4.4.2.2.2.2.2.3.cmml" xref="S2.E6.m2.4.4.2.2.2.2.2.3">𝑛</ci></apply><apply id="S2.E6.m2.4.4.2.2.2.3.3.cmml" xref="S2.E6.m2.4.4.2.2.2.3.3"><csymbol cd="ambiguous" id="S2.E6.m2.4.4.2.2.2.3.3.1.cmml" xref="S2.E6.m2.4.4.2.2.2.3.3">subscript</csymbol><ci id="S2.E6.m2.4.4.2.2.2.3.3.2.cmml" xref="S2.E6.m2.4.4.2.2.2.3.3.2">𝑦</ci><ci id="S2.E6.m2.4.4.2.2.2.3.3.3.cmml" xref="S2.E6.m2.4.4.2.2.2.3.3.3">𝑛</ci></apply></vector></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m2.4c">\displaystyle\mathcal{T}_{\mathrm{CoT}}=\{I,(x_{1},e_{1},y_{1}),\cdots,(x_{n},e_{n},y_{n})\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Benchmarks</h2>

<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:389.2pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-295.1pt,264.6pt) scale(0.42353662949067,0.42353662949067) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Task</th>
<th id="S3.T1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Dataset</th>
<td id="S3.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Size</td>
<td id="S3.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Input</td>
<td id="S3.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">Output</td>
<td id="S3.T1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">Rationale</td>
<td id="S3.T1.1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">Description</td>
</tr>
<tr id="S3.T1.1.1.2.2" class="ltx_tr">
<th id="S3.T1.1.1.2.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S3.T1.1.1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">AddSub <cite class="ltx_cite ltx_citemacro_cite">Hosseini et&nbsp;al. (<a href="#bib.bib44" title="" class="ltx_ref">2014</a>)</cite>
</th>
<td id="S3.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">395</td>
<td id="S3.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">Question</td>
<td id="S3.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">Number</td>
<td id="S3.T1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t">Equation</td>
<td id="S3.T1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t">Simple arithmetic</td>
</tr>
<tr id="S3.T1.1.1.3.3" class="ltx_tr">
<th id="S3.T1.1.1.3.3.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">SingleEq <cite class="ltx_cite ltx_citemacro_cite">Koncel-Kedziorski et&nbsp;al. (<a href="#bib.bib65" title="" class="ltx_ref">2015</a>)</cite>
</th>
<td id="S3.T1.1.1.3.3.3" class="ltx_td ltx_align_center">508</td>
<td id="S3.T1.1.1.3.3.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.3.3.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.3.3.6" class="ltx_td ltx_align_center">Equation</td>
<td id="S3.T1.1.1.3.3.7" class="ltx_td ltx_align_center">Simple arithmetic</td>
</tr>
<tr id="S3.T1.1.1.4.4" class="ltx_tr">
<th id="S3.T1.1.1.4.4.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MultiArith <cite class="ltx_cite ltx_citemacro_cite">Roy and Roth (<a href="#bib.bib123" title="" class="ltx_ref">2015</a>)</cite>
</th>
<td id="S3.T1.1.1.4.4.3" class="ltx_td ltx_align_center">600</td>
<td id="S3.T1.1.1.4.4.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.4.4.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.4.4.6" class="ltx_td ltx_align_center">Equation</td>
<td id="S3.T1.1.1.4.4.7" class="ltx_td ltx_align_center">Simple arithmetic</td>
</tr>
<tr id="S3.T1.1.1.5.5" class="ltx_tr">
<th id="S3.T1.1.1.5.5.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.5.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MAWPS <cite class="ltx_cite ltx_citemacro_cite">Koncel-Kedziorski et&nbsp;al. (<a href="#bib.bib66" title="" class="ltx_ref">2016</a>)</cite>
</th>
<td id="S3.T1.1.1.5.5.3" class="ltx_td ltx_align_center">3320</td>
<td id="S3.T1.1.1.5.5.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.5.5.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.5.5.6" class="ltx_td ltx_align_center">Equation</td>
<td id="S3.T1.1.1.5.5.7" class="ltx_td ltx_align_center">Simple arithmetic</td>
</tr>
<tr id="S3.T1.1.1.6.6" class="ltx_tr">
<th id="S3.T1.1.1.6.6.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.6.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">AQUA-RAT <cite class="ltx_cite ltx_citemacro_cite">Ling et&nbsp;al. (<a href="#bib.bib84" title="" class="ltx_ref">2017</a>)</cite>
</th>
<td id="S3.T1.1.1.6.6.3" class="ltx_td ltx_align_center">100,000</td>
<td id="S3.T1.1.1.6.6.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.6.6.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.6.6.6" class="ltx_td ltx_align_center">Natural Language</td>
<td id="S3.T1.1.1.6.6.7" class="ltx_td ltx_align_center">Math reasoning with NL rationale</td>
</tr>
<tr id="S3.T1.1.1.7.7" class="ltx_tr">
<th id="S3.T1.1.1.7.7.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.7.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">ASDiv <cite class="ltx_cite ltx_citemacro_cite">Miao et&nbsp;al. (<a href="#bib.bib101" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S3.T1.1.1.7.7.3" class="ltx_td ltx_align_center">2305</td>
<td id="S3.T1.1.1.7.7.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.7.7.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.7.7.6" class="ltx_td ltx_align_center">Equation</td>
<td id="S3.T1.1.1.7.7.7" class="ltx_td ltx_align_center">Multi-step math reasoning</td>
</tr>
<tr id="S3.T1.1.1.8.8" class="ltx_tr">
<th id="S3.T1.1.1.8.8.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.8.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">SVAMP <cite class="ltx_cite ltx_citemacro_cite">Patel et&nbsp;al. (<a href="#bib.bib114" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.8.8.3" class="ltx_td ltx_align_center">1,000</td>
<td id="S3.T1.1.1.8.8.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.8.8.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.8.8.6" class="ltx_td ltx_align_center">Equation</td>
<td id="S3.T1.1.1.8.8.7" class="ltx_td ltx_align_center">Multi-step math reasoning</td>
</tr>
<tr id="S3.T1.1.1.9.9" class="ltx_tr">
<th id="S3.T1.1.1.9.9.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.9.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">GSM8K <cite class="ltx_cite ltx_citemacro_cite">Cobbe et&nbsp;al. (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.9.9.3" class="ltx_td ltx_align_center">8,792</td>
<td id="S3.T1.1.1.9.9.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.9.9.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.9.9.6" class="ltx_td ltx_align_center">Natural Language</td>
<td id="S3.T1.1.1.9.9.7" class="ltx_td ltx_align_center">Multi-step math reasoning</td>
</tr>
<tr id="S3.T1.1.1.10.10" class="ltx_tr">
<th id="S3.T1.1.1.10.10.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.10.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">GSM-Hard <cite class="ltx_cite ltx_citemacro_cite">Gao et&nbsp;al. (<a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S3.T1.1.1.10.10.3" class="ltx_td ltx_align_center">936</td>
<td id="S3.T1.1.1.10.10.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.10.10.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.10.10.6" class="ltx_td ltx_align_center">Natural Language</td>
<td id="S3.T1.1.1.10.10.7" class="ltx_td ltx_align_center">GSM8K with larger number</td>
</tr>
<tr id="S3.T1.1.1.11.11" class="ltx_tr">
<th id="S3.T1.1.1.11.11.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.11.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MathQA <cite class="ltx_cite ltx_citemacro_cite">Amini et&nbsp;al. (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S3.T1.1.1.11.11.3" class="ltx_td ltx_align_center">37,297</td>
<td id="S3.T1.1.1.11.11.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.11.11.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.11.11.6" class="ltx_td ltx_align_center">Operation</td>
<td id="S3.T1.1.1.11.11.7" class="ltx_td ltx_align_center">Annotated based on AQUA</td>
</tr>
<tr id="S3.T1.1.1.12.12" class="ltx_tr">
<th id="S3.T1.1.1.12.12.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.12.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DROP <cite class="ltx_cite ltx_citemacro_cite">Dua et&nbsp;al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S3.T1.1.1.12.12.3" class="ltx_td ltx_align_center">96,567</td>
<td id="S3.T1.1.1.12.12.4" class="ltx_td ltx_align_center">Question+Passage</td>
<td id="S3.T1.1.1.12.12.5" class="ltx_td ltx_align_center">Number+Span</td>
<td id="S3.T1.1.1.12.12.6" class="ltx_td ltx_align_center">Equation</td>
<td id="S3.T1.1.1.12.12.7" class="ltx_td ltx_align_center">Reading comprehension form</td>
</tr>
<tr id="S3.T1.1.1.13.13" class="ltx_tr">
<th id="S3.T1.1.1.13.13.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.13.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">TheoremQA <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a href="#bib.bib13" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S3.T1.1.1.13.13.3" class="ltx_td ltx_align_center">800</td>
<td id="S3.T1.1.1.13.13.4" class="ltx_td ltx_align_center">Question+Theorem</td>
<td id="S3.T1.1.1.13.13.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.13.13.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.13.13.7" class="ltx_td ltx_align_center">Answer based on theorems</td>
</tr>
<tr id="S3.T1.1.1.14.14" class="ltx_tr">
<th id="S3.T1.1.1.14.14.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.14.14.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">TAT-QA <cite class="ltx_cite ltx_citemacro_cite">Zhu et&nbsp;al. (<a href="#bib.bib207" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.14.14.3" class="ltx_td ltx_align_center">16,552</td>
<td id="S3.T1.1.1.14.14.4" class="ltx_td ltx_align_center">Question+Table+Text</td>
<td id="S3.T1.1.1.14.14.5" class="ltx_td ltx_align_center">Number+Span</td>
<td id="S3.T1.1.1.14.14.6" class="ltx_td ltx_align_center">Operation</td>
<td id="S3.T1.1.1.14.14.7" class="ltx_td ltx_align_center">Answer based on tables</td>
</tr>
<tr id="S3.T1.1.1.15.15" class="ltx_tr">
<th id="S3.T1.1.1.15.15.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.15.15.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">FinQA <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.15.15.3" class="ltx_td ltx_align_center">8,281</td>
<td id="S3.T1.1.1.15.15.4" class="ltx_td ltx_align_center">Question+Table+Text</td>
<td id="S3.T1.1.1.15.15.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.15.15.6" class="ltx_td ltx_align_center">Operation</td>
<td id="S3.T1.1.1.15.15.7" class="ltx_td ltx_align_center">Answer based on tables</td>
</tr>
<tr id="S3.T1.1.1.16.16" class="ltx_tr">
<th id="S3.T1.1.1.16.16.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.16.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">ConvFinQA <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a href="#bib.bib15" title="" class="ltx_ref">2022b</a>)</cite>
</th>
<td id="S3.T1.1.1.16.16.3" class="ltx_td ltx_align_center">3892</td>
<td id="S3.T1.1.1.16.16.4" class="ltx_td ltx_align_center">Question+Table+Dialog</td>
<td id="S3.T1.1.1.16.16.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.16.16.6" class="ltx_td ltx_align_center">Operation</td>
<td id="S3.T1.1.1.16.16.7" class="ltx_td ltx_align_center">Multi-turn dialogs</td>
</tr>
<tr id="S3.T1.1.1.17.17" class="ltx_tr">
<th id="S3.T1.1.1.17.17.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.17.17.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">MATH <cite class="ltx_cite ltx_citemacro_cite">Hendrycks et&nbsp;al. (<a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.17.17.3" class="ltx_td ltx_align_center">12500</td>
<td id="S3.T1.1.1.17.17.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.17.17.5" class="ltx_td ltx_align_center">Number</td>
<td id="S3.T1.1.1.17.17.6" class="ltx_td ltx_align_center">Natural Language</td>
<td id="S3.T1.1.1.17.17.7" class="ltx_td ltx_align_center">Challenging competition math problems</td>
</tr>
<tr id="S3.T1.1.1.18.18" class="ltx_tr">
<th id="S3.T1.1.1.18.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.1.1.18.18.1.1" class="ltx_text">Mathematical</span></th>
<th id="S3.T1.1.1.18.18.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">NumGLUE <cite class="ltx_cite ltx_citemacro_cite">Mishra et&nbsp;al. (<a href="#bib.bib104" title="" class="ltx_ref">2022b</a>)</cite>
</th>
<td id="S3.T1.1.1.18.18.3" class="ltx_td ltx_align_center">101,835</td>
<td id="S3.T1.1.1.18.18.4" class="ltx_td ltx_align_center">Question+Text</td>
<td id="S3.T1.1.1.18.18.5" class="ltx_td ltx_align_center">Number+Span</td>
<td id="S3.T1.1.1.18.18.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.18.18.7" class="ltx_td ltx_align_center">Multi-task benchmark</td>
</tr>
<tr id="S3.T1.1.1.19.19" class="ltx_tr">
<th id="S3.T1.1.1.19.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.1.1.19.19.1.1" class="ltx_text">Reasoning</span></th>
<th id="S3.T1.1.1.19.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">LILA <cite class="ltx_cite ltx_citemacro_cite">Mishra et&nbsp;al. (<a href="#bib.bib103" title="" class="ltx_ref">2022a</a>)</cite>
</th>
<td id="S3.T1.1.1.19.19.3" class="ltx_td ltx_align_center">133,815</td>
<td id="S3.T1.1.1.19.19.4" class="ltx_td ltx_align_center">Question+Text</td>
<td id="S3.T1.1.1.19.19.5" class="ltx_td ltx_align_center">Free-form</td>
<td id="S3.T1.1.1.19.19.6" class="ltx_td ltx_align_center">Program</td>
<td id="S3.T1.1.1.19.19.7" class="ltx_td ltx_align_center">Multi-task benchmark</td>
</tr>
<tr id="S3.T1.1.1.20.20" class="ltx_tr">
<th id="S3.T1.1.1.20.20.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S3.T1.1.1.20.20.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ARC <cite class="ltx_cite ltx_citemacro_cite">Bhakthavatsalam et&nbsp;al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.20.20.3" class="ltx_td ltx_align_center ltx_border_t">7787</td>
<td id="S3.T1.1.1.20.20.4" class="ltx_td ltx_align_center ltx_border_t">Question</td>
<td id="S3.T1.1.1.20.20.5" class="ltx_td ltx_align_center ltx_border_t">Option</td>
<td id="S3.T1.1.1.20.20.6" class="ltx_td ltx_align_center ltx_border_t">✗</td>
<td id="S3.T1.1.1.20.20.7" class="ltx_td ltx_align_center ltx_border_t">From science exam</td>
</tr>
<tr id="S3.T1.1.1.21.21" class="ltx_tr">
<th id="S3.T1.1.1.21.21.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.21.21.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">OpenBookQA <cite class="ltx_cite ltx_citemacro_cite">Mihaylov et&nbsp;al. (<a href="#bib.bib102" title="" class="ltx_ref">2018</a>)</cite>
</th>
<td id="S3.T1.1.1.21.21.3" class="ltx_td ltx_align_center">5,957</td>
<td id="S3.T1.1.1.21.21.4" class="ltx_td ltx_align_center">Question+Context</td>
<td id="S3.T1.1.1.21.21.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.21.21.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.21.21.7" class="ltx_td ltx_align_center">Open-book knowledges</td>
</tr>
<tr id="S3.T1.1.1.22.22" class="ltx_tr">
<th id="S3.T1.1.1.22.22.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.22.22.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PIQA <cite class="ltx_cite ltx_citemacro_cite">Bisk et&nbsp;al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S3.T1.1.1.22.22.3" class="ltx_td ltx_align_center">21000</td>
<td id="S3.T1.1.1.22.22.4" class="ltx_td ltx_align_center">Goal+Solution</td>
<td id="S3.T1.1.1.22.22.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.22.22.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.22.22.7" class="ltx_td ltx_align_center">Physical commonsense knowledge</td>
</tr>
<tr id="S3.T1.1.1.23.23" class="ltx_tr">
<th id="S3.T1.1.1.23.23.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.23.23.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">CommonsenseQA <cite class="ltx_cite ltx_citemacro_cite">Talmor et&nbsp;al. (<a href="#bib.bib140" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S3.T1.1.1.23.23.3" class="ltx_td ltx_align_center">12247</td>
<td id="S3.T1.1.1.23.23.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.23.23.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.23.23.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.23.23.7" class="ltx_td ltx_align_center">Derived from ConceptNet</td>
</tr>
<tr id="S3.T1.1.1.24.24" class="ltx_tr">
<th id="S3.T1.1.1.24.24.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.24.24.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">CommonsenseQA 2.0 <cite class="ltx_cite ltx_citemacro_cite">Talmor et&nbsp;al. (<a href="#bib.bib141" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.24.24.3" class="ltx_td ltx_align_center">14343</td>
<td id="S3.T1.1.1.24.24.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.24.24.5" class="ltx_td ltx_align_center">Yes/No</td>
<td id="S3.T1.1.1.24.24.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.24.24.7" class="ltx_td ltx_align_center">Gaming annotation with high quality</td>
</tr>
<tr id="S3.T1.1.1.25.25" class="ltx_tr">
<th id="S3.T1.1.1.25.25.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.25.25.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Event2Mind <cite class="ltx_cite ltx_citemacro_cite">Rashkin et&nbsp;al. (<a href="#bib.bib122" title="" class="ltx_ref">2018</a>)</cite>
</th>
<td id="S3.T1.1.1.25.25.3" class="ltx_td ltx_align_center">25000</td>
<td id="S3.T1.1.1.25.25.4" class="ltx_td ltx_align_center">Event</td>
<td id="S3.T1.1.1.25.25.5" class="ltx_td ltx_align_center">Intent+Reaction</td>
<td id="S3.T1.1.1.25.25.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.25.25.7" class="ltx_td ltx_align_center">Intension commonsense reasoning</td>
</tr>
<tr id="S3.T1.1.1.26.26" class="ltx_tr">
<th id="S3.T1.1.1.26.26.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.26.26.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">McTaco <cite class="ltx_cite ltx_citemacro_cite">Zhou et&nbsp;al. (<a href="#bib.bib204" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S3.T1.1.1.26.26.3" class="ltx_td ltx_align_center">13225</td>
<td id="S3.T1.1.1.26.26.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.26.26.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.26.26.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.26.26.7" class="ltx_td ltx_align_center">Event temporal commonsense reasoning</td>
</tr>
<tr id="S3.T1.1.1.27.27" class="ltx_tr">
<th id="S3.T1.1.1.27.27.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.27.27.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">CosmosQA <cite class="ltx_cite ltx_citemacro_cite">Huang et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S3.T1.1.1.27.27.3" class="ltx_td ltx_align_center">35588</td>
<td id="S3.T1.1.1.27.27.4" class="ltx_td ltx_align_center">Question+Paragraph</td>
<td id="S3.T1.1.1.27.27.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.27.27.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.27.27.7" class="ltx_td ltx_align_center">Narrative commonsense reasoning</td>
</tr>
<tr id="S3.T1.1.1.28.28" class="ltx_tr">
<th id="S3.T1.1.1.28.28.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.28.28.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">ComValidation <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib148" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S3.T1.1.1.28.28.3" class="ltx_td ltx_align_center">11997</td>
<td id="S3.T1.1.1.28.28.4" class="ltx_td ltx_align_center">Statement</td>
<td id="S3.T1.1.1.28.28.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.28.28.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.28.28.7" class="ltx_td ltx_align_center">Commonsense verification</td>
</tr>
<tr id="S3.T1.1.1.29.29" class="ltx_tr">
<th id="S3.T1.1.1.29.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.1.1.29.29.1.1" class="ltx_text">Commonsense</span></th>
<th id="S3.T1.1.1.29.29.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">ComExplanation <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib148" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S3.T1.1.1.29.29.3" class="ltx_td ltx_align_center">11997</td>
<td id="S3.T1.1.1.29.29.4" class="ltx_td ltx_align_center">Statement</td>
<td id="S3.T1.1.1.29.29.5" class="ltx_td ltx_align_center">Option/Free-form</td>
<td id="S3.T1.1.1.29.29.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.29.29.7" class="ltx_td ltx_align_center">Commonsense explanation</td>
</tr>
<tr id="S3.T1.1.1.30.30" class="ltx_tr">
<th id="S3.T1.1.1.30.30.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.1.1.30.30.1.1" class="ltx_text">Reasoning</span></th>
<th id="S3.T1.1.1.30.30.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">StrategyQA <cite class="ltx_cite ltx_citemacro_cite">Geva et&nbsp;al. (<a href="#bib.bib34" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.30.30.3" class="ltx_td ltx_align_center">2,780</td>
<td id="S3.T1.1.1.30.30.4" class="ltx_td ltx_align_center">Question</td>
<td id="S3.T1.1.1.30.30.5" class="ltx_td ltx_align_center">Yes/No</td>
<td id="S3.T1.1.1.30.30.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.30.30.7" class="ltx_td ltx_align_center">Multi-hop commonsense reasoning</td>
</tr>
<tr id="S3.T1.1.1.31.31" class="ltx_tr">
<th id="S3.T1.1.1.31.31.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S3.T1.1.1.31.31.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Last Letter Concat. <cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite>
</th>
<td id="S3.T1.1.1.31.31.3" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S3.T1.1.1.31.31.4" class="ltx_td ltx_align_center ltx_border_t">Words</td>
<td id="S3.T1.1.1.31.31.5" class="ltx_td ltx_align_center ltx_border_t">Letters</td>
<td id="S3.T1.1.1.31.31.6" class="ltx_td ltx_align_center ltx_border_t">✗</td>
<td id="S3.T1.1.1.31.31.7" class="ltx_td ltx_align_center ltx_border_t">Rule-based</td>
</tr>
<tr id="S3.T1.1.1.32.32" class="ltx_tr">
<th id="S3.T1.1.1.32.32.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.32.32.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Coin Flip <cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite>
</th>
<td id="S3.T1.1.1.32.32.3" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.32.32.4" class="ltx_td ltx_align_center">Statement</td>
<td id="S3.T1.1.1.32.32.5" class="ltx_td ltx_align_center">Yes/No</td>
<td id="S3.T1.1.1.32.32.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.32.32.7" class="ltx_td ltx_align_center">Rule-based</td>
</tr>
<tr id="S3.T1.1.1.33.33" class="ltx_tr">
<th id="S3.T1.1.1.33.33.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.33.33.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Reverse List <cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite>
</th>
<td id="S3.T1.1.1.33.33.3" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.33.33.4" class="ltx_td ltx_align_center">List</td>
<td id="S3.T1.1.1.33.33.5" class="ltx_td ltx_align_center">Reversed List</td>
<td id="S3.T1.1.1.33.33.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.33.33.7" class="ltx_td ltx_align_center">Rule-based</td>
</tr>
<tr id="S3.T1.1.1.34.34" class="ltx_tr">
<th id="S3.T1.1.1.34.34.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.1.1.34.34.1.1" class="ltx_text">Symbolic</span></th>
<th id="S3.T1.1.1.34.34.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">BigBench <cite class="ltx_cite ltx_citemacro_cite">Srivastava et&nbsp;al. (<a href="#bib.bib136" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S3.T1.1.1.34.34.3" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.34.34.4" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.34.34.5" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.34.34.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.34.34.7" class="ltx_td ltx_align_center">Contains multiple symbolic reasoning datasets</td>
</tr>
<tr id="S3.T1.1.1.35.35" class="ltx_tr">
<th id="S3.T1.1.1.35.35.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.1.1.35.35.1.1" class="ltx_text">Reasoning</span></th>
<th id="S3.T1.1.1.35.35.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">BigBench-Hard
<cite class="ltx_cite ltx_citemacro_cite">Suzgun et&nbsp;al. (<a href="#bib.bib138" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S3.T1.1.1.35.35.3" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.35.35.4" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.35.35.5" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.35.35.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.35.35.7" class="ltx_td ltx_align_center">Contains multiple symbolic reasoning datasets</td>
</tr>
<tr id="S3.T1.1.1.36.36" class="ltx_tr">
<th id="S3.T1.1.1.36.36.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S3.T1.1.1.36.36.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ReClor <cite class="ltx_cite ltx_citemacro_cite">Yu et&nbsp;al. (<a href="#bib.bib182" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S3.T1.1.1.36.36.3" class="ltx_td ltx_align_center ltx_border_t">6,138</td>
<td id="S3.T1.1.1.36.36.4" class="ltx_td ltx_align_center ltx_border_t">Question+Context</td>
<td id="S3.T1.1.1.36.36.5" class="ltx_td ltx_align_center ltx_border_t">Option</td>
<td id="S3.T1.1.1.36.36.6" class="ltx_td ltx_align_center ltx_border_t">✗</td>
<td id="S3.T1.1.1.36.36.7" class="ltx_td ltx_align_center ltx_border_t">Questions from GMAT and LSAT</td>
</tr>
<tr id="S3.T1.1.1.37.37" class="ltx_tr">
<th id="S3.T1.1.1.37.37.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.37.37.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">LogiQA <cite class="ltx_cite ltx_citemacro_cite">Liu et&nbsp;al. (<a href="#bib.bib88" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S3.T1.1.1.37.37.3" class="ltx_td ltx_align_center">8,678</td>
<td id="S3.T1.1.1.37.37.4" class="ltx_td ltx_align_center">Question+Paragraph</td>
<td id="S3.T1.1.1.37.37.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.37.37.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.37.37.7" class="ltx_td ltx_align_center">Questions from China Civil Service Exam</td>
</tr>
<tr id="S3.T1.1.1.38.38" class="ltx_tr">
<th id="S3.T1.1.1.38.38.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.38.38.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">ProofWriter <cite class="ltx_cite ltx_citemacro_cite">Tafjord et&nbsp;al. (<a href="#bib.bib139" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.38.38.3" class="ltx_td ltx_align_center">20192</td>
<td id="S3.T1.1.1.38.38.4" class="ltx_td ltx_align_center">Question+Rule</td>
<td id="S3.T1.1.1.38.38.5" class="ltx_td ltx_align_center">Answer+Proof</td>
<td id="S3.T1.1.1.38.38.6" class="ltx_td ltx_align_center">Entailment Tree</td>
<td id="S3.T1.1.1.38.38.7" class="ltx_td ltx_align_center">Reasoning process generation</td>
</tr>
<tr id="S3.T1.1.1.39.39" class="ltx_tr">
<th id="S3.T1.1.1.39.39.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.39.39.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">FOLIO <cite class="ltx_cite ltx_citemacro_cite">Han et&nbsp;al. (<a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S3.T1.1.1.39.39.3" class="ltx_td ltx_align_center">1435</td>
<td id="S3.T1.1.1.39.39.4" class="ltx_td ltx_align_center">Conclusion+Premise</td>
<td id="S3.T1.1.1.39.39.5" class="ltx_td ltx_align_center">Yes/No</td>
<td id="S3.T1.1.1.39.39.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.39.39.7" class="ltx_td ltx_align_center">First-order logic</td>
</tr>
<tr id="S3.T1.1.1.40.40" class="ltx_tr">
<th id="S3.T1.1.1.40.40.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.1.1.40.40.1.1" class="ltx_text">Logical</span></th>
<th id="S3.T1.1.1.40.40.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">DEER <cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a href="#bib.bib170" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S3.T1.1.1.40.40.3" class="ltx_td ltx_align_center">1,200</td>
<td id="S3.T1.1.1.40.40.4" class="ltx_td ltx_align_center">Fact</td>
<td id="S3.T1.1.1.40.40.5" class="ltx_td ltx_align_center">Rule</td>
<td id="S3.T1.1.1.40.40.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.40.40.7" class="ltx_td ltx_align_center">Inductive reasoning</td>
</tr>
<tr id="S3.T1.1.1.41.41" class="ltx_tr">
<th id="S3.T1.1.1.41.41.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.1.1.41.41.1.1" class="ltx_text">Reasoning</span></th>
<th id="S3.T1.1.1.41.41.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PrOntoQA <cite class="ltx_cite ltx_citemacro_cite">Saparov and He (<a href="#bib.bib125" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S3.T1.1.1.41.41.3" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.1.1.41.41.4" class="ltx_td ltx_align_center">Question+Context</td>
<td id="S3.T1.1.1.41.41.5" class="ltx_td ltx_align_center">Yes/No+Proccess</td>
<td id="S3.T1.1.1.41.41.6" class="ltx_td ltx_align_center">First-Order Logic</td>
<td id="S3.T1.1.1.41.41.7" class="ltx_td ltx_align_center">Deductive reasoning</td>
</tr>
<tr id="S3.T1.1.1.42.42" class="ltx_tr">
<th id="S3.T1.1.1.42.42.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S3.T1.1.1.42.42.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">VCR <cite class="ltx_cite ltx_citemacro_cite">Zellers et&nbsp;al. (<a href="#bib.bib187" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S3.T1.1.1.42.42.3" class="ltx_td ltx_align_center ltx_border_t">264,720</td>
<td id="S3.T1.1.1.42.42.4" class="ltx_td ltx_align_center ltx_border_t">Question+Image</td>
<td id="S3.T1.1.1.42.42.5" class="ltx_td ltx_align_center ltx_border_t">Option</td>
<td id="S3.T1.1.1.42.42.6" class="ltx_td ltx_align_center ltx_border_t">Natural Language</td>
<td id="S3.T1.1.1.42.42.7" class="ltx_td ltx_align_center ltx_border_t">Visual commonsense reasoning</td>
</tr>
<tr id="S3.T1.1.1.43.43" class="ltx_tr">
<th id="S3.T1.1.1.43.43.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.43.43.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">VisualCOMET <cite class="ltx_cite ltx_citemacro_cite">Park et&nbsp;al. (<a href="#bib.bib113" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S3.T1.1.1.43.43.3" class="ltx_td ltx_align_center">1,465,704</td>
<td id="S3.T1.1.1.43.43.4" class="ltx_td ltx_align_center">Image+Event</td>
<td id="S3.T1.1.1.43.43.5" class="ltx_td ltx_align_center">Action+Intent</td>
<td id="S3.T1.1.1.43.43.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.43.43.7" class="ltx_td ltx_align_center">Visual commonsense reasoning</td>
</tr>
<tr id="S3.T1.1.1.44.44" class="ltx_tr">
<th id="S3.T1.1.1.44.44.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.44.44.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">PMR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Dong et&nbsp;al. (<a href="#bib.bib25" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S3.T1.1.1.44.44.3" class="ltx_td ltx_align_center">15,360</td>
<td id="S3.T1.1.1.44.44.4" class="ltx_td ltx_align_center">Image+Background</td>
<td id="S3.T1.1.1.44.44.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.44.44.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.44.44.7" class="ltx_td ltx_align_center">Premise-based multi-modal reasoning</td>
</tr>
<tr id="S3.T1.1.1.45.45" class="ltx_tr">
<th id="S3.T1.1.1.45.45.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.45.45.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">ScienceQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Lu et&nbsp;al. (<a href="#bib.bib91" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S3.T1.1.1.45.45.3" class="ltx_td ltx_align_center">21,208</td>
<td id="S3.T1.1.1.45.45.4" class="ltx_td ltx_align_center">Q+Image+Context</td>
<td id="S3.T1.1.1.45.45.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.45.45.6" class="ltx_td ltx_align_center">Natural Language</td>
<td id="S3.T1.1.1.45.45.7" class="ltx_td ltx_align_center">Multi-modal reasoning with NL rationales</td>
</tr>
<tr id="S3.T1.1.1.46.46" class="ltx_tr">
<th id="S3.T1.1.1.46.46.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.46.46.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">VLEP <cite class="ltx_cite ltx_citemacro_cite">Lei et&nbsp;al. (<a href="#bib.bib73" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S3.T1.1.1.46.46.3" class="ltx_td ltx_align_center">28,726</td>
<td id="S3.T1.1.1.46.46.4" class="ltx_td ltx_align_center">Premise+Video</td>
<td id="S3.T1.1.1.46.46.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.46.46.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.46.46.7" class="ltx_td ltx_align_center">Video event prediction</td>
</tr>
<tr id="S3.T1.1.1.47.47" class="ltx_tr">
<th id="S3.T1.1.1.47.47.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.47.47.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">CLEVRER <cite class="ltx_cite ltx_citemacro_cite">Yi et&nbsp;al. (<a href="#bib.bib178" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S3.T1.1.1.47.47.3" class="ltx_td ltx_align_center">305,280</td>
<td id="S3.T1.1.1.47.47.4" class="ltx_td ltx_align_center">Question+Video</td>
<td id="S3.T1.1.1.47.47.5" class="ltx_td ltx_align_center">Option/Free-form</td>
<td id="S3.T1.1.1.47.47.6" class="ltx_td ltx_align_center">Program</td>
<td id="S3.T1.1.1.47.47.7" class="ltx_td ltx_align_center">Video temporal and causal reasoning</td>
</tr>
<tr id="S3.T1.1.1.48.48" class="ltx_tr">
<th id="S3.T1.1.1.48.48.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.48.48.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">STAR <cite class="ltx_cite ltx_citemacro_cite">Wu et&nbsp;al. (<a href="#bib.bib163" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.48.48.3" class="ltx_td ltx_align_center">600,000</td>
<td id="S3.T1.1.1.48.48.4" class="ltx_td ltx_align_center">Question+Video</td>
<td id="S3.T1.1.1.48.48.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.48.48.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.48.48.7" class="ltx_td ltx_align_center">Video situated reasoning</td>
</tr>
<tr id="S3.T1.1.1.49.49" class="ltx_tr">
<th id="S3.T1.1.1.49.49.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T1.1.1.49.49.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">NEXT-QA <cite class="ltx_cite ltx_citemacro_cite">Xiao et&nbsp;al. (<a href="#bib.bib166" title="" class="ltx_ref">2021</a>)</cite>
</th>
<td id="S3.T1.1.1.49.49.3" class="ltx_td ltx_align_center">47,692</td>
<td id="S3.T1.1.1.49.49.4" class="ltx_td ltx_align_center">Question+Video</td>
<td id="S3.T1.1.1.49.49.5" class="ltx_td ltx_align_center">Option</td>
<td id="S3.T1.1.1.49.49.6" class="ltx_td ltx_align_center">✗</td>
<td id="S3.T1.1.1.49.49.7" class="ltx_td ltx_align_center">Video temporal,causal,commonsense reasoning</td>
</tr>
<tr id="S3.T1.1.1.50.50" class="ltx_tr">
<th id="S3.T1.1.1.50.50.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.1.1.50.50.1.1" class="ltx_text">Multimodal</span></th>
<th id="S3.T1.1.1.50.50.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Causal-VidQA <cite class="ltx_cite ltx_citemacro_cite">Li et&nbsp;al. (<a href="#bib.bib75" title="" class="ltx_ref">2022a</a>)</cite>
</th>
<td id="S3.T1.1.1.50.50.3" class="ltx_td ltx_align_center">107,600</td>
<td id="S3.T1.1.1.50.50.4" class="ltx_td ltx_align_center">Question+Video</td>
<td id="S3.T1.1.1.50.50.5" class="ltx_td ltx_align_center">Free-form</td>
<td id="S3.T1.1.1.50.50.6" class="ltx_td ltx_align_center">Natural Language</td>
<td id="S3.T1.1.1.50.50.7" class="ltx_td ltx_align_center">Video causal and commonsense reasoning</td>
</tr>
<tr id="S3.T1.1.1.51.51" class="ltx_tr">
<th id="S3.T1.1.1.51.51.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S3.T1.1.1.51.51.1.1" class="ltx_text">Reasoning</span></th>
<th id="S3.T1.1.1.51.51.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">News-KVQA <cite class="ltx_cite ltx_citemacro_cite">Gupta and Gupta (<a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S3.T1.1.1.51.51.3" class="ltx_td ltx_align_center ltx_border_bb">1,041,352</td>
<td id="S3.T1.1.1.51.51.4" class="ltx_td ltx_align_center ltx_border_bb">Q+V+KG</td>
<td id="S3.T1.1.1.51.51.5" class="ltx_td ltx_align_center ltx_border_bb">Option</td>
<td id="S3.T1.1.1.51.51.6" class="ltx_td ltx_align_center ltx_border_bb">✗</td>
<td id="S3.T1.1.1.51.51.7" class="ltx_td ltx_align_center ltx_border_bb">Video reasoning with external knowledge</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>An overview of benchmarks and tasks on reasoning. </figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Mathematical Reasoning</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Mathematical reasoning is often used to measure the reasoning power of a model.
Early benchmarks contain simple arithmetic operations&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hosseini et&nbsp;al. (<a href="#bib.bib44" title="" class="ltx_ref">2014</a>); Koncel-Kedziorski et&nbsp;al. (<a href="#bib.bib65" title="" class="ltx_ref">2015</a>); Roy and Roth (<a href="#bib.bib123" title="" class="ltx_ref">2015</a>); Koncel-Kedziorski et&nbsp;al. (<a href="#bib.bib66" title="" class="ltx_ref">2016</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Ling et&nbsp;al. (<a href="#bib.bib84" title="" class="ltx_ref">2017</a>)</cite> labels the reasoning process in natural language form, and <cite class="ltx_cite ltx_citemacro_citet">Amini et&nbsp;al. (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite> builds on AQUA by labeling the reasoning process in program form.
Later benchmarks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Miao et&nbsp;al., <a href="#bib.bib101" title="" class="ltx_ref">2020</a>; Patel et&nbsp;al., <a href="#bib.bib114" title="" class="ltx_ref">2021</a>; Cobbe et&nbsp;al., <a href="#bib.bib17" title="" class="ltx_ref">2021</a>; Gao et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite> contain more complex and diverse questions.
<cite class="ltx_cite ltx_citemacro_citep">(Zhu et&nbsp;al., <a href="#bib.bib207" title="" class="ltx_ref">2021</a>; Chen et&nbsp;al., <a href="#bib.bib14" title="" class="ltx_ref">2021</a>, <a href="#bib.bib15" title="" class="ltx_ref">2022b</a>)</cite> require reasoning based on the table content.
There are also general benchmarks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hendrycks et&nbsp;al. (<a href="#bib.bib42" title="" class="ltx_ref">2021</a>); Mishra et&nbsp;al. (<a href="#bib.bib103" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib104" title="" class="ltx_ref">b</a>)</cite> and reading comprehension form benchmarks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Dua et&nbsp;al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>); Chen et&nbsp;al. (<a href="#bib.bib13" title="" class="ltx_ref">2023</a>)</cite>. Recently, <cite class="ltx_cite ltx_citemacro_cite">Yu et&nbsp;al. (<a href="#bib.bib183" title="" class="ltx_ref">2021a</a>)</cite> endowed pre-trained model with the ability of mathematical reasoning by using hierarchical reasoning and knowledge.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Commonsense Reasoning</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Commonsense reasoning is the process of making inferences, judgments, and understandings based on knowledge that is generally known and commonly perceived in the everyday world.
How to acquire and understand commonsense knowledge is a major impediment to models facing commonsense reasoning.
Many benchmarks and tasks are proposed focusing on commonsense understanding&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Talmor et&nbsp;al., <a href="#bib.bib140" title="" class="ltx_ref">2019</a>, <a href="#bib.bib141" title="" class="ltx_ref">2021</a>; Bhakthavatsalam et&nbsp;al., <a href="#bib.bib6" title="" class="ltx_ref">2021</a>; Mihaylov et&nbsp;al., <a href="#bib.bib102" title="" class="ltx_ref">2018</a>; Geva et&nbsp;al., <a href="#bib.bib34" title="" class="ltx_ref">2021</a>; Huang et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2019</a>; Bisk et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>,
event temporal commonsense reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Rashkin et&nbsp;al., <a href="#bib.bib122" title="" class="ltx_ref">2018</a>; Zhou et&nbsp;al., <a href="#bib.bib204" title="" class="ltx_ref">2019</a>)</cite>
, and commonsense verification&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib148" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Symbolic Reasoning</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Symbolic reasoning here refers specifically to the simulation of some simple operations, which are simple for humans yet challenging for LLMs.
Last letter concatenation, coin flip, and reverse list&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite> are the most commonly used symbolic reasoning tasks.
In addition, the collaborative benchmark BigBench&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Srivastava et&nbsp;al., <a href="#bib.bib136" title="" class="ltx_ref">2022</a>)</cite> and BigBench-Hard&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Suzgun et&nbsp;al., <a href="#bib.bib138" title="" class="ltx_ref">2023</a>)</cite> also contain several symbolic reasoning datasets, such as state tracking and object counting.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Logical Reasoning</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Logical reasoning is divided into deductive reasoning, inductive reasoning, and abductive reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al., <a href="#bib.bib180" title="" class="ltx_ref">2023a</a>)</cite>.
Deductive reasoning derives conclusions from general premises&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a href="#bib.bib88" title="" class="ltx_ref">2020</a>; Yu et&nbsp;al., <a href="#bib.bib182" title="" class="ltx_ref">2020</a>; Tafjord et&nbsp;al., <a href="#bib.bib139" title="" class="ltx_ref">2021</a>; Han et&nbsp;al., <a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite>.
Inductive reasoning derives general conclusions from special cases&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a href="#bib.bib170" title="" class="ltx_ref">2022</a>)</cite>.
Abductive reasoning gives rational explanations for observed phenomena&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Saparov and He (<a href="#bib.bib125" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Multi-modal Reasoning</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">In the real world, reasoning also involves information in modalities other than text, with visual modalities being the most prevalent.
To this end, many benchmarks for visual multi-modal reasoning are proposed&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zellers et&nbsp;al., <a href="#bib.bib187" title="" class="ltx_ref">2019</a>; Park et&nbsp;al., <a href="#bib.bib113" title="" class="ltx_ref">2020</a>; Dong et&nbsp;al., <a href="#bib.bib25" title="" class="ltx_ref">2022</a>; Lu et&nbsp;al., <a href="#bib.bib91" title="" class="ltx_ref">2022</a>)</cite>, and among them, ScienceQA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lu et&nbsp;al., <a href="#bib.bib91" title="" class="ltx_ref">2022</a>)</cite> annotates reasoning process and is the most commonly used visual multi-modal reasoning benchmark.
Video multi-modal reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lei et&nbsp;al., <a href="#bib.bib73" title="" class="ltx_ref">2020</a>; Yi et&nbsp;al., <a href="#bib.bib178" title="" class="ltx_ref">2020</a>; Wu et&nbsp;al., <a href="#bib.bib163" title="" class="ltx_ref">2021</a>; Xiao et&nbsp;al., <a href="#bib.bib166" title="" class="ltx_ref">2021</a>; Li et&nbsp;al., <a href="#bib.bib75" title="" class="ltx_ref">2022a</a>; Gupta and Gupta, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite> is more challenging as it introduces additional temporal information compared to visual multi-modal reasoning.</p>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Metrics</h3>

<section id="S3.SS6.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Accuracy</h5>

<div id="S3.SS6.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS6.SSS0.Px1.p1.1" class="ltx_p">Accuracy is used to assess a model’s ability on classification tasks and is commonly used for multi-choice&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ling et&nbsp;al., <a href="#bib.bib84" title="" class="ltx_ref">2017</a>; Mihaylov et&nbsp;al., <a href="#bib.bib102" title="" class="ltx_ref">2018</a>; Liu et&nbsp;al., <a href="#bib.bib88" title="" class="ltx_ref">2020</a>; Lu et&nbsp;al., <a href="#bib.bib91" title="" class="ltx_ref">2022</a>)</cite> and yes/no&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Talmor et&nbsp;al., <a href="#bib.bib141" title="" class="ltx_ref">2021</a>; Geva et&nbsp;al., <a href="#bib.bib34" title="" class="ltx_ref">2021</a>; Han et&nbsp;al., <a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite> tasks.</p>
</div>
<div id="S3.SS6.SSS0.Px1.p2" class="ltx_para">
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.1" class="ltx_Math" alttext="\mathrm{Accuracy}=\frac{\mathrm{N_{correct}}}{\mathrm{N_{total}}}" display="block"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml"><mi id="S3.E7.m1.1.1.2" xref="S3.E7.m1.1.1.2.cmml">Accuracy</mi><mo id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.cmml">=</mo><mfrac id="S3.E7.m1.1.1.3" xref="S3.E7.m1.1.1.3.cmml"><msub id="S3.E7.m1.1.1.3.2" xref="S3.E7.m1.1.1.3.2.cmml"><mi mathvariant="normal" id="S3.E7.m1.1.1.3.2.2" xref="S3.E7.m1.1.1.3.2.2.cmml">N</mi><mi id="S3.E7.m1.1.1.3.2.3" xref="S3.E7.m1.1.1.3.2.3.cmml">correct</mi></msub><msub id="S3.E7.m1.1.1.3.3" xref="S3.E7.m1.1.1.3.3.cmml"><mi mathvariant="normal" id="S3.E7.m1.1.1.3.3.2" xref="S3.E7.m1.1.1.3.3.2.cmml">N</mi><mi id="S3.E7.m1.1.1.3.3.3" xref="S3.E7.m1.1.1.3.3.3.cmml">total</mi></msub></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1"><eq id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"></eq><ci id="S3.E7.m1.1.1.2.cmml" xref="S3.E7.m1.1.1.2">Accuracy</ci><apply id="S3.E7.m1.1.1.3.cmml" xref="S3.E7.m1.1.1.3"><divide id="S3.E7.m1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.3"></divide><apply id="S3.E7.m1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.3.2">subscript</csymbol><ci id="S3.E7.m1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.3.2.2">N</ci><ci id="S3.E7.m1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.3.2.3">correct</ci></apply><apply id="S3.E7.m1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.3.1.cmml" xref="S3.E7.m1.1.1.3.3">subscript</csymbol><ci id="S3.E7.m1.1.1.3.3.2.cmml" xref="S3.E7.m1.1.1.3.3.2">N</ci><ci id="S3.E7.m1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.3.3.3">total</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">\mathrm{Accuracy}=\frac{\mathrm{N_{correct}}}{\mathrm{N_{total}}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS6.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">EM and F1</h5>

<div id="S3.SS6.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS6.SSS0.Px2.p1.1" class="ltx_p">EM and F1 are metrics used to evaluate free form&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Mishra et&nbsp;al., <a href="#bib.bib103" title="" class="ltx_ref">2022a</a>; Wang et&nbsp;al., <a href="#bib.bib148" title="" class="ltx_ref">2019</a>; Yi et&nbsp;al., <a href="#bib.bib178" title="" class="ltx_ref">2020</a>)</cite> and span extraction&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dua et&nbsp;al., <a href="#bib.bib27" title="" class="ltx_ref">2019</a>; Zhu et&nbsp;al., <a href="#bib.bib207" title="" class="ltx_ref">2021</a>; Mishra et&nbsp;al., <a href="#bib.bib104" title="" class="ltx_ref">2022b</a>)</cite> tasks.
Both are calculated at the token level.</p>
<table id="S8.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E8.m1.1" class="ltx_Math" alttext="\displaystyle\mathrm{F1}=\frac{2\cdot\mathrm{P}\cdot\mathrm{R}}{\mathrm{P}+\mathrm{R}}" display="inline"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1" xref="S3.E8.m1.1.1.cmml"><mi id="S3.E8.m1.1.1.2" xref="S3.E8.m1.1.1.2.cmml">F1</mi><mo id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S3.E8.m1.1.1.3" xref="S3.E8.m1.1.1.3.cmml"><mfrac id="S3.E8.m1.1.1.3a" xref="S3.E8.m1.1.1.3.cmml"><mrow id="S3.E8.m1.1.1.3.2" xref="S3.E8.m1.1.1.3.2.cmml"><mn id="S3.E8.m1.1.1.3.2.2" xref="S3.E8.m1.1.1.3.2.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S3.E8.m1.1.1.3.2.1" xref="S3.E8.m1.1.1.3.2.1.cmml">⋅</mo><mi mathvariant="normal" id="S3.E8.m1.1.1.3.2.3" xref="S3.E8.m1.1.1.3.2.3.cmml">P</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E8.m1.1.1.3.2.1a" xref="S3.E8.m1.1.1.3.2.1.cmml">⋅</mo><mi mathvariant="normal" id="S3.E8.m1.1.1.3.2.4" xref="S3.E8.m1.1.1.3.2.4.cmml">R</mi></mrow><mrow id="S3.E8.m1.1.1.3.3" xref="S3.E8.m1.1.1.3.3.cmml"><mi mathvariant="normal" id="S3.E8.m1.1.1.3.3.2" xref="S3.E8.m1.1.1.3.3.2.cmml">P</mi><mo id="S3.E8.m1.1.1.3.3.1" xref="S3.E8.m1.1.1.3.3.1.cmml">+</mo><mi mathvariant="normal" id="S3.E8.m1.1.1.3.3.3" xref="S3.E8.m1.1.1.3.3.3.cmml">R</mi></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.cmml" xref="S3.E8.m1.1.1"><eq id="S3.E8.m1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"></eq><ci id="S3.E8.m1.1.1.2.cmml" xref="S3.E8.m1.1.1.2">F1</ci><apply id="S3.E8.m1.1.1.3.cmml" xref="S3.E8.m1.1.1.3"><divide id="S3.E8.m1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.3"></divide><apply id="S3.E8.m1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.3.2"><ci id="S3.E8.m1.1.1.3.2.1.cmml" xref="S3.E8.m1.1.1.3.2.1">⋅</ci><cn type="integer" id="S3.E8.m1.1.1.3.2.2.cmml" xref="S3.E8.m1.1.1.3.2.2">2</cn><ci id="S3.E8.m1.1.1.3.2.3.cmml" xref="S3.E8.m1.1.1.3.2.3">P</ci><ci id="S3.E8.m1.1.1.3.2.4.cmml" xref="S3.E8.m1.1.1.3.2.4">R</ci></apply><apply id="S3.E8.m1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.3.3"><plus id="S3.E8.m1.1.1.3.3.1.cmml" xref="S3.E8.m1.1.1.3.3.1"></plus><ci id="S3.E8.m1.1.1.3.3.2.cmml" xref="S3.E8.m1.1.1.3.3.2">P</ci><ci id="S3.E8.m1.1.1.3.3.3.cmml" xref="S3.E8.m1.1.1.3.3.3">R</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">\displaystyle\mathrm{F1}=\frac{2\cdot\mathrm{P}\cdot\mathrm{R}}{\mathrm{P}+\mathrm{R}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
<tbody id="S3.E9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E9.m1.1" class="ltx_Math" alttext="\displaystyle\mathrm{EM}=\frac{\sum\mathbb{I}[A=A^{\prime}]}{\mathrm{N_{total}}}" display="inline"><semantics id="S3.E9.m1.1a"><mrow id="S3.E9.m1.1.2" xref="S3.E9.m1.1.2.cmml"><mi id="S3.E9.m1.1.2.2" xref="S3.E9.m1.1.2.2.cmml">EM</mi><mo id="S3.E9.m1.1.2.1" xref="S3.E9.m1.1.2.1.cmml">=</mo><mstyle displaystyle="true" id="S3.E9.m1.1.1" xref="S3.E9.m1.1.1.cmml"><mfrac id="S3.E9.m1.1.1a" xref="S3.E9.m1.1.1.cmml"><mrow id="S3.E9.m1.1.1.1" xref="S3.E9.m1.1.1.1.cmml"><mo id="S3.E9.m1.1.1.1.2" xref="S3.E9.m1.1.1.1.2.cmml">∑</mo><mrow id="S3.E9.m1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml"><mi id="S3.E9.m1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.3.cmml">𝕀</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E9.m1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E9.m1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E9.m1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E9.m1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.1.2.cmml">A</mi><mo id="S3.E9.m1.1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.cmml">=</mo><msup id="S3.E9.m1.1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E9.m1.1.1.1.1.1.1.1.3.2" xref="S3.E9.m1.1.1.1.1.1.1.1.3.2.cmml">A</mi><mo id="S3.E9.m1.1.1.1.1.1.1.1.3.3" xref="S3.E9.m1.1.1.1.1.1.1.1.3.3.cmml">′</mo></msup></mrow><mo stretchy="false" id="S3.E9.m1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><msub id="S3.E9.m1.1.1.3" xref="S3.E9.m1.1.1.3.cmml"><mi mathvariant="normal" id="S3.E9.m1.1.1.3.2" xref="S3.E9.m1.1.1.3.2.cmml">N</mi><mi id="S3.E9.m1.1.1.3.3" xref="S3.E9.m1.1.1.3.3.cmml">total</mi></msub></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.1b"><apply id="S3.E9.m1.1.2.cmml" xref="S3.E9.m1.1.2"><eq id="S3.E9.m1.1.2.1.cmml" xref="S3.E9.m1.1.2.1"></eq><ci id="S3.E9.m1.1.2.2.cmml" xref="S3.E9.m1.1.2.2">EM</ci><apply id="S3.E9.m1.1.1.cmml" xref="S3.E9.m1.1.1"><divide id="S3.E9.m1.1.1.2.cmml" xref="S3.E9.m1.1.1"></divide><apply id="S3.E9.m1.1.1.1.cmml" xref="S3.E9.m1.1.1.1"><sum id="S3.E9.m1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.2"></sum><apply id="S3.E9.m1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1"><times id="S3.E9.m1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.2"></times><ci id="S3.E9.m1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.3">𝕀</ci><apply id="S3.E9.m1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E9.m1.1.1.1.1.1.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E9.m1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1"><eq id="S3.E9.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1"></eq><ci id="S3.E9.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.2">𝐴</ci><apply id="S3.E9.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.3.2">𝐴</ci><ci id="S3.E9.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.3.3">′</ci></apply></apply></apply></apply></apply><apply id="S3.E9.m1.1.1.3.cmml" xref="S3.E9.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.3.1.cmml" xref="S3.E9.m1.1.1.3">subscript</csymbol><ci id="S3.E9.m1.1.1.3.2.cmml" xref="S3.E9.m1.1.1.3.2">N</ci><ci id="S3.E9.m1.1.1.3.3.cmml" xref="S3.E9.m1.1.1.3.3">total</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.1c">\displaystyle\mathrm{EM}=\frac{\sum\mathbb{I}[A=A^{\prime}]}{\mathrm{N_{total}}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S3.SS6.SSS0.Px2.p1.2" class="ltx_p">where P and R stand for precision and recall, and EM calculates the proportion of predictions and answers that are exactly the same.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methods</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we explore X-of-thought reasoning through three different categorizations:
the construction of X-of-thought&nbsp;(§<a href="#S4.SS1" title="4.1 Construction Approach ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>),
the structural variants of X-of-thought&nbsp;(§<a href="#S4.SS2" title="4.2 XoT Structural Variants ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>),
and the enhanced methods of X-of-thought&nbsp;(§<a href="#S4.SS3" title="4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).</p>
</div>
<figure id="S4.F1" class="ltx_figure">
<div id="S4.F1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:514.6pt;vertical-align:-510.1pt;"><span class="ltx_transformed_inner" style="transform:translate(-121.1pt,1.2pt) scale(0.6415635648267,0.6415635648267) ;"><span id="S4.F1.1.1" class="ltx_ERROR undefined">{forest}</span>
<p id="S4.F1.1.2" class="ltx_p">forked edges,
for tree=
grow=east,
reversed=true,
anchor=base west,
parent anchor=east,
child anchor=west,
base=left,
font=,
rectangle,
draw=hidden-black,
rounded corners,
align=left,
minimum width=4em,
edge+=darkgray, line width=1pt,
s sep=3pt,
inner xsep=2pt,
inner ysep=3pt,
line width=0.8pt,
ver/.style=rotate=90, child anchor=north, parent anchor=south, anchor=center,
,
where level=1text width=7em,font=,,
where level=2text width=8.5em,font=,,
where level=3text width=10.5em,font=,,
where level=4text width=12em,font=,,
[
A survey of X-of-Thought, ver
[
Methods &nbsp;(§<a href="#S4" title="4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>)
[
XoT 
<br class="ltx_break">Construction &nbsp;(§<a href="#S4.SS1" title="4.1 Construction Approach ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>)
[
Manual XoT
[
E.g.,&nbsp;
Few-shot CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite> ,
PoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2022a</a>)</cite>
, leaf, text width=32.5em
]
]
[
Automatic XoT
[
E.g.,&nbsp;
Zero-shot CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Kojima et&nbsp;al. (<a href="#bib.bib64" title="" class="ltx_ref">2022</a>)</cite>,
Auto-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a href="#bib.bib196" title="" class="ltx_ref">2023f</a>)</cite>
, leaf, text width=32.5em
]
]
[
Semi-automatic XoT&nbsp;
[
E.g.,&nbsp;
AutoMate CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Shum et&nbsp;al. (<a href="#bib.bib135" title="" class="ltx_ref">2023</a>)</cite>,
BoostedPrompt &nbsp;<cite class="ltx_cite ltx_citemacro_cite">Pitis et&nbsp;al. (<a href="#bib.bib117" title="" class="ltx_ref">2023</a>)</cite>
, leaf, text width=32.5em
]
]
]
[
XoT Structural 
<br class="ltx_break">Variants&nbsp;(§<a href="#S4.SS2" title="4.2 XoT Structural Variants ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>)
[
E.g.,&nbsp;
AoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Sel et&nbsp;al., <a href="#bib.bib129" title="" class="ltx_ref">2023</a>)</cite>,
ToT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al., <a href="#bib.bib172" title="" class="ltx_ref">2023b</a>)</cite>,
SoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ning et&nbsp;al., <a href="#bib.bib107" title="" class="ltx_ref">2023</a>)</cite>,
GoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lei et&nbsp;al., <a href="#bib.bib71" title="" class="ltx_ref">2023a</a>)</cite>
, leaf, text width=44.6em
]
]
[
XoT Enhancement 
<br class="ltx_break">Methods&nbsp;(§<a href="#S4.SS3" title="4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>)
[
Verify and Refine
[
E.g.,&nbsp;
VerifyCoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Ling et&nbsp;al. (<a href="#bib.bib85" title="" class="ltx_ref">2023</a>)</cite>,
Self-Refine&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Madaan et&nbsp;al. (<a href="#bib.bib95" title="" class="ltx_ref">2023</a>)</cite>
, leaf, text width=32.5em
]
]
[
Question Decompose
[
E.g.,&nbsp;
Least-to-Most Prompting&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhou et&nbsp;al. (<a href="#bib.bib205" title="" class="ltx_ref">2023b</a>)</cite>
, leaf, text width=32.5em
]
]
[
External Knowledge
[
E.g.,&nbsp;
CoK&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib149" title="" class="ltx_ref">2023b</a>)</cite>,
KD-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib150" title="" class="ltx_ref">2023c</a>)</cite>
, leaf, text width=32.5em
]
]
[
Vote and Rank
[
E.g.,&nbsp;
Verifiers&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Cobbe et&nbsp;al. (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>,
Self-Consistency&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib158" title="" class="ltx_ref">2023j</a>)</cite>
, leaf, text width=32.5em
]
]
[
Efficiency
[
E.g.,&nbsp;
SoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Ning et&nbsp;al. (<a href="#bib.bib107" title="" class="ltx_ref">2023</a>)</cite>,
ActivePrompting&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Diao et&nbsp;al. (<a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite>
, leaf, text width=32.5em
]
]
]
]
[
Frontier 
<br class="ltx_break">Application &nbsp;(§<a href="#S5" title="5 Frontier Application ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>)
[
Tool Using&nbsp;(§<a href="#S5.SS1" title="5.1 Tool Use ‣ 5 Frontier Application ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>)
[
E.g.,&nbsp;
MRKL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Karpas et&nbsp;al. (<a href="#bib.bib60" title="" class="ltx_ref">2022</a>)</cite>,
TAML&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Parisi et&nbsp;al. (<a href="#bib.bib111" title="" class="ltx_ref">2022a</a>)</cite>,
Toolformer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Schick et&nbsp;al. (<a href="#bib.bib128" title="" class="ltx_ref">2023</a>)</cite>
, leaf, text width=44.6em
]
]
[
Planning&nbsp;(§<a href="#S5.SS2" title="5.2 Planning ‣ 5 Frontier Application ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>)
[
E.g.,&nbsp;
ToT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Long (<a href="#bib.bib89" title="" class="ltx_ref">2023</a>)</cite>,
ReAct&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yao et&nbsp;al. (<a href="#bib.bib173" title="" class="ltx_ref">2023c</a>)</cite>,
Reflexion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Shinn et&nbsp;al. (<a href="#bib.bib133" title="" class="ltx_ref">2023</a>)</cite>
, leaf, text width=44.6em
]
]
[
Distillation&nbsp;(§<a href="#S5.SS3" title="5.3 CoT Distillation ‣ 5 Frontier Application ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>)
[
E.g.,&nbsp;
STaR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zelikman et&nbsp;al. (<a href="#bib.bib186" title="" class="ltx_ref">2022</a>)</cite>,
SCoTD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Li et&nbsp;al. (<a href="#bib.bib77" title="" class="ltx_ref">2023b</a>)</cite>,
SCOTT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib155" title="" class="ltx_ref">2023h</a>)</cite>
, leaf, text width=44.6em
]
]
]
[
Future 
<br class="ltx_break">Directions &nbsp;(§<a href="#S6" title="6 Future Directions ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>)
[
Multi-modal&nbsp;(§<a href="#S6.SS1" title="6.1 Multi-modal CoT ‣ 6 Future Directions ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>)
[
E.g.,&nbsp;
MMCoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a href="#bib.bib197" title="" class="ltx_ref">2023g</a>)</cite>,
T-SciQ&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib151" title="" class="ltx_ref">2023d</a>)</cite>,
ToMT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hu et&nbsp;al. (<a href="#bib.bib47" title="" class="ltx_ref">2023b</a>)</cite>
, leaf, text width=44.6em
]
]
[
Faithfulness&nbsp;(§<a href="#S6.SS2" title="6.2 Faithfulness ‣ 6 Future Directions ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>)
[
E.g.,&nbsp;
Rethinking and Retrievaling&nbsp;<cite class="ltx_cite ltx_citemacro_cite">He et&nbsp;al. (<a href="#bib.bib40" title="" class="ltx_ref">2023a</a>)</cite>,
Measure Faithful&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Lanham et&nbsp;al. (<a href="#bib.bib69" title="" class="ltx_ref">2023</a>)</cite>
, leaf, text width=44.6em
]
]
[
CoT Theory&nbsp;(§<a href="#S6.SS3" title="6.3 CoT Theory ‣ 6 Future Directions ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a>)
[
E.g.,&nbsp;
Tang&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Tang et&nbsp;al. (<a href="#bib.bib142" title="" class="ltx_ref">2023</a>)</cite>,
Li&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Li et&nbsp;al. (<a href="#bib.bib83" title="" class="ltx_ref">2023e</a>)</cite>,
Feng&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Feng et&nbsp;al. (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>,
Wu&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wu et&nbsp;al. (<a href="#bib.bib164" title="" class="ltx_ref">2023</a>)</cite>
, leaf, text width=44.6em
]
]
]
[
Benchmarks&nbsp;(§<a href="#S3" title="3 Benchmarks ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>)
[
Mathematical 
<br class="ltx_break">Reasoning&nbsp;(§<a href="#S3.SS1" title="3.1 Mathematical Reasoning ‣ 3 Benchmarks ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>)
[
E.g.,&nbsp;
MultiArith&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Roy and Roth (<a href="#bib.bib123" title="" class="ltx_ref">2015</a>)</cite>,
AQUA-RAT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Ling et&nbsp;al. (<a href="#bib.bib84" title="" class="ltx_ref">2017</a>)</cite>,
SVAMP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Patel et&nbsp;al. (<a href="#bib.bib114" title="" class="ltx_ref">2021</a>)</cite>,

<br class="ltx_break">GSM8K&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Cobbe et&nbsp;al. (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>,
DROP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Dua et&nbsp;al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>,
LILA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Mishra et&nbsp;al. (<a href="#bib.bib103" title="" class="ltx_ref">2022a</a>)</cite>
, leaf, text width=44.6em
]
]
[
Commonsense 
<br class="ltx_break">Reasoning&nbsp;(§<a href="#S3.SS2" title="3.2 Commonsense Reasoning ‣ 3 Benchmarks ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>)
[
E.g.,&nbsp;
CSQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Talmor et&nbsp;al. (<a href="#bib.bib140" title="" class="ltx_ref">2019</a>)</cite>,
ARC&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Bhakthavatsalam et&nbsp;al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite>,
PIQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Bisk et&nbsp;al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>,

<br class="ltx_break">McTaco&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhou et&nbsp;al. (<a href="#bib.bib204" title="" class="ltx_ref">2019</a>)</cite>,
CosmosQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Huang et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2019</a>)</cite>,
StrategyQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Geva et&nbsp;al. (<a href="#bib.bib34" title="" class="ltx_ref">2021</a>)</cite>
, leaf, text width=44.6em
]
]
[
Symbolic 
<br class="ltx_break">Reasoning&nbsp;(§<a href="#S3.SS3" title="3.3 Symbolic Reasoning ‣ 3 Benchmarks ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>)
[
E.g.,&nbsp;
Last Letter Concat.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite>,
Coin Flip&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite>,
Reverse List&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite>

<br class="ltx_break">BigBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Srivastava et&nbsp;al. (<a href="#bib.bib136" title="" class="ltx_ref">2022</a>)</cite>,
BigBench-Hard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Suzgun et&nbsp;al. (<a href="#bib.bib138" title="" class="ltx_ref">2023</a>)</cite>
, leaf, text width=44.6em
]
]
[
Logical 
<br class="ltx_break">Reasoning&nbsp;(§<a href="#S3.SS4" title="3.4 Logical Reasoning ‣ 3 Benchmarks ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>)
[
E.g.,&nbsp;
ReClor&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yu et&nbsp;al. (<a href="#bib.bib182" title="" class="ltx_ref">2020</a>)</cite>,
LogiQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Liu et&nbsp;al. (<a href="#bib.bib88" title="" class="ltx_ref">2020</a>)</cite>,
ProofWriter&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Tafjord et&nbsp;al. (<a href="#bib.bib139" title="" class="ltx_ref">2021</a>)</cite>,

<br class="ltx_break">FOLIO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Han et&nbsp;al. (<a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite>,
PrOntoQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Saparov and He (<a href="#bib.bib125" title="" class="ltx_ref">2023</a>)</cite>
, leaf, text width=44.6em
]
]
[
Multi-modal 
<br class="ltx_break">Reasoning&nbsp;(§<a href="#S3.SS5" title="3.5 Multi-modal Reasoning ‣ 3 Benchmarks ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a>)
[
Image:
ScienceQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Lu et&nbsp;al. (<a href="#bib.bib91" title="" class="ltx_ref">2022</a>)</cite>,
VCR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zellers et&nbsp;al. (<a href="#bib.bib187" title="" class="ltx_ref">2019</a>)</cite>,
VisualCOMET&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Park et&nbsp;al. (<a href="#bib.bib113" title="" class="ltx_ref">2020</a>)</cite>

<br class="ltx_break">Video:
CLEVRER&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Yi et&nbsp;al. (<a href="#bib.bib178" title="" class="ltx_ref">2020</a>)</cite>,
STAR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wu et&nbsp;al. (<a href="#bib.bib163" title="" class="ltx_ref">2021</a>)</cite>,
NExT-QA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Xiao et&nbsp;al. (<a href="#bib.bib166" title="" class="ltx_ref">2021</a>)</cite>
, leaf, text width=44.6em
]
]
]
]

</p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>XoT Methods, Frontier Application, Future Direction, and Benchmarks.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Construction Approach</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">After thorough analysis, we divide the construction of X-of-thought into three categories: 1) Manual XoT, 2) Automatic XoT, and 3) Semi-automatic XoT, described as follows.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Manual XoT</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">While large language models perform few-shot in-context learning via prompting, they are still limited in reasoning tasks.
In order to explore the potential reasoning ability of large language models, one standard approach is to provide different forms of thoughts in demonstrations.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Wei et&nbsp;al. (<a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite> first propose chain-of-thought prompting (Few-shot CoT) by manually providing natural language form rationales to the demonstrations.
To further ensure certainty in the reasoning process and reduce inconsistencies between reasoning path and answers, PAL&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite>, PoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2022a</a>)</cite> and NLEP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a href="#bib.bib194" title="" class="ltx_ref">2023e</a>)</cite> leverage programming language as annotated rationales, which transforms the problem-solving into an executable Python program.
Meanwhile, to take both advantages of natural language and programming language and raise the confidence of reasoning output, MathPrompter&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Imani et&nbsp;al., <a href="#bib.bib53" title="" class="ltx_ref">2023</a>)</cite> uses the zero-shot chain-of-thought prompting to generate multiple algebraic expressions or Python functions, which can verify each other and improve the reliability of results.
Furthermore, since the reasoning complexity of samples in demonstrations, such as chains with more reasoning steps, results in performance improvement, &nbsp;<cite class="ltx_cite ltx_citemacro_citet">Fu et&nbsp;al. (<a href="#bib.bib30" title="" class="ltx_ref">2023a</a>)</cite> proposes complexity-based prompting, where voting among high-complexity rationales is performed to get the final answer.</p>
</div>
<div id="S4.SS1.SSS1.p3" class="ltx_para">
<p id="S4.SS1.SSS1.p3.1" class="ltx_p">Manually constructed X-of-thought methods expand on in-context learning by adding different types of step-by-step intermediate reasoning processes to demonstrations. They allow LLMs to mimic and generate reasoning paths.
Although manual XoT methods provide greater interpretability as well as trustworthiness for human understanding and outperform on complex tasks, i.e., mathematical reasoning, commonsense reasoning, symbolic reasoning, etc., manual annotating of rationales entails significant costs and suffers from drawbacks such as difficulty in demonstration selection and task generalization.
Specifically, different tasks require different ways of demonstrations. Therefore, other works attempt to construct the reasoning path automatically, as discussed in &nbsp;§<a href="#S4.SS1.SSS2" title="4.1.2 Automatic XoT ‣ 4.1 Construction Approach ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1.2</span></a>.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Automatic XoT</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">Chain-of-thought prompting&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a href="#bib.bib161" title="" class="ltx_ref">2022b</a>)</cite> elicits the complex reasoning ability of LLMs with task-specific exemplars in a few-shot setting, which limits the scalability and generalization.
To reduce the cost of hand-crafted few-shot exemplars, &nbsp;<cite class="ltx_cite ltx_citemacro_citet">Kojima et&nbsp;al. (<a href="#bib.bib64" title="" class="ltx_ref">2022</a>)</cite> proposes zero-shot CoT by introducing a magic phrase <span id="S4.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_italic">Let’s think step by step</span> after question, which enables LLMs to generate reasoning chains in a zero-shot manner.
However, zero-shot CoT suffers from poor-quality reasoning paths, coming with many mistakes.
Since the diversity of demonstration plays a vital role in reasoning chains generation, Auto-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a href="#bib.bib196" title="" class="ltx_ref">2023f</a>)</cite> generates the demonstrations automatically via clustering and representative exemplars selection, which improves the diversity and consistently matches or exceeds the performance of Few-shot CoT.
COSP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wan et&nbsp;al., <a href="#bib.bib145" title="" class="ltx_ref">2023</a>)</cite> introduces the outcome entropy of the question to aid demonstration selection.
&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a href="#bib.bib167" title="" class="ltx_ref">2023</a>)</cite> proposes Reprompting to find the effective CoT prompt by employing Gibbs sampling iteratively.
Meanwhile, some mistakes in reasoning chains come from missing-step errors, <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib153" title="" class="ltx_ref">2023f</a>)</cite> extend the zero-shot CoT into Plan-and-Solve (PS) Prompting via devising a plan to divide the entire task into smaller sub-tasks and carrying out the sub-tasks according to the plan with more detailed instructions.
LogiCoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhao et&nbsp;al., <a href="#bib.bib201" title="" class="ltx_ref">2023c</a>)</cite> uses symbolic logic to validate the zero-shot reasoning process, thus reducing errors in reasoning.
Besides, PoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2022a</a>)</cite> also explore language models, such as Codex, to generate an executable Python program to solve math problems in zero-shot setting via adding <span id="S4.SS1.SSS2.p1.1.2" class="ltx_text ltx_font_italic">Let’s write a Python program step by step…</span>, which mitigates errors in intermediate reasoning steps.
Some work introduces agents to solve reasoning problems. For example, Agent Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Crispino et&nbsp;al., <a href="#bib.bib18" title="" class="ltx_ref">2023a</a>)</cite> utilizes agents to generate task-related, informative instructions, which guides LLMs to perform zero-shot reasoning.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p">Unlike manual XoT, automatic XoT, using zero-shot prompt engineering or sampling, is scalable and can be generalized between domains without human intervention. However, due to the lack of human alignment, automatically generated chain-of-thought encounters challenges such as poor quality, hallucinations, and factual inconsistencies. Therefore, constructing XoT in a semi-automatic way is necessary, which is introduced in &nbsp;§<a href="#S4.SS1.SSS3" title="4.1.3 Semi-automatic XoT ‣ 4.1 Construction Approach ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1.3</span></a>.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Semi-automatic XoT</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">Semi-automatic XoT methods integrate the advantages of both manual and automatic construction methods.
<cite class="ltx_cite ltx_citemacro_citet">Shao et&nbsp;al. (<a href="#bib.bib130" title="" class="ltx_ref">2023</a>)</cite> proposes Synthetic Prompting, which leverages a few human-annotated examples to prompt models to generate more examples through an alternated forward-backward process and selects effective demonstrations to elicit better reasoning, alleviating the lack of human alignment in AutoCoT.
Although previous work solves the problem of manual annotating, demonstration selection can also significantly affect performance.
Automate-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shum et&nbsp;al., <a href="#bib.bib135" title="" class="ltx_ref">2023</a>)</cite> employs reinforcement learning with a variance-reduced policy gradient strategy to estimate the significance of each example in a black-box language model, eliciting better demonstration selection.
Similarly, <cite class="ltx_cite ltx_citemacro_citet">Lu et&nbsp;al. (<a href="#bib.bib92" title="" class="ltx_ref">2023b</a>)</cite> proposes PromptPG, which utilizes policy gradient to learn to select demonstrations in tabular reasoning.
<cite class="ltx_cite ltx_citemacro_citet">Ye and Durrett (<a href="#bib.bib176" title="" class="ltx_ref">2023</a>)</cite> initially uses two proxy metrics to evaluate each example and then searches over examples to find demonstrations that yield the best performance in a silver-labeled development set.
Meanwhile, <cite class="ltx_cite ltx_citemacro_citet">Pitis et&nbsp;al. (<a href="#bib.bib117" title="" class="ltx_ref">2023</a>)</cite> proposes Boosted Prompting, a prompt ensembling way to improve the performance, which iteratively expands the examples when encountering the problem that the current demonstration is challenging to handle.
<cite class="ltx_cite ltx_citemacro_citet">Zou et&nbsp;al. (<a href="#bib.bib208" title="" class="ltx_ref">2023</a>)</cite> introduce Meta-CoT, which automatically selects demonstrations based on the question category, eliminating the need for the task-specific prompt design.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2309.15402/assets/x1.png" id="S4.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="173" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
The evolution of reasoning, from direct I/O to chain structure, then to tree and graph structure.</figcaption>
</figure>
<div id="S4.SS1.SSS3.p2" class="ltx_para">
<p id="S4.SS1.SSS3.p2.1" class="ltx_p">The semi-automatic XoT methods reduce the workload of manual labeling while introducing human alignment signals and demonstration selection strategies to enhance the capability and stability of reasoning.
Additionally, it enables cost-effective domain generalization.
However, the demonstration selection problem has not been entirely resolved and requires more effort and research.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>XoT Structural Variants</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The most primitive chain-of-thought is a chain structure that describes intermediate reasoning steps in natural language.
In this section, we introduce structural variants that modify the original chain structure, including chain structure variants, tree structure variants, and graph structure variants.</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Chain Structure</h5>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">PAL&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite> and PoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2022a</a>)</cite> introduce programming languages to describe the reasoning process, thereby converting the reasoning problem into the implementation of an executable program to obtain the final answer.
Since the program execution is deterministic and performs arithmetic computations accurately, this approach shows excellent performance in mathematical reasoning.
Besides, symbol sequence is another type of thought representation.
Chain-of-Symbol&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hu et&nbsp;al., <a href="#bib.bib46" title="" class="ltx_ref">2023a</a>)</cite> represents the complex environments with condensed symbolic chain representations during planning, which reduces the complexity of the simulation environment.
Chain structure variants are shown in Figure&nbsp;<a href="#S4.F2" title="Figure 2 ‣ 4.1.3 Semi-automatic XoT ‣ 4.1 Construction Approach ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(c,d)
Algorithm of Thought&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Sel et&nbsp;al., <a href="#bib.bib129" title="" class="ltx_ref">2023</a>)</cite> injects algorithmic capabilities into the model, making the model’s reasoning more logical by adding examples based on algorithms.
Its absence of the huge search space of tree search&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Long, <a href="#bib.bib89" title="" class="ltx_ref">2023</a>; Yao et&nbsp;al., <a href="#bib.bib172" title="" class="ltx_ref">2023b</a>)</cite> saves computational resources and achieves excellent performance.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Tree Structure</h5>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.1" class="ltx_p">The original chain structure inherently limits the scope of exploration.
Through the incorporation of tree structures and tree search algorithms, models gain the capability to efficiently explore and backtrack during the reasoning process&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Long, <a href="#bib.bib89" title="" class="ltx_ref">2023</a>; Yao et&nbsp;al., <a href="#bib.bib172" title="" class="ltx_ref">2023b</a>)</cite>, as shown in Figure&nbsp;<a href="#S4.F2" title="Figure 2 ‣ 4.1.3 Semi-automatic XoT ‣ 4.1 Construction Approach ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(e).
Combined with self-assessment of intermediate thoughts, models can achieve global optimum solutions.
The reasoning process of ToT involves uncertainty, which can potentially lead to cascading errors. TouT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Mo and Xin, <a href="#bib.bib105" title="" class="ltx_ref">2023</a>)</cite> introduces Monte Carlo Dropout in reasoning, taking into account the uncertainty.
<cite class="ltx_cite ltx_citemacro_citet">Yu et&nbsp;al. (<a href="#bib.bib181" title="" class="ltx_ref">2023b</a>)</cite> delves into analogous problems, harnessing their solutions to elevate the intricate reasoning abilities of LLMs.
These analogous problems exhibit a tree-like structure, ultimately converging to solve the main problem.
However, the current tree-of-thought has considerable limitations on task selection and requires specific prompt designing for each task, which hinders its widespread application.
SoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ning et&nbsp;al., <a href="#bib.bib107" title="" class="ltx_ref">2023</a>)</cite> is another variant of the tree structure, which decomposes a problem into subproblems that can be processed in parallel and solved simultaneously to speed up reasoning.
However, its utility is restricted to parallel decomposable problems and is not suited for complex reasoning tasks.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Graph Structure</h5>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p1.1" class="ltx_p">Compared to trees, graphs introduce loops and rings, which bring more complex topological relationships and allow for modeling more complex reasoning, as shown in Figure&nbsp;<a href="#S4.F2" title="Figure 2 ‣ 4.1.3 Semi-automatic XoT ‣ 4.1 Construction Approach ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(f).
GoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Besta et&nbsp;al., <a href="#bib.bib5" title="" class="ltx_ref">2023</a>; Lei et&nbsp;al., <a href="#bib.bib71" title="" class="ltx_ref">2023a</a>)</cite> regards intermediate thought as nodes within a graph, combining exploration and backtracking operations, and additionally introduces aggregation and refinement operations compared to tree-of-thought.
The additional operations, aggregation and refinement elicit better reasoning in complex tasks.
Nevertheless, it faces the same dilemmas as the tree-of-thought, i.e., task limitations and poor generalizability.
Besides, it has increased reasoning costs.
Unlike GoT, which explicitly constructs a thought graph, ResPrompt&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a href="#bib.bib55" title="" class="ltx_ref">2023a</a>)</cite> introduces residual connections between thoughts in the prompt text, allowing the reasoning of different steps to interact with each other.</p>
</div>
<div id="S4.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p2.1" class="ltx_p">As models transition from linear chains to hierarchical trees and intricate graphs, the interplay of thoughts becomes progressively more complex, thereby gradually enhancing the capacity to address intricate problems.
However, as the complexity of the topology increases, associated methods impose more constraints on task selection, leading to a significant reduction in their generalizability and making their application difficult.
Extending complex topology structure-based methods to general domains is a major challenge for future research.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>XoT Enhancement Methods</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In this section, we present the XoT enhancement methods.
In total, we will provide an overview of five categories, which are
adding verification and refinement&nbsp;(§<a href="#S4.SS3.SSS1" title="4.3.1 Verify and Refine ‣ 4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.1</span></a>),
question decomposition&nbsp;(§<a href="#S4.SS3.SSS2" title="4.3.2 Question Decomposition ‣ 4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.2</span></a>),
leveraging external knowledge&nbsp;(§<a href="#S4.SS3.SSS3" title="4.3.3 External Knowledge ‣ 4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.3</span></a>),
voting and ranking&nbsp;(§<a href="#S4.SS3.SSS4" title="4.3.4 Vote and Rank ‣ 4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.4</span></a>),
and improving efficiency&nbsp;(§<a href="#S4.SS3.SSS5" title="4.3.5 Efficiency ‣ 4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.5</span></a>).</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2309.15402/assets/x2.png" id="S4.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="227" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>
Verification and refinement reduce cascading errors in reasoning.</figcaption>
</figure>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Verify and Refine</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">Chain-of-thought reasoning often tends to be hallucinatory, producing incorrect reasoning steps. Errors in intermediate reasoning steps can, in turn, trigger a cascade of errors.
Incorporating verification to obtain feedback and subsequently refining the reasoning process based on this feedback can be a highly effective strategy for mitigating this phenomenon, which is similar to the process of human reflection.
Figure&nbsp;<a href="#S4.F3" title="Figure 3 ‣ 4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> depicts the overview of verification and refinement.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p">VerifyCoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ling et&nbsp;al., <a href="#bib.bib85" title="" class="ltx_ref">2023</a>)</cite> devises a Natural Program, a deductive reasoning form, which allows models to produce accurate reasoning steps, with each subsequent step strictly based on the previous steps.
<span id="S4.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_smallcaps">DiVeRSe</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a href="#bib.bib82" title="" class="ltx_ref">2022c</a>)</cite> utilizes a voting mechanism to eliminate incorrect answers, followed by a fine-grained verification of each reasoning step independently.
SCREWS<cite class="ltx_cite ltx_citemacro_citep">(Shridhar et&nbsp;al., <a href="#bib.bib134" title="" class="ltx_ref">2023</a>)</cite> thinks that the post-modification result may not necessarily be superior to the origin, so it introduces a selection module to select a better result between the origin and modification.
To facilitate knowledge-intensive tasks, Verify-and-Edit&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhao et&nbsp;al., <a href="#bib.bib198" title="" class="ltx_ref">2023a</a>)</cite> incorporates external knowledge to re-reason uncertain examples, reducing factual mistakes in reasoning.
Some research efforts attempt to unearth the internal knowledge of models.
Some research efforts attempt to unearth the internal knowledge of models.
To address factual errors, some research attempts to unearth the intrinsic knowledge of LLMs.
They acquire knowledge from the model before answering the questions&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dhuliawala et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2023</a>; Zheng et&nbsp;al., <a href="#bib.bib202" title="" class="ltx_ref">2023</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Ji et&nbsp;al. (<a href="#bib.bib54" title="" class="ltx_ref">2023</a>)</cite> further verifies the correctness of intrinsic knowledge, and <cite class="ltx_cite ltx_citemacro_citet">Liu et&nbsp;al. (<a href="#bib.bib87" title="" class="ltx_ref">2023b</a>)</cite> enhances the accuracy of intrinsic knowledge acquisition through reinforcement learning.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.1" class="ltx_p">Inconsistency is another major challenge in reasoning, <cite class="ltx_cite ltx_citemacro_citet">Dua et&nbsp;al. (<a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite> iteratively uses previous reasoning results as prompts until the model gives a consistent answer.
<cite class="ltx_cite ltx_citemacro_citet">Paul et&nbsp;al. (<a href="#bib.bib115" title="" class="ltx_ref">2023</a>)</cite> trains a critic model to provide structured feedback on the reasoning process.
Self-Refine&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Madaan et&nbsp;al., <a href="#bib.bib95" title="" class="ltx_ref">2023</a>)</cite> performs iterative self-feedback and refinement to alleviate errors in reasoning.
Compared with Self-Refine, Reflexion&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shinn et&nbsp;al., <a href="#bib.bib133" title="" class="ltx_ref">2023</a>)</cite> introduces reinforcement learning for reflection, which additionally brings decision-making capability.
Meanwhile, some work introduces backward reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al., <a href="#bib.bib180" title="" class="ltx_ref">2023a</a>)</cite> for verification.
RCoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xue et&nbsp;al., <a href="#bib.bib168" title="" class="ltx_ref">2023</a>)</cite> reconstructs the question according to the reasoning chains, and its inconsistency with the original question exposes errors in the reasoning process.
FOBAR&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a href="#bib.bib56" title="" class="ltx_ref">2023b</a>)</cite> and Self Verification&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Weng et&nbsp;al., <a href="#bib.bib162" title="" class="ltx_ref">2022</a>)</cite> perform verification by deducing the conditions in the question from the answer.
FOBAR infers the variables in the question, and Self Verification infers the conditions in the question.
However, <cite class="ltx_cite ltx_citemacro_citet">Huang et&nbsp;al. (<a href="#bib.bib49" title="" class="ltx_ref">2023a</a>)</cite> finds that LLMs struggle to self-correct without external feedback, and it could even lead to a performance decline.</p>
</div>
<div id="S4.SS3.SSS1.p4" class="ltx_para">
<p id="S4.SS3.SSS1.p4.1" class="ltx_p">LLM reasoning is an unsupervised process in which feedback signals from intermediate reasoning steps play a crucial role in improving reasoning.
Guidance from feedback signals can effectively reduce the hallucination phenomena in reasoning.
There is still significant research space for obtaining appropriate feedback and making accurate corrections based on that feedback.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Question Decomposition</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">The essence of X-of-thought reasoning lies in its step-by-step problem-solving.
However, the original chain-of-thought reasoning approach does not explicitly strip out the step-by-step reasoning process and still uses one-stage generation.
In this section, we discuss the question decomposition approach, which explicitly solves questions step-by-step. The overview is shown in Figure&nbsp;<a href="#S4.F4" title="Figure 4 ‣ 4.3.2 Question Decomposition ‣ 4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2309.15402/assets/x3.png" id="S4.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>
Question decomposition solves complex questions progressively by solving simple sub-questions.</figcaption>
</figure>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib146" title="" class="ltx_ref">2022a</a>)</cite> iteratively acquires knowledge from the model, making progress in multi-hop QA.
<cite class="ltx_cite ltx_citemacro_citet">Zhou et&nbsp;al. (<a href="#bib.bib205" title="" class="ltx_ref">2023b</a>)</cite> proposes Least-to-Most Prompting, which initially breaks down the question into sub-questions in a top-down fashion,
and subsequently, it solves a sub-question once at a time and leverages their solutions to facilitate subsequent sub-questions.
Successive Prompting&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dua et&nbsp;al., <a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite> takes a similar approach to Least-to-Most Prompting, and the difference is that it takes a decomposition with interleaved sub-questions and answers rather than two-stage decomposition.
The above methods do not formulate tailored solutions for various sub-problems.
Decomposed Prompting&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Khot et&nbsp;al., <a href="#bib.bib63" title="" class="ltx_ref">2023</a>)</cite> designs a modular shared library, each dedicated to a class of subproblems,
which can tailor more effective solutions to different classes of sub-problems.
Apart from general tasks, some works focus on question decomposition on tabular reasoning.
BINDER<cite class="ltx_cite ltx_citemacro_citep">(Cheng et&nbsp;al., <a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite> maps reasoning to a program in a neural-symbolic manner and obtains the final answer through a program executor such as Python or SQL.
<cite class="ltx_cite ltx_citemacro_citet">Ye et&nbsp;al. (<a href="#bib.bib177" title="" class="ltx_ref">2023</a>)</cite> introduces DATER, which breaks down large tables into smaller ones and complex questions into simpler ones.
The former reduces irrelevant information, while the latter reduces the complexity of reasoning.</p>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<p id="S4.SS3.SSS2.p3.1" class="ltx_p">Providing direct answers to complex questions can be challenging.
By decomposing the question into simple sub-questions and solving them step-by-step, the difficulty is reduced.
Moreover, each sub-question can be traced back to a specific reasoning step, making the reasoning process more transparent and explainable.
Current work mostly uses top-down decomposition strategies, while bottom-up decomposition strategies based on backward reasoning remain to be explored in future work.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3 </span>External Knowledge</h4>

<figure id="S4.F5" class="ltx_figure"><img src="/html/2309.15402/assets/x4.png" id="S4.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="246" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>
Introducing external knowledge reduces factual errors in reasoning.</figcaption>
</figure>
<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">The parameterized knowledge within models is limited and outdated. Thus, factual mistakes often occur when facing knowledge-intensive tasks.
Introducing external knowledge can mitigate this phenomenon, as shown in Figure&nbsp;<a href="#S4.F5" title="Figure 5 ‣ 4.3.3 External Knowledge ‣ 4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S4.SS3.SSS3.p2" class="ltx_para">
<p id="S4.SS3.SSS3.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Lu et&nbsp;al. (<a href="#bib.bib90" title="" class="ltx_ref">2023a</a>)</cite> introduces multilingual dictionaries in prompts to enhance machine translation.
<cite class="ltx_cite ltx_citemacro_citet">Li et&nbsp;al. (<a href="#bib.bib81" title="" class="ltx_ref">2023d</a>)</cite> proposes chain-of-knowledge (CoK-Li), which obtains structured knowledge from a knowledge base via a query generator to perform knowledge-guided reasoning.
<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib149" title="" class="ltx_ref">2023b</a>)</cite>&nbsp;(CoK-Wang) also retrieves structured knowledge from KB.
Moreover, it estimates the reasoning chains in terms of factuality and faithfulness and prompts models to rethink unreliable reasonings,
which mitigates the knowledge retrieval errors in CoK-Li.
KD-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib150" title="" class="ltx_ref">2023c</a>)</cite> addresses factual reasoning problems through a multi-turn QA approach.
They design a feedback-augmented retriever for retrieving relevant external knowledge in each round of QA to calibrate the reasoning process.
Other studies use the model’s own memory as external knowledge.
For example, Memory-of-Thought&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li and Qiu, <a href="#bib.bib80" title="" class="ltx_ref">2023</a>)</cite> first performs pre-thinking to save the high-confidence thoughts into external memory, and during inference, it lets the LLM recall relevant memory to aid reasoning.</p>
</div>
<div id="S4.SS3.SSS3.p3" class="ltx_para">
<p id="S4.SS3.SSS3.p3.1" class="ltx_p">The parameterized knowledge in the model is fixed at the end of the pre-training, which leads to its shortcomings in terms of knowledge capacity and knowledge updating.
While introducing external knowledge can alleviate this to some extent, it remains an imperfect solution.
To fundamentally tackle this issue, continual learning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lange et&nbsp;al., <a href="#bib.bib68" title="" class="ltx_ref">2022</a>; Wang et&nbsp;al., <a href="#bib.bib154" title="" class="ltx_ref">2023g</a>)</cite> stands as a promising avenue for future research endeavors.</p>
</div>
</section>
<section id="S4.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4 </span>Vote and Rank</h4>

<figure id="S4.F6" class="ltx_figure"><img src="/html/2309.15402/assets/x5.png" id="S4.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="226" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>
Voting and ranking reduce inconsistency by selecting final answers from multiple samplings.</figcaption>
</figure>
<div id="S4.SS3.SSS4.p1" class="ltx_para">
<p id="S4.SS3.SSS4.p1.1" class="ltx_p">Owing to the inherent stochasticity in the generation process, LLM reasoning exhibits an element of randomness and uncertainty.
This problem can be effectively alleviated through multiple sampling strategies, as shown in Figure&nbsp;<a href="#S4.F6" title="Figure 6 ‣ 4.3.4 Vote and Rank ‣ 4.3 XoT Enhancement Methods ‣ 4 Methods ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<div id="S4.SS3.SSS4.p2" class="ltx_para">
<p id="S4.SS3.SSS4.p2.1" class="ltx_p">Some methods adopt ranking, such as <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et&nbsp;al., <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>, which trains a verifier to select high-confidence reasoning chains through ranking.
Meanwhile, other methods select reasoning chains through a voting mechanism.
Self-consistency&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib158" title="" class="ltx_ref">2023j</a>)</cite> selects the most consistent answer by majority voting among sampled reasoning chains based on final answers.
Furthermore, <cite class="ltx_cite ltx_citemacro_citep">(Fu et&nbsp;al., <a href="#bib.bib30" title="" class="ltx_ref">2023a</a>)</cite> proposes Complex CoT, which utilizes a complexity-based voting strategy that leans towards selecting answers generated by more complex reasoning chains.
However, answer-based voting mechanisms do not take into account the correctness of reasoning chains.
<cite class="ltx_cite ltx_citemacro_citet">Miao et&nbsp;al. (<a href="#bib.bib100" title="" class="ltx_ref">2023</a>)</cite> takes the reasoning steps into account when voting, which can obtain both consistent answers and trustworthy reasoning processes simultaneously.
Moreover, to consider the relations between intermediate steps across chains, <cite class="ltx_cite ltx_citemacro_citet">Yoran et&nbsp;al. (<a href="#bib.bib179" title="" class="ltx_ref">2023</a>)</cite> mixes information between reasoning chains and selects the most relevant facts to perform meta-reason over multiple reasoning chains.
GRACE<cite class="ltx_cite ltx_citemacro_citep">(Khalifa et&nbsp;al., <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite> trains a discriminator through contrastive learning and uses this discriminator to rank each intermediate reasoning step.
Previous methods sample based on the probability distribution, while Diversity-of-Thought&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Naik et&nbsp;al., <a href="#bib.bib106" title="" class="ltx_ref">2023</a>)</cite> obtains multiple reasoning paths by prompting with different instructions.</p>
</div>
<div id="S4.SS3.SSS4.p3" class="ltx_para">
<p id="S4.SS3.SSS4.p3.1" class="ltx_p">Drawing inspiration from ensemble learning, the practice of voting and ranking following with multiple sampling serves to diminish uncertainty.
Furthermore, it has showcased substantial performance improvements compared to the single-sample approach.
Multiple sampling with voting has become a common technique in current X-of-thought studies.
Integrating reasoning chains into voting remains a significant area of research for the future.</p>
</div>
</section>
<section id="S4.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.5 </span>Efficiency</h4>

<div id="S4.SS3.SSS5.p1" class="ltx_para">
<p id="S4.SS3.SSS5.p1.1" class="ltx_p">LLM reasoning and manually annotated reasoning chains impose expensive overheads.
<cite class="ltx_cite ltx_citemacro_citet">Aggarwal et&nbsp;al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite> improves self-consistency by dynamically adjusting the number of samples, which can significantly reduce inference costs with marginal performance degradation.
<cite class="ltx_cite ltx_citemacro_citet">Ning et&nbsp;al. (<a href="#bib.bib107" title="" class="ltx_ref">2023</a>)</cite> decomposed the questions in parallel and handled them simultaneously, reducing the reasoning time overhead. But it cannot handle complex questions.
<cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. (<a href="#bib.bib190" title="" class="ltx_ref">2023b</a>)</cite> accelerates the reasoning by selectively skipping some intermediate layers and then verifies the draft in another forward pass.
<cite class="ltx_cite ltx_citemacro_citet">Diao et&nbsp;al. (<a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite> borrows ideas from active learning to annotate examples with high uncertainty, reducing the human annotating cost.</p>
</div>
<div id="S4.SS3.SSS5.p2" class="ltx_para">
<p id="S4.SS3.SSS5.p2.1" class="ltx_p">Large-scale language models have showcased immense capabilities, but they also come with substantial overhead. Balancing the trade-off between performance and overhead may require significant attention in future research endeavors.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Frontier Application</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Tool Use</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Despite the extensive knowledge exhibited by LLMs, it is accompanied by several challenges. These encompass the incapacity to access up-to-the-minute news, proclivity towards hallucinations when responding to queries involving out-of-domain knowledge, and the absence of sophisticated reasoning capacities like mathematical calculations or symbolic reasoning. By granting LLMs the ability to employ external tools, it becomes possible to augment the model’s reasoning capabilities and assimilate external knowledge, enabling it to engage in information retrieval and environmental interaction.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">MRKL&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Karpas et&nbsp;al., <a href="#bib.bib60" title="" class="ltx_ref">2022</a>)</cite> introduces a novel framework comprising scalable modules (referred to as experts) and a router. These experts can take the form of neural networks or symbols. However, this study primarily focuses on conceptualization and training an LLM specifically for mathematical computation while not delving into implementing other module contents. TALM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Parisi et&nbsp;al., <a href="#bib.bib111" title="" class="ltx_ref">2022a</a>)</cite> and Toolformer&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Schick et&nbsp;al., <a href="#bib.bib128" title="" class="ltx_ref">2023</a>)</cite> integrate a text-centric methodology with supplementary tools to enhance the capabilities of language models. They employ a self-supervise mechanism to initiate performance enhancements, commencing with a limited set of tooltips. In a similar vein, HuggingGPT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shen et&nbsp;al., <a href="#bib.bib131" title="" class="ltx_ref">2023</a>)</cite> leverages visual and speech models to process information from diverse modalities, thereby endowing LLMs with the capacity for multi-modal understanding and generation. Another question is how to select the appropriate tool.
LATM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Cai et&nbsp;al., <a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite> enables the tool-making ability of LLMs to make generalized API across different tasks, and GEAR&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lu et&nbsp;al., <a href="#bib.bib93" title="" class="ltx_ref">2023c</a>)</cite> considers the efficiency of tool-using by using smaller models to delegate tool grounding and execution.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">However, converting a user request into API format is often not straightforward. The existing approaches mentioned above have limitations in facilitating multiple invocations of the tool and rectifying query errors. To tackle this problem, ReAct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al., <a href="#bib.bib173" title="" class="ltx_ref">2023c</a>)</cite> integrates the strengths of reasoning and action to enhance and complement each other, augmenting problem-solving capability mutually. ART&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Paranjape et&nbsp;al., <a href="#bib.bib110" title="" class="ltx_ref">2023</a>)</cite> uses a task library to select relevant tool usage and reasoning chains. MM-REACT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yang et&nbsp;al., <a href="#bib.bib169" title="" class="ltx_ref">2023</a>)</cite> further utilizes vision experts to enable multi-modal reasoning and action.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">The aforementioned research endeavors focus on designing tools (or APIs) to enhance the capabilities of LLMs in various domains.
Combining XoT with tools effectively addresses the challenges faced by LLMs.
X-of-thought reasoning enables models to effectively elicit, track, and update action plans while managing exceptions.
Simultaneously, action operations facilitate the model’s interaction with external sources, such as knowledge bases and environments, enabling it to gather additional information.
To assess the proficiency of tools, API-Bank&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a href="#bib.bib78" title="" class="ltx_ref">2023c</a>)</cite> and MetaTool&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Huang et&nbsp;al., <a href="#bib.bib52" title="" class="ltx_ref">2023c</a>)</cite> introduce comprehensive benchmarks, providing a robust foundation to evaluate the performance and effectiveness of tool-augmented LLMs.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Planning</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">LLMs face challenges in providing accurate responses directly for intricate problems, necessitating the need to decompose them into sequential steps and sub-tasks. While CoT offers a straightforward approach to planning, it falls short in addressing highly complex problems and lacks the ability to evaluate and rectify errors through backtracking.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Numerous studies have extended the framework of chain-of-thought to various formats to enhance the capacity for planning further. Tree-of-Thought&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al., <a href="#bib.bib172" title="" class="ltx_ref">2023b</a>)</cite> enables LLMs to consider multiple reasoning paths in a tree and self-evaluate to determine the next course of action.
In cases where global decisions are necessary, ToT allows forward or backward exploration through techniques like deep-first search or breadth-first search.
Reasoning via Planning (RAP)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hao et&nbsp;al., <a href="#bib.bib39" title="" class="ltx_ref">2023</a>)</cite> also divides the problem into a tree and explores them by Monto Carlo tree search algorithm, using LLMs as both world-model and reasoning agent.
Another method, Graph of Thought (GoT)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al., <a href="#bib.bib174" title="" class="ltx_ref">2023d</a>)</cite>, employs graph nodes to represent individual thoughts and external Graph Neural Networks for organization.
LLM+P&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a href="#bib.bib86" title="" class="ltx_ref">2023a</a>)</cite> and LLM+DP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dagan et&nbsp;al., <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> facilitate the generation of Planning Domain Definition Language (PDDL) &nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gerevini, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite> by LLMs.
PDDL assists in decomposing complex problems and utilizing specialized models for planning before converting the results into natural language for LLM processing.
However, it is essential to note that these methods use tree/graph/PDDL nodes to represent thoughts, which have limitations regarding their representation forms and can only handle specific planning problems.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">Another technique is to improve the model’s ability to correct errors and summarize historical experience.
Self-Refine&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Madaan et&nbsp;al., <a href="#bib.bib95" title="" class="ltx_ref">2023</a>)</cite> employs a unique approach where the output generated by the model is evaluated and provided with feedback using the same model.
Reflexion&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shinn et&nbsp;al., <a href="#bib.bib133" title="" class="ltx_ref">2023</a>)</cite> enables the model to reflect on and rectify errors made in previous actions, resembles reinforcement learning in textual format, and involves dividing memory into long and short-term components. However, Reflexion cannot update the plan when an out-of-plan error occurs.
AdaPlanner&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Sun et&nbsp;al., <a href="#bib.bib137" title="" class="ltx_ref">2023</a>)</cite> introduces adaptive closed-loop plan refinement, which iterative refines the task plan based on the feedback of the environment.
ISR-LLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a href="#bib.bib206" title="" class="ltx_ref">2023c</a>)</cite> combines Self-Refine with PDDL to achieve a better success rate in long-horizon sequential tasks. Meanwhile, LATS&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a href="#bib.bib203" title="" class="ltx_ref">2023a</a>)</cite> utilizes LM-based Monte Carlo Tree Search for a more flexible planning procedure.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">Planning can be flexibly combined with tools <cite class="ltx_cite ltx_citemacro_citep">(Ruan et&nbsp;al., <a href="#bib.bib124" title="" class="ltx_ref">2023</a>)</cite> or agents <cite class="ltx_cite ltx_citemacro_citep">(Crispino et&nbsp;al., <a href="#bib.bib19" title="" class="ltx_ref">2023b</a>)</cite> to enrich reasoning ability. ToRA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gou et&nbsp;al., <a href="#bib.bib35" title="" class="ltx_ref">2023</a>)</cite> designs mathematical specialized agents with external tools, and
AutoUI&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhang and Zhang, <a href="#bib.bib195" title="" class="ltx_ref">2023</a>)</cite> directly interacts with the multi-modal environment instead of converting visual inputs into text, which enhances the reasoning efficiency and reduces error propagation.</p>
</div>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p">Planning augmented approaches have advanced conventional sequential planning by introducing search-based, graph-based, and definition language-based methods.
On the other hand, some methods incorporate action, planning, reflection, or tools, aiming to enhance LLMs’ long-term planning and error resilience capabilities.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>CoT Distillation</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">LLM can be self-improved by distilling reasoning steps to solve complex problems.
<cite class="ltx_cite ltx_citemacro_citet">Huang et&nbsp;al. (<a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite> employs an LLM with self-consistency to generate reasoning chains from unlabeled data.
These chains are subsequently utilized to fine-tune the model, enhancing its generalized reasoning capabilities.
<cite class="ltx_cite ltx_citemacro_citet">Zelikman et&nbsp;al. (<a href="#bib.bib186" title="" class="ltx_ref">2022</a>)</cite> proposes STaR, a few-shot learning approach to improve LM’s reasoning capabilities using a self-loop bootstrap strategy.
SECToR&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhang and Parkes, <a href="#bib.bib189" title="" class="ltx_ref">2023</a>)</cite> uses chain-of-thought to obtain arithmetic answers, then fine-tune the model to generate the answer without CoT directly.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Thought CoT is an emerging ability primarily observed in LLMs, with limited advancements in small models. However, enhancing small models’ CoT ability is conceivable through techniques like distillation.
<cite class="ltx_cite ltx_citemacro_citet">Magister et&nbsp;al. (<a href="#bib.bib98" title="" class="ltx_ref">2023</a>)</cite> demonstrates that fine-tuning T5 with reasoning chains generated by larger teacher models and utilizing an external calculator for answer resolution can substantially enhance task performance across diverse datasets. <cite class="ltx_cite ltx_citemacro_citet">Ho et&nbsp;al. (<a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite> generates and filters multiple reasoning paths to enrich the diversity.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">Numerous endeavors can be undertaken to reduce human costs using unannotated (or very few annotated) data by utilizing the self-consistency&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib158" title="" class="ltx_ref">2023j</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Hsieh et&nbsp;al. (<a href="#bib.bib45" title="" class="ltx_ref">2023</a>)</cite> employs prompts to generate answers from much fewer labeled/unlabeled data, followed by the generation of rationales that prompt the language model to provide reasoning for the given answer.
SCoTD&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a href="#bib.bib77" title="" class="ltx_ref">2023b</a>)</cite> finds that sampling multiple reasoning chains per instance from teachers is paramount for improving the capability of students.
SCOTT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib155" title="" class="ltx_ref">2023h</a>)</cite> utilizes contrastive decoding&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a href="#bib.bib79" title="" class="ltx_ref">2022b</a>; O’Brien and Lewis, <a href="#bib.bib108" title="" class="ltx_ref">2023</a>)</cite> during rationale generation for teacher models.
Furthermore, to tackle the shortcut problem, it employs a counterfactual reasoning objective while training student models.
DialCoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Han et&nbsp;al., <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite> decomposes reasoning steps into a multi-round dialog and selects the correct path using the PPO algorithm.
<cite class="ltx_cite ltx_citemacro_citet">Jie et&nbsp;al. (<a href="#bib.bib57" title="" class="ltx_ref">2023</a>); Wang et&nbsp;al. (<a href="#bib.bib157" title="" class="ltx_ref">2023i</a>)</cite> add special tokens for mathematic problems. This high-level information improves the consistency of reasoning steps.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p">The studies above adopt a shared paradigm wherein reasoning chains are generated through LLMs possessing superior reasoning capabilities.
These reasoning chains are then distilled into smaller models.
The effectiveness of the distillation process is improved by augmenting the sampling strategy from the larger model, for example, through the utilization of multiple sampling paths, consistency, or contrastive decoding, which leads to improved diversity and accuracy in the generated reasoning chains, ultimately benefiting the distillation process to smaller models.
It’s notable that language models have intricate tradeoffs and complex balances associated with multidimensional capabilities. <cite class="ltx_cite ltx_citemacro_citet">Fu et&nbsp;al. (<a href="#bib.bib31" title="" class="ltx_ref">2023b</a>)</cite> emphasizes that increasing task-specific chain-of-thought capabilities through distillation may also adversely impact the models’ performance in solving generalized problems.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Future Directions</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">While chain-of-thought reasoning has showcased remarkable performance on numerous tasks, some challenges still require further exploration. In this section, we provide a concise overview of three promising avenues for future research: multi-modal X-of-thought reasoning&nbsp;(§<a href="#S6.SS1" title="6.1 Multi-modal CoT ‣ 6 Future Directions ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>), faithful X-of-thought reasoning&nbsp;(§<a href="#S6.SS2" title="6.2 Faithfulness ‣ 6 Future Directions ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>), and X-of-thought reasoning theory&nbsp;(§<a href="#S6.SS3" title="6.3 CoT Theory ‣ 6 Future Directions ‣ A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a>).</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Multi-modal CoT</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">The shift from text unimodal to vision-text multi-modal introduces richer information, meanwhile bringing more challenges. Some works have attempted to explore X-of-thought reasoning in multi-modal scenarios by fine-tuning multi-modal models to generate a high-quality chain of thoughts.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">Multimodal-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a href="#bib.bib197" title="" class="ltx_ref">2023g</a>)</cite> firstly fine-tunes multi-modal models to generate chain-of-thoughts and then reasons over the rationales to obtain final answers.
However, it suffers from the limitation of the linearity of the reasoning process and has difficulties in interacting between different modalities.
To alleviate the challenges encountered by Multimodal-CoT, <cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al., <a href="#bib.bib174" title="" class="ltx_ref">2023d</a>)</cite> proposes Graph-of-Thought (GoT), which models the thought processes as a graph. It parses the reasoning chains into a thought graph, which enables a more realistic representation of thought processes by capturing non-sequential information interactions.
This measure breaks the limitations of linear structure through graphical structures and further improves performance.
Furthermore, <cite class="ltx_cite ltx_citemacro_citet">Yao et&nbsp;al. (<a href="#bib.bib171" title="" class="ltx_ref">2023a</a>)</cite> proposes Hypergraph-of-Thought (HoT), replacing thought graphs with hypergraphs, which enables models with better ability of high-order multi-hop reasoning and multi-modal comparative judgment.
Meanwhile, some work takes an approach based on knowledge distillation. T-SciQ&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib151" title="" class="ltx_ref">2023d</a>)</cite> generates high-quality CoT rationales from LLMs as fine-tuning signals and introduces a novel data mixing strategy to produce effective samples for different questions.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">The aforementioned studies explore multi-modal reasoning in small models and fine-tuning scenarios, which we regard as an initial endeavor in the realm of multi-modal chain-of-thought reasoning. We believe that video multi-modal reasoning combined with in-context learning should be the focus of future research. On the one hand, videos introduce additional temporal information with innate chaining relationships compared with images. Through chain-of-thought reasoning, the information in different frames can be naturally connected to explicitly model the temporal relationship, which is well-suited for video multi-modal reasoning. On the other hand, small models are capacity-limited and need fine-tuning to gain chain-of-thought ability. Worse still, multi-modal reasoning chains are difficult to obtain, which further exacerbates the challenge. In comparison, contemporary vision-language foundation models (VLMs)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Alayrac et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2022</a>; Li et&nbsp;al., <a href="#bib.bib76" title="" class="ltx_ref">2023a</a>; Wang et&nbsp;al., <a href="#bib.bib156" title="" class="ltx_ref">2022b</a>; Huang et&nbsp;al., <a href="#bib.bib51" title="" class="ltx_ref">2023b</a>; Peng et&nbsp;al., <a href="#bib.bib116" title="" class="ltx_ref">2023</a>; Yu et&nbsp;al., <a href="#bib.bib184" title="" class="ltx_ref">2021b</a>)</cite> have strong vision-language comprehension and are already capable of in-context learning with interleaved text and images. They provide a solid foundation for chain-of-thought reasoning with in-context learning.
Utilizing chain-of-thought for video reasoning remains an unexplored territory with only a few studies. CoMT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hu et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2023b</a>)</cite> combines fast-thinking and slow-thinking in video reasoning and introduces a tree search strategy for planning, which firstly applies CoT in video multi-modal reasoning.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<p id="S6.SS1.p4.1" class="ltx_p">Although some works have started to utilize chain-of-thought reasoning and solve multi-modal reasoning tasks, previous works only focus on how to construct high-quality fine-tuned data, and there are still several challenges remaining:</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">How to unify visual and language features to elicit better multi-modal understanding.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">How to use VLMs for chain-of-thought reasoning without fine-tuning.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p">How to adapt image multi-modal reasoning into video multi-modal reasoning.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Faithfulness</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Extensive research indicates that chain-of-thought reasoning can lead to hallucination phenomena, such as factual mistakes and contextual inconsistencies.
Considering that language models fundamentally belong to statistical models, and due to factors such as data noise and knowledge forgetting, hallucination phenomena are unavoidable.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">Some works focus on mitigating factual mistakes. <cite class="ltx_cite ltx_citemacro_citet">He et&nbsp;al. (<a href="#bib.bib40" title="" class="ltx_ref">2023a</a>)</cite> introduces external knowledge to evaluate reasoning chains and votes to filter out chains that contain factual mistakes but without correcting them
&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib149" title="" class="ltx_ref">2023b</a>)</cite> adopts a similar way, with the difference that it additionally introduces a reflection mechanism to correct low-scoring reasoning.
<cite class="ltx_cite ltx_citemacro_citet">Zhao et&nbsp;al. (<a href="#bib.bib198" title="" class="ltx_ref">2023a</a>)</cite> filters out low-confidence reasoning by consistency and guides models to re-reasoning based on relevant external knowledge. While the aforementioned methods work well on knowledge-intensive tasks, they fall short in addressing the challenge of contextual inconsistencies.
<cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. (<a href="#bib.bib192" title="" class="ltx_ref">2023d</a>)</cite> explores the hallucination snowballing phenomena during the reasoning process.
Others aim to address the inconsistency issues.
<cite class="ltx_cite ltx_citemacro_citet">Radhakrishnan et&nbsp;al. (<a href="#bib.bib120" title="" class="ltx_ref">2023</a>)</cite> observes that models are more faithful when dealing with simple questions. Thus, it improves faithfulness through question decomposition.
Faithful CoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lyu et&nbsp;al., <a href="#bib.bib94" title="" class="ltx_ref">2023</a>)</cite> initially generates symbolic reasoning chains and later deterministically executes symbolic functions, mitigating reasoning inconsistencies.
<cite class="ltx_cite ltx_citemacro_citet">Lanham et&nbsp;al. (<a href="#bib.bib69" title="" class="ltx_ref">2023</a>)</cite> explores the factors that influence faithfulness, which provides an empirical perspective. It finds faithfulness varies on different tasks and decreases as the model size increases.
CoNLI&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lei et&nbsp;al., <a href="#bib.bib72" title="" class="ltx_ref">2023b</a>)</cite> proposes a post-editing strategy to diminish the hallucinations.
SynTra&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Jones et&nbsp;al., <a href="#bib.bib59" title="" class="ltx_ref">2023</a>)</cite> performs prefix-tuning on a synthetic dataset designed to elicit hallucination easily, and then transfers this capability to real tasks.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">Despite numerous efforts aimed at addressing the hallucination issues in large language models, these works have only mitigated the problem to some extent. There is still a long way to fully enhance the faithfulness of large language models.
We summarize the future directions as follows:</p>
<ul id="S6.I2" class="ltx_itemize">
<li id="S6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i1.p1" class="ltx_para">
<p id="S6.I2.i1.p1.1" class="ltx_p">Improving the ability to recognize hallucination phenomena in the reasoning processes.</p>
</div>
</li>
<li id="S6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i2.p1" class="ltx_para">
<p id="S6.I2.i2.p1.1" class="ltx_p">Improving the accuracy of external knowledge retrieval and utilization to reduce factual mistakes.</p>
</div>
</li>
<li id="S6.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i3.p1" class="ltx_para">
<p id="S6.I2.i3.p1.1" class="ltx_p">Improving the ability to recognize and correct contextual inconsistencies and logical mistakes, which is more challenging.</p>
</div>
</li>
<li id="S6.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i4.p1" class="ltx_para">
<p id="S6.I2.i4.p1.1" class="ltx_p">How to fundamentally eliminate hallucination phenomena from alternative approaches, e.g. specific pre-training.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>CoT Theory</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">Despite the impressive capability of chain-of-thought reasoning, the ability to generate chain-of-thought following instructions still lacks a comprehensive explanation.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">Some work addresses from an empirical perspective and can serve as a practical guide.
<cite class="ltx_cite ltx_citemacro_citet">Madaan and Yazdanbakhsh (<a href="#bib.bib96" title="" class="ltx_ref">2022</a>)</cite> decomposes prompts into three components: symbols, patterns, and text, exploring the impact of CoT through counterfactual prompting.
<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib147" title="" class="ltx_ref">2023a</a>)</cite> analyzes the impact of demonstration selection. They find that the correctness of reasoning chains has a negligible effect, while the relevance to the question and correct reasoning order matters.
<cite class="ltx_cite ltx_citemacro_citet">Tang et&nbsp;al. (<a href="#bib.bib142" title="" class="ltx_ref">2023</a>)</cite> explores the role of semantics.
They find that chain-of-thought reasoning relies heavily on semantic knowledge introduced during pre-training and performs poorly in symbolic reasoning.</p>
</div>
<div id="S6.SS3.p3" class="ltx_para">
<p id="S6.SS3.p3.1" class="ltx_p">Others work analyze theoretically, exploring the underlying principles and internal mechanisms.
<cite class="ltx_cite ltx_citemacro_citet">Li et&nbsp;al. (<a href="#bib.bib83" title="" class="ltx_ref">2023e</a>)</cite> deconstructs chain-of-thought reasoning as a multi-step combinatorial function. They demonstrate that chain-of-thought reduces the complexity of in-context learning to tackle complex questions.
<cite class="ltx_cite ltx_citemacro_citet">Feng et&nbsp;al. (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite> theoretically proves that a fixed-size Transformer is sufficient for computational tasks and dynamic planning with chain-of-thought.
<cite class="ltx_cite ltx_citemacro_citet">Merrill and Sabharwal (<a href="#bib.bib99" title="" class="ltx_ref">2023</a>)</cite> observes that chain-of-thought can boost reasoning ability, with the extent of improvement increasing as the number of intermediate reasoning steps grows.
<cite class="ltx_cite ltx_citemacro_citet">Wu et&nbsp;al. (<a href="#bib.bib164" title="" class="ltx_ref">2023</a>)</cite> leverages gradient-based feature attribution methods to explore the impact of chain-of-thought on outputs.
The results indicate that chain-of-thought exhibits robustness to perturbations and variations in the question.
In addition, there are some claims suggesting that the chain-of-thought ability stems from code data during the pre-training phase&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Madaan et&nbsp;al., <a href="#bib.bib97" title="" class="ltx_ref">2022</a>; Zhang et&nbsp;al., <a href="#bib.bib191" title="" class="ltx_ref">2023c</a>)</cite>, but there is currently no systematic work to substantiate this opinion.</p>
</div>
<div id="S6.SS3.p4" class="ltx_para">
<p id="S6.SS3.p4.1" class="ltx_p">Current research on chain-of-thought theory is still in its preliminary exploration stage. We summarize future research directions as follows:</p>
<ul id="S6.I3" class="ltx_itemize">
<li id="S6.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I3.i1.p1" class="ltx_para">
<p id="S6.I3.i1.p1.1" class="ltx_p">Explore the sources of chain-of-thought ability to achieve targeted improvements in CoT reasoning.</p>
</div>
</li>
<li id="S6.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I3.i2.p1" class="ltx_para">
<p id="S6.I3.i2.p1.1" class="ltx_p">Theoretically analyzing the advantages of chain-of-thought over in-context learning and exploring the boundaries of its capabilities.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Discussion</h2>

<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Comparison of XoT Construction</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">There are three main ways of constructing an X-of-thought for existing methods: (1) <span id="S7.SS1.p1.1.1" class="ltx_text ltx_font_bold">Manual</span> labeling reasoning chains.
(2) <span id="S7.SS1.p1.1.2" class="ltx_text ltx_font_bold">Automatic</span> generating reasoning chains by models.
(3) <span id="S7.SS1.p1.1.3" class="ltx_text ltx_font_bold">Semi-automatic</span> generation with automatic expansion on a small number of manually labeled reasoning chains.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p">We observe that the manual construction methods&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a href="#bib.bib161" title="" class="ltx_ref">2022b</a>; Gao et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite> face similar challenges to in-context learning, i.e., demonstration selection, instruction formatting, etc&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dong et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite>.
This causes numerous difficulties in its application and hinders the transfer ability across different tasks.
Automatic construction methods&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a href="#bib.bib196" title="" class="ltx_ref">2023f</a>; Chen et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2022a</a>; Xu et&nbsp;al., <a href="#bib.bib167" title="" class="ltx_ref">2023</a>)</cite> lack the guidance of high-quality annotations, resulting in performance deficiencies.
Benefiting from the signals brought by manual annotations, semi-automatic methods&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shum et&nbsp;al., <a href="#bib.bib135" title="" class="ltx_ref">2023</a>; Shao et&nbsp;al., <a href="#bib.bib130" title="" class="ltx_ref">2023</a>)</cite> can generate high-quality reasoning chains through self-bootstrapping and similar techniques, effectively addressing the challenges faced by previous approaches.
While achieving excellent performance, it allows for easy transfer across different tasks.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Comparison between Verification/Refinement and Planning</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">Numerous parallels exist between planning methods and verification/refinement-based methods, as both rely on feedback from intermediate processes to adjust and refine behavior.
The distinction lies in the fact that planning methods encompass decision-making, while verification/refinement-based methods solely address intermediate errors without delving into higher-level cognitive processes.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p">LLM reasoning processes are often hallucinatory, causing factual and logical mistakes.
Verify and edit based methods&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ling et&nbsp;al., <a href="#bib.bib85" title="" class="ltx_ref">2023</a>; Zhao et&nbsp;al., <a href="#bib.bib198" title="" class="ltx_ref">2023a</a>; Madaan et&nbsp;al., <a href="#bib.bib95" title="" class="ltx_ref">2023</a>; Shinn et&nbsp;al., <a href="#bib.bib133" title="" class="ltx_ref">2023</a>)</cite> verify the correctness of the reasoning process and refine reasoning step that may cause hallucinatory.
Through verification and refinement, cascading errors and hallucinatory phenomena in the reasoning process are significantly reduced.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p">The planning methods&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Long, <a href="#bib.bib89" title="" class="ltx_ref">2023</a>; Yao et&nbsp;al., <a href="#bib.bib172" title="" class="ltx_ref">2023b</a>, <a href="#bib.bib173" title="" class="ltx_ref">c</a>; Liu et&nbsp;al., <a href="#bib.bib86" title="" class="ltx_ref">2023a</a>; Shinn et&nbsp;al., <a href="#bib.bib133" title="" class="ltx_ref">2023</a>)</cite>
introduce a decision-making process in the reasoning.
They evaluate the intermediate reasoning steps to get feedback, and based on the feedback, they engage in exploration and backtracking to achieve superior solutions at a global level.
Their specialization lies in handling complex problems, enabling them to achieve remarkable performance, especially when confronted with intricate multi-hop reasoning and planning tasks.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span>Compensate for Innate Weaknesses</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p">LLMs have many inherent limitations when it comes to reasoning, such as the inability to access external information, arithmetic errors, and inconsistent reasoning.
These issues can be cleverly circumvented by entrusting specific responsibilities to dedicated modules or models.</p>
</div>
<div id="S7.SS3.p2" class="ltx_para">
<p id="S7.SS3.p2.1" class="ltx_p">In response to the models’ limitation in accessing external information, <cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a href="#bib.bib81" title="" class="ltx_ref">2023d</a>; Wang et&nbsp;al., <a href="#bib.bib149" title="" class="ltx_ref">2023b</a>; Lu et&nbsp;al., <a href="#bib.bib90" title="" class="ltx_ref">2023a</a>; Schick et&nbsp;al., <a href="#bib.bib128" title="" class="ltx_ref">2023</a>; Karpas et&nbsp;al., <a href="#bib.bib60" title="" class="ltx_ref">2022</a>; Yoran et&nbsp;al., <a href="#bib.bib179" title="" class="ltx_ref">2023</a>)</cite> utilizes external knowledge resources like knowledge base, search engines, and open-domain question-answering systems.
Some work introduces a calculator to address arithmetic errors&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Schick et&nbsp;al., <a href="#bib.bib128" title="" class="ltx_ref">2023</a>; Karpas et&nbsp;al., <a href="#bib.bib60" title="" class="ltx_ref">2022</a>; Parisi et&nbsp;al., <a href="#bib.bib112" title="" class="ltx_ref">2022b</a>)</cite>.
Code execution is deterministic, and certain work enhances the consistency of the reasoning process by introducing code executor&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2023</a>; Chen et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2022a</a>; Bi et&nbsp;al., <a href="#bib.bib7" title="" class="ltx_ref">2023</a>; Imani et&nbsp;al., <a href="#bib.bib53" title="" class="ltx_ref">2023</a>)</cite>.
We believe that employing LLMs as an agent for central planning and reasoning, delegating specific sub-tasks to dedicated sub-models, is a potential avenue for applying large models in complex scenarios in the future&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib152" title="" class="ltx_ref">2023e</a>; Xi et&nbsp;al., <a href="#bib.bib165" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4 </span>Other Work</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.1" class="ltx_p">In this chapter, we will list other works that represent early attempts at chain-of-thought reasoning or are designed for specific domains.</p>
</div>
<div id="S7.SS4.p2" class="ltx_para">
<p id="S7.SS4.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Katz et&nbsp;al. (<a href="#bib.bib61" title="" class="ltx_ref">2022</a>); Zhang et&nbsp;al. (<a href="#bib.bib193" title="" class="ltx_ref">2022</a>)</cite> provide benchmarks and resources.
Some work has empirically demonstrated the effectiveness of chain-of-thought prompting&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lampinen et&nbsp;al., <a href="#bib.bib67" title="" class="ltx_ref">2022</a>; Ye and Durrett, <a href="#bib.bib175" title="" class="ltx_ref">2022</a>; Arora et&nbsp;al., <a href="#bib.bib4" title="" class="ltx_ref">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Shi et&nbsp;al. (<a href="#bib.bib132" title="" class="ltx_ref">2023</a>)</cite> explores multi-lingual CoT reasoning.
Other work focuses on specific domains, such as machine translation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(He et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023b</a>)</cite>, sentiment analysis&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Fei et&nbsp;al., <a href="#bib.bib28" title="" class="ltx_ref">2023</a>)</cite>,
sentence embeddings&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a href="#bib.bib188" title="" class="ltx_ref">2023a</a>)</cite>,
summarization&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib159" title="" class="ltx_ref">2023k</a>)</cite>,
arithmetic&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lee and Kim, <a href="#bib.bib70" title="" class="ltx_ref">2023</a>)</cite>,
and tabular reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Chen, <a href="#bib.bib11" title="" class="ltx_ref">2023</a>; Jin and Lu, <a href="#bib.bib58" title="" class="ltx_ref">2023</a>)</cite>,
etc.
Besides, some research utilizes specific pre-training to enhance certain capabilities, such as mathematical reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewkowycz et&nbsp;al., <a href="#bib.bib74" title="" class="ltx_ref">2022</a>; Zhao et&nbsp;al., <a href="#bib.bib199" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">In this paper, we conduct an extensive survey of existing research on X-of-thought reasoning, offering a comprehensive review of the field.
We introduce the concept of generalized chain-of-thought (X-of-Thought) and examine advances in X-of-thought reasoning from various angles.
Additionally, we investigate the applications of X-of-thought in cutting-edge domains.
Furthermore, we spotlight the current challenges confronting this research and provide future prospects.
To the best of our knowledge, this survey represents the first systematic exploration of chain-of-thought reasoning.
Our objective is to furnish researchers interested in chain-of-thought reasoning with a thorough overview, with the hope that this survey will facilitate further research in this area.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aggarwal et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Pranjal Aggarwal, Aman Madaan, Yiming Yang, and Mausam. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.11860" title="" class="ltx_ref ltx_href">Let’s sample step by step: Adaptive-consistency for efficient reasoning with llms</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.11860.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alayrac et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei, Marianne Monteiro, Jacob&nbsp;L. Menick, Sebastian Borgeaud, Andy Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira, Oriol Vinyals, Andrew Zisserman, and Karén Simonyan. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2022/hash/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html" title="" class="ltx_ref ltx_href">Flamingo: a visual language model for few-shot learning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amini et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/n19-1245" title="" class="ltx_ref ltx_href">Mathqa: Towards interpretable math word problem solving with operation-based formalisms</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>, pages 2357–2367. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arora et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Simran Arora, Avanika Narayan, Mayee&nbsp;F. Chen, Laurel&nbsp;J. Orr, Neel Guha, Kush Bhatia, Ines Chami, and Christopher Ré. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=bhUPJnS2g0X" title="" class="ltx_ref ltx_href">Ask me anything: A simple strategy for prompting language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Besta et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2308.09687" title="" class="ltx_ref ltx_href">Graph of thoughts: Solving elaborate problems with large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.09687.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhakthavatsalam et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Sumithra Bhakthavatsalam, Daniel Khashabi, Tushar Khot, Bhavana&nbsp;Dalvi Mishra, Kyle Richardson, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord, and Peter Clark. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2102.03315" title="" class="ltx_ref ltx_href">Think you have solved direct-answer question answering? try arc-da, the direct-answer AI2 reasoning challenge</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2102.03315.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bi et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhen Bi, Ningyu Zhang, Yinuo Jiang, Shumin Deng, Guozhou Zheng, and Huajun Chen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2308.15452" title="" class="ltx_ref ltx_href">When do program-of-thoughts work for reasoning?</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bisk et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Yonatan Bisk, Rowan Zellers, Ronan&nbsp;Le Bras, Jianfeng Gao, and Yejin Choi. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/6239" title="" class="ltx_ref ltx_href">PIQA: reasoning about physical commonsense in natural language</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020</em>, pages 7432–7439. AAAI Press.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom&nbsp;B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel&nbsp;M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" title="" class="ltx_ref ltx_href">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2305.17126" title="" class="ltx_ref ltx_href">Large language models as tool makers</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen (2023)</span>
<span class="ltx_bibblock">
Wenhu Chen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.findings-eacl.83" title="" class="ltx_ref ltx_href">Large language models are few(1)-shot table reasoners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EACL 2023, Dubrovnik, Croatia, May 2-6, 2023</em>, pages 1090–1100. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Wenhu Chen, Xueguang Ma, Xinyi Wang, and William&nbsp;W. Cohen. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2211.12588" title="" class="ltx_ref ltx_href">Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2211.12588.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueguang Ma, Jianyu Xu, Xinyi Wang, and Tony Xia. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.12524" title="" class="ltx_ref ltx_href">Theoremqa: A theorem-driven question answering dataset</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.12524.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan&nbsp;R. Routledge, and William&nbsp;Yang Wang. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.300" title="" class="ltx_ref ltx_href">Finqa: A dataset of numerical reasoning over financial data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021</em>, pages 3697–3711. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena Shah, and William&nbsp;Yang Wang. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.emnlp-main.421" title="" class="ltx_ref ltx_href">Convfinqa: Exploring the chain of numerical reasoning in conversational finance question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 6279–6292. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, Noah&nbsp;A. Smith, and Tao Yu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=lH1PV42cbF" title="" class="ltx_ref ltx_href">Binding language models in symbolic languages</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2110.14168" title="" class="ltx_ref ltx_href">Training verifiers to solve math word problems</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2110.14168.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Crispino et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2023a.

</span>
<span class="ltx_bibblock">Agent instructs large language models to be general zero-shot reasoners.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.03710</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Crispino et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.03710" title="" class="ltx_ref ltx_href">Agent instructs large language models to be general zero-shot reasoners</a>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dagan et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Gautier Dagan, Frank Keller, and Alex Lascarides. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:260887774" title="" class="ltx_ref ltx_href">Dynamic planning with a llm</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2308.06391.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/n19-1423" title="" class="ltx_ref ltx_href">BERT: pre-training of deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>, pages 4171–4186. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhuliawala et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. 2023.

</span>
<span class="ltx_bibblock">Chain-of-verification reduces hallucination in large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.11495</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Shizhe Diao, Pengcheng Wang, Yong Lin, and Tong Zhang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.12246" title="" class="ltx_ref ltx_href">Active prompting with chain-of-thought for large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.12246.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Qingxiu Dong, Lei Li, Damai Dai, Ce&nbsp;Zheng, Zhiyong Wu, Baobao Chang, Xu&nbsp;Sun, Jingjing Xu, Lei Li, and Zhifang Sui. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2301.00234" title="" class="ltx_ref ltx_href">A survey for in-context learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2301.00234.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Qingxiu Dong, Ziwei Qin, Heming Xia, Tian Feng, Shoujie Tong, Haoran Meng, Lin Xu, Zhongyu Wei, Weidong Zhan, Baobao Chang, Sujian Li, Tianyu Liu, and Zhifang Sui. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.acl-long.66" title="" class="ltx_ref ltx_href">Premise-based multimodal reasoning: Conditional inference on joint textual and visual clues</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, pages 932–946. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt Gardner. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.emnlp-main.81" title="" class="ltx_ref ltx_href">Successive prompting for decomposing complex questions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 1251–1265. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1246" title="" class="ltx_ref ltx_href">DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 2368–2378, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fei et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hao Fei, Bobo Li, Qian Liu, Lidong Bing, Fei Li, and Tat-Seng Chua. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-short.101" title="" class="ltx_ref ltx_href">Reasoning implicit sentiment with chain-of-thought prompting</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 1171–1182. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di&nbsp;He, and Liwei Wang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.15408" title="" class="ltx_ref ltx_href">Towards revealing the mystery behind chain of thought: a theoretical perspective</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.15408.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=yf1icZHC-l9" title="" class="ltx_ref ltx_href">Complexity-based prompting for multi-step reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Yao Fu, Hao-Chun Peng, Litu Ou, Ashish Sabharwal, and Tushar Khot. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:256390607" title="" class="ltx_ref ltx_href">Specializing smaller language models towards multi-step reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.mlr.press/v202/gao23f.html" title="" class="ltx_ref ltx_href">PAL: Program-aided language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th International Conference on Machine Learning</em>, volume 202 of <em id="bib.bib32.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 10764–10799. PMLR.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gerevini (2020)</span>
<span class="ltx_bibblock">
Alfonso&nbsp;Emilio Gerevini. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1016/j.artint.2019.103221" title="" class="ltx_ref ltx_href">An introduction to the planning domain definition language (PDDL): book review</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Artif. Intell.</em>, 280:103221.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00370" title="" class="ltx_ref ltx_href">Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, 9:346–361.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang, Nan Duan, and Weizhu Chen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2309.17452" title="" class="ltx_ref ltx_href">Tora: A tool-integrated reasoning agent for mathematical problem solving</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta and Gupta (2022)</span>
<span class="ltx_bibblock">
Pranay Gupta and Manish Gupta. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1007/978-3-031-05981-0_1" title="" class="ltx_ref ltx_href">Newskvqa: Knowledge-aware news video question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Advances in Knowledge Discovery and Data Mining - 26th Pacific-Asia Conference, PAKDD 2022, Chengdu, China, May 16-19, 2022, Proceedings, Part III</em>, volume 13282 of <em id="bib.bib36.2.2" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>, pages 3–15. Springer.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chengcheng Han, Xiaowei Du, Che Zhang, Yixin Lian, Xiang Li, Ming Gao, and Baoyuan Wang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.05074" title="" class="ltx_ref ltx_href">Dialcot meets ppo: Decomposing and exploring reasoning paths in smaller language models</a>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell, David Peng, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Shafiq&nbsp;R. Joty, Alexander&nbsp;R. Fabbri, Wojciech Kryscinski, Xi&nbsp;Victoria Lin, Caiming Xiong, and Dragomir Radev. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2209.00840" title="" class="ltx_ref ltx_href">FOLIO: natural language reasoning with first-order logic</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2209.00840.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Shibo Hao, Yilan Gu, Haodi Ma, Joshua&nbsp;Jiahua Hong, Zhen Wang, Daisy&nbsp;Zhe Wang, and Zhiting Hu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258865812" title="" class="ltx_ref ltx_href">Reasoning with language model is planning with world model</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.14992.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Hangfeng He, Hongming Zhang, and Dan Roth. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2301.00303" title="" class="ltx_ref ltx_href">Rethinking with retrieval: Faithful large language model inference</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2301.00303.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, and Xing Wang. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.04118" title="" class="ltx_ref ltx_href">Exploring human-like translation strategy with large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.04118.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html" title="" class="ltx_ref ltx_href">Measuring mathematical problem solving with the MATH dataset</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Namgyu Ho, Laura Schmid, and Se-Young Yun. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.830" title="" class="ltx_ref ltx_href">Large language models are reasoning teachers</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 14852–14882. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosseini et&nbsp;al. (2014)</span>
<span class="ltx_bibblock">
Mohammad&nbsp;Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/v1/d14-1058" title="" class="ltx_ref ltx_href">Learning to solve arithmetic word problems with verb categorization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL</em>, pages 523–533. ACL.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsieh et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander&nbsp;J. Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258461606" title="" class="ltx_ref ltx_href">Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.02301.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Hanxu Hu, Hongyuan Lu, Huajian Zhang, Wai Lam, and Yue Zhang. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.10276" title="" class="ltx_ref ltx_href">Chain-of-symbol prompting elicits planning in large langauge models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.10276.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Pengbo Hu, Ji&nbsp;Qi, Xingyu Li, Hong Li, Xinqi Wang, Bing Quan, Ruiyu Wang, and Yi&nbsp;Zhou. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2308.09658" title="" class="ltx_ref ltx_href">Tree-of-mixed-thought: Combining fast and slow thinking for multi-hop visual reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.09658.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jiaxin Huang, Shixiang&nbsp;Shane Gu, Le&nbsp;Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2210.11610" title="" class="ltx_ref ltx_href">Large language models can self-improve</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2210.11610.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu&nbsp;Steven Zheng, Adams&nbsp;Wei Yu, Xinying Song, and Denny Zhou. 2023a.

</span>
<span class="ltx_bibblock">Large language models cannot self-correct reasoning yet.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.01798</em>.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Lifu Huang, Ronan&nbsp;Le Bras, Chandra Bhagavatula, and Yejin Choi. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1243" title="" class="ltx_ref ltx_href">Cosmos QA: machine reading comprehension with contextual commonsense reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019</em>, pages 2391–2401. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Shaohan Huang, Li&nbsp;Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao Lv, Lei Cui, Owais&nbsp;Khan Mohammed, Barun Patra, Qiang Liu, Kriti Aggarwal, Zewen Chi, Johan Bjorck, Vishrav Chaudhary, Subhojit Som, Xia Song, and Furu Wei. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.14045" title="" class="ltx_ref ltx_href">Language is not all you need: Aligning perception with language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.14045.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023c)</span>
<span class="ltx_bibblock">
Yue Huang, Jiawen Shi, Yuan Li, Chenrui Fan, Siyuan Wu, Qihui Zhang, Yixin Liu, Pan Zhou, Yao Wan, Neil&nbsp;Zhenqiang Gong, and Lichao Sun. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.03128" title="" class="ltx_ref ltx_href">Metatool benchmark: Deciding whether to use tools and which to use</a>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Imani et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Shima Imani, Liang Du, and Harsh Shrivastava. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-industry.4" title="" class="ltx_ref ltx_href">Mathprompter: Mathematical reasoning using large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the The 61st Annual Meeting of the Association for Computational Linguistics: Industry Track, ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 37–42. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Ishii, and Pascale Fung. 2023.

</span>
<span class="ltx_bibblock">Towards mitigating hallucination in large language models via self-reflection.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.06271</em>.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Song Jiang, Zahra Shakeri, Aaron Chan, Maziar Sanjabi, Hamed Firooz, Yinglong Xia, Bugra Akyildiz, Yizhou Sun, Jinchao Li, Qifan Wang, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Resprompt: Residual connection prompting advances multi-step reasoning in large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.04743</em>.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Weisen Jiang, Han Shi, Longhui Yu, Zhengying Liu, Yu&nbsp;Zhang, Zhenguo Li, and James&nbsp;T. Kwok. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2308.07758" title="" class="ltx_ref ltx_href">Forward-backward reasoning in large language models for verification</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.07758.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jie et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhanming Jie, Trung&nbsp;Quoc Luong, Xinbo Zhang, Xiaoran Jin, and Hang Li. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2309.11054" title="" class="ltx_ref ltx_href">Design of chain-of-thought in math problem solving</a>.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin and Lu (2023)</span>
<span class="ltx_bibblock">
Ziqi Jin and Wei Lu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-acl.651" title="" class="ltx_ref ltx_href">Tab-cot: Zero-shot tabular chain of thought</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 10259–10277. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jones et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Erik Jones, Hamid Palangi, Clarisse Simões, Varun Chandrasekaran, Subhabrata Mukherjee, Arindam Mitra, Ahmed Awadallah, and Ece Kamar. 2023.

</span>
<span class="ltx_bibblock">Teaching language models to hallucinate less with synthetic tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.06827</em>.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpas et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Ehud&nbsp;D. Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, Amnon Shashua, and Moshe Tenenholtz. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:248496374" title="" class="ltx_ref ltx_href">Mrkl systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2205.00445.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katz et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Uri Katz, Mor Geva, and Jonathan Berant. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.findings-emnlp.188" title="" class="ltx_ref ltx_href">Inferring implicit relations in complex questions with language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 2548–2566. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khalifa et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, and Lu&nbsp;Wang. 2023.

</span>
<span class="ltx_bibblock">Discriminator-guided multi-step reasoning with language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14934</em>.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khot et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=_nGgzQjzaRy" title="" class="ltx_ref ltx_href">Decomposed prompting: A modular approach for solving complex tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang&nbsp;Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2022/hash/8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html" title="" class="ltx_ref ltx_href">Large language models are zero-shot reasoners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koncel-Kedziorski et&nbsp;al. (2015)</span>
<span class="ltx_bibblock">
Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena&nbsp;Dumas Ang. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00160" title="" class="ltx_ref ltx_href">Parsing algebraic word problems into equations</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, 3:585–597.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koncel-Kedziorski et&nbsp;al. (2016)</span>
<span class="ltx_bibblock">
Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/n16-1136" title="" class="ltx_ref ltx_href">MAWPS: A math word problem repository</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, USA, June 12-17, 2016</em>, pages 1152–1157. The Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lampinen et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Andrew&nbsp;K. Lampinen, Ishita Dasgupta, Stephanie C.&nbsp;Y. Chan, Kory&nbsp;W. Mathewson, Mh&nbsp;Tessler, Antonia Creswell, James&nbsp;L. McClelland, Jane Wang, and Felix Hill. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.findings-emnlp.38" title="" class="ltx_ref ltx_href">Can language models learn from explanations in context?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 537–563. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lange et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Matthias&nbsp;De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu&nbsp;Jia, Ales Leonardis, Gregory&nbsp;G. Slabaugh, and Tinne Tuytelaars. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/TPAMI.2021.3057446" title="" class="ltx_ref ltx_href">A continual learning survey: Defying forgetting in classification tasks</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Pattern Anal. Mach. Intell.</em>, 44(7):3366–3385.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lanham et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamile Lukosiute, Karina Nguyen, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch, Robin Larson, Sam McCandlish, Sandipan Kundu, Saurav Kadavath, Shannon Yang, Thomas Henighan, Timothy Maxwell, Timothy Telleen-Lawton, Tristan Hume, Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel&nbsp;R. Bowman, and Ethan Perez. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2307.13702" title="" class="ltx_ref ltx_href">Measuring faithfulness in chain-of-thought reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.13702.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee and Kim (2023)</span>
<span class="ltx_bibblock">
Soochan Lee and Gunhee Kim. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-acl.40" title="" class="ltx_ref ltx_href">Recursion of thought: A divide-and-conquer approach to multi-context reasoning with language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 623–658. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Bin Lei, Pei-Hung Lin, Chunhua Liao, and Caiwen Ding. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2308.08614" title="" class="ltx_ref ltx_href">Boosting logical reasoning in large language models through a new framework: The graph of thought</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.08614.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Deren Lei, Yaxi Li, Mingyu Wang, Vincent Yun, Emily Ching, Eslam Kamal, et&nbsp;al. 2023b.

</span>
<span class="ltx_bibblock">Chain of natural language inference for reducing large language model ungrounded hallucinations.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.03951</em>.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Jie Lei, Licheng Yu, Tamara&nbsp;L. Berg, and Mohit Bansal. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.706" title="" class="ltx_ref ltx_href">What is more likely to happen next? video-and-language future event prediction</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020</em>, pages 8769–8784. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewkowycz et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay&nbsp;V. Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2022/hash/18abbeef8cfe9203fdf9053c9c4fe191-Abstract-Conference.html" title="" class="ltx_ref ltx_href">Solving quantitative reasoning problems with language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Jiangtong Li, Li&nbsp;Niu, and Liqing Zhang. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/CVPR52688.2022.02059" title="" class="ltx_ref ltx_href">From representation to reasoning: Towards both evidence and commonsense reasoning for video question-answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022</em>, pages 21241–21250. IEEE.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Junnan Li, Dongxu Li, Silvio Savarese, and Steven C.&nbsp;H. Hoi. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.mlr.press/v202/li23q.html" title="" class="ltx_ref ltx_href">BLIP-2: bootstrapping language-image pre-training with frozen image encoders and large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA</em>, volume 202 of <em id="bib.bib76.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 19730–19742. PMLR.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Liunian&nbsp;Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, and Yejin Choi. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.150" title="" class="ltx_ref ltx_href">Symbolic chain-of-thought distillation: Small models can also "think" step-by-step</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 2665–2679. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023c)</span>
<span class="ltx_bibblock">
Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258179056" title="" class="ltx_ref ltx_href">Api-bank: A benchmark for tool-augmented llms</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2304.08244.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Xiang&nbsp;Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori Hashimoto, Luke Zettlemoyer, and Mike Lewis. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:253157949" title="" class="ltx_ref ltx_href">Contrastive decoding: Open-ended text generation as optimization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Qiu (2023)</span>
<span class="ltx_bibblock">
Xiaonan Li and Xipeng Qiu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.05181" title="" class="ltx_ref ltx_href">Mot: Pre-thinking and recalling enable chatgpt to self-improve with memory-of-thoughts</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.05181.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023d)</span>
<span class="ltx_bibblock">
Xingxuan Li, Ruochen Zhao, Yew&nbsp;Ken Chia, Bosheng Ding, Lidong Bing, Shafiq&nbsp;R. Joty, and Soujanya Poria. 2023d.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.13269" title="" class="ltx_ref ltx_href">Chain of knowledge: A framework for grounding large language models with structured knowledge bases</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.13269.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2022c)</span>
<span class="ltx_bibblock">
Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, B.&nbsp;Chen, Jian-Guang Lou, and Weizhu Chen. 2022c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:259370847" title="" class="ltx_ref ltx_href">Making language models better reasoners with step-aware verifier</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023e)</span>
<span class="ltx_bibblock">
Yingcong Li, Kartik Sreenivasan, Angeliki Giannou, Dimitris&nbsp;S. Papailiopoulos, and Samet Oymak. 2023e.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.18869" title="" class="ltx_ref ltx_href">Dissecting chain-of-thought: A study on compositional in-context learning of mlps</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.18869.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ling et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1015" title="" class="ltx_ref ltx_href">Program induction by rationale generation: Learning to solve and explain algebraic word problems</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers</em>, pages 158–167. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ling et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland Memisevic, and Hao Su. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2306.03872" title="" class="ltx_ref ltx_href">Deductive verification of chain-of-thought reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.03872.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Bo&nbsp;Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2304.11477" title="" class="ltx_ref ltx_href">Llm+p: Empowering large language models with optimal planning proficiency</a>.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Jiacheng Liu, Ramakanth Pasunuru, Hannaneh Hajishirzi, Yejin Choi, and Asli Celikyilmaz. 2023b.

</span>
<span class="ltx_bibblock">Crystal: Introspective reasoners reinforced with self-feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.04921</em>.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.24963/ijcai.2020/501" title="" class="ltx_ref ltx_href">Logiqa: A challenge dataset for machine reading comprehension with logical reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020</em>, pages 3622–3628. ijcai.org.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Long (2023)</span>
<span class="ltx_bibblock">
Jieyi Long. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.08291" title="" class="ltx_ref ltx_href">Large language model guided tree-of-thought</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.08291.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Hongyuan Lu, Haoyang Huang, Dongdong Zhang, Haoran Yang, Wai Lam, and Furu Wei. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.06575" title="" class="ltx_ref ltx_href">Chain-of-dictionary prompting elicits translation in large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.06575.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2022/hash/11332b6b6cf4485b84afadb1352d3a9a-Abstract-Conference.html" title="" class="ltx_ref ltx_href">Learn to explain: Multimodal reasoning via thought chains for science question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Pan Lu, Liang Qiu, Kai-Wei Chang, Ying&nbsp;Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, and Ashwin Kalyan. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=DHyHRBwJUTN" title="" class="ltx_ref ltx_href">Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et&nbsp;al. (2023c)</span>
<span class="ltx_bibblock">
Yining Lu, Haoping Yu, and Daniel Khashabi. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2307.08775" title="" class="ltx_ref ltx_href">Gear: Augmenting language models with generalizable and efficient tool resolution</a>.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Qing Lyu, Shreya Havaldar, Adam Stein, Li&nbsp;Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and Chris Callison-Burch. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2301.13379" title="" class="ltx_ref ltx_href">Faithful chain-of-thought reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2301.13379.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaan et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean Welleck, Bodhisattwa&nbsp;Prasad Majumder, Shashank Gupta, Amir Yazdanbakhsh, and Peter Clark. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.17651" title="" class="ltx_ref ltx_href">Self-refine: Iterative refinement with self-feedback</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.17651.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaan and Yazdanbakhsh (2022)</span>
<span class="ltx_bibblock">
Aman Madaan and Amir Yazdanbakhsh. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2209.07686" title="" class="ltx_ref ltx_href">Text and patterns: For effective chain of thought, it takes two to tango</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2209.07686.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaan et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, and Graham Neubig. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.emnlp-main.90" title="" class="ltx_ref ltx_href">Language models of code are few-shot commonsense learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 1384–1403. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Magister et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lucie&nbsp;Charlotte Magister, Jonathan Mallinson, Jakub Adámek, Eric Malmi, and Aliaksei Severyn. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-short.151" title="" class="ltx_ref ltx_href">Teaching small language models to reason</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 1773–1781. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merrill and Sabharwal (2023)</span>
<span class="ltx_bibblock">
William Merrill and Ashish Sabharwal. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.07923" title="" class="ltx_ref ltx_href">The expresssive power of transformers with chain of thought</a>.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ning Miao, Yee&nbsp;Whye Teh, and Tom Rainforth. 2023.

</span>
<span class="ltx_bibblock">Selfcheck: Using llms to zero-shot check their own step-by-step reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.00436</em>.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miao et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Shen-yun Miao, Chao-Chun Liang, and Keh-Yih Su. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.92" title="" class="ltx_ref ltx_href">A diverse corpus for evaluating and developing English math word problem solvers</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 975–984, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mihaylov et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D18-1260" title="" class="ltx_ref ltx_href">Can a suit of armor conduct electricity? a new dataset for open book question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 2381–2391, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, and Ashwin Kalyan. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.emnlp-main.392" title="" class="ltx_ref ltx_href">LILA: A unified benchmark for mathematical reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 5807–5832. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Swaroop Mishra, Arindam Mitra, Neeraj Varshney, Bhavdeep&nbsp;Singh Sachdeva, Peter Clark, Chitta Baral, and Ashwin Kalyan. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.acl-long.246" title="" class="ltx_ref ltx_href">Numglue: A suite of fundamental yet challenging mathematical reasoning tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, pages 3505–3523. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo and Xin (2023)</span>
<span class="ltx_bibblock">
Shentong Mo and Miao Xin. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2309.07694" title="" class="ltx_ref ltx_href">Tree of uncertain thoughts reasoning for large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.07694.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naik et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ranjita Naik, Varun Chandrasekaran, Mert Yuksekgonul, Hamid Palangi, and Besmira Nushi. 2023.

</span>
<span class="ltx_bibblock">Diversity of thought improves reasoning abilities of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.07088</em>.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ning et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, and Yu&nbsp;Wang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2307.15337" title="" class="ltx_ref ltx_href">Skeleton-of-thought: Large language models can do parallel decoding</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.15337.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">O’Brien and Lewis (2023)</span>
<span class="ltx_bibblock">
Sean O’Brien and Mike Lewis. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:261884427" title="" class="ltx_ref ltx_href">Contrastive decoding improves reasoning in large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2309.09117.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.08774" title="" class="ltx_ref ltx_href">GPT-4 technical report</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.08774.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paranjape et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco&nbsp;Tulio Ribeiro. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2303.09014" title="" class="ltx_ref ltx_href">Art: Automatic multi-step reasoning and tool-use for large language models</a>.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parisi et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:249017698" title="" class="ltx_ref ltx_href">Talm: Tool augmented language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2205.12255.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parisi et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2205.12255" title="" class="ltx_ref ltx_href">TALM: tool augmented language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2205.12255.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Jae&nbsp;Sung Park, Chandra Bhagavatula, Roozbeh Mottaghi, Ali Farhadi, and Yejin Choi. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1007/978-3-030-58558-7_30" title="" class="ltx_ref ltx_href">Visualcomet: Reasoning about the dynamic context of a still image</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">Computer Vision - ECCV 2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part V</em>, volume 12350 of <em id="bib.bib113.2.2" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>, pages 508–524. Springer.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patel et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.168" title="" class="ltx_ref ltx_href">Are NLP models really able to solve simple math word problems?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021</em>, pages 2080–2094. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paul et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Debjit Paul, Mete Ismayilzada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, Robert West, and Boi Faltings. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2304.01904" title="" class="ltx_ref ltx_href">REFINER: reasoning feedback on intermediate representations</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.01904.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhiliang Peng, Wenhui Wang, Li&nbsp;Dong, Yaru Hao, Shaohan Huang, Shuming Ma, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2306.14824" title="" class="ltx_ref ltx_href">Kosmos-2: Grounding multimodal large language models to the world</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.14824.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pitis et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Silviu Pitis, Michael&nbsp;R. Zhang, Andrew Wang, and Jimmy Ba. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2304.05970" title="" class="ltx_ref ltx_href">Boosted prompt ensembles for large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.05970.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, and Huajun Chen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.acl-long.294" title="" class="ltx_ref ltx_href">Reasoning with language model prompting: A survey</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 5368–5393. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford and Narasimhan (2018)</span>
<span class="ltx_bibblock">
Alec Radford and Karthik Narasimhan. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:49313245" title="" class="ltx_ref ltx_href">Improving language understanding by generative pre-training</a>.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radhakrishnan et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ansh Radhakrishnan, Karina Nguyen, Anna Chen, Carol Chen, Carson Denison, Danny Hernandez, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamile Lukosiute, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch, Sam McCandlish, Sheer&nbsp;El Showk, Tamera Lanham, Tim Maxwell, Venkatesa Chandrasekaran, Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel&nbsp;R. Bowman, and Ethan Perez. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2307.11768" title="" class="ltx_ref ltx_href">Question decomposition improves the faithfulness of model-generated reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.11768.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J. Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, 21(1).

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rashkin et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Hannah Rashkin, Maarten Sap, Emily Allaway, Noah&nbsp;A. Smith, and Yejin Choi. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P18-1043" title="" class="ltx_ref ltx_href">Event2mind: Commonsense inference on events, intents, and reactions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers</em>, pages 463–473. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy and Roth (2015)</span>
<span class="ltx_bibblock">
Subhro Roy and Dan Roth. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D15-1202" title="" class="ltx_ref ltx_href">Solving general arithmetic word problems</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</em>, pages 1743–1752, Lisbon, Portugal. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruan et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Xingyu Zeng, and Rui Zhao. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2308.03427" title="" class="ltx_ref ltx_href">Tptu: Task planning and tool usage of large language model-based ai agents</a>.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saparov and He (2023)</span>
<span class="ltx_bibblock">
Abulhair Saparov and He&nbsp;He. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=qFVVBzXxR2V" title="" class="ltx_ref ltx_href">Language models are greedy reasoners: A systematic formal analysis of chain-of-thought</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagné, Alexandra&nbsp;Sasha Luccioni, François Yvon, Matthias Gallé, Jonathan Tow, Alexander&nbsp;M. Rush, Stella Biderman, Albert Webson, Pawan&nbsp;Sasanka Ammanamanchi, Thomas Wang, Benoît Sagot, Niklas Muennighoff, Albert&nbsp;Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major, Iz&nbsp;Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro&nbsp;Ortiz Suarez, Victor Sanh, Hugo Laurençon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa, Alham&nbsp;Fikri Aji, Amit Alfassy, Anna Rogers, Ariel&nbsp;Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue, Christopher Klamm, Colin Leong, Daniel van Strien, David&nbsp;Ifeoluwa Adelani, and et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2211.05100" title="" class="ltx_ref ltx_href">BLOOM: A 176b-parameter open-access multilingual language model</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2211.05100.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schaeffer et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2304.15004" title="" class="ltx_ref ltx_href">Are emergent abilities of large language models a mirage?</a>

</span>
<span class="ltx_bibblock"><em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.15004.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.04761" title="" class="ltx_ref ltx_href">Toolformer: Language models can teach themselves to use tools</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.04761.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sel et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Lu&nbsp;Wang, Ruoxi Jia, and Ming Jin. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2308.10379" title="" class="ltx_ref ltx_href">Algorithm of thoughts: Enhancing exploration of ideas in large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.10379.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.00618" title="" class="ltx_ref ltx_href">Synthetic prompting: Generating chain-of-thought demonstrations for large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.00618.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yongliang Shen, Kaitao Song, Xu&nbsp;Tan, Dong&nbsp;Sheng Li, Weiming Lu, and Yue&nbsp;Ting Zhuang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:257833781" title="" class="ltx_ref ltx_href">Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2303.17580.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung&nbsp;Won Chung, Yi&nbsp;Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=fR3wGCk-IXp" title="" class="ltx_ref ltx_href">Language models are multilingual chain-of-thought reasoners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinn et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258833055" title="" class="ltx_ref ltx_href">Reflexion: Language agents with verbal reinforcement learning</a>.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shridhar et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Kumar Shridhar, Harsh Jhamtani, Hao Fang, Benjamin Van&nbsp;Durme, Jason Eisner, and Patrick Xia. 2023.

</span>
<span class="ltx_bibblock">Screws: A modular framework for reasoning with revisions.

</span>
<span class="ltx_bibblock"><em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.13075</em>.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shum et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Kashun Shum, Shizhe Diao, and Tong Zhang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.12822" title="" class="ltx_ref ltx_href">Automatic prompt augmentation and selection with chain-of-thought from labeled data</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.12822.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal&nbsp;Md Shoeb, Abubakar Abid, Adam Fisch, Adam&nbsp;R. Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander&nbsp;W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ameet Rahane, Anantharaman&nbsp;S. Iyer, Anders Andreassen, Andrea Santilli, Andreas Stuhlmüller, Andrew&nbsp;M. Dai, Andrew La, Andrew&nbsp;K. Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas, and et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2206.04615" title="" class="ltx_ref ltx_href">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2206.04615.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo&nbsp;Dai, and Chao Zhang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258947337" title="" class="ltx_ref ltx_href">Adaplanner: Adaptive planning from feedback with language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.16653.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suzgun et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi&nbsp;Tay, Hyung&nbsp;Won Chung, Aakanksha Chowdhery, Quoc&nbsp;V. Le, Ed&nbsp;Chi, Denny Zhou, and Jason Wei. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-acl.824" title="" class="ltx_ref ltx_href">Challenging big-bench tasks and whether chain-of-thought can solve them</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 13003–13051. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tafjord et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Oyvind Tafjord, Bhavana Dalvi, and Peter Clark. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.findings-acl.317" title="" class="ltx_ref ltx_href">Proofwriter: Generating implications, proofs, and abductive statements over natural language</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021</em>, volume ACL/IJCNLP 2021 of <em id="bib.bib139.2.2" class="ltx_emph ltx_font_italic">Findings of ACL</em>, pages 3621–3634. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talmor et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/n19-1421" title="" class="ltx_ref ltx_href">Commonsenseqa: A question answering challenge targeting commonsense knowledge</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>, pages 4149–4158. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talmor et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Alon Talmor, Ori Yoran, Ronan&nbsp;Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and Jonathan Berant. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/3ef815416f775098fe977004015c6193-Abstract-round1.html" title="" class="ltx_ref ltx_href">Commonsenseqa 2.0: Exposing the limits of AI through gamification</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual</em>.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xiaojuan Tang, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.14825" title="" class="ltx_ref ltx_href">Large language models are in-context semantic reasoners rather than symbolic reasoners</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.14825.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.13971" title="" class="ltx_ref ltx_href">Llama: Open and efficient foundation language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.13971.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit&nbsp;Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric&nbsp;Michael Smith, Ranjan Subramanian, Xiaoqing&nbsp;Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian&nbsp;Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurélien Rodriguez, Robert Stojnic, Sergey Edunov,
and Thomas Scialom. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2307.09288" title="" class="ltx_ref ltx_href">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.09288.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan&nbsp;Ö. Arik, and Tomas Pfister. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-acl.216" title="" class="ltx_ref ltx_href">Better zero-shot reasoning with self-adaptive prompting</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 3493–3514. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Boshi Wang, Xiang Deng, and Huan Sun. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.emnlp-main.174" title="" class="ltx_ref ltx_href">Iteratively prompt pre-trained language models for chain of thought</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 2714–2730. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, and Huan Sun. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.153" title="" class="ltx_ref ltx_href">Towards understanding chain-of-thought prompting: An empirical study of what matters</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 2717–2739. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Cunxiang Wang, Shuailong Liang, Yue Zhang, Xiaonan Li, and Tian Gao. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1393" title="" class="ltx_ref ltx_href">Does it make sense? and why? a pilot study for sense making and explanation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 4020–4026, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Jianing Wang, Qiushi Sun, Nuo Chen, Xiang Li, and Ming Gao. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2306.06427" title="" class="ltx_ref ltx_href">Boosting language models reasoning with chain-of-knowledge prompting</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.06427.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023c)</span>
<span class="ltx_bibblock">
Keheng Wang, Feiyu Duan, Sirui Wang, Peiguang Li, Yunsen Xian, Chuantao Yin, Wenge Rong, and Zhang Xiong. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2308.13259" title="" class="ltx_ref ltx_href">Knowledge-driven cot: Exploring faithful reasoning in llms for knowledge-intensive question answering</a>.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023d)</span>
<span class="ltx_bibblock">
Lei Wang, Yi&nbsp;Hu, Jiabang He, Xing Xu, Ning Liu, Hui Liu, and Heng&nbsp;Tao Shen. 2023d.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.03453" title="" class="ltx_ref ltx_href">T-sciq: Teaching multimodal chain-of-thought reasoning via large language model signals for science question answering</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.03453.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023e)</span>
<span class="ltx_bibblock">
Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu&nbsp;Chen, Yankai Lin, Wayne&nbsp;Xin Zhao, Zhewei Wei, and Ji-Rong Wen. 2023e.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2308.11432" title="" class="ltx_ref ltx_href">A survey on large language model based autonomous agents</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.11432.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023f)</span>
<span class="ltx_bibblock">
Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy&nbsp;Ka-Wei Lee, and Ee-Peng Lim. 2023f.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.acl-long.147" title="" class="ltx_ref ltx_href">Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 2609–2634. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023g)</span>
<span class="ltx_bibblock">
Liyuan Wang, Xingxing Zhang, Hang Su, and Jun Zhu. 2023g.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.00487" title="" class="ltx_ref ltx_href">A comprehensive survey of continual learning: Theory, method and application</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.00487.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023h)</span>
<span class="ltx_bibblock">
Peifeng Wang, Zhengyang Wang, Zheng Li, Yifan Gao, Bing Yin, and Xiang Ren. 2023h.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258461058" title="" class="ltx_ref ltx_href">Scott: Self-consistent chain-of-thought distillation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib155.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Wenhui Wang, Hangbo Bao, Li&nbsp;Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais&nbsp;Khan Mohammed, Saksham Singhal, Subhojit Som, and Furu Wei. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2208.10442" title="" class="ltx_ref ltx_href">Image as a foreign language: Beit pretraining for all vision and vision-language tasks</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib156.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2208.10442.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023i)</span>
<span class="ltx_bibblock">
Xinyi Wang, Lucas Caccia, Oleksiy Ostapenko, Xingdi Yuan, and Alessandro Sordoni. 2023i.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.05707" title="" class="ltx_ref ltx_href">Guiding language model reasoning with planning tokens</a>.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023j)</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc&nbsp;V. Le, Ed&nbsp;H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023j.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=1PL1NIMMrw" title="" class="ltx_ref ltx_href">Self-consistency improves chain of thought reasoning in language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023k)</span>
<span class="ltx_bibblock">
Yiming Wang, Zhuosheng Zhang, and Rui Wang. 2023k.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.482" title="" class="ltx_ref ltx_href">Element-aware summarization with large language models: Expert-aligned evaluation and chain-of-thought method</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib159.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 8640–8665. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Jason Wei, Yi&nbsp;Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed&nbsp;H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=yzkSU5zdwD" title="" class="ltx_ref ltx_href">Emergent abilities of large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib160.1.1" class="ltx_emph ltx_font_italic">Trans. Mach. Learn. Res.</em>, 2022.

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed&nbsp;H. Chi, Quoc&nbsp;V. Le, and Denny Zhou. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html" title="" class="ltx_ref ltx_href">Chain-of-thought prompting elicits reasoning in large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weng et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu, and Jun Zhao. 2022.

</span>
<span class="ltx_bibblock">Large language models are reasoners with self-verification.

</span>
<span class="ltx_bibblock"><em id="bib.bib162.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.09561</em>.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Bo&nbsp;Wu, Shoubin Yu, Zhenfang Chen, Josh Tenenbaum, and Chuang Gan. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/5ef059938ba799aaa845e1c2e8a762bd-Abstract-round2.html" title="" class="ltx_ref ltx_href">STAR: A benchmark for situated reasoning in real-world videos</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib163.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual</em>.

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Skyler Wu, Eric&nbsp;Meng Shen, Charumathi Badrinath, Jiaqi Ma, and Himabindu Lakkaraju. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2307.13339" title="" class="ltx_ref ltx_href">Analyzing chain-of-thought prompting in large language models via gradient-based feature attributions</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib164.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.13339.

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xi et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi&nbsp;Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huan, and Tao Gui. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2309.07864" title="" class="ltx_ref ltx_href">The rise and potential of large language model based agents: A survey</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib165.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.07864.

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Junbin Xiao, Xindi Shang, Angela Yao, and Tat-Seng Chua. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/CVPR46437.2021.00965" title="" class="ltx_ref ltx_href">Next-qa: Next phase of question-answering to explaining temporal actions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib166.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021</em>, pages 9777–9786. Computer Vision Foundation / IEEE.

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jojic. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2305.09993" title="" class="ltx_ref ltx_href">Reprompting: Automated chain-of-thought prompt inference through gibbs sampling</a>.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, and Heng Ji. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.11499" title="" class="ltx_ref ltx_href">RCOT: detecting and rectifying factual inconsistency in reasoning by reversing chain-of-thought</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib168.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.11499.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu, Ce&nbsp;Liu, Michael Zeng, and Lijuan Wang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.11381" title="" class="ltx_ref ltx_href">MM-REACT: prompting chatgpt for multimodal reasoning and action</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib169.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.11381.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Zonglin Yang, Li&nbsp;Dong, Xinya Du, Hao Cheng, Erik Cambria, Xiaodong Liu, Jianfeng Gao, and Furu Wei. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2212.10923" title="" class="ltx_ref ltx_href">Language models as inductive reasoners</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib170.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2212.10923.

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Fanglong Yao, Changyuan Tian, Jintao Liu, Zequn Zhang, Qing Liu, Li&nbsp;Jin, Shuchao Li, Xiaoyu Li, and Xian Sun. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2308.06207" title="" class="ltx_ref ltx_href">Thinking like an expert:multimodal hypergraph-of-thought (hot) reasoning to boost foundation modals</a>.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas&nbsp;L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.10601" title="" class="ltx_ref ltx_href">Tree of thoughts: Deliberate problem solving with large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib172.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.10601.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2023c)</span>
<span class="ltx_bibblock">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik&nbsp;R. Narasimhan, and Yuan Cao. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=WE_vluYUL-X" title="" class="ltx_ref ltx_href">React: Synergizing reasoning and acting in language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib173.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2023d)</span>
<span class="ltx_bibblock">
Yao Yao, Zuchao Li, and Hai Zhao. 2023d.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.16582" title="" class="ltx_ref ltx_href">Beyond chain-of-thought, effective graph-of-thought reasoning in large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib174.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.16582.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye and Durrett (2022)</span>
<span class="ltx_bibblock">
Xi&nbsp;Ye and Greg Durrett. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2205.03401" title="" class="ltx_ref ltx_href">The unreliability of explanations in few-shot in-context learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib175.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2205.03401.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye and Durrett (2023)</span>
<span class="ltx_bibblock">
Xi&nbsp;Ye and Greg Durrett. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.04813" title="" class="ltx_ref ltx_href">Explanation selection using unlabeled data for in-context learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib176.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.04813.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, and Yongbin Li. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3539618.3591708" title="" class="ltx_ref ltx_href">Large language models are versatile decomposers: Decomposing evidence and questions for table-based reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib177.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023</em>, pages 174–184. ACM.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, and Joshua&nbsp;B. Tenenbaum. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=HkxYzANYDB" title="" class="ltx_ref ltx_href">CLEVRER: collision events for video representation and reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib178.1.1" class="ltx_emph ltx_font_italic">8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoran et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ori Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel Deutch, and Jonathan Berant. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2304.13007" title="" class="ltx_ref ltx_href">Answering questions by meta-reasoning over multiple chains of thought</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib179.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.13007.

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Fei Yu, Hongbo Zhang, and Benyou Wang. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.14725" title="" class="ltx_ref ltx_href">Nature language reasoning, A survey</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib180.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.14725.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Junchi Yu, Ran He, and Rex Ying. 2023b.

</span>
<span class="ltx_bibblock">Thought propagation: An analogical approach to complex reasoning with large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib181.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.03965</em>.

</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Weihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi Feng. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=HJgJtT4tvB" title="" class="ltx_ref ltx_href">Reclor: A reading comprehension dataset requiring logical reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2021a)</span>
<span class="ltx_bibblock">
Weijiang Yu, Yingpeng Wen, Fudan Zheng, and Nong Xiao. 2021a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.272" title="" class="ltx_ref ltx_href">Improving math word problems with pre-trained knowledge and hierarchical reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib183.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 3384–3394, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2021b)</span>
<span class="ltx_bibblock">
Weijiang Yu, Haoteng Zheng, Mengfei Li, Lei Ji, Lijun Wu, Nong Xiao, and Nan Duan. 2021b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2021/file/dea184826614d3f4c608731389ed0c74-Paper.pdf" title="" class="ltx_ref ltx_href">Learning from inside: Self-driven siamese sampling and reasoning for video question answering</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib184.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 34:26462–26474.

</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023c)</span>
<span class="ltx_bibblock">
Zihan Yu, Liang He, Zhen Wu, Xinyu Dai, and Jiajun Chen. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.04959" title="" class="ltx_ref ltx_href">Towards better chain-of-thought prompting strategies: A survey</a>.

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zelikman et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah&nbsp;D. Goodman. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2022/hash/639a9a172c044fbb64175b5fad42e9a5-Abstract-Conference.html" title="" class="ltx_ref ltx_href">Star: Bootstrapping reasoning with reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib186.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/CVPR.2019.00688" title="" class="ltx_ref ltx_href">From recognition to cognition: Visual commonsense reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib187.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019</em>, pages 6720–6731. Computer Vision Foundation / IEEE.

</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Bowen Zhang, Kehua Chang, and Chunping Li. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2309.11143" title="" class="ltx_ref ltx_href">Cot-bert: Enhancing unsupervised sentence representation through chain-of-thought</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib188.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.11143.

</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Parkes (2023)</span>
<span class="ltx_bibblock">
Hugh Zhang and David&nbsp;C. Parkes. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2309.08589" title="" class="ltx_ref ltx_href">Chain-of-thought reasoning is a policy improvement operator</a>.

</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke&nbsp;Chen, Gang Chen, and Sharad Mehrotra. 2023b.

</span>
<span class="ltx_bibblock">Draft &amp; verify: Lossless large language model acceleration via self-speculative decoding.

</span>
<span class="ltx_bibblock"><em id="bib.bib190.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.08168</em>.

</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023c)</span>
<span class="ltx_bibblock">
Li&nbsp;Zhang, Liam Dugan, Hainiu Xu, and Chris Callison-Burch. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2304.13250" title="" class="ltx_ref ltx_href">Exploring the curious case of code prompts</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib191.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.13250.

</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023d)</span>
<span class="ltx_bibblock">
Muru Zhang, Ofir Press, William Merrill, Alisa Liu, and Noah&nbsp;A. Smith. 2023d.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.13534" title="" class="ltx_ref ltx_href">How language model hallucinations can snowball</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib192.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.13534.

</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Sarah&nbsp;J. Zhang, Reece Shuttleworth, Derek Austin, Yann Hicke, Leonard Tang, Sathwik Karnik, Darnell Granberry, and Iddo Drori. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2206.05442" title="" class="ltx_ref ltx_href">A dataset and benchmark for automatically answering and generating machine learning final exams</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib193.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2206.05442.

</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023e)</span>
<span class="ltx_bibblock">
Tianhua Zhang, Jiaxin Ge, Hongyin Luo, Yung-Sung Chuang, Mingye Gao, Yuan Gong, Xixin Wu, Yoon Kim, Helen Meng, and James Glass. 2023e.

</span>
<span class="ltx_bibblock">Natural language embedded programs for hybrid language symbolic reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib194.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.10814</em>.

</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Zhang (2023)</span>
<span class="ltx_bibblock">
Zhuosheng Zhang and Aston Zhang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2309.11436" title="" class="ltx_ref ltx_href">You only look at screens: Multimodal chain-of-action agents</a>.

</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023f)</span>
<span class="ltx_bibblock">
Zhuosheng Zhang, Aston Zhang, Mu&nbsp;Li, and Alex Smola. 2023f.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=5NTt8GFjUHkr" title="" class="ltx_ref ltx_href">Automatic chain of thought prompting in large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib196.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023g)</span>
<span class="ltx_bibblock">
Zhuosheng Zhang, Aston Zhang, Mu&nbsp;Li, Hai Zhao, George Karypis, and Alex Smola. 2023g.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.00923" title="" class="ltx_ref ltx_href">Multimodal chain-of-thought reasoning in language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib197.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.00923.

</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, and Lidong Bing. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.320" title="" class="ltx_ref ltx_href">Verify-and-edit: A knowledge-enhanced chain-of-thought framework</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib198.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 5823–5840. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Wayne&nbsp;Xin Zhao, Kun Zhou, Zheng Gong, Beichen Zhang, Yuanhang Zhou, Jing Sha, Zhigang Chen, Shijin Wang, Cong Liu, and Ji-Rong Wen. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3534678.3539131" title="" class="ltx_ref ltx_href">Jiuzhang: A chinese pre-trained language model for mathematical problem understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib199.1.1" class="ltx_emph ltx_font_italic">KDD ’22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022</em>, pages 4571–4581. ACM.

</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Wayne&nbsp;Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.18223" title="" class="ltx_ref ltx_href">A survey of large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib200.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.18223.

</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023c)</span>
<span class="ltx_bibblock">
Xufeng Zhao, Mengdi Li, Wenhao Lu, Cornelius Weber, Jae&nbsp;Hee Lee, Kun Chu, and Stefan Wermter. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2309.13339" title="" class="ltx_ref ltx_href">Enhancing zero-shot chain-of-thought reasoning in large language models through logic</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib201.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.13339.

</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Huaixiu&nbsp;Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed&nbsp;H Chi, Quoc&nbsp;V Le, and Denny Zhou. 2023.

</span>
<span class="ltx_bibblock">Take a step back: Evoking reasoning via abstraction in large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib202.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.06117</em>.

</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.04406" title="" class="ltx_ref ltx_href">Language agent tree search unifies reasoning acting and planning in language models</a>.

</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1332" title="" class="ltx_ref ltx_href">"going on a vacation" takes longer than "going for a walk": A study of temporal commonsense understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib204.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019</em>, pages 3361–3367. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Denny Zhou, Nathanael Schärli, Le&nbsp;Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc&nbsp;V. Le, and Ed&nbsp;H. Chi. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/pdf?id=WZH7099tgfM" title="" class="ltx_ref ltx_href">Least-to-most prompting enables complex reasoning in large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib205.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023c)</span>
<span class="ltx_bibblock">
Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, and Lei Ma. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2308.13724" title="" class="ltx_ref ltx_href">Isr-llm: Iterative self-refined large language model for long-horizon sequential task planning</a>.

</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.acl-long.254" title="" class="ltx_ref ltx_href">TAT-QA: A question answering benchmark on a hybrid of tabular and textual content in finance</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib207.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021</em>, pages 3277–3287. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Anni Zou, Zhuosheng Zhang, Hai Zhao, and Xiangru Tang. 2023.

</span>
<span class="ltx_bibblock">Meta-cot: Generalizable chain-of-thought prompting in mixed-task scenarios with large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib208.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.06692</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2309.15401" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2309.15402" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2309.15402">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2309.15402" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2309.15404" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 04:09:45 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>