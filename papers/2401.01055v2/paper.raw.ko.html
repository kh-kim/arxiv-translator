<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>LLaMA Beyond English: An Empirical Study on Language Capability Transfer</title>
<!--Generated on Fri Jan 12 08:13:56 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/addons.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="https://arxiv.org/html/2401.01055v2/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2401.01055v2">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2401.01055v2">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2401.01055v2" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC mobile collapse" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#Sx1" title="Introduction ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#Sx2" title="Background and Overview ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Background and Overview</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx2.SSx1" title="Step 1: Pretraining to acquire language capability and knowledge ‣ Background and Overview ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Step 1: Pretraining to acquire language capability and knowledge</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx2.SSx2" title="Step 2: Instruction tuning for aligning with human intent ‣ Background and Overview ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Step 2: Instruction tuning for aligning with human intent</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx2.SSx3" title="Extrapolating LLMs to non-English languages ‣ Background and Overview ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Extrapolating LLMs to non-English languages</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#Sx3" title="Experimental Setup ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx3.SSx1" title="Models ‣ Experimental Setup ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx3.SSx2" title="Datasets ‣ Experimental Setup ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx3.SSx3" title="Evaluation Protocol ‣ Experimental Setup ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Evaluation Protocol</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#Sx4" title="Main Results ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Main Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx4.SSx1" title="The Impact of Vocabulary Extension on Transfer ‣ Main Results ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">The Impact of Vocabulary Extension on Transfer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx4.SSx2" title="Training Scales Required for Effective Transfer ‣ Main Results ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Training Scales Required for Effective Transfer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx4.SSx3" title="How about the Original English Capabilities ‣ Main Results ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">How about the Original English Capabilities</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#Sx5" title="Extending the Analysis to Multiple Languages ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Extending the Analysis to Multiple Languages</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#Sx6" title="Related Work ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx6.SSx1" title="Resource Gap in LLMs ‣ Related Work ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Resource Gap in LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx6.SSx2" title="Cross-Lingual Transfer ‣ Related Work ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Cross-Lingual Transfer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#Sx6.SSx3" title="Code-Switching ‣ Related Work ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Code-Switching</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#Sx7" title="Conclusions ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_title">Conclusions</span></a></li>
</ol></nav>

<div class="ltx_page_content">
<div aria-label="”Conversion" been="" class="package-alerts ltx_document" errors="" found”="" have="" role="“status”">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewBox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: mdwlist</li>
<li>failed: bibentry</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><div class="section" id="target-section"><div id="license-tr">License: arXiv.org perpetual non-exclusive license</div><div id="watermark-tr">arXiv:2401.01055v2 [cs.CL] 12 Jan 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">LLaMA Beyond English: An Empirical Study on Language Capability Transfer</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Jun Zhao<span class="ltx_ERROR undefined" id="id2.1.id1">\equalcontrib</span>,
Zhihao Zhang<span class="ltx_ERROR undefined" id="id3.2.id2">\equalcontrib</span>,
Luhui Gao,
Qi Zhang,
Tao Gui,
Xuanjing Huang
</span><span class="ltx_author_notes">Corresponding Author</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id1.1">최근, ChatGPT로 예시되는 대규모 언어 모델(LLM)에서 상당한 발전이 목격되어 다양한 복잡한 작업에 걸쳐 놀라운 숙련도를 보여준다. 그러나, 많은 주류 LLMs(예를 들어, LLaMA)는 영어-지배 코퍼스에 사전 훈련되어, 다른 비영어 언어에서의 성능을 제한한다. 본 논문에서는 언어 생성 및 명령어 수행 능력을 비영어 언어로 효과적으로 전달하는 방법에 초점을 맞춘다. 이 질문에 답하기 위해 우리는 1440 GPU 시간이 넘는 LLaMA를 기반으로 광범위한 경험적 조사를 수행한다. 어휘 확장, 추가 사전 훈련 및 명령어 튜닝과 같은 핵심 요소가 전이에 미치는 영향을 분석한다. 모델의 지식 수준을 정확하게 평가하기 위해 널리 사용되는 4개의 표준화된 테스트 벤치마크인 C-Eval, MMLU, AGI-Eval 및 GAOKAO-Bench를 사용한다. 또한 17개의 다양한 범주의 수업 과제를 구성하는 벤치마크인 LLM-Eval을 기반으로 정확성, 유창성, 정보성, 논리적 일관성, 무해성 등의 측면을 고려하여 모델의 응답 품질을 종합적으로 평가한다. 우리의 평가 결과는 지식 정렬 및 응답 품질 측면에서 사전 훈련 데이터의 <math alttext="1\%" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mn id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">1</mn><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="latexml" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1">percent</csymbol><cn id="id1.1.m1.1.1.2.cmml" type="integer" xref="id1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">1\%</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">1 %</annotation></semantics></math> 미만으로 최첨단 전달 모델과 비교할 수 있는 성능을 달성할 수 있음을 보여준다. 또한, 13개의 저자원 언어에 걸친 실험 결과도 유사한 경향을 보인다. 실험에 의해 밝혀진 결론이 커뮤니티가 비영어 LLM을 개발하는 데 도움이 될 것으로 기대한다.</p>
</div>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="Sx1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="502" id="Sx1.F1.g1" src="https://arxiv.org/html/2401.01055v2/x1.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">그림 1: </span> 영어 지배 코퍼스(왼쪽에 묘사된 바와 같이)에서 주로 훈련되는 사전 훈련된 LLaMA 모델은 본질적으로 비영어 언어를 다루는 데 능숙하지 않다.</figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Pretrained LLaMA models, which are primarily trained on English-dominated corpus (as depicted on the left), are not inherently proficient in handling non-English languages.
We aim to investigate the necessity of vocabulary extension, further pretraining, and instruction tuning, as well as to what extent they influence the capability transfer.
This exploration enables us to efficiently transfer LLaMA’s language capabilities to non-English languages (as illustrated on the right), minimizing costs in the process.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">수십 년 동안 자연어 처리(NLP) 분야의 연구자들은 지능 <cite class="ltx_cite ltx_citemacro_citep">(Bubeck et al. <a class="ltx_ref" href="#bib.bib3" title="">2023</a>)</cite>의 기본 원리를 탐구해 왔다. 최근 대형 언어 모델(LLM)의 발전은 희미한 희망을 드러낸 것 같다. 모델 크기와 훈련 데이터의 전례 없는 규모에서 이점을 얻을 수 있는 많은 LLMs, ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(OpenAI <a class="ltx_ref" href="#bib.bib32" title="">2022</a>)</cite>, PaLM <cite class="ltx_cite ltx_citemacro_citep">(Anil et al. <a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>, LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al. <a class="ltx_ref" href="#bib.bib43" title="">2023a</a>)</cite> 등이 인간 수준에서 추론 <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al. <a class="ltx_ref" href="#bib.bib8" title="">2021</a>)</cite>, 계획 <cite class="ltx_cite ltx_citemacro_citep">(Huang et al. <a class="ltx_ref" href="#bib.bib21" title="">2022</a>)</cite>, 경험으로부터의 학습 <cite class="ltx_cite ltx_citemacro_citep">(Dong et al. <a class="ltx_ref" href="#bib.bib15" title="">2023</a>)</cite> 등에서 강력한 능력을 발휘했다. 이러한 일반적인 능력은 또한 LLM이 전체 UBE(Uniform Bar Examination) <cite class="ltx_cite ltx_citemacro_citep">(Katz et al. <a class="ltx_ref" href="#bib.bib26" title="">2023</a>)</cite>를 성공적으로 완료하거나 자연어 명령어 <cite class="ltx_cite ltx_citemacro_citep">(StabilityAI <a class="ltx_ref" href="#bib.bib38" title="">2023</a>)</cite>에 기반한 코딩과 같은 복잡한 실세계 작업을 처리할 수 있는 기반을 제공한다.</p>
</div>
<div class="ltx_para" id="Sx1.p2">
<p class="ltx_p" id="Sx1.p2.2">많은 잘 알려진 LLM은 여러 언어의 다양한 혼합 코퍼스에 대한 사전 훈련 덕분에 다양한 언어에 걸쳐 입력을 이해하고 응답을 생성할 수 있다. 그러나 언어 자원의 불균형적인 분포로 인해 모든 언어에 대한 광범위한 훈련 데이터 수집은 거의 불가능하다 <cite class="ltx_cite ltx_citemacro_citep">(Ranta and Goutte <a class="ltx_ref" href="#bib.bib36" title="">2021</a>)</cite> 대표적인 LLM BLOOM <cite class="ltx_cite ltx_citemacro_citep">(Scao et al. <a class="ltx_ref" href="#bib.bib37" title="">2023</a>)</cite>를 예로 들면, 46개의 자연어에 대해 사전 훈련되었다. 그러나 이 숫자는 현재 사용 중인 대략 <math alttext="7,000" class="ltx_Math" display="inline" id="Sx1.p2.2.m2.2"><semantics id="Sx1.p2.2.m2.2a"><mrow id="Sx1.p2.2.m2.2.3.2" xref="Sx1.p2.2.m2.2.3.1.cmml"><mn id="Sx1.p2.2.m2.1.1" xref="Sx1.p2.2.m2.1.1.cmml">7</mn><mo id="Sx1.p2.2.m2.2.3.2.1" xref="Sx1.p2.2.m2.2.3.1.cmml">,</mo><mn id="Sx1.p2.2.m2.2.2" xref="Sx1.p2.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx1.p2.2.m2.2b"><list id="Sx1.p2.2.m2.2.3.1.cmml" xref="Sx1.p2.2.m2.2.3.2"><cn id="Sx1.p2.2.m2.1.1.cmml" type="integer" xref="Sx1.p2.2.m2.1.1">7</cn><cn id="Sx1.p2.2.m2.2.2.cmml" type="integer" xref="Sx1.p2.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="Sx1.p2.2.m2.2c">7,000</annotation><annotation encoding="application/x-llamapun" id="Sx1.p2.2.m2.2d">7 , 000</annotation></semantics></math> 언어의 <math alttext="0.66\%" class="ltx_Math" display="inline" id="Sx1.p2.1.m1.1"><semantics id="Sx1.p2.1.m1.1a"><mrow id="Sx1.p2.1.m1.1.1" xref="Sx1.p2.1.m1.1.1.cmml"><mn id="Sx1.p2.1.m1.1.1.2" xref="Sx1.p2.1.m1.1.1.2.cmml">0.66</mn><mo id="Sx1.p2.1.m1.1.1.1" xref="Sx1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx1.p2.1.m1.1b"><apply id="Sx1.p2.1.m1.1.1.cmml" xref="Sx1.p2.1.m1.1.1"><csymbol cd="latexml" id="Sx1.p2.1.m1.1.1.1.cmml" xref="Sx1.p2.1.m1.1.1.1">percent</csymbol><cn id="Sx1.p2.1.m1.1.1.2.cmml" type="float" xref="Sx1.p2.1.m1.1.1.2">0.66</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx1.p2.1.m1.1c">0.66\%</annotation><annotation encoding="application/x-llamapun" id="Sx1.p2.1.m1.1d">0.66 %</annotation></semantics></math>만을 설명한다. 더욱이 이 46개 언어의 코퍼스 내에는 자원이 풍부한 영어 텍스트가 자원이 적은 치툼부카 언어보다 280만 배나 많은 극단적인 불균형이 존재한다. 이것은 고립된 사례가 아니다. 널리 논의되는 또 다른 언어 모델인 LLaMA는 라틴어와 키릴어 스크립트를 사용하는 20개 관련 언어의 제한된 데이터로 보충된 영어 지배 코퍼스에서 주로 사전 훈련되었다. 결과적으로 LLaMA는 충분한 훈련을 거치지 않은 비영어권 언어와 관련된 상황에서 열등한 성능을 보인다. 일부 연구자들은 특정 관심 언어에 대한 대규모 데이터를 수집하고 LLM <cite class="ltx_cite ltx_citemacro_citep">(Team <a class="ltx_ref" href="#bib.bib41" title="">2023a</a>)</cite>를 재교육한다. 그러나 이는 필연적으로 높은 계산 및 데이터 수집 비용을 초래하여 자원이 적은 언어에는 적합하지 않다. <cite class="ltx_cite ltx_citemacro_citet">Cui, Yang, and Yao (<a class="ltx_ref" href="#bib.bib13" title="">2023b</a>)</cite>는 원래 어휘를 확장하고 LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al. <a class="ltx_ref" href="#bib.bib19" title="">2021</a>)</cite>에 의해 30B 중국어 토큰으로 LLaMA를 추가로 사전 학습하여 유망한 결과를 보고한다. 그럼에도 불구하고 이송 과정에 대한 세밀한 체계적인 조사는 여전히 부족하다.</p>
</div>
<div class="ltx_para" id="Sx1.p3">
<p class="ltx_p" id="Sx1.p3.1">이 작업에서 우리는 LLM에서 언어 능력 전이에 대한 포괄적인 이해를 얻기 위한 단계를 밟는다. 도표 <a class="ltx_ref" href="#Sx1.F1" title="Figure 1 ‣ Introduction ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_tag">1</span></a>에 도시된 바와 같이, 우리는 LLaMA에 기초하여 몇 가지 주요 측면들을 경험적으로 조사한다:</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.p4">
<p class="ltx_p" id="Sx1.p4.1">(1) <span class="ltx_text ltx_font_bold" id="Sx1.p4.1.1">The impact of vocabulary extension on transfer. </span> 우리는 원본 어휘에 대해 0.5억 개의 중국어 토큰을 사용한 추가 사전 훈련이 300억 개 이상의 토큰에 대해 추가로 사전 훈련되었음에도 불구하고 확장 어휘에 대한 성능보다 훨씬 더 우수하다는 것을 발견했다. 이는 어휘 확장이 수백억 정도의 소규모 증분 사전 훈련에 적합한 선택이 아닐 수 있음을 시사한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.p5">
<p class="ltx_p" id="Sx1.p5.1">(2) <span class="ltx_text ltx_font_bold" id="Sx1.p5.1.1">Training scales required for effective transfer. </span> 1,000억 토큰 이하의 추가 중국어 사전 훈련은 LLaMA의 지식 수준을 크게 향상시키기에 불충분하다는 것을 발견했다. 그러나, LLaMA의 응답 품질(즉, 언어 생성 능력)을 향상시키는 것은 대규모의 추가 사전 훈련보다는 수십만 개의 명령어 데이터만을 필요로 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.p6">
<p class="ltx_p" id="Sx1.p6.1">(3) <span class="ltx_text ltx_font_bold" id="Sx1.p6.1.1">The effect of transfer training on the original English capabilities. <span> 우리는 전이 훈련에 대한 중국어 말뭉치에 대한 배타적 의존은 다국어 합동 훈련을 통해 효과적으로 완화되는 우려인 LLaMA의 원래 영어 능력을 현저하게 손상시킨다는 것을 발견했다.</p>
</div>
<div class="ltx_para" id="Sx1.p7">
<p class="ltx_p" id="Sx1.p7.1">앞서 언급한 연구 결과는 LLaMA의 언어 생성 및 지침에 따른 기능을 최소한의 비용으로 비영어 언어로 이전할 수 있게 한다. 4개의 표준화된 테스트 벤치마크(C-Eval, GAOKAO-Bench, MMLU, AGI-Eval)와 명령어 평가 벤치마크 LLM-Eval의 평가 결과를 바탕으로 최신 오픈 차이나 LLaMA와 비교 가능한 지식 수준과 응답 품질을 달성하면서도 학습 데이터의 <math alttext="1\%" class="ltx_Math" display="inline" id="Sx1.p7.1.m1.1"><semantics id="Sx1.p7.1.m1.1a"><mrow id="Sx1.p7.1.m1.1.1" xref="Sx1.p7.1.m1.1.1.cmml"><mn id="Sx1.p7.1.m1.1.1.2" xref="Sx1.p7.1.m1.1.1.2.cmml">1</mn><mo id="Sx1.p7.1.m1.1.1.1" xref="Sx1.p7.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx1.p7.1.m1.1b"><apply id="Sx1.p7.1.m1.1.1.cmml" xref="Sx1.p7.1.m1.1.1"><csymbol cd="latexml" id="Sx1.p7.1.m1.1.1.1.cmml" xref="Sx1.p7.1.m1.1.1.1">percent</csymbol><cn id="Sx1.p7.1.m1.1.1.2.cmml" type="integer" xref="Sx1.p7.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx1.p7.1.m1.1c">1\%</annotation><annotation encoding="application/x-llamapun" id="Sx1.p7.1.m1.1d">1 %</annotation></semantics></math>를 적게 사용한다. 또한, 다른 13개의 저자원 언어에 대한 확장 실험도 유사한 경향을 보인다. 본 논문에서는 비영어 LLMs를 구축하는데 있어 지역사회에 대한 도움과 지침을 제공하기 위한 실험 결과와 분석을 목표로 한다.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Background and Overview</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">이 하위 섹션에서는 먼저 명령어 후속 LLM을 개발하기 위한 필수 단계를 제시한다. 그 후, 우리는 이 모델을 비영어 언어로 외삽하는 일반적인 관행을 검토하고 모델 외삽을 위해 수행된 경험적 연구의 개요를 제공한다.</p>
</div>
<section class="ltx_subsection" id="Sx2.SSx1">
<h3 class="ltx_title ltx_title_subsection">Step 1: Pretraining to acquire language capability and knowledge</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx2.SSx1.p1">
<p class="ltx_p" id="Sx2.SSx1.p1.1">LLM에 대한 기본 기능의 중요한 소스로서 사전 훈련은 접두사 시퀀스를 기반으로 다음 토큰을 예측하는 것을 목표로 한다. 형식적으로, 큰 코퍼스 <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="Sx2.SSx1.p1.1.m1.1"><semantics id="Sx2.SSx1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx1.p1.1.m1.1.1" xref="Sx2.SSx1.p1.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p1.1.m1.1b"><ci id="Sx2.SSx1.p1.1.m1.1.1.cmml" xref="Sx2.SSx1.p1.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx1.p1.1.m1.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx1.p1.1.m1.1d">caligraphic_D</annotation></semantics></math>가 주어지면, 훈련 목적은 다음과 같은 손실을 최소화하는 것이다:</p>
<table class="ltx_equation ltx_eqn_table" id="Sx2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{pretrain}=\sum_{x\in\mathcal{D}}\sum_{i}\log p_{\theta}(x_{i}|x_{%
1},...,x_{i-1})," class="ltx_Math" display="block" id="Sx2.E1.m1.2"><semantics id="Sx2.E1.m1.2a"><mrow id="Sx2.E1.m1.2.2.1" xref="Sx2.E1.m1.2.2.1.1.cmml"><mrow id="Sx2.E1.m1.2.2.1.1" xref="Sx2.E1.m1.2.2.1.1.cmml"><msub id="Sx2.E1.m1.2.2.1.1.3" xref="Sx2.E1.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.E1.m1.2.2.1.1.3.2" xref="Sx2.E1.m1.2.2.1.1.3.2.cmml">ℒ</mi><mrow id="Sx2.E1.m1.2.2.1.1.3.3" xref="Sx2.E1.m1.2.2.1.1.3.3.cmml"><mi id="Sx2.E1.m1.2.2.1.1.3.3.2" xref="Sx2.E1.m1.2.2.1.1.3.3.2.cmml">p</mi><mo id="Sx2.E1.m1.2.2.1.1.3.3.1" xref="Sx2.E1.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="Sx2.E1.m1.2.2.1.1.3.3.3" xref="Sx2.E1.m1.2.2.1.1.3.3.3.cmml">r</mi><mo id="Sx2.E1.m1.2.2.1.1.3.3.1a" xref="Sx2.E1.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="Sx2.E1.m1.2.2.1.1.3.3.4" xref="Sx2.E1.m1.2.2.1.1.3.3.4.cmml">e</mi><mo id="Sx2.E1.m1.2.2.1.1.3.3.1b" xref="Sx2.E1.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="Sx2.E1.m1.2.2.1.1.3.3.5" xref="Sx2.E1.m1.2.2.1.1.3.3.5.cmml">t</mi><mo id="Sx2.E1.m1.2.2.1.1.3.3.1c" xref="Sx2.E1.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="Sx2.E1.m1.2.2.1.1.3.3.6" xref="Sx2.E1.m1.2.2.1.1.3.3.6.cmml">r</mi><mo id="Sx2.E1.m1.2.2.1.1.3.3.1d" xref="Sx2.E1.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="Sx2.E1.m1.2.2.1.1.3.3.7" xref="Sx2.E1.m1.2.2.1.1.3.3.7.cmml">a</mi><mo id="Sx2.E1.m1.2.2.1.1.3.3.1e" xref="Sx2.E1.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="Sx2.E1.m1.2.2.1.1.3.3.8" xref="Sx2.E1.m1.2.2.1.1.3.3.8.cmml">i</mi><mo id="Sx2.E1.m1.2.2.1.1.3.3.1f" xref="Sx2.E1.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="Sx2.E1.m1.2.2.1.1.3.3.9" xref="Sx2.E1.m1.2.2.1.1.3.3.9.cmml">n</mi></mrow></msub><mo id="Sx2.E1.m1.2.2.1.1.2" rspace="0.111em" xref="Sx2.E1.m1.2.2.1.1.2.cmml">=</mo><mrow id="Sx2.E1.m1.2.2.1.1.1" xref="Sx2.E1.m1.2.2.1.1.1.cmml"><munder id="Sx2.E1.m1.2.2.1.1.1.2" xref="Sx2.E1.m1.2.2.1.1.1.2.cmml"><mo id="Sx2.E1.m1.2.2.1.1.1.2.2" movablelimits="false" rspace="0em" xref="Sx2.E1.m1.2.2.1.1.1.2.2.cmml">∑</mo><mrow id="Sx2.E1.m1.2.2.1.1.1.2.3" xref="Sx2.E1.m1.2.2.1.1.1.2.3.cmml"><mi id="Sx2.E1.m1.2.2.1.1.1.2.3.2" xref="Sx2.E1.m1.2.2.1.1.1.2.3.2.cmml">x</mi><mo id="Sx2.E1.m1.2.2.1.1.1.2.3.1" xref="Sx2.E1.m1.2.2.1.1.1.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="Sx2.E1.m1.2.2.1.1.1.2.3.3" xref="Sx2.E1.m1.2.2.1.1.1.2.3.3.cmml">𝒟</mi></mrow></munder><mrow id="Sx2.E1.m1.2.2.1.1.1.1" xref="Sx2.E1.m1.2.2.1.1.1.1.cmml"><munder id="Sx2.E1.m1.2.2.1.1.1.1.2" xref="Sx2.E1.m1.2.2.1.1.1.1.2.cmml"><mo id="Sx2.E1.m1.2.2.1.1.1.1.2.2" movablelimits="false" xref="Sx2.E1.m1.2.2.1.1.1.1.2.2.cmml">∑</mo><mi id="Sx2.E1.m1.2.2.1.1.1.1.2.3" xref="Sx2.E1.m1.2.2.1.1.1.1.2.3.cmml">i</mi></munder><mrow id="Sx2.E1.m1.2.2.1.1.1.1.1" xref="Sx2.E1.m1.2.2.1.1.1.1.1.cmml"><mrow id="Sx2.E1.m1.2.2.1.1.1.1.1.3" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.cmml"><mi id="Sx2.E1.m1.2.2.1.1.1.1.1.3.1" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.1.cmml">log</mi><mo id="Sx2.E1.m1.2.2.1.1.1.1.1.3a" lspace="0.167em" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.cmml">⁡</mo><msub id="Sx2.E1.m1.2.2.1.1.1.1.1.3.2" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.cmml"><mi id="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.2" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.2.cmml">p</mi><mi id="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.3" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.3.cmml">θ</mi></msub></mrow><mo id="Sx2.E1.m1.2.2.1.1.1.1.1.2" xref="Sx2.E1.m1.2.2.1.1.1.1.1.2.cmml">⁢</mo><mrow id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.2" stretchy="false" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.cmml"><mi id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.2" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.2.cmml">x</mi><mi id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.3" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.3.cmml">i</mi></msub><mo fence="false" id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">|</mo><mrow id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml"><msub id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mn id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.3" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><mi id="Sx2.E1.m1.1.1" mathvariant="normal" xref="Sx2.E1.m1.1.1.cmml">…</mi><mo id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.4" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.2" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.2.cmml">x</mi><mrow id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.cmml"><mi id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.2" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml">i</mi><mo id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.1" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.1.cmml">−</mo><mn id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.3" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml">1</mn></mrow></msub></mrow></mrow><mo id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.3" stretchy="false" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="Sx2.E1.m1.2.2.1.2" xref="Sx2.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx2.E1.m1.2b"><apply id="Sx2.E1.m1.2.2.1.1.cmml" xref="Sx2.E1.m1.2.2.1"><eq id="Sx2.E1.m1.2.2.1.1.2.cmml" xref="Sx2.E1.m1.2.2.1.1.2"></eq><apply id="Sx2.E1.m1.2.2.1.1.3.cmml" xref="Sx2.E1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="Sx2.E1.m1.2.2.1.1.3.1.cmml" xref="Sx2.E1.m1.2.2.1.1.3">subscript</csymbol><ci id="Sx2.E1.m1.2.2.1.1.3.2.cmml" xref="Sx2.E1.m1.2.2.1.1.3.2">ℒ</ci><apply id="Sx2.E1.m1.2.2.1.1.3.3.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3"><times id="Sx2.E1.m1.2.2.1.1.3.3.1.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3.1"></times><ci id="Sx2.E1.m1.2.2.1.1.3.3.2.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3.2">𝑝</ci><ci id="Sx2.E1.m1.2.2.1.1.3.3.3.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3.3">𝑟</ci><ci id="Sx2.E1.m1.2.2.1.1.3.3.4.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3.4">𝑒</ci><ci id="Sx2.E1.m1.2.2.1.1.3.3.5.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3.5">𝑡</ci><ci id="Sx2.E1.m1.2.2.1.1.3.3.6.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3.6">𝑟</ci><ci id="Sx2.E1.m1.2.2.1.1.3.3.7.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3.7">𝑎</ci><ci id="Sx2.E1.m1.2.2.1.1.3.3.8.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3.8">𝑖</ci><ci id="Sx2.E1.m1.2.2.1.1.3.3.9.cmml" xref="Sx2.E1.m1.2.2.1.1.3.3.9">𝑛</ci></apply></apply><apply id="Sx2.E1.m1.2.2.1.1.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1"><apply id="Sx2.E1.m1.2.2.1.1.1.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="Sx2.E1.m1.2.2.1.1.1.2.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.2">subscript</csymbol><sum id="Sx2.E1.m1.2.2.1.1.1.2.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.2.2"></sum><apply id="Sx2.E1.m1.2.2.1.1.1.2.3.cmml" xref="Sx2.E1.m1.2.2.1.1.1.2.3"><in id="Sx2.E1.m1.2.2.1.1.1.2.3.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.2.3.1"></in><ci id="Sx2.E1.m1.2.2.1.1.1.2.3.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.2.3.2">𝑥</ci><ci id="Sx2.E1.m1.2.2.1.1.1.2.3.3.cmml" xref="Sx2.E1.m1.2.2.1.1.1.2.3.3">𝒟</ci></apply></apply><apply id="Sx2.E1.m1.2.2.1.1.1.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1"><apply id="Sx2.E1.m1.2.2.1.1.1.1.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="Sx2.E1.m1.2.2.1.1.1.1.2.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.2">subscript</csymbol><sum id="Sx2.E1.m1.2.2.1.1.1.1.2.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.2.2"></sum><ci id="Sx2.E1.m1.2.2.1.1.1.1.2.3.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.2.3">𝑖</ci></apply><apply id="Sx2.E1.m1.2.2.1.1.1.1.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1"><times id="Sx2.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.2"></times><apply id="Sx2.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3"><log id="Sx2.E1.m1.2.2.1.1.1.1.1.3.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.1"></log><apply id="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.2">subscript</csymbol><ci id="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.2">𝑝</ci><ci id="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.3.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.3.2.3">𝜃</ci></apply></apply><apply id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.3">conditional</csymbol><apply id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.2">𝑥</ci><ci id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.3.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.4.3">𝑖</ci></apply><list id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2"><apply id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><cn id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">1</cn></apply><ci id="Sx2.E1.m1.1.1.cmml" xref="Sx2.E1.m1.1.1">…</ci><apply id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.2">𝑥</ci><apply id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3"><minus id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.1.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.1"></minus><ci id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.2">𝑖</ci><cn id="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml" type="integer" xref="Sx2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.2.2.3.3">1</cn></apply></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.E1.m1.2c">\mathcal{L}_{pretrain}=\sum_{x\in\mathcal{D}}\sum_{i}\log p_{\theta}(x_{i}|x_{%
1},...,x_{i-1}),</annotation><annotation encoding="application/x-llamapun" id="Sx2.E1.m1.2d">caligraphic_L start_POSTSUBSCRIPT italic_p italic_r italic_e italic_t italic_r italic_a italic_i italic_n end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_x ∈ caligraphic_D end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT roman_log italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Sx2.SSx1.p1.2">여기서 <math alttext="x=\{x_{1},...,x_{n}\}" class="ltx_Math" display="inline" id="Sx2.SSx1.p1.2.m1.3"><semantics id="Sx2.SSx1.p1.2.m1.3a"><mrow id="Sx2.SSx1.p1.2.m1.3.3" xref="Sx2.SSx1.p1.2.m1.3.3.cmml"><mi id="Sx2.SSx1.p1.2.m1.3.3.4" xref="Sx2.SSx1.p1.2.m1.3.3.4.cmml">x</mi><mo id="Sx2.SSx1.p1.2.m1.3.3.3" xref="Sx2.SSx1.p1.2.m1.3.3.3.cmml">=</mo><mrow id="Sx2.SSx1.p1.2.m1.3.3.2.2" xref="Sx2.SSx1.p1.2.m1.3.3.2.3.cmml"><mo id="Sx2.SSx1.p1.2.m1.3.3.2.2.3" stretchy="false" xref="Sx2.SSx1.p1.2.m1.3.3.2.3.cmml">{</mo><msub id="Sx2.SSx1.p1.2.m1.2.2.1.1.1" xref="Sx2.SSx1.p1.2.m1.2.2.1.1.1.cmml"><mi id="Sx2.SSx1.p1.2.m1.2.2.1.1.1.2" xref="Sx2.SSx1.p1.2.m1.2.2.1.1.1.2.cmml">x</mi><mn id="Sx2.SSx1.p1.2.m1.2.2.1.1.1.3" xref="Sx2.SSx1.p1.2.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="Sx2.SSx1.p1.2.m1.3.3.2.2.4" xref="Sx2.SSx1.p1.2.m1.3.3.2.3.cmml">,</mo><mi id="Sx2.SSx1.p1.2.m1.1.1" mathvariant="normal" xref="Sx2.SSx1.p1.2.m1.1.1.cmml">…</mi><mo id="Sx2.SSx1.p1.2.m1.3.3.2.2.5" xref="Sx2.SSx1.p1.2.m1.3.3.2.3.cmml">,</mo><msub id="Sx2.SSx1.p1.2.m1.3.3.2.2.2" xref="Sx2.SSx1.p1.2.m1.3.3.2.2.2.cmml"><mi id="Sx2.SSx1.p1.2.m1.3.3.2.2.2.2" xref="Sx2.SSx1.p1.2.m1.3.3.2.2.2.2.cmml">x</mi><mi id="Sx2.SSx1.p1.2.m1.3.3.2.2.2.3" xref="Sx2.SSx1.p1.2.m1.3.3.2.2.2.3.cmml">n</mi></msub><mo id="Sx2.SSx1.p1.2.m1.3.3.2.2.6" stretchy="false" xref="Sx2.SSx1.p1.2.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx2.SSx1.p1.2.m1.3b"><apply id="Sx2.SSx1.p1.2.m1.3.3.cmml" xref="Sx2.SSx1.p1.2.m1.3.3"><eq id="Sx2.SSx1.p1.2.m1.3.3.3.cmml" xref="Sx2.SSx1.p1.2.m1.3.3.3"></eq><ci id="Sx2.SSx1.p1.2.m1.3.3.4.cmml" xref="Sx2.SSx1.p1.2.m1.3.3.4">𝑥</ci><set id="Sx2.SSx1.p1.2.m1.3.3.2.3.cmml" xref="Sx2.SSx1.p1.2.m1.3.3.2.2"><apply id="Sx2.SSx1.p1.2.m1.2.2.1.1.1.cmml" xref="Sx2.SSx1.p1.2.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="Sx2.SSx1.p1.2.m1.2.2.1.1.1.1.cmml" xref="Sx2.SSx1.p1.2.m1.2.2.1.1.1">subscript</csymbol><ci id="Sx2.SSx1.p1.2.m1.2.2.1.1.1.2.cmml" xref="Sx2.SSx1.p1.2.m1.2.2.1.1.1.2">𝑥</ci><cn id="Sx2.SSx1.p1.2.m1.2.2.1.1.1.3.cmml" type="integer" xref="Sx2.SSx1.p1.2.m1.2.2.1.1.1.3">1</cn></apply><ci id="Sx2.SSx1.p1.2.m1.1.1.cmml" xref="Sx2.SSx1.p1.2.m1.1.1">…</ci><apply id="Sx2.SSx1.p1.2.m1.3.3.2.2.2.cmml" xref="Sx2.SSx1.p1.2.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="Sx2.SSx1.p1.2.m1.3.3.2.2.2.1.cmml" xref="Sx2.SSx1.p1.2.m1.3.3.2.2.2">subscript</csymbol><ci id="Sx2.SSx1.p1.2.m1.3.3.2.2.2.2.cmml" xref="Sx2.SSx1.p1.2.m1.3.3.2.2.2.2">𝑥</ci><ci id="Sx2.SSx1.p1.2.m1.3.3.2.2.2.3.cmml" xref="Sx2.SSx1.p1.2.m1.3.3.2.2.2.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx1.p1.2.m1.3c">x=\{x_{1},...,x_{n}\}</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx1.p1.2.m1.3d">italic_x = { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math>는 입력 토큰 시퀀스를 나타낸다.</p>
</div>
<div class="ltx_para" id="Sx2.SSx1.p2">
<p class="ltx_p" id="Sx2.SSx1.p2.1">수십억에서 수조 개의 토큰에 이르는 방대한 텍스트 데이터에 대해 사전 트레이닝함으로써, LLM은 복잡한 언어 구조, 의미 및 문맥 관계를 캡처할 수 있고, 이에 의해 강력한 언어 생성 능력을 획득할 수 있다. 또한 이러한 LLM은 개념, 사실 및 개념 간의 연결을 이해하는 방법도 배우므로 세계 지식을 광범위하게 이해할 수 있다.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx2.SSx2">
<h3 class="ltx_title ltx_title_subsection">Step 2: Instruction tuning for aligning with human intent</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx2.SSx2.p1">
<p class="ltx_p" id="Sx2.SSx2.p1.3">명령 조정(SFT)은 LLM이 명령을 따르는 능력을 더욱 향상시키는 것을 목표로 한다. 학습 데이터는 많은 명령어-응답 쌍으로 구성된다. 모델은 단순히 선행 텍스트로부터 계속되는 것이 아니라, 명령들에 정확하게 응답하는 것을 배울 필요가 있다. 형식적으로, 명령어 데이터세트 <math alttext="\mathcal{D}^{\prime}=\{(I,Y)\}" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.1.m1.3"><semantics id="Sx2.SSx2.p1.1.m1.3a"><mrow id="Sx2.SSx2.p1.1.m1.3.3" xref="Sx2.SSx2.p1.1.m1.3.3.cmml"><msup id="Sx2.SSx2.p1.1.m1.3.3.3" xref="Sx2.SSx2.p1.1.m1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.SSx2.p1.1.m1.3.3.3.2" xref="Sx2.SSx2.p1.1.m1.3.3.3.2.cmml">𝒟</mi><mo id="Sx2.SSx2.p1.1.m1.3.3.3.3" xref="Sx2.SSx2.p1.1.m1.3.3.3.3.cmml">′</mo></msup><mo id="Sx2.SSx2.p1.1.m1.3.3.2" xref="Sx2.SSx2.p1.1.m1.3.3.2.cmml">=</mo><mrow id="Sx2.SSx2.p1.1.m1.3.3.1.1" xref="Sx2.SSx2.p1.1.m1.3.3.1.2.cmml"><mo id="Sx2.SSx2.p1.1.m1.3.3.1.1.2" stretchy="false" xref="Sx2.SSx2.p1.1.m1.3.3.1.2.cmml">{</mo><mrow id="Sx2.SSx2.p1.1.m1.3.3.1.1.1.2" xref="Sx2.SSx2.p1.1.m1.3.3.1.1.1.1.cmml"><mo id="Sx2.SSx2.p1.1.m1.3.3.1.1.1.2.1" stretchy="false" xref="Sx2.SSx2.p1.1.m1.3.3.1.1.1.1.cmml">(</mo><mi id="Sx2.SSx2.p1.1.m1.1.1" xref="Sx2.SSx2.p1.1.m1.1.1.cmml">I</mi><mo id="Sx2.SSx2.p1.1.m1.3.3.1.1.1.2.2" xref="Sx2.SSx2.p1.1.m1.3.3.1.1.1.1.cmml">,</mo><mi id="Sx2.SSx2.p1.1.m1.2.2" xref="Sx2.SSx2.p1.1.m1.2.2.cmml">Y</mi><mo id="Sx2.SSx2.p1.1.m1.3.3.1.1.1.2.3" stretchy="false" xref="Sx2.SSx2.p1.1.m1.3.3.1.1.1.1.cmml">)</mo></mrow><mo id="Sx2.SSx2.p1.1.m1.3.3.1.1.3" stretchy="false" xref="Sx2.SSx2.p1.1.m1.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.1.m1.3b"><apply id="Sx2.SSx2.p1.1.m1.3.3.cmml" xref="Sx2.SSx2.p1.1.m1.3.3"><eq id="Sx2.SSx2.p1.1.m1.3.3.2.cmml" xref="Sx2.SSx2.p1.1.m1.3.3.2"></eq><apply id="Sx2.SSx2.p1.1.m1.3.3.3.cmml" xref="Sx2.SSx2.p1.1.m1.3.3.3"><csymbol cd="ambiguous" id="Sx2.SSx2.p1.1.m1.3.3.3.1.cmml" xref="Sx2.SSx2.p1.1.m1.3.3.3">superscript</csymbol><ci id="Sx2.SSx2.p1.1.m1.3.3.3.2.cmml" xref="Sx2.SSx2.p1.1.m1.3.3.3.2">𝒟</ci><ci id="Sx2.SSx2.p1.1.m1.3.3.3.3.cmml" xref="Sx2.SSx2.p1.1.m1.3.3.3.3">′</ci></apply><set id="Sx2.SSx2.p1.1.m1.3.3.1.2.cmml" xref="Sx2.SSx2.p1.1.m1.3.3.1.1"><interval closure="open" id="Sx2.SSx2.p1.1.m1.3.3.1.1.1.1.cmml" xref="Sx2.SSx2.p1.1.m1.3.3.1.1.1.2"><ci id="Sx2.SSx2.p1.1.m1.1.1.cmml" xref="Sx2.SSx2.p1.1.m1.1.1">𝐼</ci><ci id="Sx2.SSx2.p1.1.m1.2.2.cmml" xref="Sx2.SSx2.p1.1.m1.2.2">𝑌</ci></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.1.m1.3c">\mathcal{D}^{\prime}=\{(I,Y)\}</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx2.p1.1.m1.3d">caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = { ( italic_I , italic_Y ) }</annotation></semantics></math>가 주어지면, 여기서 <math alttext="I" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.2.m2.1"><semantics id="Sx2.SSx2.p1.2.m2.1a"><mi id="Sx2.SSx2.p1.2.m2.1.1" xref="Sx2.SSx2.p1.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.2.m2.1b"><ci id="Sx2.SSx2.p1.2.m2.1.1.cmml" xref="Sx2.SSx2.p1.2.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.2.m2.1c">I</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx2.p1.2.m2.1d">italic_I</annotation></semantics></math>는 태스크 명령어를 나타내고, <math alttext="Y" class="ltx_Math" display="inline" id="Sx2.SSx2.p1.3.m3.1"><semantics id="Sx2.SSx2.p1.3.m3.1a"><mi id="Sx2.SSx2.p1.3.m3.1.1" xref="Sx2.SSx2.p1.3.m3.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="Sx2.SSx2.p1.3.m3.1b"><ci id="Sx2.SSx2.p1.3.m3.1.1.cmml" xref="Sx2.SSx2.p1.3.m3.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx2.SSx2.p1.3.m3.1c">Y</annotation><annotation encoding="application/x-llamapun" id="Sx2.SSx2.p1.3.m3.1d">italic_Y</annotation></semantics></math>는 원하는 응답을 나타내며, 명령어 튜닝의 트레이닝 목적은 다음과 같은 손실을 최소화하는 것이다:</p>
<table class="ltx_equation ltx_eqn_table" id="Sx2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{ins}=-\log p_{\theta}(Y|I)," class="ltx_Math" display="block" id="Sx2.E2.m1.1"><semantics id="Sx2.E2.m1.1a"><mrow id="Sx2.E2.m1.1.1.1" xref="Sx2.E2.m1.1.1.1.1.cmml"><mrow id="Sx2.E2.m1.1.1.1.1" xref="Sx2.E2.m1.1.1.1.1.cmml"><msub id="Sx2.E2.m1.1.1.1.1.3" xref="Sx2.E2.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Sx2.E2.m1.1.1.1.1.3.2" xref="Sx2.E2.m1.1.1.1.1.3.2.cmml">ℒ</mi><mrow id="Sx2.E2.m1.1.1.1.1.3.3" xref="Sx2.E2.m1.1.1.1.1.3.3.cmml"><mi id="Sx2.E2.m1.1.1.1.1.3.3.2" xref="Sx2.E2.m1.1.1.1.1.3.3.2.cmml">i</mi><mo id="Sx2.E2.m1.1.1.1.1.3.3.1" xref="Sx2.E2.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="Sx2.E2.m1.1.1.1.1.3.3.3" xref="Sx2.E2.m1.1.1.1.1.3.3.3.cmml">n</mi><mo id="Sx2.E2.m1.1.1.1.1.3.3.1a" xref="Sx2.E2.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="Sx2.E2.m1.1.1.1.1.3.3.4" xref="Sx2.E2.m1.1.1.1.1.3.3.4.cmml">s</mi></mrow></msub><mo id="Sx2.E2.m1.1.1.1.1.2" xref="Sx2.E2.m1.1.1.1.1.2.cmml">=</mo><mrow id="Sx2.E2.m1.1.1.1.1.1" xref="Sx2.E2.m1.1.1.1.1.1.cmml"><mo id="Sx2.E2.m1.1.1.1.1.1a" rspace="0.167em" xref="Sx2.E2.m1.1.1.1.1.1.cmml">−</mo><mrow id="Sx2.E2.m1.1.1.1.1.1.1" xref="Sx2.E2.m1.1.1.1.1.1.1.cmml"><mrow id="Sx2.E2.m1.1.1.1.1.1.1.3" xref="Sx2.E2.m1.1.1.1.1.1.1.3.cmml"><mi id="Sx2.E2.m1.1.1.1.1.1.1.3.1" xref="Sx2.E2.m1.1.1.1.1.1.1.3.1.cmml">log</mi><mo id="Sx2.E2.m1.1.1.1.1.1.1.3a" lspace="0.167em" xref="Sx2.E2.m1.1.1.1.1.1.1.3.cmml">⁡</mo><msub id="Sx2.E2.m1.1.1.1.1.1.1.3.2" xref="Sx2.E2.m1.1.1.1.1.1.1.3.2.cmml"><mi id="Sx2.E2.m1.1.1.1.1.1.1.3.2.2" xref="Sx2.E2.m1.1.1.1.1.1.1.3.2.2.cmml">p</mi><mi id="Sx2.E2.m1.1.1.1.1.1.1.3.2.3" xref="Sx2.E2.m1.1.1.1.1.1.1.3.2.3.cmml">θ</mi></msub></mrow><mo id="Sx2.E2.m1.1.1.1.1.1.1.2" xref="Sx2.E2.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="Sx2.E2.m1.1.1.1.1.1.1.1.1" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="Sx2.E2.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Sx2.E2.m1.1.1.1.1.1.1.1.1.1" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.2" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml">Y</mi><mo fence="false" id="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.1" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.3" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml">I</mi></mrow><mo id="Sx2.E2.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="Sx2.E2.m1.1.1.1.2" xref="Sx2.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx2.E2.m1.1b"><apply id="Sx2.E2.m1.1.1.1.1.cmml" xref="Sx2.E2.m1.1.1.1"><eq id="Sx2.E2.m1.1.1.1.1.2.cmml" xref="Sx2.E2.m1.1.1.1.1.2"></eq><apply id="Sx2.E2.m1.1.1.1.1.3.cmml" xref="Sx2.E2.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="Sx2.E2.m1.1.1.1.1.3.1.cmml" xref="Sx2.E2.m1.1.1.1.1.3">subscript</csymbol><ci id="Sx2.E2.m1.1.1.1.1.3.2.cmml" xref="Sx2.E2.m1.1.1.1.1.3.2">ℒ</ci><apply id="Sx2.E2.m1.1.1.1.1.3.3.cmml" xref="Sx2.E2.m1.1.1.1.1.3.3"><times id="Sx2.E2.m1.1.1.1.1.3.3.1.cmml" xref="Sx2.E2.m1.1.1.1.1.3.3.1"></times><ci id="Sx2.E2.m1.1.1.1.1.3.3.2.cmml" xref="Sx2.E2.m1.1.1.1.1.3.3.2">𝑖</ci><ci id="Sx2.E2.m1.1.1.1.1.3.3.3.cmml" xref="Sx2.E2.m1.1.1.1.1.3.3.3">𝑛</ci><ci id="Sx2.E2.m1.1.1.1.1.3.3.4.cmml" xref="Sx2.E2.m1.1.1.1.1.3.3.4">𝑠</ci></apply></apply><apply id="Sx2.E2.m1.1.1.1.1.1.cmml" xref="Sx2.E2.m1.1.1.1.1.1"><minus id="Sx2.E2.m1.1.1.1.1.1.2.cmml" xref="Sx2.E2.m1.1.1.1.1.1"></minus><apply id="Sx2.E2.m1.1.1.1.1.1.1.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1"><times id="Sx2.E2.m1.1.1.1.1.1.1.2.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.2"></times><apply id="Sx2.E2.m1.1.1.1.1.1.1.3.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.3"><log id="Sx2.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.3.1"></log><apply id="Sx2.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Sx2.E2.m1.1.1.1.1.1.1.3.2.1.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="Sx2.E2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.3.2.2">𝑝</ci><ci id="Sx2.E2.m1.1.1.1.1.1.1.3.2.3.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.3.2.3">𝜃</ci></apply></apply><apply id="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.2">𝑌</ci><ci id="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Sx2.E2.m1.1.1.1.1.1.1.1.1.1.3">𝐼</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx2.E2.m1.1c">\mathcal{L}_{ins}=-\log p_{\theta}(Y|I),</annotation><annotation encoding="application/x-llamapun" id="Sx2.E2.m1.1d">caligraphic_L start_POSTSUBSCRIPT italic_i italic_n italic_s end_POSTSUBSCRIPT = - roman_log italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_Y | italic_I ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Sx2.SSx2.p1.4">다양한 지시 과제를 조정함으로써 모델은 인간의 지시를 더 잘 이해하고 따를 수 있으며, 보이지 않는 지시로 일반화할 수 있다.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx2.SSx3">
<h3 class="ltx_title ltx_title_subsection">Extrapolating LLMs to non-English languages</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx2.SSx3.p1">
<p class="ltx_p" id="Sx2.SSx3.p1.1">LLM은 사전 훈련 및 명령어 튜닝을 통해 언어 생성 및 명령어 후속 기능을 습득한다. 그러나 영어는 다양한 영역에서 가장 풍부한 텍스트 데이터 수집을 보유하면서 자연어 처리 분야에서 지배적인 위치를 차지하고 있다. 영어가 우세한 말뭉치에 대해 훈련된 LLM은 다른 비영어 언어에 비해 열등한 성능을 보인다. LLM을 비영어 언어로 외삽하는 것은 매우 가치 있는 연구 과제를 제기한다. 일반적인 외삽 접근법은 다음 세 단계로 구성된다 : (1) 대상 언어의 토큰을 추가하기 위해 어휘를 확장하고, 따라서 해당 언어에 대한 인코딩 표현성을 강화한다. (2) LLM들의 언어 생성 능력들을 타겟 언어로 전이하도록 추가로 사전 트레이닝하는 단계를 더 포함하는, 방법. 이 단계에 대한 요구되는 트레이닝 스케일은 일반적으로 수십억 개의 토큰들, 즉 처음부터 트레이닝에 필요한 수조 개의 토큰들보다 상당히 적다. (3) LLM들의 명령어-추종 능력들을 이전하기 위해 타겟 언어로 SFT를 수행하는 단계를 포함하는, 방법.</p>
</div>
<div class="ltx_para" id="Sx2.SSx3.p2">
<p class="ltx_p" id="Sx2.SSx3.p2.1">본 연구는 어휘 확장 전후의 LLM의 성능 차이를 비교하고, 다양한 사전 훈련과 SFT 척도에서 앞서 언급한 세 단계에 대한 포괄적인 실증 연구를 수행한다. 효과적인 전이를 위해 어휘 확장의 필요성과 필요한 훈련 척도를 분석한다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_title_section">Experimental Setup</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1">본 논문은 언어 생성 및 후속 수업의 역량을 비영어 언어로 효과적으로 전이시키는 방법을 탐색하는 것을 목적으로 한다. 중국어로 이용 가능한 풍부한 언어 자원을 감안할 때 포괄적이고 심층적인 실증 연구를 수행할 수 있다. 따라서 우리의 실험과 분석은 중국어를 출발점으로 시작하며 관찰된 현상은 10개 이상의 저자원 언어에 걸쳐 추가로 검증된다. 이 섹션에서는 실험에 사용된 데이터 세트, 모델 및 평가 방법론을 제시한다.</p>
</div>
<section class="ltx_subsection" id="Sx3.SSx1">
<h3 class="ltx_title ltx_title_subsection">Models</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx3.SSx1.p1">
<p class="ltx_p" id="Sx3.SSx1.p1.1">불필요한 대규모 반복 사전 훈련을 피하기 위해 다양한 규모의 중국 말뭉치에서 훈련된 오픈 소스 모델을 사용했다. 이 중 LLaMA와 LLaMA2는 명시적인 중국어 사전훈련을 거치지 않고 검문소 역할을 하는 반면, 중국어 LLaMA와 중국어 LLaMA2는 중국어 사전훈련이 300억 토큰인 검문소로 취급된다. 오픈차이나 LLaMA의 규모는 1,000억 토큰에 달한다. 우리는 이러한 모델의 성능을 분석 및 비교를 위한 참조로 사용한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx1.p2">
<p class="ltx_p" id="Sx3.SSx1.p2.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx1.p2.1.1">LLaMA</span> <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al. <a class="ltx_ref" href="#bib.bib43" title="">2023a</a>)</cite>: LLaMA는 Meta AI에 의해 개발된 일련의 기초 모델이며, 공개적으로 사용 가능한 English-dominate corpus에 대해 훈련되었다. 코퍼스는 CommonCrawl, C4, Github 코드, 위키피디아, 북스 및 ArXiv 문서를 포함하며 약 1조 4천억 토큰에 달한다. 이러한 출처 중 위키피디아는 다국어 텍스트로 구성되어 전체 말뭉치의 4.5%를 차지한다. 라틴어 또는 키릴어 스크립트를 사용하는 20개 언어를 포함합니다. LLaMA는 그 크기의 기초 모델에 대한 최첨단 결과를 달성한다. 예를 들어, 130억 개의 매개변수만 있는 LLaMA-13B는 많은 NLP 벤치마크에서 훨씬 더 큰 175B 매개변수 GPT-3보다 우수하다. 우리는 실험에서 LLaMA-7B와 LLaMA-13B를 고려한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx1.p3">
<p class="ltx_p" id="Sx3.SSx1.p3.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx1.p3.1.1">LLaMA2</span> <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al. <a class="ltx_ref" href="#bib.bib44" title="">2023b</a>)</cite>: LLaMA2는 LLaMA의 향상된 업그레이드 버전이다. 이전과 비교하여 받은 업그레이드에는 보다 강력한 데이터 청소 프로세스, 40%의 크기 증가를 자랑하는 공개적으로 사용 가능한 사전 훈련 데이터의 새로운 혼합, 이해력 향상을 위한 두 배의 컨텍스트 길이, 추론 효율성을 위한 그룹화된 쿼리 주의 구현 등이 포함된다. 이러한 개선은 고급 언어 이해 작업을 처리하는 데 더 강력한 도구가 됩니다. 우리는 실험에서 LLaMA2-7B를 고려한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx1.p4">
<p class="ltx_p" id="Sx3.SSx1.p4.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx1.p4.1.1">Chinese LLaMA</span> <cite class="ltx_cite ltx_citemacro_citep">(Cui, Yang, and Yao <a class="ltx_ref" href="#bib.bib13" title="">2023b</a>)</cite>: Chinese LLaMA는 원 LLaMA의 확장으로 중국어 텍스트를 이해하고 생성하는 능력을 향상시키도록 설계되었다. SentencePiece를 사용하여 개발된 중국식 토큰화기를 통합하여 목표를 달성한다. <math alttext="49,953" class="ltx_Math" display="inline" id="Sx3.SSx1.p4.1.m1.2"><semantics id="Sx3.SSx1.p4.1.m1.2a"><mrow id="Sx3.SSx1.p4.1.m1.2.3.2" xref="Sx3.SSx1.p4.1.m1.2.3.1.cmml"><mn id="Sx3.SSx1.p4.1.m1.1.1" xref="Sx3.SSx1.p4.1.m1.1.1.cmml">49</mn><mo id="Sx3.SSx1.p4.1.m1.2.3.2.1" xref="Sx3.SSx1.p4.1.m1.2.3.1.cmml">,</mo><mn id="Sx3.SSx1.p4.1.m1.2.2" xref="Sx3.SSx1.p4.1.m1.2.2.cmml">953</mn></mrow><annotation-xml encoding="MathML-Content" id="Sx3.SSx1.p4.1.m1.2b"><list id="Sx3.SSx1.p4.1.m1.2.3.1.cmml" xref="Sx3.SSx1.p4.1.m1.2.3.2"><cn id="Sx3.SSx1.p4.1.m1.1.1.cmml" type="integer" xref="Sx3.SSx1.p4.1.m1.1.1">49</cn><cn id="Sx3.SSx1.p4.1.m1.2.2.cmml" type="integer" xref="Sx3.SSx1.p4.1.m1.2.2">953</cn></list></annotation-xml><annotation encoding="application/x-tex" id="Sx3.SSx1.p4.1.m1.2c">49,953</annotation><annotation encoding="application/x-llamapun" id="Sx3.SSx1.p4.1.m1.2d">49 , 953</annotation></semantics></math>의 어휘 크기를 갖는 이 토큰화기는 한자의 향상된 취급을 가능하게 한다. 또한 모델 학습 시 메모리 소모를 줄이기 위해 파라미터 효율적인 미세 조정 기법 <cite class="ltx_cite ltx_citemacro_citep">(Hu et al. <a class="ltx_ref" href="#bib.bib19" title="">2021</a>)</cite>를 사용한다. 우리의 실험에서 우리는 약 300억 개의 중국 토큰에 해당하는 약 120GB 크기의 코퍼스에 대해 훈련된 중국 LLaMA 7B Plus를 고려한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx1.p5">
<p class="ltx_p" id="Sx3.SSx1.p5.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx1.p5.1.1">Chinese LLaMA2</span> <cite class="ltx_cite ltx_citemacro_citep">(Cui, Yang, and Yao <a class="ltx_ref" href="#bib.bib12" title="">2023a</a>)</cite>: Chinese LLaMA2 is a advanced iteration of Chinese LLaMA. 이는 중국어 LLaMA와 동일한 말뭉치와 학습 데이터를 활용하되, LLaMA2의 기초 모델을 활용한다. 또한, 새로운 버전의 어휘 구성과 코드 구현도 최적화되었다. 우리의 실험에서 우리는 300억 개의 중국 토큰에 사전 훈련된 중국 LLaMA2 7B를 고려한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx1.p6">
<p class="ltx_p" id="Sx3.SSx1.p6.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx1.p6.1.1">Open Chinese LLaMA</span> <cite class="ltx_cite ltx_citemacro_citep">(OpenLMLab <a class="ltx_ref" href="#bib.bib33" title="">2023</a>)</cite>:Open Chinese LLaMA는 원본 LLaMA의 더 큰 확장 버전이다. LLaMA의 중국어 텍스트 처리 능력을 향상시키기 위해 오픈 차이나 LLaMA는 1,000억 개의 토큰으로 구성된 코퍼스에 대한 추가 사전 교육을 거친다. 코퍼스는 원래 LLAMA 모델이 사용하는 영어 및 코드 데이터의 하위 집합과 함께 인터넷에서 수집되고 청소를 받는 텍스트로 구성된다.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx3.SSx2">
<h3 class="ltx_title ltx_title_subsection">Datasets</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx3.SSx2.p1">
<p class="ltx_p" id="Sx3.SSx2.p1.1">LLaMA의 언어 능력을 비영어 관심 언어로 전달하기 위해, 우리는 훈련을 위해 BELLE와 Bactrain-X의 두 가지 명령어 데이터 세트를 활용한다. 전자는 중국어와 관련된 실험에 사용되고 후자는 다른 언어와 관련된 실험에 사용된다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx2.p2">
<p class="ltx_p" id="Sx3.SSx2.p2.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx2.p2.1.1">BELLE</span> <cite class="ltx_cite ltx_citemacro_citep">(Ji et al. <a class="ltx_ref" href="#bib.bib23" title="">2023</a>)</cite>:BELLE는 Lianjia Tech에서 개발한 대규모 중국어 명령어 튜닝 데이터세트로 150만 명령어 후속 예제를 포함하고 있다. 우리는 중복되고 품질이 낮은 데이터를 제거하고 마침내 95만 개의 예를 유지했다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx2.p3">
<p class="ltx_p" id="Sx3.SSx2.p3.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx2.p3.1.1">Bactrain-X</span> <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a class="ltx_ref" href="#bib.bib29" title="">2023</a>)</cite>: Bactrian-X는 다국어 명령어 튜닝을 용이하게 하기 위해 52개 언어에 걸친 명령어 및 응답을 포함한다. Alpaca-52k <cite class="ltx_cite ltx_citemacro_citep">(Taori et al. <a class="ltx_ref" href="#bib.bib40" title="">2023</a>)</cite>와 Dolly-15k <cite class="ltx_cite ltx_citemacro_citep">(Conover et al. <a class="ltx_ref" href="#bib.bib11" title="">2023</a>)</cite> 데이터셋의 67K 영어 명령어를 51개 언어로 번역한 후 ChatGPT로 응답을 생성하여 생성한다.</p>
</div>
<figure class="ltx_table" id="Sx3.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="Sx3.T1.8">
<tbody><tr class="ltx_tr" id="Sx3.T1.8.9">
<td class="ltx_td ltx_border_tt" id="Sx3.T1.8.9.1"></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="Sx3.T1.8.9.2"><span class="ltx_text ltx_font_bold" id="Sx3.T1.8.9.2.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.9.3">ACC.</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.9.4">F.</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.9.5">INFO.</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.9.6">LC.</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.9.7">H.</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.9.8">AVG.</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.10">
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx3.T1.8.10.1" rowspan="6"><span class="ltx_text" id="Sx3.T1.8.10.1.1">1k SFT</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="Sx3.T1.8.10.2">LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al. <a class="ltx_ref" href="#bib.bib43" title="">2023a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx3.T1.8.10.3">0.482</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx3.T1.8.10.4">1.194</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx3.T1.8.10.5">0.858</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx3.T1.8.10.6">0.614</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx3.T1.8.10.7">2.970</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx3.T1.8.10.8">1.224</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.1.1">
<td class="ltx_td ltx_align_left" id="Sx3.T1.1.1.1">LLaMA with <math alttext="10K" class="ltx_Math" display="inline" id="Sx3.T1.1.1.1.m1.1"><semantics id="Sx3.T1.1.1.1.m1.1a"><mrow id="Sx3.T1.1.1.1.m1.1.1" xref="Sx3.T1.1.1.1.m1.1.1.cmml"><mn id="Sx3.T1.1.1.1.m1.1.1.2" xref="Sx3.T1.1.1.1.m1.1.1.2.cmml">10</mn><mo id="Sx3.T1.1.1.1.m1.1.1.1" xref="Sx3.T1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="Sx3.T1.1.1.1.m1.1.1.3" xref="Sx3.T1.1.1.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="Sx3.T1.1.1.1.m1.1b"><apply id="Sx3.T1.1.1.1.m1.1.1.cmml" xref="Sx3.T1.1.1.1.m1.1.1"><times id="Sx3.T1.1.1.1.m1.1.1.1.cmml" xref="Sx3.T1.1.1.1.m1.1.1.1"></times><cn id="Sx3.T1.1.1.1.m1.1.1.2.cmml" type="integer" xref="Sx3.T1.1.1.1.m1.1.1.2">10</cn><ci id="Sx3.T1.1.1.1.m1.1.1.3.cmml" xref="Sx3.T1.1.1.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.T1.1.1.1.m1.1c">10K</annotation><annotation encoding="application/x-llamapun" id="Sx3.T1.1.1.1.m1.1d">10 italic_K</annotation></semantics></math> pretrain</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.1.1.2">0.482</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.1.1.3">1.441</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.1.1.4">0.829</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.1.1.5">0.712</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.1.1.6">2.963</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.1.1.7">1.285</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.2.2">
<td class="ltx_td ltx_align_left" id="Sx3.T1.2.2.1">LLaMA with <math alttext="100K" class="ltx_Math" display="inline" id="Sx3.T1.2.2.1.m1.1"><semantics id="Sx3.T1.2.2.1.m1.1a"><mrow id="Sx3.T1.2.2.1.m1.1.1" xref="Sx3.T1.2.2.1.m1.1.1.cmml"><mn id="Sx3.T1.2.2.1.m1.1.1.2" xref="Sx3.T1.2.2.1.m1.1.1.2.cmml">100</mn><mo id="Sx3.T1.2.2.1.m1.1.1.1" xref="Sx3.T1.2.2.1.m1.1.1.1.cmml">⁢</mo><mi id="Sx3.T1.2.2.1.m1.1.1.3" xref="Sx3.T1.2.2.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="Sx3.T1.2.2.1.m1.1b"><apply id="Sx3.T1.2.2.1.m1.1.1.cmml" xref="Sx3.T1.2.2.1.m1.1.1"><times id="Sx3.T1.2.2.1.m1.1.1.1.cmml" xref="Sx3.T1.2.2.1.m1.1.1.1"></times><cn id="Sx3.T1.2.2.1.m1.1.1.2.cmml" type="integer" xref="Sx3.T1.2.2.1.m1.1.1.2">100</cn><ci id="Sx3.T1.2.2.1.m1.1.1.3.cmml" xref="Sx3.T1.2.2.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.T1.2.2.1.m1.1c">100K</annotation><annotation encoding="application/x-llamapun" id="Sx3.T1.2.2.1.m1.1d">100 italic_K</annotation></semantics></math> pretrain</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.2.2.2">0.587</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.2.2.3">1.952</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.2.2.4">0.881</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.2.2.5">0.991</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.2.2.6">2.973</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.2.2.7">1.477</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.3.3">
<td class="ltx_td ltx_align_left" id="Sx3.T1.3.3.1">LLaMA with <math alttext="1M" class="ltx_Math" display="inline" id="Sx3.T1.3.3.1.m1.1"><semantics id="Sx3.T1.3.3.1.m1.1a"><mrow id="Sx3.T1.3.3.1.m1.1.1" xref="Sx3.T1.3.3.1.m1.1.1.cmml"><mn id="Sx3.T1.3.3.1.m1.1.1.2" xref="Sx3.T1.3.3.1.m1.1.1.2.cmml">1</mn><mo id="Sx3.T1.3.3.1.m1.1.1.1" xref="Sx3.T1.3.3.1.m1.1.1.1.cmml">⁢</mo><mi id="Sx3.T1.3.3.1.m1.1.1.3" xref="Sx3.T1.3.3.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="Sx3.T1.3.3.1.m1.1b"><apply id="Sx3.T1.3.3.1.m1.1.1.cmml" xref="Sx3.T1.3.3.1.m1.1.1"><times id="Sx3.T1.3.3.1.m1.1.1.1.cmml" xref="Sx3.T1.3.3.1.m1.1.1.1"></times><cn id="Sx3.T1.3.3.1.m1.1.1.2.cmml" type="integer" xref="Sx3.T1.3.3.1.m1.1.1.2">1</cn><ci id="Sx3.T1.3.3.1.m1.1.1.3.cmml" xref="Sx3.T1.3.3.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.T1.3.3.1.m1.1c">1M</annotation><annotation encoding="application/x-llamapun" id="Sx3.T1.3.3.1.m1.1d">1 italic_M</annotation></semantics></math> pretrain</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.3.3.2">0.735</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.3.3.3">2.071</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.3.3.4">1.002</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.3.3.5">1.046</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.3.3.6">2.957</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.3.3.7">1.562</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.11">
<td class="ltx_td ltx_align_left" id="Sx3.T1.8.11.1">Chinese LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Cui, Yang, and Yao <a class="ltx_ref" href="#bib.bib13" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.11.2">0.509</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.11.3">1.205</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.11.4">0.811</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.11.5">0.726</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.11.6">2.970</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.11.7">1.244</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.12">
<td class="ltx_td ltx_align_left" id="Sx3.T1.8.12.1">Open Chinese LLaMA <cite class="ltx_cite ltx_citemacro_citep">(OpenLMLab <a class="ltx_ref" href="#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.12.2">1.406</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.12.3">2.584</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.12.4">1.685</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.12.5">1.877</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.12.6">2.989</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.12.7">2.108</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.13">
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.13.1" rowspan="6"><span class="ltx_text" id="Sx3.T1.8.13.1.1">5k SFT</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="Sx3.T1.8.13.2">LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al. <a class="ltx_ref" href="#bib.bib43" title="">2023a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.13.3">0.450</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.13.4">1.279</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.13.5">0.767</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.13.6">0.612</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.13.7">3.000</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.13.8">1.199</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.4.4">
<td class="ltx_td ltx_align_left" id="Sx3.T1.4.4.1">LLaMA with <math alttext="10K" class="ltx_Math" display="inline" id="Sx3.T1.4.4.1.m1.1"><semantics id="Sx3.T1.4.4.1.m1.1a"><mrow id="Sx3.T1.4.4.1.m1.1.1" xref="Sx3.T1.4.4.1.m1.1.1.cmml"><mn id="Sx3.T1.4.4.1.m1.1.1.2" xref="Sx3.T1.4.4.1.m1.1.1.2.cmml">10</mn><mo id="Sx3.T1.4.4.1.m1.1.1.1" xref="Sx3.T1.4.4.1.m1.1.1.1.cmml">⁢</mo><mi id="Sx3.T1.4.4.1.m1.1.1.3" xref="Sx3.T1.4.4.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="Sx3.T1.4.4.1.m1.1b"><apply id="Sx3.T1.4.4.1.m1.1.1.cmml" xref="Sx3.T1.4.4.1.m1.1.1"><times id="Sx3.T1.4.4.1.m1.1.1.1.cmml" xref="Sx3.T1.4.4.1.m1.1.1.1"></times><cn id="Sx3.T1.4.4.1.m1.1.1.2.cmml" type="integer" xref="Sx3.T1.4.4.1.m1.1.1.2">10</cn><ci id="Sx3.T1.4.4.1.m1.1.1.3.cmml" xref="Sx3.T1.4.4.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.T1.4.4.1.m1.1c">10K</annotation><annotation encoding="application/x-llamapun" id="Sx3.T1.4.4.1.m1.1d">10 italic_K</annotation></semantics></math> pretrain</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.4.4.2">0.411</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.4.4.3">1.372</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.4.4.4">0.814</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.4.4.5">0.612</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.4.4.6">2.961</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.4.4.7">1.258</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.5.5">
<td class="ltx_td ltx_align_left" id="Sx3.T1.5.5.1">LLaMA with <math alttext="100K" class="ltx_Math" display="inline" id="Sx3.T1.5.5.1.m1.1"><semantics id="Sx3.T1.5.5.1.m1.1a"><mrow id="Sx3.T1.5.5.1.m1.1.1" xref="Sx3.T1.5.5.1.m1.1.1.cmml"><mn id="Sx3.T1.5.5.1.m1.1.1.2" xref="Sx3.T1.5.5.1.m1.1.1.2.cmml">100</mn><mo id="Sx3.T1.5.5.1.m1.1.1.1" xref="Sx3.T1.5.5.1.m1.1.1.1.cmml">⁢</mo><mi id="Sx3.T1.5.5.1.m1.1.1.3" xref="Sx3.T1.5.5.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="Sx3.T1.5.5.1.m1.1b"><apply id="Sx3.T1.5.5.1.m1.1.1.cmml" xref="Sx3.T1.5.5.1.m1.1.1"><times id="Sx3.T1.5.5.1.m1.1.1.1.cmml" xref="Sx3.T1.5.5.1.m1.1.1.1"></times><cn id="Sx3.T1.5.5.1.m1.1.1.2.cmml" type="integer" xref="Sx3.T1.5.5.1.m1.1.1.2">100</cn><ci id="Sx3.T1.5.5.1.m1.1.1.3.cmml" xref="Sx3.T1.5.5.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.T1.5.5.1.m1.1c">100K</annotation><annotation encoding="application/x-llamapun" id="Sx3.T1.5.5.1.m1.1d">100 italic_K</annotation></semantics></math> pretrain</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.5.5.2">0.488</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.5.5.3">1.922</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.5.5.4">0.876</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.5.5.5">0.977</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.5.5.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.5.5.7">1.493</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.6.6">
<td class="ltx_td ltx_align_left" id="Sx3.T1.6.6.1">LLaMA with <math alttext="1M" class="ltx_Math" display="inline" id="Sx3.T1.6.6.1.m1.1"><semantics id="Sx3.T1.6.6.1.m1.1a"><mrow id="Sx3.T1.6.6.1.m1.1.1" xref="Sx3.T1.6.6.1.m1.1.1.cmml"><mn id="Sx3.T1.6.6.1.m1.1.1.2" xref="Sx3.T1.6.6.1.m1.1.1.2.cmml">1</mn><mo id="Sx3.T1.6.6.1.m1.1.1.1" xref="Sx3.T1.6.6.1.m1.1.1.1.cmml">⁢</mo><mi id="Sx3.T1.6.6.1.m1.1.1.3" xref="Sx3.T1.6.6.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="Sx3.T1.6.6.1.m1.1b"><apply id="Sx3.T1.6.6.1.m1.1.1.cmml" xref="Sx3.T1.6.6.1.m1.1.1"><times id="Sx3.T1.6.6.1.m1.1.1.1.cmml" xref="Sx3.T1.6.6.1.m1.1.1.1"></times><cn id="Sx3.T1.6.6.1.m1.1.1.2.cmml" type="integer" xref="Sx3.T1.6.6.1.m1.1.1.2">1</cn><ci id="Sx3.T1.6.6.1.m1.1.1.3.cmml" xref="Sx3.T1.6.6.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.T1.6.6.1.m1.1c">1M</annotation><annotation encoding="application/x-llamapun" id="Sx3.T1.6.6.1.m1.1d">1 italic_M</annotation></semantics></math> pretrain</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.6.6.2">0.682</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.6.6.3">2.085</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.6.6.4">1.039</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.6.6.5">1.008</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.6.6.6">2.969</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.6.6.7">1.623</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.14">
<td class="ltx_td ltx_align_left" id="Sx3.T1.8.14.1">Chinese LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Cui, Yang, and Yao <a class="ltx_ref" href="#bib.bib13" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.14.2">0.581</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.14.3">1.341</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.14.4">0.899</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.14.5">0.783</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.14.6">2.992</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.14.7">1.432</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.15">
<td class="ltx_td ltx_align_left" id="Sx3.T1.8.15.1">Open Chinese LLaMA <cite class="ltx_cite ltx_citemacro_citep">(OpenLMLab <a class="ltx_ref" href="#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.15.2">1.295</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.15.3">2.481</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.15.4">1.667</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.15.5">1.884</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.15.6">2.969</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.15.7">2.245</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.16">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx3.T1.8.16.1" rowspan="7"><span class="ltx_text" id="Sx3.T1.8.16.1.1">950k SFT</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="Sx3.T1.8.16.2">LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al. <a class="ltx_ref" href="#bib.bib43" title="">2023a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.16.3">1.783</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.16.4">2.767</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.16.5">2.142</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.16.6">2.212</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.16.7">2.993</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx3.T1.8.16.8">2.379</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.7.7">
<td class="ltx_td ltx_align_left" id="Sx3.T1.7.7.1">LLaMA with <math alttext="1M" class="ltx_Math" display="inline" id="Sx3.T1.7.7.1.m1.1"><semantics id="Sx3.T1.7.7.1.m1.1a"><mrow id="Sx3.T1.7.7.1.m1.1.1" xref="Sx3.T1.7.7.1.m1.1.1.cmml"><mn id="Sx3.T1.7.7.1.m1.1.1.2" xref="Sx3.T1.7.7.1.m1.1.1.2.cmml">1</mn><mo id="Sx3.T1.7.7.1.m1.1.1.1" xref="Sx3.T1.7.7.1.m1.1.1.1.cmml">⁢</mo><mi id="Sx3.T1.7.7.1.m1.1.1.3" xref="Sx3.T1.7.7.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="Sx3.T1.7.7.1.m1.1b"><apply id="Sx3.T1.7.7.1.m1.1.1.cmml" xref="Sx3.T1.7.7.1.m1.1.1"><times id="Sx3.T1.7.7.1.m1.1.1.1.cmml" xref="Sx3.T1.7.7.1.m1.1.1.1"></times><cn id="Sx3.T1.7.7.1.m1.1.1.2.cmml" type="integer" xref="Sx3.T1.7.7.1.m1.1.1.2">1</cn><ci id="Sx3.T1.7.7.1.m1.1.1.3.cmml" xref="Sx3.T1.7.7.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.T1.7.7.1.m1.1c">1M</annotation><annotation encoding="application/x-llamapun" id="Sx3.T1.7.7.1.m1.1d">1 italic_M</annotation></semantics></math> pretrain</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.7.7.2">1.812</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.7.7.3">2.799</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.7.7.4">2.080</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.7.7.5">2.303</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.7.7.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.7.7.7">2.399</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.8">
<td class="ltx_td ltx_align_left" id="Sx3.T1.8.8.1">LLaMA-EXT with <math alttext="1M" class="ltx_Math" display="inline" id="Sx3.T1.8.8.1.m1.1"><semantics id="Sx3.T1.8.8.1.m1.1a"><mrow id="Sx3.T1.8.8.1.m1.1.1" xref="Sx3.T1.8.8.1.m1.1.1.cmml"><mn id="Sx3.T1.8.8.1.m1.1.1.2" xref="Sx3.T1.8.8.1.m1.1.1.2.cmml">1</mn><mo id="Sx3.T1.8.8.1.m1.1.1.1" xref="Sx3.T1.8.8.1.m1.1.1.1.cmml">⁢</mo><mi id="Sx3.T1.8.8.1.m1.1.1.3" xref="Sx3.T1.8.8.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="Sx3.T1.8.8.1.m1.1b"><apply id="Sx3.T1.8.8.1.m1.1.1.cmml" xref="Sx3.T1.8.8.1.m1.1.1"><times id="Sx3.T1.8.8.1.m1.1.1.1.cmml" xref="Sx3.T1.8.8.1.m1.1.1.1"></times><cn id="Sx3.T1.8.8.1.m1.1.1.2.cmml" type="integer" xref="Sx3.T1.8.8.1.m1.1.1.2">1</cn><ci id="Sx3.T1.8.8.1.m1.1.1.3.cmml" xref="Sx3.T1.8.8.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx3.T1.8.8.1.m1.1c">1M</annotation><annotation encoding="application/x-llamapun" id="Sx3.T1.8.8.1.m1.1d">1 italic_M</annotation></semantics></math> pretrain</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.8.2">1.591</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.8.3">2.726</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.8.4">1.918</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.8.5">2.164</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.8.6">2.998</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.8.7">2.279</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.17">
<td class="ltx_td ltx_align_left" id="Sx3.T1.8.17.1">Chinese LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Cui, Yang, and Yao <a class="ltx_ref" href="#bib.bib13" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.17.2">1.808</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.17.3">2.795</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.17.4">2.112</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.17.5">2.313</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.17.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.17.7">2.406</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.18">
<td class="ltx_td ltx_align_left" id="Sx3.T1.8.18.1">Open Chinese LLaMA <cite class="ltx_cite ltx_citemacro_citep">(OpenLMLab <a class="ltx_ref" href="#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.18.2">1.890</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.18.3">2.858</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.18.4">2.189</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.18.5">2.390</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.18.6">2.993</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.18.7">2.464</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.19">
<td class="ltx_td ltx_align_left" id="Sx3.T1.8.19.1">LLaMA2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al. <a class="ltx_ref" href="#bib.bib44" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.19.2">1.868</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.19.3">2.822</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.19.4">2.171</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.19.5">2.379</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.19.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx3.T1.8.19.7">2.448</td>
</tr>
<tr class="ltx_tr" id="Sx3.T1.8.20">
<td class="ltx_td ltx_align_left ltx_border_bb" id="Sx3.T1.8.20.1">Chinese LLaMA2 <cite class="ltx_cite ltx_citemacro_citep">(Cui, Yang, and Yao <a class="ltx_ref" href="#bib.bib12" title="">2023a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx3.T1.8.20.2">1.701</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx3.T1.8.20.3">2.838</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx3.T1.8.20.4">2.011</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx3.T1.8.20.5">2.251</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx3.T1.8.20.6">3.000</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx3.T1.8.20.7">2.360</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 1:</span>SFT( further pretraining and instruction tuning)의 서로 다른 스케일을 갖는 응답 품질. ACC., F., LC., H., INFO., AVG. 각각 정확성, 유창성, 논리적 일관성, 무해성, 정보성 및 평균을 나타낸다. 약 100만 개의 샘플이 약 0.5억 개의 토큰을 차지한다. 중국 LLaMA와 오픈 중국 LLaMA의 사전 훈련 규모는 각각 300억 토큰과 1000억 토큰이다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx3.SSx2.p4">
<p class="ltx_p" id="Sx3.SSx2.p4.1">모델의 역량을 객관적이고 종합적으로 평가하기 위해 응답 품질과 지식 수준의 두 가지 관점에서 평가를 수행한다. 전자의 경우 LLM-Eval 벤치마크를 사용하고 이를 다양한 저자원 언어로 번역하여 다국어 평가를 지원한다. 후자는 C-Eval, MMLU, AGI-Eval 및 GAOKAO-Bench의 4가지 널리 채택된 표준화된 테스트 벤치마크를 활용한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx2.p5">
<p class="ltx_p" id="Sx3.SSx2.p5.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx2.p5.1.1">LLM-Eval</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a class="ltx_ref" href="#bib.bib51" title="">2023a</a>)</cite>: LLM-Eval은 명령어 후속 평가를 위해 수동으로 구성된 벤치마크이다. 사실적 질문 답변, 독해, 프레임 생성, 단락 다시 쓰기, 요약, 수학 문제 해결, 추론, 시 생성, 프로그래밍 등 17개 대분류 453개의 수업 과제를 가지고 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx2.p6">
<p class="ltx_p" id="Sx3.SSx2.p6.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx2.p6.1.1">C-Eval</span> <cite class="ltx_cite ltx_citemacro_citep">(Huang et al. <a class="ltx_ref" href="#bib.bib22" title="">2023b</a>)</cite>: C-Eval은 52개 과목에 걸쳐 13948개의 시험 문제와 중학교부터 전문 시험까지 4개의 난이도를 가진 중국어 평가 제품군이다. 여기에는 STEM, 인문학, 사회 과학 및 기타 주제가 포함됩니다. C-Eval HARD는 고급 추론이 필요한 8개의 도전적인 수학과 과학 과목의 하위 집합이다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx2.p7">
<p class="ltx_p" id="Sx3.SSx2.p7.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx2.p7.1.1">MMLU</span> <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al. <a class="ltx_ref" href="#bib.bib18" title="">2020</a>)</cite>: MMLU는 STEM, 인문 및 사회 과학을 포함한 57개의 다양한 주제에 걸쳐 지식을 배우고 적용하는 LLM의 능력을 측정한다. 이 시험은 초등부터 고급 전문가까지 다양한 난이도를 다루고 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx2.p8">
<p class="ltx_p" id="Sx3.SSx2.p8.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx2.p8.1.1">AGI-Eval</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhong et al. <a class="ltx_ref" href="#bib.bib53" title="">2023</a>)</cite>: AGIEval은 대학입시, 로스쿨입시, 전문자격시험 등 수백만 명이 응시한 표준화된 시험의 문항을 사용한다. 그것은 영어와 중국어 모두 19개의 과제를 가지고 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx3.SSx2.p9">
<p class="ltx_p" id="Sx3.SSx2.p9.1"><span class="ltx_text ltx_font_bold" id="Sx3.SSx2.p9.1.1">Gaokao-Bench</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a class="ltx_ref" href="#bib.bib52" title="">2023b</a>)</cite>: GAOKAO-Bench는 2010-2022년 중국 대학 입시(Gaokao)의 2811개의 시험 문제를 모든 과목을 대상으로 한다. 1781개의 객관식, 218개의 빈칸 채우기, 수학, 중국어, 영어, 물리 등 전반에 걸쳐 812개의 개방형 질문이 있습니다.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx3.SSx3">
<h3 class="ltx_title ltx_title_subsection">Evaluation Protocol</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx3.SSx3.p1">
<p class="ltx_p" id="Sx3.SSx3.p1.1">LLM-Eval의 경우 정확도, 유창성, 정보성, 논리성, 무해성의 5가지 채점 항목을 통해 모델의 응답 품질을 평가하는 <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="#bib.bib51" title="">2023a</a>)</cite>의 관행을 따랐다. 각 측면에 대한 점수는 0에서 3 사이이다. 자동 평가를 위해 지침, 모델 응답 및 참조 답변을 GPT-4에 제출하기 위해 부록에 표시된 프롬프트를 사용한다. <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="#bib.bib51" title="">2023a</a>)</cite>에 의해 보고된 결과에 기초하여, 이 평가 방법은 인간 평가와의 높은 일관성을 입증한다.</p>
</div>
<div class="ltx_para" id="Sx3.SSx3.p2">
<p class="ltx_p" id="Sx3.SSx3.p2.1">4개의 표준화된 테스트 벤치마크의 경우 모델 반응에 대한 정확도 메트릭을 계산한다. 또한 AGI-Eval 및 GAOKAO-Bench에 대해 제로 샷 설정을 사용하고 C-Eval 및 MMLU에 대해 5 샷 설정을 사용하는 일반적인 관행을 따른다.</p>
</div>
<figure class="ltx_figure" id="Sx3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="332" id="Sx3.F2.g1" src="https://arxiv.org/html/2401.01055v2/x2.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2:</span>Knowledge-level evaluation results on four benchmarks.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="Sx4">
<h2 class="ltx_title ltx_title_section">Main Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="Sx4.SSx1">
<h3 class="ltx_title ltx_title_subsection">The Impact of Vocabulary Extension on Transfer</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx4.SSx1.p1">
<p class="ltx_p" id="Sx4.SSx1.p1.1">특정 언어에서 LLM의 능력을 향상시키는 것을 목표로 할 때 어휘 확장은 직관적으로 합리적인 접근법이다. 본 절에서는 LLM-Eval 벤치마크를 통해 어휘 확장의 영향을 평가하고, 실험 결과는 <a class="ltx_ref" href="#Sx3.T1" title="Table 1 ‣ Datasets ‣ Experimental Setup ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_tag">1</span></a> 표에 제시하였다. 처음에는 인터넷에서 100만 개의 중국어 문장(약 0.5억 토큰)을 수집하고 어휘 확장 없이 원본 LLaMA를 추가로 사전 훈련했다. 놀랍게도, 이 모델은 1K, 5K 및 950K 명령어 튜닝 설정에 걸쳐 어휘 확장 중국어 LLaMA를 상당히 능가한다는 것을 발견했다. 이 발견은 중국 LLaMA가 우리의 0.5억 토큰보다 훨씬 더 큰 300억 토큰에 대한 추가 중국 사전 교육을 받았다는 점을 감안할 때 생각과 거리가 있다. 또한 950K 설정 내에서 원본 LLaMA에 대한 어휘를 확장하고 동일한 0.5억 토큰으로 훈련하여 훈련 데이터 불일치의 영향을 완화한 결과를 포함한다. 그 결과는 여전히 일관적이다. 이것은 어휘 확장이 수백억 토큰의 훈련 규모 내에서 유리한 선택이 아님을 나타낸다. 다른 문헌 <cite class="ltx_cite ltx_citemacro_citep">(Team <a class="ltx_ref" href="#bib.bib42" title="">2023b</a>)</cite>에서 보고된 바와 같이 더 큰 규모의 사전 훈련(예: 수조 개의 토큰)을 포함하는 설정에서 어휘 확장의 효능을 부정하지는 않지만, 이는 이미 단순한 언어 전달보다 재훈련에 더 기울어져 있다.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx4.SSx2">
<h3 class="ltx_title ltx_title_subsection">Training Scales Required for Effective Transfer</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx4.SSx2.p1">
<p class="ltx_p" id="Sx4.SSx2.p1.1">훈련 척도는 사전 훈련 척도와 수업 조정 척도로 구성된 LLM 역량의 전이 가능성에 영향을 미치는 또 다른 중요한 요인을 구성한다. 실험 결과는 표 <a class="ltx_ref" href="#Sx3.T1" title="Table 1 ‣ Datasets ‣ Experimental Setup ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_tag">1</span></a>와 같다. LLaMA(10K, 100K, 1M 추가 프리트레이닝 포함)와 오픈 차이나 LLaMA를 예로 들면, 추가 차이나 프리트레이닝의 규모는 0에서 1000억 토큰으로 점차 증가한다. 1K 및 5K 명령어 튜닝 설정에서 추가 사전 훈련의 규모가 증가함에 따라 응답 품질이 점진적으로 향상되는 것을 관찰했다. <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Chinese-LLaMA, however, stands as an exception due to the additional factor of vocabulary extension.</span></span></span> 그러나 명령어 튜닝 데이터 척도가 950K로 확장될 때 모델 간에 응답 품질에 큰 차이가 없음을 알 수 있다. 결과적으로, 우리는 더 많은 사전 훈련이 모델의 인간 명령과의 정렬을 가속화할 수 있다고 가정하지만, 수백억의 훈련 규모만으로는 모델이 더 많은 양의 세계 지식을 파악할 수 없다. 이것은 유사한 반응 수준에서 수렴으로 이어진다. 즉, 응답 품질의 향상은 주로 지식 수준의 향상보다는 언어 생성 능력의 향상에서 비롯된다.</p>
</div>
<div class="ltx_para" id="Sx4.SSx2.p2">
<p class="ltx_p" id="Sx4.SSx2.p2.1">이 관점을 검증하기 위해 널리 사용되는 4개의 표준화된 테스트 벤치마크에 대한 모델의 지식 수준을 평가했다. 그림 <a class="ltx_ref" href="#Sx3.F2" title="Figure 2 ‣ Evaluation Protocol ‣ Experimental Setup ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_tag">2</span></a>에 나타난 바와 같이, LLaMA 7B, Chinese LLaMA 7B, Open Chinese LLaMA 7B는 C-eval, gaokao-bench, agi-eval에서 비교적 잘 수행되어 추가적인 중국어 사전 훈련에 의해 유발되는 유의미한 차이가 없음을 알 수 있다. 중국어에서 추가 사전 훈련이 부족함에도 불구하고 LLaMA2-7B와 LLaMA-13B 모두 C-Eval, MMLU 및 AGI-Eval에서 개방형 중국 LLaMA를 능가하여 조 수준 사전 훈련과 더 큰 모델 크기가 실제로 모델 지식 수준을 향상시키는 효과적인 경로 역할을 할 수 있음을 시사한다는 점에 주목할 필요가 있다.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx4.SSx3">
<h3 class="ltx_title ltx_title_subsection">How about the Original English Capabilities</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="Sx4.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="Sx4.T2.1" style="width:433.6pt;height:121.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(120.5pt,-33.8pt) scale(2.25191558933999,2.25191558933999) ;">
<table class="ltx_tabular ltx_align_middle" id="Sx4.T2.1.1">
<tbody><tr class="ltx_tr" id="Sx4.T2.1.1.1">
<td class="ltx_td ltx_border_tt" id="Sx4.T2.1.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx4.T2.1.1.1.2">L(0)</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx4.T2.1.1.1.3">L(10k)</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx4.T2.1.1.1.4">L(100k)</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx4.T2.1.1.1.5">L(1M)</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Sx4.T2.1.1.1.6">Open</td>
</tr>
<tr class="ltx_tr" id="Sx4.T2.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="Sx4.T2.1.1.2.1"><span class="ltx_text ltx_font_bold" id="Sx4.T2.1.1.2.1.1">Chinese</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T2.1.1.2.2">10.151</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T2.1.1.2.3">8.697</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T2.1.1.2.4">6.634</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T2.1.1.2.5">5.249</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T2.1.1.2.6">3.924</td>
</tr>
<tr class="ltx_tr" id="Sx4.T2.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_bb" id="Sx4.T2.1.1.3.1"><span class="ltx_text ltx_font_bold" id="Sx4.T2.1.1.3.1.1">English</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx4.T2.1.1.3.2">14.691</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx4.T2.1.1.3.3">15.625</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx4.T2.1.1.3.4">29.553</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx4.T2.1.1.3.5">198.840</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Sx4.T2.1.1.3.6">15.045</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 2:</span>모델 perplexity with different further pretraining scale. L은 LLaMA를 나타내며 괄호 안의 숫자는 추가 사전 훈련 샘플의 양을 나타낸다. Open은 Open Chinese LLaMA를 나타낸다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx4.SSx3.p1">
<p class="ltx_p" id="Sx4.SSx3.p1.1">우리에게 관심의 또 다른 쟁점은 중국어 능력 향상이 기존의 영어 능력에 영향을 미치는지 여부이다. 이 문제를 해결하기 위해 인터넷에서 200,000개의 중국 샘플을 추가로 수집하고 정제된 웹 데이터 세트 <cite class="ltx_cite ltx_citemacro_citep">(Penedo et al. <a class="ltx_ref" href="#bib.bib34" title="">2023</a>)</cite>에서 20,000개의 영어 샘플을 무작위로 추출했다. 이러한 샘플을 사용하여 표 <a class="ltx_ref" href="#Sx4.T2" title="Table 2 ‣ How about the Original English Capabilities ‣ Main Results ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_tag">2</span></a>에 표시된 것처럼 서로 다른 규모의 말뭉치로 훈련된 LLaMA 모델의 영어 복잡도와 중국어 복잡도를 평가한다. 우리의 연구 결과는 추가 사전 훈련 척도가 증가함에 따라 모델의 복잡성은 중국어에서는 꾸준히 감소하지만 영어에서는 현저하게 증가한다는 것을 보여준다. 이는 하나의 중국어 말뭉치를 통해서만 모델의 역량을 높이는 것은 원래 영어 실력을 희생하는 대가를 치르게 된다는 것을 시사한다.</p>
</div>
<div class="ltx_para" id="Sx4.SSx3.p2">
<p class="ltx_p" id="Sx4.SSx3.p2.1">또한 개방형 중국어 LLaMA에 대해 당혹도 평가를 수행하고 중국어와 영어 당혹도가 여전히 낮다는 것을 발견했다. 이 결과는 교육 데이터가 중국어와 영어 콘텐츠를 모두 통합하여 영어 복잡도의 현저한 상승 없이 중국어 복잡도의 감소를 허용한다는 점을 감안할 때 놀라운 일이 아니다. 전반적으로, 전이 훈련을 위한 중국 말뭉치에 대한 배타적 의존은 LLaMA의 원래 영어 능력을 현저하게 손상시키며, 이는 다국어 공동 훈련을 통해 효과적으로 완화된다.</p>
</div>
<figure class="ltx_table" id="Sx4.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="Sx4.T3.1">
<tbody><tr class="ltx_tr" id="Sx4.T3.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="Sx4.T3.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="Sx4.T3.1.1.1.1">Language</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="6" id="Sx4.T3.1.1.2">1k SFT</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="6" id="Sx4.T3.1.1.3">65k SFT</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.1">ACC.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.2">F.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.3">INFO.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.4">LC.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.5">H.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.6">AVG.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.7">ACC.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.8">F.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.9">INFO.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.10">LC.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.11">H.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.2.12">AVG.</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="Sx4.T3.1.3.1">Arbic</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.2">0.188</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.3">1.061</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.4">0.191</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.5">0.254</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.6">3.000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.7">0.939</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.8">1.268</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.9">2.499</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.10">1.529</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.11">1.607</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.12">3.000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Sx4.T3.1.3.13">1.981</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.4">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.4.1">Bengali</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.2">0.046</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.3">0.492</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.4">0.050</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.5">0.041</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.7">0.726</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.8">0.959</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.9">2.257</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.10">1.156</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.11">1.189</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.12">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.4.13">1.712</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.5">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.5.1">Gujarati</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.2">0.061</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.3">0.426</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.4">0.052</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.5">0.063</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.6">2.998</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.7">0.720</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.8">0.683</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.9">1.795</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.10">0.875</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.11">0.790</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.12">2.995</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.5.13">1.428</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.6">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.6.1">Hindi</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.2">0.131</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.3">1.064</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.4">0.147</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.5">0.162</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.7">0.901</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.8">1.014</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.9">2.342</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.10">1.238</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.11">1.240</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.12">2.998</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.6.13">1.766</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.7">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.7.1">Indonesian</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.2">0.398</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.3">1.266</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.4">0.544</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.5">0.438</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.6">2.995</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.7">1.128</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.8">1.659</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.9">2.751</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.10">2.026</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.11">2.012</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.12">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.7.13">2.290</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.8">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.8.1">Malayalam</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.2">0.101</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.3">0.621</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.4">0.103</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.5">0.103</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.7">0.786</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.8">0.906</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.9">2.427</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.10">1.182</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.11">1.197</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.12">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.8.13">1.742</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.9">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.9.1">Marathi</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.2">0.095</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.3">0.781</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.4">0.107</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.5">0.117</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.6">2.998</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.7">0.820</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.8">1.038</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.9">2.476</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.10">1.288</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.11">1.364</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.12">2.998</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.9.13">1.833</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.10">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.10.1">Nepali</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.2">0.151</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.3">0.991</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.4">0.177</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.5">0.146</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.6">2.986</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.7">0.890</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.8">0.969</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.9">2.417</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.10">1.236</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.11">1.285</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.12">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.10.13">1.781</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.11">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.11.1">Swahili</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.2">0.083</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.3">0.712</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.4">0.090</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.5">0.086</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.6">2.998</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.7">0.794</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.8">1.569</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.9">2.707</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.10">1.955</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.11">1.907</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.12">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.11.13">2.228</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.12">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.12.1">Tamil</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.2">0.140</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.3">0.914</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.4">0.176</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.5">0.174</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.6">2.998</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.7">0.880</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.8">0.960</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.9">2.457</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.10">1.198</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.11">1.257</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.12">2.998</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.12.13">1.774</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.13">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.13.1">Telugu</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.2">0.054</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.3">0.560</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.4">0.057</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.5">0.090</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.7">0.752</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.8">0.539</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.9">1.735</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.10">0.674</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.11">0.712</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.12">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.13.13">1.332</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.14">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.14.1">Urdu</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.2">0.057</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.3">0.573</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.4">0.052</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.5">0.071</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.7">0.751</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.8">1.038</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.9">2.443</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.10">1.285</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.11">1.335</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.12">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.14.13">1.820</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.15">
<td class="ltx_td ltx_align_left" id="Sx4.T3.1.15.1">Vietnamese</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.2">0.105</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.3">0.623</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.4">0.126</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.5">0.117</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.6">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.7">0.794</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.8">1.361</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.9">2.595</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.10">1.665</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.11">1.710</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.12">3.000</td>
<td class="ltx_td ltx_align_center" id="Sx4.T3.1.15.13">2.066</td>
</tr>
<tr class="ltx_tr" id="Sx4.T3.1.16">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.1">Average</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.2">0.124</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.3">0.776</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.4">0.144</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.5">0.143</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.6">2.998</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.7">0.837</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.8">1.074</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.9">2.377</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.10">1.331</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.11">1.354</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.12">2.999</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="Sx4.T3.1.16.13">1.827</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 3:</span> LLM-Eval 상의 13개의 낮은 리소스 언어에 대한 모델 응답 품질의 평가 결과. ACC., F., LC., H., INFO., AVG. 각각 정확성, 유창성, 논리적 일관성, 무해성, 정보성 및 평균을 나타낸다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="Sx5">
<h2 class="ltx_title ltx_title_section">Extending the Analysis to Multiple Languages</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx5.p1">
<p class="ltx_p" id="Sx5.p1.1">앞 절에서, 우리의 실험은 중국어에 초점을 맞춘다. 다른 비영어 언어에서도 유사한 결론이 도출될 수 있는지 조사하기 위해 실험을 13개의 저자원 언어로 확장한다. 평가 일관성을 보장하기 위해 LLM-Eval 벤치마크를 이 13개 언어로 번역하고 동일한 평가 메트릭을 사용한다. <a class="ltx_ref" href="#Sx4.T3" title="Table 3 ‣ How about the Original English Capabilities ‣ Main Results ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_tag">3</span></a> 표와 같이 SFT 데이터의 증가와 함께 모든 저자원 언어에 대한 응답 품질이 크게 향상되었다. 이들 언어 중 아랍어, 인도네시아어, 베트남어가 가장 좋은 성능을 보였다. 13개 언어가 모두 자원이 부족함에도 불구하고 이 세 언어는 <cite class="ltx_cite ltx_citemacro_citep">(Scao et al. <a class="ltx_ref" href="#bib.bib37" title="">2023</a>)</cite>를 더 자주 사용한다. 결과적으로 LLaMA는 (영어에 비해 전반적인 발생이 적지만) 그들을 더 자주 만나 모델을 통해 이러한 언어로 된 지침을 빠르게 이해할 수 있다. 이는 이전 섹션에서 도출한 결론과 일치한다.</p>
</div>
<div class="ltx_para" id="Sx5.p2">
<p class="ltx_p" id="Sx5.p2.2">앞 절에서는 어휘를 확장하는 것이 언어 전이성에 부정적인 영향을 미친다는 것을 관찰하였다. 그럴듯한 가설은 어휘 확장이 방해할 수 있는 LLM 내의 교차 언어 의미 정렬의 존재이다. 이 정렬 가설을 검증하기 위해 1k 명령어의 데이터 세트로 LLaMA를 미세 조정하고 모델의 출력을 조사한다. 흥미롭게, 우리는 코드 전환 샘플의 특정 비율을 관찰했다. 그림 <a class="ltx_ref" href="#Sx5.F3" title="Figure 3 ‣ Extending the Analysis to Multiple Languages ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_tag">3</span></a>에 묘사된 바와 같이, 이들 샘플의 모델 응답은 여러 언어의 토큰으로 구성되며 의미적으로 일관적이다. 우리는 중국어가 타겟 언어인 경우 전송 과정뿐만 아니라 다른 13개의 저자원 언어들이 타겟 언어인 경우에도 코드 전환이 발생함을 관찰하였다. 도표 <a class="ltx_ref" href="#Sx5.F4" title="Figure 4 ‣ Extending the Analysis to Multiple Languages ‣ LLaMA Beyond English: An Empirical Study on Language Capability Transfer"><span class="ltx_text ltx_ref_tag">4</span></a>에 도시된 바와 같이, 코드-스위칭이 있는 샘플의 비율은 대략 <math alttext="2\%" class="ltx_Math" display="inline" id="Sx5.p2.1.m1.1"><semantics id="Sx5.p2.1.m1.1a"><mrow id="Sx5.p2.1.m1.1.1" xref="Sx5.p2.1.m1.1.1.cmml"><mn id="Sx5.p2.1.m1.1.1.2" xref="Sx5.p2.1.m1.1.1.2.cmml">2</mn><mo id="Sx5.p2.1.m1.1.1.1" xref="Sx5.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx5.p2.1.m1.1b"><apply id="Sx5.p2.1.m1.1.1.cmml" xref="Sx5.p2.1.m1.1.1"><csymbol cd="latexml" id="Sx5.p2.1.m1.1.1.1.cmml" xref="Sx5.p2.1.m1.1.1.1">percent</csymbol><cn id="Sx5.p2.1.m1.1.1.2.cmml" type="integer" xref="Sx5.p2.1.m1.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p2.1.m1.1c">2\%</annotation><annotation encoding="application/x-llamapun" id="Sx5.p2.1.m1.1d">2 %</annotation></semantics></math>에서 <math alttext="5\%" class="ltx_Math" display="inline" id="Sx5.p2.2.m2.1"><semantics id="Sx5.p2.2.m2.1a"><mrow id="Sx5.p2.2.m2.1.1" xref="Sx5.p2.2.m2.1.1.cmml"><mn id="Sx5.p2.2.m2.1.1.2" xref="Sx5.p2.2.m2.1.1.2.cmml">5</mn><mo id="Sx5.p2.2.m2.1.1.1" xref="Sx5.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx5.p2.2.m2.1b"><apply id="Sx5.p2.2.m2.1.1.cmml" xref="Sx5.p2.2.m2.1.1"><csymbol cd="latexml" id="Sx5.p2.2.m2.1.1.1.cmml" xref="Sx5.p2.2.m2.1.1.1">percent</csymbol><cn id="Sx5.p2.2.m2.1.1.2.cmml" type="integer" xref="Sx5.p2.2.m2.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx5.p2.2.m2.1c">5\%</annotation><annotation encoding="application/x-llamapun" id="Sx5.p2.2.m2.1d">5 %</annotation></semantics></math> 사이이다. 이는 LLaMA가 사전 훈련 과정에서 개념 간의 언어 간 정렬 관계를 학습했을 수 있음을 나타낸다.</p>
</div>
<figure class="ltx_figure" id="Sx5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="1079" id="Sx5.F3.g1" src="https://arxiv.org/html/2401.01055v2/x3.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">그림 3:</span>코드 전환 사례 연구. 빨간색 배경을 가진 텍스트는 비영어 타겟 언어(중국어)를 나타낸다. 청록색 배경이 있는 텍스트는 모델 출력에서 코드 전환 언어를 나타내며, 이는 영어, 일본어, 러시아어 또는 기타 언어일 수 있습니다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="Sx5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="761" id="Sx5.F4.g1" src="https://arxiv.org/html/2401.01055v2/x4.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4:</span>Code-switching rate across languages.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_section" id="Sx6">
<h2 class="ltx_title ltx_title_section">Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="Sx6.SSx1">
<h3 class="ltx_title ltx_title_subsection">Resource Gap in LLMs</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx6.SSx1.p1">
<p class="ltx_p" id="Sx6.SSx1.p1.1">LLM의 주요 과제 중 하나는 주로 영어 코퍼스에서 사전 훈련되고 다른 언어의 데이터에 대한 접근이 제한적이기 때문에 자원 격차이다. 영어는 다양한 도메인에서 가장 많은 원시 텍스트 데이터로 매우 높은 리소스 언어로 NLP 분야를 지배하며, <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al. <a class="ltx_ref" href="#bib.bib25" title="">2020</a>)</cite> 필드에 표현되는 세계의 7000개 이상의 언어 중 거의 남지 않는다. 이것은 다른 언어를 다루는 언어 모델의 능력에 차이를 만든다. 이전 연구 결과에 따르면 LLM은 특히 자원이 낮은 언어<cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al. <a class="ltx_ref" href="#bib.bib31" title="">2023</a>; Zhu et al. <a class="ltx_ref" href="#bib.bib54" title="">2023</a>; Huang et al. <a class="ltx_ref" href="#bib.bib20" title="">2023a</a>)</cite>에서 비영어 텍스트를 이해하고 생성하는 데 어려움이 있다. 자원 격차를 해결하기 위해 연구자와 실무자에 의해 몇 가지 솔루션이 제안되거나 구현되었다. 하나의 가능한 해결책은 다양한 언어 및 필드로부터 이용가능한 데이터의 양을 증가시키고, LLMs <cite class="ltx_cite ltx_citemacro_citep">(Lin et al. <a class="ltx_ref" href="#bib.bib30" title="">2022</a>; Chen et al. <a class="ltx_ref" href="#bib.bib6" title="">2022</a>; Cahyawijaya et al. <a class="ltx_ref" href="#bib.bib4" title="">2023</a>)</cite>를 사전 훈련하고 평가하기 위해 액세스 가능하게 하는 것이다. 그러나, 이 접근법은 상당한 계산 비용을 초래하고 자원 격차는 지속된다. 대안적으로, mBERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al. <a class="ltx_ref" href="#bib.bib14" title="">2019</a>)</cite> 및 XLM-R <cite class="ltx_cite ltx_citemacro_citep">(Conneau et al. <a class="ltx_ref" href="#bib.bib9" title="">2020a</a>)</cite>와 같이 동시에 상이한 언어로부터의 텍스트에 대해 트레이닝된 다국어 언어 모델은 갭을 효과적으로 해소하도록 도입되었다.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx6.SSx2">
<h3 class="ltx_title ltx_title_subsection">Cross-Lingual Transfer</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx6.SSx2.p1">
<p class="ltx_p" id="Sx6.SSx2.p1.1">다국어 언어 모델은 광범위한 작업 <cite class="ltx_cite ltx_citemacro_citep">(Wu and Dredze <a class="ltx_ref" href="#bib.bib49" title="">2019</a>; Pires, Schlinger, and Garrette <a class="ltx_ref" href="#bib.bib35" title="">2019</a>; Winata et al. <a class="ltx_ref" href="#bib.bib48" title="">2021b</a>)</cite>에 걸쳐 높은 수준의 제로 샷 또는 소수 샷 교차 언어 전달 가능성을 입증했다. 이는 한 언어의 지도 데이터에서 언어 능력을 습득하고 추가 훈련 데이터 없이 또는 거의 없이 다른 언어에 적용할 수 있음을 의미한다. 강한 교차 언어 성능의 이면에 있는 메커니즘은 연구자들에 의해 조사되었다. 다국어 언어 모델은 모든 언어 <cite class="ltx_cite ltx_citemacro_citep">(Artetxe, Ruder, and Yogatama <a class="ltx_ref" href="#bib.bib2" title="">2020</a>; Chi, Hewitt, and Manning <a class="ltx_ref" href="#bib.bib7" title="">2020</a>; Conneau et al. <a class="ltx_ref" href="#bib.bib10" title="">2020b</a>)</cite>에 적용 가능한 보편적인 규칙을 추론한 것으로 나타났다. mBERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al. <a class="ltx_ref" href="#bib.bib14" title="">2019</a>)</cite>와 같은 다언어 다언어 모델이 공유된 하위 단어 어휘에 의존한다는 일반적인 가설과 달리, 연구자들은 여러 언어에 걸쳐 공동 사전 훈련 <cite class="ltx_cite ltx_citemacro_citep">(Pires, Schlinger, and Garrette <a class="ltx_ref" href="#bib.bib35" title="">2019</a>; Cao, Kitaev, and Klein <a class="ltx_ref" href="#bib.bib5" title="">2020</a>; Wu and Dredze <a class="ltx_ref" href="#bib.bib49" title="">2019</a>)</cite>를 통해 모델에 대한 새로운 이해도를 개발했으며, 모델의 보편적 의미 추상화 학습 능력을 강조했다. 언어 간 성능에 영향을 미치는 요인 측면에서 연구자들은 매개변수 공유 <cite class="ltx_cite ltx_citemacro_citep">(Conneau et al. <a class="ltx_ref" href="#bib.bib10" title="">2020b</a>; Dufter and Schütze <a class="ltx_ref" href="#bib.bib16" title="">2020</a>; Wu, Papadimitriou, and Tamkin <a class="ltx_ref" href="#bib.bib50" title="">2022</a>)</cite> 및 언어 거리 <cite class="ltx_cite ltx_citemacro_citep">(Conneau et al. <a class="ltx_ref" href="#bib.bib10" title="">2020b</a>; Eronen, Ptaszynski, and Masui <a class="ltx_ref" href="#bib.bib17" title="">2023</a>)</cite>와 전이성을 연관시켰다. 우리는 여기에서 새로운 LLaMA 기반 실험을 통해 언어 모델의 언어 간 전달 가능성을 추가로 조사하여 다른 측면에서 결과를 제시한다.</p>
</div>
</section>
<section class="ltx_subsection" id="Sx6.SSx3">
<h3 class="ltx_title ltx_title_subsection">Code-Switching</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx6.SSx3.p1">
<p class="ltx_p" id="Sx6.SSx3.p1.1">코드 전환은 단일 발화 내에서 다국어 화자가 언어 간 전환을 하는 현상이다. 코드 전환 태스크에 대한 다국어 언어 모델의 성능에 대한 이전 연구는 혼합된 결과를 보여주었다. 일부 연구에서는 특정 코드 전환 시나리오에 대해 미세 조정된 사전 훈련된 모델이 영어-스페인어 및 영어-힌디 <cite class="ltx_cite ltx_citemacro_citep">(Khanuja et al. <a class="ltx_ref" href="#bib.bib27" title="">2020</a>)</cite>와 같은 특정 언어 쌍에 대해 최첨단 성능을 달성할 수 있다고 제안했으며 다른 연구에서는 메타 임베딩을 사용하면 더 적은 매개변수 <cite class="ltx_cite ltx_citemacro_citep">(Winata, Lin, and Fung <a class="ltx_ref" href="#bib.bib46" title="">2019</a>; Winata et al. <a class="ltx_ref" href="#bib.bib47" title="">2019</a>, <a class="ltx_ref" href="#bib.bib45" title="">2021a</a>)</cite>로 더 나은 결과를 얻을 수 있음을 발견했다. 또 다른 연구 라인에서, 코드 스위칭 기반 방법은 다국어 언어 모델 <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al. <a class="ltx_ref" href="#bib.bib24" title="">2020</a>; Tan and Joty <a class="ltx_ref" href="#bib.bib39" title="">2021</a>; Krishnan et al. <a class="ltx_ref" href="#bib.bib28" title="">2021</a>)</cite>의 능력을 향상시키기 위해 제시되었다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Sx7">
<h2 class="ltx_title ltx_title_section">Conclusions</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx7.p1">
<p class="ltx_p" id="Sx7.p1.1">본 논문에서는 언어 생성 및 명령어 수행 능력을 비영어 언어로 효과적으로 전달하는 방법에 초점을 맞춘다. 구체적으로 효과적인 전이를 위해 어휘 확장의 필요성과 필요한 훈련 척도를 분석하기 위한 포괄적인 실증 연구를 수행한다. 어휘 확장이 불필요하고 추가 사전 훈련 데이터의 <math alttext="1\%" class="ltx_Math" display="inline" id="Sx7.p1.1.m1.1"><semantics id="Sx7.p1.1.m1.1a"><mrow id="Sx7.p1.1.m1.1.1" xref="Sx7.p1.1.m1.1.1.cmml"><mn id="Sx7.p1.1.m1.1.1.2" xref="Sx7.p1.1.m1.1.1.2.cmml">1</mn><mo id="Sx7.p1.1.m1.1.1.1" xref="Sx7.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="Sx7.p1.1.m1.1b"><apply id="Sx7.p1.1.m1.1.1.cmml" xref="Sx7.p1.1.m1.1.1"><csymbol cd="latexml" id="Sx7.p1.1.m1.1.1.1.cmml" xref="Sx7.p1.1.m1.1.1.1">percent</csymbol><cn id="Sx7.p1.1.m1.1.1.2.cmml" type="integer" xref="Sx7.p1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx7.p1.1.m1.1c">1\%</annotation><annotation encoding="application/x-llamapun" id="Sx7.p1.1.m1.1d">1 %</annotation></semantics></math> 미만으로 최신 모델과 비교할 수 있는 전송 성능이 달성될 수 있음을 발견했다. 또한 전달 훈련 중 코드 전환 사례를 관찰하여 언어 간 정렬이 모델 내에서 내재화되었을 수 있음을 시사한다. 13개의 저자원 언어에 대한 확장 실험에서도 유사한 결과가 관찰된다. 우리의 분석 및 결과는 비영어 LLM 개발에 있어 커뮤니티에 대한 도움과 지침을 제공한다.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anil, R.; Dai, A.&nbsp;M.; Firat, O.; Johnson, M.; and Lepikhin, D. 2023.

</span>
<span class="ltx_bibblock">PaLM 2 Technical Report.

</span>
<span class="ltx_bibblock">arXiv:2305.10403.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Artetxe, Ruder, and Yogatama (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Artetxe, M.; Ruder, S.; and Yogatama, D. 2020.

</span>
<span class="ltx_bibblock">On the Cross-lingual Transferability of Monolingual Representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, 4623–4637. Online: Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bubeck et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bubeck, S.; Chandrasekaran, V.; Eldan, R.; Gehrke, J.; Horvitz, E.; Kamar, E.;
Lee, P.; Lee, Y.&nbsp;T.; Li, Y.; Lundberg, S.; Nori, H.; Palangi, H.; Ribeiro,
M.&nbsp;T.; and Zhang, Y. 2023.

</span>
<span class="ltx_bibblock">Sparks of Artificial General Intelligence: Early experiments with
GPT-4.

</span>
<span class="ltx_bibblock">arXiv:2303.12712.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cahyawijaya et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cahyawijaya, S.; Lovenia, H.; Aji, A.&nbsp;F.; Winata, G.&nbsp;I.; and Wilie, B. 2023.

</span>
<span class="ltx_bibblock">NusaCrowd: Open Source Initiative for Indonesian NLP Resources.

</span>
<span class="ltx_bibblock">arXiv:2212.09648.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao, Kitaev, and Klein (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cao, S.; Kitaev, N.; and Klein, D. 2020.

</span>
<span class="ltx_bibblock">Multilingual Alignment of Contextual Word Representations.

</span>
<span class="ltx_bibblock">arXiv:2002.03518.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chen, G.; Ma, S.; Chen, Y.; Zhang, D.; Pan, J.; Wang, W.; and Wei, F. 2022.

</span>
<span class="ltx_bibblock">Towards Making the Most of Multilingual Pretraining for Zero-Shot
Neural Machine Translation.

</span>
<span class="ltx_bibblock">arXiv:2110.08547.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chi, Hewitt, and Manning (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chi, E.&nbsp;A.; Hewitt, J.; and Manning, C.&nbsp;D. 2020.

</span>
<span class="ltx_bibblock">Finding Universal Grammatical Relations in Multilingual BERT.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, 5564–5577. Online: Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cobbe, K.; Kosaraju, V.; Bavarian, M.; Hilton, J.; Nakano, R.; Hesse, C.; and
Schulman, J. 2021.

</span>
<span class="ltx_bibblock">Training Verifiers to Solve Math Word Problems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">CoRR</em>, abs/2110.14168.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et&nbsp;al. (2020a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Conneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V.; Wenzek, G.; Guzmán, F.;
Grave, E.; Ott, M.; Zettlemoyer, L.; and Stoyanov, V. 2020a.

</span>
<span class="ltx_bibblock">Unsupervised Cross-lingual Representation Learning at Scale.

</span>
<span class="ltx_bibblock">arXiv:1911.02116.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et&nbsp;al. (2020b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Conneau, A.; Wu, S.; Li, H.; Zettlemoyer, L.; and Stoyanov, V.
2020b.

</span>
<span class="ltx_bibblock">Emerging Cross-lingual Structure in Pretrained Language Models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, 6022–6034. Online: Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conover et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Conover, M.; Hayes, M.; Mathur, A.; Xie, J.; Wan, J.; Shah, S.; Ghodsi, A.;
Wendell, P.; Zaharia, M.; and Xin, R. 2023.

</span>
<span class="ltx_bibblock">Free Dolly: Introducing the World’s First Truly Open
Instruction-Tuned LLM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui, Yang, and Yao (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cui, Y.; Yang, Z.; and Yao, X. 2023a.

</span>
<span class="ltx_bibblock">Chinese LLaMA and Alpaca Large Language Models.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui, Yang, and Yao (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cui, Y.; Yang, Z.; and Yao, X. 2023b.

</span>
<span class="ltx_bibblock">Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca.

</span>
<span class="ltx_bibblock">arXiv:2304.08177.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language
Understanding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, 4171–4186. Minneapolis,
Minnesota: Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dong, Q.; Li, L.; Dai, D.; Zheng, C.; Wu, Z.; Chang, B.; Sun, X.; Xu, J.; Li,
L.; and Sui, Z. 2023.

</span>
<span class="ltx_bibblock">A Survey on In-context Learning.

</span>
<span class="ltx_bibblock">arXiv:2301.00234.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dufter and Schütze (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dufter, P.; and Schütze, H. 2020.

</span>
<span class="ltx_bibblock">Identifying Elements Essential for BERT’s Multilinguality.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, 4423–4437. Online: Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eronen, Ptaszynski, and Masui (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Eronen, J.; Ptaszynski, M.; and Masui, F. 2023.

</span>
<span class="ltx_bibblock">Zero-shot cross-lingual transfer language selection using linguistic
similarity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Information Processing &amp; Management</em>, 60(3): 103250.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hendrycks, D.; Burns, C.; Basart, S.; Zou, A.; Mazeika, M.; Song, D.; and
Steinhardt, J. 2020.

</span>
<span class="ltx_bibblock">Measuring Massive Multitask Language Understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">CoRR</em>, abs/2009.03300.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hu, E.&nbsp;J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; and Chen,
W. 2021.

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">CoRR</em>, abs/2106.09685.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Huang, H.; Tang, T.; Zhang, D.; Zhao, W.&nbsp;X.; Song, T.; Xia, Y.; and Wei, F.
2023a.

</span>
<span class="ltx_bibblock">Not All Languages Are Created Equal in LLMs: Improving Multilingual
Capability by Cross-Lingual-Thought Prompting.

</span>
<span class="ltx_bibblock">arXiv:2305.07004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Huang, W.; Abbeel, P.; Pathak, D.; and Mordatch, I. 2022.

</span>
<span class="ltx_bibblock">Language Models as Zero-Shot Planners: Extracting Actionable
Knowledge for Embodied Agents.

</span>
<span class="ltx_bibblock">In Chaudhuri, K.; Jegelka, S.; Song, L.; Szepesvari, C.; Niu, G.; and
Sabato, S., eds., <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the 39th International Conference on
Machine Learning</em>, volume 162 of <em class="ltx_emph ltx_font_italic" id="bib.bib21.2.2">Proceedings of Machine Learning
Research</em>, 9118–9147. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Huang, Y.; Bai, Y.; Zhu, Z.; Zhang, J.; and Zhang, J. 2023b.

</span>
<span class="ltx_bibblock">C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for
Foundation Models.

</span>
<span class="ltx_bibblock">arXiv:2305.08322.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ji, Y.; Deng, Y.; Gong, Y.; Peng, Y.; Niu, Q.; Ma, B.; and Li, X. 2023.

</span>
<span class="ltx_bibblock">BELLE: Be Everyone’s Large Language model Engine.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url" href="https://github.com/LianjiaTech/BELLE" title="">https://github.com/LianjiaTech/BELLE</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiang, Z.; Anastasopoulos, A.; Araki, J.; Ding, H.; and Neubig, G. 2020.

</span>
<span class="ltx_bibblock">X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained
Language Models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, 5943–5959. Online: Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joshi, P.; Santy, S.; Budhiraja, A.; Bali, K.; and Choudhury, M. 2020.

</span>
<span class="ltx_bibblock">The State and Fate of Linguistic Diversity and Inclusion in the NLP
World.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, 6282–6293. Online: Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katz et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Katz, D.&nbsp;M.; Bommarito, M.&nbsp;J.; Gao, S.; and Arredondo, P. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 passes the bar exam.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Available at SSRN 4389233</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khanuja et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Khanuja, S.; Dandapat, S.; Srinivasan, A.; Sitaram, S.; and Choudhury, M. 2020.

</span>
<span class="ltx_bibblock">GLUECoS: An Evaluation Benchmark for Code-Switched NLP.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, 3575–3585. Online: Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishnan et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Krishnan, J.; Anastasopoulos, A.; Purohit, H.; and Rangwala, H. 2021.

</span>
<span class="ltx_bibblock">Multilingual Code-Switching for Zero-Shot Cross-Lingual Intent
Prediction and Slot Filling.

</span>
<span class="ltx_bibblock">arXiv:2103.07792.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Li, H.; Koto, F.; Wu, M.; Aji, A.&nbsp;F.; and Baldwin, T. 2023.

</span>
<span class="ltx_bibblock">Bactrian-X : A Multilingual Replicable Instruction-Following Model
with Low-Rank Adaptation.

</span>
<span class="ltx_bibblock">arXiv:2305.15011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lin, X.&nbsp;V.; Mihaylov, T.; Artetxe, M.; Wang, T.; Chen, S.; Simig, D.; Ott, M.;
Goyal, N.; Bhosale, S.; Du, J.; Pasunuru, R.; Shleifer, S.; Koura, P.&nbsp;S.;
Chaudhary, V.; O’Horo, B.; Wang, J.; Zettlemoyer, L.; Kozareva, Z.; Diab, M.;
Stoyanov, V.; and Li, X. 2022.

</span>
<span class="ltx_bibblock">Few-shot Learning with Multilingual Language Models.

</span>
<span class="ltx_bibblock">arXiv:2112.10668.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nguyen, X.-P.; Aljunied, S.&nbsp;M.; Joty, S.; and Bing, L. 2023.

</span>
<span class="ltx_bibblock">Democratizing LLMs for Low-Resource Languages by Leveraging their
English Dominant Abilities with Linguistically-Diverse Prompts.

</span>
<span class="ltx_bibblock">arXiv:2306.11372.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI. 2022.

</span>
<span class="ltx_bibblock">Introducing ChatGPT.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenLMLab (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenLMLab. 2023.

</span>
<span class="ltx_bibblock">Open-Chinese-LLaMA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Penedo et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Penedo, G.; Malartic, Q.; Hesslow, D.; Cojocaru, R.; Cappelli, A.; Alobeidli,
H.; Pannier, B.; Almazrouei, E.; and Launay, J. 2023.

</span>
<span class="ltx_bibblock">The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora
with Web Data, and Web Data Only.

</span>
<span class="ltx_bibblock">arXiv:2306.01116.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pires, Schlinger, and Garrette (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pires, T.; Schlinger, E.; and Garrette, D. 2019.

</span>
<span class="ltx_bibblock">How Multilingual is Multilingual BERT?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, 4996–5001. Florence, Italy: Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranta and Goutte (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ranta, A.; and Goutte, C. 2021.

</span>
<span class="ltx_bibblock">Linguistic Diversity in Natural Language Processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Traitement Automatique des Langues</em>, 62(3): 7–11.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Scao, T.&nbsp;L.; Fan, A.; Akiki, C.; Pavlick, E.; Ilić, S.; Hesslow, D.; and
Castagné, R. 2023.

</span>
<span class="ltx_bibblock">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model.

</span>
<span class="ltx_bibblock">arXiv:2211.05100.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">StabilityAI (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
StabilityAI. 2023.

</span>
<span class="ltx_bibblock">Announcing StableCode.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan and Joty (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tan, S.; and Joty, S. 2021.

</span>
<span class="ltx_bibblock">Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots.

</span>
<span class="ltx_bibblock">arXiv:2103.09593.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Taori, R.; Gulrajani, I.; Zhang, T.; Dubois, Y.; Li, X.; Guestrin, C.; Liang,
P.; and Hashimoto, T.&nbsp;B. 2023.

</span>
<span class="ltx_bibblock">Alpaca: A Strong, Replicable Instruction-Following Model.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Team, I. 2023a.

</span>
<span class="ltx_bibblock">Internlm: A multilingual language model with progressively enhanced
capabilities.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Team, I. 2023b.

</span>
<span class="ltx_bibblock">InternLM: A Multilingual Language Model with Progressively Enhanced
Capabilities.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url" href="https://github.com/InternLM/InternLM-techreport" title="">https://github.com/InternLM/InternLM-techreport</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux, M.-A.; Lacroix,
T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F.; Rodriguez, A.; Joulin,
A.; Grave, E.; and Lample, G. 2023a.

</span>
<span class="ltx_bibblock">LLaMA: Open and Efficient Foundation Language Models.

</span>
<span class="ltx_bibblock">arXiv:2302.13971.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Touvron, H.; Martin, L.; Stone, K.; Albert, P.; and Almahairi, A.
2023b.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models.

</span>
<span class="ltx_bibblock">arXiv:2307.09288.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Winata et&nbsp;al. (2021a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Winata, G.&nbsp;I.; Cahyawijaya, S.; Liu, Z.; Lin, Z.; Madotto, A.; and Fung, P.
2021a.

</span>
<span class="ltx_bibblock">Are Multilingual Models Effective in Code-Switching?

</span>
<span class="ltx_bibblock">arXiv:2103.13309.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Winata, Lin, and Fung (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Winata, G.&nbsp;I.; Lin, Z.; and Fung, P. 2019.

</span>
<span class="ltx_bibblock">Learning Multilingual Meta-Embeddings for Code-Switching Named Entity
Recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the 4th Workshop on Representation Learning
for NLP (RepL4NLP-2019)</em>, 181–186. Florence, Italy: Association for
Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Winata et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Winata, G.&nbsp;I.; Lin, Z.; Shin, J.; Liu, Z.; and Fung, P. 2019.

</span>
<span class="ltx_bibblock">Hierarchical Meta-Embeddings for Code-Switching Named Entity
Recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, 3541–3547. Hong Kong, China:
Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Winata et&nbsp;al. (2021b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Winata, G.&nbsp;I.; Madotto, A.; Lin, Z.; Liu, R.; Yosinski, J.; and Fung, P.
2021b.

</span>
<span class="ltx_bibblock">Language Models are Few-shot Multilingual Learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Proceedings of the 1st Workshop on Multilingual
Representation Learning</em>, 1–15. Punta Cana, Dominican Republic: Association
for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu and Dredze (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wu, S.; and Dredze, M. 2019.

</span>
<span class="ltx_bibblock">Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of
BERT.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, 833–844. Hong Kong, China:
Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu, Papadimitriou, and Tamkin (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wu, Z.; Papadimitriou, I.; and Tamkin, A. 2022.

</span>
<span class="ltx_bibblock">Oolong: Investigating What Makes Crosslingual Transfer Hard with
Controlled Studies.

</span>
<span class="ltx_bibblock">arXiv:2202.12312.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhang, M.; Zhang, Q.; Zhang, Y.; and Gui, T. 2023a.

</span>
<span class="ltx_bibblock">LLMEVAL-1 Chinese Large Language Model Evaluation Phase 1.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhang, X.; Li, C.; Zong, Y.; Ying, Z.; He, L.; and Qiu, X. 2023b.

</span>
<span class="ltx_bibblock">Evaluating the Performance of Large Language Models on GAOKAO
Benchmark.

</span>
<span class="ltx_bibblock">arXiv:2305.12474.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhong, W.; Cui, R.; Guo, Y.; Liang, Y.; Lu, S.; Wang, Y.; Saied, A.; Chen, W.;
and Duan, N. 2023.

</span>
<span class="ltx_bibblock">AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models.

</span>
<span class="ltx_bibblock">arXiv:2304.06364.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhu, W.; Liu, H.; Dong, Q.; Xu, J.; Huang, S.; Kong, L.; Chen, J.; and Li, L.
2023.

</span>
<span class="ltx_bibblock">Multilingual Machine Translation with Large Language Models:
Empirical Results and Analysis.

</span>
<span class="ltx_bibblock">arXiv:2304.04675.

</span>
</li>
</ul>
</section>
<section class="ltx_section" id="Sx8">
<h2 class="ltx_title ltx_title_section">Appendix</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx8.p1">
<p class="ltx_p" id="Sx8.p1.1"><span class="ltx_text ltx_font_bold" id="Sx8.p1.1.1">The prompt for LLM-Eval</span></p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p2">
<p class="ltx_p" id="Sx8.p2.1">특정 교과와 관련된 질문의 경우 0/1/2/3의 척도를 사용하여 다음 LLM 산출물의 점수를 매긴다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p3">
<p class="ltx_p" id="Sx8.p3.1">정확성: 정답이 정확하고 정확한지 정확한 정보로 평가합니다. 질 높은 답은 사실적으로 신뢰할 수 있어야 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p4">
<p class="ltx_p" id="Sx8.p4.1">유창성: 일관된 표현과 명확한 표현으로 해답이 인간의 언어 관습을 얼마나 잘 준수하는지 평가하라. 질 높은 답은 복잡한 문장이나 구문이 어려운 문장 없이 이해하기 쉬워야 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p5">
<p class="ltx_p" id="Sx8.p5.1">정보성: 답이 실용적인 가치의 충분한 관련 정보를 제공하는지를 판단한다. 질 높은 답변은 질문자에게 유용하고 적절한 정보를 제공해야 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p6">
<p class="ltx_p" id="Sx8.p6.1">논리성: 논점과 논증을 제시함에 있어 답이 논리적으로 타당하고 정확한지를 검토한다. 질 높은 답은 논리적인 원리를 따라야 하며, 명확한 추론과 일관성을 입증해야 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p7">
<p class="ltx_p" id="Sx8.p7.1">무해성: 대답이 윤리적 규범을 준수하면서 비윤리적 또는 유해한 내용을 회피하는지 여부를 평가한다. 질 높은 답변은 유해하거나 비도덕적인 정보의 전파를 피하면서 윤리 원칙을 지켜야 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p8">
<p class="ltx_p" id="Sx8.p8.1">참고: 모형이 응답을 제공하지 않는 경우 "무해"를 제외한 모든 점수는 0이어야 합니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p9">
<p class="ltx_p" id="Sx8.p9.1">질문은: 질문 LLM 응답은: 응답</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p10">
<p class="ltx_p" id="Sx8.p10.1">이 질문에 대한 참조 답변은 다음과 같습니다. 참조 답변</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p11">
<p class="ltx_p" id="Sx8.p11.1">LLM 응답의 "정확성", "유창성", "정보성", "논리성" 및 "무해성"에 대해 0/1/2/3 척도로 인식된 점수를 할당하고 다음 형식으로 답변을 제공하십시오.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p12">
<p class="ltx_p" id="Sx8.p12.1">"정확도" : LLM 반응의 정확도(정수)에 대한 점수,</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p13">
<p class="ltx_p" id="Sx8.p13.1">“유창성” : LLM 응답의 유창성(정수)에 대한 점수</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p14">
<p class="ltx_p" id="Sx8.p14.1">"정보성" : LLM 반응의 정보성(정수)에 대한 점수</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p15">
<p class="ltx_p" id="Sx8.p15.1">"논리성" : LLM 반응의 논리성(정수)에 대한 점수,</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx8.p16">
<p class="ltx_p" id="Sx8.p16.1">"무해함" : LLM 반응의 무해함(정수)에 대한 점수.</p>
</div>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>