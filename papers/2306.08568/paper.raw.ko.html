<html lang="en"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>WizardCoder: Empowering Code Large Language Models with Evol-Instruct</title>
<!--Generated on Thu Jul 13 18:39:44 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="css/ar5iv.min.css" rel="stylesheet" type="text/css">
<link crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" rel="stylesheet">
<script crossorigin="anonymous" integrity="sha384-geWF76RCwLtnZ8qwWowPQNguL3RmwHVBC9FhGdlKrxdiJJigb/j/68SIy3Te4Bkz" src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script defer="" src="https://services.dev.arxiv.org/html/addons.js"></script>
<script defer="" src="https://services.dev.arxiv.org/html/feedbackOverlay.js"></script>
<link href="https://services.dev.arxiv.org/html/styles.css" rel="stylesheet" type="text/css"></head>
<body>
<div class="ltx_page_main" id="main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_ERROR undefined" id="id1">\newtcolorbox</span>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">boxEnv colback=mythmback,coltitle=blue,colframe=mythmback,center, width=boxrule=0.5pt, left=5pt,right=0pt, top=2pt,bottom=2pt, before skip=10pt, after skip=10pt</p>
</div>
<h1 class="ltx_title ltx_title_document">
<em class="ltx_emph ltx_font_italic" id="id13.id1">WizardCoder</em>: Empowering Code Large Language Models with Evol-Instruct</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">  Ziyang Luo<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><msup id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1a" xref="id1.1.m1.1.1.cmml"></mi><mn id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><cn id="id1.1.m1.1.1.1.cmml" type="integer" xref="id1.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>  Can Xu<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><msup id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mi id="id2.2.m2.1.1a" xref="id2.2.m2.1.1.cmml"></mi><mn id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><cn id="id2.2.m2.1.1.1.cmml" type="integer" xref="id2.2.m2.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>  Pu Zhao<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id3.3.m3.1"><semantics id="id3.3.m3.1a"><msup id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml"><mi id="id3.3.m3.1.1a" xref="id3.3.m3.1.1.cmml"></mi><mn id="id3.3.m3.1.1.1" xref="id3.3.m3.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><apply id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"><cn id="id3.3.m3.1.1.1.cmml" type="integer" xref="id3.3.m3.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>  Qingfeng Sun<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id4.4.m4.1"><semantics id="id4.4.m4.1a"><msup id="id4.4.m4.1.1" xref="id4.4.m4.1.1.cmml"><mi id="id4.4.m4.1.1a" xref="id4.4.m4.1.1.cmml"></mi><mn id="id4.4.m4.1.1.1" xref="id4.4.m4.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id4.4.m4.1b"><apply id="id4.4.m4.1.1.cmml" xref="id4.4.m4.1.1"><cn id="id4.4.m4.1.1.1.cmml" type="integer" xref="id4.4.m4.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.4.m4.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id4.4.m4.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>  Xiubo Geng<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id5.5.m5.1"><semantics id="id5.5.m5.1a"><msup id="id5.5.m5.1.1" xref="id5.5.m5.1.1.cmml"><mi id="id5.5.m5.1.1a" xref="id5.5.m5.1.1.cmml"></mi><mn id="id5.5.m5.1.1.1" xref="id5.5.m5.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id5.5.m5.1b"><apply id="id5.5.m5.1.1.cmml" xref="id5.5.m5.1.1"><cn id="id5.5.m5.1.1.1.cmml" type="integer" xref="id5.5.m5.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id5.5.m5.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id5.5.m5.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="id6.6.1">Wenxiang Hu<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id6.6.1.m1.1"><semantics id="id6.6.1.m1.1a"><msup id="id6.6.1.m1.1.1" xref="id6.6.1.m1.1.1.cmml"><mi id="id6.6.1.m1.1.1a" xref="id6.6.1.m1.1.1.cmml"></mi><mn id="id6.6.1.m1.1.1.1" mathvariant="normal" xref="id6.6.1.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id6.6.1.m1.1b"><apply id="id6.6.1.m1.1.1.cmml" xref="id6.6.1.m1.1.1"><cn id="id6.6.1.m1.1.1.1.cmml" type="integer" xref="id6.6.1.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.6.1.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id6.6.1.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id7.7.2">Chongyang Tao<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id7.7.2.m1.1"><semantics id="id7.7.2.m1.1a"><msup id="id7.7.2.m1.1.1" xref="id7.7.2.m1.1.1.cmml"><mi id="id7.7.2.m1.1.1a" xref="id7.7.2.m1.1.1.cmml"></mi><mn id="id7.7.2.m1.1.1.1" mathvariant="normal" xref="id7.7.2.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id7.7.2.m1.1b"><apply id="id7.7.2.m1.1.1.cmml" xref="id7.7.2.m1.1.1"><cn id="id7.7.2.m1.1.1.1.cmml" type="integer" xref="id7.7.2.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id7.7.2.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id7.7.2.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id8.8.3">Jing Ma<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id8.8.3.m1.1"><semantics id="id8.8.3.m1.1a"><msup id="id8.8.3.m1.1.1" xref="id8.8.3.m1.1.1.cmml"><mi id="id8.8.3.m1.1.1a" xref="id8.8.3.m1.1.1.cmml"></mi><mn id="id8.8.3.m1.1.1.1" mathvariant="normal" xref="id8.8.3.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id8.8.3.m1.1b"><apply id="id8.8.3.m1.1.1.cmml" xref="id8.8.3.m1.1.1"><cn id="id8.8.3.m1.1.1.1.cmml" type="integer" xref="id8.8.3.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id8.8.3.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id8.8.3.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id9.9.4">Qingwei Lin<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id9.9.4.m1.1"><semantics id="id9.9.4.m1.1a"><msup id="id9.9.4.m1.1.1" xref="id9.9.4.m1.1.1.cmml"><mi id="id9.9.4.m1.1.1a" xref="id9.9.4.m1.1.1.cmml"></mi><mn id="id9.9.4.m1.1.1.1" mathvariant="normal" xref="id9.9.4.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id9.9.4.m1.1b"><apply id="id9.9.4.m1.1.1.cmml" xref="id9.9.4.m1.1.1"><cn id="id9.9.4.m1.1.1.1.cmml" type="integer" xref="id9.9.4.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.9.4.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id9.9.4.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id11.11.6">Daxin Jiang<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id10.10.5.m1.1"><semantics id="id10.10.5.m1.1a"><msup id="id10.10.5.m1.1.1" xref="id10.10.5.m1.1.1.cmml"><mi id="id10.10.5.m1.1.1a" xref="id10.10.5.m1.1.1.cmml"></mi><mn id="id10.10.5.m1.1.1.1" mathvariant="normal" xref="id10.10.5.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id10.10.5.m1.1b"><apply id="id10.10.5.m1.1.1.cmml" xref="id10.10.5.m1.1.1"><cn id="id10.10.5.m1.1.1.1.cmml" type="integer" xref="id10.10.5.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id10.10.5.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id10.10.5.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break"><math alttext="{}^{1}" class="ltx_Math" display="inline" id="id11.11.6.m2.1"><semantics id="id11.11.6.m2.1a"><msup id="id11.11.6.m2.1.1" xref="id11.11.6.m2.1.1.cmml"><mi id="id11.11.6.m2.1.1a" xref="id11.11.6.m2.1.1.cmml"></mi><mn id="id11.11.6.m2.1.1.1" mathvariant="normal" xref="id11.11.6.m2.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id11.11.6.m2.1b"><apply id="id11.11.6.m2.1.1.cmml" xref="id11.11.6.m2.1.1"><cn id="id11.11.6.m2.1.1.1.cmml" type="integer" xref="id11.11.6.m2.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id11.11.6.m2.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id11.11.6.m2.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>Microsoft
<br class="ltx_break"><math alttext="{}^{2}" class="ltx_Math" display="inline" id="id12.12.m6.1"><semantics id="id12.12.m6.1a"><msup id="id12.12.m6.1.1" xref="id12.12.m6.1.1.cmml"><mi id="id12.12.m6.1.1a" xref="id12.12.m6.1.1.cmml"></mi><mn id="id12.12.m6.1.1.1" xref="id12.12.m6.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id12.12.m6.1b"><apply id="id12.12.m6.1.1.cmml" xref="id12.12.m6.1.1"><cn id="id12.12.m6.1.1.1.cmml" type="integer" xref="id12.12.m6.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id12.12.m6.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id12.12.m6.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>Hong Kong Baptist University 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id14.13.id1">{caxu,puzhao,qins,xigeng,wenxh,chongyang.tao,qlin,djiang}@microsoft.com
<br class="ltx_break">{cszyluo, majing}@comp.hkbu.edu.hk</span>
</span><span class="ltx_author_notes"> Equal contribution. Work done during the internship at Microsoft. Corresponding author.
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id15.id1">StarCoder와 같은 코드 대용량 언어 모델(Code LLMs)은 코드 관련 작업에서 탁월한 성능을 보여주었다. 그러나 대부분의 기존 모델은 명령어 미세 조정 없이 광범위한 원시 코드 데이터에 대해서만 사전 훈련된다. 본 논문에서는 <em class="ltx_emph ltx_font_italic" id="id15.id1.1">WizardCoder</em> 메서드를 코드 도메인에 적용하여 복잡한 명령어 미세 조정을 통해 Code LLMs에 권한을 부여하는 <em class="ltx_emph ltx_font_italic" id="id15.id1.2">Evol-Instruct</em> 메서드를 소개한다. 4개의 주요 코드 생성 벤치마크인 HumanEval, HumanEval+, MBPP 및 DS-1000에 대한 포괄적인 실험을 통해 모델의 탁월한 성능을 공개합니다. 다른 모든 오픈 소스 코드 LLM을 상당한 차이로 능가합니다. 게다가, 우리의 모델은 휴먼에벌과 휴먼에벌+에서 가장 큰 폐쇄형 LLM인 앤트로픽의 클로드와 구글의 바드를 능가한다. 코드, 모델 가중치 및 데이터는 <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/nlpxucan/WizardLM" title="">https://github.com/nlpxucan/WizardLM</a>에서 공개됩니다.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">최근 LLM(Large Language Models) <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">GPT3</span> </a>; <a class="ltx_ref" href="#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">GPT4</span> </a>; <a class="ltx_ref" href="#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">PaLM</span> </a>; <a class="ltx_ref" href="#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">palm2</span> </a>; <a class="ltx_ref" href="#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">Chinchilla</span> </a>; <a class="ltx_ref" href="#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">gopher</span> </a>; <a class="ltx_ref" href="#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">GLM-130B</span> </a>; <a class="ltx_ref" href="#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">llama</span> </a>; <a class="ltx_ref" href="#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">opt</span> </a></cite>가 큰 주목을 받으며 인상적인 성공을 거두었다. 특히 OpenAI의 ChatGPT가 두드러진 사례로 눈에 띈다. 광범위한 양의 인터넷 데이터에 대한 광범위한 사전 교육을 활용하고 상세한 명령 데이터 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">DBLP:conf/nips/Ouyang0JAWMZASR22</span> </a></cite>로 추가 미세 조정을 통해 이러한 모델은 다양한 작업에 걸쳐 최첨단(SOTA) 제로 샷 성능을 달성했다. 이러한 경향은 코드 이해와 생성의 영역에서도 관찰된다. 코드 관련 작업과 관련된 문제를 해결하기 위해 수많은 코드 LLMs<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">li2023starcoder</span> </a>; <a class="ltx_ref" href="#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">AlphaCode</span> </a>; <a class="ltx_ref" href="#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">codegen</span> </a>; <a class="ltx_ref" href="#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">CodeGeeX</span> </a>; <a class="ltx_ref" href="#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">incoder</span> </a>; <a class="ltx_ref" href="#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">codex</span> </a>; <a class="ltx_ref" href="#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">codet5</span> </a>; <a class="ltx_ref" href="#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">CodeT5+</span> </a></cite>가 제안되었다. 이러한 코드 LLM은 상당한 양의 코드 데이터를 사용하여 사전 훈련을 거쳐 다양한 코드 관련 작업을 탁월하게 수행할 수 있어 인상적인 성능을 보여줍니다.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">사전 훈련 과정을 주로 강조하는 대부분의 이전 코드 LLM과 달리 코드 도메인에서 세밀한 명령어 튜닝에 대한 탐색은 제한적이었다. 명령어 튜닝의 도입은 처음에 다른 태스크들 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">t5</span> </a>; <a class="ltx_ref" href="#bib.bib20" title=""><span class="ltx_text" style="font-size:90%;">DBLP:conf/iclr/WeiBZGYLDDL22</span> </a>; <a class="ltx_ref" href="#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">flan-t5</span> </a>; <a class="ltx_ref" href="#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">ExT5</span> </a>; <a class="ltx_ref" href="#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">T0</span> </a>; <a class="ltx_ref" href="#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">ZeroPrompt</span> </a>; <a class="ltx_ref" href="#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">UnifiedQA</span> </a></cite>에 걸쳐 LM의 일반화 능력을 향상시키는 것을 목표로 했다. 예를 들어 OpenAI의 InstructGPT <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">DBLP:conf/nips/Ouyang0JAWMZASR22</span> </a></cite>는 사용자의 의도와 정렬을 보장하기 위해 명시적인 지침을 제공하기 위해 인간 주석자를 요청하는 것을 포함했다. 이와 유사하게 Alpaca <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">alpaca</span> </a></cite>와 같은 최근 연구에서는 ChatGPT가 명령어 데이터를 생성하는 self-instruct <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">wang2022self</span> </a></cite> 방법을 사용하였다. Vicuna <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">vicuna2023</span> </a></cite>는 ShareGPT.com에서 수집된 사용자 공유 대화를 활용했다. WizardLM <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">xu2023wizardlm</span> </a></cite>는 <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">Evol-Instruct</em> 메소드를 도입했는데, 이 메소드는 더 복잡하고 다양한 데이터 세트를 생성하기 위해 기존 명령 데이터를 진화시키는 것을 포함했다. 그러나 이러한 모든 접근법은 주로 일반 도메인에 초점을 맞추고 코드 도메인에 대한 구체적인 설계 고려 사항이 부족하다는 점에 주목할 필요가 있다.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">Evol-Instruct</em> 방법에 의해 동기화된 본 연구는 코드별 <em class="ltx_emph ltx_font_italic" id="S1.p3.1.2">Evol-Instruct</em>을 통해 복잡한 코드 명령어 데이터를 생성함으로써 SOTA 오픈 소스 Code LLM, StarCoder <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">li2023starcoder</span> </a></cite>의 성능을 향상시키는 것을 목표로 한다. 이를 위해 코드 관련 작업을 위해 특별히 조정된 진화적 프롬프트 프로세스에 몇 가지 적응을 수행했다. 이러한 수정은 진화 명령어를 정제하는 것, 진화 프롬프트의 형태를 단순화하는 것, 코드 디버깅 및 시공간 복잡성 제약들을 통합하는 것을 포함한다. 초기에는 기본 코드 명령 데이터인 Code Alpaca<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib30" title=""><span class="ltx_text" style="font-size:90%;">codealpaca</span> </a></cite>를 진화시키기 위해 이 방법을 적용하였다. 그런 다음 새로 만든 코드 명령어 추적 훈련 세트를 사용하여 StarCoder의 미세 조정을 수행하고 <em class="ltx_emph ltx_font_italic" id="S1.p3.1.3">WizardCoder</em>을 얻는다.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">4개의 코드 생성 벤치마크(HumanEval <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">humeval</span> </a></cite>, HumanEval+ <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">humanevalp</span> </a></cite>, MBPP <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">MBPP</span> </a></cite>, DS-100 <cite idx=3></cite)로부터 얻은 실험 결과는 우리의 <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">WizardCoder</em>이 다른 모든 오픈 소스 코드 LLMs보다 우수한 성능을 보여 SOTA(state-of-the-art) 성능을 달성했음을 보여준다. 특히, +22.3(57.3 vs. 35.0)의 증가로 패스@1 점수의 상당한 개선을 관찰한다. In HumanEval and +8.2 (51.8 vs. 43.6) (p<0.05). 놀랍게도, 훨씬 작은 크기에도 불구하고, 우리의 <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">WizardCoder</em>은 HumanEval과 HumanEval+의 합격률 면에서 Anthropic의 Claude와 Google의 Bard를 능가한다.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">이 작품의 공헌은 다음과 같이 요약할 수 있다.</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">우리는 Code <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.1">WizardCoder</em>의 적용을 통해 오픈 소스 Code LLM인 StarCoder의 성능을 향상시키는 <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.2">Evol-Instruct</em>을 소개한다.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><em class="ltx_emph ltx_font_italic" id="S1.I1.i2.p1.1.1">WizardCoder</em>은 StarCoder, CodeGen, CodeGee, CodeT5+, InstructCodeT5+, StarCoder-GPTeacher 및 Instruct-Codegen-16B를 포함하여 코드 생성 측면에서 상당한 마진만큼 다른 모든 오픈 소스 Code LLMs를 능가합니다.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><em class="ltx_emph ltx_font_italic" id="S1.I1.i3.p1.1.1">WizardCoder</em>은 크기가 상당히 작음에도 불구하고 Claude, Bard, PaLM, PaLM-2 및 LaMDA와 같은 가장 큰 폐쇄 소스 LLM과 비교하여 코드 생성에서 우수한 결과를 달성한다.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Large Language Models.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Recently, LLMs have demonstrated remarkable achievements across a broad spectrum of tasks. Prominent tech companies have made significant strides in developing highly proficient LLMs. These include OpenAI’s GPT3&amp;4 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">GPT3</span> </a>; <a class="ltx_ref" href="#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">GPT4</span> </a></cite>, Google’s PaLM <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">PaLM</span> </a>; <a class="ltx_ref" href="#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">palm2</span> </a></cite>, and Bard<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bard.google.com/" title="">https://bard.google.com/</a></span></span></span>, DeepMind’s Chinchilla <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">Chinchilla</span> </a></cite>, and Gopher <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">gopher</span> </a></cite>, as well as Anthropic’s Claude<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/index/introducing-claude" title="">https://www.anthropic.com/index/introducing-claude</a></span></span></span>. However, it is important to note that these models are closed-source and can only be accessed through specific APIs or may not be accessible at all.</p>최근 LLM은 광범위한 작업에서 놀라운 성과를 보여주었다. 저명한 기술 회사들은 매우 능숙한 LLM을 개발하는 데 상당한 진전을 이루었다. OpenAI의 GPT3&4<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">GPT3</span> </a>; <a class="ltx_ref" href="#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">GPT4</span> </a></cite>, 구글의 PaLM<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">PaLM</span> </a>; <a class="ltx_ref" href="#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">palm2</span> </a></cite>, Bard<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bard.google.com/" title="">https://bard.google.com/</a></span></span></span>, DeepMind의 Chinchilla<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">Chinchilla</span> </a></cite>, 고퍼<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">gopher</span> </a></cite>, Anthropic의 Claude<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/index/introducing-claude" title="">https://www.anthropic.com/index/introducing-claude</a></span></span></span> 등이 그것이다. 그러나 이러한 모델은 폐쇄 소스이며 특정 API를 통해서만 액세스할 수 있거나 전혀 액세스할 수 없을 수 있다는 점에 유의하는 것이 중요합니다.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">AI 커뮤니티는 모델 가중치가 공개적으로 공개되는 여러 오픈 소스 LLM이 출시되는 것을 목격했다. EleutherAI는 GPT-NeoX-20B <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib35" title=""><span class="ltx_text" style="font-size:90%;">GPT-NeoX-20B</span> </a></cite>와 GPT-J-6B <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib36" title=""><span class="ltx_text" style="font-size:90%;">gpt-j</span> </a></cite>에 기여했다. 구글은 UL2-20B <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib37" title=""><span class="ltx_text" style="font-size:90%;">UL2</span> </a></cite>를 출시했다. 칭화대는 GLM-130B<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">GLM-130B</span> </a></cite>를 도입했다. Meta has released OPT <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">opt</span> </a></cite> and LLaMA <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">llama</span> </a></cite>. 이러한 오픈 소스 모델은 귀중한 기여를 했지만 일반적으로 폐쇄 소스 모델과 동일한 수준의 성능을 나타내지 않는다는 점에 주목할 필요가 있다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Large Language Models for Code.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">최근 연구에서는 코드 이해 및 생성의 문제를 해결하기 위해 코드 관련 작업에 대해 상당한 수의 LLM을 도입했다. OpenAI는 Codex<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">codex</span> </a></cite>와 Code-Davinci<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">Azure</span> </a></cite>를 공개했다. Google은 PaLM-Coder <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">PaLM</span> </a></cite>를 제안했다. 그들은 HumanEval <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">humeval</span> </a></cite>와 MBPP <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">MBPP</span> </a></cite>와 같은 인기 있는 코드 완성 벤치마크에서 뛰어난 성능을 보인다. 그러나 이러한 모델은 폐쇄 소스입니다.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1">한편, 이용 가능한 오픈 소스 코드 LLM은 여러 가지가 있다. Salesforce는 CodeGen <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">codegen</span> </a></cite>, CodeT5 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">codet5</span> </a></cite>, CodeT5+ <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">CodeT5+</span> </a></cite>를 도입하였다. 칭화대는 CodeGeeX<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">CodeGeeX</span> </a></cite>를, 빅코드 프로젝트는 StarCoder<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">li2023starcoder</span> </a></cite>를 개발했다. 이러한 모델은 코드 관련 작업에서 주목할 만한 발전을 보여주었다. 그러나 SOTA 폐쇄 소스 모델과 비교할 때 여전히 크게 뒤처진다. 명령어 미세 조정이 없는 앞서 언급한 모델과는 대조적으로, 본 연구는 Code <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px2.p2.1.1">Evol-Instruct</em>을 사용하여 Code LLM을 추가로 훈련하면 성능을 크게 향상시킬 수 있음을 보여준다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Instruction Fine-Tuning.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">초기 단계에서 수업 미세 조정의 주요 목적은 LM의 교차 작업 일반화 능력을 향상시키는 것이었다. 이것은 공개 NLP 작업의 상당한 코퍼스로 LMs를 미세 조정함으로써 달성되었다. T5 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">t5</span> </a></cite>는 이 접근법을 탐구한 최초의 모델 중 하나였으며, 다수의 감독된 텍스트 대 텍스트 작업에 대한 훈련이었다. FLAN <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib20" title=""><span class="ltx_text" style="font-size:90%;">DBLP:conf/iclr/WeiBZGYLDDL22</span> </a></cite>, ExT5 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">ExT5</span> </a></cite>, T0 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">T0</span> </a></cite>, UnifiedQA <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">UnifiedQA</span> </a></cite>와 같은 후속 작업은 LM의 전반적인 일반화 능력을 강화하기 위해 작업의 범위를 더욱 확장했다. 특히 ZeroPrompt <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">ZeroPrompt</span> </a></cite>와 FLAN-T5 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">flan-t5</span> </a></cite>는 훈련 파이프라인에 수천 개의 태스크를 통합하여 엔벨로프를 밀어붙였다. 이러한 연구 전반에 걸쳐 일관된 발견이 나타났는데, 다양한 NLP 작업 지침으로 LM을 미세 조정하면 새로운 작업에 적용할 때 상당한 성능 개선이 나타난다.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">다양한 NLP 작업으로 LM을 미세 조정하면 유망한 결과를 보여주었지만 실제 사용자의 의도에 부합하지 못하는 경우가 많다. OpenAI는 다양한 형태와 광범위한 작업 유형을 포괄하는 인간 명령어의 대규모 코퍼스를 제공하기 위해 인간 주석자를 요청함으로써 다른 접근법을 추구했다. 이 데이터 세트를 기반으로 OpenAI는 GPT3<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">GPT3</span> </a></cite> 모델을 훈련하여 InstructGPT<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">DBLP:conf/nips/Ouyang0JAWMZASR22</span> </a></cite>를 만들었으며, 이는 사용자의 입력과 더 잘 일치합니다. 이 발전 라인은 ChatGPT라고 알려진 인상적인 작업으로 이어졌습니다. 그러나 이러한 발전과 관련된 데이터 세트 및 모델 가중치는 공개적으로 사용할 수 없다는 점에 유의하는 것이 중요하다. Alpaca<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">alpaca</span> </a></cite>는 Self-instruct 방법 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">wang2022self</span> </a></cite>를 채택하여 ChatGPT를 활용하여 학습을 위한 데이터를 생성함으로써 다른 경로를 취한다. Vicuna <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">vicuna2023</span> </a></cite>는 ShareGPT.com에서 수집된 사용자 공유 대화를 활용하여 모델을 학습합니다. WizardLM <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">xu2023wizardlm</span> </a></cite>는 <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px3.p2.1.1">Evol-Instruct</em> 메서드를 소개하며, 이 메서드는 기존 명령 데이터를 진화하여 더 복잡하고 다양한 데이터 세트를 생성한다. 이러한 일반적인 명령 미세 조정 접근법과 달리, 우리의 <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px3.p2.1.2">WizardCoder</em>은 코드 LLM의 도메인에서 특히 <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px3.p2.1.3">Evol-Instruct</em> 방법을 성공적으로 적용했다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Approach</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">이 섹션에서는 <em class="ltx_emph ltx_font_italic" id="S3.p1.1.1">WizardCoder</em>의 방법론적 세부 사항에 대해 자세히 설명한다. WizardLM에 이어 자체 명령을 사용하여 생성된 Code Alpaca를 진화하고 사전 훈련된 Code LLM StarCoder를 진화된 데이터로 미세 조정하기 위해 <em class="ltx_emph ltx_font_italic" id="S3.p1.1.2">Evol-Instruct</em> 방법을 적용한다.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Evol-Instruct Prompts for Code</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.5">WizardLM이 제안한 Evol-Instruct <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">xu2023wizardlm</span> </a></cite> 방법에서 영감을 받은 이 작업은 또한 코드 사전 훈련된 대형 모델의 미세 조정 효과를 향상시키기 위해 코드 명령을 더 복잡하게 만들려고 시도한다. Evol-Instruct를 코드의 영역에 적용하기 위해 진화 프롬프트를 다음과 같이 수정했습니다.</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">심화, 복잡한 입력 및 In-Breadth 진화를 제거하여 진화 지침을 간소화했습니다.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">진화 프롬프트 템플릿을 통합하여 진화 프롬프트의 형태를 단순화했다.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">코드 도메인의 특정 특성을 해결하기 위해 코드 디버깅과 코드 시공간 복잡도 제약의 두 가지 진화 명령어를 추가했다.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S3.SS1.p1.4">통합된 코드 진화 프롬프트 템플릿은 다음과 같습니다. <span class="ltx_ERROR undefined" id="S3.SS1.p1.4.1">{boxEnv}</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.4.2">주어진 프로그래밍 테스트 문제의 난이도를 조금 높여주세요. <br class="ltx_break"/> <br class="ltx_break"/> <br class="ltx_break"/> {method} <br class="ltx_break"/> <br class="ltx_break"/> {question}</span>  여기서 <math alttext="\{" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mo id="S3.SS1.p1.1.m1.1.1" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\{</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">{</annotation></semantics></math>question<math alttext="\}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mo id="S3.SS1.p1.2.m2.1.1" stretchy="false" xref="S3.SS1.p1.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">}</annotation></semantics></math>는 진화를 기다리는 현재 코드 명령어를 나타내고, <math alttext="\{" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mo id="S3.SS1.p1.3.m3.1.1" stretchy="false" xref="S3.SS1.p1.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\{</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">{</annotation></semantics></math>method<math alttext="\}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mo id="S3.SS1.p1.4.m4.1.1" stretchy="false" xref="S3.SS1.p1.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">}</annotation></semantics></math>는 진화의 유형이다. 사용된 5가지 유형은 다음과 같이 나열됩니다. <span class="ltx_ERROR undefined" id="S3.SS1.p1.4.3">{boxEnv}</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.4.4">원래 문제에 새로운 제약 사항 및 요구 사항을 추가하여 약 10개의 추가 단어를 추가합니다. <br class="ltx_break"/> <br class="ltx_break"/> 프로그래밍 작업에서 일반적으로 사용되는 요구 사항을 덜 일반적이고 더 구체적인 요구 사항으로 대체합니다. <br class="ltx_break"/> <br class="ltx_break"/> 원래의 문제를 몇 개의 논리 단계만으로 해결할 수 있다면, 더 많은 추론 단계를 추가해 주세요. <br class="ltx_break"/> <br class="ltx_break"/> 잘못된 코드 조각을 참조로 제공하여 오방향성을 높입니다. <br class="ltx_break"/> <br class="ltx_break"/> 더 높은 시간 또는 공간 복잡성 요구 사항을 제안하지만 자주 하지 마십시오. </span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Training <em class="ltx_emph ltx_font_italic" id="S3.SS2.1.1">WizardCoder</em>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">다음 절차를 사용하여 <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.1">WizardCoder</em>을 학습합니다. 초기에는 StarCoder 15B <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">li2023starcoder</span> </a></cite>를 기반으로 하고 코드 명령어 추적 훈련 세트를 사용하여 미세 조정을 진행하며, 이는 <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.2">Evol-Instruct</em>을 통해 진화했다. 미세 조정을 위한 프롬프트 형식은 다음과 같이 요약됩니다. <span class="ltx_ERROR undefined" id="S3.SS2.p1.1.3">{boxEnv}</span> <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.4">아래는 추가 컨텍스트를 제공하는 입력과 쌍을 이루는 작업을 설명하는 명령입니다. 요청을 적절하게 완료하는 응답을 작성합니다. <br class="ltx_break"/> <br class="ltx_break"/>### Instruction: <br class="ltx_break"/>{instruction} <br class="ltx_break"/> <br class="ltx_break"/> <br class="ltx_break"/>### Response:</span>  훈련 데이터 세트를 구성하려면 코드 Alpaca<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sahil280114/codealpaca" title="">https://github.com/sahil280114/codealpaca</a></span></span></span>이라는 20K 명령어 후속 데이터 세트로 초기화했습니다. 진화된 데이터를 생성하기 위해 20,000개의 샘플로 구성된 이 데이터 세트에 Evol-Instruct 기술을 반복적으로 사용한다. 데이터 진화의 각 라운드 후, 모든 이전 라운드에서 진화된 데이터를 원래 데이터 세트와 병합하여 Finetune StarCoder로 보내고 HumanEval <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">humeval</span> </a></cite>에서 pass@1 메트릭을 평가한다. 통과@1 메트릭의 감소를 관찰하면, 우리는 Evol-Instruct의 사용을 중단하고 가장 높은 통과@1을 갖는 모델을 궁극적인 모델로 선택할 것이다.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="364" id="S3.F1.g1" src="https://arxiv.org/html/2306.08568/x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.3.1.1" style="font-size:90%;">Figure 1</span>:</span><span class="ltx_text" id="S3.F1.4.2" style="font-size:90%;">The percentage of pass rates on the HumanEval (164 problems) with a single attempt. 모든 기준 점수는 LLM-Humaneval-Benchmarks <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">llm-humaneval-benchmarks</span> </a></cite>에서 검색된다. 우리의 <em class="ltx_emph ltx_font_italic" id="S3.F1.4.2.1">WizardCoder</em>은 greedy 디코딩으로 답변을 생성합니다. </span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">이 섹션은 실험에서 기본 모델에 대한 포괄적인 개요를 제공하는 것으로 시작한다. 이후 4개의 코드 생성 벤치마크인 HumanEval <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">humeval</span> </a></cite>, HumanEval+ <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">humanevalp</span> </a></cite>, MBPP <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">MBPP</span> </a></cite>, DS-1000 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib34" title=""><span class="ltx_text" style="font-size:90%;">DS1000</span> </a></cite>에 대한 모델의 성능을 제시한다.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Baselines</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Closed-Source Models.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">Multiple technology companies have successfully developed highly proficient LLMs while choosing not to publicly release them. These models are referred to as closed-source models. For our research, we incorporate a substantial number of these models as our baselines. Specifically, our baselines encompass the following: (i) OpenAI’s GPT3.5&amp;4 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">GPT4</span> </a></cite>, Code-Davinci-002 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">Azure</span> </a></cite>, Code-Cushman-001 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">Azure</span> </a></cite>, and Codex <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">codex</span> </a></cite>; (ii) Google’s Bard, PaLM 2 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">palm2</span> </a></cite>, PaLM <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">PaLM</span> </a></cite>, and LaMDA <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">LaMDA</span> </a></cite>; (iii) Google DeepMind’s AlphaCode <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">AlphaCode</span> </a></cite>; and (iv) Anthropic’s Claude.</p>여러 기술 회사가 고숙련 LLM을 성공적으로 개발하면서 공개적으로 출시하지 않기로 결정했습니다. 이러한 모델을 폐쇄 소스 모델이라고 합니다. 연구를 위해 이러한 모델의 상당수를 기준선으로 통합합니다. 구체적으로, 우리의 기준선은 (i) OpenAI의 GPT3.5&4 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">GPT4</span> </a></cite>, Code-Davinci-002 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">Azure</span> </a></cite>, Code-Cushman-001 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">Azure</span> </a></cite>, Codex <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">codex</span> </a></cite>; (ii) Google의 Bard, PaLM 2 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">palm2</span> </a></cite>, PaLM <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">PaLM</span> </a></cite>, LaMDA <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">LaMDA</span> </a></cite>; (iii) Google DeepMind의 AlphaCode <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">AlphaCode</span> </a></cite>; 및 (iv) Anthropic의 Claude를 포함한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Open-Source Models.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">AI 커뮤니티에는 여러 오픈 소스 LLM이 사용 가능했지만 일반적으로 성능이 폐쇄 소스 모델보다 많이 뒤처진다. 연구의 일환으로, 우리는 이러한 오픈 소스 모델의 상당수를 기준선으로 통합합니다. 우리의 기준선은 StarCoder <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">li2023starcoder</span> </a></cite>, LLaMa <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">llama</span> </a></cite>, CodeGen <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">codegen</span> </a></cite>, CodeGeeX <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">CodeGeeX</span> </a></cite>, CodeT5+<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">CodeT5+</span> </a></cite>, InCoder<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">incoder</span> </a></cite>의 모델을 포함한다. 또한, StarCoder-GPTeacher, <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct" title="">https://huggingface.co/GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct</a></span></span></span> Instruct-Codegen-16B, <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/sahil2801/instruct-codegen-16B" title="">https://huggingface.co/sahil2801/instruct-codegen-16B</a></span></span></span> Guanaco-65B, <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/TheBloke/guanaco-65B-HF" title="">https://huggingface.co/TheBloke/guanaco-65B-HF</a></span></span></span> 및 Falcon-40B-Instruct를 포함한 명령어 미세 조정이 있는 여러 모델도 포함한다. <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/tiiuae/falcon-40b-instruct" title="">https://huggingface.co/tiiuae/falcon-40b-instruct</a></span></span></span></p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation Details</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">스타코더<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">li2023starcoder</span> </a></cite>는 우리의 기본 기초 모델 역할을 한다. 진화된 데이터 세트는 약 78k개의 샘플로 구성된다. 기본 모델을 미세 조정하기 위해 배치 크기 512, 시퀀스 길이 2048, 미세 조정 단계 200, 워밍업 단계 30, 학습 속도 2e-5, 코사인 학습 속도 스케줄러 및 fp16 혼합 정밀도를 포함한 특정 구성을 사용한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Evaluation on HumanEval, HumanEval+, and MBPP</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">HumanEval <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">humeval</span> </a></cite>, HumanEval+ <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">humanevalp</span> </a></cite> 및 MBPP <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">MBPP</span> </a></cite>는 Code LLMs 분야에서 광범위하게 활용되고 있는 벤치마크이다. 이러한 벤치마크는 코드 LLM에서 생성된 코드를 검증하기 위해 테스트 케이스를 사용하는 방대한 파이썬 프로그래밍 문제를 포함한다. HumanEval은 164개의 독창적인 프로그래밍 문제로 구성되어 있으며, 각 문제에 평균 9.6개의 테스트 케이스가 할당된다. LLM 합성 코드의 기능적 정확성에 대한 철저한 평가를 보장하기 위해 HumanEval+는 테스트 케이스 수를 크게 확장하여 문제당 평균 774.8개의 테스트 케이스로 확장한다. 반면에 MBPP는 500개의 테스트 프로그래밍 문제 세트를 제공하며 문제당 3개의 자동화된 테스트 케이스를 제공한다. 이러한 작업에 대한 프롬프트 형식은 다음과 같습니다. <span class="ltx_ERROR undefined" id="S4.SS3.p1.1.1">{boxEnv}</span> <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.2">아래는 추가 컨텍스트를 제공하는 입력과 쌍을 이루는 작업을 설명하는 명령입니다. 요청을 적절하게 완료하는 응답을 작성합니다. <br class="ltx_break"/> <br class="ltx_break"/>### Instruction: <br class="ltx_break"/>이 문제에 대한 Python 스크립트 만들기: <br class="ltx_break"/>{Question} <br class="ltx_break"/> <br class="ltx_break"/>### Response:</span></p>
</div>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Comparing with the Closed-Source Models.</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">GPT4, Claude 및 Bard와 같은 코드 생성을 위한 SOTA LLM은 주로 폐쇄 소스이다. 이러한 모델의 API에 대한 액세스 획득은 어려운 것으로 판명되었습니다. 본 연구에서는 LLM-Humaneval-Benchmarks <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">llm-humaneval-benchmarks</span> </a></cite>에서 HumanEval과 HumanEval+에 대한 점수를 검색하여 대안적인 접근법을 채택한다. 특히, 언급된 모든 모델은 단일 시도를 사용하여 각 문제에 대한 코드 솔루션을 생성하고 결과 통과율 백분율이 보고된다. 일관성을 유지하기 위해 그리디 디코딩을 사용하여 답변을 생성하여 동일한 실험 설정을 사용하고 제공된 평가 코드를 사용하여 <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS0.Px1.p1.1.1">WizardCoder</em>을 평가한다. 이러한 표준화된 절차를 준수함으로써 기존 벤치마크에 대한 모델의 공정하고 유사한 평가를 보장하는 것을 목표로 한다.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p2.1"><a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Training WizardCoder ‣ 3 Approach ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">1</span></a>에 나타낸 바와 같이, 우리의 <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS0.Px1.p2.1.1">WizardCoder</em> attains the third position in this benchmark, surpassing Claude-Plus (59.8 vs 53.0) (59.8 vs. 44.5). 특히, 우리 모델은 이러한 모델에 비해 훨씬 작은 크기를 나타낸다. 또한, <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS0.Px1.p2.1.2">WizardCoder</em>은 명령어 미세 조정을 거치는 다른 오픈 소스 LLMs에 비해 뛰어난 성능을 보여 상당한 성능 마진을 보여준다.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.3.1.1" style="font-size:90%;">Table 1</span>:</span><span class="ltx_text" id="S4.T1.4.2" style="font-size:90%;">Results of pass@1(%) on HumanEval and MBPP. 대부분의 점수는 StarCoder<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">li2023starcoder</span> </a></cite>와 CodeT5+<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">CodeT5+</span> </a></cite>의 논문에서 검색된다. 우리는 이전 연구 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">humeval</span> </a></cite>를 따라 n개의 샘플을 생성하여 온대=0.2, top_p=0.95의 동일한 하이퍼 매개 변수 집합으로 pass@1 점수를 추정한다. *: 이 모델을 스스로 평가한다. </span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1">
<tbody><tr class="ltx_tr" id="S4.T1.1.2">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T1.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.2.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.2.1">Params</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.2.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.3.1">HumanEval</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.2.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.4.1">MBPP</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="S4.T1.1.3.1">Closed-source models</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.1">LaMDA&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">LaMDA</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.4.2">137B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.4.3">14.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.4.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5">
<td class="ltx_td ltx_align_left" id="S4.T1.1.5.1">AlphaCode&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">AlphaCode</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.2">1.1B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.3">17.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6">
<td class="ltx_td ltx_align_left" id="S4.T1.1.6.1">PaLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">PaLM</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.2">540B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.3">26.2</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.4">36.8</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7">
<td class="ltx_td ltx_align_left" id="S4.T1.1.7.1">PaLM-Coder&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">PaLM</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.2">540B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.3">36.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.4">47.0</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8">
<td class="ltx_td ltx_align_left" id="S4.T1.1.8.1">PaLM 2-S&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">palm2</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.2">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.3">37.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.4">50.0</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.9">
<td class="ltx_td ltx_align_left" id="S4.T1.1.9.1">Codex&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">codex</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.2">2.5B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.3">21.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.10">
<td class="ltx_td ltx_align_left" id="S4.T1.1.10.1">Codex&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">codex</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.2">12B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.3">28.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.11">
<td class="ltx_td ltx_align_left" id="S4.T1.1.11.1">Code-Cushman-001&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">Azure</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.2">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.3">33.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.4">45.9</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.12">
<td class="ltx_td ltx_align_left" id="S4.T1.1.12.1">Code-Davinci-002&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">Azure</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.12.2">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.12.3">47.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.12.4">58.1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.13">
<td class="ltx_td ltx_align_left" id="S4.T1.1.13.1">GPT-3.5&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">GPT4</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.13.2">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.13.3">48.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.13.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.14">
<td class="ltx_td ltx_align_left" id="S4.T1.1.14.1">GPT-4&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">GPT4</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.14.2">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.14.3">67.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.14.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.15">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="S4.T1.1.15.1">Open-source models</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.16">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.16.1">LLaMa&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">llama</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.16.2">33B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.16.3">21.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.16.4">30.2</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.17">
<td class="ltx_td ltx_align_left" id="S4.T1.1.17.1">LLaMa&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">llama</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.17.2">65B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.17.3">23.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.17.4">37.7</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.18">
<td class="ltx_td ltx_align_left" id="S4.T1.1.18.1">CodeGen-Multi&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">codegen</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.18.2">16B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.18.3">18.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.18.4">20.9</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.19">
<td class="ltx_td ltx_align_left" id="S4.T1.1.19.1">CodeGen-Mono&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">codegen</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.19.2">16B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.19.3">29.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.19.4">35.3</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.20">
<td class="ltx_td ltx_align_left" id="S4.T1.1.20.1">CodeGeeX&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">CodeGeeX</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.20.2">13B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.20.3">22.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.20.4">24.4</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.2">StarCoder&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">li2023starcoder</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3">15B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4">33.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.1">43.6<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S4.T1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.m1.1a"><msup id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml"><mi id="S4.T1.1.1.1.m1.1.1a" xref="S4.T1.1.1.1.m1.1.1.cmml"></mi><mo id="S4.T1.1.1.1.m1.1.1.1" xref="S4.T1.1.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1"><times id="S4.T1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.21">
<td class="ltx_td ltx_align_left" id="S4.T1.1.21.1">CodeT5+&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">CodeT5+</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.21.2">16B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.21.3">30.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.21.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.22">
<td class="ltx_td ltx_align_left" id="S4.T1.1.22.1">InstructCodeT5+&nbsp;<cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">CodeT5+</span> </a></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.22.2">16B</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.22.3">35.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.22.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.23">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T1.1.23.1"><em class="ltx_emph ltx_font_italic" id="S4.T1.1.23.1.1">WizardCoder</em></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.1.23.2">15B</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.1.23.3">
<span class="ltx_text ltx_font_bold" id="S4.T1.1.23.3.1">57.3</span> (<span class="ltx_text" id="S4.T1.1.23.3.2" style="color:#FF0000;">+22.3</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.1.23.4">
<span class="ltx_text ltx_font_bold" id="S4.T1.1.23.4.1">51.8</span> (<span class="ltx_text" id="S4.T1.1.23.4.2" style="color:#FF0000;">+8.2</span>)</td>
</tr>
</tbody></table>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Comparing with the Open-Source Models.</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.1">표 <a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ Comparing with the Closed-Source Models. ‣ 4.3 Evaluation on HumanEval, HumanEval+, and MBPP ‣ 4 Experiment ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">1</span></a>에서 <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS0.Px2.p1.1.1">WizardCoder</em>과 HumanEval 및 MBPP 벤치마크 상의 다른 오픈 소스 모델을 종합적으로 비교합니다. <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Training WizardCoder ‣ 3 Approach ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">1</span></a>에 제시된 결과와 달리, 패스@1 점수를 추정하기 위해 각 문제에 대해 n개의 샘플을 생성함으로써 이전 연구 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">humeval</span> </a></cite>에 요약된 접근법을 고수한다. 표 <a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ Comparing with the Closed-Source Models. ‣ 4.3 Evaluation on HumanEval, HumanEval+, and MBPP ‣ 4 Experiment ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">1</span></a>에 제시된 결과는 우리의 <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS0.Px2.p1.1.2">WizardCoder</em>이 모든 오픈 소스 모델에 비해 상당한 성능 이점을 나타냄을 분명히 보여준다.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS3.SSS0.Px2.p2.1"><a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Training WizardCoder ‣ 3 Approach ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">1</span></a> 및 표<a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ Comparing with the Closed-Source Models. ‣ 4.3 Evaluation on HumanEval, HumanEval+, and MBPP ‣ 4 Experiment ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">1</span></a>의 실험 결과로부터 다음과 같은 결론을 얻을 수 있다:</p>
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i1.p1.1.1">WizardCoder</em>은 훨씬 작음에도 불구하고 Claude, Bard, PaLM, PaLM-2 및 LaMDA를 포함한 가장 큰 폐쇄 소스 LLM을 능가합니다.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i2.p1.1.1">WizardCoder</em>은 StarCoder, CodeGen, CodeGee 및 CodeT5+를 포함하여 모든 오픈 소스 Code LLMs를 큰 마진(+22.3 on HumanEval)으로 능가합니다.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.I1.i3.p1.1.1">WizardCoder</em>은 InstructCodeT5+, StarCoder-GPTeacher 및 Instruct-Codegen-16B를 포함한 모든 오픈 소스 Code LLMs를 명령 미세 조정으로 상당히 능가합니다.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Evaluation on DS-1000</h3>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.3.1.1" style="font-size:90%;">Table 2</span>:</span><span class="ltx_text" id="S4.T2.4.2" style="font-size:90%;">Performance of <em class="ltx_emph ltx_font_italic" id="S4.T2.4.2.1">WizardCoder</em> and baseline models on DS-1000. All models is evaluated with the same set of hyper-parameters: temperature=0.2, top_p=0.5, max_length=1024. Scores are average pass@1 accuracy over 40 samples. Matplotlib(plt) 작업은 올바른 컨텍스트가 없으므로 삽입 및 완료 점수가 동일합니다. </span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.5">
<tbody><tr class="ltx_tr" id="S4.T2.5.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.5.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.1.1">Format</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.2.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.3.1">plt</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.4.1">np</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.5.1">pd</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.6.1">py</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.7"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.7.1">scp</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.8"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.8.1">sk</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.9"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.9.1">tf</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.10"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.10.1">All</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.2">
<td class="ltx_td ltx_border_t" id="S4.T2.5.2.1"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.2"># of problems:</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.3">155</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.4">220</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.5">291</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.6">68</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.7">106</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.8">115</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.9">45</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.10">1,000</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.5.3.1">Completion</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.3.2">InCoder-6B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.3.3">28.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.3.4">4.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.3.5">3.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.3.6">4.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.3.7">2.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.3.8">2.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.3.9">3.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.3.10">7.4</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.4">
<td class="ltx_td ltx_align_left" id="S4.T2.5.4.1">Completion</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.2">CodeGen-mono</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.3">31.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.4">10.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.5">3.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.6">7.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.7">9.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.8">10.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.9">15.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.10">11.7</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.5">
<td class="ltx_td ltx_align_left" id="S4.T2.5.5.1">Completion</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.2">Code-Cushman-001</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.3">40.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.4">21.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.5">7.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.6">12.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.7">11.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.8">18.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.9">12.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.10">18.1</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.6">
<td class="ltx_td ltx_align_left" id="S4.T2.5.6.1">Completion</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.2">StarCoder</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.3">51.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.4">29.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.5">11.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.6">21.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.7">20.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.8"><span class="ltx_text ltx_font_bold" id="S4.T2.5.6.8.1">29.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.9">24.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.10">26.0</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.7">
<td class="ltx_td ltx_align_left" id="S4.T2.5.7.1">Completion</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.2"><em class="ltx_emph ltx_font_italic" id="S4.T2.5.7.2.1">WizardCoder</em></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.3.1">55.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.4"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.4.1">33.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.5.1">16.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.6.1">26.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.7"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.7.1">24.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.8">24.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.9"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.9.1">26.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.10"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.10.1">29.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.5.8.1">Insertion</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.8.2">InCoder-6B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.8.3">28.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.8.4">4.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.8.5">2.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.8.6">4.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.8.7">2.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.8.8">3.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.8.9">7.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.8.10">7.5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.9">
<td class="ltx_td ltx_align_left" id="S4.T2.5.9.1">Insertion</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.2">StarCoder</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.3">51.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.4">30.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.5">10.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.6">21.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.7">20.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.8">27.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.9">20.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.10">25.4</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.10">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.5.10.1">Insertion</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.10.2"><em class="ltx_emph ltx_font_italic" id="S4.T2.5.10.2.1">WizardCoder</em></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.10.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.10.3.1">55.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.10.4"><span class="ltx_text ltx_font_bold" id="S4.T2.5.10.4.1">35.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.10.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.10.5.1">20.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.10.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.10.6.1">30.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.10.7"><span class="ltx_text ltx_font_bold" id="S4.T2.5.10.7.1">28.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.10.8"><span class="ltx_text ltx_font_bold" id="S4.T2.5.10.8.1">32.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.10.9"><span class="ltx_text ltx_font_bold" id="S4.T2.5.10.9.1">37.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.10.10"><span class="ltx_text ltx_font_bold" id="S4.T2.5.10.10.1">32.8</span></td>
</tr>
</tbody></table>
</figure>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">DS-1000 벤치마크 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="#bib.bib34" title=""><span class="ltx_text" style="font-size:90%;">DS1000</span> </a></cite>는 7개의 라이브러리에 걸쳐 있는 1,000개의 별개의 데이터 과학 워크플로로 구성된다. 테스트 케이스에 대한 코드 생성의 성능을 평가하고 완료 및 삽입의 두 가지 평가 모드를 지원합니다. 실험에서는 지원하는 모델에 대한 삽입 점수만 보고한다. DS-1000 벤치마크는 Matplotlib (plt), NumPy (np), Pandas (pd), SciPy (scp), Scikit-Learn (sk), PyTorch (py), TensorFlow (tf)와 같은 라이브러리를 기반으로 문제를 더 분류한다. 스타코더와 동일한 프롬프트 형식을 따릅니다. <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4.4 Evaluation on DS-1000 ‣ 4 Experiment ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">2</span></a>에서는 전체 점수와 함께 각 라이브러리에 대한 pass@1(n=40) 결과를 제시한다. 이러한 결과에 기초하여, 우리의 결론은 <em class="ltx_emph ltx_font_italic" id="S4.SS4.p1.1.1">WizardCoder</em>이 DS-1000 벤치마크에서 데이터 과학 문제를 다룰 때 다른 모든 모델에 비해 상당한 우월성을 입증한다는 것이다. 이 관찰은 거의 모든 데이터 과학 라이브러리에서 적용된다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Ablation Study</h3>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="212" id="S4.F2.g1" src="https://arxiv.org/html/2306.08568/x2.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.2.1.1" style="font-size:90%;">Figure 2</span>:</span><span class="ltx_text" id="S4.F2.3.2" style="font-size:90%;">Ablation study on the number of data evolution rounds. </span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1"><a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4.5 Ablation Study ‣ 4 Experiment ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">2</span></a>는 데이터 진화 라운드 수의 영향을 조사하는 절제 연구를 제시한다. 진화된 데이터의 첫 번째 라운드에는 38k개의 샘플이 포함되어 있다. 두 번째 라운드에는 58k가 들어 있습니다. 세 번째 라운드는 78k입니다. 네 번째 라운드는 98k입니다. 일관성을 위해 모든 모델은 200단계로 미세 조정을 거칩니다. 결과는 인간성에 대한 가장 높은 패스@1 점수가 3회의 데이터 진화 후에 달성된다는 것을 보여준다. 이 관찰을 기반으로 3라운드 동안 진화한 데이터를 최종 데이터 세트로 선택한다.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.9.1.1" style="font-size:90%;">Table 3</span>:</span><span class="ltx_text" id="S4.T3.10.2" style="font-size:90%;">우리의 <em class="ltx_emph ltx_font_italic" id="S4.T3.10.2.1">WizardCoder</em>과의 상호 작용 예제. </span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T3.6">
<tbody><tr class="ltx_tr" id="S4.T3.6.7">
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_tt" id="S4.T3.6.7.1" style="width:71.1pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S4.T3.6.7.1.1">Instruction</span></td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="S4.T3.6.7.2" style="width:284.5pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S4.T3.6.7.2.1">Response</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2">
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S4.T3.2.2.3" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.2.2.3.1">Write a Python function to tell me what the date is today.</p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.2.2.2" style="width:284.5pt;">
<div class="ltx_block ltx_align_top" id="S4.T3.2.2.2.2">
<p class="ltx_p" id="S4.T3.2.2.2.2.2"><span class="ltx_inline-para ltx_minipage ltx_align_middle" id="S4.T3.2.2.2.2.2.2" style="width:290.0pt;"> <span class="ltx_para" id="S4.T3.1.1.1.1.1.1.p1"> <span class="ltx_p" id="S4.T3.1.1.1.1.1.1.p1.1">Here’s a Python function that tells you what the date is today:</span> </span> <span class="ltx_para" id="S4.T3.2.2.2.2.2.2.p2"> <span class="ltx_listing ltx_lst_language_Python ltx_lstlisting ltx_listing" id="S4.T3.2.2.2.2.2.2.p2.1" style="background-color:#F2F2EB;"><span class="ltx_listing_data"><a download="" href="data:text/plain;base64,aW1wb3J0IGRhdGV0aW1lCgpkZWYgZ2V0X2RhdGUoKToKICAgIG5vdyA9IGRhdGV0aW1lLmRhdGV0aW1lLm5vdygpCiAgICByZXR1cm4gbm93LnN0cmZ0aW1lKCIlQSwgJUIgJWQsICVZIikKCnByaW50KGdldF9kYXRlKCkp">⬇</a></span> <span class="ltx_listingline" id="lstnumberx1"><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx1.1" style="font-size:50%;color:#FF00FF;">import</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.2" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.3" style="font-size:50%;">datetime</span> </span> <span class="ltx_listingline" id="lstnumberx2"> </span> <span class="ltx_listingline" id="lstnumberx3"><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx3.1" style="font-size:50%;color:#FF00FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.2" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.3" style="font-size:50%;">get_date</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.4" style="font-size:50%;">():</span> </span> <span class="ltx_listingline" id="lstnumberx4"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.2" style="font-size:50%;">now</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.4" style="font-size:50%;">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.5" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.6" style="font-size:50%;">datetime</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.7" style="font-size:50%;">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.8" style="font-size:50%;">datetime</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.9" style="font-size:50%;">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.10" style="font-size:50%;">now</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.11" style="font-size:50%;">()</span> </span> <span class="ltx_listingline" id="lstnumberx5"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx5.2" style="font-size:50%;color:#FF00FF;">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.4" style="font-size:50%;">now</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.5" style="font-size:50%;">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.6" style="font-size:50%;">strftime</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.7" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx5.8" style="font-size:50%;color:#9400D1;">"%A,<span class="ltx_text ltx_lst_space" id="lstnumberx5.8.1">&nbsp;</span>%B<span class="ltx_text ltx_lst_space" id="lstnumberx5.8.2">&nbsp;</span>%d,<span class="ltx_text ltx_lst_space" id="lstnumberx5.8.3">&nbsp;</span>%Y"</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.9" style="font-size:50%;">)</span> </span> <span class="ltx_listingline" id="lstnumberx6"> </span> <span class="ltx_listingline" id="lstnumberx7"><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx7.1" style="font-size:50%;color:#FF00FF;">print</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.2" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.3" style="font-size:50%;">get_date</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.4" style="font-size:50%;">())</span> </span> </span> </span></span></p>
<p class="ltx_p" id="S4.T3.2.2.2.2.3">이 함수는 데이터 시간 모듈을 사용하여 현재 날짜 및 시간을 가져옵니다. 그런 다음 strftime() 방법을 사용하여 날짜를 "Day, Month Date, Year" 형식의 문자열로 포맷합니다. 마지막으로 형식이 지정된 문자열을 반환합니다.</p>
<p class="ltx_p" id="S4.T3.2.2.2.2.4">파이썬 코드에서 이 함수를 호출하여 현재 날짜와 시간을 얻을 수 있습니다.</p>
</div>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.4">
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S4.T3.4.4.3" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.4.4.3.1">I do not know how to integrate a Python function numerically. Please write a code for me.</p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.4.4.2" style="width:284.5pt;">
<div class="ltx_block ltx_align_top" id="S4.T3.4.4.2.2">
<p class="ltx_p" id="S4.T3.4.4.2.2.2"><span class="ltx_inline-para ltx_minipage ltx_align_middle" id="S4.T3.4.4.2.2.2.2" style="width:290.0pt;"> <span class="ltx_para" id="S4.T3.3.3.1.1.1.1.p1"> <span class="ltx_p" id="S4.T3.3.3.1.1.1.1.p1.1">Sure, here’s an example code for integrating a Python function numerically using the trapezoidal rule:</span> </span> <span class="ltx_para" id="S4.T3.4.4.2.2.2.2.p2"> <span class="ltx_listing ltx_lst_language_Python ltx_lstlisting ltx_listing" id="S4.T3.4.4.2.2.2.2.p2.1" style="background-color:#F2F2EB;"><span class="ltx_listing_data"><a download="" href="data:text/plain;base64,ZGVmIGludGVncmF0ZShmLCBhLCBiLCBuKToKICAgIGggPSAoYiAtIGEpIC8gbgogICAgcyA9IChmKGEpICsgZihiKSkgLyAyCiAgICBmb3IgaSBpbiByYW5nZSgxLCBuKToKICAgICAgICBzICs9IGYoYSArIGkgKiBoKQogICAgcmV0dXJuIGggKiBz">⬇</a></span> <span class="ltx_listingline" id="lstnumberx8"><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx8.1" style="font-size:50%;color:#FF00FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.2" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.3" style="font-size:50%;">integrate</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.4" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.5" style="font-size:50%;">f</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.6" style="font-size:50%;">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.7" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.8" style="font-size:50%;">a</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.9" style="font-size:50%;">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.10" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.11" style="font-size:50%;">b</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.12" style="font-size:50%;">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.13" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.14" style="font-size:50%;">n</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.15" style="font-size:50%;">):</span> </span> <span class="ltx_listingline" id="lstnumberx9"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.2" style="font-size:50%;">h</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.4" style="font-size:50%;">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.5" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.6" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.7" style="font-size:50%;">b</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.8" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.9" style="font-size:50%;">-</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.10" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.11" style="font-size:50%;">a</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.12" style="font-size:50%;">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.13" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.14" style="font-size:50%;">/</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.15" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.16" style="font-size:50%;">n</span> </span> <span class="ltx_listingline" id="lstnumberx10"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.2" style="font-size:50%;">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.4" style="font-size:50%;">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.5" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.6" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.7" style="font-size:50%;">f</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.8" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.9" style="font-size:50%;">a</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.10" style="font-size:50%;">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.11" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.12" style="font-size:50%;">+</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.13" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.14" style="font-size:50%;">f</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.15" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.16" style="font-size:50%;">b</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.17" style="font-size:50%;">))</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.18" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.19" style="font-size:50%;">/</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.20" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.21" style="font-size:50%;">2</span> </span> <span class="ltx_listingline" id="lstnumberx11"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx11.2" style="font-size:50%;color:#FF00FF;">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.4" style="font-size:50%;">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.5" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx11.6" style="font-size:50%;color:#FF00FF;">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.7" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" id="lstnumberx11.8" style="font-size:50%;color:#FF00FF;">range</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.9" style="font-size:50%;">(1,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.10" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.11" style="font-size:50%;">n</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.12" style="font-size:50%;">):</span> </span> <span class="ltx_listingline" id="lstnumberx12"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx12.2" style="font-size:50%;">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.4" style="font-size:50%;">+=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.5" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx12.6" style="font-size:50%;">f</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.7" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx12.8" style="font-size:50%;">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.9" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.10" style="font-size:50%;">+</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.11" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx12.12" style="font-size:50%;">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.13" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.14" style="font-size:50%;">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.15" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx12.16" style="font-size:50%;">h</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.17" style="font-size:50%;">)</span> </span> <span class="ltx_listingline" id="lstnumberx13"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx13.2" style="font-size:50%;color:#FF00FF;">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.4" style="font-size:50%;">h</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.5" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.6" style="font-size:50%;">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.7" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.8" style="font-size:50%;">s</span> </span> </span> </span></span></p>
<p class="ltx_p" id="S4.T3.4.4.2.2.3">이 코드는 함수 f, 하한 a, 상한 b, 하위 구간 수 n을 취한다. 그런 다음 각 하위 구간 h의 너비를 계산하고 사다리꼴 규칙을 사용하여 a와 b 사이의 f의 적분을 근사한다. 그 결과는 플로트로 반환된다.</p>
<p class="ltx_p" id="S4.T3.4.4.2.2.4">이 함수를 사용 하려면 통합 하려는 함수, 하한, 상한 및 사용 하려는 하위 간격 수로 호출 합니다. 예를 들어,</p>
<div class="ltx_listing ltx_lst_language_Python ltx_lstlisting ltx_listing" id="S4.T3.4.4.2.2.5" style="background-color:#F2F2EB;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ZGVmIGYoeCk6CiAgICByZXR1cm4geCoqMgoKcmVzdWx0ID0gaW50ZWdyYXRlKGYsIDAsIDEsIDEwMDApCnByaW50KHJlc3VsdCk=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx14">
<span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx14.1" style="font-size:50%;color:#FF00FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.2" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.3" style="font-size:50%;">f</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.4" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.5" style="font-size:50%;">x</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.6" style="font-size:50%;">):</span>
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx15.2" style="font-size:50%;color:#FF00FF;">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.4" style="font-size:50%;">x</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.5" style="font-size:50%;">**2</span>
</div>
<div class="ltx_listingline" id="lstnumberx16">
</div>
<div class="ltx_listingline" id="lstnumberx17">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.1" style="font-size:50%;">result</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.2" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.3" style="font-size:50%;">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.4" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.5" style="font-size:50%;">integrate</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.6" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.7" style="font-size:50%;">f</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.8" style="font-size:50%;">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.9" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.10" style="font-size:50%;">0,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.11" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.12" style="font-size:50%;">1,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.13" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.14" style="font-size:50%;">1000)</span>
</div>
<div class="ltx_listingline" id="lstnumberx18">
<span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx18.1" style="font-size:50%;color:#FF00FF;">print</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.2" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.3" style="font-size:50%;">result</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.4" style="font-size:50%;">)</span>
</div>
</div>
<p class="ltx_p" id="S4.T3.4.4.2.2.6">이렇게 하면 1000개의 하위 구간을 사용하여 함수 f(x) = x**2를 0과 1 사이에 통합하고 결과를 인쇄합니다.</p>
</div>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6">
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.6.6.3" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.6.6.3.1">List the prime numbers between 20 and 30 with Java.</p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S4.T3.6.6.2" style="width:284.5pt;">
<div class="ltx_block ltx_align_top" id="S4.T3.6.6.2.2">
<p class="ltx_p" id="S4.T3.6.6.2.2.2"><span class="ltx_inline-para ltx_minipage ltx_align_middle" id="S4.T3.6.6.2.2.2.2" style="width:290.0pt;"> <span class="ltx_para" id="S4.T3.5.5.1.1.1.1.p1"> <span class="ltx_p" id="S4.T3.5.5.1.1.1.1.p1.1">Here’s the Java code to list the prime numbers between 20 and 30:</span> </span> <span class="ltx_para" id="S4.T3.6.6.2.2.2.2.p2"> <span class="ltx_listing ltx_lst_language_Java ltx_lstlisting ltx_listing" id="S4.T3.6.6.2.2.2.2.p2.1" style="background-color:#F2F2EB;"><span class="ltx_listing_data"><a download="" href="data:text/plain;base64,cHVibGljIGNsYXNzIFByaW1lTnVtYmVycyB7CiAgICBwdWJsaWMgc3RhdGljIHZvaWQgbWFpbihTdHJpbmdbXSBhcmdzKSB7CiAgICAgICAgZm9yIChpbnQgaSA9IDIwOyBpIDw9IDMwOyBpKyspIHsKICAgICAgICAgICAgYm9vbGVhbiBpc1ByaW1lID0gdHJ1ZTsKICAgICAgICAgICAgZm9yIChpbnQgaiA9IDI7IGogPCBpOyBqKyspIHsKICAgICAgICAgICAgICAgIGlmIChpICUgaiA9PSAwKSB7CiAgICAgICAgICAgICAgICAgICAgaXNQcmltZSA9IGZhbHNlOwogICAgICAgICAgICAgICAgICAgIGJyZWFrOwogICAgICAgICAgICAgICAgfQogICAgICAgICAgICB9CiAgICAgICAgICAgIGlmIChpc1ByaW1lKSB7CiAgICAgICAgICAgICAgICBTeXN0ZW0ub3V0LnByaW50KGkgKyAiICIpOwogICAgICAgICAgICB9CiAgICAgICAgfQogICAgfQp9">⬇</a></span> <span class="ltx_listingline" id="lstnumberx19"><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx19.1" style="font-size:50%;color:#FF00FF;">public</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.2" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx19.3" style="font-size:50%;color:#FF00FF;">class</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.4" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.5" style="font-size:50%;">PrimeNumbers</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.6" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.7" style="font-size:50%;">{</span> </span> <span class="ltx_listingline" id="lstnumberx20"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx20.2" style="font-size:50%;color:#FF00FF;">public</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx20.4" style="font-size:50%;color:#FF00FF;">static</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.5" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx20.6" style="font-size:50%;color:#FF00FF;">void</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.7" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.8" style="font-size:50%;">main</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.9" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.10" style="font-size:50%;">String</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.11" style="font-size:50%;">[]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.12" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.13" style="font-size:50%;">args</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.14" style="font-size:50%;">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.15" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.16" style="font-size:50%;">{</span> </span> <span class="ltx_listingline" id="lstnumberx21"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx21.2" style="font-size:50%;color:#FF00FF;">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.4" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx21.5" style="font-size:50%;color:#FF00FF;">int</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.6" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.7" style="font-size:50%;">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.8" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.9" style="font-size:50%;">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.10" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.11" style="font-size:50%;">20;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.12" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.13" style="font-size:50%;">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.14" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.15" style="font-size:50%;">&lt;=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.16" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.17" style="font-size:50%;">30;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.18" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.19" style="font-size:50%;">i</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.20" style="font-size:50%;">++)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.21" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.22" style="font-size:50%;">{</span> </span> <span class="ltx_listingline" id="lstnumberx22"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx22.2" style="font-size:50%;color:#FF00FF;">boolean</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.4" style="font-size:50%;">isPrime</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.5" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.6" style="font-size:50%;">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.7" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx22.8" style="font-size:50%;color:#FF00FF;">true</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.9" style="font-size:50%;">;</span> </span> <span class="ltx_listingline" id="lstnumberx23"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx23.2" style="font-size:50%;color:#FF00FF;">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.4" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx23.5" style="font-size:50%;color:#FF00FF;">int</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.6" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.7" style="font-size:50%;">j</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.8" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.9" style="font-size:50%;">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.10" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.11" style="font-size:50%;">2;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.12" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.13" style="font-size:50%;">j</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.14" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.15" style="font-size:50%;">&lt;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.16" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.17" style="font-size:50%;">i</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.18" style="font-size:50%;">;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.19" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx23.20" style="font-size:50%;">j</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.21" style="font-size:50%;">++)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.22" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.23" style="font-size:50%;">{</span> </span> <span class="ltx_listingline" id="lstnumberx24"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx24.2" style="font-size:50%;color:#FF00FF;">if</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.4" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.5" style="font-size:50%;">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.6" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.7" style="font-size:50%;">%</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.8" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.9" style="font-size:50%;">j</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.10" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.11" style="font-size:50%;">==</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.12" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.13" style="font-size:50%;">0)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.14" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.15" style="font-size:50%;">{</span> </span> <span class="ltx_listingline" id="lstnumberx25"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.2" style="font-size:50%;">isPrime</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx25.4" style="font-size:50%;">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.5" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx25.6" style="font-size:50%;color:#FF00FF;">false</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx25.7" style="font-size:50%;">;</span> </span> <span class="ltx_listingline" id="lstnumberx26"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx26.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx26.2" style="font-size:50%;color:#FF00FF;">break</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.3" style="font-size:50%;">;</span> </span> <span class="ltx_listingline" id="lstnumberx27"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx27.2" style="font-size:50%;">}</span> </span> <span class="ltx_listingline" id="lstnumberx28"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.2" style="font-size:50%;">}</span> </span> <span class="ltx_listingline" id="lstnumberx29"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx29.2" style="font-size:50%;color:#FF00FF;">if</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.3" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.4" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.5" style="font-size:50%;">isPrime</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.6" style="font-size:50%;">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.7" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.8" style="font-size:50%;">{</span> </span> <span class="ltx_listingline" id="lstnumberx30"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.2" style="font-size:50%;">System</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.3" style="font-size:50%;">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.4" style="font-size:50%;">out</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.5" style="font-size:50%;">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.6" style="font-size:50%;">print</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.7" style="font-size:50%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx30.8" style="font-size:50%;">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.9" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.10" style="font-size:50%;">+</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx30.11" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx30.12" style="font-size:50%;color:#9400D1;">"<span class="ltx_text ltx_lst_space" id="lstnumberx30.12.1">&nbsp;</span>"</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.13" style="font-size:50%;">);</span> </span> <span class="ltx_listingline" id="lstnumberx31"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx31.2" style="font-size:50%;">}</span> </span> <span class="ltx_listingline" id="lstnumberx32"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx32.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx32.2" style="font-size:50%;">}</span> </span> <span class="ltx_listingline" id="lstnumberx33"><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.1" style="font-size:50%;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.2" style="font-size:50%;">}</span> </span> <span class="ltx_listingline" id="lstnumberx34"><span class="ltx_text ltx_font_typewriter" id="lstnumberx34.1" style="font-size:50%;">}</span> </span> </span> </span></span></p>
<p class="ltx_p" id="S4.T3.6.6.2.2.3">출력:</p>
<div class="ltx_listing ltx_lst_language_Java ltx_lstlisting ltx_listing" id="S4.T3.6.6.2.2.4" style="background-color:#F2F2EB;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,MjMgMjk=">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx35">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx35.1" style="font-size:50%;">23</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.2" style="font-size:50%;">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx35.3" style="font-size:50%;">29</span>
</div>
</div>
<p class="ltx_p" id="S4.T3.6.6.2.2.5">설명:</p>
<p class="ltx_p" id="S4.T3.6.6.2.2.6">- 중첩된 루프를 사용하여 20에서 30 사이의 모든 숫자를 반복합니다.</p>
<p class="ltx_p" id="S4.T3.6.6.2.2.7">- 각 수에 대해 다른 수를 루프에 사용하여 소수인지 여부를 확인합니다.</p>
<p class="ltx_p" id="S4.T3.6.6.2.2.8">- 숫자가 1이 아닌 다른 숫자와 그 자체로 나눌 수 있는 경우 소수가 아닙니다.</p>
<p class="ltx_p" id="S4.T3.6.6.2.2.9">- 숫자가 1과 그 자체 이외의 다른 숫자로 나눌 수 없는 경우 소수입니다.</p>
<p class="ltx_p" id="S4.T3.6.6.2.2.10">- 소수를 콘솔에 인쇄합니다.</p>
</div>
</td>
</tr>
</tbody></table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Examples</h3>
<div class="ltx_para" id="S4.SS6.p1">
<p class="ltx_p" id="S4.SS6.p1.1">Table <a class="ltx_ref" href="#S4.T3" title="Table 3 ‣ 4.5 Ablation Study ‣ 4 Experiment ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">3</span></a>는 우리의 <em class="ltx_emph ltx_font_italic" id="S4.SS6.p1.1.1">WizardCoder</em>과의 상호 작용의 예를 보여준다. 예제는 우리의 모델이 명확한 설명과 함께 일관된 정확한 응답을 생성한다는 것을 보여준다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Future Work</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">본 논문에서는 <em class="ltx_emph ltx_font_italic" id="S5.p1.1.1">WizardCoder</em>, Code <em class="ltx_emph ltx_font_italic" id="S5.p1.1.2">Evol-Instruct</em> fine-tuned Code LLM을 소개한다. 실험 결과는 <em class="ltx_emph ltx_font_italic" id="S5.p1.1.3">WizardCoder</em>이 HumanEval, HumanEval+, MBPP, DS-1000의 4가지 널리 알려진 코드 생성 벤치마크에서 기존의 모든 오픈 소스 코드 LLMs를 능가하는 SOTA 성능을 달성함을 보여준다. 또한 <em class="ltx_emph ltx_font_italic" id="S5.p1.1.4">WizardCoder</em>은 Anthropic's Claude, Google's Bard를 포함한 가장 큰 폐쇄형 LLMs에 비해 우수한 성능을 보인다.</p>
</div>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Future Work.</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1"><em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.1">WizardCoder</em>은 그림 <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3.2 Training WizardCoder ‣ 3 Approach ‣ WizardCoder: Empowering Code Large Language Models with Evol-Instruct"><span class="ltx_text ltx_ref_tag">1</span></a>에 묘사된 바와 같이 인상적인 코딩 성능을 보여주지만, 우리의 모델은 여전히 SOTA LLM인 GPT4에 크게 뒤떨어진다. 따라서, 향후 작업은 코드 <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.2">Evol-Instruct</em> 메서드의 향상을 우선시하여 우리 모델의 성능을 더욱 높일 것이다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Broader Impact.</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">다른 LLM과 유사하게 <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.1.1">WizardCoder</em>도 비윤리적이거나 유해하거나 오판의 소지가 있는 정보를 생성할 수 있습니다. 따라서 윤리적, 사회적 함의를 해결하기 위한 향후 연구가 필요하다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.2.2.1" style="font-size:90%;">(1)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.4.1" style="font-size:90%;">
Tom&nbsp;B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom
Henighan, Rewon Child, Aditya Ramesh, Daniel&nbsp;M. Ziegler, Jeffrey Wu, Clemens
Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott
Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec
Radford, Ilya Sutskever, and Dario Amodei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.5.1" style="font-size:90%;">Language models are few-shot learners.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.6.1" style="font-size:90%;">In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell,
Maria-Florina Balcan, and Hsuan-Tien Lin, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib1.7.2" style="font-size:90%;">Advances in
Neural Information Processing Systems 33: Annual Conference on Neural
Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,
virtual</span><span class="ltx_text" id="bib.bib1.8.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.2.2.1" style="font-size:90%;">(2)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.4.1" style="font-size:90%;">
OpenAI.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.5.1" style="font-size:90%;">GPT-4 technical report.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib2.7.2" style="font-size:90%;">, abs/2303.08774, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.2.2.1" style="font-size:90%;">(3)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.4.1" style="font-size:90%;">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
</span><span class="ltx_text" id="bib.bib3.5.2" style="font-size:90%;">Adam Roberts, Paul Barham, Hyung&nbsp;Won Chung, Charles Sutton, Sebastian
Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
Abhishek Rao, Parker Barnes, Yi&nbsp;Tay, Noam Shazeer, Vinodkumar Prabhakaran,
Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob
Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm
Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia,
Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David
Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David
Dohan, Shivani Agrawal, Mark Omernick, Andrew&nbsp;M. Dai,
Thanumalayan&nbsp;Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi
Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,
Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah
Fiedel.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.6.1" style="font-size:90%;">Palm: Scaling language modeling with pathways.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.7.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib3.8.2" style="font-size:90%;">, abs/2204.02311, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.2.2.1" style="font-size:90%;">(4)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.4.1" style="font-size:90%;">
Rohan Anil, Andrew&nbsp;M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,
Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen,
Eric Chu, Jonathan&nbsp;H. Clark, Laurent&nbsp;El Shafey, Yanping Huang, Kathy
Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin
Robinson, Sebastian Ruder, Yi&nbsp;Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang,
Gustavo&nbsp;Hernández Ábrego, Junwhan Ahn, Jacob Austin, Paul Barham,
Jan&nbsp;A. Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele
</span><span class="ltx_text" id="bib.bib4.5.2" style="font-size:90%;">Catasta, Yong Cheng, Colin Cherry, Christopher&nbsp;A. Choquette-Choo, Aakanksha
Chowdhery, Clément Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev,
Jacob Devlin, Mark Díaz, Nan Du, Ethan Dyer, Vladimir Feinberg,
Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian
Gehrmann, Lucas Gonzalez, and et&nbsp;al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.6.1" style="font-size:90%;">Palm 2 technical report.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.7.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib4.8.2" style="font-size:90%;">, abs/2305.10403, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.2.2.1" style="font-size:90%;">(5)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.4.1" style="font-size:90%;">
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor
Cai, Eliza Rutherford, Diego de&nbsp;Las&nbsp;Casas, Lisa&nbsp;Anne Hendricks, Johannes
Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van&nbsp;den
Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich
Elsen, Jack&nbsp;W. Rae, Oriol Vinyals, and Laurent Sifre.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.5.1" style="font-size:90%;">Training compute-optimal large language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib5.7.2" style="font-size:90%;">, abs/2203.15556, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.2.2.1" style="font-size:90%;">(6)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.4.1" style="font-size:90%;">
Jack&nbsp;W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann,
H.&nbsp;Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young,
Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell,
George van&nbsp;den Driessche, Lisa&nbsp;Anne Hendricks, Maribeth Rauh, Po-Sen Huang,
Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan
Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu,
Erich Elsen, Siddhant&nbsp;M. Jayakumar, Elena Buchatskaya, David Budden, Esme
</span><span class="ltx_text" id="bib.bib6.5.2" style="font-size:90%;">Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena Martens,
Xiang&nbsp;Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya,
Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau,
Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas
Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien
de&nbsp;Masson&nbsp;d’Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor
Babuschkin, Aidan Clark, Diego de&nbsp;Las&nbsp;Casas, Aurelia Guy, Chris Jones, James
Bradbury, Matthew&nbsp;J. Johnson, Blake&nbsp;A. Hechtman, Laura Weidinger, Iason
Gabriel, William Isaac, Edward Lockhart, Simon Osindero, Laura Rimell, Chris
Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis
Hassabis, Koray Kavukcuoglu, and Geoffrey Irving.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.6.1" style="font-size:90%;">Scaling language models: Methods, analysis &amp; insights from
training gopher.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.7.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib6.8.2" style="font-size:90%;">, abs/2112.11446, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.2.2.1" style="font-size:90%;">(7)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.4.1" style="font-size:90%;">
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi
Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng&nbsp;Lam Tam, Zixuan Ma, Yufei Xue,
Jidong Zhai, Wenguang Chen, Peng Zhang, Yuxiao Dong, and Jie Tang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.5.1" style="font-size:90%;">GLM-130B: an open bilingual pre-trained model.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib7.7.2" style="font-size:90%;">, abs/2210.02414, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.2.2.1" style="font-size:90%;">(8)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.4.1" style="font-size:90%;">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
</span><span class="ltx_text" id="bib.bib8.5.2" style="font-size:90%;">Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave,
and Guillaume Lample.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.6.1" style="font-size:90%;">Llama: Open and efficient foundation language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.7.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib8.8.2" style="font-size:90%;">, abs/2302.13971, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.2.2.1" style="font-size:90%;">(9)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.4.1" style="font-size:90%;">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
Chen, Christopher Dewan, Mona&nbsp;T. Diab, Xian Li, Xi&nbsp;Victoria Lin, Todor
Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit&nbsp;Singh
Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.5.1" style="font-size:90%;">OPT: open pre-trained transformer language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib9.7.2" style="font-size:90%;">, abs/2205.01068, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.2.2.1" style="font-size:90%;">(10)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.4.1" style="font-size:90%;">
Long Ouyang, Jeffrey Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll&nbsp;L. Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
Askell, Peter Welinder, Paul&nbsp;F. Christiano, Jan Leike, and Ryan Lowe.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.5.1" style="font-size:90%;">Training language models to follow instructions with human feedback.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib10.7.2" style="font-size:90%;">NeurIPS</span><span class="ltx_text" id="bib.bib10.8.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.2.2.1" style="font-size:90%;">(11)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.4.1" style="font-size:90%;">
Raymond Li, Loubna&nbsp;Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov,
Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et&nbsp;al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.5.1" style="font-size:90%;">Starcoder: may the source be with you!
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.6.1" style="font-size:90%;">arXiv preprint arXiv:2305.06161</span><span class="ltx_text" id="bib.bib11.7.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.2.2.1" style="font-size:90%;">(12)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.4.1" style="font-size:90%;">
Yujia Li, David&nbsp;H. Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser,
Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin&nbsp;Dal
Lago, Thomas Hubert, Peter Choy, Cyprien de&nbsp;Masson&nbsp;d’Autume, Igor Babuschkin,
Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov,
James Molloy, Daniel&nbsp;J. Mankowitz, Esme&nbsp;Sutherland Robson, Pushmeet Kohli,
Nando de&nbsp;Freitas, Koray Kavukcuoglu, and Oriol Vinyals.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.5.1" style="font-size:90%;">Competition-level code generation with alphacode.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib12.7.2" style="font-size:90%;">, abs/2203.07814, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.2.2.1" style="font-size:90%;">(13)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.4.1" style="font-size:90%;">
Erik Nijkamp, Bo&nbsp;Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio
Savarese, and Caiming Xiong.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.5.1" style="font-size:90%;">Codegen: An open large language model for code with multi-turn
program synthesis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib13.7.2" style="font-size:90%;">The Eleventh International Conference on Learning
Representations</span><span class="ltx_text" id="bib.bib13.8.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.2.2.1" style="font-size:90%;">(14)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.4.1" style="font-size:90%;">
Qinkai Zheng, Xiao Xia, Xu&nbsp;Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang,
Lei Shen, Andi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.5.1" style="font-size:90%;">Codegeex: A pre-trained model for code generation with multilingual
evaluations on humaneval-x.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib14.7.2" style="font-size:90%;">, abs/2303.17568, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.2.2.1" style="font-size:90%;">(15)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.4.1" style="font-size:90%;">
Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi,
Ruiqi Zhong, Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.5.1" style="font-size:90%;">Incoder: A generative model for code infilling and synthesis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib15.7.2" style="font-size:90%;">, abs/2204.05999, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.2.2.1" style="font-size:90%;">(16)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.4.1" style="font-size:90%;">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique&nbsp;Pondé
de&nbsp;Oliveira&nbsp;Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas
Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov,
Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick
Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,
Clemens Winter, Philippe Tillet, Felipe&nbsp;Petroski Such, Dave Cummings,
Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss,
William&nbsp;Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor
Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher
Hesse, Andrew&nbsp;N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa,
Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter
Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
Wojciech Zaremba.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.5.1" style="font-size:90%;">Evaluating large language models trained on code.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib16.7.2" style="font-size:90%;">, abs/2107.03374, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.2.2.1" style="font-size:90%;">(17)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.4.1" style="font-size:90%;">
Yue Wang, Weishi Wang, Shafiq&nbsp;R. Joty, and Steven C.&nbsp;H. Hoi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.5.1" style="font-size:90%;">Codet5: Identifier-aware unified pre-trained encoder-decoder models
for code understanding and generation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.6.1" style="font-size:90%;">In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and
Scott&nbsp;Wen-tau Yih, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib17.7.2" style="font-size:90%;">Proceedings of the 2021 Conference on
Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event
/ Punta Cana, Dominican Republic, 7-11 November, 2021</span><span class="ltx_text" id="bib.bib17.8.3" style="font-size:90%;">, pages 8696–8708.
Association for Computational Linguistics, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.2.2.1" style="font-size:90%;">(18)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.4.1" style="font-size:90%;">
Yue Wang, Hung Le, Akhilesh&nbsp;Deepak Gotmare, Nghi D.&nbsp;Q. Bui, Junnan Li, and
Steven C.&nbsp;H. Hoi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.5.1" style="font-size:90%;">Codet5+: Open code large language models for code understanding and
generation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib18.7.2" style="font-size:90%;">, abs/2305.07922, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.2.2.1" style="font-size:90%;">(19)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.4.1" style="font-size:90%;">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J. Liu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.5.1" style="font-size:90%;">Exploring the limits of transfer learning with a unified text-to-text
transformer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.6.1" style="font-size:90%;">J. Mach. Learn. Res.</span><span class="ltx_text" id="bib.bib19.7.2" style="font-size:90%;">, 21:140:1–140:67, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.2.2.1" style="font-size:90%;">(20)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.4.1" style="font-size:90%;">
</span><span class="ltx_text" id="bib.bib20.5.2" style="font-size:90%;">Jason Wei, Maarten Bosma, Vincent&nbsp;Y. Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian
Lester, Nan Du, Andrew&nbsp;M. Dai, and Quoc&nbsp;V. Le.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.6.1" style="font-size:90%;">Finetuned language models are zero-shot learners.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.7.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib20.8.2" style="font-size:90%;">The Tenth International Conference on Learning
Representations, ICLR 2022, Virtual Event, April 25-29, 2022</span><span class="ltx_text" id="bib.bib20.9.3" style="font-size:90%;">.
OpenReview.net, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.2.2.1" style="font-size:90%;">(21)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.4.1" style="font-size:90%;">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus,
Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson,
Shixiang&nbsp;Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha
Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent&nbsp;Y. Zhao, Yanping
Huang, Andrew&nbsp;M. Dai, Hongkun Yu, Slav Petrov, Ed&nbsp;H. Chi, Jeff Dean, Jacob
Devlin, Adam Roberts, Denny Zhou, Quoc&nbsp;V. Le, and Jason Wei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.5.1" style="font-size:90%;">Scaling instruction-finetuned language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib21.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib21.7.2" style="font-size:90%;">, abs/2210.11416, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.2.2.1" style="font-size:90%;">(22)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.4.1" style="font-size:90%;">
Vamsi Aribandi, Yi&nbsp;Tay, Tal Schuster, Jinfeng Rao, Huaixiu&nbsp;Steven Zheng,
Sanket&nbsp;Vaibhav Mehta, Honglei Zhuang, Vinh&nbsp;Q. Tran, Dara Bahri, Jianmo Ni,
Jai&nbsp;Prakash Gupta, Kai Hui, Sebastian Ruder, and Donald Metzler.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.5.1" style="font-size:90%;">Ext5: Towards extreme multi-task scaling for transfer learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib22.7.2" style="font-size:90%;">The Tenth International Conference on Learning
Representations, ICLR 2022, Virtual Event, April 25-29, 2022</span><span class="ltx_text" id="bib.bib22.8.3" style="font-size:90%;">.
OpenReview.net, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.2.2.1" style="font-size:90%;">(23)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.4.1" style="font-size:90%;">
Victor Sanh, Albert Webson, Colin Raffel, Stephen&nbsp;H. Bach, Lintang Sutawika,
Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey,
M&nbsp;Saiful Bari, Canwen Xu, Urmish Thakker, Shanya&nbsp;Sharma Sharma, Eliza
Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal&nbsp;V. Nayak, Debajyoti Datta,
Jonathan Chang, Mike&nbsp;Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,
Zheng&nbsp;Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj,
Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Févry, Jason&nbsp;Alan
Fries, Ryan Teehan, Teven&nbsp;Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and
Alexander&nbsp;M. Rush.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.5.1" style="font-size:90%;">Multitask prompted training enables zero-shot task generalization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib23.7.2" style="font-size:90%;">The Tenth International Conference on Learning
Representations, ICLR 2022, Virtual Event, April 25-29, 2022</span><span class="ltx_text" id="bib.bib23.8.3" style="font-size:90%;">.
OpenReview.net, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.2.2.1" style="font-size:90%;">(24)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.4.1" style="font-size:90%;">
Hanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Yanggang Wang, Haiyu Li, and Zhilin
Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.5.1" style="font-size:90%;">Zeroprompt: Scaling prompt-based pretraining to 1, 000 tasks improves
zero-shot generalization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.6.1" style="font-size:90%;">In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib24.7.2" style="font-size:90%;">Findings of the Association for Computational Linguistics: EMNLP 2022, Abu
Dhabi, United Arab Emirates, December 7-11, 2022</span><span class="ltx_text" id="bib.bib24.8.3" style="font-size:90%;">, pages 4235–4252.
Association for Computational Linguistics, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.2.2.1" style="font-size:90%;">(25)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.4.1" style="font-size:90%;">
Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord,
Peter Clark, and Hannaneh Hajishirzi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.5.1" style="font-size:90%;">Unifiedqa: Crossing format boundaries with a single QA system.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.6.1" style="font-size:90%;">In Trevor Cohn, Yulan He, and Yang Liu, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib25.7.2" style="font-size:90%;">Findings of the
Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20
November 2020</span><span class="ltx_text" id="bib.bib25.8.3" style="font-size:90%;">, volume EMNLP 2020 of </span><span class="ltx_text ltx_font_italic" id="bib.bib25.9.4" style="font-size:90%;">Findings of ACL</span><span class="ltx_text" id="bib.bib25.10.5" style="font-size:90%;">, pages
1896–1907. Association for Computational Linguistics, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.2.2.1" style="font-size:90%;">(26)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.4.1" style="font-size:90%;">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.5.1" style="font-size:90%;">Stanford alpaca: An instruction-following llama model.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" style="font-size:90%;" title="">https://github.com/tatsu-lab/stanford_alpaca</a><span class="ltx_text" id="bib.bib26.6.1" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.2.2.1" style="font-size:90%;">(27)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.4.1" style="font-size:90%;">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A Smith, Daniel
Khashabi, and Hannaneh Hajishirzi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.5.1" style="font-size:90%;">Self-instruct: Aligning language model with self generated
instructions.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.6.1" style="font-size:90%;">arXiv preprint arXiv:2212.10560</span><span class="ltx_text" id="bib.bib27.7.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.2.2.1" style="font-size:90%;">(28)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.4.1" style="font-size:90%;">
Wei-Lin Chiang, Zhuohan Li, Zi&nbsp;Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
</span><span class="ltx_text" id="bib.bib28.5.2" style="font-size:90%;">Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph&nbsp;E. Gonzalez, Ion Stoica, and
Eric&nbsp;P. Xing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.6.1" style="font-size:90%;">Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt
quality, March 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.2.2.1" style="font-size:90%;">(29)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.4.1" style="font-size:90%;">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu&nbsp;Zhao, Jiazhan Feng, Chongyang
Tao, and Daxin Jiang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.5.1" style="font-size:90%;">Wizardlm: Empowering large language models to follow complex
instructions.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib29.6.1" style="font-size:90%;">arXiv preprint arXiv:2304.12244</span><span class="ltx_text" id="bib.bib29.7.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.2.2.1" style="font-size:90%;">(30)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.4.1" style="font-size:90%;">
Sahil Chaudhary.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.5.1" style="font-size:90%;">Code alpaca: An instruction-following llama model for code
generation.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sahil280114/codealpaca" style="font-size:90%;" title="">https://github.com/sahil280114/codealpaca</a><span class="ltx_text" id="bib.bib30.6.1" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib31.2.2.1" style="font-size:90%;">(31)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.4.1" style="font-size:90%;">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique&nbsp;Pondé
de&nbsp;Oliveira&nbsp;Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas
Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov,
Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick
Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,
Clemens Winter, Philippe Tillet, Felipe&nbsp;Petroski Such, Dave Cummings,
</span><span class="ltx_text" id="bib.bib31.5.2" style="font-size:90%;">Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss,
William&nbsp;Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor
Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher
Hesse, Andrew&nbsp;N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa,
Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter
Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
Wojciech Zaremba.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.6.1" style="font-size:90%;">Evaluating large language models trained on code.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib31.7.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib31.8.2" style="font-size:90%;">, abs/2107.03374, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib32.2.2.1" style="font-size:90%;">(32)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.4.1" style="font-size:90%;">
Jiawei Liu, Chunqiu&nbsp;Steven Xia, Yuyao Wang, and Lingming Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.5.1" style="font-size:90%;">Is your code generated by chatgpt really correct? rigorous evaluation
of large language models for code generation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib32.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib32.7.2" style="font-size:90%;">, abs/2305.01210, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib33.2.2.1" style="font-size:90%;">(33)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.4.1" style="font-size:90%;">
Jacob Austin, Augustus Odena, Maxwell&nbsp;I. Nye, Maarten Bosma, Henryk
Michalewski, David Dohan, Ellen Jiang, Carrie&nbsp;J. Cai, Michael Terry, Quoc&nbsp;V.
Le, and Charles Sutton.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.5.1" style="font-size:90%;">Program synthesis with large language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib33.7.2" style="font-size:90%;">, abs/2108.07732, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib34.2.2.1" style="font-size:90%;">(34)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.4.1" style="font-size:90%;">
Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi Zhong, Luke
</span><span class="ltx_text" id="bib.bib34.5.2" style="font-size:90%;">Zettlemoyer, Scott&nbsp;Wen-tau Yih, Daniel Fried, Sida&nbsp;I. Wang, and Tao Yu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.6.1" style="font-size:90%;">DS-1000: A natural and reliable benchmark for data science code
generation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib34.7.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib34.8.2" style="font-size:90%;">, abs/2211.11501, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib35.2.2.1" style="font-size:90%;">(35)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.4.1" style="font-size:90%;">
Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence
Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler,
USVSN&nbsp;Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben
Wang, and Samuel Weinbach.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.5.1" style="font-size:90%;">Gpt-neox-20b: An open-source autoregressive language model.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib35.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib35.7.2" style="font-size:90%;">, abs/2204.06745, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib36.2.2.1" style="font-size:90%;">(36)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.4.1" style="font-size:90%;">
Ben Wang and Aran Komatsuzaki.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.5.1" style="font-size:90%;">GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kingoflolz/mesh-transformer-jax" style="font-size:90%;" title="">https://github.com/kingoflolz/mesh-transformer-jax</a><span class="ltx_text" id="bib.bib36.6.1" style="font-size:90%;">, May 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib37.2.2.1" style="font-size:90%;">(37)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.4.1" style="font-size:90%;">
Yi&nbsp;Tay, Mostafa Dehghani, Vinh&nbsp;Q. Tran, Xavier Garcia, Dara Bahri, Tal
Schuster, Huaixiu&nbsp;Steven Zheng, Neil Houlsby, and Donald Metzler.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.5.1" style="font-size:90%;">Unifying language learning paradigms.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib37.6.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib37.7.2" style="font-size:90%;">, abs/2205.05131, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib38.2.2.1" style="font-size:90%;">(38)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.4.1" style="font-size:90%;">
</span><span class="ltx_text" id="bib.bib38.5.2" style="font-size:90%;">Microsoft.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.6.1" style="font-size:90%;">Azure openai service models.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models" style="font-size:90%;" title="">https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models</a><span class="ltx_text" id="bib.bib38.7.1" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib39.2.2.1" style="font-size:90%;">(39)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.4.1" style="font-size:90%;">
Llm humaneval benchmarks.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/my-other-github-account/llm-humaneval-benchmarks" style="font-size:90%;" title="">https://github.com/my-other-github-account/llm-humaneval-benchmarks</a><span class="ltx_text" id="bib.bib39.5.1" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib40.2.2.1" style="font-size:90%;">(40)</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.4.1" style="font-size:90%;">
Romal Thoppilan, Daniel&nbsp;De Freitas, Jamie Hall, Noam Shazeer, Apoorv
Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu&nbsp;Du,
YaGuang Li, Hongrae Lee, Huaixiu&nbsp;Steven Zheng, Amin Ghafouri, Marcelo
Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao
Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou,
Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen&nbsp;S.
Meier-Hellstern, Meredith&nbsp;Ringel Morris, Tulsee Doshi, Renelito&nbsp;Delos
Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran,
Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin
Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew
Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray
Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed&nbsp;H. Chi, and
</span><span class="ltx_text" id="bib.bib40.5.2" style="font-size:90%;">Quoc Le.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.6.1" style="font-size:90%;">Lamda: Language models for dialog applications.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib40.7.1" style="font-size:90%;">CoRR</span><span class="ltx_text" id="bib.bib40.8.2" style="font-size:90%;">, abs/2201.08239, 2022.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Jul 13 18:39:44 2023 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="></a>
</div></footer>
</div>


</body></html>