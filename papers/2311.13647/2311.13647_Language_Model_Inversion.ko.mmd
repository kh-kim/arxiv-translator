# 언어 모델 반전

존 엑스 모리스, 원팅 자오, 저스틴 T. 추, 비탈리 슈마티코프, 알렉산더 러쉬

고려대학교 컴퓨터학과

Cornell University

###### Abstract

언어 모델은 다음 토큰에 대한 분포를 생성합니다. 이를 사용하여 프롬프트 토큰을 복구할 수 있습니까? 우리는 언어 모델 역산의 문제를 고려하고 다음 토큰 확률에 이전 텍스트에 대한 놀라운 양의 정보가 포함되어 있음을 보여준다. 종종 텍스트가 사용자에게 숨겨져 있는 경우 텍스트를 복구할 수 있으며, 모델의 현재 배포 출력만 주어지면 알려지지 않은 프롬프트를 복구하는 방법에 동기를 부여할 수 있습니다. 다양한 모델 접근 시나리오를 고려하고, 어휘의 모든 토큰에 대한 예측이 없더라도 검색을 통해 확률 벡터를 복구할 수 있는 방법을 보여준다. Llama-2 (b)에서 우리의 역산 방법은 BLEU가 \(59\)이고 토큰 레벨 F1이 \(78\)인 프롬프트를 재구성하고 프롬프트의 \(27\%\)를 정확히 복구한다.1

각주 1: 모든 실험을 재현하기 위한 코드는 github.com/jxmorris12/vec2text에서 사용할 수 있습니다. 프롬프트의 데이터 세트는 종이 출판 시 제공됩니다.

## 1 Introduction

언어 모델들은 자동 회귀(autoregressive)이고, 각각의 다음 토큰의 확률을 선행 텍스트에 조건화된 시퀀스로 출력한다. 이 분배는 시퀀스에서 미래의 토큰을 생성하는 데 사용된다. 이 분포를 프롬프트를 재구성하는 데에도 사용할 수 있습니까?

대부분의 맥락에서 이 질문은 무의미합니다. 왜냐하면 우리는 이미 이 정보를 조건화했기 때문입니다. 그러나, 점점 더 많은 언어 모델들은 사용자가 출력들에 액세스할 수 있지만, 진정한 프롬프트의 전부는 아닐 수 있는 "서비스로서" 제공되고 있다. 이러한 맥락에서, 사용자는 프롬프트를 알고, 아마도 서비스 제공자가 이를 보호하는 것이 흥미로울 수 있다. 이 목표는 프롬프트를 드러내기 위해 모델의 전방 텍스트 생성을 사용하려고 시도하는 "감옥 파괴" 접근법의 초점이었다.

우리는 프롬프트 재구성의 이 문제를 언어 모델의 다음 토큰 확률에 조건화된 입력 프롬프트를 복구하는 _언어 모델 반전_으로 공식화한다. 흥미롭게도 컴퓨터 비전에 대한 연구는 이미지 분류기의 확률 예측이 놀라운 양의 세부 사항을 유지한다는 것을 보여주었으므로(도소비츠키 & 브록스, 2016), 이것이 언어 모델에도 적용된다는 것이 그럴듯하다. 본 논문에서는 미리 학습된 인코더-디코더 언어 모델에 의해 효과적으로 처리될 수 있는 시퀀스로 분포 벡터를 "언롤링"함으로써 프롬프트를 예측하는 아키텍처를 제안한다. 이 방법은 언어 모델 예측이 대부분 되돌릴 수 없다는 것을 처음으로 보여준다: 많은 경우, 우리는 원문과 매우 유사한 입력을 복구할 수 있으며, 때때로 입력 텍스트를 정확하게 되돌릴 수 있다.

우리는 또한 완전한 다음 토큰 확률 출력, top-K 확률, 요청 시 토큰당 확률 및 이산 샘플링과 같은 실제 액세스 패턴의 스펙트럼에 걸쳐 신속한 복구의 가능성을 탐구한다. 우리는 모델로부터 출력된 텍스트만을 관찰할 수 있는 경우(확률 없음)에서도 프롬프트를 재구성하기에 충분한 확률 분포를 복구할 수 있음을 발견한다.

우리의 결과는 언어 모델에 대한 텍스트 전용 액세스를 제공하는 시스템이 프롬프트에 대한 정보를 드러낸다는 것을 보여준다. 충분한 질의로 주어진 위치에서 다음 토큰 확률을 추출할 수 있으며, 이는 입력을 재구성하는 데 사용될 수 있다. 텍스트 기반 탈옥과 달리 밀도 분포 역산은 모델을 정렬하기 위해 RLHF와 같은 사전 훈련 후 강화 학습 기술에 의해 덜 억제된다. 또한, 본 논문에서 제안한 역산 기법이 같은 계열의 모델들 간에 전달됨을 보이고, 언어 모델 스케일링에 영향을 받지 않음을 보인다.

## 2 관련 작업

**역전 딥 임베딩** 컴퓨터 비전의 여러 작업 라인에 따르면 입력은 이미지 분류기(Mahendran and Vedaldi, 2014; Dosovitskiy and Brox, 2016; Teterwak et al., 2021)의 로짓 또는 자체 감독 표현 벡터(Bordes et al., 2021)로부터 대략 재구성될 수 있다. 일부 최근 작업(Takahashi et al., 2023)은 컴퓨터 비전 모델의 출력이 연합 학습 설정에서 공유될 때 개인 정보를 드러낼 수 있음을 보여주었다. 또한 NLP: Song and Raghunathan (2020); Li et al. (2023); Morris et al. (2023)은 인코더 모델로부터 텍스트 임베딩의 프라이버시 누출을 조사한다. Morris et al. (2023)은 역산을 위해 인코더-디코더 트랜스포머의 인코더를 컨디셔닝함으로써 그들의 임베딩으로부터 전체 텍스트 시퀀스들을 복구하는데 성공한다. 우리의 것은 언어 모델의 확률 출력에서 직접 반전하는 첫 번째 작업이다.

**모델 반전 및 멤버 자격 추론.** 모델의 출력이 주어지면 _모델 반전_ 은 해당 출력을 생성하는 입력을 구성하는 것을 목표로 합니다. 이 문제는 (Fredrikson et al., 2014, 2015)의 단순 회귀 분류기에 대해 조사되었고 (Zhang et al., 2020)의 신경 얼굴 인식 분류기로 확장되었다. 일부 경우에, 모델 역산은 훈련 데이터를 복구하는 데 도움이 될 수 있다. 예를 들어, 얼굴 인식 분류기들에서 각각의 클래스는 단일 인물에 대응하고, 따라서 모델 반전에 의해 복구된 임의의 이미지는 동일한 클래스 라벨에 대한 트레이닝 이미지들과 시각적으로 유사하다. (Zhang et al., 2022)는 사전 트레이닝된 언어 모델들로부터 암기된 트레이닝 데이터를 복구하기 위해 모델 반전 기법들을 사용하였다. 관련 문제는 _멤버십 추론_ 입니다. 데이터 포인트가 주어지면 모델의 훈련 데이터의 일부인지 여부를 결정합니다 (Shokri et al., 2017). Duan et al.(2023)은 in-context learning을 위한 membership inference를 시연하였다.

신속한 역산은 모델 역산의 한 형태이지만 이전 모델 역산 작업에서 연구된 분류기보다 입력의 차원이 훨씬 더 높은 훨씬 더 복잡한 언어 모델로 작업한다. 학습 데이터에 대한 정보를 복구하는 대신 모델에 주어진 특정 프롬프트를 복구하여 학습 데이터와 관련된 정보를 필터링하는 것을 목표로 한다.

**모델 훔치기** 언어 모델이 점점 더 가치가 높아짐에 따라 점점 더 엄격한 보호 장치 뒤에 숨겨집니다. '모델 훔치기'에 대한 연구는 API 쿼리를 통해 모델 자체가 복제될 수 있는 방법을 탐구하는 것을 목표로 한다(Tramer et al., 2016). NLP 모델을 훔치는 것은 선형 텍스트 기반 분류(Lowd and Meek, 2005), 언어 분류(Pal et al., 2019; Krishna et al., 2020), 기계 번역 Wallace et al., (2021), 및 심지어 텍스트 리트레이벌(Dziedzic et al., 2023)의 많은 도메인에서 입증되었다. 최근 Gudibande et al.(2023)은 이러한 형태의 모방이 표면 수준의 구문을 복제하지만 지식이나 사실성과 같은 더 복잡한 속성을 학습하지 않는 모델을 생성할 수 있음을 시사한다. 이러한 작업과 달리 우리는 제3자 모델 출력에서 모델 가중치를 재구성하는 데 중점을 두지 않고 제3자 모델의 출력에서 숨겨진 프롬프트를 찾는다.

그림 1: 언어 모델이 다음 단어 확률을 생성하는 숨겨진 접두사 프롬프트를 갖는 서비스로서 제공된다는 가정 하에서, 시스템은 언어 모델을 반전시키기 위해, 즉 다음 토큰에 대한 프롬프트가 주어진 언어 모델 확률을 복구하기 위해 샘플들로부터 트레이닝된다.

Prompt Reconstruction

언어 모델은 이전에 온 토큰에 대해 조건화된 다음 토큰의 확률을 제공합니다. 즉, \(\mathbf{v}=p(x_{T+1}\mid x_{1},...,x_{T};\theta)\), 여기서 \(\mathbf{v}\in\Delta^{|\mathcal{V}|-1}\)는 가능한 다음 토큰 각각에 대한 확률을 제공합니다. 일반적으로 이러한 모델은 어휘의 크기가 비교적 크며, 어휘 \(\mathcal{V}\)는 수십만 개 또는 수십만 개의 요소를 포함할 수 있다.

### Logits contains residual information

LM 로짓이 입력에 대해 전달할 수 있는 정보의 양을 입증하기 위해 간단한 실험을 구성한다. 위키피디아에서 100개의 텍스트 입력을 주어 첫 번째 문장에서 하나의 단어를 동의어 2로 치환한다. \(\hat{x}_{s}\)를 단어 \(x_{s}\)의 동의어로 하자. 원본 수열( \(x_{s}\) 포함)과 새로운 수열( \(\hat{x_{s}}\) 포함) 사이의 언어 모델 출력 변화를 측정하기 위해, 원수열과 동의어 교환 수열에 대한 \(p\)의 확률 출력 사이의 KL 발산량과 16비트 정밀도로 표현될 때 두 분포 사이의 비트 수준 해밍 거리의 두 양을 계산한다.

각주 2: GPT-4를 사용하여 동의어 스와프를 수행합니다. 이 실험에 대한 자세한 내용은 부록 D에 나와 있습니다.

그림 2에서 동의어 스왑의 위치에 대한 KL과 비트별 해밍 거리를 표시한다. LMs에 이전 단어에 대한 잔차 정보가 포함되지 않은 경우 스왑의 위치에서 멀어질수록 비트별 거리가 0으로 감소할 것으로 예상한다. 그러나 벡터 \(\mathbf{v}\)는 다음 토큰을 예측하는 데만 사용되지만 프롬프트 토큰 \(x_{1},...,x_{T}\)에 대한 잔차 정보를 분명히 포함한다. KL은 가장 높은 가능성 토큰에 대부분의 비중을 두기 때문에 0으로 붕괴할 수 있는 반면, 정보의 대부분은 낮은 가능성 토큰에 남아 있다.

### Prompt Reconstruction

우리는 이제 과정을 뒤집는 문제를 고려한다: 확률 벡터가 주어지면, 우리는 이러한 다음 토큰 확률로 이어지는 프롬프트를 생성하려고 시도한다. 다음 토큰 확률을 제공하는 보이지 않는 모델 \(f:\mathcal{V}^{T}\rightarrow\Delta^{|\mathcal{V}|-1}\)이 주어졌을 때, 우리는 텍스트 접두사 쌍과 관련된 다음 토큰 확률 벡터 \((x_{1:T}^{1},\mathbf{v}^{1})\ldots(x_{1:T}^{J},\mathbf{v}^{J})\로부터 이 함수를 반전시키는 방법을 학습하고자 한다.

출력에서 반전?확률 벡터에서 반전하는 것 외에도 고려해야 할 자연적인 절차는 언어 모델의 출력에서 프롬프트를 직접 예측하는 것이다. 예를 들어, 모델 출력 "보고타"가 주어지면, 우리는 입력 "컬럼비아의 수도는 무엇인가?"를 예측할 수 있다. 단일 로짓 벡터에 이러한 벡터의 argmax에서 샘플링된 단일 서열보다 프롬프트에 대한 훨씬 더 자세한 정보가 포함되어 있다고 가정한다. 그러나 섹션 6에 설명된 _샘플 인버터_ 기준선에서 이 시나리오를 고려한다.

즉각적인 데이터셋을 구축하기 위해 사용자 및 시스템 프롬프트를 포함한 2.33M 명령어들로 구성된 메타 데이터셋인 Instructions-2M을 구축한다. 이는 Supernatural Instructions(Wang et al., 2022), Self Instructions(Wang et al., 2023), Alpaca(Taori et al., 2023), Dolly3, ShareGPT4, Unnatural Instructions(Honovich et al., 2023), ChatBot Arena5. Stable Diffusion Dataset6, WizardLM instructions(Xu et al., 2023; Luo et al., 2023), GPTeacher7,

그림 2: \(\log\mathbf{v}\)의 장기 정보입니다.

T0(Chung et al., 2022), LaMini instruction(Wu et al., 2023). 또한 영역 외 프롬프트를 수집하여 모델이 국소 영역에서 일반화하는 능력을 테스트한다.

우리의 위협 모델에 대한 가정.우리는 서비스로서의 언어 모델의 보급으로 이 문제에 동기를 부여한다. 이러한 사용 사례에서 _prompt_ 로 알려진 알려지지 않은 접두사 시퀀스가 사용자 입력에 미리 붙여져 있다고 가정합니다. 우리는 다양한 수준의 모델 접근, 즉 전체 분포 접근, 부분 분포 접근(top-K 또는 요청에 의해), 사용자 정의 로짓 편향이 있는 텍스트 출력, 텍스트 출력 액세스만을 고려한다. 모델 가중치 또는 활성화에 대한 액세스가 없다고 가정합니다.

## 4 방법: 확률을 반전시키는 학습

제안된 방법은 다음 토큰 확률로부터 토큰: \(p(x_{1:T}\mid\mathbf{v})\)로 매핑되는 조건부 언어 모델을 학습하는 것이다. 사전 훈련된 트랜스포머 언어 모델을 사용하여 이 분포를 매개변수화하고 무조건 모델의 샘플에 대해 훈련한다. 특징 레벨 컨디셔닝에 대한 Dumoulin et al.(2018)의 작업에 따라, 우리는 인코더-디코더 트랜스포머에서 교차 주목(cross-attention)을 사용하여 다음 토큰 벡터를 컨디셔닝한다.

본 논문에서 제안한 인코더 모델은 텍스트에 미리 학습되어 있으므로, 언어 인코더로 전송되기 위해서는 \(\mathbf{v}\)를 재편집해야 한다. 가장 간단한 방법은 \(\mathbf{v}\)를 \(\mathbb{R}^{d}\)에 투영하여 입력 은닉 벡터로 공급하는 것이다. 그러나 어휘의 크기가 큰 \(|\mathcal{V}|\)과 소프트맥스(softmax)를 통과한다는 사실을 고려할 때, 이는 큰 순위 감소와 정보 손실의 원인이 된다. 대신에 벡터를 의사 임베딩의 시퀀스 \(\mathbf{c}_{i}\in\mathbb{R}^{d}\)로 '언롤'하여 전체 확률 벡터 \(\mathbf{v}\)에 대한 변압기 출력을 조건화할 수 있다.

각주 8: 부록 G. 1의 절제 실험을 통해 이 투영의 변형을 탐구한다.

\[\mathbf{c}_{i} = \text{MLP}_{i}(\log(\mathbf{v}_{d(i-1):di}))\;\;\forall\;i\in \{1\dots\lceil|\mathcal{V}|/d\rceil\}\] \[x^{*} = \arg\max_{x}\text{Dec}(x,\text{Enc}(\mathbf{c}))\

여기서, \(x^{*}\)는 예측된 반전이고, \(d\)는 임베딩 차원이며, \(\mathbf{v}\)는 최종 위치에 0으로 패딩된다. 실제 실험에서는 \(|\mathcal{V}|=32000\)와 \(d=768\)를 사용하여 \(42\) 단어의 고정 길이 입력 시퀀스를 유도한다.

## 5 API를 통해 로짓 추출

이전 섹션에서는 전체 언어 모델 출력 확률 벡터에 액세스할 수 있다고 가정합니다. 그러나 많은 언어 모델 플랫폼은 API 호출에서 반환되는 정보를 제한한다. 예를 들어 잘 알려진 서비스의 API는 샘플 또는 상위 5개 로그 확률만 노출하지만 주어진 입력에 대한 모든 출력 확률은 노출하지 않습니다.

따라서 우리는 전체 확률 분포를 즉시 사용할 수 없는 API에서 다음 토큰 확률을 추출하는 방법을 제안한다. API 서비스가 전체 확률을 반환하지 않는 경우에도 일반적으로 사용자가 _logit bias_ 를 추가하여 분포를 조정할 수 있다는 점을 활용합니다. API 호출당 로짓 바이어스를 제공하는 것 외에도, 이들은 일반적으로 분포의 argmax를 제공하기 위해 온도 파라미터를 제로로 설정하는 것을 허용한다.

따라서 각 토큰의 확률은 가장 가능성이 높은 단어와의 차이를 찾아냄으로써 회복될 수 있다. 우리는 그 단어를 가장 가능성 있게 만들기 위해 가장 작은 로짓 편향을 찾아 이 차이를 계산한다. 알고리즘 1은 각 단어에 대한 로짓 편향을 찾기 위해 이진 검색에 의존하는 접근법을 보여준다.

바이너리 탐색은 각 단어에 대해 독립적으로 수행될 수 있어, 완전한 병렬화를 가능하게 하고 한 번에 단일 로짓 바이어스만을 필요로 한다는 점에 유의한다. 어휘의 각 단어에 대해 이 절차를 실행하면 전체 분포 \(\mathbf{v}=\text{softmax}(\text{logits})\)를 재구성할 수 있다. 배포를 결정하기 위한 필요한 쿼리 수는 \(|\mathcal{V}|\) times the number of bits required to represent the desired precision.9```
procedureApi_Argmax(\(i,b\)) return\(\arg\max[\log\mathbf{v}_{0},\ldots,\log\mathbf{v}_{i}+b,\ldots]\)\(\triangleright\) Argmax of hidden \(\mathbf{v}\) with bias \(i\) procedureFindLogit(\(i\leftarrow\epsilon\)\(\triangleright\) upper bound to initialization \(\epsilon>0\) whileApl_Argmax(\(i,U\)) \(\neq i\)do\(\triangleright\) lower bound \(L\gets 0\)\(L+U)/2\) while\(U-L>\delta\)do\(\triangleright\) ifApl_Argmax(\(i,M\) upweighted \(i\) ifApl_Argmax(\(i,M\)) \(=i\)then\
```

**알고리즘 1** 각 단어에 대한 이진 검색을 통한 로짓 추출 \(i\)

## 6 실험 설정

모델.우리는 모델을 훈련시켜 Llama-2(7B) 및 Llama-2 Chat(7B)의 분포를 반전시킨다(Touvron et al., 2023). 출판 시점 현재 7B 매개변수 규모에서 가장 성능이 좋은 오픈 소스 LLM이기 때문에 이 모델을 선택한다. 우리는 온도 \(0\)로 설정하고 단일 로짓 바이어스 인수를 제공하는 섹션 7의 분포 추출 실험 동안을 제외하고 모델 출력 확률에 완전히 액세스한다고 가정한다.

우리는 4절에서 설명한 방법을 사용하여 역산 모델을 매개변수화하고 \(222M\) 매개변수를 갖는 인코더-디코더 백본으로 T5-베이스(Raffel et al., 2020)를 선택한다. 우리는 모든 실험에 대해 최대 시퀀스 길이를 \(64\)로 설정했다. 우리는 학습률이 \(2e-4\)인 Adam Optimizer를 사용하여 \(100\) epoch에 대한 모델을 학습한다. 첫 번째 \(25,000\) 훈련 단계에서 선형 웜업과 함께 일정한 학습률을 사용한다. 우리는 bfloat16 정밀 훈련을 한다.

메트릭스.우리는 신속한 재구성을 위한 몇 가지 메트릭스: 토큰 레벨에서의 F1 스코어, 스트링 중첩의 척도로서 BLEU 스코어(Papineni et al., 2002), 및 정확한 일치를 고려한다. 또한 의미적 연관성의 척도로 원본 텍스트와 복원된 텍스트의 임베딩 사이의 코사인 유사도를 고려한다. 코사인 유사성에 대해서는 OpenAI API(Neelakantan et al., 2022)를 통해 입수 가능한 모델 텍스트-embeddings-ada-002로부터의 임베딩을 사용한다. 각 메트릭에 대해 오차 범위를 평균(SEM)의 표준 오차로 보고합니다.

우리는 테스트를 위해 훈련 데이터의 \(1\%\)를 무작위로 유지한다. 인간이 작성한 프롬프트의 두 데이터 세트, 즉 Alpaca의 코드 프롬프트(Taori et al., 2023)와 Bai et al.(2022)에서 수집한 유용성과 무해성 데이터에서 추출한 프롬프트를 추가로 평가한다. 두 데이터 세트는 전체 통합 훈련 데이터 세트보다 더 좁고 다른 분포에서 추출된다.

기준.우리는 언어 모델 확률에서 직접 텍스트를 반전시키는 것을 고려하는 첫 번째 작업이기 때문에 비교할 이전 기준선이 없다. 따라서 몇 가지 기준선을 개발합니다.

* _재발 문자열입니다._ 인간이 쓴 수열은 언어 모델을 설득하여 수열의 초기 정보를 누설하려고 시도한다. 수동으로 작성하는 것을 포함하여 다양한 출처에서 탈옥 문자열을 수집합니다. 우리는 표에서 가장 높은 탈옥 문자열만 보여주고 부록에 더 많은 결과를 포함한다. 우리는 \(20\) 탈옥 문자열을 소스하여 모든 모델에서 테스트합니다. 사전 훈련된 라마 모델의 경우 탈옥 문자열이 프롬프트에 간단히 추가됩니다. 채팅 모델의 경우 숨겨진 프롬프트를 시스템 명령으로 입력하고 모델에 숨겨진 프롬프트를 누설하지 않도록 지시하는 기본 시스템 명령을 입력한다. 그런 다음 탈옥 문자열을 사용자 프롬프트로 입력한다. 결과를 보고할 때 모든 프롬프트의 평균 성능과 평가 후 선택한 테스트 데이터 세트에서 가장 성능이 좋은 탈옥 문자열을 나타내는 오라클 수치를 보고한다.

* _GPT-4 Few-shot._ 우리는 Llama-2 입력 예측의 확률로 top-K 토큰의 예를 사용하여 GPT-4를 프롬프트한다. 이러한 예제 입력-출력 쌍은 숨겨진 입력에 대한 상위 확률에 미리 붙여집니다.
* _샘플 인버터._ 다음 토큰 확률에서 반전하는 대신 LM에서 텍스트 출력 샘플에서 프롬프트를 예측할 수 있는지 여부를 고려한다. 이 모델을 학습하기 위해 Llama-2 7b 채팅에서 출력을 샘플링하고 주어진 언어 모델 출력에서 입력 프롬프트를 예측하기 위해 T5 기반 인코더-디코더를 학습한다.

## 7 Results

표 1은 원시 LLM 및 RLHF Chat 변이체 모두에 대한 지침-2M 테스트 세트의 역전 프롬프트에 대한 실험의 주요 결과를 보여준다. 본 논문에서 제안한 방법은 실제 프롬프트로 높은 BLEU 점수를 얻을 수 있으며, 높은 정확도의 일치 재현을 얻을 수 있음을 보인다. 이 접근법은 GPT-4를 사용하는 경우에도 적은 샷 프롬프트 접근법보다 훨씬 우수하다. 다른 훈련된 접근법(샘플 인버터)은 적절한 BLEU를 갖지만 정확한 복구율은 0이다. 샘플 역산의 실패는 argmax 출력 단독보다 로짓 벡터에서 프롬프트에 대한 더 유용한 정보를 추출할 수 있음을 나타낸다.

수동으로 작성된 탈옥 문자열과 비교하여 우리의 접근법은 오라클 탈옥 방법과 비교할 수 있는 평균값보다 훨씬 우수하다. 특히, 최상의 탈옥 방법은 원시 LM에서 잘 작동하지만, 탈옥 접근법 중 어느 것도 RLHF 채팅 버전에서 작동하지 않는다. 비채팅 모델(\(59\) vs. \ (52\) mean BLEU), indi

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline  & & \multicolumn{4}{c}{Instructions-2M} \\  & & BLEU & CS & Exact & Token F1 \\ \hline \multirow{8}{*}{2000} & Sample inverter & \(25.55_{\pm 0.89}\) & \(90.2_{\pm 0.4}\) & \(0.0_{\pm 0.0}\) & \(65.1_{\pm 1.5}\) \\  & Few-shot (GPT-3.5) & \(4.00_{\pm 0.43}\) & \(77.9_{\pm 0.4}\) & \(0.0_{\pm 0.0}\) & \(19.4_{\pm 0.9}\) \\  & Few-shot (GPT-4) & \(6.07_{\pm 0.59}\) & \(79.3_{\pm 0.4}\) & \(0.0_{\pm 0.0}\) & \(25.4_{\pm 1.1}\) \\  & Jailbreak (mean) & \(10.23_{\pm 1.22}\) & \(80.1_{\pm 0.4}\) & \(0.0_{\pm 0.0}\) & \(25.0_{\pm 1.5}\) \\  & Jailbreak (oracle) & \(14.88_{\pm 1.42}\) & \(82.0_{\pm 0.4}\) & \(0.0_{\pm 0.0}\) & \(32.9_{\pm 1.7}\) \\  & Ours & \(\mathbf{58.26_{\pm 17.6}}\) & \(\mathbf{93.6_{\pm 0.4}}\) & \(\mathbf{23.4_{\pm 27.7}}\) & \(\mathbf{75.8_{\pm 1.3}}\) \\ \hline \multirow{8}{*}{2000} & Few-shot (GPT-3.5) & \(2.73_{\pm 0.29}\) & \(75.3_{\pm 0.3}\) & \(0.0_{\pm 0.0}\) & \(18.6_{\pm 0.9}\) \\  & Few-shot (GPT-4) & \(3.01_{\pm 0.39}\) & \(74.9_{\pm 0.3}\) & \(0.0_{\pm 0.0}\) & \(18.5_{\pm 1.1}\) \\ \cline{1-1}  & Jailbreak (mean) & \(13.97_{\pm 1.69}\) & \(83.5_{\pm 0.4}\) & \(5.4_{\pm 1.0}\) & \(21.3_{\pm 2.0}\) \\ \cline{1-1}  & Jailbreak (oracle) & \(54.37_{\pm 2.96}\) & \(88.8_{\pm 0.3}\) & \(\mathbf{36.5_{\pm 34.3}}\) & \(68.4_{\pm 2.5}\) \\ \cline{1-1}  & Ours & \(\mathbf{59.21_{\pm 2.11}}\) & \(\mathbf{94.6_{\pm 0.4}}\) & \(26.6_{\pm 2.8}\) & \(\mathbf{77.8_{\pm 1.3}}\) \\ \hline \hline \end{tabular}
\end{table}
표 1: 프롬프트의 지침-2M 데이터 세트에 대한 프롬프트 역전에 대한 주요 결과. 모델들은 Llama-2 7B 및 Llama-2 7B 채팅으로부터 확률들을 반전시키도록 훈련되었다.

\begin{table}
\begin{tabular}{l l l l l l l l l} \hline \hline  & & \multicolumn{4}{c}{Alpaca Code Generation} & \multicolumn{4}{c}{Anthropic HH} \\  & & BLEU & CS & Exact & Tok F1 & BLEU & CS & Exact & Tok F1 \\ \hline \multirow{8}{*}{2000} & Few (3.5) & \(6.57_{\pm 0.52}\) & \(79.7_{\pm 0.4}\) & \(0.0_{\pm 0.0}\) & \(28.7_{\pm 1.0}\) & \(2.70_{\pm 0.23}\) & \(75.1_{\pm 0.3}\) & \(0.0_{\pm 0.0}\) & \(14.7_{\pm 0.8}\) \\  & Few (4) & \(6.83_{\pm 0.44}\) & \(80.3_{\pm 0.4}\) & \(cating that the RLHF procedure used to train the chat model may reduce the amount of information from what was initially available in the next-token probabilities.

**도메인 외.** 표 2는 길이와 내용 모두에서 교육 분포와 크게 다른 프롬프트를 사용할 때의 결과를 보여 줍니다. 이러한 도메인의 경우 모델은 RLHF 모델에서 적은 샷 및 탈옥보다 훨씬 우수하다. 채팅 모델을 사용하면 다량의 독성 콘텐츠가 포함된 인류 HH 데이터 세트에서 탈옥 문자열이 특히 비효율적이라는 것을 관찰하며, 이는 독성 콘텐츠가 프롬프트에 존재할 때 채팅 모델이 사용자의 요청에 덜 따를 가능성이 있음을 나타낸다. 원시 모델의 경우 반전 접근법은 BLEU에서 탈옥하는 것보다 약간 더 나쁘다.

**APL 기반 로짓 추출** 다음은 다음 토큰 확률 분포를 복구하는 기능을 조사합니다. 로컬 LLAMA-2 모델을 사용하여 '로짓 바이어스' 인수와 argmax 출력이 있는 API를 시뮬레이션한다. 본 논문에서 제안한 기법(파란색 대 파란색)의 결과를 시각화한다. 그림 4(왼쪽)의 순진한 몬테카를로 표본 기준선(빨간색)입니다. 결정론적 알고리즘은 몬테카를로 기준선보다 적은 수의 질의에서 유용한 로짓들을 추출한다. 이 결과는 무작위 샘플링 동안 거의 발생하지 않는 매우 가능성이 낮은 단어의 확률에 유용한 정보가 포함되어 있다는 가설(섹션 3.1)을 따른다.

**이동성** 다음으로 13B 버전 및 70B 버전에서 7B 버전의 LLama-2에서 훈련된 반전 모델을 평가하여 역전이 다른 크기의 모델로 전달되는지 여부를 조사합니다. 결과는 표 3에 나와 있다. 우리는 역전이 채팅 모델 사이보다 코드 생성에서 가장 잘 수행되고 비RLHFd 모델 사이에서 상당히 잘 전달된다는 것을 관찰한다. 우리는 다른 모델에 적응하기 위해 모델을 더 미세 조정해야 할 수 있다고 추측한다.

**역전 및 언어 모델 척도** 종속 반전 결과가 언어 모델 크기에 미치는 영향을 이해 하려면 GPT-2의 다른 크기를 반전 하는 것을 고려 하 고 결과를 표 9 (왼쪽)에 표시 합니다. 흥미롭게도, 재구성은 반전된 언어 모델의 크기에 관계없이 매우 유사하게(BLEU 점수 1점 이내) 수행된다. 출력 확률이 매우 다른 양의 처리(다양한 모델 크기에 의존함)를 거친 후에도 유사한 양의 정보를 포함한다는 사실은 CNN에서 더 많은 계산 계층이 역전을 더 어렵게 만든다는 도소비츠키 및 브록스(2016)의 결과와 다르다.

### 프롬프트 반전 방지

언어 모델 제공자는 프롬프트를 반전으로부터 방어하는 데 관심이 있을 수 있다. 한 가지 간단한 방어는 언어 모델 출력 분포에 노이즈를 추가하는 것인데, 결정적(argmax) 출력을 제공하는 대신 공격자가 출력 확률을 쉽게 재구성할 수 있는 언어 모델 제공자는 대신 출력 분포에서 _샘플_ 할 수 있다.

즉각적인 역산에 대한 방어로 세 가지 다른 LM 샘플링 메커니즘을 고려한다: 샘플링 중 소프트맥스 온도 조정, 핵 샘플링의 top-p 매개변수 조정(Holtzman et al., 2020), 고려되는 총 토큰 수 조정(top-K)이다. 우리는 LLama-2 7b (비채팅)에서 샘플을 채취하고 원하는 전략에 따라 인버터 모델에 확률을 공급한다. 결과는 그림 3에 시각화되어 있다.

각각의 경우에, 우리는 언어 모델 충실도와 반전 성능 사이의 트레이드오프를 관찰한다. 흥미롭게도, 반전은 온도 값 \(\tau=1\)에서 가장 잘 수행되며, 온도가 되면 어려움을 겪는다.

\begin{table}
\begin{tabular}{l l|c c c} \hline \hline Train & Test & Alpaca Code Generation & Anthropic HH & Instructions-2M \\ \hline
7b & 7b & \(76.3_{\pm 1.9}\) & \(56.2_{\pm 2.3}\) & \(77.7_{\pm 2.3}\) \\  & 13b & \(48.4_{\pm 1.4}\) & \(44.3_{\pm 2.2}\) & \(54.9_{\pm 1.9}\) \\  & 70b & \(52.1_{\pm 1.5}\) & \(44.8_{\pm 2.2}\) & \(53.0_{\pm 2.0}\) \\ \hline
7b-chat & 7b-chat & \(76.6_{\pm 1.9}\) & \(55.6_{\pm 2.3}\) & \(75.8_{\pm 2.1}\) \\  & 13b-chat & \(37.3_{\pm 1.4}\) & \(32.5_{\pm 2.0}\) & \(43.6_{\pm 1.7}\) \\  & 70b-chat & \(36.5_{\pm 1.2}\) & \(32.2_{\pm 1.7}\) & \(43.1_{\pm 1.8}\) \\ \hline \hline \end{tabular}
\end{table}
표 3: 모델 전송의 결과: 각각의 13B 및 70B 파라미터 버전들에서 LLama-2 7B 및 LLama-2 7B 채팅을 반전시키도록 트레이닝된 테스트 인버터들. 결과는 토큰 F1에서 측정되며, 비교를 위해 7B의 점수가 제공된다.

LM 분포가 argmax로 어닐링될 때뿐만 아니라 온도가 증가할 때 분포가 균일하게 붕괴됨에 따라 감소한다. top-p와 top-k 모두에 대해 우리는 모델이 거의 모든 분포가 잘 수행되어야 한다는 점에 주목하며, 이는 꼬리에 중요한 정보가 있음을 나타낸다.

### Analysis

**정성적 예제.** 표 4의 지침-2M에서 무작위로 선택된 일부 정성적 예제를 보여줍니다. 반전 프롬프트는 일반적으로 주제에 대한 것이며 원본과 구문적으로 유사합니다. 두 개의 프롬프트가 완벽하게 재구성되었습니다. 우리는 고유명사가 어려워 보인다는 것을 알아챘다. 한 예에서, 우리의 모델은 질문의 구조를 올바르게 복구하지만, 스타인벡의 _Of Mice and Men_ 과 샐린저의 _The Catcher in the Rye_10을 혼합한다. (어떤 사람은 이 정보가 확률 분포로 표현된다고 가정할 수 있지만, 흥미롭게도 원시 확률은 어느 제목을 선호하지 않는다.) 모든 예에서, 시스템은 프롬프트가 구두점에서 끝나는지 여부를 정확하게 식별한다.

\begin{table}
\begin{tabular}{l l} \hline \hline
**Original** & **Reconstruction** \\ \hline What is the Charles ’Chick’ Evans Memorial & \(\Rightarrow\) \\ Scholarship? & **Program**? \\ Is the following sentence grammatically correct? & \(\Rightarrow\) \\ They was playing soccer in the park. OPTIONS: - unacceptable - acceptable & \(\Rightarrow\) \\ What are the benefits of practicing mindfulness & \(\Rightarrow\) \\ meditation? & \(\Rightarrow\) \\ Come up with an essay on the importance of emotions in decision-making. No input & **Write an essay about** the importance of **empathy**. No input \\ What are the rules of a sit-and-go poker tournament? & \(\Rightarrow\) \\ What impact do workplace policies have on reducing unconscious bias, and how can they be improved? & What **are the impact of unconscious biases** on **workplace policies and practices**, and how can they be **addressed**? \\ Given that John Steinbeck’s “Of Mice and Men” & \(\Rightarrow\) \\ was published in 1937, can it be concluded that Steinbeck won the Nobel Prize in Literature that same year? & **Given that the novel “The Catcher in the Rye” was **written by J.D. Salinger** and published in **1951**, can it be concluded that it won the **Pulitzer Prize for Fiction in 1951**? \\ \hline \hline \end{tabular}
\end{table}
표 4: 언어 모델 확률에만 조건이 있는 우리 모델의 프롬프트 반전 예제입니다. 샘플은 지침-2M 유효성 검사 세트에서 무작위로 선택된다.

그림 3: 언어 모델 제공자는 프롬프트를 반전으로부터 보호하기 위한 노력으로 다르게 샘플링할 수 있다. 역전 공격에 대한 방어 수단으로 사용되는 다양한 샘플링 전략, 즉 가열냉각 온도, top-K 값 설정 및 핵(top-p) 샘플링에서 역전 성능을 탐구한다. 우리는 로그 공간(주황색)과 확률 공간(파란색) 모두에서 소프트맥스에 온도를 적용하는 것을 고려한다.

인버터는 분포의 어떤 구성 요소가 필요한가? 우리의 모델이 입력의 가장 큰 구성 요소에 가장 중점을 두는지 조사하기 위해 우리는 오름차순과 내림차순으로 확률 벡터에서 (평균) \(k\로 설정된) 구성 요소를 반복적으로 제거한다. 또한 입력에서 \(k\) 성분의 임의 부분 집합을 제외한 모든 부분을 제거하는 것을 고려한다. 그림 4는 구성 요소 제거 수준에 따른 재구성 성능의 차이를 강조한다. 모델은 가능성이 높은 단어에 더 중점을 두는 것으로 판단된다. 특히, 가장 작은 \(k\) 확률은 랜덤 \(k\) 확률보다 약간 더 유용하다. 거의 전체 분포가 다시 포함될 때까지 일반적으로 재구성이 좋지 않다.

## 8 Conclusion & Future Work

언어 모델 출력으로부터 역산 문제를 정의하고 공격과 방어 관점에서 역산 접근 방식을 분석한다. 이 공격 벡터가 모델 출력 분포에 직접 액세스할 수 없는 경우에도 LM 시스템에서 숨겨진 프롬프트를 유도하는 데 사용할 수 있음을 보여준다.

_반전의 한계는 무엇인가?_ 실험 결과는 언어 모델 확률로부터 입력에 대한 많은 정보를 복구할 수 있지만 상한을 추정하지는 않는다는 것을 보여준다. 부록 G.1의 크기 조정 분석에서는 더 큰 백본 모델이 더 많은 정보를 복구한다는 것을 의미하지만, 우리는 1억 개의 매개변수 크기보다 큰 백본 모델로 실험을 실행하지 않는다.

_어떻게 하면 프롬프트를 안전하게 유지할 수 있습니까?_ 실험은 샘플링이 활성화될 때 모델에 충분한 쿼리가 주어진 모델 확률 분포를 재구성할 수 있음을 보여준다. 사용자에게 언어 모델에서 텍스트를 생성하기 위한 액세스를 제공하는 동안 프롬프트를 보호하는 유일한 확실한 방법은 최상위 로짓 액세스를 비활성화하고(텍스트만 출력) 온도를 0으로 설정하는 것이다.

_반전을 위한 더 스마트한 매개 변수화._ 향후 작업은 LM에 단일 접미사를 입력하면 끝뿐만 아니라 각 위치에 하나씩 여러 개의 다음 토큰 예측이 출력된다는 사실을 활용하는 것을 고려할 수 있다. 추가 연구에서는 토큰 임베딩을 확률 값과 통합하는 매개변수화를 활용하여 역산 모델이 어떤 값에 해당하는지를 '알 수 있다'는 것이 유용할 수 있음을 발견할 수 있다.

그림 4: (왼쪽) API 기반 로짓 복구 기술 대 몬테 카를로 기준선에서 모델 성능. 파란색 점선은 실제 확률 벡터로부터 프롬프트를 재구성함으로써 주어진다. (오른쪽) 확률 벡터 수정 수준에 따른 모델 성능입니다. 우리는 K를 1에서 32,000까지 변화시키면서 상위 K 확률을 제외한 모든 확률, 하위 K를 제외한 모든 확률, 랜덤 K를 제외한 모든 확률을 제거한다(전체 입력 차원).

Ethics

언어 모델의 역전에 대한 우리의 연구는 특히 제공자가 가치 있거나 개인 정보를 포함하는 프롬프트를 유지할 때 서비스와 같은 모델의 배치를 둘러싼 윤리적 의미를 강조한다. 언어 모델의 사용자는 콘텐츠 생성 및 정보 검색을 포함한 다양한 목적을 위해 이러한 서비스에 의존함에 따라 영향을 받을 수 있다. 신속한 비밀성은 상호 작용하는 시스템에 대한 사용자의 신뢰를 손상시켜 서비스 자체의 투명성과 무결성에 대한 우려를 불러일으킬 수 있다.

기본적인 프롬프트에 대한 액세스 부족은 언어 모델을 효과적으로 조사, 평가 및 규제하려는 노력을 방해하여 AI 기술의 책임 있고 윤리적인 발전의 발전을 방해한다. 우리의 연구는 언어 모델 서비스 제공자의 중요한 개인 정보 보호 문제를 강조하면서 프롬프트에 대한 광범위한 액세스를 향한 분야를 발전시킨다.

## 10 Reproducibility

모든 실험을 재현하기 위한 코드는 익명.4open.science/status/language-model-inversion에서 사용할 수 있다. 프롬프트 데이터 세트는 종이 출판 시 제공됩니다. 모든 실험은 모든 모델 훈련, 로짓 샘플링 및 평가를 포함하여 Github 저장소에서 완전히 재현 가능하고 문서화된다.

## 11 Acknowledgements

JXM은 NSF GRFP에서 지원됩니다. JC는 NSF 2242302에 의해 지원된다. AMR은 NSF 2242302, NSF CAREER 2037519, IARPA HIATUS 및 슬론 펠로우십에 의해 지원된다. LLAMA 역산 모델을 훈련하는 데 필요한 계산을 제공하는 AI 앨런 연구소 덕분입니다.

## References

* Bai 등(2022) Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. 2022년 인간 피드백에서 강화 학습으로 유용하고 무해한 조수를 훈련합니다.
* Bordes et al.(2021) Florian Bordes, Randall Balestriero, and Pascal Vincent. 자기 지도 표현에 대해 알고 있는 내용을 정확하게 시각화합니다. _ 트랜스젠더 마흐 배워요 Res._ 2022년, 2021년
* Chung et al.(2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. _ arXiv preprint arXiv:2210.11416_, 2022.
* Dosovitskiy & Brox (2016) Alexey Dosovitskiy and Thomas Brox. 시각적 표현들을 컨볼루션 네트워크들로 반전시키는 것, 2016.
*Duan 등(2023) Haonan Duan, Adam Dziedzic, Mohammad Yaghini, Nicolas Papernot, and Franziska Boenisch. 상황 내 학습의 개인 정보 보호 위험에 대해. 2023년, _ACL 2023 신뢰할 수 있는 자연어 처리에 대한 워크샵_ 에서.
* Dumoulin 등(2018) Vincent Dumoulin, Ethan Perez, Nathan Schucher, Florian Strub, Harm de Vries, Aaron Courville, and Yoshua Bengio. 기능별 변환입니다. _ Distill_, 2018. doi: 10.23915/distill.00011. [https://distill.pub/2018/feature-wise-transformations](https://distill.pub/2018/feature-wise-transformations).
* Dziedzic et al.(2023) Adam Dziedzic, Franziska Boenisch, Mingjian Jiang, Haonan Duan, and Nicolas Papernot. 문장 삽입 인코더는 훔치기 쉽지만 방어하기 어렵다. 신뢰할 수 있는 ML에 대 한 제한된 데이터 및 계산의 Pitfall에 대 한 _ICLR 2023 워크샵 2023. URL [https://openreview.net/forum?id=XN5qQxI8gkz](https://openreview.net/forum?id=XN5qQxI8gkz)입니다.

* Fredrikson 등(2015) Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. 신뢰도 정보와 기본 대응책을 활용하는 모델 반전 공격. In _Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security_, CCS '15, pp. 1322-1333, New York, NY, USA, 2015. Association for Computing Machinery. ISBN 9781450338325. doi: 10.1145/2810103.2813677. URL [https://doi.org/10.1145/2810103.2813677](https://doi.org/10.1145/2810103.2813677)입니다.
* Fredrikson 등(2014) Matthew Fredrikson, Eric Lantz, Somesh Jha, Simon Lin, David Page, and Thomas Ristenpart. 약물유전학에서의 프라이버시: 개인화된 와파린 투여에 대한 종단 간 사례 연구. In _Proceedings of the USENIX Security Symposium_, pp. 17-32, August 2014.
* Gudibande et al. (2023) Arnav Gudibande, Eric Wallace, Charlie Snell, Xinyang Geng, Hao Liu, Pieter Abbeel, Sergey Levine, and Dawn Song. 전매영화를 모방한다는 거짓 약속, 2023.
* Holtzman et al.(2020) Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 뉴럴 텍스트 변성의 특이한 경우, 2020년.
* Honovich et al. (2023) Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 부자연스러운 지시: 인간 노동력이 거의 없는 언어 모델 조정 In _Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp. 14409-14428, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.806. URL [https://aclanthology.org/2023.acl-long.806](https://aclanthology.org/2023.acl-long.806)
* Krishna et al.(2020) Kalpesh Krishna, Gaurav Singh Tomar, Ankur P. Parikh, Nicolas Papernot, and Mohit Iyyer. 참깨 거리의 도둑들! model extraction of bert-based apis, 2020.
* Lebret 등(2016) R. Lebret, D. Grangier, M. 올리 바이오그래픽 도메인에 응용된 구조화된 데이터로부터 신경망 텍스트 생성 2016년 자연 언어 처리(EMNLP)에 대한 실증적 방법에 대한 회의록에서_2016년.
* Li et al.(2023) Haoran Li, Mingshi Xu, and Yangqiu Song. 문장 임베딩은 예상했던 것보다 더 많은 정보를 유출한다: 전체 문장을 복구하기 위한 생성 임베딩 반전 공격, 2023.
* Lowd and Meek (2005) Daniel Lowd and Christopher Meek. 적대적 배움 In _Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining_, KDD '05, pp. 641-647, New York, NY, USA, 2005. Association for Computing Machinery. ISBN 159593135X. doi: 10.1145/1081870.1081950. URL [https://doi.org/10.1145/1081870.1081950](https://doi.org/10.1145/1081870.1081950).
* Luo et al. (2023) Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. 위저드코더: evol-instruct를 사용하여 코드 대용량 언어 모델에 권한을 부여합니다. _ arXiv preprint arXiv:2306.08568_, 2023.
* Mahendran and Vedaldi (2014) Aravindh Mahendran and Andrea Vedaldi. 깊은 이미지 표현을 뒤집어서 이해합니다. _ 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, pp. 5188-5196, 2014.
* Merity 등(2016) Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. 포인터 센티넬 혼합물 모델, 2016년
* Morris et al. (2023) John X. 모리스, 볼로디미르 쿨레쇼프, 비탈리 슈마티코프, 알렉산더 M. 러쉬 텍스트 임베딩은 2023년 텍스트만큼 (거의) 드러난다.
* Neelakantan 등(2022) Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas Tezak, Jong Wook Kim, Chris Hallacy, Johannes Heidecke, Pranav Shyam, Boris Power, Tyna Eloundou Nekoul, Girish Sastry, Gretchen Krueger, David Schnurr, Felipe Petroski Such, Kenny Hsu, Madeleine Thompson, Tabarak Khan, Toki Sherbakov, Joanne Jang, Peter Welinder, and Lilian Weng. 2022년 대비 사전 훈련에 의한 텍스트 및 코드 임베딩.
* Pal et al.(2019) Soham Pal, Yash Gupta, Aditya Shukla, Aditya Kanade, Shirish K. 셰베이드, 비노드 가나파시 공공 데이터를 활용하여 심층 신경망을 추출하는 프레임워크입니다. _ ArXiv_, abs/1905.09165, 2019. URL [https://api.semanticscholar.org/CorpusID:162168576](https://api.semanticscholar.org/CorpusID:162168576).
* Parikh et al. (2019)Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: 기계 번역의 자동 평가를 위한 방법. In _Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics_, pp. 311-318, Philadelphia, Pennsylvania, USA, July 2002. Association for Computational Linguistics. doi: 10.3115/1073083.1073135. URL [https://aclanthology.org/P02-1040](https://aclanthology.org/P02-1040).
* Radford et al. (2019) Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 언어 모델은 감독되지 않은 다중 작업 학습자입니다. 2019년.
* Raffel 등(2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 통합 텍스트 대 텍스트 변환기를 사용한 전이 학습의 한계 탐색, 2020.
* Shokri et al.(2017) Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017년 머신러닝 모델에 대한 멤버십 추론 공격.
* Song and Raghunathan (2020) Congzheng Song and Ananth Raghunathan. 임베딩 모델에서의 정보 유출, 2020.
* Takahashi 등(2023) Hideaki Takahashi, Jingjing Liu, and Yang Liu. 파악 fedmd: 페어드-로짓 반전 공격을 통한 이미지 복구, 2023.
* Taori 등(2023) Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Stanford alpaca: 명령어 후속 llama 모델. [https://github.com/tatsu-lab/stanford_alpaca] (https://github.com/tatsu-lab/stanford_alpaca), 2023.
* Teterwak et al.(2021) Piotr Teterwak, Chiyuan Zhang, Dilip Krishnan, and Michael C. Mozer. 차별적으로 훈련된 분류기, 2021의 피드포워드 역산을 통한 불변 이해.
* 투브론 외 (2023) 휴고 투브론, 루이 마틴, 케빈 스톤, 피터 알버트, 암자드 알마하리, 야스민 바바이, 니콜라이 바슐리코프, 소우마 바트라, 프라즈왈 바살리, 슈루티 보살레, 단 비켈, 루카스 블레처, 크리스티안 칸톤 페러, 모야 첸, 기옌 쿠쿠룰, 다비드 에시오부, 주드 페르난데스, 제레미 푸, 원린 푸, 브라이언 풀러, 신시아 가오, 제레미 푸, 베다누즈 고세이니, 루이 호우, 하칸 이난, 마르신 카다스, 빅토르 케르케즈, 마디안 고예프, 이사벨 클루만, 아르템 고레네프, 신시아 가오, 사그하르 호세이니, 루이 호우, 제냐 리, 다이애나 리스코비치, 잉하이 루, 윤잉 마오, 사보트 라흐로프, 제냐 라흐로프, 제냐 리, 디아나 리스코비치, 잉하이 루, 윤잉 마오, 라마 2: 오픈 파운데이션과 미세 조정된 채팅 모델, 2023.
* Tramer et al. (2016) Florian Tramer, Fan Zhang, Ari Juels, Michael K. 라이터와 토마스 리스텐파트 예측 Apis, 2016을 통해 기계 학습 모델을 훔칩니다.
* Wallace 등(2021) Eric Wallace, Mitchell Stern, and Dawn Song. 블랙박스 기계 번역 시스템에 대한 모방 공격 및 방어, 2021.
* Wang et al.(2021) Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Kuntal Kumar Pal, Maitreya Patel, Mehrad Moradshahi, Mihir Parmar, Miral Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Raveshahi Singh Puri, Rushang Karia, Savan Doshi, Shailaja Keyur Sampat, Siddhartha Mishra, Sujan Reddy A, Sumanta Patro, Tanay Dixit 및 Xudong Shen. 초자연적 지침: 1600개 이상의 NLP 작업에 대한 선언적 지침을 통한 일반화. In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pp. 5085-5109, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.340. URL [https://aclanthology.org/2022.emnlp-main.340](https://aclanthology.org/2022.emnlp-main.340).
* Wang et al.(2020) Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 자체 지침: 언어 모델을 자체 생성 지침과 정렬합니다. In_Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp. 13484-13508, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.754. URL [https://aclanthology.org/2023.acl-long.754](https://aclanthology.org/2023.acl-long.754)
* Wu et al.(2023) Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, and Alham Fikri Aji. 라미-lm: 대규모 지침의 다양한 증류 모델 무리입니다. _ CoRR_, abs/2304.14402, 2023. URL [https://arxiv.org/abs/2304.14402](https://arxiv.org/abs/2304.14402)입니다.
* Xu et al. (2023) Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 마법사: 복잡한 지침을 따르도록 대규모 언어 모델에 권한을 부여합니다. _ arXiv preprint arXiv:2304.12244_, 2023.
* Yuan et al.(2022) Ann Yuan, Daphne Ippolito, Vitaly Nikolaev, Chris Callison-Burch, Andy Coenen, and Sebastian Gehrmann. 신트바이오: 2022년 텍스트 데이터셋의 휴먼-아이 협업 큐레이션 사례 연구.
* Zhang et al.(2022) Ruisi Zhang, Seira Hidano, and Farinaz Koushanfar. 텍스트 드러머: 트랜스포머에 대한 모델 반전 공격을 통한 개인 텍스트 재구성, 2022.
* Zhang et al.(2020) Yuheng Zhang, Ruoxi Jia, Hengzhi Pei, Wenxiao Wang, Bo Li, and Dawn Song. 비밀 드러머: 심층 신경망에 대한 생성 모델 반전 공격, 2020.

## 부록 A 기준선: Jailbreak 프롬프트

탈옥 프롬프트는 NLP 전문가 패널이 수동으로 작성했다. 프롬프트는 출력의 첫 번째 줄을 취하거나 취하지 않고 미리 작성된 새 줄의 유무에 관계없이 테스트되었다. 표 5에는 효과가 떨어지는 순서대로 테스트한 모든 탈옥 프롬프트 목록이 포함되어 있다. 모델 및 데이터 세트에 따른 성능 그림은 그림 5에서 확인할 수 있다.

그림 5: 데이터 세트별 탈옥 프롬프트의 성능입니다.

[MISSING_PAGE_EMPTY:14]

[MISSING_PAGE_EMPTY:15]

## 부록 D 동의어 스왑 실험 세부 정보

도 2에 예시된 실험을 수행하기 위해, 우리는 위키텍스트 데이터세트를 통해 획득된 위키피디아로부터 100개의 단락들을 샘플링한다(Merity et al., 2016). 우리는 GPT-4에 텍스트 _"한 단어 문장을 가까운 동의어로 대체하여 문장을 업데이트해 주십시오. 워드1 -? 워드2 형식으로 바꿀 단어로만 응답해 주십시오. _ 그런 다음 GPT-4의 응답으로부터 단어 스왑을 추출하고 이를 입력에 적용하여 변환된 입력 \(\hat{x}\)을 생성한다. 프롬프트에 사용되는 언어 모델은 LLAMA-2(비채팅 버전)의 70억 파라미터 버전이다.

원래 시퀀스( \(x_{s}\) 포함)와 새로운 시퀀스( \(\hat{x_{s}}\) 포함) 사이의 언어 모델 출력 변화를 측정하기 위해 두 가지 양을 계산한다:

\[\text{KL}(x,\hat{x};T):=\mathbb{D}_{KL}\left[p(x_{T+1}\mid x_{1},...,x_{s},...,x _{T};\theta)\mid\mid p(x_{T+1}\mid x_{1},...,\hat{x}_{s},...x_{T};\theta)\right]\]

\begin{table}
\begin{tabular}{l l} \hline \hline Prompt & Given the top-K predicted tokens and log-probabilities from a language model, please predict what the input was. Please follow the examples and don’t output anything except the predicted input. \\ Top tokens: \{ Leon: 11.2398 Da: 9.6961 da: 8.9290 Leo: 8.6994 Leonard: 8.1272 Nob: 7.8001 Was: 7.3815 Vincent: 7.1921 Obviously: 7.1842 D27. 70648 Madonna: 6.9382 Gio: 7.6738 Lc: 6.7331 Michel: 6.6347 Diego: 6.5983 Him: 6.5977 Luci: 6.5903 Prima: 6.5503 Giorg: 6.5424... Moreover: 5.0031 Natur: 4.9922 Ric: 4.9754 Pope: 4.9442 Cec: 4.9418 clear: 4.9349 wasn: 4.9321 Newton: 4.9319 Jesus: 4.9271 Lee: 4.9231 Bob: 4.9100 Arist: 4.9000 Renaissance: 4.8975 Bern: 4.8926 Vlad: 4.8796 \(\}\) \\ Output: Suppose it’s true that The Mona Lisa was painted by Leonardo da Vinci. Then, who painted the Mona Lisa? \\ Top tokens: \{ :. 8.2570 but: 7.4238 they: 5.5620 /: 5.1770 but: 5.1659 ; 5.1307.: 4.9385 unless: 4.8892 indeed: 4.8305 /: 4.7388 because: 4.3290 except: 4.2364 and: 4.1802 with: 4.1525 AND: 4.1523... Genomsnit: 2.5206 \(\}\) \\ Output: How can itot soda have zero calories? \\ What is the main reason why thet soda is bad for you? \\ Do those questions have the same meaning? \\ OPTIONS: \\ - no \\ - yes \\ Top tokens: \{ whether: 11.8282 conclus: 11.2570 definit: 10.4762 from: 9.0172 unless: 8.9301 without: 8.8401 either: 8.8082 yet: 8.7552 based: 8.5534 : 8.1669 if: 7.8553 because: 7.6823 anything: 7.4641 weather: 7.3586 given: 7.2563 until: 7.2539 due: 7.2475 /: 7.2354 with: 7.0059 reli: 6.9824 since: 6.9268 posit: 6.8239 for: 6.7511 decis: 6.5534 accir: 6.5436 sole: 6.5126 definitely: 6.4109 anymore: 6.3978 definite: 6.3382 defin: 6.0519 directly: 5.9700 form: 5.8993 necessarily: 5.8884 right: 5.8829 vis: 5.8768 between: 5.7320 just: 5.7161 bec: 5.6957 yes: 5.6823 prem: 5.6057 using: 5.5305 initial: 5.5000 merely: 5.4670 certain: 5.4666 depending: 5.4145 exactly: 5.3382 statisk: 5.2684 purely: 5.2434 what: 5.2341 correctly: 5.1911 determin: 5.1818 through: 5.1817 one: 5.1599 within: 5.1509 conclusion: 5.1501 nor: 5.1132 use: 5.1099 w.: 5.0780 concl: 5.0452 empir: 5.0357 alone: 5.0024 regardless: 4.9944 being: 4.9090 clearly: 4.9603 which: 4.9244 immediately: 4.9147 explicitly: 4.9100 conflict: 4.906 enough: 4.8983 wit: 4.8966 counvin: 4.8228 knowing: 4.8048 by: 4.7944 iff: 4.7470 till: 4.7308 outside: 4.7040 bases: 4.6989 at: 4.6928 simply: 4.6816 straight: 4.6590 them: 4.6589 but: 4.6522 precisely: 4.6370 blind: 4.5758 positive: 4.5536 direction: 4.5310 only: 4.5170 easily: 4.5093 via: 4.5076 anyway: 4.4790 /: 4.4679 the: 4.4674 apart: 4.4162 ye: 4.4095 much: 4.4033 absolutely: 4.3913 their: 4.3850 jud: 4.3697 : 4.3651 fro: 4.3244 \(\}\) Output: Preme: Dance striking a beautiful pose on a basketball court. Hypothesis: The dancer is outside. \\.Given the premise, can we conclude the hypothesis? \\ OPTIONS: \\ - yes \\ - it is not possible to tell \\ \hline \hline \end{tabular}
\end{table}
표 7: GPT에 대한 예 몇 번-샷 프롬프트.

즉, 원본 및 동의어 교환 시퀀스에 대한 \(p\)의 확률 출력 사이의 KL 발산, 및

\[\text{Hamming}(x,\hat{x};T):=\sum_{i}|\text{bin}_{16}(p(x_{T+1}\mid x _{1},...,x_{s},...,x_{T};\theta))_{i}\] \[\qquad\qquad\qquad\qquad\qquad\qquad-\text{bin}_{16}(p(x_{T+1}\mid x_{1},...,\hat{x}_{s},...,x_{T};\theta))_{i}|\

## Appendix E Datasets

표 8은 명령-2M 데이터 세트에 포함된 프롬프트 데이터 세트의 분류를 보여준다. 프롬프트는 사용자 프롬프트와 선택적 시스템 프롬프트의 연결입니다. T0 프롬프트가 평균 32.4 단어로 가장 길다. 라미니 프롬프트는 총 1.8M이 포함된 대부분의 훈련 데이터를 구성한다.

## Appendix F Logit extraction with API access with probability

이 섹션에서는 API가 상위 2개의 가장 가능성이 높은 단어의 확률에 대한 액세스를 제공할 때 로그 확률을 추출하는 또 다른 접근법을 제공한다. 높은 수준에서 원래 분포에서 단어의 확률을 찾기 위해 먼저 해당 단어를 가장 가능성이 높은 로짓 편향을 찾는다. 그런 다음 가장 가능성이 높은 단어의 확률 변화를 사용하여 원래 분포의 정규화 상수를 계산하고 그것을 사용하여 관심 단어의 확률을 찾는다.

형식적으로 단어 \(\log p(v)=f(v)-\log Z\)의 로그 확률을 다음과 같이 추출할 수 있다. 먼저 가장 높은 확률의 단어 \(v^{*}\)보다 단어 \(v\)를 더 확률적으로 만드는 로짓 바이어스 \(b_{v}\)를 찾는다. 로짓 편향을 사용

\begin{table}
\begin{tabular}{l r r} \hline \hline Dataset & Num. words & Total \\ \hline alpaca & 13.2 & 51280 \\ arxiv\_math & 7.1 & 50488 \\ dolly & 11.9 & 10684 \\ evol & 23.9 & 26530 \\ evol\_code & 25 & 41090 \\ gpt4\_teacher & 15.4 & 88933 \\ laminin & 20.7 & 1826928 \\ self\_instruct & 20.9 & 77840 \\ super\_natural\_instructions & 20.9 & 77840 \\ t0 & 32.4 & 80427 \\ \hline \hline \end{tabular}
\end{table}
표 8: 훈련 데이터의 데이터 집합당 통계량.

그림 6: 참 및 재구성(빨간색) 입력 길이입니다. 우리의 모델은 분포 내 길이를 밀접하게 모델링하고 다른 두 데이터 세트에 대해 과대 예측하는 경향이 있다.

정규화 상수에 대해 풀기 위해 단어 \(v\neq v^{*}\)에 로짓 바이어스를 추가한 후 가장 높은 확률 단어의 확률 \(\Delta=\log p(v^{*})-\log p(v^{*};b_{v})\)과 확률의 변화 \(\Delta=\log p(v^{*});b_{v})\):

\[\Delta =(\log f(v^{*})-\log Z)-(\log f(v^{*})-\log(Z+\exp(b_{v})))\] \[=\log(Z+\exp(b_{v}))-\log(Z+\exp(b_{v})))\] \[\exp(\Delta) =\frac{Z+\exp(b_{v})}{Z}\] \[=1+\frac{\exp(b_{v})}{Z}\] \[Z =\frac{\exp(b_{v})}{\exp(\Delta)-1}\] \[\log Z =b_{v}-\log(\Delta)-1] \] \

이를 통해 단어 \(f(v)\)의 정규화되지 않은 로그 확률을 해결할 수 있다:

\[\log p(v;b_{v}) =f(v)+b_{v}-\log(Z+\exp(b_{v}))\] \[f(v) =\log p(v;b_{v})+\log(Z+\exp(b_{v}))-b_{v},\]

yielding \(\log p(v)=f(v)-\log Z\).

이를 통해 가장 가능성이 높은 단어의 확률을 찾기 위해 하나의 호출로 각 단어에 대한 로그 확률을 추출하고, 충분히 큰 로짓 편향을 가진 서로 다른 단어에 대해 하나의 호출을 추출할 수 있다.

## 부록 G 반복 정제를 사용한 초기 탐색

이러한 접근법에 대한 자연스러운 확장은 vec2text에서 제안된 반복적 정제 접근법일 수 있다(Morris et al., 2023). 우리는 세 가지 입력을 취하는 인코더-디코더를 파라미터화한다:

* 섹션 4의 알려지지 않은 프롬프트(\(v\))에 대한 모델 출력 확률 벡터
* a '가설' 시퀀스, \(\hat{x}_{1},...,\hat{x}_{T}\)
* 모델 출력 확률 벡터 \(p(\hat{x}_{1},...,\hat{x}_{T})\)

실제 프롬프트 \(x\mid p(x)=v\)에서 언어 모델링을 통해 학습합니다. 훈련을 위해 가설로 사용할 조건부 LM(섹션 4)의 체크포인트에서 출력을 샘플링한다. 이 모델은 Llama-2 (7B)의 출력에 대해 섹션 6에 설명된 동일한 하이퍼파라미터를 사용하여 \(100\) epoch에 대해 훈련한다. 이 모델은 명령-2M에서 \(58.7\)의 1단계 BLEU 점수를 달성할 수 있으며 기본적으로 원래 모델의 BLEU 성능 \(59.2\)을 복구할 수 있다. 그러나 여러 단계의 보정 후 BLEU 점수는 증가하지 않았으며, 5단계 이후로는 \(56.43\)의 BLEU 점수를 얻었다.

그림 7은 반복 정제 모델을 훈련하는 데 사용된 가설에서 BLEU 점수를 나타낸다. 우리는 이러한 가설이 BLEU 점수 100까지 교정 가능한 텍스트의 전체 스펙트럼을 포함하지 않는다는 점에 주목한다. 이는 정제 모델이 서로 다른 텍스트에서 교정하는 것을 배우는 것을 어렵게 할 수 있다.

그림 7: BLEU는 반복 정제 실험을 위한 \(100_{0}00\) 훈련 가설에 걸쳐 점수를 매긴다. 대부분의 훈련 예제는 \(20\) 이하의 BLEU 점수를 갖는다.

진실 텍스트에서 '불편함'이 나왔습니다. 아마도 반복적 개선은 볼록성의 부족으로 인해 텍스트 임베딩보다 언어 모델 확률 출력의 공간에서 더 어려울 수 있다; 또한 반복적 개선을 사용하여 더 강력한 인버터를 트레이닝하기 위해 상이한 아키텍처 또는 하이퍼파라미터 세트가 필요할 수 있다는 것이 그럴듯하다.

### Ablations

제안된 모델 학습은 \(1M\)의 최대 시퀀스 길이를 갖는 데이터세트로부터 \(16\), \(40\) 에폭에 대한 학습을 수행하는 축소된 환경에서 수행된다. 절제 결과를 표 9(Left)에 나타낸다.

Parameterization.우리는 Morris et al. (2023)과 같이 프로젝션을 갖는 인코더-디코더라는 하나의 대안적인 모델 아키텍처를 고려한다. 이 모델은 확률 벡터를 더 작은 순위로 투영하면 중요한 정보가 폐기된다는 것을 나타내는 매우 저조한 성능을 보인다. 또한 정규화되지 않은 출력이 확률보다 더 많은 사용 가능한 정보를 포함하는지 확인하기 위해 로그 정규화된 확률 대신 언어 모델의 원시 출력에 대한 조건이 동일한 매개변수화를 테스트한다. 이 제거는 또한 차이를 만든다: 입력에 softmax를 적용하지 않고, BLEU에서 \(20\%\) drop 이상 관찰한다.

주요 실험은 16비트 정밀도로 수행되기 때문에 추가 비트가 성능을 향상시키는지 확인하기 위해 전체 정밀도(32비트)에서 훈련을 테스트한다. 완전 정밀 입력에 대한 훈련은 약 1 BLEU 포인트를 획득하며, 이는 확률 벡터를 반 정밀도로 저장함으로써 유의미한 정보를 폐기하지 않는다는 것을 나타낸다.

스케일링 인버터.모델 스케일이 인버터의 역산 성능에 미치는 영향을 알아보기 위해 다양한 크기의 인버터 모델을 학습시킨다. 인버터의 매개변수 수는 매우 큰 영향을 미치며, 더 큰 인버터 모델이 훨씬 더 잘 수행된다는 점에 주목한다. 절제 설정에서 동일한 훈련 단계 수로 T5-대 인버터는 T5-소 인버터보다 \(24\%\) 더 높은 BLEU 점수를 달성한다. 이 발견은 우리가 시스템을 확장함으로써 언어 모델을 더 정확하게 반전시킬 수 있음을 나타낸다.

입력 차원 감소.32비트 정밀도로 디스크에 저장될 때, \(32,000\) 크기의 어휘에 대한 1,000만 개의 확률 벡터는 1.28 TB를 차지한다. 이러한 입력 벡터의 전체 차원을 유지할 필요가 있는가? 놀랍게도, 표 9(오른쪽)는 대부분의 확률 벡터가 양호한 역산 성능을 달성하기 위해 요구된다는 것을 나타낸다. 상위 1000개의 예측 토큰은 평균적으로 확률 질량의 \(98\%\)를 포함하지만, 상위 1000개의 토큰만으로 훈련 및 평가하면 성능이 \(45\%\) 감소한다.

\begin{table}
\begin{tabular}{l l l l l} \hline \hline Experiment & LM & Inverter & BLEU & Token F1 \\ \hline \multirow{3}{*}{LM Scale} & 117M & & \(38.5_{\pm 1.5}\) & \(60.1_{\pm 1.3}\) \\  & 355M & & \(38.4_{\pm 1.5}\) & \(59.8_{\pm 1.3}\) \\  & 774M & & \(39.4_{\pm 1.5}\) & \(60.2_{\pm 1.3}\) \\  & 1558M & & \(39.2_{\pm 1.5}\) & \(60.0_{\pm 1.3}\) \\ \hline \multirow{3}{*}{Inverter Scale} & \multirow{3}{*}{117M} & 60M & \(38.5_{\pm 1.5}\) & \(60.1_{\pm 1.3}\) \\  & & 220M & \(44.5_{\pm 1.6}\) & \(65.4_{\pm 1.2}\) \\  & & 738M & \(47.8_{\pm 1.6}\) & \(67.5_{\pm 1.2}\) \\ \hline Baseline & & & \(38.5_{\pm 1.5}\) & \(60.1_{\pm 1.3}\) \\ No softmax & & & \(29.9_{\pm 1.4}\) & \(51.1_{\pm 1.3}\) \\ Projection & & & \(4.1_{\pm 0.2}\) & \(15.5_{\pm 0.5}\) \\ Full precision & & & \(39.7_{\pm 1.5}\) & \(61.3_{\pm 1.2}\) \\ \hline \hline \end{tabular}
\begin{tabular}{l l l l} \hline \hline \(k\) & BLEU & Token F1 \\ \hline
1 & \(4.6_{\pm 0.2}\) & \(17.3_{\pm 0.5}\) \\
10 & \(4.6_{\pm 0.2}\) & \(17.3_{\pm 0.5}\) \\
100 & \(8.0_{\pm 0.7}\) & \(21.5_{\pm 0.9}\) \\
1000 & \(21.4_{\pm 1.3}\) & \(39.2_{\pm 1.3}\) \\
10000 & \(30.7_{\pm 1.4}\) & \(52.0_{\pm 1.3}\) \\
32000 & \(38.5_{\pm 1.5}\) & \(60.1_{\pm 1.3}\) \\ \hline \hline \end{tabular}
\begin{tabular}{l l l l} \hline \hline \(k\) & BLEU & Token F1 \\ \hline
1 & \(4.6_{\pm 0.2}\) & \(17.3_{\pm 0.5}\) \\
10 & \(4.6_{\pm 0.2}\) & \(17.3_{\pm 0.5}\) \\
100 & \(8.0_{\pm 0.7}\) & \(21.5_{\pm 0.9}\) \\
1000 & \(21.4_{\pm 1.3}\) & \(39.2_{\pm 1.3}\) \\
10000 & \(30.7_{\pm 1.4}\) & \(52.0_{\pm 1.3}\) \\
32000 & \(38.5_{\pm 1.5}\) & \(60.1_{\pm 1.3}\) \\ \hline \hline \end{tabular}
\end{table}
표 9: (좌측) 모델링 절제. 언어 모델 규모, 인버터 모델 규모 및 몇 가지 대체 매개변수의 영향을 조사한다. (오른쪽) 다른 입력 차원 값 \(k\)에서 훈련될 때 모델 성능입니다. \(k=1\)일 때, 우리는 가장 높은 확률만을 입력하고, 다른 모든 값들을 최소값으로 설정한다. \ (32,000\)는 Llama-2의 어휘 크기이며, 완전한 차원에서의 입력을 제공하는 것과 동등하다.

## 부록 H 개인 정보 복구 실험

프롬프트에서 개체를 복구할 때 시스템의 성능을 측정하기 위해 작은 실험을 수행했다. 이를 위해 위키비오와 신트비오의 개인 정보를 포함하는 프롬프트 데이터 세트를 만들었다. 우리는 바이오 데이터 세트의 표 부분에서 개체 자체를 추출하고 명령어-2M을 기반으로 수동으로 조작된 템플릿 문자열에 개체를 삽입했다. PII 재구성에 대한 향후 연구를 돕기 위해 이 데이터 세트를 공개적으로 공개한다.

이름, 날짜 및 국적과 같은 개인 정보를 포함할 가능성이 높은 프롬프트에서 특정 개체를 재구성하는 모델의 능력을 고려한다. 이를 테스트하기 위해 이러한 속성을 포함하는 프롬프트의 합성 데이터 세트를 생성한다. 우리는 Wikibio (Lebret et al., 2016)와 Synthbio (Yuan et al., 2022)11에서 가져온 개인 속성을 사용하여 Instructions-2M에서 프롬프트를 편집한다. 우리는 LLAMA 7B 모델과 LLAMA-chat 7B 모델을 모두 사용하여 이러한 프롬프트를 반전시키고 범주 전반에 걸쳐 개인 개체를 재구성할 때의 정확도를 측정한다.

각주 11: 샘플 프롬프트와 함께 자세한 내용은 부록 I에서 확인할 수 있습니다.

결과는 표 10에 나와 있다. 우리의 모델은 다른 모델보다 일부 개인 개체를 재구성하는 데 훨씬 더 뛰어나다: 국가와 국적은 특히 성공적이지만 개별 날짜와 연도는 일반적으로 역산 과정에서 손실된다. 지침-2M은 프롬프트에 개인 정보의 좁은 분포만 포함하기 때문에 향후 작업은 더 나은 성능을 위해 더 광범위한 훈련 데이터를 고려할 수 있다.

## 부록 I 프라이빗 프롬프트 데이터 세트

\begin{table}
\begin{tabular}{l l c c c c c c c} \hline \hline  & & Country & Nationality & Day & Month & Year & First Name & Last Name \\ \hline \multirow{2}{*}{7b} & synthbio & \(87.2_{\pm 1.5}\) & \(64.5_{\pm 2.4}\) & \(9.0_{\pm 1.6}\) & \(15.0_{\pm 3.3}\) & \(1.0_{\pm 0.4}\) & \(5.9_{\pm 1.0}\) & \(1.4_{\pm 0.5}\) \\  & wikibio & \(75.7_{\pm 1.5}\) & \(34.2_{\pm 2.1}\) & \(13.8_{\pm 1.7}\) & \(17.7_{\pm 3.4}\) & \(1.0_{\pm 0.4}\) & \(3.3_{\pm 0.8}\) & \(1.4_{\pm 0.5}\) \\ \hline \multirow{2}{*}{7b-chat} & synthbio & \(84.2_{\pm 1.6}\) & \(64.8_{\pm 2.4}\) & \(7.4_{\pm 1.5}\) & \(15.8_{\pm 3.3}\) & \(2.0_{\pm 0.5}\) & \(5.6_{\pm 0.8}\) & \(1.8_{\pm 0.5}\) \\  & wikibio & \(75.7_{\pm 1.6}\) & \(32.2_{\pm 1.7}\) & \(12.5_{\pm 1.7}\) & \(7.7_{\pm 2.3}\) & \(1.4_{\pm 0.4}\) & \(3.6_{\pm 0.7}\) & \(1.2_{\pm 0.4}\) \\ \hline \hline \end{tabular}
\end{table}
표 10: 프롬프트 반전 동안 다양한 유형의 개인 정보를 보존할 때의 정확성.

\begin{table}
\begin{tabular}{c c l l l l} \hline \hline field & prompt & value & reconstruction & correct \\ \hline country & State the capital city of Uzbekistan. & Uzbekistan & State the capital city of Uzbekistan. & True \\ first\_name & Decide if the given name is male or female. output ”male” or ”female”. Aung & & Calculate the average hexadecimal value of the given string. Bao & False \\ full\_name & From the dialogue, can we infer that Andrejs Kisins & Andrejs Kisins & From the dialogue, can we infer that Andre likes dogs? & False \\ last\_name & If Qahtani needs to buy 3 leaves of bread at the store, and each local costs & Qahtani & If Sally buys 2 bags of candy and 3 bags of chips, how much money will she spend in total? & False \\ month & Published November Please remove spaces between words. & November & Displaying 1 to 12 of 12 Please remove spaces between words. & False \\ nationality & What challenges did the Qatari independence movement face? & Qatari & What challenges did the Quakerism movement face? & False \\ year & Meet Bessy Boot 1889 & 1889 & Meet Betty in the 123 What is the correctly punctuated version of this sentence? & False \\ \hline country & List the countries that border Iran. & Iran & List the countries that border Iran. & True \\ day & Task: Find out what day of the week is it on 01. & 01 & Convert the following date from mm/dd/yyyy to iso 8601 format. 01/01/2018 & False \\ first\_name & While walking through the park, raoul noticed something unusual. What did they notice? & raoul & Let the gender of the park, Ray spotted something unusual. What was & False \\ full\_name & Given that jack bruton failed his driving test twice. & Jack bruton & Given that Jack failed his driving test. Does it follow that Jack is not good at driving. Yes, no, or maybe? & False \\ month & Last\_name & Decide if the given name is male or female. output “male” or ”female”. Fredersken & Frederiksen & Detect the gender of the person based on his/her name. output “male” or ”female”. christian doe & False \\ month & Registration feb 21:15 & feb & Registration 28 February 2011 20:39 Make this lower case & False \\ nationality & Can you name a famous egyptian musician who blends traditional egyptian music with other genres? & Egyptian musician who specializes in traditional music from different genres? & False \\ year & Registration 1918 & 21:15 & 1918 & Registration 2 August 2005 18:13 Make this lower case & False \\ \hline \hline \end{tabular}
\end{table}
표 11: LLAMA-7B 인버터가 질문에 올바르게 응답했는지 여부와 함께 합성 개인 프롬프트 데이터 세트의 프롬프트 예.
