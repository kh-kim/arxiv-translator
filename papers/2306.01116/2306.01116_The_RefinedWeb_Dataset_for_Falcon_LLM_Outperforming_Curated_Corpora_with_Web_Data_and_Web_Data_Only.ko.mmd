# RefinedWeb Dataset for Falcon LLM:

웹 데이터 및 웹 데이터 전용으로 큐레이션된 코퍼라 성능 향상

**팰콘 LLM 팀**

**Guilherme Penedo 1 Quentin Malartic 2**

**Daniel Hesslow 1 Ruxandra Cojocaru 2 Alessandro Cappelli 1 Hamza Alobeidli 2 Baptiste Pannier 1 Ebtesam Almazrouel 2 Julien Launay 1 3**

[https://huggingface.co/datasets/tiiuae/falcon-refinedweb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)

각주 1: Falcon LLM 오픈 소스에 액세스하는 방법에 대한 자세한 내용은 falconllm.tii.ae에서 사용할 수 있습니다.

###### Abstract

대형 언어 모델은 일반적으로 필터링된 웹 데이터와 소셜 미디어 대화, 책 또는 기술 문서와 같은 선별된 "고급" 코퍼라의 혼합물에서 훈련된다. 이러한 큐레이션 과정은 광범위한 제로샷 일반화 능력을 가진 성능 모델을 생산하는 데 필요할 것으로 판단된다. 그러나 수조 개의 토큰에 대한 사전 훈련이 필요한 더 큰 모델이 고려됨에 따라 확장성이 얼마나 있는지, 그리고 곧 고유한 고품질 데이터가 고갈될지 여부는 불분명하다. 이전 믿음과 달리, 우리는 적절하게 필터링되고 중복 제거된 웹 데이터만으로도 강력한 모델로 이어질 수 있음을 보여주며, 심지어 더 파일에서 훈련된 최첨단 모델의 성능을 상당히 능가한다. 광범위한 필터링에도 불구하고 웹에서 추출한 고품질 데이터는 여전히 풍부하며 커먼크롤에서 5조 개의 토큰을 얻을 수 있다. 우리는 RefinedWeb 데이터 세트에서 6,000억 토큰의 추출물과 이에 대해 훈련된 1.3/7.5B 매개변수 언어 모델을 공개적으로 공개합니다*.

각주 *: [https://huggingface.co/datasets/tiiuae/falcon-refinedweb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)

[MISSING_PAGE_FAIL:2]

## 2 관련 작업

대형 언어 모델에 대한 사전 훈련 데이터.초기 대형 언어 모델은 길고 일관성 있는 문서를 갖는 데이터 세트의 중요성을 식별하였다(Radford et al., 2018; Devlin et al., 2019). 이전에 사용된 문장 단위 데이터 세트(Chelba et al., 2013)에서 넘어갈 때, 그들은 대신 문서 중심의 단일 도메인 말뭉치인 위키피디아 또는 북코퍼스(Zhu et al., 2015)를 활용했다. 모델이 규모가 증가함에 따라 대규모 웹 스크래프를 기반으로 한 데이터 세트가 보급되었다(Ortiz Suarez et al., 2019; Raffel et al., 2020). 그러나 추가 연구에서는 이러한 비표적 웹 스크랩이 인간 큐레이트 데이터(Radford et al., 2019)에 미치지 못하여 웹 데이터를 책, 기술 기사 및 소셜 미디어 대화와 결합하는 더 파일(Gao et al., 2020)과 같은 큐레이트 데이터 세트가 광범위하게 채택되었다고 주장했다. 규모에서, 약한 신호들을 활용함으로써 인간 큐레이션 프로세스를 모방하는 것이 제안되었다: 예를 들어, 포럼의 상단 링크들을 크롤링함으로써(Gokaslan 등, 2019). 표적화된 말뭉치는 또한 도메인-특정 모델을 생성할 수 있거나(Beltagy et al., 2019), 또는 모델의 표현성을 넓힐 수 있다(예를 들어, 대화 양식 Adiwardana et al. (2020); Thoppilan et al. (2022)). 최신 대형 언어 모델(Brown et al., 2020; Rae et al., 2021; Chowdhery et al., 2022; Scao et al., 2022)은 거대한 웹 스크레이프와 소위 "고품질" 큐레이팅된 단일 도메인 소스(예를 들어, 뉴스, 책, 기술 논문, 소셜 미디어 대화)를 모두 결합한 거대 집합 말뭉치에 대해 트레이닝된다. 이러한 표적화된 소스는 종종 업샘플링되며, 최종 데이터 세트에서 표현을 증가시키는 것이 가장 일반적이다. 이러한 집계된 데이터 세트에 의해 네 번째로 가져온 다양성과 "고품질"은 모델 품질의 중심인 것으로 생각되며, 웹 데이터만으로는 강력한 대규모 언어 모델을 훈련하기에 불충분한 것으로 간주된다(Liu et al., 2019; Scao et al., 2022).

웹 데이터에 대한 파이프라인.대용량 웹 데이터 세트는 일반적으로 공개적으로 사용할 수 있는 인터넷 스크래플인 커먼크롤을 기반으로 하며, 현재 12년 동안 실행되었으며 페타바이트의 데이터를 수집했다. 인터넷 전체에서 스크래핑된 데이터로 작업하는 것은 독특한 과제를 제시한다: 특히, 상당 부분은 저품질 기계 생성 스팸 또는 음란 콘텐츠이다(Trinh and Le, 2018; Kreutzer et al., 2022). 따라서, 필터링되지 않은 웹 데이터에 대한 트레이닝은 바람직하지 않으며, 그 결과 모델들이 제대로 수행되지 않는다(Raffel et al., 2020). 현대 파이프라인들은 이 바람직하지 않은 콘텐츠를 필터링하는 것에 초점을 맞춘다(Wenzek et al., 2020). 넓게 말하면, 이러한 파이프라인들은 일반적으로 다양한 단계들을 결합한다: (1) _언어 식별_, 저렴한 n-그램 모델들(예를 들어, fastText Joulin 등(2016)); (2) _필터링 규칙들 및 휴리스틱_, 예를 들어, 유효한 구두점을 갖는 라인들만을 유지하거나, 너무 많은 심볼들을 갖는 라인들을 폐기하거나, 금지 단어들을 포함하는 문서들을 제거하는 것(Grave 등, 2018; Raffel 등, 2020); (3) _ML 기반 품질 필터링_, 유사한 고품질 웹 문서들을 식별하기 위해 알려진 골드 데이터에 대해 트레이닝된 경량 모델들을 사용하는 것(Wenzek 등, 2020; Brown 등, 2020); (4) _중복 제거_, 정확한 중복 스팬들 또는 유사한 문서들 중 하나를 제거하는 것(Lee 등, 2022). 일부 필터링이 필요하지만 과도한 필터링은 모델에 바람직하지 않은 편향을 초래할 수 있다. 이는 소수자에게 과도하게 영향을 미칠 수 있으며(Dodge et al., 2021), 의사 크롤링과 같은 관행의 채택을 동기 부여하며, 허용되는 URL은 수동으로 큐레이팅된다(Laurencon et al., 2022).

중복제거.중복제거는 데이터 세트에서 반복된 추출 및 문서를 제거합니다. 이는 모든 문자에서 동일하거나 일부 유사성 메트릭을 기반으로 하는 정확한 일치 또는 근사 일치일 수 있습니다. 정확한 복제의 경우, 접미사 배열(Manber and Myers, 1993)을 사용하여 최소 길이의 정확한 부분 문자열을 일치시키는 것이 일반적이다. 퍼지 중복의 경우, MinHash(Broder, 1997) 또는 SimHash(Charikar, 2002)와 같은 국부적으로 민감한 해시에 기초한 방법이 대형 언어 모델의 사전 훈련 데이터에 채택되었다(Brown et al., 2020; Zeng et al., 2021; Rae et al., 2021). 최근 Abbas et al.(2023)은 근사 매칭 알고리즘에서 의미론적 이해를 불어넣기 위해 사전 훈련된 모델의 임베딩을 활용하는 것을 제안했다. 중복제거는 언어 모델 개선에 중요한 역할을 하는 것으로 확인되었다(Allamanis, 2019; Lee et al., 2022). 특히, 큰 모델에서 특히 문제가 되는 암기(Carlini et al., 2022)를 감소시킨다(Carlini et al., 2021). 또한, 반복된 데이터는 파라미터 카운트가 증가함에 따라 모델 품질에 점점 더 해로운 것으로 나타났다(Hernandez et al., 2022). 1B 파라미터 모델의 경우, 100개의 중복이 유해하며, 175B에서는 몇 개의 중복도 불균형적인 영향을 미칠 수 있다. 이 작업과 동시에 피티아 모델 제품군은 중복제거 The Pile이 제로샷 성능에 제한된 영향을 미친다는 것을 발견했으며(Biderman 등, 2023), 중복제거가 주로 웹 기반 데이터 세트에 대한 것만큼 선별된 코퍼스와 관련이 있는지 의문을 제기했다.

부록 F.3의 표 12에 추가 정보와 함께 표 1의 LLM에 대해 널리 채택된 일부 기존 사전 훈련 영어 데이터 세트에 대한 개요를 제공한다. 또한 최근 인기 있는 오픈 모델(Zhang 등, 2022; Touvron 등, 2023)은 종종 구성요소의 혼합 및 일치를 수행하여 The Pile(Gao 등, 2020)을 간접적으로 활용한다는 점에 주목한다.

대규모 고품질 웹 사전 훈련 데이터 세트를 구축하는 데 중점을 두고, 우리는 (1) 문서 준비 및 필터링을 위한 모범 사례를 집계하고 결합하고, 라인별 수정을 도입한다; (2) 매우 대규모로 정확 및 퍼지 중복 제거를 결합한다; (3) 최종 데이터 세트의 규모는 독특하며, 총 5,000억 토큰 및 허용 라이센스가 있는 공개용으로 사용할 수 있는 6,000억 토큰 추출이다. 리파인드웹에서 대규모 모델을 훈련하는 것은 또한 웹 데이터가 큐레이팅된 코퍼라보다 엄격히 나쁘다는 일반적인 믿음에 도전하게 한다.

## 3 Macrodata Refinement and RefinedWeb

CommonCrawl에서 웹 데이터를 매우 대규모로 필터링하고 중복 해제하기 위한 파이프라인인 **MDR**(매크로 데이터 정제)을 소개합니다. MDR을 사용하여 웹 데이터만 기반으로 5조 토큰의 영어 사전 훈련 데이터 세트인 RefinedWerb를 생산한다. 엄격한 필터링과 엄격한 중복 제거를 활용하여 웹 데이터의 품질을 높이고 최신 모델을 훈련하는 데 사용되는 집계된 말뭉치의 품질과 일치하는 말뭉치로 증류합니다.

디자인 원칙.다음 지침을 준수합니다.

* **먼저 크기 조정** MDR에서 40-200B 매개 변수 모델을 학습 하는 데 사용할 데이터 집합을 생성 하 고 수 조 개의 토큰이 필요 합니다 (호프만 등, 2022). 영어 전용 RefinedWeb의 경우 3-6조 토큰의 크기를 목표로 합니다. 특히, 노동 집약적인 인간 큐레이션 프로세스를 피하고 이질적인 단일 도메인 소스 대신 커먼크롤에 중점을 둔다.
* **엄격한 중복 제거** 대규모 언어 모델에 대한 중복 제거의 가치를 입증한 Lee 등(2022)의 작업에서 영감을 받아 엄격한 중복 제거 파이프라인을 구현합니다. 우리는 정확한 중복 제거와 퍼지 중복 제거를 모두 결합하고 다른 사람들이 보고한 것보다 훨씬 높은 제거율로 이어지는 엄격한 설정을 사용한다.
* **중성 필터링.** 모델에 바람직하지 않은 편향을 더 이상 도입하지 않으려면 (Dodge 등, 2021; Welbl 등, 2021) 언어 식별 외부에서 ML 기반 필터링을 사용하는 것을 피합니다. 우리는 간단한 규칙과 휴리스틱을 고수하며 성인 콘텐츠에 대해서는 URL 필터링만 사용한다.

표 2와 그림 2는 전체 MDR 파이프라인을 간략하게 설명한다.

### 문서 준비: 데이터 읽기, URL 필터링, 텍스트 추출 및 언어 식별

데이터 읽기.CommonCrawl은 WARC(원시 HTML 응답) 또는 WET 파일(일반 텍스트만 포함하도록 전처리됨)에서 사용할 수 있습니다. 개별 파일은 지정된 URL의 페이지에 해당하며, 이는 단일 문서/샘플을 구성합니다. WET 파일로 작업하면 자체 HTML 추출을 실행할 수 없지만 이전 작업(Gao 등, 2020; Rae 등, 2021)과 일치하여 WET 파일이 바람직하지 않은 탐색 메뉴, 광고 및 기타 관련 없는 텍스트를 포함하는 것을 발견했다. 따라서 파이프라인은 wavcio 라이브러리로 읽은 원시 WARC 파일에서 시작됩니다.

URL 필터링.계산량이 많은 처리를 수행하기 전에 URL만을 기반으로 첫 번째 필터링을 수행합니다. 이는 사기 및/또는 성인 웹사이트(예를 들어, 주로 포르노, 폭력, 도박과 관련된 것 등)를 대상으로 한다. 우리는 두 가지 규칙을 기반으로 필터링한다: (1) 4.6M 도메인의 집계된 블록 리스트; (2) 우리가 선별하고 심각도에 따라 칭량한 리스트로부터의 단어의 존재에 기초한 URL 점수. 우리는 일반적으로 사용되는 블록 리스트가 인기 있는 블로깅 플랫폼이나 대중 문화 웹사이트와 같은 많은 거짓 긍정들을 포함한다는 것을 발견했다. 또한 단어 기반 규칙(C4, Raffel 등(2020))은 의료 및 법률 페이지가 쉽게 차단될 수 있다. 이 조사를 기반으로 한 최종 세부 규칙은 부록 G.1에서 공유된다. 정제된 웹이 선별된 말뭉치와 함께 집계 데이터 세트의 일부로 사용되도록 의도하기 때문에 고품질 데이터의 공통 소스인 위키피디아, arXiv 등도 필터링했다. 자세한 목록은 부록 G.1.3에서 확인할 수 있습니다.

그림 2: **Macrodata Refinement의 후속 단계** 는 원래 CommonCrawl에 있는 문서의 거의 90%를 제거 합니다.* * 특히 필터링 및 중복 제거 결과 사용 가능한 데이터가 절반으로 줄어듭니다. 문서의 약 50%는 영어가 아닌 경우 폐기되고, 24%는 품질이 부족한 경우, 12%는 중복됩니다. 우리는 각 이전 단계에 대한 제거율(회색)을 보고하고 전반적으로 유지율(음영)을 보고한다. 문서 준비 단계에서 문서의 %로 측정한 다음 토큰으로 측정한 비율입니다.

텍스트 추출.메뉴, 머리글, 바닥글, 광고 등을 무시하고 페이지의 주요 내용만을 추출하고자 한다. 로푸킨(2019)은 트라필라투라(Barbaresi, 2021)가 블로그 게시물과 뉴스 기사로부터 콘텐츠를 검색하는 데 가장 적합한 비상업 라이브러리임을 발견했다. 이것은 CommonCrawl을 구성하는 페이지 종류의 좁은 부분집합일 뿐이지만, 우리는 이 발견이 더 광범위하게 유지된다는 것을 발견했다. 텍스트 추출을 위해 trafilatura를 사용하고 정규식을 통해 추가 형식을 적용합니다. 새 행을 두 개의 연속 행으로 제한하고 모든 URL을 제거합니다.

Language identification.We used the fastText language classifier of CCNet (Wenzek et al., 2020) at the document-level: it used characters n-gram and training on Wikipedia, supporting 176 languages. 우리는 상위 언어 점수가 0.65 미만인 문서를 제거한다: 이것은 보통 자연 텍스트가 없는 페이지에 해당한다. 이 논문을 위해 우리는 영어에 초점을 맞추고; 정제된 웹은 다른 언어에 대해서도 파생될 수 있으며, 자세한 내용은 부록 D를 참조하십시오.

우리가 이 단계에서 검색하는 RW-Raw라는 데이터는 최소한의 필터링으로 추출할 수 있는 것에 해당한다. 이 단계에서는 원본 문서의 48%만이 남아 있으며 대부분 언어 식별에 의해 걸러진다.

### 필터링: 문서별 및 라인별

반복 제거.크롤링 에러 및 저품질 소스들로 인해, 많은 문서들은 반복된 시퀀스들을 포함한다: 이것은 최종 모델에서 병리학적 거동을 야기할 수 있다(Holtzman et al., 2019). 나중에 중복 제거 단계에서 이 콘텐츠를 잡을 수 있지만 초기에 문서적으로 더 저렴하고 쉽게 잡을 수 있습니다. 우리는 Rae et al.(2021)의 휴리스틱을 구현하고, 과도한 선, 단락 또는 n-그램 반복이 있는 문서를 제거한다.

문서별 필터링 페이지의 상당 부분은 기계 생성 스팸으로, 주로 키워드 목록, 상용구 텍스트 또는 특수 문자 시퀀스로 만들어진다. 이러한 문서들은 언어 모델링에 적합하지 않으며, 이를 필터링하기 위해 Rae et al.(2021)의 품질 필터링 휴리스틱을 채택한다. 이는 전체 길이, 기호 대 단어 비율 및 문서가 실제 자연 언어임을 보장하는 기타 기준 측면에서 이상치를 제거하는 데 중점을 둡니다. 이러한 필터는 영어에서 다른 언어로 순진하게 전달되면 과적합으로 이어질 수 있으므로 언어별로 적응해야 한다.

라인별 수정.사전처리된 파일에 의존하는 대신에 트라필라투라를 사용함으로써 야기된 개선에도 불구하고, 많은 문서들이 바람직하지 않은 라인(예를 들어, 소셜 미디어 카운터 3 좋아요, 네비게이션 버튼)으로 인터레이스된 채로 남아 있다. 따라서, 우리는 이러한 바람직하지 않은 항목을 대상으로 라인 보정 필터를 고안했다. 이러한 수정 사항이 문서의 5% 이상을 제거하면 문서를 완전히 제거합니다. 자세한 내용은 부록 G.2를 참조하십시오.

이 단계에서 우리가 검색한 데이터는 MDR 파이프라인에서 모든 필터링 휴리스틱을 거쳤다. 이 데이터 세트를 RW 필터링이라고 합니다. CommonCrawl 문서의 23%만이 남아 있으며 RW-Raw 문서의 약 50%가 필터링에 의해 제거된다.

### 중복 제거: 퍼지, 정확 및 전체 덤프

필터링 후, 데이터 품질이 향상되었지만, 문서의 많은 부분이 문서에 걸쳐 반복된다. 이는 크롤러가 동일한 페이지를 여러 번 간접적으로 타격하거나, 상용구 내용이 반복되거나(예를 들어, 라이센스), 심지어 표절에 기인할 수 있다. 이러한 중복은 일반화 대신 암기를 선호하여 모델에 강력한 영향을 미칠 수 있다(Lee et al., 2022; Hernandez et al., 2022). 중복제거는 비용이 많이 들기 때문에, 공공 데이터 세트에서 제한적으로 채택되었다(Ortiz Suarez et al., 2019; Raffel et al., 2020). 우리는 퍼지 문서 일치와 정확한 시퀀스 제거를 모두 결합한 공격적인 중복 제거 전략을 채택한다.

퍼지 중복 제거.우리는 MinHash (Broder, 1997)를 적용하여 유사 문서를 제거한다. 각 문서에 대해 스케치를 계산하고 다른 문서와의 근사 유사도를 측정하여 결국 중복도가 높은 쌍을 제거한다. MinHash는 템플릿 문서를 찾는 데 탁월합니다. 특정 엔터티만 다른 라이선스, 웹사이트 전체에서 반복되는 자리 표시자 SEO 텍스트 - 참고

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline
**Document preparation** & & & & **Filtering** & & **Deduplication** & \\ \hline
**URL filtering** & **Text extraction** & **Language identification** & **Document-wise filtering** & **Line-wise filtering** & **Deduplication** & **URL deduplication** \\ \hline Aggregated block-list, URL scoring, common HQ sources blocked & From WARC using warcio, frafilatura for stratification & fastText classification from CCNet, thresholding on top language score & In-document repo-utility heuristics from MassiveWeb & Remove undesirable lines (call to actions, navigation buttons, social counters, etc.) & Fuzzy deduplication with suffix arrays & Remove URLs revisited across CommonCrawl dumps \\ Appendix G.1 & Barbaresi (2021) & Wenzek et al. (2020) & Rae et al. (2021) & Appendix G.2 & Lee et al. (2022) & Section 3.3 \\ \hline \hline \end{tabular}
\end{table}
표 2: **매크로데이터 정제** 는 고품질 웹 데이터를 생성하기 위해 최신 및 새로운 접근법(URL 점수 매기기, 라인별 필터링 등)의 모범 사례를 집계합니다.* * 중복 제거에서 MDR은 수행되는 규모와 적용 범위 및 확장성을 개선하기 위해 후속적으로 퍼지 및 정확한 부분 문자열 방법을 적용할 때 모두 고유합니다.

부록 H.1에서 가장 큰 클러스터입니다. 문서당 9,000개의 해시를 사용하여 MinHash 중복 제거를 수행합니다. 5-gram에 걸쳐 계산되고 450개의 해시로 구성된 20개의 버킷으로 분할됩니다. 더 파일의 10개 해시(Gao et al., 2020)와 같이 덜 공격적인 설정을 사용하면 중복 제거율이 낮아지고 모델 성능이 악화된다는 것을 발견했다. 민해시 설정에 대한 자세한 내용은 부록 G.3.1을 참조하십시오.

정확한 중복제거.정확한 부분 문자열은 문서 수준 대신 시퀀스 수준에서 작동하여 접미사 배열(Manber and Myers, 1993)을 사용하여 정확한 토큰별 일치인 문자열 간의 일치(예: 부록 H.2에 표시된 대로 전체 문서를 손상시키지 않을 수 있는 특정 거부권 또는 통지)를 찾습니다. Lee et al.(2022)의 구현을 사용하여 50개 이상의 연속 토큰의 일치를 제거한다. 우리는 특정 기간을 제거함으로써 정확한 부분 문자열이 문서를 변경한다는 점에 주목한다: 또한 전체 문서를 삭제하거나 중복된 문자열을 절단하는 대신 손실 마스킹하는 실험을 했지만, 이는 제로 샷 성능에 큰 변화를 가져오지 않았다.

URL 중복제거.계산상의 제약으로 인해 RW-Filtered에서 직접 중복제거를 수행하는 것은 불가능하다. 대신 CommonCrawl을 각 파트가 각 덤프의 100분의 1을 포함하는 100개의 파트로 분할하고 개별 파트에 대해 중복 제거를 수행한다. 대부분의 더 큰 중복 클러스터(예: 라이선스, 공통 스팸)는 부품 간에 공유되고 효과적으로 제거됩니다. 그러나 커먼크롤 덤프는 콘텐츠의 변경에도 불구하고 덤프 간에 URL이 재방문되는 등 상당한 중복이 있음을 발견했다. 따라서 각 파트에서 보관한 모든 샘플의 URL 목록을 보관하고 처리 중인 후속 파트에서 제거합니다.

## 4 Experiments

이제 정제된 웹이 선별된 말뭉치 및 최첨단 언어 모델로 얻은 제로샷 성능과 일치하는 강력한 모델을 훈련하는 데 사용될 수 있음을 검증한다. 먼저 평가 및 사전 훈련 설정과 비교 모델에 대해 논의한다. 우리는 내부적으로 다른 인기 있는 데이터 세트와 비교하기 위해 소규모 실험을 수행하고 RefinedWeb의 세 가지 주요 단계(raw, filtered, final)를 제거한다. 그런 다음 350GT에서 훈련된 1B 및 7B 모델로 확장하여 최첨단 모델과 비교한다. 마지막으로 MDR 파이프라인을 기존 프리트레이닝 데이터셋에 적용하여 추가적인 개선점을 제공할 수 있음을 보인다.

### Setting

평가.사전 훈련 데이터 세트를 연구하는 이전 작업(Rae et al., 2021; Lee et al., 2022)과의 분산에서, 검증 손실을 측정하기보다는 많은 작업에 걸쳐 제로 샷 일반화에 대한 평가에 초점을 맞춘다. 복잡함만으로는 최종 작업 성능과 상충될 수 있으며(Tay et al., 2021), LLMs에 대한 현대 작품은 주로 제로 샷 성능을 보고한다(Brown et al., 2020; Rae et al., 2021; Chowdhery et al., 2022). 더욱이, 제로-샷 일반화는 자기회귀 디코더-전용 모델들에 대한 "자연적인" 설정이며, 여기서 이들은 최상의 성능을 수행한다(Wang et al., 2022). 우리의 평가 설정은 빅 사이언스의 아키텍처 및 스케일링 그룹에서 사용된 것에서 영감을 받았다(Scao et al., 2022).

우리는 인기 있는 Eleuther AI 평가 하네스(가오 외, 2021)를 기반으로 평가를 수행하여 제로 샷 환경에서 광범위한 작업에 걸쳐 평가할 수 있다. 우리는 우리가 할 수 있는 작업의 집합체를 확인했다: (1) 작은 규모의 신호 획득(즉, 제로 제로 샷 성능 없음)

\begin{table}
\begin{tabular}{l l c c c c} \hline \hline
**Tasks** & **Type** & **Random** & **small** & **core** & **main** & **ext** \\ \hline HeILAsWang (Zellers et al., 2019) & Sentence completion & 25.0 & ✓ & ✓ & ✓ & ✓ \\ LAMBADA (Paperno et al., 2016) & Sentence completion & 0.0 & ✓ & ✓ & ✓ & ✓ \\ Winogrande (Sakaguchi et al., 2021) & Conference resolution & 50.0 & ✓ & ✓ & ✓ & ✓ \\ PIQA (Bik et al., 2020) & Multiple-choice question answering & 50.0 & ✓ & ✓ & ✓ & ✓ \\ ARC (Clark et al., 2018) & Natural language inference & 25.0 & ✓ & ✓ & ✓ & ✓ \\ OpenBookQA (Mihaylov et al., 2018) & Multiple-choice question answering & 25.0 & ✓ & ✓ & ✓ & ✓ \\ BooD (Clark et al., 2019) & Multiple-choice question answering & 50.0 & ✓ & ✓ & ✓ & ✓ \\ COPA (Gordon et al., 2012) & Sentence completion & 50.0 & & ✓ & ✓ & ✓ \\ CB (De Marneffe et al., 2019) & Natural language inference & 33.3 & & ✓ & ✓ \\ RTE (Dagan et al., 2010) & Natural language inference & 50.0 & & ✓ & ✓ \\ ReCoRD (Zhang et al., 2018) & Question answering & 0.0 & & & ✓ & \\ ANLI (Nie et al., 2019) & Natural language inference & 33.3 & & & ✓ \\ LogiQA (Liu et al., 2021) & Multiple-choice question answering & 25.0 & & & ✓ \\ HeadQA (Vilares and Gomez-Rodriguez, 2019) & Multiple-choice question answering & 20.0 & & & ✓ \\ MathQA (Amini et al., 2019) & Multiple-choice question answering & 20.0 & & & ✓ \\ PROSY (Arroe-Ouelleit et al., 2021) & Paraphrasing identification & 50.0 & & & & ✓ \\ PubMedQA (Jin et al., 2019) & Multiple-choice question answering & 50.0 & & & ✓ \\ SciQ (Wehl et al., 2017) & Multiple-choice question answering & 25.0 & ✓ & & ✓ \\ \hline \hline \end{tabular}
\end{table}
표 3: **RefinedWeb에서 훈련된 모델을 평가하고 최신 기술과 비교하기 위해 제로 샷 성능을 측정하기 위해 18개의 작업에 걸쳐 4개의 집합체를 구축합니다. 소형은 내부 삭제를 위해 구축되었으며, 소규모로 일관된 성능을 갖는 태스크를 기반으로 하며, 코어는 모델의 공용 스위트(Dey et al., 2023; Biderman et al., 2023)에 대해 일반적으로 보고되는 태스크를 기반으로 하며, 메인은 GPT-3 및 PaLM 논문의 태스크를 기반으로 하며(Brown et al., 2020; Chowdhery et al., 2022), ext는 BigScience Architecture and Scaling Group(Scao et al., 2022)에 의해 사용되는 태스크를 기반으로 한다. 보고된 모든 결과에 대해 임의의 평가 설정에서 얻은 \(\dagger\) 결과와 EAI Harness (Gao 등, 2021)에서 얻은 \(*\) 결과를 플래그하고 모든 모델에 사용합니다.*ablations; (2) 다른 모델에서 보고된 결과와 비교합니다. 우리는 표 3에서 이 네 가지 응집체를 작고(절제용), 핵심, 주요, ext(비교용)로 요약한다.

다양한 설정에서 훈련되고 평가된 모델 간의 비교는 많은 외부성이 1개의 987개의 결과(예: 훈련 대 추론의 수치 정밀도, 사용된 프롬프트)에 영향을 미칠 수 있으므로 풀기 어렵다. 우리는 세 가지 수준의 비교를 구분한다. (1) 사전 훈련 데이터 세트만 다른 코드 베이스 내에서 훈련되고 평가된 모델과의 내부 비교; (2) 벤치마크 수준 비교는 다른 코드 베이스로 훈련되었지만 Eleuther AI 하네스로 평가된 모델과의 비교, Scao 등(2022), Black 등(2022), Aleph Alpha(2023), Dey 등(2023), 이후 \(*\); (3) Brown 등(2020), Chowdhery 등(2022), 이후 \(\dagger\)의 결과를 취한다. 평가에 대한 자세한 내용은 부록 F.1을 참조하십시오.

**모델.** GPT-3(Brown 등, 2020)과 유사한 구성 및 하이퍼파라미터를 기반으로 1B, 3B 및 7B 매개 변수 자동 회귀 디코더 전용 모델을 학습하며 주로 ALiBi(Press 등, 2021) 사용에 따라 분기됩니다. 우리는 사용자 지정 코드 베이스에서 FlashAttention (Dao et al., 2022)를 사용한다. 사전 훈련 설정으로 인한 편차를 제어하기 위해 The Pile 및 RefinedWeb에서 내부 모델을 훈련했으며, 다른 모델과 인라인으로 수행할 The Pile 모델을 발견했다. 소규모 및 절제 연구의 경우(섹션 4.2의 전반부; 섹션 4.3) 1B 및 3B 매개변수 모델에 대해 각각 27B 및 60B 토큰에 대해 Hoffmann 등(2022)의 스케일링 법칙에 따라 최적성으로 모델을 훈련한다. 우리의 접근법을 입증하는 주요 실험(섹션 4.2의 Falcon-RW 모델)을 위해, 우리는 인기 있는 공개 모델(Brown et al., 2020; Wang and Komatuszaki, 2021; Scao et al., 2022)에 따라 350GT로 모델을 훈련시킨다. 최근에 도입된 LLaMA 모델(Touvron et al., 2023)과 비교하지 않는데, 그 중 가장 작은 모델이 가장 큰 모델보다 x2.5 더 많은 컴퓨팅에 대해 훈련되어 데이터 세트별로 유의미한 비교가 이루어지지 않기 때문이다. 비교하는 모델 및 사전 훈련 데이터 세트에 대한 보다 심층적인 개요는 부록 F를 참조하십시오.

### 웹 데이터만 큐레이팅된 말뭉치를 능가할 수 있습니까?

우리는 웹 데이터만으로 모델이 선별된 코퍼스에 대해 훈련된 다른 모델을 능가하는 결과를 가져올 수 있음을 입증하려고 노력한다. 이를 위해 먼저 인기 있는 웹 및 큐레이트된 데이터 세트에서 최적성(27GT 및 60GT)으로 훈련된 1B 및 3B 매개변수 모델을 사용하여 소규모 연구를 수행한다. 그런 다음 350GT에서 훈련된 1B 및 7B 모델까지 확장하고 제로샷 일반화를 최신 모델과 비교한다.

소규모 연구.우리는 먼저 인기 있는 공개 웹 데이터 세트(OSCAR-2019(Ortiz Suarez et al., 2019), OSCAR-2022(Abadji et al., 2021), C4(Raffel et al., 2020)), The Pile(Gao et al., 2020)를 가장 인기 있는 공개 사용 큐레이트 데이터 세트로 간주하고, RefinedWeb의 변형(RW-Raw, RW-Filtered, RW)을 섹션 3에서 설명한 대로 사용한다. 이 첫 번째 연구의 경우, 모든 모델은 동일한 아키텍처와 동일한 내부 코드 베이스로 훈련되며, 또한 모두 동일한 프레임워크 전용 사전 훈련 데이터 세트 내에서 평가된다.

6개의 태스크의 작은-=+ 집합에 대한 평균 결과는 표 4에 나와 있다. 우리는 큐레이션이 수행 언어 모델에 대한 은 총알이 아님을 보여주는 The Pile에 비해 모든 웹 데이터 세트의 상대적으로 강한 성능을 관찰한다. C4는 Scao et al.(2022)의 연구 결과에 따라 강력한 사전 훈련 데이터 세트임을 발견했지만, The Pile은 벤치마크에서 상대적으로 성능이 더 낮다. OSCAR-22.01에 대한 상대적으로 실망스러운 결과는 중복 제거 없이 배포되는 데이터 세트의 주요 버전 때문일 수 있다. RefinedWeb과 관련하여 필터링 및 중복 제거 모두 성능을 크게 향상시킵니다.

실제 규모 모델.이제 이러한 결과를 최신 모델과의 비교를 통해 검증한다. 350GT에서 1B 및 7B 모델을 훈련하여 이전 실험을 확장하고 사전 훈련 설정의 영향에 대한 제어로 더 파일에서 350GT에서 1B 모델을 훈련한다. GPT-3 시리즈(Brown et al., 2020), FairSeq 시리즈(Artetxe et al., 2021), GPT-Neo(X)/J 모델(Black et al., 2021; Wang and Komatuszaki, 2021; Black et al., 2022), OPT 시리즈(Zhang et al., 2022),

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline \multicolumn{3}{c}{**Massive web datasets**} & \multicolumn{2}{c}{**Curated**} & **Ours** & \\ \hline  & OSCAR-21.09 & OSCAR-22.01 & C4 & \(\blacktriangledown\) The Pile & RW-Raw & RW-Filtered & \(\blacklozenge\) RefinedWeb \\ \hline
**1B@27GT** & 55.0\% & 52.7\% & 55.7\% & 53.4\% & 52.7\% & 54.3\% & **56.2\%** \\
**3B@60GT** & 59.1\% & 55.9\% & 59.6\% & 57.9\% & 57.4\% & 58.2\% & **59.8\%** \\ \hline \hline \end{tabular}
\end{table}
표 4: **큐레이션은 제로 샷 일반화를 위한 은 총알이 아닙니다. \(\blacklozenge\) RefinedWeb에서 훈련된 소규모 모델이 웹 데이터(C4, OSCAR) 및 큐레이트된 말뭉치(\(\blacktriangledown\) The Pile에서 훈련된 모델보다 우수합니다. 작은 골재에서 제로 샷의 평균 정확도입니다. 모든 모델은 동일한 아키텍처로 훈련되고 하이퍼파라미터를 사전 훈련한다. 중복 제거가 선택 사항이기 때문에 OSCAR-22.01이 다른 데이터 세트보다 성능이 현저히 떨어집니다. C4는 OSCAR-21.09가 약간 뒤처진 강력한 기준선이지만 RefinedWeb이 웹 데이터 세트와 가장 인기 있는 큐레이트 데이터 세트인 The Pile보다 우수하다는 것을 발견했다. 필터링 및 중복 제거 모두 제로 샷 성능을 향상시키는 데 크게 기여합니다.**BigScience Architecture and Scaling Pile 모델(Scao et al., 2022), PaLM-8B(Chowdhery et al., 2022), Aleph Alpha Luminous 13B(Aleph Alpha, 2023), Pythia 시리즈(Biderman et al., 2023) 및 Cerebras-GPT 시리즈(Dey et al., 2023). GPT-3의 경우 EleutherAI LM 평가 하네스(Gao 등, 2021)(*)를 사용하여 API(배비지와 큐리)를 통해 얻은 결과와 다른 평가 설정(\(\dagger\))으로 논문에 보고된 결과를 구별한다. PaLM 및 OPT의 경우 다른 평가 제품군(\(\dagger\))에서도 결과가 얻어졌으며 다른 모델의 경우 평가 하네스(*)에서도 얻어져 보다 직접적인 비교가 가능했다.

메인-agg에 대한 결과는 그림 1과 코어-agg 및 엑스트-agg에 대한 그림 3에 나와 있다. 우리는 개방형 모델이 유사한 평가 설정을 사용할 때에도 GPT-3-와 같은 개인 선별된 코퍼라에서 훈련된 모델보다 일관되게 성능이 낮다는 것을 발견했다. 반대로 RefinedWeb에서 훈련된 모델은 The Pile에서 사용되는 일반적인 고품질 소스가 RefinedWeb에서 제외되었음에도 불구하고 웹 데이터만을 사용하여 GPT-3 시리즈의 성능을 일치시킬 수 있다(부록의 표 14 참조). 마지막으로, 더 파일에서 훈련된 내부 모델은 빅사이언스 아키텍처 및 스케일링 모델에 따라 수행된다는 점에 주목한다. 이는 우리의 사전 훈련 설정이 RefinedWeb에서 훈련된 모델의 성능 증가의 주요 원천이 될 가능성이 없음을 강조한다.

**찾아보기** 데이터 품질 및 LLM에 대한 기존 믿음에 도전하는 경우 적절하게 필터링되고 중복 제거된 웹 데이터에 대해 학습된 모델 _alone_ 은 큐레이트된 데이터에 대해 학습된 모델의 성능과 일치할 수 있습니다.

### 다른 말뭉치가 MDR의 이점을 얻습니까?

MDR 파이프라인에서 개별 구성요소의 기여도를 삭제하고 성능을 평가하는 것은 어렵다: 대부분의 휴리스틱의 경우 합의된 그라운드 트루스가 없으며 사전 훈련 후 충분한 제로 샷 신호를 생성하기에는 변화가 너무 미미할 수 있다. 섹션 4.2의 전반부에서 우리는 RefinedWeb의 후속 단계(raw, filtered, final)가 성능 개선으로 이어진다는 것을 확인했다. 이 섹션에서는 MDR의 필터링 및 중복 제거 단계를 인기 있는 사전 훈련 데이터 세트에 독립적으로 적용하는 것을 제안하여 널리 일반화되는지 여부를 연구한다.

표 5의 소형agg에 대한 결과를 보고한다. 첫째, 필터링으로 인한 개선이 체계적이지 않다는 것을 알 수 있다. 파일에서 우리는 책과 코드를 삭제하지 않기 위해 줄 길이와 문자 비율 휴리스틱을 조정해야 했다. OSCAR-21.09, C4 및 The Pile의 개선에도 불구하고, 우리의 필터는 OSCAR-22.01의 성능을 악화시키며, 일반적으로 필터링으로부터의 제거율은 다운스트림 정확도와 강하게 상관되지 않는 것으로 보인다. 반대로 중복 제거는 모든 데이터 세트에서 안정적인 부스트를 제공하며 제거 속도는 성능 변화와 더 잘 상관됩니다. 우리는 OSCAR-21.09와 C4가 이미 잘 중복되어 있는 반면, The Pile과 OSCAR-22.01은 40-60%의 중복을 보인다. OSCAR-22.01의 기본 버전은 중복 제거 없이 배포되며, The Pile의 경우, 이는 Zhang 등(2022)의 발견과 일치한다. 마지막으로 필터링과 중복 제거를 결합하면 추가 개선이 이루어지며 흥미롭게도 이제 데이터 세트 간에 성능이 더 균일하지만 차이가 남아 원문 추출 및 처리의 결함을 완전히 보상할 수 없음을 시사한다.

그림 3: **\(\blacktriangled\) RefinedWeb 단독으로 훈련된 모델이 큐레이트된 말뭉치에 대해 훈련된 모델보다 성능이 우수합니다.* * 코어-agg(왼쪽) 및 ext-agg(오른쪽) 작업 집계(자세한 내용은 섹션 4.1 참조), 메인-agg에 대한 결과는 그림 1 참조)에서 평균화된 제로샷 성능입니다. 기존 공개 모델은 원본 GPT-3 시리즈(왼쪽)의 성능과 일치하지 않지만, RefinedWeb에서 훈련된 모델이 \(\blacktriangled\)에서 훈련된 모델보다 훨씬 우수합니다. 파일: 직접 비교 모델(오른쪽)을 포함하여 사전 훈련 설정을 성능 증가의 주요 원인으로 배제합니다. 실제로, 우리의 RefinedWeb 모델은 \(\blacksquare\) GPT-3 모델의 성능과도 일치한다.

MDR을 통해 C4를 처리함으로써 RefinedWeb을 약간 능가할 수 있는 데이터의 하위 집합을 얻을 수 있으며, 이는 C4의 엄격한 필터링(예: 엄격한 NSFW 단어 블록리스트, 3문장 스팬 중복제거)과 자체 필터 및 중복제거를 결합한다. 이러한 조합은 3-6조 토큰의 목표에서 수용할 수 없는 거부율을 초래하지만, 이는 대규모 웹 데이터 세트에서 매우 고품질 하위 집합을 추출할 수 있는 더 짧은 실행에 대한 흥미로운 관점을 나타낸다.

**찾기.** 필터링 휴리스틱에는 원본 종속 조정이 필요할 수 있지만 엄격한 중복 제거는 데이터 세트 전체에서 제로샷 성능을 일관되게 향상시킵니다.

## 5 Limitations

편향.우리는 그림 4에서 RefinedWeb의 독성에 대한 기본 분석을 수행한다. 우리는 Perspective API에서 제공하는 독성의 정의에 따라 RW가 파일만큼 독성이 있음을 발견한다: "무례하거나 무례한 내용"이다. 특히, 이 정의는 사회적 편견이나 유해성에 대한 문제를 다루지 않는다. 우리의 파이프라인이 인기 있는 데이터 세트에 대해 이미 문서화된 것보다 이 측면에서 추가 문제를 도입할 가능성은 낮지만 RefinedWeb의 공개 추출물에 대한 추가 정량적 작업을 권장한다.

여러 시대.조 규모의 사전 훈련 데이터 세트를 구성하기 위해 "고유한" 토큰을 찾는 대신 여러 시대에 걸쳐 데이터를 반복할 수 있습니다. OPT 및 NeoX-20B와 같은 인기 있는 모델은 최대 2개의 에폭에 대해 이 작업을 수행하며 대부분의 큐레이트된 데이터 세트는 2-5회 말뭉치를 업샘플링합니다. 그러나 Hernandez et al.(2022)은 최근 100B+ 매개변수를 가진 모델이 몇 번의 에포크에도 민감할 수 있음을 보여주었다. 우리의 작업과 직교하는 것은 데이터 제약 체제에서 절충점을 탐구하는 연구 라인에 있다: 중복 제거가 더 많은 시대를 지속하는 데 도움이 될 수 있는가? 고품질 데이터의 여러 에포크가 저품질 데이터의 한 에포크보다 나은가요? 자세한 내용은 부록 E.3을 참조하십시오.

**중복제거에 대한 다른 결과** Biderman 등(2023)은 중복제거 The Pile로 인한 제로샷 성능에 제한된 영향을 발견했습니다. 부록 F.2에서 더 논의하지만 선별된 코퍼라에 대한 추가 중복제거 연구를 장려하고 중복제거로 인해 발생하는 토큰의 감소를 보상하기 위해 여러 에포크를 수행해야 하는 데이터 제한 체제에서 중복제거를 연구합니다.

## 6 Conclusion

LLM들이 널리 채택됨에 따라, 스케일링 법칙들의 권고들을 지나 훈련된 모델들은 추론 비용들을 상각하기 위해 점점 더 보편화될 수밖에 없다(Touvron et al., 2023). 이는 공개적으로 사용 가능한 말뭉치를 넘어 수십조 개의 토큰을 사용하여 데이터 세트를 사전 훈련해야 할 필요성을 더욱 촉진할 것이다. 우리는 엄격한 필터링과 중복 제거가 큐레이팅된 코퍼라에서 훈련된 LLM을 능가하는 최첨단 모델과 경쟁력 있는 모델을 생성하기에 적합한 5조 토큰 웹 데이터 세트만을 초래할 수 있음을 입증했다. 우리는 RefinedWeb의 600GT 추출물을 공개적으로 출시하며, RefinedWeb은 이미 Falcon-40B(Almazrouei et al., 2023)와 같은 최첨단 언어 모델을 훈련하는 데 사용되었음을 주목한다.

그림 4: **RefinedWeb의 독성 콘텐츠는 파일과 유사하게 배포됩니다. 원근법 API에 의해 평가된 독성 점수 미만의 문서의 누적 비율입니다.**

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline  & \multicolumn{2}{c}{**Massive web datasets**} & \multicolumn{2}{c}{**Curated**} & **Ours** \\ \hline  & OSCAR-21.09 & OSCAR-22.01 & C4 & \(\blacktriangledown\) Pile & \(\tt@\)RefinedWeb \\ \hline
**Base** & 55.0\% & 52.7\% & **55.7\%** & 53.4\% & 52.7\% \\
**Filtered** & 55.4\% [+.4] & 52.3\% [-.4] & **56.2\% [+.5]** & 54.2\% [+.8] & 54.3\% [+1.6] \\ _제거율_ & _-25.0\%_ & _-39.8\%_ & _-16.4\%_ & _-27.1\%_ & _-50.8\%_ \\
**Deduplicated** & 55.6\% [+.6] & 55.6\% [+2.9] & **55.9\% [+.2]** & 54.5\% [+1.1] & \\ 제거율_ & _-10.8\%_ & _-60.8\%_ & _-7.59\%_ & _-45.3\%_ & \\
**Filt+Dedu.** & 55.5\% [+.5] & 55.4\% [+2.7] & **56.4\% [+.7]** & 55.2\% [+1.8] & 56.2\% [+3.5] \\ _removal rate_ & _-28.2\%_ & _-62.2\%_ & _-17.9\%_ & _-66.0\%_ & _-75.4\%_ \\ \hline \hline \end{tabular}
\end{table}
표 5: **필터링의 개선 사항은 데이터 집합 간에 체계적이지 않지만 중복 제거는 전체적으로 안정적인 성능 향상을 가져옵니다. Zero-shot 정확도는 작은agg 집합에서 평균되었으며 [+x.x]는 베이스에 대해 보고된 제거율인 베이스와 비교하여 절대 이득을 보고한다. 파이프라인의 제한 사항으로 인해 RefinedWeb에 대해 중복 제거 단계를 독립적으로 적용할 수 없습니다.**

## References

* 9, Mannheim, 2021. Leibniz-Institut fur Deutsche Sprache. doi: 10.14618/ids-pub-10468. URL [https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688](https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688).
* Abadji et al.(2022) Abadji, J., Ortiz Suarez, P., Romary, L., and Sagot, B. Towards a Cleaner Document-Oriented Multilingual Crawled Corpus. _ arXiv e-prints_, art. arXiv:2201.06642, 1월 2022.
* Abbas 등(2023) Abbas, A. K. M., Tirumala, K., Simig, D., Ganguli, S., and Morcos, A. S. Semedup: data-efficient learning at web-scale through semantic deduplication. 2023년, _ICLR 2023 기초 모델의 수학적 및 경험적 이해에 관한 워크숍_ 에서.
* Adiwardana et al. (2020) Adiwardana, D., Luong, M. - T., So, D. R., Hall, J., Fiedel, N., Thoppilan, R., Yang, Z., Kulshreshtha, A., Nemade, G., Lu, Y., et al. Towards a human-like open-domain chatbot. _ arXiv preprint arXiv:2001.09977_, 2020.
* 알레프 알파(2023) 알레프 알파. 발광: 성능 벤치마크입니다. _ arXiv preprint arXiv:1810.12885_, 2023. URL [https://www.aleph-alpha.com/pdf/2023_02_AA_Benchmarks_doc.pdf](https://www.aleph-alpha.com/pdf/2023_02_AA_Benchmarks_doc.pdf)
* Allamanis (2019) Allamanis, M. 코드의 기계 학습 모델에서 코드 복제의 역효과. <Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software>에서, pp. 143-153, 2019.
* Almazrouei et al. (2023) Almazrouei, E., Cappelli, A., Cojocaru, R., Debbah, M., Goffinet, E., Heslow, D., Launay, J., Malartic, Q., Noune, B., Pannier, B., and Penedo, G. Falcon-40b: a open large language model with the state-of-the-art performance. 2023년
* Amini et al. (2019) Amini, A., Gabriel, S., Lin, S., Koncel-Kedziorski, R., Choi, Y., and Hajishirzi, H. Mathqa: Towards interpretable math word problem solving with operation-based formalisms. In _Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)_, pp. 2357-2367, 2019.
* Aroca-Ouellette et al. (2021) Aroca-Ouellette, S., Paik, C., Roncone, A., and Kann, K. 프로스트: 공간과 시간을 통해 사물에 대한 물리적 추론. In _Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021_, pp. 4597-4608, 2021.
* Artetxe et al.(2021) Artetxe, M., Bhosale, S., Goyal, N., Mihaylov, T., Ott, M., Shleifer, S., Lin, X. V., Du, J., Iyer, S., Pasunuru, R., et al. Efficient large scale language modeling with mixtures of experts _ arXiv preprint arXiv:2112.10684_, 2021.
* Barbaresi (2021) Barbaresi, A. Trafilatura: 웹 스크래핑 라이브러리 및 명령줄 도구 for Text Discovery and Extraction. <Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations_, pp. 122-131. Association for Computational Linguistics, 2021. URL [https://aclanthology.org/2021.acl-demo.15](https://aclanthology.org/2021.acl-demo.15).
* Beltagy et al. (2019) Beltagy, I., Lo, K., and Cohan, A. Scibert: A pretrained language model for scientific text. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_, pp.3615-3620, 2019.
* Biderman 등(2023) Biderman, S., Schoelkopf, H., Anthony, Q., Bradley, H., O'Brien, K., Hallahan, E., Khan, M. A., Purohit, S., Prashanth, U. S., Raff, E., et al. Pythia: A suite for analyzing large language models across training and scaling. _ arXiv preprint arXiv:2304.01373_, 2023.
* Bisk et al.(2020) Bisk, Y., Zellers, R., Gao, J., Choi, Y., et al. Piga: Reasoning about physical commonsense in natural language. {Proceedings of the AAAI conference on artificial intelligence_, volume 34, pp. 7432-7439, 2020}
* Black et al. (2021) Black, S., Leo, G., Wang, P., Leahy, C., and Biderman, S. GPT-Neo: Mesh-Tensorflow를 사용한 대규모 Autoregressive Language Modeling, 2021년 3월. URL [https://doi.org/10.5281/zenodo.5297715](https://doi.org/10.5281/zenodo.5297715). 이 소프트웨어를 사용하는 경우 이 메타데이터를 사용하여 인용하십시오.
* Black 등 (2022) Black, S., Biderman, S., Hallahan, E., Anthony, Q., Gao, L., Golding, L., He, H., Leahy, C., McDonell, K., Phang, J., et al. Gpt-neox-20b: Open-source autoregressive language model. _ Challenges & Perspectives in Creating Large Language Models_, pp. 95, 2022.
* Broder (1997) Broder, A. Z. 문서의 유사성과 포함에 대해. <프로시빙스>에서. Compression and Complexity of Sequences 1997_, pp. 21-29. IEEE, 1997.
* Brown 등(2020) Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models is few-shot learners. _ Advances in neural information processing systems_, 33:1877-1901, 2020.
* Carlini et al. (2020) Carlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D., Erlingsson, U., et al. Extracting training data from large language models. _30th USENIX Security Symposium (USENIX Security 21)_, pp. 2633-2650, 2021.
* Carlini et al. (2022) Carlini, N., Ippolito, D., Jagielski, M., Lee, K., Tramer, F., and Zhang, C. Quantifying memorization across neural language models. _ arXiv preprint arXiv:2202.07646_, 2022.
* Charikar (2002) Charikar, M. S. 반올림 알고리즘으로부터의 유사성 추정 기법. "Proceedings of the third-fourth annual ACM symposium on Theory of computing"에서, pp. 380-388, 2002.
* Chelba et al. (2013) Chelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T., Koehn, P., and Robinson, T. 통계 언어 모델링의 진행률을 측정하기 위한 10억 단어 벤치마크 _ arXiv preprint arXiv:1312.3005_, 2013.
* Chowdhery et al.(2022) Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. _ arXiv preprint arXiv:2204.02311_, 2022.
* Clark et al.(2019) Clark, C., Lee, K., Chang, M. - W., Kwiatkowski, T., Collins, M., and Toutanova, K. 불크: 자연스러운 예/아니오 질문의 놀라운 난이도를 탐구합니다. In _Proceedings of NAACL-HLT_, pp. 2924-2936, 2019.
* Clark et al. (2018) Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., and Tafjord, O. 질문을 풀었다고 생각해? try arc, ai2 reasoning challenge. _ arXiv preprint arXiv:1803.05457_, 2018.
* Dagan 등(2010) Dagan, I., Dolan, B., Magnini, B., and Roth, D. Recognizing textual entailment: Rational, evaluation and approaches-erratum. _ Natural Language Engineering_, 16(1):105-105, 2010.
* Dao et al. (2022) Dao, T., Fu, D. Y., Ermon, S., Rudra, A., and Re, C. Flashattention: Fast and memory-efficient exact attention with io-awareness. 2022년, 신경 정보 처리 시스템의 발전에서.
* De Marneffe et al. (2019) De Marneffe, M. - C., Simons, M., and Tonhauser, J. The commitmentbank: Investigating projection in naturally occurring discourse. In _proceedings of Sinn und Bedeutung_, volume 23, pp. 107-124, 2019.
* Devlin et al. (2019) Devlin, J., Chang, M. -W., Lee, K., and Toutanova, K. 버트: 언어 이해를 위한 딥 양방향 트랜스포머의 사전 훈련. <Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)_, pp. 4171-4186, 2019).
* Dey et al.(2023) Dey, N., Gosal, G., Khachane, H., Marshall, W., Pathria, R., Tom, M., Hestness, J., et al. Cerebras-gpt: Open compute-optimal language models trained on the cerebral s wafer-scale cluster. _ arXiv preprint arXiv:2304.03208_, 2023.
* Dodge et al. (2021) Dodge, J., Sap, M., Marasovic, A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., and Gardner, M. 대형 웹텍스트 말뭉치 문서화: 크롤링된 거대한 말뭉치에 대한 사례 연구 In _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pp. 1286-1305, 2021.
* Eberhard 등(2023) Eberhard, D. M., Simons, G. F., and Fennig, C. D. _Ethnologue: Languages of the World_. SIL International, Dallas, TX, USA, 26판, 2023.
* Gao et al.(2020) Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., et al. The pile: An 800gb dataset of various text for language modeling _ arXiv preprint arXiv:2101.00027_, 2020.
* Gao 등 (2021) Gao, L., Tow, J., Biderman, S., Black, S., DiPofi, A., Foster, C., Golding, L., Hsu, J., McDonell, K., Muennighoff, N., Phang, J., Reynolds, L., Tang, E., Thite, A., Wang, B., Wang, K., and Zou, A. A framework for few-shot language model evaluation, September 2021. URL [https://doi.org/10.5281/zenodo.5371628](https://doi.org/10.5281/zenodo.5371628)
*Gebru et al. (2021) Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Iii, H. D., and Crawford, K. 데이터 세트에 대한 데이터 시트입니다. _ Communications of the ACM_, 64(12):86-92, 2021.
* Gokaslan et al. (2019) Gokaslan, A., Cohen, V., Pavlick, E., and Tellex, S. Open-webtext corpus. [http://Skylion007.github.io/OpenWebTextCorpus] (http://Skylion007.github.io/OpenWebTextCorpus), 2019.
* Gordon 등 (2012) Gordon, A., Kozareva, Z., and Roemmele, M. Semeval-2012 과제 7: 그럴듯한 대안의 선택: 상식적인 인과 추론의 평가. In
* _SEM 2012: The First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012)_, pp. 394-398, 2012.
* Grave et al.(2018) Grave, E., Bojanowski, P., Gupta, P., Joulin, A., and Mikolov, T. 157개 언어에 대한 단어 벡터를 학습합니다. LREC 2018(언어 자원 및 평가에 관한 제11차 국제 회의)_, 2018에서.
* Hanu & Unitary team (2020) Hanu, L. 그리고 유니터리 팀. 해독제 Github. [https://github.com/unitaryai/detoxify] (https://github.com/unitaryai/detoxify), 2020.
* Hernandez et al.(2018) Hernandez, D., Brown, T., Conerly, T., DasSarma, N., Drain, D., El-Showk, S., Elhage, N., Hatfield-Dodds, Z., Henighan, T., Hume, T., et al. Scaling laws and interpretability of learning from repeated data. _ arXiv preprint arXiv:2205.10487_, 2022.
* Hoffmann 등(2022) Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. _ arXiv preprint arXiv:2203.15556_, 2022.
* Holtzman et al. (2019) Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. 신경 텍스트 변성의 기이한 사례 2019년 _International Conference on Learning Representations_ 에서.
* Jaccard (1912) Jaccard, P. The distribution of the flora in the alpine zone.1. _New Phytologist_, 11:37-50, 1912.
* Jin et al. (2019) Jin, Q., Dhingra, B., Liu, Z., Cohen, W., and Lu, X. Pubmedqa: 생의학 연구 질의 응답을 위한 데이터 세트. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_, pp. 2567-2577, 2019.
* Joulin et al. (2016) Joulin, A., Grave, E., Bojanowski, P., Douze, M., Jegou, H., and Mikolov, T. 신속한 문자 zip: 텍스트 분류 모델을 압축합니다. _ arXiv preprint arXiv:1612.03651_, 2016.
* Kaplan 등(2020) Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D. Scaling laws for neural language models. _ arXiv preprint arXiv:2001.08361_, 2020.
* Kreutzer et al.(2022) Kreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., Tapo, A. A., Subramani, N., Sokolov, A., Sikasote, C., et al. Quality at a glance: An audit of web-crawled multilingual datasets. _ 계산 언어학 협회의 트랜잭션_, 10:50-72, 2022.
* Laurencon et al.(2022) Laurencon, H., Saulnier, L., Wang, T., Akiki, C., del Moral, A. V., Le Scao, T., Von Werra, L., Mou, C., Ponferrada, E. G., Nguyen, H., et al. The bigscience root corpus: A 1.6 tb composite multilingual dataset. 뉴럴 정보 처리 시스템 데이터 세트 및 벤치마크 트랙에 관한 36차 회의에서 2022년.
* Lee et al. (2022) Lee, K., Ippolito, D., Nystrom, A., Zhang, C., Eck, D., Callison-Burch, C., and Carlini, N. 훈련 데이터를 복제하면 언어 모델이 더 좋아집니다. "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_", pp. 8424-8445, 2022.
* Liu et al.(2021) Liu, J., Cui, L., Liu, H., Huang, D., Wang, Y., and Zhang, Y. Logiqa: 논리적 추론으로 기계 읽기 이해를 위한 챌린지 데이터 세트입니다. In _Proceedings of the 20-9th International Conference on International Joint Conferences on Artificial Intelligence_, pp. 3622-3628, 2021.
* Liu et al. (2019) Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V. 로베르타: 강력하게 최적화된 버트 사전 훈련 접근법입니다. _ arXiv preprint arXiv:1907.11692_, 2019.
* Lopukhin (2019) Lopukhin, K. 상업 서비스 및 오픈 소스 라이브러리의 문서 본문 추출 품질 평가 [https://github.com/scrapinghub/article-extraction-benchmark] (https://github.com/scrapinghub/article-extraction-benchmark), 2019.
* Manber & Myers (1993) Manber, U. 및 Myers, G. 접미사 배열: 온라인 문자열 검색을 위한 새 메서드입니다. _ Journal on Computing_, 22(5):935-948, 1993.
* Mihaylov et al. (2018) Mihaylov, T., Clark, P., Khot, T., and Sabharwal, A. Can a suit of armor conduct electricity? 오픈 북 질문 응답을 위한 새 데이터 세트 In _Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing_, pp. 2381-2391, 2018.
* Mitchell et al. (2019) Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I. D., and Gebru, T. 모델 보고용 모델 카드입니다. <Proceedings of the conference on fairness, responsibility, and transparency_>에서, pp. 220-229, 2019.
* Nie et al.(2019) Nie, Y., Williams, A., Dinan, E., Bansal, M., Weston, J., and Kiela, D. Adversarial nli: A new benchmark for natural language understanding _ arXiv preprint arXiv:1910.14599_, 2019.
* 16, Mannheim, 2019. Leibniz-Institut fur Deutsche Sprache. doi: 10.14618/ids-pub-9021. URL [http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215](http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215).
* Paperno et al. (2016) Paperno, D., Kruszewski, G., Lazaridou, A., Pham, N. -Q., Bernardi, R., Pezzelle, S., Baroni, M., Boleda, G., and Fernandez, R. 람바다 데이터 세트: 광범위한 담화 컨텍스트를 요구하는 단어 예측. <Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp.1525-1534, 2016).
* Pomikalek (2011) Pomikalek, J. Justext. 2011년
* Press 등(2021) Press, O., Smith, N., and Lewis, M. 열차 짧음, 테스트 길음: 선형 편향을 사용한 주의는 입력 길이 외삽을 가능하게 합니다. 2021년 _International Conference on Learning Representations_ 에서.

Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et al. Improving language understanding by generative pre-training. 2018년.
* Radford et al.(2019) Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al. 언어 모델은 비감독 멀티태스크 학습자이다. 2019년.
* Rae et al.(2019) Rae, J. W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F., Aslanides, J., Henderson, S., Ring, R., 영, S., 러더포드, E., Hennigan, T., Wu, A., Elsen, E., Dathathri, S., Wang, S., Uesato, J., S., Sutherland, E., Simonyan, K., Paganini, M., Sifre, L., C. K., M. M., M. 2021. doi: 10.48550/ARXIV.2112.11446. URL [https://arxiv.org/abs/2112.11446](https://arxiv.org/abs/2112.11446)
* Raffel et al.(2020) Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring the limit of transfer learning with a unified text-to-text transformer _ Journal of Machine Learning Research_, 21(140):1-67, 2020. URL [http://jmlr.org/papers/v21/20-074.html](http://jmlr.org/papers/v21/20-074.html)
* Sakaguchi et al. (2021) Sakaguchi, K., Bras, R. L., Bhagavatula, C., and Choi, Y. 위노그란데: 규모의 적대적인 위노그라드 스키마 도전입니다. _ Communications of the ACM_, 64(9):99-106, 2021.
* Scao 등(2022a) Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilic, S., Hesslow, D., Castagne, R., Luccioni, A. S., Yvon, F., Galle, M., et al. Bloom: A 176b-parameter open-access multilingual language model. _ arXiv preprint arXiv:2211.05100_, 2022a.
* Scao 등(2022b) Scao, T. L., Wang, T., Hesslow, D., Saulnier, L., Bekman, S., Bari, M. S., Bideman, S., Elsahar, H., Muennighoff, N., Phang, J., et al. 100만 gpu 시간을 갖는 경우 어떤 언어 모델을 훈련시킬 것인가? _ arXiv preprint arXiv:2210.15424_, 2022b.
* Sevilla et al. (2022) Sevilla, J., Heim, L., Ho, A., Besiroglu, T., Hobbhahn, M., and Villalobos, P. Compute trends across three eras of machine learning. _ arXiv preprint arXiv:2202.05924_, 2022.
* 사이트 (2013) 사이트, D. 컴팩트 언어 디텍터 2. _https://github. com/CLD2Owners/cld2에서 사용할 수 있는 소프트웨어 (2015년 8월에 마지막으로 업데이트 됨)_, 2013.
* Tay 등(2021) Tay, Y., Dehghani, M., Rao, J., Fedus, W., Abnar, S., Chung, H. W., Narang, S., Yogatama, D., Vaswani, A., and Metzler, D. Scale efficiently: Insights from pretraining and finetuning transformers. 2021년 _International Conference on Learning Representations_ 에서.
* Thoppilan et al.(2022) Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T., Jin, A., Bos, T., Baker, L., Du, Y., et al. Lamda: Language models for dialog applications. _ arXiv preprint arXiv:2201.08239_, 2022.
* Touvron et al. (2023) Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M. - A., Lacroix, T., Roziere, B., Goyal, N., Hambro, E., Azhar, F., et al. Llama: Open and efficient foundation language models. _ arXiv preprint arXiv:2302.13971_, 2023.
* Trinh and Le (2018) Trinh, T. H. and Le, Q. V. A simple method for 상식 추론_ arXiv preprint arXiv:1806.02847_, 2018.
* Vilares & Gomez-Rodriguez (2019) Vilares, D. and Gomez-Rodriguez, C. Head-qa: A healthcare dataset for complex reasoning. <Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics>, pp. 960-966, 2019.
* Villalobos et al. (2022) Villalobos, P., Sevilla, J., Heim, L., Besiroglu, T., Hobbhahn, M., and Ho, A. We will run of data? 기계 학습에서 데이터 세트의 크기 조정 한계에 대한 분석 _ arXiv preprint arXiv:2211.04325_, 2022.
* Wang & Komatsuzaki (2021) Wang, B. and Komatsuzaki, A. GPT-J-6B: A 60억 파라미터 자기회귀 언어 모델. [https://github.com/kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax), 2021년 5월.
* Wang et al. (2022) Wang, T., Roberts, A., Hesslow, D., Scao, T. L., Chung, H. W., Beltagy, I., Launay, J., and Raffel, C. 어떤 언어 모델 아키텍처 및 프리트레이닝 대물렌즈가 제로-샷 일반화를 위해 가장 잘 작동하나? 2022년 국제 기계 학습 회의에서.
* Wei et al.(2022) Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. Emergent abilities of large language models. _ Transactions on Machine Learning Research_, 2022.
* Welbl et al. (2017) Welbl, J., Liu, N. F., and Gardner, M. 선다형 과학 문제를 크라우드소싱합니다. <Proceedings of the 3rd Workshop on Noisy User-generated Text>, pp. 94-106, 2017.

* Welbl et al.(2021) Welbl, J., Glaese, A., Uesato, J., Dathathri, S., Mellor, J., Hendricks, L. A., Anderson, K., Kohli, P., Coppin, B., and Huang, P.-S. 언어 모델 해독에 대한 도전 In _Findings of the Association for Computational Linguistics: EMNLP 2021_, pp. 2447-2469, 2021.
* Wenzek et al.(2020) Wenzek, G., Lachaux, M. - A., Conneau, A., Chaudhary, V., Guzman, F., Joulin, A., and Grave, E. Ccnet: Extracting high quality monolingual datasets from web crawl data. In _Proceedings of the 12th Language Resources and Evaluation Conference_, pp. 4003-4012, 2020.
* Xue et al.(2021) Xue, L., Constant, N., Roberts, A., Kale, M., Al-Rfou, R., Siddhant, A., Barua, A., and Raffel, C. mt5: Amassively multilingual pre-trained text-to-text transformer. [Proceedings of the 2021 Conference of the North American Chapter of the Computational Linguistics: Human Language Technologies_, pp. 483-498, 2021]에서.
* Yang et al.(2021) Yang, G., Hu, E., Babuschkin, I., Sidor, S., Liu, X., Farhi, D., Ryder, N., Pachocki, J., Chen, W., and Gao, J. Tuning large neural networks via zero-shot hyperparameter transfer _ Advances in Neural Information Processing Systems_, 34:17084-17097, 2021.
* Zellers et al.(2019) Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi, Y. 헬라스와그: 기계가 정말로 당신의 문장을 끝낼 수 있을까요? <Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics>, pp. 4791-4800, 2019.
* Zeng et al.(2021) Zeng, W., Ren, X., Su, T., Wang, H., Liao, Y., Wang, Z., Jiang, X., Yang, Z., Wang, K., Zhang, X., et al. Pangualpha: Large-scale autoregressive pretrained chinese language models with auto-parallel computation _ arXiv preprint arXiv:2104.12369_, 2021.
* Zhang et al.(2018) Zhang, S., Liu, X., Liu, J., Gao, J., Duh, K., and Van Durme, B. Record: Bridging the gap between human and machine commonsense reading comprehension. _ arXiv preprint arXiv:1810.12885_, 2018.
* Zhang et al.(2022) Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., Dewan, C., Diab, M., Li, X., Lin, X. V., et al. Opt: Open pre-trained transformer language models. _ arXiv preprint arXiv:2205.01068_, 2022.
* Zhu et al. (2015) Zhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., and Fidler, S. 책과 영화의 정렬: 영화를 보고 책을 읽음으로써 이야기와 같은 시각적 설명을 향해. In _Proceedings of the IEEE international conference on computer vision_, pp. 19-27, 2015.

## 부록 A RefinedWeb Datasheet

**Falcon LLM에 대한 RefinedWeb 데이터 세트**

**데이터 세트에 오류, 노이즈 소스 또는 중복이 있습니까?* *

자연어로 적합하지 않은 콘텐츠를 필터링하고 문서를 중복 제거하려는 최선의 노력에도 불구하고 파이프라인은 오류 또는 중복으로 간주될 수 있는 문서를 통과할 수 있다.

**데이터 세트는 자체 포함됩니까, 아니면 외부 리소스에 연결 하거나 그렇지 않으면 의존 하나요?* *

데이터 세트의 기본 버전은 자체 포함되지만 멀티모달 버전은 이미지에 대한 링크와 인터레이싱됩니다. 이 버전은 데이터 세트의 일부로 배포되지 않으며 외부 소스를 구성합니다.

**데이터 세트에는 기밀로 간주될 수 있는 데이터가 포함되어 있습니까?* *

**데이터 세트에는 직접 볼 경우 모욕적이거나 모욕적이거나 위협적이거나 그렇지 않으면 불안감을 유발할 수 있는 데이터가 포함되어 있습니까?* *

**Collection**

**각 인스턴스와 연결된 데이터는 어떻게 획득되었습니까?**

워시오와 함께 다운로드했습니다 커먼크롤 재단의 WET 파일입니다

**데이터를 수집하는 데 사용된 메커니즘 또는 절차는 무엇입니까?* *

데이터 수집 방법에 대한 자세한 내용은 CommonCrawl 웹 사이트(commoncrawl.org)를 참조하십시오.

**데이터 집합이 더 큰 집합의 샘플인 경우 샘플링 전략은 무엇이었습니까?**

**데이터 수집 프로세스에 누가 참여했으며 어떻게 보상받았습니까?**

**수집한 데이터가 몇 시간 동안이었습니까?**

우리는 2008년부터 2023년 1월/2월까지 모든 커먼크롤 덤프를 사용한다.

**윤리 검토 프로세스가 수행되었습니까?**

**Preprocessing**

**데이터의 전처리/청소/라벨링이 수행되었습니까?**

예, 데이터의 광범위한 전처리 및 청소를 적용했습니다. 먼저 블록리스트와 스코어 시스템(부록 G.1)을 사용하여 성인 콘텐츠를 제거하기 위해 URL을 필터링한 후 trafilatura(Barbaresi, 2021)를 사용하여 페이지로부터 콘텐츠를 추출하고, CCNet(Wenzek et al., 2020)의 fastText 분류기로 언어 식별을 수행한다. 이 첫 번째 전처리 단계 후, MassiveWeb(Rae et al., 2021)의 휴리스틱과 자체 라인별 수정(부록 G.2)을 사용하여 데이터를 필터링한다. 마지막으로, Lee et al.(2022)의 각 단계 도면을 사용하여 덤프에서 재방문된 URL(섹션 3.3)을 제거하고 퍼지 및 정확한 부분 문자열 중복 제거를 수행하는 광범위한 중복 제거를 실행한다. 자세한 내용은 섹션 3을 참조하고 개요는 표 2를 참조하십시오.

**전처리된/청소된/라벨이 지정된 데이터 외에 "원시" 데이터가 저장되었습니까?**

개발하는 동안 조사와 삭제를 위해 파이프라인에서 중간 출력을 저장했으며 중간 출력은 RefinedWeb의 약 5%에 대해 존재한다. 스토리지 및 리소스 제약으로 인해 데이터 세트의 최종 생산 버전에 대한 중간 출력을 보관하지 않았습니다.

**데이터를 전처리/청소/표지하는 데 사용된 소프트웨어를 사용할 수 있습니까?* *

**Uses**

**데이터 집합이 이미 작업에 사용 되었습니까?* *

예, 이 데이터는 과학 실험(예: 이 논문) 및 생산 사용을 위한 대규모 언어 모델을 개발하는 데 사용되었습니다.

**데이터 세트를 사용하는 문서 또는 시스템에 링크하는 리포지토리가 있습니까?* *

\begin{table}
\begin{tabular}{p{113.8pt}|p{113.8pt}} \hline \hline
**Is there a repository that links to any or all papers or systems that use the dataset?** & No. \\ \hline
**What (other) tasks could the dataset be used for?** & RefinedWeb was built as a large-scale corpora representative of the web, and as such may see many downstream uses which are difficult to predict. \\ \hline
**Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses?** & For the public extract of RefinedWeb, we chose to only draw from the English version of the dataset, preventing multilingual applications. \\ \hline
**Are there tasks for which the dataset should not be used?** & Any tasks which may considered irresponsible or harmful. \\ \hline
**Distribution** \\ \hline
**Will the dataset be distributed to third parties outside of the entity on behalf of which the dataset was created?** & Yes, we make a 600GT extract publicly available for NLP practitioners. We currently don’t plan to share the full version of the dataset. \\ \hline
**How will the dataset will be distributed?** & The dataset will be made available through the HuggingFace Hub. \\ \hline
**When will the dataset be distributed?** & The dataset is available immediately. \\ \hline
**Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)?** & The public extract is made available under an ODC-By 1.0 license; users should also abide to the CommonCrawl ToU: [https://commoncrawl.org/terms-of-use/](https://commoncrawl.org/terms-of-use/). \\ \hline
**Have any third parties imposed IP-based or other restrictions on the data associated with the instances?** & Not to our knowledge. \\ \hline
**Do any export controls or other regulatory restrictions apply to the dataset or to individual instances?** & Not to our knowledge. \\ \hline \hline \end{tabular}
\end{table}
표 6: Gebru 등이 소개한 프레임워크(2021)에 따라 **Datasheet for RefinedWeb** 입니다.

[MISSING_PAGE_EMPTY:18]

## Appendix C Dataset 분석

웹 코퍼스의 대규모적이고 다양한 특성으로 인해 전체적으로 문서화 및 분석이 어려우며, 그림 5(a)의 문서 길이와 그림 5(b)의 최상위 도메인 이름에 초점을 맞춘 섹션의 몇 가지 주요 메트릭을 제공한다. 우리는 또한 그림 4에 제시된 독성 함량의 분포 분석을 참조한다.

## 부록 D 다국어 정제 웹

다국어 데이터.언어 식별 필터를 사용하여 처리된 CommonCrawl 데이터를 176개의 언어로 분류한다. 그림 6은 내림차순으로 상대적 기여도를 기준으로 _영어 제외_ 데이터에 존재하는 상위 20개 언어를 보여준다. 가공된 CommonCrawl 자료에서 전체 문서의 58.20%가 영어로 확인되었다. 우리는 CommonCrawl의 언어 분포가 언어 화자의 전 세계 분포와 부분적으로만 일치한다는 것을 발견한다(Eberhard et al., 2023): 러시아어는 과대 대표되고(CC에서는 2위이지만 전 세계 8위), 중국어는 과소 대표되고(CC에서는 6~7위이지만 전 세계 2위), 힌디어는 3번째로 많이 사용되었음에도 불구하고 상위 20위 안에 나타나지 않는다.

다국어 데이터 처리 MDR 파이프라인은 모든 언어를 처리하는데 사용될 수 있다: 텍스트 추출과 같은 특징은 언어-불가지론적인 반면, 라인-와이즈 보정과 같은 특정 필터는 일반적으로 각각의 개별 언어에 대해 튜닝될 필요가 있다. 또한 개별 언어에 대한 중복 제거 매개 변수를 조정하는 것이 유용하다는 것을 발견했습니다.

그림 5: **문서 길이(왼쪽) 및 상단 도메인(오른쪽)에서 RefinedWeb의 구성** (a) OSCAR 데이터 세트와 RW-Raw가 유사한 문서 길이 분포를 갖는 것을 찾습니다. 필터링 후 대부분의 짧은 문서는 RW-Filtered에서 폐기됩니다. 중복제거가 기간을 제거함에 따라 더 짧은 문서를 RefinedWeb에 다시 도입합니다. C4와 RefinedWeb의 구성은 RefinedWeb에 대한 짧은 문서의 더 긴 꼬리와 함께 비교적 유사하다는 점에 주목한다. 마지막으로, The File은 긴(책 등) 문서와 짧은 문서의 긴 꼬리를 가진 독특한 화장을 보여줍니다. (b) RefinedWeb의 상위 도메인은 인기 있는 콘텐츠 플랫폼(Blogspot, WordPress, Tumblr 등), 뉴스 웹사이트(CNN, New York Times 등)에 걸쳐 있으며, BioMed Central 또는 Springer와 같은 기술 콘텐츠도 포함한다.

그림 6: **문서 수와 디스크 크기에 따라 처리된 CommonCrawl에서 상위 20개 언어(영어를 제외)**입니다.

## 부록 E 추가 결과

이 섹션에서는 매크로데이터 정제 파이프라인을 개발하는 동안 얻은 추가 결과를 제시한다. 부록 E.1 및 부록 E.3의 경우 데이터 세트의 이전 개발 버전을 사용하여 얻었으므로 결과가 본문과 직접 비교할 수 없다. 부록 E.2의 경우, 이는 Falcon-RW 모델을 기반으로 한다.

### 중복 제거 접근법에 대한 소규모 제거

우리는 표 8에 결과를 제시하는데, 설정은 30GT에 대한 1B 모델을 훈련하는 초기 제거와 유사하다. 우리는 그것을 관찰합니다

* 정확한 중복 제거의 제로 샷 성능과 일치하지 않기 때문에 **MinHash만으로는 충분하지 않습니다* *. 반대로, 이를 정확한 중복 제거와 결합한다고 해서 성능이 더 향상되지는 않는다.
* **스패닝 된 중복을 마스킹 하면 성능이 저하 됩니다* * 다른 접근 방식을 체계적으로 성능 저하 합니다. 드롭핑과 컷팅 스팬은 유사하게 수행되지만, 문서를 드롭하는 것이 컷팅보다 약간 더 우수할 수 있습니다.

마지막으로, 스케일링이 더 쉽기 때문에 정확한 중복제거 전에 MinHash를 적용하기로 결정했다: 대략적인 중복제거는 가지치기 단계로 작용하여 중복제거를 더 확장할 수 있다. 마지막으로, 우리는 경간을 줄이는 일반적인 옵션을 선택하는데, 이는 하락으로 인해 5조 토큰 수집 능력이 손상될 훨씬 더 엄격한 거부율이 발생했기 때문이다.

### 언어 모델링 평가

우리의 집합체와 함께 위키텍스트에 대한 당혹감도 평가했다(표 9). 우리는 RefinedWeb에서 훈련된 모델이 The Pile에서 훈련된 모델에 가까운 성능을 달성한다는 것을 발견했다. 중요한 것은 RefinedWeb에는 위키피디아의 콘텐츠가 포함되어 있지 않다는 것입니다. - URL 수준에서 명시적으로 필터링됩니다. 우리는 RW 모델이 위키텍스트의 특징(예: 기사 레이아웃 등)에 익숙하지 않을 수 있기 때문에 이것이 복잡성의 대부분의 차이를 설명한다고 믿는다.

\begin{table}
\begin{tabular}{c c c c} \hline \hline
**Minhash** & **Exact substring** & pile-bpb \(\downarrow\) & agg-dev-1 \(\uparrow\) \\ \hline \multicolumn{3}{c}{RefinedWeb-Filtered} & 1.11 & 43.51 \\ \hline  & Mask & 1.08 & 45.84 \\ ✓ & Mask & 1.07 & 46.28 \\ ✓ & & 1.07 & 46.57 \\ ✓ & Cut & **1.05** & 47.11 \\  & Cut & 1.06 & 47.24 \\ ✓ & Drop partial & **1.05** & 47.25 \\  & Drop any & 1.07 & 47.77 \\ ✓ & Drop any & 1.07 & 47.86 \\  & Drop partial & 1.06 & **47.97** \\ \hline  & Pile & 0.88 & 43.70 \\ \hline \hline \end{tabular}
\end{table}
표 8: **MinHash만으로는 정확한 부분 문자열 중복 제거의 성능을 일치시키기에 충분하지 않으며, 이 둘을 결합해도 성능이 크게 향상되지 않습니다. 정확한 부분 문자열 접근법 중 중복된 스팬을 마스킹하면 성능이 저하되지만 다른 모든 방법은 유사한 성능을 보입니다. ✓ 민해시 + 정확한 부분 문자열 절단은 최종 중복 제거 설정에 해당합니다. 더 파일(파일-bpb, 더 낮음)의 바이트당 비트 복잡성, LAMBADA, PIQA 및 HellaSwag(agg-dev)에 대해 집계된 제로 샷 성능. 가장 좋은 결과는 굵은 글씨로, 가장 좋은 결과는 밑줄의 민해시를 사용하여 agg-dev-1을 증가시켜 테이블을 정렬합니다.* *

\begin{table}
\begin{tabular}{l c c c} \hline \hline
**모델 크기** & **1B** & & **7B** \\
**Dataset** & The Pile & RW & RW \\ \hline wiki-bpb \(\downarrow\) & 0.64 & 0.66 & 0.60 \\ \hline \hline \end{tabular}
\end{table}
표 9: **RefinedWeb에서 훈련된 모델은 위키피디아에서 콘텐츠를 보지 못했음에도 불구하고 위키텍스트의 파일에서 훈련된 모델에 가까운 성능을 달성합니다. 위키텍스트의 바이트당 비트 복잡도(wiki-bpb, 더 낮으면 더 좋습니다.)**

### 중복 제거가 여러 epoch에 도움이 되나요?

이 작업에서 우리는 사전 훈련 데이터를 확장하기 위해 실무자들이 두 가지 선택을 했다고 설명했다: (1) 우리가 추구하기로 선택한 방법인 데이터 수집을 개선하고, (2) 동일한 데이터의 여러 시대에 모델을 훈련시킨다. 더 큰 모델이 부작용 없이 여러 시기를 지속할 수 있는 능력의 현재 불확실성으로 인해(Hernandez et al., 2022), 우리는 (1)에 초점을 맞췄다. (2)에 관한 상당히 합리적인 질문은 중복 제거가 상황을 개선할 수 있는지 여부와 중복 제거된 데이터가 모델 품질을 손상시키지 않으면서 더 많은 시기를 유지할 수 있는지 여부이다.

우리는 RW 및 RW 필터링의 30GT에서 1B 매개변수 모델을 훈련한다. 우리는 사전 훈련 토큰의 수를 고정시키지만 1, 5, 25, 100 에포크로 훈련한다. 이것은 확정적인 결과를 얻기 위해 개선되어야 하는 소규모의 제한된 설정이다. 그림 7(a)의 단일 에폭과 그림 7(b)의 RW와 RW-F 사이의 간격에 비해 성능 저하를 표시한다. 우리는 RefinedWeb이 RefinedWeb 필터링보다 절대적 열화가 덜 중요하다는 것을 발견했으며, 또한 epoch의 수가 증가함에 따라 격차가 확대된다. 그러나 작업 전반에 걸쳐 상당한 변동성을 관찰합니다.

## 최신 상태의 F 태스크, 모델 및 데이터 세트 추가

### Task aggregates

모델을 평가하기 위해 다양한 작업 집합에 대한 평균 제로 샷 성능 집합은 표 3에 요약되어 있다.

* small: small-scale ablation studies, taskswith non-zero performance for 1B parameters models trained on 30GT;
* 코어: 광범위한 모델과의 비교, 특히 (Dey 등, 2023)에서 보고된 작업에 기초함;
* main: tasks available in the GPT-3 and PaLM papers (Brown et al., 2020; Chowdhery et al., 2022);
* ext: BigScience Architecture and Scaling Group의 작업에서 사용 가능한 작업(Scao et al., 2022).

최첨단 모델의 모델과 비교할 때 표 10에 자세히 설명된 몇 가지 다른 논문의 결과를 제공한다.

### Models

표 11에 제시된 다양한 선별된 코퍼라에 대해 훈련된 10개의 시리즈에 걸쳐 거의 50개의 모델과 비교한다.

Cerebras-GPT는 \(\mu\)-parametrization을 갖는다. Cerebras-GPT 시리즈(Dey et al., 2023)는 또한 \(\mu\)-parametrization의 권고에 따라 2.7B 파라미터까지 더 작은 시리즈로 제공된다(Yang et al., 2021). 이 더 작은 시리즈의 성능이 주요 시리즈 모델에 가깝다는 것을 발견했고(그림 8 참조), 우리가 비교하는 것과 유사한 계산 규모의 모델이 포함되지 않았기 때문에 주요 그림에 보고하지 않기로 결정했다.

그림 7: **중복 제거는 여러 에포크로 인해 발생하는 성능 저하를 줄일 수 있습니다.* * 그러나 실험은 소규모(30GT에서 훈련된 1B 모델)에서만 수행되었으며 작업 전반에 걸쳐 결과의 변동성이 높습니다. agg-dev-2 집합체(HellaSwag, PIQA, ARC, BoolQ, COPA, MRPC, SciQ)에서 제로샷 성능을 측정하였다. 작업별 결과에 대한 개별 곡선과 투명하게 집계된 모든 작업에 대한 1-\(\sigma\) 표준 편차.

피티아 및 중복 제거.피티아 시리즈 모델은 두 가지 맛으로 제공됩니다. 하나는 더 파일의 바닐라 버전에서 훈련되고 다른 하나는 민해시와 중복 제거된 버전에서 훈련됩니다. 이 두 가지 맛 사이의 성능은 최소한으로 다른 것으로 나타났다(Biderman 등, 2023). 그림 9에서 중복 제거된 버전이 집계 아래 중복되지 않은 버전보다 약간 앞설 수 있음을 발견했다. 이러한 개선의 더 높은 목적은 표 5의 우리의 발견과 대체로 일치하지만, 그럼에도 불구하고 우리의 발견과 그들의 발견에는 차이가 남아 있다. 우리는 몇 가지 가능한 가설을 상정한다:

* **큐레이팅된 데이터와 웹 데이터의 차이점** 웹 데이터가 중복에 더 민감할 수 있습니다. 예를 들어, 웹 데이터에서 가장 일반적인 복제물(예: 스팸)은 큐레이트된 데이터에서 가장 일반적인 복제물보다 더 해로울 수 있다. 이것은 우리가 이 작업에서 연구하지 않은 중복제거에 대한 질적 구성요소를 시사한다.
* **중복 제거 파이프라인의 차이점** Biderman 등(2023)은 Lee 등(2022)의 MinHash 설정을 사용하므로 대부분 우리와 동일합니다. 그러나 우리는 또한 정확한 중복 제거를 적용합니다: 그들의 중복 제거는 크기가 30% 감소하지만, 우리의 중복 제거는 더 공격적이어서 크기가 45% 감소합니다. 이것은 표 5의 결과가 그림 9의 결과보다 중복 제거에서 더 강한 이득을 보이는 이유를 설명할 수 있다.
* **사전 훈련의 차이점** 마지막으로 Biderman 등(2023)이 중복 제거 된 데이터에서 부분 추가 에포크를 수행 하 여 300GT에 도달 하는 반면 항상 단일 에포크를 수행 합니다. 그들의 설정은 데이터 제약 시나리오에 해당하며, 이는 그들이 연구하는 선별된 데이터에 대해 더 현실적이며, 우리에게 웹 데이터는 풍부하기 때문에 중복 제거는 우리가 사용할 수 있는 데이터 세트의 크기를 결코 진정으로 제한하지 않는다.

### Datasets

우리는 표 12의 표 1에서 확장하여 리터러티에 걸쳐 사용되는 필터링 및 중복 제거 전략에 대한 세부 정보를 제공한다.

\begin{table}
\begin{tabular}{c c c c} \hline \hline
**Models** & **Aggregates reported** & **Source of results** & **EAI eval harness?** \\ \hline Ours & main, core, ext & This paper & ✓ \\ BS-A\&S\({}^{*}\) & main, core & Scao et al. (2022b) & ✓ \\ GPT-Neo\({}^{*}\) & main, core & Scao et al. (2022b) & ✓ \\ PaLM\({}^{\dagger}\) & main & Chowdhery et al. (2022) & \\ GPT-3 API\({}^{*}\) & main, core & Scao et al. (2022b) & ✓ \\ GPT-3\({}^{\dagger}\) & main & Brown et al. (2020) & \\ Aleph Alpha\({}^{*}\) & core & Aleph Alpha (2023) & ✓ \\ Cerebras-GPT\({}^{*}\) & core & Dey et al. (2023) & ✓ \\ FairSeq\({}^{*}\) & core & Black et al. (2022) & ✓ \\ Pythia(-Dedup)\({}^{*}\) & core & Dey et al. (2023) & ✓ \\ OPT\({}^{*}\) & core & Dey et al. (2023) & ✓ \\ GPT-J\({}^{*}\) & core & Black et al. (2022) & ✓ \\ GPT-NeoX 20B\({}^{*}\) & core & Black et al. (2022) & ✓ \\ \hline \hline \end{tabular}
\end{table}
표 10: **우리는 다양한 문헌의 평가 결과를 원본으로 하여 작업 범위를 극대화합니다. 대부분의 결과는 EAI 평가 Harness(Gao et al., 2021)에서 나왔지만 PaLM 및 GPT-3의 결과는 각각의 논문에서 출처한다. 그림 1에서 GPT-3 논문의 결과는 여전히 EAI 평가 하니스가 있는 API를 통해 얻은 결과보다 앞서 있습니다.**그림 8: \(\mu\)**-parametrization(양 등, 2021)은 Cerebras-GPT 시리즈(Dey 등, 2023)에서 성능을 약간 향상시킵니다.* * 핵심 집합에 대한 제로샷 성능, \(\mu\)-param이 있거나 없는 Cerebras-GPT 간의 간격입니다. 작업별 결과에 대한 개별 곡선과 투명하게 집계된 모든 작업에 대한 1-\(\sigma\) 표준 편차.

그림 9: **핵심 집합에서 중복 제거는 피티아 제품군에 약간의 개선을 가져옵니다(Biderman 등, 2023).** 핵심 집합에서 제로샷 성능, 중복 제거와 바닐라 파일에서 훈련된 피티아 간의 간격입니다. 작업별 결과에 대한 개별 곡선과 투명하게 집계된 모든 작업에 대한 1-\(\sigma\) 표준 편차.

\begin{table}
\begin{tabular}{l c c c c c c c c} \hline \hline
**Series** & GPT-3 (paper)\({}^{\ddagger}\) & GPT-3 (API)\({}^{*}\) & BigScience\({}^{*}\) & PaLM\({}^{\dagger}\) & & Ours \\ \hline
**모델** & XL & XXL & babbage & curie & BS-A\&S & PaLM-8B & Ours (파일) & Falcon-RW \\
**데이터 세트** & GPT-3 & GPT-3 & GPT-3 & GPT-3 & Pile & PaLM & Pile & RW & RW \\
**Params.** & 1.3B & 6.7B & 1.3B & 6.7B & 1.3B & 8.6B & 1.3B & 1.3B & 7.5B \\
**퍼트레이닝** & 300GT & 300GT & 300GT & 300GT & 300GT & 300GT & 300GT & 780GT & 350GT & 350GT & 350GT \\
**PF-days** & 27 & 140 & 27 & 140 & 27 & 466 & 32 & 32 & 182 \\
**Citation** & & Brown et al. (2020) & & Scao et al. (2022) & Chowdhery et al. (2022) & & This paper & \\ \hline \hline \multicolumn{10}{c}{**Series**} & \multicolumn{4}{c}{ElteurAI\({}^{*}\)} & \multicolumn{4}{c}{Pythia\({}^{*}\)} \\ \hline
**Model** & GPT-Noc & GPT-J & GPT-Noc20B & Pythia(-Dedup) \\
**Dataset** & Pile & Pile & Pile & Pile (dedeb) \\
**Params.** & 1.3B & 6.7B & 20B & 700-12B & \\
**프리트레이닝** & 380GT & 402GT & 472GT & 300GT & 300GT \\
**PF-days** & 34 & 187 & 656 & 1.5 - 250 \\
**Citation** & Black et al. (2021) & Wang \& Komatsuzaki (2021) & Black et al. (2022) & Biderman et al. (2023) \\ \hline \hline \multicolumn{10}{c}{**Series**} & \multicolumn{4}{c}{Alpha\({}^{*}\)} & \multicolumn{4}{c}{Cerebras-GPT\({}^{*}\)} & \multicolumn{4}{c}{OPT\({}^{*}\)} & FairSeq\({}^{*}\) \\ \hline
**모델** & 발광 & 대뇌-GPT & OPT & FairSeq \\
**Dataset** & _undisclosed_ & Pile & Pile (subset) + curated & curated \\
**Params.** & 13B & 111M-13B & 125M-175B & 1.3 - 13B \\
**프리트레이닝** & 400GT & 2 - 257GT & 300GT & 300GT \\
**PF-days** & 361 & 0.02 - 232 & 3 - 3646 & 27 - 271 \\
**Citation** & Aleph Alpha (2023) & Dey et al. (2023) & Zhang et al. (2022) & Artetxe et al. (2021) \\ \hline \hline \end{tabular}
\end{table}
표 11: **RefinedWeb(Falcon-RW) 및 최신 모델의 기타 모델에서 훈련된 전체 모델**. 파일에서 훈련된 모델 전반에 걸쳐 피티아 모델은 회전식 임베딩과 함께 플래시 어텐션을 사용하며, 특히 모델에 병렬 주의 및 피드포워드 사용을 예외로 한다. 훈련 예산 \(C\) \(C=6ND\), 매개변수 수 \(N\), 사전 훈련 데이터 세트 크기 \(D\)를 사용하여 계산됩니다 (Kaplan 등, 2020).**

## Macrodata 정제 파이프라인의 부록 G 세부 정보

### URL filtering

섹션 3.1에서 논의한 바와 같이, 성인 문서의 필터링은 문서의 내용이 아닌 URL 자체만을 기반으로 한다. 이 디자인 선택은 (1) 문서 콘텐츠에 ML 기반 분류기를 사용할 때 소수자로부터 콘텐츠를 오버필터링하는 것을 방지하는 데 어려움이 있으며(Welbl 등, 2021), (2) 콘텐츠에 적용된 NSFW 단어 블록 리스트(예: C4에서 사용된 것)도 법적 및 의학적 콘텐츠의 오버필터링을 초래한다(Dodge 등, 2021).

우리의 URL 필터링은 성인 콘텐츠와 관련되거나, 사용자에게 유해할 수 있거나, 대부분 구조화되지 않은 텍스트/스팸(예를 들어, 파일 호스팅 웹사이트)을 포함할 가능성이 매우 높은 도메인을 찾는 것에 초점을 맞춘다. 먼저, 명시적으로 금지된 부록 G.1.1에 자세히 설명된 4.6M 도메인 목록을 집계한 다음, 큐레이팅한 단어 목록과 URL의 하위 단어를 일치시키는 것을 기반으로 간단한 URL 점수 시스템을 구축했다(부록 G.1.2 참조). 우리는 독성의 이상치로 ToxicBERT에 의해 표면화된 페이지와 수동 검사, 교차 참조 결과를 기반으로 이 단어 목록을 선별했다(Hanu and Unitary team, 2020).

#### g.1.1 URL Blocklist

목록의 원본.우리는 명시적으로 금지한 약 4.6M URL의 집계된 목록+를 사용합니다. 이 목록은 범주(예: 음란물, 도박)에서 깨졌습니다. 우리는 표 13에서 선택한 범주의 개요를 설명합니다. 이 목록은 정기적으로 업데이트되며 대학용 블록 목록으로 원래 의도된 용도를 사용합니다.

각주 †: [https://dsi.ut-capitole.fr/blacklists/](https://dsi.ut-capitole.fr/blacklists/)

큐레이션.목록이 많은 도메인을 부적절하게 차단했음을 알 수 있습니다. 이러한 도메인은 소수이지만(\(<\)100), 목록에 의해 필터링된 데이터의 상당 부분을 차지하며, 이는 수천 페이지의 콘텐츠를 포함하는 다소 많은 도메인이기 때문입니다. 이러한 허위 도메인을 식별하기 위해 832M 페이지의 하위 집합에 블록리스트를 적용하였으며, 6.04M(\(0.73\%\)) 페이지가 블록리스트와 일치하였고 URL 당 발생 횟수는 1~79k였다. 4k회 이상 일치하는 모든 URL을 수동으로 검사했으며 이는 데이터 세트의 상당한 부분을 나타낸다. 우리는 대중문화 뉴스 웹사이트나 블로그 플랫폼과 같은 많은 양성 도메인을 발견했는데, 이는 목록에서 제외되었다.

#### g.1.2 URL Scoring with Word-List

URL 점수를 매기기 위해 소프트, 하드, 엄격한 위반 단어 목록을 기반으로 세 가지 일치하는 패턴을 사용했다.

* **엄격한 하위 단어 일치**: [http://foobann.edsub-wo.rdbar.com/any/bar](http://foobann.edsub-wo.rdbar.com/any/bar), xvideos, groupsex와 같은 일치하는 단어;
* **하드 전체 단어 일치**: [http://www.foo.bannedword-bar.com](http://www.foo.bannedword-bar.com) 포르노, xxx, orgy와 같은 단어가 포함됨;
* **연어 일치**: [http://www.foo.soft1-bar-soft2.com](http://www.foo.soft1-bar-soft2.com) 및 성별, 웹캠, 에스코트와 같은 "더 부드러운" 단어가 있습니다.

각 목록은 서로 다른 수준의 심각도와 연관되어 있다: 가장 엄격한 것(엄격한 하위 단어 매칭)의 경우, 하위 문자열에서 금지된 단어와 일치하는 모든 URL을 금지한다(사기 웹 사이트가 성인 키워드를 분해하여 유사한 인식 체계를 탈출하려고 시도할 수 있기 때문에). 하드 전체 단어 매칭의 경우, 목록에서 전체 단어 매칭과 URL을 금지하고, 마지막으로 소프트 단어 매칭과 최소 2개의 매칭이 필요하다.

\begin{table}
\begin{tabular}{l l l} \hline \hline
**Category** & **Description** & **Number of links** \\ \hline adult & adult websites: from eroticism to hard pornography & 4516478 \\ phishing & phishing websites, malwares, etc. & 42445 \\ dating & dating websites & 3829 \\ gambling & online casino & 1365 \\ filehosting & websites hosting files, videos, pictures, music & 909 \\ ddos & websites related to ddos attacks & 421 \\ agressif & hate, racism, etc & 390 \\ chat & online chat websites & 244 \\ mixed adult & websites with some adult content & 153 \\ ariel & French regulated gambling websites & 69 \\ \hline \hline \end{tabular}
\end{table}
표 13: **성인이거나 악의적인 콘텐츠뿐만 아니라 스팸 또는 구조화되지 않은 텍스트를 포함할 가능성이 있는 범주를 선택합니다.* *ToxicBERT가 보고한 상위 히트에서 알 수 있는 데이터의 수동 검사를 기반으로 목록을 선별했습니다. 엄격한 하위 단어 매칭을 위해 성인 콘텐츠(예: 그룹섹스)와 명확하게 관련된 단어를 포함했다. 우리는 중립 단어(예: 매사추세츠)의 일부일 수 있는 부분적인 불분명한 일치(예: 엉덩이)를 피했다. 소프트 워드 리스트에는 문서를 스스로 폐기할 충분한 이유가 되지 않지만 리스트의 여러 단어가 일치할 때 의심스러운 단어를 포함시켰다. 이것은 의료 또는 법적 내용을 영향을 받지 않도록 하는 데 도움이 되었다(예를 들어, 고추의 단일 매치).

#### g.1.3 Excluded High Quality Sources

본 논문은 RefinedWeb의 연구에만 초점을 맞추고 있기 때문에 선별된 데이터의 일반적인 온라인 출처를 제외하기로 결정했다. 이것은 두 가지 목적을 제공한다: (1) RefinedWeb이 실제로 대부분 알려진 고품질 소스(예: 위키피디아는 C4의 상당 부분을 나타냄)로 만들어지지 않도록 함으로써 우리의 결과를 강화한다; (2) 향후 작업은 RefinedWeb에 포함된 경우 추가 중복 제거가 필요한 기존 큐레이트된 코포라와 RefinedWeb을 결합하는 데 관심이 있을 수 있다. 따라서, 우리는 RefinedWeb에서 The Pile(Gao et al., 2020)에서 사용되는 공통 소스를 제거한다. 차단한 선별된 데이터 원본 도메인의 전체 목록은 표 14에 나와 있습니다.

### Line-wise filtering

트라필라투라로 텍스트 추출을 실행하여 얻은 개선에도 불구하고, 우리는 여전히 많은 관련 없는 선이 침투한다는 것을 발견했다. 이러한 줄은 보통 탐색 메뉴, 작업 호출 또는 소셜 미디어 카운터와 관련이 있습니다. 데이터를 수동으로 검사한 후 라인별 필터링 전략을 고안했다. 우리는 문서를 라인 단위로 분석하고 다음 규칙을 기반으로 라인을 폐기하거나 편집합니다.

* 주로 대문자(discard)로 구성되는 경우;
* 숫자문자만으로 구성되는 경우(discard);
* 카운터(예: likes)인 경우(discard);
* 하나의 단어만 포함하는 경우(discard);
* 짧은 경우(\(\leq 10\) 단어) 패턴과 일치하는 경우(편집):
* 줄의 시작 부분에서(예: 로그인);
* 라인의 끝에서(예를 들어, Read more...);
* 줄의 아무 곳(예: 장바구니에 있는 항목)입니다.

마지막으로, 플래그된 선에 있는 단어들이 전체 문서 단어들의 \(5\%\) 이상을 나타내면, 문서는 폐기된다. 데이터의 수동 검사를 통해 이러한 필터를 도출했으며 언어 전반에 걸쳐 적응이 필요하다는 점에 유의한다.

\begin{table}
\begin{tabular}{l l} \hline \hline
**Curated data source** & **Domain name blocked** \\ \hline arxiv & arxiv.org \\ AskUbuntu & askubuntu.com \\ StackOverflow & stackoverflow.com \\  & stackapps.com \\  & stackexchange.com \\  & mathoverflow.net \\ NIH Abstracts & exporter.nih.gov \\  & nchi.nlm.nih.gov \\ Github & github.com \\ Ubuntu IRC & irclogs.ubuntu.com \\ HackerNews & news.ycombinator.com \\ FreeLaw & courtlistener.com \\ Reddit & reddit.com \\ Europarl & statmt.org \\ United States Patents & uspto.gov \\ Wikipedia & wikipedia.org \\ \hline \hline \end{tabular}
\end{table}
표 14: **RefinedWeb은 기존 큐레이트된 코퍼라와의 결합을 단순화하기 위해 일반적인 소위 고품질 소스에서 제거됩니다.* * 이 블록리스트는 성인 콘텐츠 블록리스트와 함께 URL 필터링 단계에서 적용된다.

### deduplication

Lee 등(2022)에 설명된 두 가지 중복 제거 방법을 사용합니다. ExactSubstr 및 NearDedup(부록 G.3.1 및 부록 G.3.2에 자세히 설명되어 있음; 중복 샘플의 경우 부록 H 참조).

우리는 가장 확장 가능한 접근법인 NearDedup으로 시작한다. 본 논문에서는 MinHash (Broder, 1997)를 적용하여 유사 문서를 제거함으로써, 데이터 셋의 각 문서에 대해 효율적인 근사 유사도 질의를 지원하는 서명/스케치를 계산하고, \(n\)-gram 겹침이 높은 문서 쌍을 식별한다.

그런 다음 ExactSubstr을 사용하여 Lee 등(2022)++의 구현을 활용하여 최소 50개 토큰의 정확한 중복 텍스트의 범위를 식별한다. 이러한 범위에 대해 세 가지 다른 접근법을 실험합니다. 원본 구현에서 수행한 대로 원본 텍스트에서 제거하는 ExactSubstr-Cut; 데이터 세트는 변경되지 않지만 복제된 범위에 대한 손실을 계산하지 않는 ExactSubstr-Mask; 및 복제된 범위가 콘텐츠의 특정 비율 이상을 구성하는 경우 전체 문서를 단순히 드롭하는 ExactSubstr-Drop.

각주 ‡: [https://github.com/google-research/dedduplicate-text-datasets](https://github.com/google-research/dedduplicate-text-datasets)

부록 E.1에서 이러한 다양한 접근법을 중심으로 소규모 삭제를 제시한다.

#### g.3.1 MinHash 근사 매칭

우리는 MinHash를 사용하여 웹 코퍼라에서 매우 큰 규모로 대략적인 중복 문서를 찾는다. 이 기술을 사용하면 산재된 복제 섹션의 대부분이 정확한 매칭 방법(50 토큰보다 작은 모든 것)에 의해 식별되지 않을 만큼 충분히 작은 템플릿 페이지 또는 그렇지 않으면 매우 유사한 콘텐츠를 식별할 수 있다.

서명.우리는 리콜을 증가시키기 위해 콘텐츠를 정규화하는 것으로 시작한다: 구두점이 제거되고, 텍스트가 하부케이싱되고, NFD 유니코드 정규화가 적용되고, 액센트가 제거되고, 모든 화이트 스페이스가 정규화된다. 결과 텍스트를 GPT-2 tokenizer (Radford et al., 2019)를 사용하여 토큰화하고 각 문서에 대한 고유한 \(n\)-gram 집합을 얻는다. 해시 함수는 각 문서에 대한 서명을 얻기 위해 사용되며, 각 해시 함수에 대해, 문서의 모든 고유한 \(n\)-그램을 해싱하는 것으로부터 가장 작은 값이 유지된다. 두 문서가 유사하다면, 사용된 해시 함수들 중 적어도 일부에 대해 동일한 최소 해시(MinHash)를 가질 확률이 높다(Broder, 1997). 두 문서 간의 일치 해시의 비율은 고유한 \(n\)-grams 집합의 Jaccard 유사성(Jaccard, 1912)에 근사한다(집합은 \(d_{i}\) 및 \(d_{j}\)):

\[J(d_{i},d_{j})=\frac{|d_{i}\cap d_{j}|}{|d_{i}\cup d_{j}|} \tag{1}\]

매칭. 가능한 모든 문서 쌍 간의 MinHash 서명을 비교하는 것은 계산 비용이 많이 들기 때문에, 본 논문에서는 MinHash, MinHash LSH의 지역성 민감 해싱 버전을 적용한다. 문서 서명은 각각 \(b\) minhash가 있는 \(r\) 버킷으로 분할됩니다. 문서는 각 \(r\) 버킷에서 이러한 \(b\) minhash에 의해 인덱싱되며, 해당 \(b\) minhash가 버킷 중 하나 이상에서 정확히 동일한 경우 두 문서를 중복으로 표시합니다. 이 두 매개변수 \(b\)와 \(r\)는 유사한 문서가 탐지될 확률을 결정합니다. MinHash 서명 간의 일치 해시의 비율이 \(s_{i,j}\)인 두 문서 \(i\)와 \(j\)의 경우, 주어진 버킷에서 일치할 확률은 \(s_{i,j}^{b}\); 어떤 버킷에서도 일치하지 않을 확률은 \((1-s_{i,j}^{b})^{r}\); 마지막으로 버킷 중 적어도 하나에서 일치할 확률은 \(s_{i,j}^{b})^{r}\:

\[P=1-(1-s_{i,j}^{b})^{r} \tag{2}\]

우리는 Lee et al.(2022)과 동일한 매개변수를 사용한다: \(n=5\)(5-grams); \(b=20\) 및 \(r=450\). 이는 각 문서에 대해 총 9000개의 minhash를 계산하며, 유사도가 0.75 또는 0.8인 문서 쌍이 중복으로 표시될 확률은 \(76\%\) 및 \(99.4\%\)로 유사도가 작을수록 빠르게 감소한다는 것을 의미한다.

마지막으로, 모든 버킷에 걸쳐 문서를 클러스터링합니다. 문서 A와 B가 하나의 버킷에서 일치하고 B와 C가 다른 버킷에서 일치하면 A-B-C가 클러스터가 됩니다. 우리는 각 클러스터의 문서 중 하나를 제외한 모든 문서를 무작위로 제거한다.

Lee et al.(2022)은 또한 실제 자카드 유사성 또는 식별된 문서 쌍 간의 편집 유사성과 같은 다른 메트릭을 계산함으로써 거짓 긍정에 대한 필터링을 제안했다. 모든 커먼크롤에서 사용할 수 있는 많은 양의 데이터와 주요 관심사가 리콜 개선이라는 점을 감안할 때 이 추가 단계는 생략하기로 결정했다.

#### g.3.2 Exact substring 중복 제거

정확한 텍스트 매칭을 위해 Lee et al.(2022)에 의해 공개된 ExactSubstr 구현을 이용한다. 우리는 MinHash에 의해 이미 중복 제거된 데이터에 정확한 부분 문자열 중복 제거를 적용하여 우리가 작동해야 하는 데이터 세트의 거의 40% 크기를 줄인다. ExactSubstr은 여러 문서에 걸쳐 있는 문자의 긴 문자열을 찾습니다. 이들 중 일부는 근사 중복 제거의 초기 단계를 벗어났을 수 있다: 문서의 충분한 부분을 구성하지 못할 수 있다; 하나의 문서가 여러 다른 문서에 걸쳐 소스된 섹션을 반복했을 수 있다; 또는 단순히 MinHash의 근사적 특성으로 인해 발견되지 않았을 수 있다.

중복 검색 ExactSubstr은 데이터 세트의 모든 문서를 연결하여 하나의 긴 텍스트 시퀀스를 만든 다음 선형 시간에서 접미사 배열(Manber and Myers, 1993)을 구축합니다. 마지막으로, 접미사의 순서화된 목록을 단순히 횡단하고 두 개의 연속 접미사의 각 쌍의 시작을 비교함으로써 접미사 배열을 사용하여 선형 시간에서도 중복 서열을 찾을 수 있다.

우리는 MinHash와 동일한 정규화 및 토큰화를 문서 연결 전에 문서 내용에 적용한다. 한 가지 중요한 차이점은 가역성이 중요하다는 것이다: MinHash의 경우 전체 문서를 폐기했기 때문에 다운스트림 사용을 위해 정규화된+토큰화된 표현에 의존하지 않았다. 여기서 중복된 정규화된+토큰화된 스팬을 식별하면 원래 스팬으로 되돌아가 제거해야 한다. 따라서 토큰화 프로세스에 정규화를 포함하고 프로세스가 가역적인지 검증한다.

일치가 50 토큰보다 긴 경우 중복 범위가 여러 개 있습니다. 연결된 데이터 세트 시퀀스에서 중복되는 이러한 범위는 파일에 저장하기 전에 병합됩니다. 그런 다음 이러한 범위를 취하여 원본 문서를 검색하여 복제된 토큰 범위에 해당하는 문자 부분 문자열을 가져옵니다.

중복 제거. 중복 경간에 다음 변환을 적용하는 것을 고려했습니다.

* ExactSubstr-Cut: 중복된 스팬을 제거하고, 20개 미만의 중복되지 않은 문자가 남아 있는 문서를 폐기합니다. 이것은 Lee et al. (2022)에 의해 사용된 바닐라 설정이고;
* ExactSubstr-Mask: 중복된 기간을 손실 마스킹하여 사전 훈련 중에 중복된 텍스트에서 손실이 계산되지 않도록 하고, 마스킹되지 않은 문자가 20개 미만인 문서는 폐기합니다.
* ExactSubstr-DropPartial: 문서의 20% 이상이 중복되면 전체 문서를 제거합니다.
* ExactSubstr-DropPary: 중복된 범위를 가진 모든 문서를 삭제합니다.

일반적으로 ExactSubstr-Cut은 텍스트 중간 문장을 제거하여 연결이 끊긴 텍스트를 생성할 수 있습니다. ExactSubstr-Mask는 이 문제가 없지만 훈련 토큰의 상당 부분이 모델의 가중치 업데이트에 직접 기여하지 않기 때문에 효율성이 떨어질 수 있습니다. ExactSubstr-Drop은 부분 버전, 특히 더 큰 문서에서 여전히 상당한 중복 섹션을 유지할 수 있지만 Any 버전은 지나치게 공격적일 수 있습니다. 부록 E.1의 절제 후 바닐라 접근법인 ExactSubstr-Cut을 고수하기로 선택한다.

모든 경우에 MinHash는 복제된 문서의 복사본 하나를 보관하지만, 정확한 중복 제거는 복제된 범위의 복사본을 모두 제거합니다.

### Execution environment

대부분의 데이터 처리는 100-250 AWS c5.18xlarge 인스턴스로 대규모 CPU 클러스터에서 수행되었으며 각 인스턴스에는 72개의 vCPU와 144개의 GiB의 메모리가 있다. 일반적으로 클러스터에서 10,000-20,000 vCPU로 실행하므로 빠른 병렬 처리가 가능합니다.

ExactSubstr의 경우 중복 제거된 전체 데이터 세트를 메모리에 로드해야 합니다. 단일 인스턴스에서 최대 2TiB의 메모리와 함께 제공되는 AWS x2iedn 인스턴스를 활용했습니다.

## RefinedWeb의 부록 H 중복 제거 샘플

### MinHash clusters

우리는 표 15에서 MinHash가 발견한 8개의 가장 큰 중복 클러스터를 보고하며, 각각은 수십만 개의 문서에 걸쳐 있다. 또한 URL GET 매개 변수가 다르기 때문에 중복 문서 쌍이 많이 발견되어 내용이 크게 다르지 않다. 이 행동의 예는 표 16에 제시된 URL에서 볼 수 있다.

\begin{table}
\begin{tabular}{p{113.8pt}|p{113.8pt}} \hline \hline
**Description** & **Example document** \\ \hline Wordpress sitemap notice generated by the Google Bitemap & This is a XML Sitemap which is supposed to be processed by search engines which follow the XML Sitemap standard like Ask.com, Bing, Google and Yahoo. It was generated using the WordPress content management system and the Google Bitemap Generator Plugin by Arne Brachhold. You can find more information about XML sitemaps on sitemaps.org and Google’s list of sitemap programs. This file contains links to sub-sitemaps, follow them to see the actual sitemap content. \\ \hline Cloudflare notice to enable Javascript & \\ \hline Templated disability notice, with different phone numbers across pages & Welcome to our website! As we have the ability to list over one million items on our website (our selection changes all of the time), it is not feasible for a company our size to record and playback the descriptions on every item on our website. However, if you are an American with a disability we are here to help you. Please call our disability services phone line at [redacted] or [redacted] during regular business hours and one of our kind and friendly personal shoppers will help you navigate through our website, help conduct advanced searches, help you choose the item you are looking for with the specifications you are seeking, read you the specifications of any item and consult with you about the products themselves. There is no charge for the help of this personal shopper for any American with a disability. Finally, your personal shopper will explain our Privacy Policy and Terms of Service, and help you place an order if you so desire. \\ \hline Templated cookies notice & \\ \hline Templated domain name for sale page & \\ \hline www.metoperashop.org and sub-URLs, with content changes but always the same (large) footer & \\ \hline Different pages across more than 80 different domain names but with a common section & DC Customers also liked: Special event items are produced by manufacturers only after the outcome of a game or event. These are advanced sale items and will ship immediately after they are received in our warehouse. Manufacturer direct items are shipped directly from the manufacturer. These items are not available for international or expedited shipping. Customized items can be personalized with options such as your name, your favorite number, and/or designs. Some options may be limited by league rules. \\ \hline [http://www.boxofficemojo.com/daily](http://www.boxofficemojo.com/daily) and sub-URLs & \\ \hline \hline \end{tabular}
\end{table}
표 15: **RefinedWeb을 빌드할 때 가장 큰 MinHash 클러스터를 찾을 수 있습니다.* * 가독성을 위해 가장 긴 샘플 중 일부를 잘라 간략한 설명만 유지합니다.**

### 정확한 부분 문자열 일치

정확한 부분 문자열 중복 제거에 의해 발견되는 정확한 일치의 예는 표 17에서 볼 수 있다.

\begin{table}
\begin{tabular}{l|l} \hline \hline [http://gamesandbiz.blogspot.com/2010/](http://gamesandbiz.blogspot.com/2010/) & [http://gamesandbiz.blogspot.com/2010/](http://gamesandbiz.blogspot.com/2010/) \\
07/bad-reviews-can-hurt-game-sales.ht & 07/bad-reviews-can-hurt-game-sales.ht \\ ml?showComment=1278486430242 & ml?showComment=1278499674195 \\ \hline [https://www.ocean-oxygen.org/home](https://www.ocean-oxygen.org/home);jse & [https://www.ocean-oxygen.org/home?p_p](https://www.ocean-oxygen.org/home?p_p) \\ ssionid=1E3290E84F668552FAC643D0A8F81 & _id=122_INSTANCE_Zy6zjkRLA97vg_p_lif \\ BEC?p_p_id=122_INSTANCE_Zy6zjkRLA97vg & ccycle=08p_p_state=normal\_p_p \\ p\_p\_lifecycle=0\&p\_p\_state=normal\_p\_p \\ p\_p\_lifecycle=0\&p\_p\_state=normal\_p\_p \\ mode=view\&p\_p\_col\_id=column-2\&p\_p\_col\_pos=1\& \\ p\_pos=1\&p\_p\_col\_count=6\&p\_r\_p\_564233524\_reset \\
4\_resetCur=true\&p\_r\_p\_564233524\_categoryId=1 & Cur=true\&p\_r\_p\_564233524\_categoryId=1 \\ dryId=1346016 & 346016 & 346016 \\ \hline \hline \end{tabular}
\end{table}
표 16: **다른 GET 매개 변수가 있는 URL이 항상 페이지 내용이 크게 다른 것은 아닙니다.* * 이 관계에 순위 신호가 전송 되는 것으로 나타났습니다. 이 발견을 지원하는 것은 구글의 지침에서 인용한 것입니다: _JavaScript를 사용하여 사용자를 리디렉션하는 것은 합법적인 관행이 될 수 있습니다. 예를 들어 사용자가 로그인한 후 내부 페이지로 리디렉션하는 경우 JavaScript를 사용하여 수행할 수 있습니다. 자바스크립트 또는 기타 리디렉션 방법을 검토하여 사이트가 당사 지침을 준수하는지 확인할 때 의도를 고려하십시오. 사이트를 이동할 때는 301 리디렉션이 가장 좋지만 웹 사이트의 서버에 액세스할 수 없는 경우 이 목적으로 JavaScript 리디렉션을 사용할 수 있습니다._ NOTE: 그들의 실험은 상태 코드가 200인 라이브 페이지를 기반으로 하고 비활성 페이지가 아닙니다. 따라서 레거시 +를 위해 이것을 구현하려면
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 생동감 넘치는 수채화 팝슬 패턴으로 여러분의 강아지는 여름마다 요리할 준비가 될 것입니다! _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 생동감 넘치는 수채화 팝슬 패턴으로 여러분의 강아지는 여름마다 요리할 준비가 될 것입니다! _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 생동감 넘치는 수채화 팝슬 패턴으로 여러분의 강아지는 여름마다 요리할 준비가 될 것입니다! _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_

+
각주 †: 이 반다나는 모든 아기 생일 컬렉션에 완벽한 추가를 만듭니다! 반짝이는 왕관 무늬로 여러분의 강아지는 모든 생일 축하를 위해 준비될 것입니다. _ 보안을 위한 스냅으로 이 반다나는 사랑으로 만들어집니다 마지막 바느질까지! 원단: 면 관리 지침: 손 씻기 전용, 필요에 따라 철분, 약한 불에서 항상 강아지가 Faithful Paws Co. 액세서리를 착용하는 동안 감독합니다. 소비하면 질식 위험이 될 수 있으므로_
