<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.16971] AIOS: LLM Agent Operating System</title><meta property="og:description" content="The integration and deployment of large language model (LLM)-based intelligent agents have been fraught with challenges that compromise their efficiency and efficacy. Among these issues are sub-optimal scheduling and r…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AIOS: LLM Agent Operating System">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="AIOS: LLM Agent Operating System">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.16971">

<!--Generated on Fri Apr  5 16:24:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">AIOS: LLM Agent Operating System</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Kai Mei 
<br class="ltx_break">Rutgers University 
<br class="ltx_break">Zelong Li 
<br class="ltx_break">Rutgers University 
<br class="ltx_break">Shuyuan Xu 
<br class="ltx_break">Rutgers University 
<br class="ltx_break">Ruosong Ye 
<br class="ltx_break">Rutgers University 
<br class="ltx_break">Yingqiang Ge 
<br class="ltx_break">Rutgers University 
<br class="ltx_break">Yongfeng Zhang 
<br class="ltx_break">Rutgers University
</span><span class="ltx_author_notes"><sup id="id2.2.id1" class="ltx_sup">∗</sup><span id="id3.3.id2" class="ltx_text ltx_font_bold">Author Affiliations</span>: Department of Computer Science, Rutgers University, New Brunswick, NJ 08854; <span id="id4.4.id3" class="ltx_text ltx_font_bold">Author Emails</span>: kai.mei, zelong.li, shuyuan.xu, ruosong.ye, yingqiang.ge, yongfeng.zhang@rutgers.edu</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">대규모 언어 모델(LLM) 기반 지능형 에이전트의 통합 및 배포는 효율성과 효율성을 손상시키는 과제로 가득했다. 이러한 문제 중에는 LLM을 통한 에이전트 요청의 차선책 스케줄링 및 자원 할당, 에이전트와 LLM 간의 상호 작용 중 컨텍스트 유지의 어려움, 서로 다른 기능과 전문화를 가진 이종 에이전트를 통합하는 데 내재된 복잡성이 있다. 에이전트 양과 복잡성의 급격한 증가는 이러한 문제를 더욱 악화시켜 종종 병목 현상과 리소스의 차선책 활용으로 이어진다. 이러한 문제에서 영감을 얻은 이 논문은 LLM 에이전트 운영 시스템인 AIOS를 제안하며, 이는 OS의 뇌로서 운영 체제(OS)에 큰 언어 모델을 내장하여 AGI를 향한 중요한 단계인 "영혼이 있는" 운영 체제를 가능하게 한다. 구체적으로, AIOS는 리소스 할당을 최적화하고, 에이전트들 간의 컨텍스트 전환을 용이하게 하며, 에이전트들의 동시 실행을 가능하게 하고, 에이전트들에 대한 툴 서비스를 제공하고, 에이전트들에 대한 액세스 제어를 유지하도록 설계된다. 우리는 이러한 운영체제의 아키텍처를 제시하고, 그것이 해결하고자 하는 핵심 과제를 개괄하며, AIOS의 기본 설계 및 구현을 제공한다. 여러 에이전트의 동시 실행에 대한 실험은 AIOS 모듈의 신뢰성과 효율성을 보여준다. 이를 통해 LLM 에이전트의 성능과 효율성을 향상시킬 뿐만 아니라 향후 AIOS 생태계의 더 나은 개발 및 배치를 위한 개척을 목표로 한다. 프로젝트는 <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/agiresearch/AIOS" target="_blank" title="">https://github.com/agiresearch/AIOS</a>에서 오픈 소스입니다.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">자율 에이전트 분야에서 연구 노력 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>, <a class="ltx_ref" href="#bib.bib3" title="">3</a>]</cite>는 인간의 개입 없이 독립적으로 작동하고 의사 결정을 내리고 작업을 수행할 수 있는 시스템을 지향한다. 이러한 에이전트는 지시를 이해하고, 정보를 처리하고, 결정을 내리고, 자율 상태를 달성하기 위한 조치를 취하도록 설계되었다. 대형 언어 모델(LLMs) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>, <a class="ltx_ref" href="#bib.bib5" title="">5</a>, <a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite>의 등장은 에이전트 개발 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>]</cite>에 새로운 가능성을 가져왔다. 현재 LLMs은 명령어 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib9" title="">9</a>, <a class="ltx_ref" href="#bib.bib10" title="">10</a>, <a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite>, 추론 및 문제 해결 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib13" title="">13</a>, <a class="ltx_ref" href="#bib.bib14" title="">14</a>, <a class="ltx_ref" href="#bib.bib15" title="">15</a>, <a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite>, 외부 환경 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>, <a class="ltx_ref" href="#bib.bib19" title="">19</a>]</cite>뿐만 아니라 인간 사용자 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib17" title="">17</a>]</cite>와 상호작용하는 데 큰 힘을 발휘하고 있다. 이러한 강력한 LLM을 기반으로 한 새로운 LLM 기반 에이전트 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>, <a class="ltx_ref" href="#bib.bib21" title="">21</a>, <a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>는 가상 비서부터 복잡하고 창의적인 문제 해결, 계획 및 추론을 포함하는 보다 정교한 시스템에 이르기까지 다양한 환경에서 강력한 작업 수행 능력을 제시할 수 있다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">LLM 기반 에이전트가 실제 작업을 해결하는 방법에 대한 한 가지 강력한 예는 <a class="ltx_ref ltx_refmacro_autoref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>에서 볼 수 있다. 사용자로부터의 여행 조직 요청이 주어지면, 여행 에이전트는 태스크를 실행가능한 단계들로 분해한다. 그런 다음 사용자의 선호도에 따라 항공편 예약, 호텔 예약, 결제 처리 및 일정 업데이트 단계를 순차적으로 수행합니다. 계획 실행 동안 에이전트는 추론 및 의사 결정 능력을 보여주며, 이는 미리 정의된 함수 집합 또는 워크플로우로 제한되는 전통적인 소프트웨어 애플리케이션과 구별된다. 이 여행 시나리오를 실현하기 위해, 에이전트는 LLM 서비스(예를 들어, 사용자 선호도 검색 및 이해, 호출할 도구 API 결정, 리뷰 및 응답 생성) 및 전통적인 운영 체제(OS) 서비스(예를 들어, 디스크 드라이버 액세스 및 소프트웨어 실행) 둘 다와 상호작용할 필요가 있다.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2403.16971/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="117" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 1: </span>에이전트(즉, Travel Agent)가 작업을 완료하기 위해 LLM 레벨 및 OS 레벨 리소스 및 함수 모두를 필요로 하는 방법의 동기 부여 예.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.1">제제 양과 복잡성의 기하급수적인 증가와 함께 LLM 및 OS의 기능에 대한 부담이 증가하고 있다. 예를 들어, 제한된 LLM 리소스들에서 에이전트 요청들을 스케줄링하고 우선순위화하는 것은 상당한 도전을 제기한다. 더욱이, LLM의 생성 프로세스는 긴 컨텍스트들을 다룰 때 시간 집약적이 될 수 있고, 때때로 스케줄러에 의해 생성이 중단된다. 이는 LLM의 현재 생성 결과를 스냅샷하는 메커니즘을 고안하여 LLM이 현재 요청에 대한 응답 생성을 완료하지 않은 경우에도 일시 중지/재시작 동작을 가능하게 하는 문제를 야기한다. 또한 에이전트가 사용 가능한 호출 도구 목록을 얻으면 여러 에이전트가 동일한 도구를 호출해야 할 수 있기 때문에 이러한 도구를 호출하기 위한 최적의 순서를 결정하는 것은 또 다른 과제를 제시한다. 또한, 다수의 에이전트들의 동시 동작은 상이한 에이전트들에 걸쳐 메모리 관리를 위한 강력한 시스템을 필요로 하는 동시에, 프라이버시 및 액세스 제어 조치들의 엄격한 집행을 보장한다.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1">위에서 언급한 문제를 해결하기 위해 LLM 및 OS 기능의 모듈 분리 및 집계를 제공하는 LLM 에이전트 운영 체제(<a class="ltx_ref ltx_refmacro_autoref" href="#S2.F2" title="Figure 2 ‣ LLM-based Multi-Agent Systems. ‣ 2.2 Large Language Model Agents ‣ 2 Related Work ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>)인 AIOS를 제안한다. LLM과 관련된 태스크와 LLM과 관련이 없는 태스크 간에 발생할 수 있는 잠재적인 충돌을 해결하기 위해 LLM 특정 커널의 설계를 제안한다. 이 커널은 OS와 같은 임무, 특히 LLM 에이전트, 해당 리소스 및 개발 도구 키트의 감독과 관련된 임무를 분리한다. 이러한 분리를 통해 LLM 커널은 LLM 관련 활동의 관리 및 조정을 향상시키는 것을 목표로 한다. 제안된 LLM 커널 내에서 우리는 각각 LLM 연산과 관련된 고유한 기능을 다루는 데 전념하는 모듈 세트를 고안했다. 이러한 모듈 및 각각의 기능에 대한 개요는 섹션 <a class="ltx_ref" href="#S4" title="4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">4</span></a>에 자세히 설명된 기본 메커니즘에 대한 포괄적인 논의와 함께 다음에서 제시된다.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Agent Scheduler</span>: Prioritizes and schedules agent requests to optimize LLM utilization.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Context Manager</span>: LLM 및 LLM의 컨텍스트 윈도우 관리에서 스냅샷을 지원하고 중간 생성 상태를 복원합니다.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Memory Manager</span>: 각 에이전트의 상호 작용 로그에 대한 단기 메모리를 제공합니다.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i4.p1.1.1">Storage Manager</span>: Persists agent interaction logs to long-term storage for future retrieval.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i5.p1.1.1">Tool Manager</span>: Manages agent's calling of external API tools (예: search, scientific computing).</p>
</div>
</li>
<li id="S1.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i6.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i6.p1.1.1">Access Manager</span>: Enforces privacy and access control policies between agent.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S1.p4.2">모듈 외에도 커널은 에이전트가 이러한 서비스를 투명하게 활용할 수 있는 LLM 시스템 호출 인터페이스를 노출합니다. 또한, LLM 시스템 호출을 더욱 캡슐화하여 에이전트 개발자에게 보다 편리한 에이전트 라이브러리 기능을 제공하기 위해 AIOS SDK를 설계한다. AIOS 아키텍처를 사용하여 여행 플래너와 같은 에이전트는 작업을 LLM 추론(예: 계획 생성 및 도구 호출 결정)과 OS 수준 작업(예: 스토리지 액세스 및 소프트웨어 서비스 실행)을 유동적으로 결합하는 단계로 나눌 수 있습니다. 이러한 시너지 기능의 조합은 여러 LLM 에이전트를 구비하여 추론, 실행 및 물리적 세계와의 상호 작용을 필요로 하는 점점 더 복잡한 다중 모드 작업을 해결한다.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p" id="S1.p5.1">앞으로는 AIOS를 확장하여 보다 엄격한 에이전트-세계 통합(예: 로봇 제어를 통해), 보다 지능적인 리소스 관리 및 보다 안전한 다중 에이전트 협업을 지원하는 것을 구상합니다. 궁극적으로 AIOS는 다양한 복잡한 LLM 에이전트의 개발, 배포 및 사용을 촉진하는 중요한 플랫폼 역할을 한다.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Evolution of Operating Systems</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p1.1">운영 체제(OS)의 진화는 초보적인 시스템에서 오늘날의 복잡하고 상호작용적인 OS로 진화하는 점진적인 방식으로 전개되었다. 초기에, 운영 체제들은 전자 및 게이트 조작과 같은 컴퓨터 하드웨어의 이진 기능과 사용자-레벨 태스크들 사이의 갭을 해소하는 역할을 하였다. 그들의 진화는 단순 배치 작업 처리 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite>에서 시간 공유 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite> 및 다중 작업 처리 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>, <a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>와 같은 고급 프로세스 관리 기술로 전환되어 점점 더 복잡한 작업의 처리를 용이하게 했다. 프로세스 스케줄링 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>, 메모리 관리 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>, <a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>, 파일시스템 관리 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>, <a class="ltx_ref" href="#bib.bib32" title="">32</a>]</cite> 등의 구체적인 책임을 기술하면서 OS 내에서 모듈화 방향으로 나아갔다. 그래픽 사용자 인터페이스(GUI)의 추가 출현, 예를 들어, Macintosh<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://apple-history.com/128k" target="_blank" title="">http://apple-history.com/128k</a></span></span></span>, Windows<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://winworldpc.com/product/windows-3/31" target="_blank" title="">https://winworldpc.com/product/windows-3/31</a></span></span></span> 및 GNOME<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.gnome.org/" target="_blank" title="">https://www.gnome.org/</a></span></span></span>은 운영 체제를 보다 상호작용적이고 사용자 중심적으로 만든다. 한편, 운영 체제 생태계도 확장되어 개발 도구(OS SDK)와 런타임 라이브러리의 포괄적인 제품군을 제공한다. 이러한 도구를 통해 애플리케이션 개발자는 OS 환경 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite> 내에서 애플리케이션을 효율적으로 설계, 구현 및 실행할 수 있다. OS 생태계의 주목할 만한 예로는 Android Studio<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://developer.android.com/studio" target="_blank" title="">https://developer.android.com/studio</a></span></span></span>, XCode<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://developer.apple.com/xcode/" target="_blank" title="">https://developer.apple.com/xcode/</a></span></span></span> 및 Cloud SDK<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cloud.google.com/sdk" target="_blank" title="">https://cloud.google.com/sdk</a></span></span></span> 등이 있다. 이러한 생태계에서 OS는 소프트웨어 개발을 촉진하기 위해 수많은 자원을 제공하고 소프트웨어 애플리케이션을 배포하고 호스팅하는 플랫폼 역할을 하여 번성하는 OS-애플리케이션 생태계로 이어진다. 오늘날 우리는 지능형 운영체제의 잠재력을 보기 위해 변형 단계에 서 있다. 대형 언어 모델(LLM)의 통합으로, 이러한 고급 시스템은 인간과 기계 사이의 통신 격차를 더욱 좁혀 사용자-컴퓨터 상호 작용의 새로운 시대를 앞당길 것을 약속한다.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Large Language Model Agents</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p1.1">LLM(Large Language Model) 기반의 자율 에이전트는 복잡한 과제 해결을 위해 자연어 명령어를 입력으로 사용한다. LLM 기반 에이전트에 대한 연구는 일반적으로 단일 에이전트 시스템과 다중 에이전트 시스템 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>로 분류할 수 있다.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">LLM-based Single-Agent Systems.</h4>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.1">LLM 기반 단일 에이전트 시스템(SAS)은 여행 계획, 개인화된 추천, 예술적 디자인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>]</cite>와 같은 복잡한 과제 해결을 위해 단일 LLM 에이전트를 사용한다. 에이전트는 사용자로부터의 자연어 명령을 입력으로 하고 태스크를 태스크 해결을 위한 다단계 계획으로 분해하며, 여기서 각 단계는 정보 수집, 전문 모델 실행 또는 외부 세계와의 상호작용과 같은 완료될 외부 도구를 호출할 수 있다. 단일 에이전트 애플리케이션은 해결해야 할 작업에 따라 디지털 환경 또는 물리적 환경 또는 둘 다와 결합할 수 있다. 예를 들어, 가상 또는 디지털 환경의 에이전트들은 API들 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>, <a class="ltx_ref" href="#bib.bib34" title="">34</a>, <a class="ltx_ref" href="#bib.bib35" title="">35</a>, <a class="ltx_ref" href="#bib.bib36" title="">36</a>, <a class="ltx_ref" href="#bib.bib37" title="">37</a>]</cite>, 웹사이트들 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib38" title="">38</a>, <a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>, 또는 코드들 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib39" title="">39</a>]</cite>를 호출할 수 있고, 물리적 환경의 에이전트들은 오브젝트들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib19" title="">19</a>, <a class="ltx_ref" href="#bib.bib40" title="">40</a>, <a class="ltx_ref" href="#bib.bib41" title="">41</a>]</cite>, 랩 실험들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib42" title="">42</a>, <a class="ltx_ref" href="#bib.bib43" title="">43</a>]</cite>, 또는 행동가능한 결정들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>, <a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>를 수행할 수 있다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">LLM-based Multi-Agent Systems.</h4>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.1">LLM 기반 다중 에이전트 시스템(MAS)은 문제 해결을 위해 여러 에이전트 간의 상호 작용을 활용한다. 여러 에이전트 간의 관계는 협력, 경쟁 또는 협력과 경쟁의 혼합 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>일 수 있다. 협력형 다중 에이전트 시스템에서 각 에이전트는 다른 에이전트가 제공하는 정보를 가져와서 평가함으로써 역할극 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>, 소셜 시뮬레이션 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib47" title="">47</a>]</cite> 및 소프트웨어 개발 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib48" title="">48</a>, <a class="ltx_ref" href="#bib.bib49" title="">49</a>, <a class="ltx_ref" href="#bib.bib50" title="">50</a>, <a class="ltx_ref" href="#bib.bib51" title="">51</a>]</cite>와 같은 복잡한 작업을 해결하기 위해 함께 작업한다. 경쟁적 다중 에이전트 시스템에서 에이전트는 협상 기술 개선 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib52" title="">52</a>]</cite> 및 정답 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib53" title="">53</a>, <a class="ltx_ref" href="#bib.bib54" title="">54</a>, <a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>에 대한 토론과 같이 목표를 달성하기 위해 게임 환경에서 서로 디타브, 협상 및 경쟁할 수 있다. 일부 다중 에이전트 시스템은 에이전트 간의 협력과 경쟁을 모두 나타낼 수 있다. 예를 들어 WarAgent <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>는 각 국가를 LLM 기반 에이전트로 모델링하여 각 국가 간의 상호 작용이 국제 분쟁으로 이어질 수 있는 방법을 연구하는데, 각 국가는 동맹을 수립하고 평화 협정을 체결하는 등 서로 협력하거나 군비 경쟁, 동원, 전쟁 선포 등 서로 경쟁할 수 있다.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2403.16971/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="248" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 2:</span>AIOS 아키텍처의 개요.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overview of the AIOS architecture.
</figcaption>
</figure>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>AIOS Layers</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p" id="S3.p1.1"><a class="ltx_ref ltx_refmacro_autoref" href="#S2.F2" title="Figure 2 ‣ LLM-based Multi-Agent Systems. ‣ 2.2 Large Language Model Agents ‣ 2 Related Work ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>에 묘사된 바와 같이, AIOS의 아키텍처는 애플리케이션 계층, 커널 계층 및 하드웨어 계층의 세 가지 별개의 계층으로 구성된다. 이 계층화된 아키텍처는 시스템 전반에 걸친 책임의 명확한 묘사를 보장합니다. 각각의 상위 계층은 그 아래의 계층들의 복잡성을 추상화하여, 인터페이스들 또는 특정 모듈들을 통한 상호작용을 용이하게 하여, 모듈성을 향상시키고 상이한 계층들에 걸친 시스템 상호작용들을 단순화시킨다.</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Application Layer. </h4>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">응용 프로그램 계층에서 여행 에이전트 또는 수학 에이전트와 같은 에이전트 응용 프로그램이 개발 및 배포됩니다. 이 계층에서 AIOS는 에이전트 개발자를 위한 개발 프로세스를 간소화하는 시스템 호출의 더 높은 추상화를 AIOS SDK에 제공한다. 이 SDK는 하위 수준 시스템 기능의 복잡성을 추상화하는 풍부한 툴킷을 제공하여 에이전트 애플리케이션을 개발할 수 있습니다. 이를 통해 개발자는 에이전트의 필수 논리 및 기능에 초점을 맞출 수 있어 보다 효율적인 개발 프로세스를 촉진할 수 있다.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Kernel Layer. </h4>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1">커널 레이어는 OS 커널과 LLM 커널의 두 가지 주요 구성 요소로 나뉘며, 각각은 비LLM 및 LLM 특정 연산의 고유한 요구 사항을 제공한다. 이러한 구별은 LLM 커널이 컨텍스트 관리 및 에이전트 스케줄링과 같은 LLM 특정 작업에 초점을 맞출 수 있게 하는데, 이는 LLM 관련 활동을 처리하는데 필수적이며 일반적으로 표준 OS 커널 함수의 범위 내에 있지 않다. 우리의 작업은 주로 기존 OS 커널 구조를 크게 변경하지 않고 LLM 커널을 향상시키는 데 중점을 둔다. LLM 커널에는 LLM 시스템 호출 인터페이스, 에이전트 스케줄러, 컨텍스트 매니저, 메모리 매니저, 스토리지 매니저, 툴 매니저, 액세스 매니저 등 여러 핵심 모듈이 탑재되어 있다. 이러한 구성 요소는 에이전트 애플리케이션의 다양한 실행 요구를 해결하기 위해 설계되어 AIOS 프레임워크 내에서 효율적인 관리 및 실행을 보장합니다. 이들 모듈의 구체적인 내용은 섹션 <a class="ltx_ref" href="#S4" title="4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">4</span></a>에서 더 자세히 설명될 것이다.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Hardware Layer. </h4>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">하드웨어 계층은 CPU, GPU, 메모리, 디스크 및 주변 장치를 포함하는 시스템의 물리적 구성요소를 포함한다. LLM 커널의 시스템 호출은 하드웨어와 직접 상호 작용할 수 없다는 점에 유의하는 것이 중요하다. 대신 이러한 호출은 OS의 시스템 호출과 인터페이스하여 하드웨어 리소스를 관리합니다. 이러한 간접적인 상호 작용은 추상화 및 보안의 계층을 보장하여 LLM 커널이 직접적인 하드웨어 관리를 요구하지 않고 하드웨어 능력을 활용할 수 있도록 하여 시스템의 무결성 및 효율성을 유지한다.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>AIOS Implementation</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1">이 섹션에서는 LLM 커널 내의 각 모듈의 기본 설계 및 구현에 대한 개요로 시작한다. 이후, 각 모듈에 대한 필수 기능을 포괄하는 LLM 시스템 호출을 제시한다. 마지막으로 에이전트 개발자를 위한 개발 프로세스를 용이하게 하기 위해 AIOS SDK에 대한 탐색에 대해 논의한다.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Agent Scheduler</h3>

<figure id="S4.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2403.16971/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="107" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 3:</span>에이전트 스케줄러의 예시.</figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1">에이전트 스케줄러는 에이전트 요청을 효율적으로 관리할 수 있도록 설계되었다. <a class="ltx_ref ltx_refmacro_autoref" href="#S4.F3" title="Figure 3 ‣ 4.1 Agent Scheduler ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>에서 다양한 에이전트(A, B, C로 표시됨)를 고려하며, 각 에이전트에는 여러 실행 단계가 있습니다. 순차 실행 패러다임에서, 에이전트 태스크들은 선형 순서로 처리되며, 여기서 동일한 에이전트로부터의 단계들이 먼저 처리될 것이다. 이는 시퀀스 후반에 대기 중인 태스크에 대한 잠재적인 대기 시간을 증가시킬 수 있다.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p2.1">에이전트 스케줄러는 이 프로세스를 최적화하기 위해 FIFO(First-In-First-Out)<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)" target="_blank" title="">https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)</a></span></span></span>, RR(Round Robin)<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/Round-robin_scheduling" target="_blank" title="">https://en.wikipedia.org/wiki/Round-robin_scheduling</a></span></span></span>, 기타 스케줄링 알고리즘과 같은 전략을 사용한다. 동시 실행을 통해, 스케줄러는 상이한 에이전트로부터의 태스크들이 인터리빙되고 병렬로 실행됨에 따라 각 에이전트의 대기 시간 및 턴어라운드 시간의 균형을 상당히 조정한다. 이 동시 접근법은 상이한 에이전트들로부터의 태스크들이 인터리빙된 방식(예를 들어, A1, B1, C1, B2, A2, A3, C2, C3)으로 프로세싱되는 타임라인을 통해 시각화되어, 단일 에이전트가 프로세싱 리소스들을 독점하지 않고 유휴 시간들이 최소화되도록 보장한다. 기존의 스케줄링 알고리즘들을 구현하는 것 외에도, 에이전트 요청들 간의 종속 관계를 고려한 보다 복잡한 스케줄링 알고리즘들이 또한 통합될 수 있으며, 이는 향후 고려될 수 있다.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Context Manager</h3>

<figure id="S4.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2403.16971/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="287" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 4:</span>컨텍스트 스냅샷 및 복원, 여기서 우리는 이러한 생성 디코딩 프로세스를 예시하기 위해 빔 서치(빔 폭 = 1)를 예시적인 서치 알고리즘으로서 사용한다.</figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p1.1">컨텍스트 관리자는 LLM에 제공되는 컨텍스트 및 특정 컨텍스트가 주어진 생성 프로세스를 관리하는 역할을 한다. 여기에는 주로 컨텍스트 스냅숏 및 복원, 컨텍스트 창 관리의 두 가지 중요한 기능이 포함됩니다.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2403.16971/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="231" height="246" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5:</span>Storage of interaction history with memory manager and storage manager.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Context Snapshot and Restoration. </span> 스케줄러 알고리즘들이 시간 양자 연산들(예를 들어, 라운드-로빈)을 수반할 수 있고 에이전트 요청들이 스케줄러에 의해 일시 중지될 수 있음을 고려한다. 이 서스펜션은 LLM에 의해 아직 응답이 완전히 생성되지 않은 경우에도 발생한다. 따라서 LLM 생성 과정의 상태를 보존할 수 있는 메커니즘이 필요하며, 자원을 다시 사용할 수 있게 되면 이를 정확하게 재개할 수 있다.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p3.1">AIOS는 이 문제를 해결하기 위해 컨텍스트 관리자에서 스냅샷 및 복원 메커니즘을 제공하며, 이는 <a class="ltx_ref ltx_refmacro_autoref" href="#S4.F4" title="Figure 4 ‣ 4.2 Context Manager ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Figure 4</span></a>에서 볼 수 있다. 우리는 생성 디코딩 프로세스를 설명하기 위해 LLMs<cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>, <a class="ltx_ref" href="#bib.bib57" title="">57</a>, <a class="ltx_ref" href="#bib.bib58" title="">58</a>]</cite>의 전형적인 관행인 빔 탐색 프로세스 <span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/Beam_search" target="_blank" title="">https://en.wikipedia.org/wiki/Beam_search</a></span></span></span>을 사용한다. 예시의 단순화를 위해 빔 폭을 1로 설정합니다. 구체적으로 에이전트 요청을 다음과 같이 간주합니다. <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.1">비행 UA057</span>의 목적지에 비가 올지 여부를 결정합니다. 각각의 단계에서, LLM은 다수의 잠재적인 후보들을 평가하고, 미리 정의된 빔 폭에 기초하여 추가 확장을 위해 가장 유망한 경로들이 유지된다.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p4.1">이러한 생성 프로세스가 중간 단계에서 스케줄러에 의해 중단되었을 때, 컨텍스트 관리자는 스냅샷 함수를 사용하여 응답을 생성하기 위해 탐색되는 모든 중간 확률 및 경로를 포함하는 LLM 빔 탐색 트리의 현재 상태를 캡처하고 저장한다. 재시작 시 복원 함수를 사용 하 여 스냅숏에서 저장 된 상태를 다시 로드 하 여 LLM이 중지 지점에서 정확히 생성 프로세스를 계속 하 여 최종 답변에 도달할 수 있습니다. <span class="ltx_text ltx_font_italic" id="S4.SS2.p4.1.1">Search weather in Paris</span>. 이러한 방식으로, 컨텍스트 관리자는 하나의 에이전트의 요청의 일시적인 중단이 진행의 손실로 이어지지 않도록 보장함으로써, 응답 생성의 품질 및 효율성을 손상시키지 않으면서 자원 사용을 최적화한다.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p5.1.1">Context Window Management. </span> LLM의 컨텍스트 윈도우 한계를 초과하는 긴 컨텍스트에 의해 야기되는 문제를 해결하기 위해 컨텍스트 관리자는 또한 컨텍스트 윈도우의 잠재적인 확장을 관리할 필요가 있다. 구체적으로, AIOS의 컨텍스트 매니저는 기본적인 텍스트 요약을 지원하며, 컨텍스트 윈도우를 관리하기 위해 다른 확장 기법 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>, <a class="ltx_ref" href="#bib.bib60" title="">60</a>]</cite>를 통합한다. 이러한 방식으로 정보의 무결성 또는 관련성을 손상시키지 않으면서 광범위한 컨텍스트를 처리하고 이해하는 LLM의 능력을 향상시키는 데 도움이 될 수 있다.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Memory Manager</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.p1.1"><a class="ltx_ref ltx_refmacro_autoref" href="#S4.F5" title="Figure 5 ‣ 4.2 Context Manager ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>에 표시된 것처럼 메모리 관리자는 에이전트의 수명 주기 내에서 단기 메모리를 관리하여 실행 대기 또는 런타임 동안 에이전트가 활성 상태인 동안에만 데이터가 저장되고 액세스할 수 있도록 합니다. 현재 AIOS는 각 에이전트의 메모리를 독립적으로 저장할 수 있도록 지원하며, 각 에이전트는 액세스 관리자에 의해 승인되지 않는 한 다른 에이전트에 직접 액세스할 수 없다. 에이전트 간의 공유 메모리 풀 또는 계층적 캐시와 같은 보다 복잡한 메모리 메커니즘이 고려되어 향후 AIOS에 통합될 수 있다. 다음에서 소개된 스토리지 매니저와 비교하여, 메모리 매니저는 신속한 데이터 검색 및 처리를 가능하게 하여, AIOS의 스토리지에 과도한 부담을 주지 않으면서 사용자 질의 및 상호 작용에 대한 신속한 응답을 용이하게 한다.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1:</span>Managed tools in AIOS. 마지막 열에는 각 도구의 필수 입력 및 출력 형식이 표시됩니다.</figcaption>
<div id="S4.T1.15" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:217.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-53.7pt,26.8pt) scale(0.8016,0.8016) ;">
<p id="S4.T1.15.15" class="ltx_p"><span id="S4.T1.15.15.15" class="ltx_text"> <span id="S4.T1.15.15.15.15" class="ltx_inline-block ltx_transformed_outer" style="width:540.9pt;height:271pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;"> <span id="S4.T1.15.15.15.15.15" class="ltx_p"><span id="S4.T1.15.15.15.15.15.15" class="ltx_text">  <span id="S4.T1.15.15.15.15.15.15.15" class="ltx_tabular ltx_align_middle"> <span class="ltx_tbody"> <span id="S4.T1.1.1.1.1.1.1.1.1" class="ltx_tr"> <span id="S4.T1.1.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T1.1.1.1.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Category</span></span> <span id="S4.T1.1.1.1.1.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T1.1.1.1.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Tool Name</span></span> <span id="S4.T1.1.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T1.1.1.1.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Description</span></span> <span id="S4.T1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S4.T1.1.1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Input <math id="S4.T1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math> Output</span></span></span> <span id="S4.T1.2.2.2.2.2.2.2.2" class="ltx_tr"> <span id="S4.T1.2.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_left ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S4.T1.2.2.2.2.2.2.2.2.2.1" class="ltx_text">Search</span></span> <span id="S4.T1.2.2.2.2.2.2.2.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.2.2.2.2.2.2.2.2.3.1" class="ltx_text ltx_font_typewriter">google_search</span></span> <span id="S4.T1.2.2.2.2.2.2.2.2.4" class="ltx_td ltx_align_left ltx_border_t">search information by Google API</span> <span id="S4.T1.2.2.2.2.2.2.2.2.1" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">Image/Text <math id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1b"><ci id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.2.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math> Image/Text</span></span> <span id="S4.T1.3.3.3.3.3.3.3.3" class="ltx_tr"> <span id="S4.T1.3.3.3.3.3.3.3.3.2" class="ltx_td ltx_align_left"><span id="S4.T1.3.3.3.3.3.3.3.3.2.1" class="ltx_text ltx_font_typewriter">bing_search</span></span> <span id="S4.T1.3.3.3.3.3.3.3.3.3" class="ltx_td ltx_align_left">search information by Bing API</span> <span id="S4.T1.3.3.3.3.3.3.3.3.1" class="ltx_td ltx_nopad_r ltx_align_center">Image/Text <math id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1b"><ci id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1.cmml" xref="S4.T1.3.3.3.3.3.3.3.3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.3.3.3.3.1.m1.1c">\rightarrow</annotation></semantics></math> Image/Text</span></span> <span id="S4.T1.4.4.4.4.4.4.4.4" class="ltx_tr"> <span id="S4.T1.4.4.4.4.4.4.4.4.2" class="ltx_td ltx_align_left ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S4.T1.4.4.4.4.4.4.4.4.2.1" class="ltx_text">Computation</span></span> <span id="S4.T1.4.4.4.4.4.4.4.4.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.4.4.4.4.4.4.4.4.3.1" class="ltx_text ltx_font_typewriter">currency_converter</span></span> <span id="S4.T1.4.4.4.4.4.4.4.4.4" class="ltx_td ltx_align_left ltx_border_t">currency converting</span> <span id="S4.T1.4.4.4.4.4.4.4.4.1" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">Text <math id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1b"><ci id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1.cmml" xref="S4.T1.4.4.4.4.4.4.4.4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.4.4.4.4.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.5.5.5.5.5.5.5.5" class="ltx_tr"> <span id="S4.T1.5.5.5.5.5.5.5.5.2" class="ltx_td ltx_align_left"><span id="S4.T1.5.5.5.5.5.5.5.5.2.1" class="ltx_text ltx_font_typewriter">wolframalpha</span></span> <span id="S4.T1.5.5.5.5.5.5.5.5.3" class="ltx_td ltx_align_left">mathematical computation</span> <span id="S4.T1.5.5.5.5.5.5.5.5.1" class="ltx_td ltx_nopad_r ltx_align_center">Image/Text <math id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1a"><mo stretchy="false" id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1b"><ci id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.5.5.5.5.5.5.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.5.5.5.5.5.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.6.6.6.6.6.6.6.6" class="ltx_tr"> <span id="S4.T1.6.6.6.6.6.6.6.6.2" class="ltx_td ltx_align_left ltx_border_t ltx_rowspan ltx_rowspan_5"><span id="S4.T1.6.6.6.6.6.6.6.6.2.1" class="ltx_text">Database Query</span></span> <span id="S4.T1.6.6.6.6.6.6.6.6.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.6.6.6.6.6.6.6.6.3.1" class="ltx_text ltx_font_typewriter">sql_query</span></span> <span id="S4.T1.6.6.6.6.6.6.6.6.4" class="ltx_td ltx_align_left ltx_border_t">query data from SQL database</span> <span id="S4.T1.6.6.6.6.6.6.6.6.1" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">Text <math id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1a"><mo stretchy="false" id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1b"><ci id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1.cmml" xref="S4.T1.6.6.6.6.6.6.6.6.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.6.6.6.6.6.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.7.7.7.7.7.7.7.7" class="ltx_tr"> <span id="S4.T1.7.7.7.7.7.7.7.7.2" class="ltx_td ltx_align_left"><span id="S4.T1.7.7.7.7.7.7.7.7.2.1" class="ltx_text ltx_font_typewriter">wikipedia_query</span></span> <span id="S4.T1.7.7.7.7.7.7.7.7.3" class="ltx_td ltx_align_left">query data from Wikipedia database</span> <span id="S4.T1.7.7.7.7.7.7.7.7.1" class="ltx_td ltx_nopad_r ltx_align_center">Text <math id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1a"><mo stretchy="false" id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1b"><ci id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1.cmml" xref="S4.T1.7.7.7.7.7.7.7.7.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.7.7.7.7.7.7.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.8.8.8.8.8.8.8.8" class="ltx_tr"> <span id="S4.T1.8.8.8.8.8.8.8.8.2" class="ltx_td ltx_align_left"><span id="S4.T1.8.8.8.8.8.8.8.8.2.1" class="ltx_text ltx_font_typewriter">arxiv_search</span></span> <span id="S4.T1.8.8.8.8.8.8.8.8.3" class="ltx_td ltx_align_left">query articles from Arxiv</span> <span id="S4.T1.8.8.8.8.8.8.8.8.1" class="ltx_td ltx_nopad_r ltx_align_center">Text <math id="S4.T1.8.8.8.8.8.8.8.8.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.8.8.8.8.8.8.8.8.1.m1.1a"><mo stretchy="false" id="S4.T1.8.8.8.8.8.8.8.8.1.m1.1.1" xref="S4.T1.8.8.8.8.8.8.8.8.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.8.8.8.8.8.8.1.m1.1b"><ci id="S4.T1.8.8.8.8.8.8.8.8.1.m1.1.1.cmml" xref="S4.T1.8.8.8.8.8.8.8.8.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.8.8.8.8.8.8.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.9.9.9.9.9.9.9.9" class="ltx_tr"> <span id="S4.T1.9.9.9.9.9.9.9.9.2" class="ltx_td ltx_align_left"><span id="S4.T1.9.9.9.9.9.9.9.9.2.1" class="ltx_text ltx_font_typewriter">words_api</span></span> <span id="S4.T1.9.9.9.9.9.9.9.9.3" class="ltx_td ltx_align_left">query definitions and synonyms of English words</span> <span id="S4.T1.9.9.9.9.9.9.9.9.1" class="ltx_td ltx_nopad_r ltx_align_center">Text <math id="S4.T1.9.9.9.9.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.9.9.9.9.9.9.9.9.1.m1.1a"><mo stretchy="false" id="S4.T1.9.9.9.9.9.9.9.9.1.m1.1.1" xref="S4.T1.9.9.9.9.9.9.9.9.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.9.9.9.9.9.9.1.m1.1b"><ci id="S4.T1.9.9.9.9.9.9.9.9.1.m1.1.1.cmml" xref="S4.T1.9.9.9.9.9.9.9.9.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.9.9.9.9.9.9.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.10.10.10.10.10.10.10.10" class="ltx_tr"> <span id="S4.T1.10.10.10.10.10.10.10.10.2" class="ltx_td ltx_align_left"><span id="S4.T1.10.10.10.10.10.10.10.10.2.1" class="ltx_text ltx_font_typewriter">urban_dictionary</span></span> <span id="S4.T1.10.10.10.10.10.10.10.10.3" class="ltx_td ltx_align_left">query random words, the current word of the day</span> <span id="S4.T1.10.10.10.10.10.10.10.10.1" class="ltx_td ltx_nopad_r ltx_align_center">Text <math id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1a"><mo stretchy="false" id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1.1" xref="S4.T1.10.10.10.10.10.10.10.10.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1b"><ci id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1.1.cmml" xref="S4.T1.10.10.10.10.10.10.10.10.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.11.11.11.11.11.11.11.11" class="ltx_tr"> <span id="S4.T1.11.11.11.11.11.11.11.11.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t ltx_rowspan ltx_rowspan_5"><span id="S4.T1.11.11.11.11.11.11.11.11.2.1" class="ltx_text">Image Processing</span></span> <span id="S4.T1.11.11.11.11.11.11.11.11.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.11.11.11.11.11.11.11.11.3.1" class="ltx_text ltx_font_typewriter">image_denoising</span></span> <span id="S4.T1.11.11.11.11.11.11.11.11.4" class="ltx_td ltx_align_left ltx_border_t">denoise images with noise</span> <span id="S4.T1.11.11.11.11.11.11.11.11.1" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">Image <math id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1a"><mo stretchy="false" id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1.1" xref="S4.T1.11.11.11.11.11.11.11.11.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1b"><ci id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1.1.cmml" xref="S4.T1.11.11.11.11.11.11.11.11.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.12.12.12.12.12.12.12.12" class="ltx_tr"> <span id="S4.T1.12.12.12.12.12.12.12.12.2" class="ltx_td ltx_align_left"><span id="S4.T1.12.12.12.12.12.12.12.12.2.1" class="ltx_text ltx_font_typewriter">image_deblurring</span></span> <span id="S4.T1.12.12.12.12.12.12.12.12.3" class="ltx_td ltx_align_left">deblur images</span> <span id="S4.T1.12.12.12.12.12.12.12.12.1" class="ltx_td ltx_nopad_r ltx_align_center">Image <math id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1a"><mo stretchy="false" id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1.1" xref="S4.T1.12.12.12.12.12.12.12.12.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1b"><ci id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1.1.cmml" xref="S4.T1.12.12.12.12.12.12.12.12.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.13.13.13.13.13.13.13.13" class="ltx_tr"> <span id="S4.T1.13.13.13.13.13.13.13.13.2" class="ltx_td ltx_align_left"><span id="S4.T1.13.13.13.13.13.13.13.13.2.1" class="ltx_text ltx_font_typewriter">image_classification</span></span> <span id="S4.T1.13.13.13.13.13.13.13.13.3" class="ltx_td ltx_align_left">classify images</span> <span id="S4.T1.13.13.13.13.13.13.13.13.1" class="ltx_td ltx_nopad_r ltx_align_center">Image <math id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1a"><mo stretchy="false" id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1.1" xref="S4.T1.13.13.13.13.13.13.13.13.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1b"><ci id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1.1.cmml" xref="S4.T1.13.13.13.13.13.13.13.13.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.14.14.14.14.14.14.14.14" class="ltx_tr"> <span id="S4.T1.14.14.14.14.14.14.14.14.2" class="ltx_td ltx_align_left"><span id="S4.T1.14.14.14.14.14.14.14.14.2.1" class="ltx_text ltx_font_typewriter">object_detection</span></span> <span id="S4.T1.14.14.14.14.14.14.14.14.3" class="ltx_td ltx_align_left">detect objects in images</span> <span id="S4.T1.14.14.14.14.14.14.14.14.1" class="ltx_td ltx_nopad_r ltx_align_center">Image <math id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1a"><mo stretchy="false" id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1.1" xref="S4.T1.14.14.14.14.14.14.14.14.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1b"><ci id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1.1.cmml" xref="S4.T1.14.14.14.14.14.14.14.14.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> <span id="S4.T1.15.15.15.15.15.15.15.15" class="ltx_tr"> <span id="S4.T1.15.15.15.15.15.15.15.15.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T1.15.15.15.15.15.15.15.15.2.1" class="ltx_text ltx_font_typewriter">face_rect</span></span> <span id="S4.T1.15.15.15.15.15.15.15.15.3" class="ltx_td ltx_align_left ltx_border_bb">detect faces in images by FaceRect API</span> <span id="S4.T1.15.15.15.15.15.15.15.15.1" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">Image <math id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1a"><mo stretchy="false" id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1.1" xref="S4.T1.15.15.15.15.15.15.15.15.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1b"><ci id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1.1.cmml" xref="S4.T1.15.15.15.15.15.15.15.15.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1c">\rightarrow</annotation></semantics></math> Text</span></span> </span> </span></span></span> </span></span></span></p>
</span></div>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Storage Manager</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS4.p1.1">반대로, 스토리지 관리자는 단일 에이전트의 활성 수명을 넘어 무기한으로 유지되어야 하는 정보의 저장을 감독하면서 데이터의 장기 보존을 책임진다. AIOS의 이러한 영구 저장소는 로컬 파일, 데이터베이스 또는 클라우드 기반 솔루션과 같은 다양한 내구성 있는 매체를 통해 달성되어 향후 참조 또는 분석을 위한 데이터 무결성 및 가용성을 보장합니다. 스토리지 관리자는 검색 증강 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib61" title="">61</a>]</cite>를 지원한다. 사용자 선호도들을 저장하고 이력 상호작용 로그들을 유지함으로써, 스토리지 관리자는 에이전트 지식 업데이트를 풍부하게 하고 장기 사용자 경험을 강화할 수 있다.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Tool Manager</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS5.p1.1">AIOS 시스템의 도구 관리자는 LLM의 기능을 향상시키는 다양한 API 도구를 관리한다. 도구 관리자는 <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T1" title="Table 1 ‣ 4.3 Memory Manager ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Table 1</span></a>에 도시된 바와 같이, 다양한 소스에서 흔히 사용되는 도구인 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>, <a class="ltx_ref" href="#bib.bib62" title="">62</a>, <a class="ltx_ref" href="#bib.bib63" title="">63</a>]</cite>를 통합하여 웹 검색, 과학 컴퓨팅, 데이터베이스 검색, 이미지 처리 등을 포함하는 다양한 카테고리로 분류한다. 이러한 방식으로, 관리되는 도구들은 입력 및 출력(이미지 및 텍스트)의 상이한 양식들을 커버할 수 있고, 따라서 AIOS 생태계 내에서 에이전트 개발을 용이하게 한다.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 2:</span>LLM 시스템 호출의 인스턴스.</figcaption>
<div id="S4.T2.1" class="ltx_inline-block ltx_transformed_outer" style="width:390.3pt;height:345.8pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-39.0pt,34.5pt) scale(0.83338,0.83338) ;">
<p class="ltx_p" id="S4.T2.1.1"><span class="ltx_text" id="S4.T2.1.1.1.1.1.1.1.1.1"><span class="ltx_inline-block ltx_transformed_outer" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;"><span class="ltx_p" id="S4.T2.1.1.1.1.1.1.1"><span class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1.1.1.1.1.1.1.1.1.1.1.1.1"><span class="ltx_tbular ltx_align_left ltx_border_tt" id="S4.T2.1.</p>
</span></div>
</figure>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Access Manager</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS6.p1.1">액세스 관리자는 각 에이전트에 대한 전용 권한 그룹을 관리하여 별개의 에이전트 간의 액세스 제어 작업을 오케스트레이션합니다. 에이전트의 권한 그룹에서 제외된 다른 에이전트는 상호 작용 기록과 같은 리소스에 대한 액세스가 거부됩니다. 시스템 투명성을 더욱 강화하기 위해 액세스 관리자는 감사 로그를 컴파일하고 유지합니다. 이러한 로그는 액세스 요청, 에이전트 활동 및 액세스 제어 매개 변수에 대 한 모든 수정에 대 한 자세한 정보를 캡처 하며, 이는 잠재적인 권한 공격 [cite idx=0></cite>]으로부터 보호 하는 데 도움이 됩니다.</p>
</div>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>LLM System Call</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS7.p1.1">LLM 커널 내의 LLM 시스템 호출 인터페이스는 기본 LLM 호출 연산 기능을 제공하도록 설계되었다. 이 인터페이스는 복잡한 에이전트 요청과 다른 커널 모듈의 실행 사이의 브리지 역할을 합니다. OS 시스템 호출과 유사한 <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T2" title="Table 2 ‣ 4.5 Tool Manager ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Table 2</span></a>에 표시된 것처럼 LLM 시스템 호출은 에이전트 관리, 컨텍스트 처리, 메모리 및 스토리지 작업, 액세스 제어 등 커널의 모듈에 걸쳐 있는 기본 함수 집합을 제공합니다. LLM 시스템 호출 목록은 향후 더 많은 운영을 지원하기 위해 더 확장될 수 있다.</p>
</div>
</section>
<section id="S4.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.8 </span>AIOS SDK</h3>

<div id="S4.SS8.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS8.p1.1">AIOS SDK는 개발자에게 AIOS 내에서 정교한 에이전트 애플리케이션을 만들기 위한 다목적 툴킷을 제공하도록 설계되었습니다. 이 SDK는 에이전트 초기화 및 에이전트 수명 주기 관리에서 리소스 모니터링 및 에이전트 작업에 대한 생성 계획과 같은 복잡한 작업을 용이하게 하는 광범위한 기능을 포함합니다. 모든 운영 체제와 마찬가지로 SDK를 포괄적이고 개발자 친화적으로 강화하는 것은 장기적이고 끝없는 노력입니다. AIOS에서 지원되는 현재 SDK 기능은 <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T3" title="Table 3 ‣ 4.8 AIOS SDK ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Table 3</span></a>와 같으며, 이는 진화하는 에이전트 애플리케이션의 요구를 충족하기 위해 지속적으로 업데이트되고 확장될 것이다. 이러한 개발 노력은 AIOS 프레임워크 내에서 에이전트 애플리케이션의 잠재력을 최대한 활용하는 데 필요한 도구를 개발자에게 제공하는 것을 목표로 한다.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 3:</span>AIOS SDK에서 SDK 함수 목록</figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:242.9pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-41.1pt,22.9pt) scale(0.84071,0.84071) ;">
<p class="ltx_p" id="S4.T3.1.1"><span class="ltx_text" id="S4.T3.1.1.1.1.1.1.1.1.1"><span class="ltx_inline-block ltx_transformed_outer" id="S4.T3.1.1.1.1.1" style="width:515.8pt;height:289pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;"><span class="ltx_p" id="S4.T3.1.1.1.1.1.1.1.1.1"><span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><span class</p>
</span></div>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Evaluation</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p" id="S5.p1.1">이 섹션에서는 AIOS에서 여러 에이전트가 병렬로 실행될 때 AIOS 모듈의 정확성과 성능을 모두 평가한다. 이 연구는 두 가지 연구 질문에 의해 유도된다: 첫째, 에이전트 요청에 대한 LLM 응답이 에이전트 중단 및 다른 에이전트로의 전환 후 일관성이 있는지 여부, 둘째, AIOS 스케줄링이 비스케줄(순차적) 실행에 비해 대기 및 처리 시간의 균형을 개선하는 데 있어 성능이 어떻게 되는지 여부.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Setup</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.p1.1">우리의 실험은 8개의 NVIDIA RTX A5000 GPU가 장착된 우분투 22.04 기계에서 PyTorch 2.0.1 및 CUDA 11.8과 함께 파이썬 3.9에서 수행된다. AIOS의 백본으로 공개된 LLMs(즉, Gemma-2b-it 및 Gemma-7b-it <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>, LLaMA-2-13b-chat-hf <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>)를 사용한다. 이 선택은 오픈 소스 모델의 로컬 배치의 장점으로 구동되며, 이는 시간 지연의 정확한 측정에 도움이 된다. 평가를 위해 수학 과제를 해결하기 위한 수학 에이전트, 새로운 내러티브를 생성하기 위한 내러티브 에이전트, 레스토랑 추천을 제공하기 위한 Rec 에이전트의 세 가지 전문 에이전트를 구성했다. 각 에이전트는 실행 중에 백본 LLM에 2~3개의 요청을 보내도록 설계되었습니다.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experimental Results</h3>

<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 4:</span> 단일 에이전트를 하나씩 실행할 때 LLM 생성 응답과 비교하여 여러 에이전트를 병렬로 실행할 때 LLM 생성 응답의 일관성.</figcaption>
<div id="S5.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:74.9pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-46.5pt,7.9pt) scale(0.82341,0.82341) ;">
<p id="S5.T4.1.1" class="ltx_p"><span id="S5.T4.1.1.1" class="ltx_text"> <span id="S5.T4.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:526.6pt;height:91pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;"> <span id="S5.T4.1.1.1.1.1" class="ltx_p"><span id="S5.T4.1.1.1.1.1.1" class="ltx_text">  <span id="S5.T4.1.1.1.1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle"> <span class="ltx_thead"> <span id="S5.T4.1.1.1.1.1.1.1.1.1" class="ltx_tr"> <span id="S5.T4.1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt ltx_rowspan ltx_rowspan_2"><span id="S5.T4.1.1.1.1.1.1.1.1.1.1.1" class="ltx_text">LLM-backbone</span></span> <span id="S5.T4.1.1.1.1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_2">Math Agent</span> <span id="S5.T4.1.1.1.1.1.1.1.1.1.3" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></span> <span id="S5.T4.1.1.1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_2">Narrative Agent</span> <span id="S5.T4.1.1.1.1.1.1.1.1.1.5" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></span> <span id="S5.T4.1.1.1.1.1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_2">Rec Agent</span></span> <span id="S5.T4.1.1.1.1.1.1.1.2.2" class="ltx_tr"> <span id="S5.T4.1.1.1.1.1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">BLEU Score</span> <span id="S5.T4.1.1.1.1.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">BERT Score</span> <span id="S5.T4.1.1.1.1.1.1.1.2.2.3" class="ltx_td ltx_th ltx_th_column"></span> <span id="S5.T4.1.1.1.1.1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">BLEU Score</span> <span id="S5.T4.1.1.1.1.1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">BERT Score</span> <span id="S5.T4.1.1.1.1.1.1.1.2.2.6" class="ltx_td ltx_th ltx_th_column"></span> <span id="S5.T4.1.1.1.1.1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">BLEU Score</span> <span id="S5.T4.1.1.1.1.1.1.1.2.2.8" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t">BERT Score</span></span> </span> <span class="ltx_tbody"> <span id="S5.T4.1.1.1.1.1.1.1.3.1" class="ltx_tr"> <span id="S5.T4.1.1.1.1.1.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Gemma-2b-it</span> <span id="S5.T4.1.1.1.1.1.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.3.1.4" class="ltx_td ltx_border_t"></span> <span id="S5.T4.1.1.1.1.1.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.3.1.7" class="ltx_td ltx_border_t"></span> <span id="S5.T4.1.1.1.1.1.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.3.1.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">1.0</span></span> <span id="S5.T4.1.1.1.1.1.1.1.4.2" class="ltx_tr"> <span id="S5.T4.1.1.1.1.1.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Gemma-7b-it</span> <span id="S5.T4.1.1.1.1.1.1.1.4.2.2" class="ltx_td ltx_align_center">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.4.2.3" class="ltx_td ltx_align_center">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.4.2.4" class="ltx_td"></span> <span id="S5.T4.1.1.1.1.1.1.1.4.2.5" class="ltx_td ltx_align_center">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.4.2.6" class="ltx_td ltx_align_center">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.4.2.7" class="ltx_td"></span> <span id="S5.T4.1.1.1.1.1.1.1.4.2.8" class="ltx_td ltx_align_center">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.4.2.9" class="ltx_td ltx_nopad_r ltx_align_center">1.0</span></span> <span id="S5.T4.1.1.1.1.1.1.1.5.3" class="ltx_tr"> <span id="S5.T4.1.1.1.1.1.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">LLaMA-2-13b-chat-hf</span> <span id="S5.T4.1.1.1.1.1.1.1.5.3.2" class="ltx_td ltx_align_center ltx_border_bb">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.5.3.3" class="ltx_td ltx_align_center ltx_border_bb">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.5.3.4" class="ltx_td ltx_border_bb"></span> <span id="S5.T4.1.1.1.1.1.1.1.5.3.5" class="ltx_td ltx_align_center ltx_border_bb">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.5.3.6" class="ltx_td ltx_align_center ltx_border_bb">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.5.3.7" class="ltx_td ltx_border_bb"></span> <span id="S5.T4.1.1.1.1.1.1.1.5.3.8" class="ltx_td ltx_align_center ltx_border_bb">1.0</span> <span id="S5.T4.1.1.1.1.1.1.1.5.3.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">1.0</span></span> </span> </span></span></span> </span></span></span></p>
</span></div>
</figure>
<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Consistency Analysis.</h4>

<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">일관성 질문에 답하기 위해 먼저 구성된 3개의 에이전트 각각을 개별적으로 실행하여 결과를 생성한다. 그런 다음 이러한 에이전트를 병렬로 실행하여 각 단계에서 출력을 캡처한다. 여러 에이전트가 병렬로 실행되고 단일 에이전트가 하나씩 실행되었을 때 출력의 일관성을 평가하기 위해 평가 메트릭으로 BLEU 점수 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>와 BERT 점수 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite>를 사용한다. 두 메트릭 모두 0.0에서 1.0까지 확장되며 단일 에이전트 컨텍스트에서 생성된 출력이 참조 표준 역할을 하며 무작위성의 영향을 제거하기 위해 온도 매개변수를 0으로 설정한다. 표 <a class="ltx_ref" href="#S5.T4" title="Table 4 ‣ 5.2 Experimental Results ‣ 5 Evaluation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">4</span></a>에서 알 수 있듯이 BLEU 및 BERT 점수는 모두 1.0의 값을 달성하며, 이는 다중 에이전트 구성과 단일 에이전트 구성에서 생성된 출력 간의 완벽한 정렬을 나타낸다. 이 결과는 동시 다중 에이전트 작업을 효과적으로 지원하는 데 있어 설계의 일관성을 확인한다.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Performance Analysis. </h4>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1">효율성 질문에 답하기 위해, 우리는 FIFO 스케줄링을 사용하는 AIOS와 앞서 언급한 세 에이전트가 동시에 실행되는 비스케줄드 접근법 간의 비교 분석을 수행한다. 예약되지 않은 설정에서 세 개의 에이전트는 미리 정의된 순차적 순서인 수학 에이전트, 내러티브 에이전트 및 Rec 에이전트에 따라 실행됩니다. 시간 효율성을 평가하기 위해 대기 시간(에이전트 요청 제출에서 시작까지의 간격)과 처리 시간(에이전트 요청 제출에서 완료까지의 기간)의 두 가지 메트릭을 사용한다. 각 에이전트가 LLM에 여러 요청을 보내기 때문에 각 에이전트의 대기 시간과 처리 시간은 전송된 모든 요청의 대기 시간과 처리 시간의 평균으로 각각 계산된다. 무작위성을 완화하기 위해 우리는 결과를 보고하기 위해 5개의 개별 시도에서 스케줄이 있거나 없는 이 세 가지 에이전트를 실행합니다. <a class="ltx_ref ltx_refmacro_autoref" href="#S5.T5" title="Table 5 ‣ Performance Analysis. ‣ 5.2 Experimental Results ‣ 5 Evaluation ‣ AIOS: LLM Agent Operating System"><span class="ltx_text ltx_ref_tag">Table 5</span></a>에 도시된 바와 같이, 스케쥴링되지 않은 접근법은 시퀀스 초기에 에이전트들에 대해 양호한 성능을 나타내지만, 시퀀스 후에 에이전트들에 대해 연장된 대기 시간 및 턴어라운드 시간을 희생시킨다. 반대로, AIOS의 스케줄링 메커니즘은 대기 시간과 턴어라운드 시간 모두를 효율적으로 규제하는데, 이는 특히 LLM이 클 때 에이전트에 의해 나중에 제출되는 에이전트 요청에 대해 특히 명백해지는 이점이다. 이는 여러 에이전트의 병렬 작업을 수용하기 위한 스케줄링의 중요성을 시사한다.</p>
</div>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 5:</span>Effectiveness of agent scheduling, compared with non-scheduled (sequential) execution.</figcaption>
<div id="S5.T5.36" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:151.9pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-67.4pt,23.5pt) scale(0.76289,0.76289) ;">
<p id="S5.T5.36.36" class="ltx_p"><span id="S5.T5.36.36.36" class="ltx_text"> <span id="S5.T5.36.36.36.36" class="ltx_inline-block ltx_transformed_outer" style="width:568.4pt;height:199pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;"> <span id="S5.T5.36.36.36.36.36" class="ltx_p"><span id="S5.T5.36.36.36.36.36.36" class="ltx_text">  <span id="S5.T5.36.36.36.36.36.36.36" class="ltx_tabular ltx_guessed_headers ltx_align_middle"> <span class="ltx_thead"> <span id="S5.T5.36.36.36.36.36.36.36.37.1" class="ltx_tr"> <span id="S5.T5.36.36.36.36.36.36.36.37.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt ltx_rowspan ltx_rowspan_2"><span id="S5.T5.36.36.36.36.36.36.36.37.1.1.1" class="ltx_text">LLM backbone</span></span> <span id="S5.T5.36.36.36.36.36.36.36.37.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt ltx_rowspan ltx_rowspan_2"><span id="S5.T5.36.36.36.36.36.36.36.37.1.2.1" class="ltx_text">Agent</span></span> <span id="S5.T5.36.36.36.36.36.36.36.37.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_2">Sequential execution (non-scheduled)</span> <span id="S5.T5.36.36.36.36.36.36.36.37.1.4" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></span> <span id="S5.T5.36.36.36.36.36.36.36.37.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T5.36.36.36.36.36.36.36.37.1.5.1" class="ltx_text ltx_font_bold">Concurrent execution (scheduled)</span></span></span> <span id="S5.T5.36.36.36.36.36.36.36.38.2" class="ltx_tr"> <span id="S5.T5.36.36.36.36.36.36.36.38.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Waiting time (s)</span> <span id="S5.T5.36.36.36.36.36.36.36.38.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Turnaround time (s)</span> <span id="S5.T5.36.36.36.36.36.36.36.38.2.3" class="ltx_td ltx_th ltx_th_column"></span> <span id="S5.T5.36.36.36.36.36.36.36.38.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Waiting time (s)</span> <span id="S5.T5.36.36.36.36.36.36.36.38.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t">Turnaround time (s)</span></span> </span> <span class="ltx_tbody"> <span id="S5.T5.4.4.4.4.4.4.4.4" class="ltx_tr"> <span id="S5.T5.4.4.4.4.4.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t ltx_rowspan ltx_rowspan_3"><span id="S5.T5.4.4.4.4.4.4.4.4.5.1" class="ltx_text">Gemma-2b-it</span></span> <span id="S5.T5.4.4.4.4.4.4.4.4.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Math Agent</span> <span id="S5.T5.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">0.002<math id="S5.T5.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="S5.T5.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.T5.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.1.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T5.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.1.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.1.1.1.1.1.1.1.1.1.m1.1c">\pm</annotation></semantics></math>0.001</span> <span id="S5.T5.2.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">2.71<math id="S5.T5.2.2.2.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.2.2.2.2.2.2.2.2.2.m1.1a"><mo id="S5.T5.2.2.2.2.2.2.2.2.2.m1.1.1" xref="S5.T5.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.2.2.2.2.2.2.2.2.2.m1.1b"><csymbol cd="latexml" id="S5.T5.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S5.T5.2.2.2.2.2.2.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.2.2.2.2.2.2.2.2.m1.1c">\pm</annotation></semantics></math>0.53</span> <span id="S5.T5.4.4.4.4.4.4.4.4.7" class="ltx_td ltx_border_t"></span> <span id="S5.T5.3.3.3.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">2.50<math id="S5.T5.3.3.3.3.3.3.3.3.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.3.3.3.3.3.3.3.3.3.m1.1a"><mo id="S5.T5.3.3.3.3.3.3.3.3.3.m1.1.1" xref="S5.T5.3.3.3.3.3.3.3.3.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.3.3.3.3.3.3.3.3.3.m1.1b"><csymbol cd="latexml" id="S5.T5.3.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S5.T5.3.3.3.3.3.3.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.3.3.3.3.3.3.3.3.m1.1c">\pm</annotation></semantics></math>0.05</span> <span id="S5.T5.4.4.4.4.4.4.4.4.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">4.18<math id="S5.T5.4.4.4.4.4.4.4.4.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.4.4.4.4.4.4.4.4.4.m1.1a"><mo id="S5.T5.4.4.4.4.4.4.4.4.4.m1.1.1" xref="S5.T5.4.4.4.4.4.4.4.4.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.4.4.4.4.4.4.4.4.4.m1.1b"><csymbol cd="latexml" id="S5.T5.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S5.T5.4.4.4.4.4.4.4.4.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.4.4.4.4.4.4.4.4.m1.1c">\pm</annotation></semantics></math>0.18</span></span> <span id="S5.T5.8.8.8.8.8.8.8.8" class="ltx_tr"> <span id="S5.T5.8.8.8.8.8.8.8.8.5" class="ltx_td ltx_align_left ltx_th ltx_th_row">Narrative Agent</span> <span id="S5.T5.5.5.5.5.5.5.5.5.1" class="ltx_td ltx_align_center">2.18<math id="S5.T5.5.5.5.5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.5.5.5.5.5.5.5.5.1.m1.1a"><mo id="S5.T5.5.5.5.5.5.5.5.5.1.m1.1.1" xref="S5.T5.5.5.5.5.5.5.5.5.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.5.5.5.5.5.5.5.5.1.m1.1b"><csymbol cd="latexml" id="S5.T5.5.5.5.5.5.5.5.5.1.m1.1.1.cmml" xref="S5.T5.5.5.5.5.5.5.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.5.5.5.5.5.5.5.5.1.m1.1c">\pm</annotation></semantics></math>0.53</span> <span id="S5.T5.6.6.6.6.6.6.6.6.2" class="ltx_td ltx_align_center">3.18<math id="S5.T5.6.6.6.6.6.6.6.6.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.6.6.6.6.6.6.6.6.2.m1.1a"><mo id="S5.T5.6.6.6.6.6.6.6.6.2.m1.1.1" xref="S5.T5.6.6.6.6.6.6.6.6.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.6.6.6.6.6.6.6.6.2.m1.1b"><csymbol cd="latexml" id="S5.T5.6.6.6.6.6.6.6.6.2.m1.1.1.cmml" xref="S5.T5.6.6.6.6.6.6.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.6.6.6.6.6.6.6.6.2.m1.1c">\pm</annotation></semantics></math>0.64</span> <span id="S5.T5.8.8.8.8.8.8.8.8.6" class="ltx_td"></span> <span id="S5.T5.7.7.7.7.7.7.7.7.3" class="ltx_td ltx_align_center">3.34<math id="S5.T5.7.7.7.7.7.7.7.7.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.7.7.7.7.7.7.7.7.3.m1.1a"><mo id="S5.T5.7.7.7.7.7.7.7.7.3.m1.1.1" xref="S5.T5.7.7.7.7.7.7.7.7.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.7.7.7.7.7.7.7.7.3.m1.1b"><csymbol cd="latexml" id="S5.T5.7.7.7.7.7.7.7.7.3.m1.1.1.cmml" xref="S5.T5.7.7.7.7.7.7.7.7.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.7.7.7.7.7.7.7.7.3.m1.1c">\pm</annotation></semantics></math>0.17</span> <span id="S5.T5.8.8.8.8.8.8.8.8.4" class="ltx_td ltx_nopad_r ltx_align_center">4.18<math id="S5.T5.8.8.8.8.8.8.8.8.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.8.8.8.8.8.8.8.8.4.m1.1a"><mo id="S5.T5.8.8.8.8.8.8.8.8.4.m1.1.1" xref="S5.T5.8.8.8.8.8.8.8.8.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.8.8.8.8.8.8.8.8.4.m1.1b"><csymbol cd="latexml" id="S5.T5.8.8.8.8.8.8.8.8.4.m1.1.1.cmml" xref="S5.T5.8.8.8.8.8.8.8.8.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.8.8.8.8.8.8.8.8.4.m1.1c">\pm</annotation></semantics></math>0.18</span></span> <span id="S5.T5.12.12.12.12.12.12.12.12" class="ltx_tr"> <span id="S5.T5.12.12.12.12.12.12.12.12.5" class="ltx_td ltx_align_left ltx_th ltx_th_row">Rec Agent</span> <span id="S5.T5.9.9.9.9.9.9.9.9.1" class="ltx_td ltx_align_center">4.78<math id="S5.T5.9.9.9.9.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.9.9.9.9.9.9.9.9.1.m1.1a"><mo id="S5.T5.9.9.9.9.9.9.9.9.1.m1.1.1" xref="S5.T5.9.9.9.9.9.9.9.9.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.9.9.9.9.9.9.9.9.1.m1.1b"><csymbol cd="latexml" id="S5.T5.9.9.9.9.9.9.9.9.1.m1.1.1.cmml" xref="S5.T5.9.9.9.9.9.9.9.9.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.9.9.9.9.9.9.9.9.1.m1.1c">\pm</annotation></semantics></math>0.96</span> <span id="S5.T5.10.10.10.10.10.10.10.10.2" class="ltx_td ltx_align_center">7.68<math id="S5.T5.10.10.10.10.10.10.10.10.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.10.10.10.10.10.10.10.10.2.m1.1a"><mo id="S5.T5.10.10.10.10.10.10.10.10.2.m1.1.1" xref="S5.T5.10.10.10.10.10.10.10.10.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.10.10.10.10.10.10.10.10.2.m1.1b"><csymbol cd="latexml" id="S5.T5.10.10.10.10.10.10.10.10.2.m1.1.1.cmml" xref="S5.T5.10.10.10.10.10.10.10.10.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.10.10.10.10.10.10.10.10.2.m1.1c">\pm</annotation></semantics></math>1.27</span> <span id="S5.T5.12.12.12.12.12.12.12.12.6" class="ltx_td"></span> <span id="S5.T5.11.11.11.11.11.11.11.11.3" class="ltx_td ltx_align_center">3.46<math id="S5.T5.11.11.11.11.11.11.11.11.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.11.11.11.11.11.11.11.11.3.m1.1a"><mo id="S5.T5.11.11.11.11.11.11.11.11.3.m1.1.1" xref="S5.T5.11.11.11.11.11.11.11.11.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.11.11.11.11.11.11.11.11.3.m1.1b"><csymbol cd="latexml" id="S5.T5.11.11.11.11.11.11.11.11.3.m1.1.1.cmml" xref="S5.T5.11.11.11.11.11.11.11.11.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.11.11.11.11.11.11.11.11.3.m1.1c">\pm</annotation></semantics></math>0.20</span> <span id="S5.T5.12.12.12.12.12.12.12.12.4" class="ltx_td ltx_nopad_r ltx_align_center">5.91<math id="S5.T5.12.12.12.12.12.12.12.12.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.12.12.12.12.12.12.12.12.4.m1.1a"><mo id="S5.T5.12.12.12.12.12.12.12.12.4.m1.1.1" xref="S5.T5.12.12.12.12.12.12.12.12.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.12.12.12.12.12.12.12.12.4.m1.1b"><csymbol cd="latexml" id="S5.T5.12.12.12.12.12.12.12.12.4.m1.1.1.cmml" xref="S5.T5.12.12.12.12.12.12.12.12.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.12.12.12.12.12.12.12.12.4.m1.1c">\pm</annotation></semantics></math>0.19</span></span> <span id="S5.T5.16.16.16.16.16.16.16.16" class="ltx_tr"> <span id="S5.T5.16.16.16.16.16.16.16.16.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t ltx_rowspan ltx_rowspan_3"><span id="S5.T5.16.16.16.16.16.16.16.16.5.1" class="ltx_text">Gemma-7b-it</span></span> <span id="S5.T5.16.16.16.16.16.16.16.16.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Math Agent</span> <span id="S5.T5.13.13.13.13.13.13.13.13.1" class="ltx_td ltx_align_center ltx_border_t">0.002<math id="S5.T5.13.13.13.13.13.13.13.13.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.13.13.13.13.13.13.13.13.1.m1.1a"><mo id="S5.T5.13.13.13.13.13.13.13.13.1.m1.1.1" xref="S5.T5.13.13.13.13.13.13.13.13.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.13.13.13.13.13.13.13.13.1.m1.1b"><csymbol cd="latexml" id="S5.T5.13.13.13.13.13.13.13.13.1.m1.1.1.cmml" xref="S5.T5.13.13.13.13.13.13.13.13.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.13.13.13.13.13.13.13.13.1.m1.1c">\pm</annotation></semantics></math>0.001</span> <span id="S5.T5.14.14.14.14.14.14.14.14.2" class="ltx_td ltx_align_center ltx_border_t">4.95<math id="S5.T5.14.14.14.14.14.14.14.14.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.14.14.14.14.14.14.14.14.2.m1.1a"><mo id="S5.T5.14.14.14.14.14.14.14.14.2.m1.1.1" xref="S5.T5.14.14.14.14.14.14.14.14.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.14.14.14.14.14.14.14.14.2.m1.1b"><csymbol cd="latexml" id="S5.T5.14.14.14.14.14.14.14.14.2.m1.1.1.cmml" xref="S5.T5.14.14.14.14.14.14.14.14.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.14.14.14.14.14.14.14.14.2.m1.1c">\pm</annotation></semantics></math>0.10</span> <span id="S5.T5.16.16.16.16.16.16.16.16.7" class="ltx_td ltx_border_t"></span> <span id="S5.T5.15.15.15.15.15.15.15.15.3" class="ltx_td ltx_align_center ltx_border_t">5.92<math id="S5.T5.15.15.15.15.15.15.15.15.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.15.15.15.15.15.15.15.15.3.m1.1a"><mo id="S5.T5.15.15.15.15.15.15.15.15.3.m1.1.1" xref="S5.T5.15.15.15.15.15.15.15.15.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.15.15.15.15.15.15.15.15.3.m1.1b"><csymbol cd="latexml" id="S5.T5.15.15.15.15.15.15.15.15.3.m1.1.1.cmml" xref="S5.T5.15.15.15.15.15.15.15.15.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.15.15.15.15.15.15.15.15.3.m1.1c">\pm</annotation></semantics></math>0.01</span> <span id="S5.T5.16.16.16.16.16.16.16.16.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">10.75<math id="S5.T5.16.16.16.16.16.16.16.16.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.16.16.16.16.16.16.16.16.4.m1.1a"><mo id="S5.T5.16.16.16.16.16.16.16.16.4.m1.1.1" xref="S5.T5.16.16.16.16.16.16.16.16.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.16.16.16.16.16.16.16.16.4.m1.1b"><csymbol cd="latexml" id="S5.T5.16.16.16.16.16.16.16.16.4.m1.1.1.cmml" xref="S5.T5.16.16.16.16.16.16.16.16.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.16.16.16.16.16.16.16.16.4.m1.1c">\pm</annotation></semantics></math>0.19</span></span> <span id="S5.T5.20.20.20.20.20.20.20.20" class="ltx_tr"> <span id="S5.T5.20.20.20.20.20.20.20.20.5" class="ltx_td ltx_align_left ltx_th ltx_th_row">Narrative Agent</span> <span id="S5.T5.17.17.17.17.17.17.17.17.1" class="ltx_td ltx_align_center">4.96<math id="S5.T5.17.17.17.17.17.17.17.17.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.17.17.17.17.17.17.17.17.1.m1.1a"><mo id="S5.T5.17.17.17.17.17.17.17.17.1.m1.1.1" xref="S5.T5.17.17.17.17.17.17.17.17.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.17.17.17.17.17.17.17.17.1.m1.1b"><csymbol cd="latexml" id="S5.T5.17.17.17.17.17.17.17.17.1.m1.1.1.cmml" xref="S5.T5.17.17.17.17.17.17.17.17.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.17.17.17.17.17.17.17.17.1.m1.1c">\pm</annotation></semantics></math>0.10</span> <span id="S5.T5.18.18.18.18.18.18.18.18.2" class="ltx_td ltx_align_center">9.46<math id="S5.T5.18.18.18.18.18.18.18.18.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.18.18.18.18.18.18.18.18.2.m1.1a"><mo id="S5.T5.18.18.18.18.18.18.18.18.2.m1.1.1" xref="S5.T5.18.18.18.18.18.18.18.18.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.18.18.18.18.18.18.18.18.2.m1.1b"><csymbol cd="latexml" id="S5.T5.18.18.18.18.18.18.18.18.2.m1.1.1.cmml" xref="S5.T5.18.18.18.18.18.18.18.18.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.18.18.18.18.18.18.18.18.2.m1.1c">\pm</annotation></semantics></math>0.05</span> <span id="S5.T5.20.20.20.20.20.20.20.20.6" class="ltx_td"></span> <span id="S5.T5.19.19.19.19.19.19.19.19.3" class="ltx_td ltx_align_center">7.78<math id="S5.T5.19.19.19.19.19.19.19.19.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.19.19.19.19.19.19.19.19.3.m1.1a"><mo id="S5.T5.19.19.19.19.19.19.19.19.3.m1.1.1" xref="S5.T5.19.19.19.19.19.19.19.19.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.19.19.19.19.19.19.19.19.3.m1.1b"><csymbol cd="latexml" id="S5.T5.19.19.19.19.19.19.19.19.3.m1.1.1.cmml" xref="S5.T5.19.19.19.19.19.19.19.19.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.19.19.19.19.19.19.19.19.3.m1.1c">\pm</annotation></semantics></math>0.18</span> <span id="S5.T5.20.20.20.20.20.20.20.20.4" class="ltx_td ltx_nopad_r ltx_align_center">12.25<math id="S5.T5.20.20.20.20.20.20.20.20.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.20.20.20.20.20.20.20.20.4.m1.1a"><mo id="S5.T5.20.20.20.20.20.20.20.20.4.m1.1.1" xref="S5.T5.20.20.20.20.20.20.20.20.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.20.20.20.20.20.20.20.20.4.m1.1b"><csymbol cd="latexml" id="S5.T5.20.20.20.20.20.20.20.20.4.m1.1.1.cmml" xref="S5.T5.20.20.20.20.20.20.20.20.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.20.20.20.20.20.20.20.20.4.m1.1c">\pm</annotation></semantics></math>0.18</span></span> <span id="S5.T5.24.24.24.24.24.24.24.24" class="ltx_tr"> <span id="S5.T5.24.24.24.24.24.24.24.24.5" class="ltx_td ltx_align_left ltx_th ltx_th_row">Rec Agent</span> <span id="S5.T5.21.21.21.21.21.21.21.21.1" class="ltx_td ltx_align_center">14.21<math id="S5.T5.21.21.21.21.21.21.21.21.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.21.21.21.21.21.21.21.21.1.m1.1a"><mo id="S5.T5.21.21.21.21.21.21.21.21.1.m1.1.1" xref="S5.T5.21.21.21.21.21.21.21.21.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.21.21.21.21.21.21.21.21.1.m1.1b"><csymbol cd="latexml" id="S5.T5.21.21.21.21.21.21.21.21.1.m1.1.1.cmml" xref="S5.T5.21.21.21.21.21.21.21.21.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.21.21.21.21.21.21.21.21.1.m1.1c">\pm</annotation></semantics></math>0.07</span> <span id="S5.T5.22.22.22.22.22.22.22.22.2" class="ltx_td ltx_align_center">18.64<math id="S5.T5.22.22.22.22.22.22.22.22.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.22.22.22.22.22.22.22.22.2.m1.1a"><mo id="S5.T5.22.22.22.22.22.22.22.22.2.m1.1.1" xref="S5.T5.22.22.22.22.22.22.22.22.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.22.22.22.22.22.22.22.22.2.m1.1b"><csymbol cd="latexml" id="S5.T5.22.22.22.22.22.22.22.22.2.m1.1.1.cmml" xref="S5.T5.22.22.22.22.22.22.22.22.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.22.22.22.22.22.22.22.22.2.m1.1c">\pm</annotation></semantics></math>0.08</span> <span id="S5.T5.24.24.24.24.24.24.24.24.6" class="ltx_td"></span> <span id="S5.T5.23.23.23.23.23.23.23.23.3" class="ltx_td ltx_align_center">9.45<math id="S5.T5.23.23.23.23.23.23.23.23.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.23.23.23.23.23.23.23.23.3.m1.1a"><mo id="S5.T5.23.23.23.23.23.23.23.23.3.m1.1.1" xref="S5.T5.23.23.23.23.23.23.23.23.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.23.23.23.23.23.23.23.23.3.m1.1b"><csymbol cd="latexml" id="S5.T5.23.23.23.23.23.23.23.23.3.m1.1.1.cmml" xref="S5.T5.23.23.23.23.23.23.23.23.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.23.23.23.23.23.23.23.23.3.m1.1c">\pm</annotation></semantics></math>0.27</span> <span id="S5.T5.24.24.24.24.24.24.24.24.4" class="ltx_td ltx_nopad_r ltx_align_center">13.61<math id="S5.T5.24.24.24.24.24.24.24.24.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.24.24.24.24.24.24.24.24.4.m1.1a"><mo id="S5.T5.24.24.24.24.24.24.24.24.4.m1.1.1" xref="S5.T5.24.24.24.24.24.24.24.24.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.24.24.24.24.24.24.24.24.4.m1.1b"><csymbol cd="latexml" id="S5.T5.24.24.24.24.24.24.24.24.4.m1.1.1.cmml" xref="S5.T5.24.24.24.24.24.24.24.24.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.24.24.24.24.24.24.24.24.4.m1.1c">\pm</annotation></semantics></math>0.28</span></span> <span id="S5.T5.28.28.28.28.28.28.28.28" class="ltx_tr"> <span id="S5.T5.28.28.28.28.28.28.28.28.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t ltx_rowspan ltx_rowspan_3"><span id="S5.T5.28.28.28.28.28.28.28.28.5.1" class="ltx_text">LLaMA2-13b-chat-hf</span></span> <span id="S5.T5.28.28.28.28.28.28.28.28.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Math Agent</span> <span id="S5.T5.25.25.25.25.25.25.25.25.1" class="ltx_td ltx_align_center ltx_border_t">0.003<math id="S5.T5.25.25.25.25.25.25.25.25.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.25.25.25.25.25.25.25.25.1.m1.1a"><mo id="S5.T5.25.25.25.25.25.25.25.25.1.m1.1.1" xref="S5.T5.25.25.25.25.25.25.25.25.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.25.25.25.25.25.25.25.25.1.m1.1b"><csymbol cd="latexml" id="S5.T5.25.25.25.25.25.25.25.25.1.m1.1.1.cmml" xref="S5.T5.25.25.25.25.25.25.25.25.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.25.25.25.25.25.25.25.25.1.m1.1c">\pm</annotation></semantics></math>0.001</span> <span id="S5.T5.26.26.26.26.26.26.26.26.2" class="ltx_td ltx_align_center ltx_border_t">18.48<math id="S5.T5.26.26.26.26.26.26.26.26.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.26.26.26.26.26.26.26.26.2.m1.1a"><mo id="S5.T5.26.26.26.26.26.26.26.26.2.m1.1.1" xref="S5.T5.26.26.26.26.26.26.26.26.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.26.26.26.26.26.26.26.26.2.m1.1b"><csymbol cd="latexml" id="S5.T5.26.26.26.26.26.26.26.26.2.m1.1.1.cmml" xref="S5.T5.26.26.26.26.26.26.26.26.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.26.26.26.26.26.26.26.26.2.m1.1c">\pm</annotation></semantics></math>0.34</span> <span id="S5.T5.28.28.28.28.28.28.28.28.7" class="ltx_td ltx_border_t"></span> <span id="S5.T5.27.27.27.27.27.27.27.27.3" class="ltx_td ltx_align_center ltx_border_t">23.27<math id="S5.T5.27.27.27.27.27.27.27.27.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.27.27.27.27.27.27.27.27.3.m1.1a"><mo id="S5.T5.27.27.27.27.27.27.27.27.3.m1.1.1" xref="S5.T5.27.27.27.27.27.27.27.27.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.27.27.27.27.27.27.27.27.3.m1.1b"><csymbol cd="latexml" id="S5.T5.27.27.27.27.27.27.27.27.3.m1.1.1.cmml" xref="S5.T5.27.27.27.27.27.27.27.27.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.27.27.27.27.27.27.27.27.3.m1.1c">\pm</annotation></semantics></math>0.21</span> <span id="S5.T5.28.28.28.28.28.28.28.28.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">40.02<math id="S5.T5.28.28.28.28.28.28.28.28.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.28.28.28.28.28.28.28.28.4.m1.1a"><mo id="S5.T5.28.28.28.28.28.28.28.28.4.m1.1.1" xref="S5.T5.28.28.28.28.28.28.28.28.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.28.28.28.28.28.28.28.28.4.m1.1b"><csymbol cd="latexml" id="S5.T5.28.28.28.28.28.28.28.28.4.m1.1.1.cmml" xref="S5.T5.28.28.28.28.28.28.28.28.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.28.28.28.28.28.28.28.28.4.m1.1c">\pm</annotation></semantics></math>2.01</span></span> <span id="S5.T5.32.32.32.32.32.32.32.32" class="ltx_tr"> <span id="S5.T5.32.32.32.32.32.32.32.32.5" class="ltx_td ltx_align_left ltx_th ltx_th_row">Narrative Agent</span> <span id="S5.T5.29.29.29.29.29.29.29.29.1" class="ltx_td ltx_align_center">18.49<math id="S5.T5.29.29.29.29.29.29.29.29.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.29.29.29.29.29.29.29.29.1.m1.1a"><mo id="S5.T5.29.29.29.29.29.29.29.29.1.m1.1.1" xref="S5.T5.29.29.29.29.29.29.29.29.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.29.29.29.29.29.29.29.29.1.m1.1b"><csymbol cd="latexml" id="S5.T5.29.29.29.29.29.29.29.29.1.m1.1.1.cmml" xref="S5.T5.29.29.29.29.29.29.29.29.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.29.29.29.29.29.29.29.29.1.m1.1c">\pm</annotation></semantics></math>0.34</span> <span id="S5.T5.30.30.30.30.30.30.30.30.2" class="ltx_td ltx_align_center">35.89<math id="S5.T5.30.30.30.30.30.30.30.30.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.30.30.30.30.30.30.30.30.2.m1.1a"><mo id="S5.T5.30.30.30.30.30.30.30.30.2.m1.1.1" xref="S5.T5.30.30.30.30.30.30.30.30.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.30.30.30.30.30.30.30.30.2.m1.1b"><csymbol cd="latexml" id="S5.T5.30.30.30.30.30.30.30.30.2.m1.1.1.cmml" xref="S5.T5.30.30.30.30.30.30.30.30.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.30.30.30.30.30.30.30.30.2.m1.1c">\pm</annotation></semantics></math>0.76</span> <span id="S5.T5.32.32.32.32.32.32.32.32.6" class="ltx_td"></span> <span id="S5.T5.31.31.31.31.31.31.31.31.3" class="ltx_td ltx_align_center">28.61<math id="S5.T5.31.31.31.31.31.31.31.31.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.31.31.31.31.31.31.31.31.3.m1.1a"><mo id="S5.T5.31.31.31.31.31.31.31.31.3.m1.1.1" xref="S5.T5.31.31.31.31.31.31.31.31.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.31.31.31.31.31.31.31.31.3.m1.1b"><csymbol cd="latexml" id="S5.T5.31.31.31.31.31.31.31.31.3.m1.1.1.cmml" xref="S5.T5.31.31.31.31.31.31.31.31.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.31.31.31.31.31.31.31.31.3.m1.1c">\pm</annotation></semantics></math>2.10</span> <span id="S5.T5.32.32.32.32.32.32.32.32.4" class="ltx_td ltx_nopad_r ltx_align_center">46.15<math id="S5.T5.32.32.32.32.32.32.32.32.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.32.32.32.32.32.32.32.32.4.m1.1a"><mo id="S5.T5.32.32.32.32.32.32.32.32.4.m1.1.1" xref="S5.T5.32.32.32.32.32.32.32.32.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.32.32.32.32.32.32.32.32.4.m1.1b"><csymbol cd="latexml" id="S5.T5.32.32.32.32.32.32.32.32.4.m1.1.1.cmml" xref="S5.T5.32.32.32.32.32.32.32.32.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.32.32.32.32.32.32.32.32.4.m1.1c">\pm</annotation></semantics></math>2.02</span></span> <span id="S5.T5.36.36.36.36.36.36.36.36" class="ltx_tr"> <span id="S5.T5.36.36.36.36.36.36.36.36.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Rec Agent</span> <span id="S5.T5.33.33.33.33.33.33.33.33.1" class="ltx_td ltx_align_center ltx_border_bb">53.86<math id="S5.T5.33.33.33.33.33.33.33.33.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.33.33.33.33.33.33.33.33.1.m1.1a"><mo id="S5.T5.33.33.33.33.33.33.33.33.1.m1.1.1" xref="S5.T5.33.33.33.33.33.33.33.33.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.33.33.33.33.33.33.33.33.1.m1.1b"><csymbol cd="latexml" id="S5.T5.33.33.33.33.33.33.33.33.1.m1.1.1.cmml" xref="S5.T5.33.33.33.33.33.33.33.33.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.33.33.33.33.33.33.33.33.1.m1.1c">\pm</annotation></semantics></math>1.15</span> <span id="S5.T5.34.34.34.34.34.34.34.34.2" class="ltx_td ltx_align_center ltx_border_bb">71.62<math id="S5.T5.34.34.34.34.34.34.34.34.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.34.34.34.34.34.34.34.34.2.m1.1a"><mo id="S5.T5.34.34.34.34.34.34.34.34.2.m1.1.1" xref="S5.T5.34.34.34.34.34.34.34.34.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.34.34.34.34.34.34.34.34.2.m1.1b"><csymbol cd="latexml" id="S5.T5.34.34.34.34.34.34.34.34.2.m1.1.1.cmml" xref="S5.T5.34.34.34.34.34.34.34.34.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.34.34.34.34.34.34.34.34.2.m1.1c">\pm</annotation></semantics></math>1.26</span> <span id="S5.T5.36.36.36.36.36.36.36.36.6" class="ltx_td ltx_border_bb"></span> <span id="S5.T5.35.35.35.35.35.35.35.35.3" class="ltx_td ltx_align_center ltx_border_bb">34.92<math id="S5.T5.35.35.35.35.35.35.35.35.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.35.35.35.35.35.35.35.35.3.m1.1a"><mo id="S5.T5.35.35.35.35.35.35.35.35.3.m1.1.1" xref="S5.T5.35.35.35.35.35.35.35.35.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.35.35.35.35.35.35.35.35.3.m1.1b"><csymbol cd="latexml" id="S5.T5.35.35.35.35.35.35.35.35.3.m1.1.1.cmml" xref="S5.T5.35.35.35.35.35.35.35.35.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.35.35.35.35.35.35.35.35.3.m1.1c">\pm</annotation></semantics></math>2.22</span> <span id="S5.T5.36.36.36.36.36.36.36.36.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">52.44<math id="S5.T5.36.36.36.36.36.36.36.36.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T5.36.36.36.36.36.36.36.36.4.m1.1a"><mo id="S5.T5.36.36.36.36.36.36.36.36.4.m1.1.1" xref="S5.T5.36.36.36.36.36.36.36.36.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T5.36.36.36.36.36.36.36.36.4.m1.1b"><csymbol cd="latexml" id="S5.T5.36.36.36.36.36.36.36.36.4.m1.1.1.cmml" xref="S5.T5.36.36.36.36.36.36.36.36.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.36.36.36.36.36.36.36.36.4.m1.1c">\pm</annotation></semantics></math>2.43</span></span> </span> </span></span></span> </span></span></span></p>
</span></div>
</figure>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p" id="S6.p1.1">본 논문은 AIOS 아키텍처를 제안하여 LLM 기반 에이전트의 개발 및 배포를 촉진하고 보다 응집력 있고 효과적이며 효율적인 AIOS-Agent 생태계를 조성할 수 있는 가능성을 보여준다. 여기에 제시된 통찰력과 방법론은 AI 및 시스템 연구 모두에서 진행 중인 담론에 기여하여 AI 에이전트의 다양한 지형이 제기하는 통합 문제에 대한 실행 가능한 솔루션을 제공한다. 이러한 기반 위에 다양한 미래 작업이 구축될 수 있으며, LLM 에이전트를 개발하고 배치하는 진화하는 요구 사항을 충족하기 위해 AIOS 아키텍처를 개선하고 확장하는 혁신적인 방법을 모색할 수 있다.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Future Work</h2>

<div id="S7.p1" class="ltx_para">
<p class="ltx_p" id="S7.p1.1">AIOS를 시작으로 향후 연구가 나아가야 할 방향들이 많다. 이 섹션에서는 AIOS의 기본 기능을 확장하는 잠재적인 연구 영역을 설명한다.</p>
</div>
<section id="S7.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Advanced Scheduling Algorithms. </h4>

<div id="S7.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px1.p1.1">AIOS의 스케줄링 기능은 보다 진보된 알고리즘 개발을 위한 토대를 마련한다. 향후 연구에서는 에이전트 요청 간의 종속성 분석을 수행하여 계산 자원 할당을 최적화하는 알고리즘에 초점을 맞출 수 있다. 또한, 도구 리소스 중 일부는 로컬로 배포된 모델이며, 이는 또한 스케줄링 패러다임에 통합될 수 있다. 여기에는 도구 상태 및 스냅샷 관리가 포함되며, 에이전트와 도구를 모두 포함하는 통일된 스케줄링 프레임워크로의 이동을 제안한다.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Efficiency of Context Management. </h4>

<div id="S7.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px2.p1.1">상황 관리를 지원하기 위해 보다 효율적인 메커니즘이 고안될 수 있다. 예를 들어, 시간 효율적인 컨텍스트 관리 기술의 추구는 컨텍스트 스냅샷 및 복원의 프로세스를 신속하게 함으로써 사용자 경험을 크게 증가시킬 수 있다. 또한, 컨텍스트 압축 기술들은 또한 스냅샷팅 전에 레버리지될 수 있으며, 이는 보다 공간 효율적인 솔루션을 산출할 수 있다.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Optimization of Memory and Storage Architecture. </h4>

<div id="S7.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px3.p1.1">에이전트 협업 및 통신의 맥락에서, 향후 메모리 및 스토리지 시스템의 설계는 공유 접근법을 채택하여, 에이전트들 간의 메모리 및 스토리지의 공유를 가능하게 할 수 있다. 이러한 아키텍처는 에이전트가 메모리 및 저장소의 공동 풀에 액세스할 수 있게 하여, 한 에이전트가 다른 에이전트의 메모리 또는 저장소의 이점을 얻을 수 있기 때문에 에이전트의 의사 결정 능력을 향상시킬 수 있다. 또한, 향후 작업은 데이터 검색 및 스토리지 효율성을 최적화하도록 설계된 계층적 스토리지 솔루션을 탐색할 수 있습니다. 이것은 자주 액세스되는 데이터에 대해 더 빠른 액세스 및 감소된 스토리지 할당의 우선순위를 결정하는 것을 포함할 수 있고, 덜 자주 액세스되는 정보에 대해서는 그 반대의 경우도 마찬가지이다.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Safety and Privacy Enhancements. </h4>

<div id="S7.SS0.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px4.p1.1">AIOS의 안전성 측면은 LLM을 탈옥하거나 다른 에이전트 메모리의 무단 액세스와 같은 악의적인 공격에 대한 시스템의 복원력을 보장하는 다양한 공격에 대한 보호 조치를 필요로 한다. 프라이버시 영역에서 고급 암호화 기술에 대한 탐색은 AIOS 내에서 데이터 전송을 보호하여 에이전트 통신의 기밀성을 유지하는 데 필수적이다. 또한, 워터마킹 기술의 구현은 출력물에 고유한 식별자를 내장하여 데이터 계통의 추적을 용이하게 함으로써 에이전트 개발자의 지적 재산을 보호하는 역할을 할 수 있다.</p>
</div>
<div id="S7.SS0.SSS0.Px4.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px4.p2.1">네셸에서 AIOS는 광범위한 연구 기회를 가져오는 동기 부여 작업체로 서 있다. 개요된 각 방향은 AIOS의 기본 요소를 기반으로 할 뿐만 아니라 전반적인 분야의 발전에 기여할 수 있다.</p>
</div>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.p1.1">우리는 프로젝트 기간 동안 그들의 귀중한 토론과 제안에 대해 젠 장, 젠팅 왕, 그리고 원웨 화에게 감사한다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Michael Wooldridge and Nicholas&nbsp;R Jennings.

</span>
<span class="ltx_bibblock">Intelligent agents: Theory and practice.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">The knowledge engineering review</span>, 10(2):115–152, 1995.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Nicholas&nbsp;R Jennings, Katia Sycara, and Michael Wooldridge.

</span>
<span class="ltx_bibblock">A roadmap of agent research and development.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Autonomous agents and multi-agent systems</span>, 1:7–38, 1998.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Paolo Bresciani, Anna Perini, Paolo Giorgini, Fausto Giunchiglia, and John Mylopoulos.

</span>
<span class="ltx_bibblock">Tropos: An agent-oriented software development methodology.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Autonomous Agents and Multi-Agent Systems</span>, 8:203–236, 2004.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openai.com/research/gpt-4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/research/gpt-4</a>, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Facebook.

</span>
<span class="ltx_bibblock">Meta. introducing llama: A foundational, 65-billion-parameter large language model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ai.facebook.com/blog/largelanguage-model-llama-meta-ai" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ai.facebook.com/blog/largelanguage-model-llama-meta-ai</a>, 2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew&nbsp;M Dai, Anja Hauth, et&nbsp;al.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2312.11805</span>, 2023.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Yingqiang Ge, Wenyue Hua, Kai Mei, Juntao Tan, Shuyuan Xu, Zelong Li, and Yongfeng Zhang.

</span>
<span class="ltx_bibblock">OpenAGI: When LLM Meets Domain Experts.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 35:27730–27744, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et&nbsp;al.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2210.11416</span>, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang.

</span>
<span class="ltx_bibblock">Recommendation as language processing (rlp): A unified pretrain, personalized prompt &amp; predict paradigm (p5).

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proceedings of the 16th ACM Conference on Recommender Systems</span>, page 299–315, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang&nbsp;Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 35:22199–22213, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Erik Nijkamp, Bo&nbsp;Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong.

</span>
<span class="ltx_bibblock">Codegen: An open large language model for code with multi-turn program synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2203.13474</span>, 2022.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic.

</span>
<span class="ltx_bibblock">Galactica: A large language model for science.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.09085</span>, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Shibo Hao, Yi&nbsp;Gu, Haodi Ma, Joshua Hong, Zhen Wang, Daisy Wang, and Zhiting Hu.

</span>
<span class="ltx_bibblock">Reasoning with language model is planning with world model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</span>, pages 8154–8173, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Geunwoo Kim, Pierre Baldi, and Stephen McAleer.

</span>
<span class="ltx_bibblock">Language models can solve computer tasks.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Steven&nbsp;I Ross, Fernando Martinez, Stephanie Houde, Michael Muller, and Justin&nbsp;D Weisz.

</span>
<span class="ltx_bibblock">The programmer’s assistant: Conversational interaction with a large language model for software development.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Proceedings of the 28th International Conference on Intelligent User Interfaces</span>, pages 491–514, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Danny Driess, Fei Xia, Mehdi&nbsp;SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Palm-e: an embodied multimodal language model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Proceedings of the 40th International Conference on Machine Learning</span>, pages 8469–8488, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, et&nbsp;al.

</span>
<span class="ltx_bibblock">Do as i can, not as i say: Grounding language in robotic affordances.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Conference on robot learning</span>, pages 287–318. PMLR, 2023.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.

</span>
<span class="ltx_bibblock">ReAct: Synergizing reasoning and acting in language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.

</span>
<span class="ltx_bibblock">Reflexion: Language agents with verbal reinforcement learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2023.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Xiang Deng, Yu&nbsp;Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu&nbsp;Su.

</span>
<span class="ltx_bibblock">Mind2web: Towards a generalist agent for the web.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2023.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
UW:CSE451.

</span>
<span class="ltx_bibblock">History of Operating Systems, 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf</a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Dennis&nbsp;M. Ritchie and Ken Thompson.

</span>
<span class="ltx_bibblock">The unix time-sharing system.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Commun. ACM</span>, 17(7):365–375, jul 1974.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Charles Antony&nbsp;Richard Hoare.

</span>
<span class="ltx_bibblock">Monitors: An operating system structuring concept.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">Communications of the ACM</span>, 17(10):549–557, 1974.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Dawson&nbsp;R Engler, M&nbsp;Frans Kaashoek, and James O’Toole&nbsp;Jr.

</span>
<span class="ltx_bibblock">Exokernel: An operating system architecture for application-level resource management.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">ACM SIGOPS Operating Systems Review</span>, 29(5):251–266, 1995.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Chung&nbsp;Laung Liu and James&nbsp;W Layland.

</span>
<span class="ltx_bibblock">Scheduling algorithms for multiprogramming in a hard-real-time environment.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Journal of the ACM (JACM)</span>, 20(1):46–61, 1973.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Edsger&nbsp;W Dijkstra.

</span>
<span class="ltx_bibblock">Cooperating sequential processes.

</span>
<span class="ltx_bibblock">In <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">The origin of concurrent programming: from semaphores to remote procedure calls</span>, pages 65–138. Springer, 2002.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Peter&nbsp;J Denning.

</span>
<span class="ltx_bibblock">The working set model for program behavior.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Communications of the ACM</span>, 11(5):323–333, 1968.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Robert&nbsp;C Daley and Jack&nbsp;B Dennis.

</span>
<span class="ltx_bibblock">Virtual memory, processes, and sharing in multics.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Communications of the ACM</span>, 11(5):306–312, 1968.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Mendel Rosenblum and John&nbsp;K Ousterhout.

</span>
<span class="ltx_bibblock">The design and implementation of a log-structured file system.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Computer Systems (TOCS)</span>, 10(1):26–52, 1992.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Marshall&nbsp;K McKusick, William&nbsp;N Joy, Samuel&nbsp;J Leffler, and Robert&nbsp;S Fabry.

</span>
<span class="ltx_bibblock">A fast file system for unix.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Computer Systems (TOCS)</span>, 2(3):181–197, 1984.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Yingqiang Ge, Yujie Ren, Wenyue Hua, Shuyuan Xu, Juntao Tan, and Yongfeng Zhang.

</span>
<span class="ltx_bibblock">LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">arXiv:2312.03815</span>, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.

</span>
<span class="ltx_bibblock">Toolformer: Language models can teach themselves to use tools.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.04761</span>, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Shunyu Yao and Karthik Narasimhan.

</span>
<span class="ltx_bibblock">Language agents in the digital world: Opportunities and risks.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">princeton-nlp.github.io</span>, Jul 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Aaron Parisi, Yao Zhao, and Noah Fiedel.

</span>
<span class="ltx_bibblock">Talm: Tool augmented language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2205.12255</span>, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, and Le&nbsp;Sun.

</span>
<span class="ltx_bibblock">Toolalpaca: Generalized tool learning for language models with 3000 simulated cases.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.05301</span>, 2023.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu&nbsp;Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman.

</span>
<span class="ltx_bibblock">Webgpt: Browser-assisted question-answering with human feedback, 2022.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Kechi Zhang, Ge&nbsp;Li, Jia Li, Zhuo Li, and Zhi Jin.

</span>
<span class="ltx_bibblock">Toolcoder: Teach code generation models to use apis with search tools.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.04032</span>, 2023.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar.

</span>
<span class="ltx_bibblock">Minedojo: Building open-ended embodied agents with internet-scale knowledge.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 35:18343–18362, 2022.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar.

</span>
<span class="ltx_bibblock">Voyager: An open-ended embodied agent with large language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Intrinsically-Motivated and Open-Ended Learning Workshop@ NeurIPS2023</span>, 2023.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Daniil&nbsp;A Boiko, Robert MacKnight, and Gabe Gomes.

</span>
<span class="ltx_bibblock">Emergent autonomous scientific research capabilities of large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.05332</span>, 2023.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Andres&nbsp;M Bran, Sam Cox, Andrew&nbsp;D White, and Philippe Schwaller.

</span>
<span class="ltx_bibblock">Chemcrow: Augmenting large-language models with chemistry tools.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.05376</span>, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch.

</span>
<span class="ltx_bibblock">Language models as zero-shot planners: Extracting actionable knowledge for embodied agents.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 9118–9147. PMLR, 2022.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Jiannan Xiang, Tianhua Tao, Yi&nbsp;Gu, Tianmin Shu, Zirui Wang, Zichao Yang, and Zhiting Hu.

</span>
<span class="ltx_bibblock">Language models meet world models: Embodied experiences enhance language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 36, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.

</span>
<span class="ltx_bibblock">Camel: Communicative agents for "mind" exploration of large language model society.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Joon&nbsp;Sung Park, Joseph O’Brien, Carrie&nbsp;Jun Cai, Meredith&nbsp;Ringel Morris, Percy Liang, and Michael&nbsp;S Bernstein.

</span>
<span class="ltx_bibblock">Generative agents: Interactive simulacra of human behavior.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</span>, pages 1–22, 2023.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka&nbsp;Shing Yau, Zijuan Lin, et&nbsp;al.

</span>
<span class="ltx_bibblock">Metagpt: Meta programming for multi-agent collaborative framework.

</span>
<span class="ltx_bibblock">In <span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">The Twelfth International Conference on Learning Representations</span>, 2023.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun.

</span>
<span class="ltx_bibblock">Communicative agents for software development.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.07924</span>, 2023.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li&nbsp;Jiang, Xiaoyun Zhang, and Chi Wang.

</span>
<span class="ltx_bibblock">Autogen: Enabling next-gen llm applications via multi-agent conversation framework.

</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.08155</span>, 2023.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Martin Josifoski, Lars Klein, Maxime Peyrard, Yifei Li, Saibo Geng, Julian&nbsp;Paul Schnitzler, Yuxing Yao, Jiheng Wei, Debjit Paul, and Robert West.

</span>
<span class="ltx_bibblock">Flows: Building blocks of reasoning and collaborating ai.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.01285</span>, 2023.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata.

</span>
<span class="ltx_bibblock">Improving language model negotiation with self-play and in-context learning from ai feedback.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.10142</span>, 2023.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Yilun Du, Shuang Li, Antonio Torralba, Joshua&nbsp;B Tenenbaum, and Igor Mordatch.

</span>
<span class="ltx_bibblock">Improving factuality and reasoning in language models through multiagent debate.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.14325</span>, 2023.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu.

</span>
<span class="ltx_bibblock">Chateval: Towards better llm-based evaluators through multi-agent debate.

</span>
<span class="ltx_bibblock">In <span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">The Twelfth International Conference on Learning Representations</span>, 2023.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi.

</span>
<span class="ltx_bibblock">Encouraging divergent thinking in large language models through multi-agent debate.

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.19118</span>, 2023.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge, Libby Hemphill, and Yongfeng Zhang.

</span>
<span class="ltx_bibblock">War and peace (waragent): Large language model-based multi-agent simulation of world wars.

</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2311.17227</span>, 2023.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Albert&nbsp;Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.06825</span>, 2023.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Stella Biderman, Hailey Schoelkopf, Quentin&nbsp;Gregory Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad&nbsp;Aflah Khan, Shivanshu Purohit, USVSN&nbsp;Sai Prashanth, Edward Raff, et&nbsp;al.

</span>
<span class="ltx_bibblock">Pythia: A suite for analyzing large language models across training and scaling.

</span>
<span class="ltx_bibblock">In <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 2397–2430. PMLR, 2023.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian.

</span>
<span class="ltx_bibblock">Extending context window of large language models via positional interpolation.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.15595</span>, 2023.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole.

</span>
<span class="ltx_bibblock">Yarn: Efficient context window extension of large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2309.00071</span>, 2023.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Grégoire Mialon, Roberto Dessi, Maria Lomeli, Christoforos Nalmpantis, Ramakanth Pasunuru, Roberta Raileanu, Baptiste Roziere, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et&nbsp;al.

</span>
<span class="ltx_bibblock">Augmented language models: a survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">Transactions on Machine Learning Research</span>, 2023.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
LangChain.

</span>
<span class="ltx_bibblock">Langchain.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/langchain-ai/langchain" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/langchain-ai/langchain</a>, 2024.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Rapid.

</span>
<span class="ltx_bibblock">Rapid api hub.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://rapidapi.com/hub" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://rapidapi.com/hub</a>, 2024.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Ken Thompson.

</span>
<span class="ltx_bibblock">Reflections on trusting trust.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">Communications of the ACM</span>, 27(8):761–763, 1984.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Sven Bugiel, Lucas Davi, Alexandra Dmitrienko, Thomas Fischer, Ahmad-Reza Sadeghi, and Bhargava Shastry.

</span>
<span class="ltx_bibblock">Towards taming privilege-escalation attacks on android.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">NDSS</span>, volume&nbsp;17, page&nbsp;19, 2012.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Tris&nbsp;Warkentin Jeanine&nbsp;Banks.

</span>
<span class="ltx_bibblock">Gemma: Introducing new state-of-the-art open models.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://blog.google/technology/developers/gemma-open-models/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://blog.google/technology/developers/gemma-open-models/</a>, 2024.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</span>, pages 311–318, 2002.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian&nbsp;Q Weinberger, and Yoav Artzi.

</span>
<span class="ltx_bibblock">Bertscore: Evaluating text generation with bert.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1904.09675</span>, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2403.16970" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2403.16971" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2403.16971">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.16971" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2403.16972" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 16:24:05 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>