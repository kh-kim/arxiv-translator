# AIOS: LLM 에이전트 운영체제

 카이메이

Rutgers University

&Zelong Li

Rutgers University

&Shuyuan Xu

Rutgers University

&Ruosong Ye

Rutgers University

&Yingqiang Ge

Rutgers University

&Yongfeng Zhang

Rutgers University

Author Affiliations: Department of Computer Science, Rutgers University, New Brunswick, NJ 08854; **Author Emails**: kai.mei, zelong.li, shuyuan.xu, ruosong.ye, yingqiang.ge, yongfeng.zhang@rutgers.edu

###### Abstract

대규모 언어 모델(LLM) 기반 지능형 에이전트의 통합 및 배포는 효율성과 효율성을 손상시키는 과제로 가득했다. 이러한 문제 중에는 LLM을 통한 에이전트 요청의 차선책 스케줄링 및 자원 할당, 에이전트와 LLM 간의 상호 작용 중 컨텍스트 유지의 어려움, 서로 다른 기능과 전문화를 가진 이종 에이전트를 통합하는 데 내재된 복잡성이 있다. 에이전트 양과 복잡성의 급격한 증가는 이러한 문제를 더욱 악화시켜 종종 병목 현상과 리소스의 차선책 활용으로 이어진다. 이러한 문제점에 착안하여 본 논문에서는 LLM 에이전트 운영체제인 AIOS를 제안한다. AIOS는 OS의 두뇌로서 운영체제(Operating System, OS)에 큰 언어 모델을 내장하여 AGI를 향한 중요한 단계인 "영혼이 있는" 운영체제를 가능하게 한다. 구체적으로, AIOS는 리소스 할당을 최적화하고, 에이전트들 간의 컨텍스트 전환을 용이하게 하며, 에이전트들의 동시 실행을 가능하게 하고, 에이전트들에 대한 툴 서비스를 제공하고, 에이전트들에 대한 액세스 제어를 유지하도록 설계된다. 우리는 이러한 운영체제의 아키텍처를 제시하고, 그것이 해결하고자 하는 핵심 과제를 개괄하며, AIOS의 기본 설계 및 구현을 제공한다. 여러 에이전트의 동시 실행에 대한 실험은 AIOS 모듈의 신뢰성과 효율성을 보여준다. 이를 통해 LLM 에이전트의 성능과 효율성을 향상시킬 뿐만 아니라 향후 AIOS 생태계의 더 나은 개발 및 배치를 위한 개척을 목표로 한다. 이 프로젝트는 [https://github.com/agiresearch/AIOS](https://github.com/agiresearch/AIOS)의 오픈 소스입니다.

## 1 Introduction

자율 에이전트 분야에서 연구 노력[1; 2; 3]은 인간의 개입 없이 또는 최소한의 개입 없이 독립적으로 작동하고, 결정을 내리고, 작업을 수행할 수 있는 시스템을 지향한다. 이러한 에이전트는 지시를 이해하고, 정보를 처리하고, 결정을 내리고, 자율 상태를 달성하기 위한 조치를 취하도록 설계되었다. 대규모 언어 모델(LLM)의 출현[4;5;6]은 에이전트 개발에 새로운 가능성을 가져왔다[7]. 현재의 LLM은 명령어[8; 9; 10; 11], 추론 및 문제 해결[12; 13; 14; 15; 16] 및 외부 환경뿐만 아니라 인간 사용자[17]와 상호작용하는 데 큰 힘을 보여주었다[18; 19]. 이러한 강력한 LLM을 기반으로 한 새로운 LLM 기반 에이전트[7; 20; 21; 22]는 가상 비서에서 복잡하고 창의적인 문제 해결, 계획 및 추론을 포함하는 보다 정교한 시스템에 이르기까지 다양한 환경에서 강력한 작업 수행 능력을 제시할 수 있다.

LLM 기반 에이전트가 실제 태스크를 해결하는 방법에 대한 하나의 매력적인 예는 그림 1에서 볼 수 있다. 사용자로부터의 여행 조직 요청이 주어지면, 여행 에이전트는 태스크를 실행가능한 단계들로 분해한다. 그런 다음, 사용자의 선호도에 따라 항공편 예약, 호텔 예약, 결제 처리 및 일정 업데이트 단계를 순차적으로 수행합니다. 계획 실행 중에 에이전트는 추론 및 의사 결정 능력을 보여주며, 이는 미리 정의된 함수 또는 워크플로우 집합으로 제한되는 전통적인 소프트웨어 애플리케이션과 구별된다. 이 여행 시나리오를 실현하기 위해, 에이전트는 LLM 서비스(예를 들어, 사용자 선호도 검색 및 이해, 호출할 도구 API 결정, 리뷰 및 응답 생성) 및 전통적인 운영 체제(OS) 서비스(예를 들어, 디스크 드라이버 액세스 및 소프트웨어 실행) 둘 다와 상호작용할 필요가 있다.

제제 양과 복잡성의 기하급수적인 증가와 함께 LLM 및 OS의 기능에 대한 부담이 증가하고 있다. 예를 들어, 제한된 LLM 리소스들에서 에이전트 요청들을 스케줄링하고 우선순위화하는 것은 상당한 도전을 제기한다. 더욱이, LLM의 생성 프로세스는 긴 컨텍스트들을 다룰 때 시간 집약적이 될 수 있고, 때때로 스케줄러에 의해 생성이 중단되는 결과를 초래한다. 이는 LLM의 현재 생성 결과를 스냅샷하는 메커니즘을 고안하여 LLM이 현재 요청에 대한 응답 생성을 완료하지 않은 경우에도 일시 중지/재시작 동작을 가능하게 하는 문제를 야기한다. 또한 에이전트가 사용 가능한 호출 도구 목록을 얻으면 여러 에이전트가 동일한 도구를 호출해야 할 수 있기 때문에 이러한 도구를 호출하기 위한 최적의 순서를 결정하는 것은 또 다른 과제를 제시한다. 또한, 다수의 에이전트들의 동시 동작은 상이한 에이전트들에 걸쳐 메모리 관리를 위한 강력한 시스템을 필요로 하는 동시에, 프라이버시 및 액세스 제어 조치들의 엄격한 집행을 보장한다.

위에서 언급한 문제를 해결하기 위해 LLM 및 OS 기능의 모듈 격리 및 집계를 제공하는 LLM 에이전트 운영 체제(그림 2)인 AIOS를 제안한다. LLM과 관련된 태스크와 LLM과 관련이 없는 태스크 간에 발생할 수 있는 잠재적인 충돌을 해결하기 위해 LLM 특정 커널의 설계를 제안한다. 이 커널은 OS와 같은 임무, 특히 LLM 에이전트, 해당 리소스 및 개발 도구 키트의 감독과 관련된 임무를 분리한다. 이러한 분리를 통해 LLM 커널은 LLM 관련 활동의 관리 및 조정을 향상시키는 것을 목표로 한다. 제안된 LLM 커널 내에서 우리는 각각 LLM 연산과 관련된 고유한 기능을 다루는 데 전념하는 모듈 세트를 고안했다. 이러한 모듈과 각각의 기능에 대한 개요는 섹션 4에 자세히 설명된 기본 메커니즘에 대한 포괄적인 논의와 함께 다음에서 제시된다.

* **에이전트 스케줄러**: LLM 사용률을 최적화하기 위해 에이전트 요청의 우선순위를 지정하고 스케줄을 지정합니다.
* **컨텍스트 관리자**: 스냅숏을 지원 하 고 LLM 및 LLM의 컨텍스트 창 관리에서 중간 생성 상태를 복원 합니다.
* **메모리 관리자**: 각 에이전트의 상호 작용 로그에 대한 단기 메모리를 제공합니다.
* **스토리지 관리자**: 향후 검색을 위해 에이전트 상호 작용 로그를 장기 스토리지에 유지합니다.
* **도구 관리자**: 에이전트의 외부 API 도구 호출(예: 검색, 과학 컴퓨팅)을 관리합니다.
* **액세스 관리자**: 에이전트 간의 개인 정보 보호 및 액세스 제어 정책을 적용합니다.

모듈 외에도 커널은 에이전트가 이러한 서비스를 투명하게 활용할 수 있는 LLM 시스템 호출 인터페이스를 노출합니다. 또한, LLM 시스템 호출을 더욱 캡슐화하여 에이전트 개발자에게 보다 편리한 에이전트 라이브러리 기능을 제공하기 위해 AIOS SDK를 설계한다. AIOS 아키텍처를 사용하여 여행 플래너와 같은 에이전트는 작업을 LLM 추론(예: 계획 생성 및 도구 호출 결정)과 OS 수준 작업(예: 스토리지 액세스 및 소프트웨어 서비스 실행)을 유동적으로 결합하는 단계로 나눌 수 있습니다. 이러한 시너지 기능의 조합은 여러 LLM 에이전트를 구비하여 추론, 실행 및 물리적 세계와의 상호 작용을 필요로 하는 점점 더 복잡한 다중 모드 작업을 해결한다.

그림 1: 에이전트(즉, Travel Agent)가 작업을 완료하기 위해 LLM 수준과 OS 수준 리소스와 기능을 모두 필요로 하는 방법에 대한 동기 부여 예제입니다.

앞으로는 AIOS를 확장하여 보다 엄격한 에이전트-세계 통합(예: 로봇 제어를 통해), 보다 지능적인 리소스 관리 및 보다 안전한 다중 에이전트 협업을 지원하는 것을 구상합니다. 궁극적으로 AIOS는 다양한 복잡한 LLM 에이전트의 개발, 배포 및 사용을 촉진하는 중요한 플랫폼 역할을 한다.

## 2 관련 작업

### 운영 체제 진화

운영 체제(OS)의 진화는 초보적인 시스템에서 오늘날의 복잡하고 상호작용적인 OS로 진화하는 점진적인 방식으로 전개되었다. 초기에, 운영 체제들은 전자 및 게이트 조작과 같은 컴퓨터 하드웨어의 이진 기능과 사용자-레벨 태스크들 사이의 갭을 해소하는 역할을 하였다. 그들의 진화는 단순 배치 작업 처리[23]에서 시간 공유[24] 및 다중 작업 처리[25, 26]와 같은 보다 진보된 프로세스 관리 기술로 전환되었으며, 이는 점점 더 복잡한 작업의 처리를 용이하게 했다. 프로세스 스케줄링[27, 28], 메모리 관리[29, 30] 및 파일 시스템 관리[31, 32]와 같은 특정 책임을 기술하면서 OS 내에서 모듈화 방향으로 진행되었으며 효율성 및 관리성을 향상시켰다. 그래픽 사용자 인터페이스(GUI)(예: Macintosh1, Windows2 및 GNOME3)의 추가 출현은 운영 체제를 보다 상호작용적이고 사용자 중심적으로 만든다. 한편, 운영 체제 생태계도 확장되어 개발 도구(OS SDK)와 런타임 라이브러리의 포괄적인 제품군을 제공한다. 이러한 툴들은 애플리케이션 개발자들이 그들의 애플리케이션들을 OS 환경 내에서 효율적으로 설계, 구현 및 실행할 수 있게 한다[33]. OS 생태계의 대표적인 예로는 Android Studio4, XCode5 및 Cloud SDK6이 있다. 이러한 생태계에서 OS는 소프트웨어 개발을 용이하게 하기 위해 수많은 리소스를 제공하고 소프트웨어 애플리케이션을 배포하고 호스팅하는 플랫폼 역할을 하여 번성하는 OS-애플리케이션 생태계로 이어진다. 오늘날 우리는 지능형 운영체제의 잠재력을 보기 위해 변형 단계에 서 있다. 대형 언어 모델(LLM)의 통합으로, 이러한 고급 시스템은 인간과 기계 사이의 통신 격차를 더욱 좁혀 사용자-컴퓨터 상호 작용의 새로운 시대를 앞당길 것을 약속한다.

각주 1: [http://apple-history.com/128k](http://apple-history.com/128k)

각주 2: [https://winworldpc.com/product/windows-3/31](https://winworldpc.com/product/windows-3/31)

각주 3: [https://www.gnome.org/](https://www.gnome.org/)

각주 4: [https://developer.android.com/studio](https://developer.android.com/studio)

각주 5: [https://developer.apple.com/xcode/](https://developer.apple.com/xcode/)

각주 6: [https://cloud.google.com/sdk](https://cloud.google.com/sdk)

### 대용량 언어 모델 에이전트

LLM(Large Language Model) 기반의 자율 에이전트는 복잡한 과제 해결을 위해 자연어 명령어를 입력으로 사용한다. LLM 기반 에이전트에 대한 연구는 일반적으로 단일 에이전트 시스템과 다중 에이전트 시스템으로 분류할 수 있다[33].

LLM 기반 Single-Agent Systems.LLM 기반 Single-Agent Systems (SAS)는 여행 계획, 개인화된 추천, 예술적 디자인과 같은 복잡한 과제 해결을 위해 단일 LLM 에이전트를 사용한다[7]. 에이전트는 사용자로부터의 자연어 명령을 입력으로 하고 태스크를 태스크 해결을 위한 다단계 계획으로 분해하며, 여기서 각 단계는 정보 수집, 전문 모델 실행 또는 외부 세계와의 상호작용과 같은 완료될 외부 도구를 호출할 수 있다. 단일 에이전트 애플리케이션은 해결해야 할 작업에 따라 디지털 환경 또는 물리적 환경 또는 둘 다와 결합할 수 있다. 예를 들어, 가상 또는 디지털 환경의 에이전트들은 API들을 호출하고[7, 34, 35, 36, 37], 웹사이트들을 탐색하고[38, 22], 또는 코드들을 실행할 수 있는 반면, 물리적 환경의 에이전트들은 객체들을 조작하고[19, 40, 41], 랩 실험들을 수행하고[42, 43], 또는 실행가능한 결정들을 할 수 있다[44, 45].

LLM 기반 다중 에이전트 시스템.LLM 기반 다중 에이전트 시스템(MAS)은 문제 해결을 위해 여러 에이전트 간의 상호 작용을 활용한다. 여러 에이전트 간의 관계는 협력, 경쟁 또는 협력과 경쟁의 혼합일 수 있다[33]. 협력형 다중-에이전트 시스템에서, 각각의 에이전트는 다른 에이전트들에 의해 제공된 정보를 취하고 평가함으로써, 역할 수행[46], 소셜 시뮬레이션[47] 및 소프트웨어 개발[48, 49, 50, 51]과 같은 복잡한 태스크들을 해결하기 위해 함께 작업한다. 경쟁적 다중 에이전트 시스템에서, 에이전트는 협상 기술 향상[52] 및 정답에 대한 토론[53, 54, 55]과 같이, 목표를 달성하기 위해 게임 환경에서 서로 디타브, 협상 및 경쟁할 수 있다. 일부 다중 에이전트 시스템은 에이전트 간의 협력과 경쟁을 모두 나타낼 수 있다. 예를 들어 WarAgent[56]는 각 국가를 LLM 기반 에이전트로 모델링하여 국가 간의 상호 작용이 국제 분쟁으로 이어질 수 있는 방법을 연구하는데, 국가는 동맹을 수립하고 평화 협정을 체결하는 등 서로 협력하거나 군비 경쟁, 동원, 전쟁 선포 등 서로 경쟁할 수 있다.

## 3 AIOS 계층

그림 2와 같이, AIOS의 아키텍처는 애플리케이션 계층, 커널 계층 및 하드웨어 계층의 세 가지 별개의 계층으로 구성된다. 이 계층화된 아키텍처는 시스템 전반에 걸친 책임의 명확한 묘사를 보장합니다. 각각의 상위 계층은 그 아래의 계층들의 복잡성을 추상화하여, 인터페이스들 또는 특정 모듈들을 통한 상호작용을 용이하게 하여, 모듈성을 향상시키고 상이한 계층들에 걸친 시스템 상호작용들을 단순화시킨다.

**애플리케이션 계층.** 애플리케이션 계층에서 여행 에이전트 또는 수학 에이전트와 같은 에이전트 애플리케이션이 개발 및 배포됩니다. 이 계층에서 AIOS는 에이전트 개발자를 위한 개발 프로세스를 간소화하는 시스템 호출의 더 높은 추상화를 AIOS SDK에 제공한다. 이 SDK는 하위 수준 시스템 기능의 복잡성을 추상화하는 풍부한 툴킷을 제공하여 에이전트 애플리케이션을 개발할 수 있습니다. 이를 통해 개발자는 에이전트의 필수 논리 및 기능에 초점을 맞출 수 있어 보다 효율적인 개발 프로세스를 촉진할 수 있다.

**커널 계층.** 커널 계층은 OS 커널과 LLM 커널의 두 가지 기본 구성 요소로 나뉘며, 각 구성 요소는 각각 비LLM 및 LLM 특정 작업의 고유한 요구 사항을 제공합니다. 이러한 구별은 LLM 커널이 컨텍스트 관리 및 에이전트 스케줄링과 같은 LLM 특정 작업에 초점을 맞출 수 있게 하는데, 이는 LLM 관련 활동을 처리하는데 필수적이며 일반적으로 표준 OS 커널 함수의 범위 내에 있지 않다. 우리의 작업은 주로 기존 OS 커널 구조를 크게 변경하지 않고 LLM 커널을 향상시키는 데 중점을 둔다. LLM 커널에는 LLM 시스템 호출 인터페이스, 에이전트 스케줄러, 컨텍스트 매니저, 메모리 매니저, 스토리지 매니저, 툴 매니저, 액세스 매니저 등 여러 핵심 모듈이 탑재되어 있다. 이러한 구성 요소는 에이전트 애플리케이션의 다양한 실행 요구를 해결하기 위해 설계되어 AIOS 프레임워크 내에서 효율적인 관리 및 실행을 보장합니다. 이러한 모듈의 세부 사항은 섹션 4에서 더 자세히 설명한다.

**하드웨어 계층.** 하드웨어 계층은 CPU, GPU, 메모리, 디스크 및 주변 장치를 포함한 시스템의 물리적 구성 요소로 구성됩니다. LLM 커널의 시스템 호출은 하드웨어와 직접 상호 작용할 수 없다는 점에 유의하는 것이 중요하다. 대신에, 이러한 호출들은 OS의 시스템 호출들과 인터페이스하고, 이는 차례로 하드웨어 리소스들을 관리한다. 이러한 간접적인 상호작용은 추상화 및 보안의 계층을 보장하여, LLM 커널이 직접적인 하드웨어 관리를 요구하지 않고 하드웨어 능력을 레버리지할 수 있게 하여, 시스템의 무결성 및 효율성을 유지한다.

그림 2: AIOS 아키텍처의 개요입니다.

AOS Implementation

이 섹션에서는 LLM 커널 내의 각 모듈의 기본 설계 및 구현에 대한 개요로 시작한다. 이후, 각 모듈에 대한 필수 기능을 포괄하는 LLM 시스템 호출을 제시한다. 마지막으로 에이전트 개발자를 위한 개발 프로세스를 용이하게 하기 위해 AIOS SDK에 대한 탐색에 대해 논의한다.

### Agent Scheduler

에이전트 스케줄러는 에이전트 요청을 효율적으로 관리할 수 있도록 설계되었다. 그림 3에서 다양한 에이전트(A, B 및 C로 표시됨)를 고려하며, 각 에이전트에는 여러 실행 단계가 있습니다. 순차 실행 패러다임에서, 에이전트 태스크들은 선형 순서로 처리되며, 여기서 동일한 에이전트로부터의 단계들이 먼저 처리될 것이다. 이는 시퀀스 후반에 대기 중인 태스크에 대한 잠재적인 대기 시간을 증가시킬 수 있다.

에이전트 스케줄러는 이 프로세스를 최적화하기 위해 FIFO(First-In-First-Out)7, RR(Round Robin)8 및 기타 스케줄링 알고리즘과 같은 전략을 사용한다. 동시 실행을 통해, 스케줄러는 상이한 에이전트로부터의 태스크들이 인터리빙되고 병렬로 실행됨에 따라 각 에이전트의 대기 시간 및 턴어라운드 시간의 균형을 상당히 조정한다. 이 동시 접근법은 상이한 에이전트들로부터의 태스크들이 인터리빙된 방식(예를 들어, A1, B1, C1, B2, A2, A3, C2, C3)으로 프로세싱되는 타임라인을 통해 시각화되어, 단일 에이전트가 프로세싱 리소스들을 독점하지 않고 유휴 시간들이 최소화되도록 보장한다. 기존의 스케줄링 알고리즘들을 구현하는 것 외에도, 에이전트 요청들 간의 종속 관계를 고려한 보다 복잡한 스케줄링 알고리즘들이 또한 통합될 수 있으며, 이는 향후 고려될 수 있다.

각주 7: [https://en.wikipedia.org/wiki/FIFO_](https://en.wikipedia.org/wiki/FIFO_)(computing_and_electronics)

각주 8: [https://en.wikipedia.org/wiki/Round-robin_scheduling](https://en.wikipedia.org/wiki/Round-robin_scheduling)

### Context Manager

도 4: 컨텍스트 스냅샷 및 복원, 여기서 우리는 이러한 생성 디코딩 프로세스를 예시하기 위한 예시적인 탐색 알고리즘으로서 빔 탐색(빔 폭 = 1)을 사용한다.

도 3: 에이전트 스케줄러의 예시.

컨텍스트 관리자는 LLM에 제공되는 컨텍스트 및 특정 컨텍스트가 주어진 생성 프로세스를 관리하는 역할을 한다. 여기에는 주로 컨텍스트 스냅숏 및 복원, 컨텍스트 창 관리의 두 가지 중요한 기능이 포함됩니다.

**컨텍스트 스냅샷 및 복원** 스케줄러 알고리즘에 시간 양자 작업(예: 라운드 로빈)이 포함될 수 있고 에이전트 요청이 스케줄러에 의해 일시 중지될 수 있다고 가정합니다. 이 서스펜션은 LLM에 의해 아직 응답이 완전히 생성되지 않은 경우에도 발생한다. 따라서 LLM 생성 프로세스의 상태를 보존하여 자원이 다시 사용되면 정확하게 재개할 수 있도록 하는 메커니즘이 필요하다.

AIOS는 이 문제를 해결하기 위해 컨텍스트 관리자에서 스냅샷 및 복원 메커니즘을 제공하며, 이는 그림 4에서 볼 수 있다. 우리는 생성 디코딩 프로세스를 예시하기 위해 LLMs[10; 57; 58]의 전형적인 관행인 빔 탐색 프로세스9를 사용한다. 예시의 단순화를 위해 빔 폭을 1로 설정합니다. 구체적으로 에이전트 요청을 다음과 같이 간주합니다. _비행 UA057의 목적지에 비가 올지 여부를 결정합니다_. 각각의 단계에서, LLM은 다수의 잠재적인 후보들을 평가하고, 미리 정의된 빔 폭에 기초하여 추가 확장을 위해 가장 유망한 경로들이 유지된다.

각주 9: [https://en.wikipedia.org/wiki/Beam_search](https://en.wikipedia.org/wiki/Beam_search)

이러한 생성 프로세스가 중간 단계에서 스케줄러에 의해 중단되었을 때, 컨텍스트 관리자는 스냅샷 함수를 사용하여 응답을 생성하기 위해 탐색되는 모든 중간 확률 및 경로를 포함하는 LLM의 빔 탐색 트리의 현재 상태를 캡처하고 저장한다. 재시작 시 복원 함수를 사용하여 스냅샷에서 저장된 상태를 다시 로드하여 LLM이 중지 지점에서 정확히 생성 프로세스를 계속하여 최종 답변인 _파리의 날씨 검색_ 에 도달할 수 있습니다. 이러한 방식으로, 컨텍스트 관리자는 하나의 에이전트의 요청의 일시적인 중단이 진행의 손실로 이어지지 않도록 보장함으로써, 응답 생성의 품질 및 효율성을 손상시키지 않으면서 자원 사용을 최적화한다.

**컨텍스트 창 관리** LLM의 컨텍스트 창 제한을 초과하는 긴 컨텍스트에서 발생하는 문제를 해결하려면 컨텍스트 관리자도 컨텍스트 창의 잠재적인 확장을 관리해야 합니다. 구체적으로, AIOS에서의 컨텍스트 매니저는 기본적인 텍스트 요약을 지원하고, 컨텍스트 윈도우를 관리하기 위해 다른 확장 기법들을 통합한다[59; 60]. 이러한 방식으로 정보의 무결성 또는 관련성을 손상시키지 않으면서 광범위한 컨텍스트를 처리하고 이해하는 LLM의 능력을 향상시키는 데 도움이 될 수 있다.

### Memory Manager

그림 5에서 볼 수 있듯이 메모리 관리자는 에이전트의 수명 주기 내에서 단기 메모리를 관리하여 실행 대기 또는 런타임 중에 에이전트가 활성 상태인 경우에만 데이터가 저장되고 액세스할 수 있도록 합니다. 현재 AIOS는 각 에이전트의 메모리를 독립적으로 저장하도록 지원하며, 각 에이전트는 액세스 관리자에 의해 승인되지 않는 한 다른 에이전트에 직접 액세스하지 않는다. 에이전트 간의 공유 메모리 풀 또는 계층적 캐시와 같은 보다 복잡한 메모리 메커니즘이 고려되어 향후 AIOS에 통합될 수 있다. 다음에서 소개된 스토리지 매니저와 비교하여, 메모리 매니저는 신속한 데이터 검색 및 처리를 가능하게 하여, AIOS의 스토리지에 과도한 부담을 주지 않으면서 사용자 질의 및 상호 작용에 대한 신속한 응답을 용이하게 한다.

### Storage Manager

반면에 스토리지 관리자는 데이터의 장기 보존을 책임지고, 무기한으로 유지되어야 하는 정보의 저장을 감독하며, 임의의 활성 수명을 초과한다.

그림 5: 메모리 관리자 및 저장소 관리자와의 상호 작용 이력의 저장소.

단일 작용제. AIOS의 이러한 영구 저장소는 로컬 파일, 데이터베이스 또는 클라우드 기반 솔루션과 같은 다양한 내구성 있는 매체를 통해 달성되어 향후 참조 또는 분석을 위한 데이터 무결성 및 가용성을 보장합니다. 스토리지 관리자는 검색 증강을 지원한다[61]. 사용자 선호도들을 저장하고 이력 상호작용 로그들을 유지함으로써, 스토리지 관리자는 에이전트 지식 업데이트를 풍부하게 하고 장기 사용자 경험을 강화할 수 있다.

### Tool Manager

AIOS 시스템의 도구 관리자는 LLM의 기능을 향상시키는 다양한 API 도구를 관리한다. 도구 관리자는 표 1에서 보는 바와 같이 다양한 소스[7; 62; 63]에서 공통적으로 사용되는 도구를 통합하여 웹 검색, 과학 컴퓨팅, 데이터베이스 검색, 이미지 처리 등을 포괄하는 서로 다른 범주로 분류한다. 이러한 방식으로, 관리되는 도구들은 입력 및 출력(이미지 및 텍스트)의 상이한 양식들을 커버할 수 있고, 따라서 AIOS 생태계 내에서 에이전트 개발을 용이하게 한다.

### Access Manager

액세스 관리자는 각 에이전트에 대한 전용 권한 그룹을 관리하여 별개의 에이전트 간의 액세스 제어 작업을 오케스트레이션합니다. 에이전트의 권한 그룹에서 제외된 다른 에이전트는 상호 작용 기록과 같은 리소스에 대한 액세스가 거부됩니다. 시스템 투명성을 더욱 강화하기 위해 액세스 관리자는 감사 로그를 컴파일하고 유지합니다. 이 로그 캡처

\begin{table}
\begin{tabular}{l l l l} \hline \hline
**Category** & **Name** & **Description** & **Arguments** \\ \hline \multirow{6}{*}{Agent syscall} & get\_aid & get ID of an agent & - \\  & set\_aid & set ID of an agent & int aid \\  & get\_status & get status of an agent & int aid \\  & set\_status & get status of an agent & int aid, string status \\  & get\_priority & get priority of an agent & int aid \\  & set\_priority & set priority of an agent & int aid, int priority \\  & suspend\_agent & suspend agent’s operation & int aid \\  & resume\_agent & resume an agent’s operation & int aid \\ \hline \multirow{6}{*}{Context syscall} & gen\_snapshot & snapshot intermediate LLM generation status & - \\  & gen\_restore & restore intermediate LLM generation status & - \\  & get\_context & get context window length & - \\  & exp\_context & expand context window length & - \\  & clr\_context & clear current context window & - \\  & set\_context & set a specific context window & context c \\ \hline \multirow{3}{*}{Memory syscall} & mem\_write & write the interaction record into memory & int aid, memory m \\  & mem\_read & read the interaction record from memory & int aid, memory m \\  & mem\_clear & clear specific memory record & int aid, memory m \\  & mem\_alloc & allocate memory for an agent & int aid, size s \\ \hline \multirow{3}{*}{Storage syscall} & sto\_write & write the interaction record into storage & int aid, storage s \\  & sto\_read & load the interaction record from storage & int aid, storage s \\  & sto\_delete & delete the interaction record from storage & int aid, storage s \\  & sto\_alloc & allocate storage for an agent & int aid, size s \\ \hline \hline \end{tabular}
\end{table}
표 2: LLM 시스템 호출의 인스턴스.

\begin{table}
\begin{tabular}{l l l l} \hline \hline
**Category** & **Tool Name** & **Description** & **Input**\(\rightarrow\)**Output** \\ \hline \multirow{3}{*}{Search} & google\_search & search information by Google API & Image/Text \(\rightarrow\) Image/Text \\  & bing\_search & search information by Bing API & Image/Text \(\rightarrow\) Image/Text \\ \hline \multirow{3}{*}{Computation} & currency\_converter & currency converting & Text \(\rightarrow\) Text \\  & wolframelpha & mathematical computation & Image/Text \(\rightarrow\) Text \\ \hline \multirow{3}{*}{Database Query} & sql\_query & query data from SQL database & Text \(\rightarrow\) Text \\  & wikipedia\_query & query data from Wikipedia database & Text \(\rightarrow\) Text \\  & axriv\_search & query articles from Arxiv & Text \(\rightarrow\) Text \\  & words\_api & query definitions and synonyms of English words & Text \(\rightarrow\) Text \\  & urban\_dictionary & query random words, the current word of the day & Text \(\rightarrow\) Text \\ \hline \multirow{3}{*}{Image Processing} & image\_denoising & denoise images with noise & Image \(\rightarrow\) Text \\  & image\_deblurring & deblur images & Image \(\rightarrow\) Text \\ \cline{1-1}  & image\_classification & classify images & Image \(\rightarrow\) Text \\ \cline{1-1}  & object\_detection & detect objects in images & Image \(\rightarrow\) Text \\ \cline{1-1}  & face\_rect & detect faces in images by FaceRect API & Image \(\rightarrow\) Text \\ \hline \hline \end{tabular}
\end{table}
표 1: AIOS에서 관리되는 도구. 마지막 열에는 각 도구의 필수 입력 및 출력 형식이 표시됩니다.

액세스 요청들, 에이전트 활동들, 및 액세스 제어 파라미터들에 대한 임의의 수정들에 대한 상세한 정보는 잠재적인 권한 공격들로부터 보호하는 것을 돕는다[64; 65].

### LLM System Call

LLM 커널 내의 LLM 시스템 호출 인터페이스는 기본 LLM 호출 연산 기능을 제공하도록 설계되었다. 이 인터페이스는 복잡한 에이전트 요청과 다른 커널 모듈의 실행 사이의 브리지 역할을 한다. 표 2에 나타낸 바와 같이, OS 시스템 호출과 유사하게, LLM 시스템 호출은 에이전트 관리, 컨텍스트 핸들링, 메모리 및 스토리지 동작, 및 액세스 제어를 포함하는 커널의 모듈에 걸쳐 있는 일련의 기본 기능을 제공한다. LLM 시스템 호출 목록은 향후 더 많은 운영을 지원하기 위해 더 확장될 수 있다.

### Aios Sdk

AIOS SDK는 개발자에게 AIOS 내에서 정교한 에이전트 애플리케이션을 만들기 위한 다목적 툴킷을 제공하도록 설계되었습니다. 이 SDK는 에이전트 초기화 및 에이전트 수명 주기 관리에서 리소스 모니터링 및 에이전트 작업에 대한 생성 계획과 같은 복잡한 작업을 용이하게 하는 광범위한 기능을 포함합니다. 모든 운영 체제와 마찬가지로 SDK를 포괄적이고 개발자 친화적으로 강화하는 것은 장기적이고 끝없는 노력입니다. AIOS에서 지원되는 현재 SDK 기능은 표 3과 같으며, 이는 진화하는 에이전트 애플리케이션의 요구를 충족하기 위해 지속적으로 업데이트되고 확장될 것이다. 이러한 개발 노력은 AIOS 프레임워크 내에서 에이전트 애플리케이션의 잠재력을 최대한 활용하는 데 필요한 도구를 개발자에게 제공하는 것을 목표로 한다.

## 5 Evaluation

이 섹션에서는 AIOS에서 여러 에이전트가 병렬로 실행될 때 AIOS 모듈의 정확성과 성능을 모두 평가한다. 이 연구는 두 가지 연구 질문에 의해 유도된다: 첫째, 에이전트 요청에 대한 LLM 응답이 에이전트 중단 및 다른 에이전트로의 전환 후 일관성이 있는지 여부, 둘째, AIOS 스케줄링이 비스케줄(순차적) 실행에 비해 대기 및 처리 시간의 균형을 개선하는 데 있어 성능이 어떻게 되는지 여부.

### Setup

우리의 실험은 8개의 NVIDIA RTX A5000 GPU가 장착된 우분투 22.04 기계에서 PyTorch 2.0.1 및 CUDA 11.8과 함께 파이썬 3.9에서 수행된다. 우리는 AIOS의 백본으로 공개적으로 사용 가능한 LLM(즉, Gemma-2b-it 및 Gemma-7b-it [66], LLaMA-2-13b-chat-hf [10])을 사용한다. 이 선택은 오픈 소스 모델의 로컬 배치의 장점으로 구동되며, 이는 시간 지연의 정확한 측정에 도움이 된다. 평가를 위해 수학 과제를 해결하기 위한 수학 에이전트, 새로운 내러티브를 생성하기 위한 내러티브 에이전트, 레스토랑 추천을 제공하기 위한 Rec 에이전트의 세 가지 전문 에이전트를 구성했다. 각 에이전트는 실행 중에 백본 LLM에 2~3개의 요청을 보내도록 설계되었습니다.

### Experimental Results

일관성 분석.일관성 질문에 답하기 위해 먼저 구성된 3개의 에이전트를 개별적으로 실행하여 결과를 생성한다. 그 후, 우리는 이러한 에이전트를 병렬로 실행하여 캡처한다.

\begin{table}
\begin{tabular}{l l l} \hline \hline
**SDK Function Name** & **Description** & **Return Type** \\ \hline initializeAgent() & set up environment for agent execution, including resource allocation & Void \\ registerAgent() & register a new agent to the system, providing it with ID and permissions & Boolean \\ queueForExecution() & enqueue the agent for execution & Void \\ generatePlan() & generate a plan of a given agent task & Object \\ terminalAgent() & terminate an agent’s execution with cleanup & Void \\ createAgentSnapshot() & Create a snapshot of the agent’s current state for rollback & Object \\ rollbackAgentState() & Rollback the agent’s state to a previous snapshot & Void \\ updateAgentConfig() & update the configuration settings for an agent & Boolean \\ authenticateAgent() & authenticate an agent’s credentials before execution & Boolean \\ monitorResourceUsage() & track and report the usage of system resources by agents & Object \\ logEvent() & provide logging of agent-specific events for debugging and auditing & Void \\ listActiveAgents() & list all currently active agents within the system & List \\ queryAgentHistory() & query the historical operations of an agent & Object \\ encryptData() & encrypt sensitive data generated by an agent & Object \\ decryptData() & decrypt sensitive data for an agent’s consumption & Object \\ \hline \hline \end{tabular}
\end{table}
표 3: 각 단계에서 AIOS SDKtheir 출력의 SDK 함수 목록입니다. 여러 에이전트가 병렬로 실행되고 단일 에이전트가 하나씩 실행되었을 때 출력의 일관성을 평가하기 위해 BLEU 점수[67]와 BERT 점수[68]를 평가 메트릭으로 활용한다. 두 메트릭 모두 0.0에서 1.0까지 확장되며 단일 에이전트 컨텍스트에서 생성된 출력이 참조 표준 역할을 하며 무작위성의 영향을 제거하기 위해 온도 매개변수를 0으로 설정한다. 표 4에서 입증된 바와 같이, BLEU 및 BERT 스코어는 모두 1.0의 값을 달성하며, 이는 다중-에이전트 및 단일-에이전트 구성에서 생성된 출력들 사이의 완벽한 정렬을 나타낸다. 이 결과는 동시 다중 에이전트 작업을 효과적으로 지원하는 데 있어 설계의 일관성을 확인한다.

성능 분석.효율성 질문에 답하기 위해, 우리는 FIFO 스케줄링을 사용하는 AIOS와 앞서 언급한 세 에이전트가 동시에 실행되는 비스케줄드 접근법 간의 비교 분석을 수행한다. 예약되지 않은 설정에서 세 개의 에이전트는 미리 정의된 순차적 순서인 수학 에이전트, 내러티브 에이전트 및 Rec 에이전트에 따라 실행됩니다. 시간 효율성을 평가하기 위해 대기 시간(에이전트 요청 제출에서 시작까지의 간격)과 처리 시간(에이전트 요청 제출에서 완료까지의 기간)의 두 가지 메트릭을 사용한다. 각 에이전트가 LLM에 여러 요청을 보내기 때문에 각 에이전트의 대기 시간과 처리 시간은 전송된 모든 요청의 대기 시간과 처리 시간의 평균으로 각각 계산된다. 무작위성을 완화하기 위해 우리는 결과를 보고하기 위해 5개의 개별 시도에서 스케줄이 있거나 없는 이 세 가지 에이전트를 실행합니다. 표 5에 나타난 바와 같이, 스케쥴링되지 않은 접근법은 시퀀스 초기에 에이전트에 대해 양호한 성능을 나타내지만, 시퀀스 후에 에이전트에 대해 연장된 대기 시간 및 턴어라운드 시간을 희생시키면서, 반대로, AIOS의 스케줄링 메커니즘은 대기 시간과 턴어라운드 시간 모두를 효율적으로 규제하는데, 이는 특히 LLM이 클 때 에이전트에 의해 나중에 제출되는 에이전트 요청에 대해 특히 명백해지는 이점이다. 이는 여러 에이전트의 병렬 작업을 수용하기 위한 스케줄링의 중요성을 시사한다.

## 6 Conclusions

본 논문은 AIOS 아키텍처를 제안하여 LLM 기반 에이전트의 개발 및 배포를 촉진하고 보다 응집력 있고 효과적이며 효율적인 AIOS-Agent 생태계를 조성할 수 있는 가능성을 보여준다. 여기에 제시된 통찰력과 방법론은 AI 및 시스템 연구 모두에서 진행 중인 담론에 기여하여 AI 에이전트의 다양한 지형이 제기하는 통합 문제에 대한 실행 가능한 솔루션을 제공한다. 이러한 기반 위에 다양한 미래 작업이 구축될 수 있으며, LLM 에이전트를 개발하고 배치하는 진화하는 요구 사항을 충족하기 위해 AIOS 아키텍처를 개선하고 확장하는 혁신적인 방법을 모색할 수 있다.

## 7 Future Work

AIOS를 시작으로 향후 연구가 나아가야 할 방향들이 많다. 이 섹션에서는 AIOS의 기본 기능을 확장하는 잠재적인 연구 영역을 설명한다.

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline \multirow{2}{*}{LLM backbone} & \multicolumn{2}{c}{Math Agent} & \multicolumn{2}{c}{Narrative Agent} & \multicolumn{2}{c}{Rec Agent} \\ \cline{2-7}  & BLEU Score & BERT Score & BLEU Score & BERT Score & BLEU Score & BERT Score \\ \hline \hline Gemma-2b-it & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\ Gemma-7b-it & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\ LLaMA-2-13b-chat-hf & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\ \hline \hline \end{tabular}
\end{table}
표 4: 단일 에이전트를 하나씩 실행할 때 LLM 생성 응답과 비교하여 여러 에이전트를 병렬로 실행할 때 LLM 생성 응답의 일관성.

\begin{table}
\begin{tabular}{l l l c c c} \hline \hline \multirow{2}{*}{LLM backbone} & \multirow{2}{*}{Agent} & Sequential execution (non-scheduled) & \multicolumn{2}{c}{**Concurrent execution (scheduled)**} \\ \cline{3-6}  & & & Waiting time (s) & Turnaround time (s) & Waiting time (s) & Turnaround time (s) \\ \hline \multirow{3}{*}{Gemma-2b-it} & Math Agent & 0.002\(\pm\)0.001 & 2.71\(\pm\)0.53 & 2.50\(\pm\)0.05 & 4.18\(\pm\)0.18 \\  & Narrative Agent & 2.18\(\pm\)0.53 & 3.18\(\pm\)0.64 & 3.34\(\pm\)0.17 & 4.18\(\pm\)0.18 \\  & Rec Agent & 4.78\(\pm\)0.96 & 7.68\(\pm\)1.27 & 3.46\(\pm\)0.20 & 5.91\(\pm\)0.19 \\ \hline \multirow{3}{*}{Gemma-7b-it} & Math Agent & 0.002\(\pm\)0.001 & 4.95\(\pm\)0.10 & 5.92\(\pm\)0.01 & 10.75\(\pm\)0.19 \\  & Narrative Agent & 4.96\(\pm\)0.10 & 9.46\(\pm\)0.05 & 7.78\(\pm\)0.18 & 12.25\(\pm\)0.18 \\  & Rec Agent & 14.21\(\pm\)0.07 & 18.64\(\pm\)0.08 & 9.45\(\pm\)0.27 & 13.61\(\pm\)0.28 \\ \hline \multirow{3}{*}{LLaMA2-13b-chat-hf} & Math Agent & 0.003\(\pm\)0.001 & 18.48\(\pm\)0.34 & 23.27\(\pm\)0.21 & 40.02\(\pm\)2.01 \\  & Narrative Agent & 18.49\(\pm\)0.34 & 35.89\(\pm\)0.76 & 28.61\(\pm\)2.10 & 46.15\(\pm\)0.22 \\ \cline{1-1}  & Rec Agent & 53.86\(\pm\)1.15 & 71.62\(\pm\)1.26 & 34.92\(\pm\)2.22 & 52.44\(\pm\)2.43 \\ \hline \hline \end{tabular}
\end{table}
표 5: 스케줄링되지 않은(순차적) 실행과 비교하여, 에이전트 스케줄링의 효과성.

고급 스케줄링 알고리즘. AIOS의 스케줄링 기능은 보다 진보된 알고리즘 개발을 위한 토대를 마련한다. 향후 연구에서는 에이전트 요청 간의 종속성 분석을 수행하여 계산 자원 할당을 최적화하는 알고리즘에 초점을 맞출 수 있다. 또한, 도구 리소스 중 일부는 로컬로 배포된 모델이며, 이는 또한 스케줄링 패러다임에 통합될 수 있다. 여기에는 도구 상태 및 스냅샷 관리가 포함되며, 에이전트와 도구를 모두 포함하는 통일된 스케줄링 프레임워크로의 이동을 제안한다.

상황 관리의 효율성 상황 관리를 지원하기 위해 보다 효율적인 메커니즘이 고안될 수 있다. 예를 들어, 시간 효율적인 컨텍스트 관리 기술의 추구는 컨텍스트 스냅샷 및 복원의 프로세스를 신속하게 함으로써 사용자 경험을 크게 증가시킬 수 있다. 또한, 컨텍스트 압축 기술들은 또한 스냅샷팅 전에 레버리지될 수 있으며, 이는 보다 공간 효율적인 솔루션을 산출할 수 있다.

메모리 및 스토리지 아키텍처의 최적화 에이전트 협업 및 통신의 맥락에서, 향후 메모리 및 스토리지 시스템의 설계는 공유 접근법을 채택하여, 에이전트들 간의 메모리 및 스토리지의 공유를 가능하게 할 수 있다. 이러한 아키텍처는 에이전트가 메모리 및 저장소의 공동 풀에 액세스할 수 있게 하여, 한 에이전트가 다른 에이전트의 메모리 또는 저장소의 이점을 얻을 수 있기 때문에 에이전트의 의사 결정 능력을 향상시킬 수 있다. 또한, 향후 작업은 데이터 검색 및 스토리지 효율성을 최적화하도록 설계된 계층적 스토리지 솔루션을 탐색할 수 있습니다. 이것은 자주 액세스되는 데이터에 대해 더 빠른 액세스 및 감소된 스토리지 할당의 우선순위를 결정하는 것을 포함할 수 있고, 덜 자주 액세스되는 정보에 대해서는 그 반대의 경우도 마찬가지이다.

안전성 및 개인 정보 보호 향상 AIOS의 안전성 측면은 LLM을 탈옥하거나 다른 에이전트의 메모리를 무단 액세스하는 것과 같은 악의적인 공격에 대한 시스템의 복원력을 보장하는 다양한 공격에 대한 보호 조치를 필요로 한다. 프라이버시 영역에서 고급 암호화 기술에 대한 탐색은 AIOS 내에서 데이터 전송을 보호하여 에이전트 통신의 기밀성을 유지하는 데 필수적이다. 또한, 워터마킹 기술의 구현은 출력물에 고유한 식별자를 내장하여 데이터 계통의 추적을 용이하게 함으로써 에이전트 개발자의 지적 재산을 보호하는 역할을 할 수 있다.

네셸에서 AIOS는 광범위한 연구 기회를 가져오는 동기 부여 작업체로 서 있다. 개요된 각 방향은 AIOS의 기본 요소를 기반으로 할 뿐만 아니라 전반적인 분야의 발전에 기여할 수 있다.

## Acknowledgement

우리는 프로젝트 기간 동안 그들의 귀중한 토론과 제안에 대해 젠 장, 젠팅 왕, 그리고 원웨 화에게 감사한다.

## References

* [1] Michael Wooldridge and Nicholas R Jennings. Intelligent agents: Theory and practice. _The knowledge engineering review_, 10(2):115-152, 1995.
* [2] Nicholas R Jennings, Katia Sycara, and Michael Wooldridge. A roadmap of agent research and development. _Autonomous agents and multi-agent systems_, 1:7-38, 1998.
* [3] Paolo Bresciani, Anna Perini, Paolo Giorgini, Fausto Giunchiglia, and John Mylopoulos. Tropos: An agent-oriented software development methodology. _Autonomous Agents and Multi-Agent Systems_, 8:203-236, 2004.
* [4] OpenAI. Gpt-4. [https://openai.com/research/gpt-4](https://openai.com/research/gpt-4), 2023.
* [5] Facebook. Meta. introducing llama: A foundational, 65-billion-parameter large language model. [https://ai.facebook.com/blog/largelanguage-model-lllama-meta-ai](https://ai.facebook.com/blog/largelanguage-model-lllama-meta-ai), 2022.
* [6] Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. Gemini: a family of highly capable multimodal models. _arXiv preprint arXiv:2312.11805_, 2023.
* [7] Yingqiang Ge, Wenyue Hua, Kai Mei, Juntao Tan, Shuyuan Xu, Zelong Li, and Yongfeng Zhang. OpenAGI: When LLM Meets Domain Experts. _Advances in Neural Information Processing Systems_, 36, 2023.

* [8] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. _Advances in Neural Information Processing Systems_, 35:27730-27744, 2022.
* [9] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. _arXiv preprint arXiv:2210.11416_, 2022.
* [10] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. _arXiv preprint arXiv:2307.09288_, 2023.
* [11] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5). In _Proceedings of the 16th ACM Conference on Recommender Systems_, page 299-315, 2022.
* [12] Takeshi Kojima, Shixiang Shane Gu, Michel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. _Advances in neural information processing systems_, 35:22199-22213, 2022.
* [13] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. Codegen: An open large language model for code with multi-turn program synthesis. _arXiv preprint arXiv:2203.13474_, 2022.
* [14] Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. Galactica: A large language model for science. _arXiv preprint arXiv:2211.09085_, 2022.
* [15] Shibo Hao, Yi Gu, Haodi Ma, Joshua Hong, Zhen Wang, Daisy Wang, and Zhiting Hu. Reasoning with language model is planning with world model. In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pages 8154-8173, 2023.
* [16] Geunwoo Kim, Pierre Baldi, and Stephen McAleer. Language models can solve computer tasks. _Advances in Neural Information Processing Systems_, 36, 2023.
* [17] Steven I Ross, Fernando Martinez, Stephanie Houde, Michael Muller, and Justin D Weisz. The programmer's assistant: Conversational interaction with a large language model for software development. In _Proceedings of the 28th International Conference on Intelligent User Interfaces_, pages 491-514, 2023.
* [18] Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. Palm-e: an embodied multimodal language model. In _Proceedings of the 40th International Conference on Machine Learning_, pages 8469-8488, 2023.
* [19] Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, et al. Do as i can, not as is say: Grounding language in robotic affordances. In _Conference on robot learning_, pages 287-318. PMLR, 2023.
* [20] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. ReAct: Synergizing reasoning and acting in language models. _International Conference on Learning Representations_, 2023.
* [21] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. _Advances in Neural Information Processing Systems_, 36, 2023.
* [22] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. Mind2web: Towards a generalist agent for the web. _Advances in Neural Information Processing Systems_, 36, 2023.

* [23] UW:CSE451. History of Operating Systems, 2023. [https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf](https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf).
* [24] Dennis M. Ritchie and Ken Thompson. The unix time-sharing system. _Commun. ACM_, 17(7):365-375, jul 1974.
* [25] Charles Antony Richard Hoare. Monitors: An operating system structuring concept. _Communications of the ACM_, 17(10):549-557, 1974.
* [26] Dawson R Engler, M Frans Kaashoek, and James O'Toole Jr. Exokernel: An operating system architecture for application-level resource management. _ACM SIGOPS Operating Systems Review_, 29(5):251-266, 1995.
* [27] Chung Laung Liu and James W Layland. Scheduling algorithms for multiprogramming in a hard-real-time environment. _Journal of the ACM (JACM)_, 20(1):46-61, 1973.
* [28] Edsger W Dijkstra. Cooperating sequential processes. In _The origin of concurrent programming: from semaphores to remote procedure calls_, pages 65-138. Springer, 2002.
* [29] Peter J Denning. The working set model for program behavior. _Communications of the ACM_, 11(5):323-333, 1968.
* [30] Robert C Daley and Jack B Dennis. Virtual memory, processes, and sharing in multics. _Communications of the ACM_, 11(5):306-312, 1968.
* [31] Mendel Rosenblum and John K Ousterhout. The design and implementation of a log-structured file system. _ACM Transactions on Computer Systems (TOCS)_, 10(1):26-52, 1992.
* [32] Marshall K McKusick, William N Joy, Samuel J Leffler, and Robert S Fabry. A fast file system for unix. _ACM Transactions on Computer Systems (TOCS)_, 2(3):181-197, 1984.
* [33] Yingqiang Ge, Yujie Ren, Wenyue Hua, Shuyuan Xu, Juntao Tan, and Yongfeng Zhang. LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem. _arXiv:2312.03815_, 2023.
* [34] Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. _arXiv preprint arXiv:2302.04761_, 2023.
* [35] Shunyu Yao and Karthik Narasimhan. Language agents in the digital world: Opportunities and risks. _princeton-nlp.github.io_, Jul 2023.
* [36] Aaron Parisi, Yao Zhao, and Noah Fiedel. Talm: Tool augmented language models. _arXiv preprint arXiv:2205.12255_, 2022.
* [37] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, and Le Sun. Toolalpaca: Generalized tool learning for language models with 3000 simulated cases. _arXiv preprint arXiv:2306.05301_, 2023.
* [38] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt: Browser-assisted question-answering with human feedback, 2022.
* [39] Kechi Zhang, Ge Li, Jia Li, Zhuo Li, and Zhi Jin. Toolcoder: Teach code generation models to use apis with search tools. _arXiv preprint arXiv:2305.04032_, 2023.
* [40] Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar. Minedjo: Building open-ended embodied agents with internet-scale knowledge. _Advances in Neural Information Processing Systems_, 35:18343-18362, 2022.

* [41] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. In _Intrinsically-Motivated and Open-Ended Learning Workshop@ NeurIPS2023_, 2023.
* [42] Daniil A Boiko, Robert MacKnight, and Gabe Gomes. Emergent autonomous scientific research capabilities of large language models. _arXiv preprint arXiv:2304.05332_, 2023.
* [43] Andres M Bran, Sam Cox, Andrew D White, and Philippe Schwaller. Chemcrow: Augmenting large-language models with chemistry tools. _arXiv preprint arXiv:2304.05376_, 2023.
* [44] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In _International Conference on Machine Learning_, pages 9118-9147. PMLR, 2022.
* [45] Jiannan Xiang, Tianhua Tao, Yi Gu, Tianmin Shu, Zirui Wang, Zichao Yang, and Zhiting Hu. Language models meet world models: Embodied experiences enhance language models. _Advances in neural information processing systems_, 36, 2023.
* [46] Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbulilin, and Bernard Ghanem. Camel: Communicative agents for "mind" exploration of large language model society. _Advances in Neural Information Processing Systems_, 36, 2023.
* [47] Joon Sung Park, Joseph O'Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. In _Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology_, pages 1-22, 2023.
* [48] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, et al. Metagpt: Meta programming for multi-agent collaborative framework. In _The Twelfth International Conference on Learning Representations_, 2023.
* [49] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun. Communicative agents for software development. _arXiv preprint arXiv:2307.07924_, 2023.
* [50] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. _arXiv preprint arXiv:2308.08155_, 2023.
* [51] Martin Josifoski, Lars Klein, Maxime Peyrard, Yifei Li, Saibo Geng, Julian Paul Schnitzler, Yuxing Yao, Jiheng Wei, Debjit Paul, and Robert West. Flows: Building blocks of reasoning and collaborating ai. _arXiv preprint arXiv:2308.01285_, 2023.
* [52] Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata. Improving language model negotiation with self-play and in-context learning from ai feedback. _arXiv preprint arXiv:2305.10142_, 2023.
* [53] Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. Improving factuality and reasoning in language models through multiagent debate. _arXiv preprint arXiv:2305.14325_, 2023.
* [54] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. Chateval: Towards better llm-based evaluators through multi-agent debate. In _The Twelfth International Conference on Learning Representations_, 2023.
* [55] Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-agent debate. _arXiv preprint arXiv:2305.19118_, 2023.
* [56] Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge, Libby Hemphill, and Yongfeng Zhang. War and peace (waragent): Large language model-based multi-agent simulation of world wars. _arXiv preprint arXiv:2311.17227_, 2023.

* [57] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. _arXiv preprint arXiv:2310.06825_, 2023.
* [58] Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O'Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, et al. Pythia: A suite for analyzing large language models across training and scaling. In _International Conference on Machine Learning_, pages 2397-2430. PMLR, 2023.
* [59] Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. Extending context window of large language models via positional interpolation. _arXiv preprint arXiv:2306.15595_, 2023.
* [60] Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. Yarn: Efficient context window extension of large language models. _arXiv preprint arXiv:2309.00071_, 2023.
* [61] Gregoire Mialon, Roberto Dessi, Maria Lomeli, Christoforos Nalmpantis, Ramakanth Pasunuru, Roberta Raileanu, Baptiste Roziere, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. Augmented language models: a survey. _Transactions on Machine Learning Research_, 2023.
* [62] LangChain. Langchain. [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain), 2024.
* [63] Rapid. Rapid api hub. [https://rapidapi.com/hub](https://rapidapi.com/hub), 2024.
* [64] Ken Thompson. Reflections on trusting trust. _Communications of the ACM_, 27(8):761-763, 1984.
* [65] Sven Bugiel, Lucas Davi, Alexandra Dmitrienko, Thomas Fischer, Ahmad-Reza Sadeghi, and Bhargava Shastry. Towards taming privilege-escalation attacks on android. In _NDSS_, volume 17, page 19, 2012.
* [66] Tris Warkentin Jeanine Banks. Gemma: Introducing new state-of-the-art open models. [https://blog.google/technology/developers/gemma-open-models/](https://blog.google/technology/developers/gemma-open-models/), 2024.
* [67] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In _Proceedings of the 40th annual meeting of the Association for Computational Linguistics_, pages 311-318, 2002.
* [68] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. Bertscore: Evaluating text generation with bert. _arXiv preprint arXiv:1904.09675_, 2019.
