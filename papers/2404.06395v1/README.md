# 2404.06395v1 MiniCPM Unveiling the Potential of Small Language Models with Scalable Training Strategies

[ArXiv Version](https://arxiv.org/abs/2404.06395v1)

Arxiv HTML version may not be shown if they don't provide HTML version.

[Arxiv HTML English Version](https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2404.06395v1/paper.raw.en.html)

[Arxiv HTML Korean Version](https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2404.06395v1/paper.raw.ko.html)

You can also access Ar5iv version if they provide.
Note that Ar5iv update their DB at the end of the month.
Thus, Ar5iv version would not be available, if it was added before Ar5iv's update.

[Ar5iv Original](https://ar5iv.org/abs/2404.06395v1)

[Ar5iv HTML English Version](https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2404.06395v1/paper.ar5iv.en.html)

[Ar5iv HTML Korean Version](https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2404.06395v1/paper.ar5iv.ko.html)

Below is naive version using Nougat OCR, which only contains text, including table.

[English Version](https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2404.06395v1/paper.en.html)

[Korean Version](https://raw.githack.com/kh-kim/arxiv-translator/master/papers/2404.06395v1/paper.ko.html)