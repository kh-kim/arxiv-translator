<html lang="en" data-theme="dark"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey</title>
<!--Generated on Wed May  1 15:10:54 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/addons_new.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="https://arxiv.org/html/2404.11584v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2404.11584v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="Dark mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2404.11584v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2404.11584v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC mobile collapse" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S1" title="In The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S1.SS1" title="In 1 Introduction ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Taxonomy</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S2" title="In The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Key Considerations for Effective Agents</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S2.SS1" title="In 2 Key Considerations for Effective Agents ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S2.SS2" title="In 2 Key Considerations for Effective Agents ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>The Importance of Reasoning and Planning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S2.SS3" title="In 2 Key Considerations for Effective Agents ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>The Importance of Effective Tool Calling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S3" title="In The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Single Agent Architectures</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S3.SS1" title="In 3 Single Agent Architectures ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S3.SS2" title="In 3 Single Agent Architectures ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Key Themes</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S3.SS3" title="In 3 Single Agent Architectures ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Examples</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S4" title="In The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Multi Agent Architectures</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S4.SS1" title="In 4 Multi Agent Architectures ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S4.SS2" title="In 4 Multi Agent Architectures ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Key Themes</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S4.SS3" title="In 4 Multi Agent Architectures ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Examples</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S5" title="In The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion and Observations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S5.SS1" title="In 5 Discussion and Observations ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S5.SS2" title="In 5 Discussion and Observations ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Key Findings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S5.SS3" title="In 5 Discussion and Observations ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Summary</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S6" title="In The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations of Current Research and Considerations for Future Research</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S6.SS1" title="In 6 Limitations of Current Research and Considerations for Future Research ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S6.SS2" title="In 6 Limitations of Current Research and Considerations for Future Research ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Challenges with Agent Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S6.SS3" title="In 6 Limitations of Current Research and Considerations for Future Research ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Impact of Data Contamination and Static Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S6.SS4" title="In 6 Limitations of Current Research and Considerations for Future Research ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Benchmark Scope and Transferability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S6.SS5" title="In 6 Limitations of Current Research and Considerations for Future Research ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5 </span>Real-world Applicability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S6.SS6" title="In 6 Limitations of Current Research and Considerations for Future Research ‣ The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.6 </span>Bias and Fairness in Agent Systems</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.11584v1#S7" title="In The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion and Future Directions</span></a></li>
</ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert" onclick="closePopup()">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: biblatex</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0</a><div id="watermark-tr">arXiv:2404.11584v1 [cs.AI] 17 Apr 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\addbibresource</span>
<p class="ltx_p" id="p1.2">references.bib</p>
</div>
<h1 class="ltx_title ltx_title_document">The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey
</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Tula Masterman* 
<br class="ltx_break">Neudesic, an IBM Company 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">tula.masterman@neudesic.com</span>
<br class="ltx_break"><span class="ltx_ERROR undefined" id="id2.2.id2">\And</span>Sandi Besen* 
<br class="ltx_break">IBM 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">sandi.besen@ibm.com</span>
<br class="ltx_break"><span class="ltx_ERROR undefined" id="id4.4.id4">\AND</span>Mason Sawtell* 
<br class="ltx_break">Neudesic, an IBM Company 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id5.5.id5">mason.sawtell@neudesic.com</span>
<br class="ltx_break">
<br class="ltx_break">* Denotes Equal Contribution
<span class="ltx_ERROR undefined" id="id6.6.id6">\And</span>Alex Chao 
<br class="ltx_break">Microsoft 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id7.7.id7">achao@microsoft.com</span>
<br class="ltx_break">
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id8.id1">본 논문은 AI 에이전트 구현의 최근 발전을 살펴보고, 향상된 추론, 계획 및 도구 실행 기능이 필요한 복잡한 목표를 달성하는 능력에 초점을 맞춘다. 이 작업의 주요 목적은 a) 기존 AI 에이전트 구현의 현재 기능과 한계를 전달하고, b) 이러한 시스템의 관찰에서 얻은 통찰력을 공유하며, c) AI 에이전트 설계의 향후 개발을 위한 중요한 고려 사항을 제안하는 것이다. 이를 위해 단일 에이전트 및 다중 에이전트 아키텍처에 대한 개요를 제공하고, 설계 선택에서 주요 패턴과 분기점을 식별하고, 제공된 목표를 달성하는 데 미치는 전반적인 영향을 평가합니다. 우리의 기여는 강력한 AI 에이전트 시스템을 가능하게 하는 계획, 실행 및 반성을 위한 에이전트 아키텍처, 리더십이 에이전트 시스템에 미치는 영향, 에이전트 커뮤니케이션 스타일 및 주요 단계를 선택할 때 주요 주제를 설명한다.</p>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotetext: </span>The opinions expressed in this paper are solely those of the authors and do not necessarily reflect the views or policies of their respective employers.</span></span></span>
<div class="ltx_para ltx_noindent" id="p2">
<p class="ltx_p" id="p2.9"><em class="ltx_emph ltx_font_bold ltx_font_italic" id="p2.9.1">K</em><span class="ltx_text ltx_font_bold" id="p2.9.2">eywords</span> AI Agent &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p2.1.m1.1"><semantics id="p2.1.m1.1a"><mo id="p2.1.m1.1.1" xref="p2.1.m1.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.1.m1.1b"><ci id="p2.1.m1.1.1.cmml" xref="p2.1.m1.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.1.m1.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.1.m1.1d">⋅</annotation></semantics></math> Agent Architecture &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p2.2.m2.1"><semantics id="p2.2.m2.1a"><mo id="p2.2.m2.1.1" xref="p2.2.m2.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.2.m2.1b"><ci id="p2.2.m2.1.1.cmml" xref="p2.2.m2.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.2.m2.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.2.m2.1d">⋅</annotation></semantics></math> AI Reasoning &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p2.3.m3.1"><semantics id="p2.3.m3.1a"><mo id="p2.3.m3.1.1" xref="p2.3.m3.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.3.m3.1b"><ci id="p2.3.m3.1.1.cmml" xref="p2.3.m3.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.3.m3.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.3.m3.1d">⋅</annotation></semantics></math> Planning &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p2.4.m4.1"><semantics id="p2.4.m4.1a"><mo id="p2.4.m4.1.1" xref="p2.4.m4.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.4.m4.1b"><ci id="p2.4.m4.1.1.cmml" xref="p2.4.m4.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.4.m4.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.4.m4.1d">⋅</annotation></semantics></math> Tool Calling &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p2.5.m5.1"><semantics id="p2.5.m5.1a"><mo id="p2.5.m5.1.1" xref="p2.5.m5.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.5.m5.1b"><ci id="p2.5.m5.1.1.cmml" xref="p2.5.m5.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.5.m5.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.5.m5.1d">⋅</annotation></semantics></math> Single Agent &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p2.6.m6.1"><semantics id="p2.6.m6.1a"><mo id="p2.6.m6.1.1" xref="p2.6.m6.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.6.m6.1b"><ci id="p2.6.m6.1.1.cmml" xref="p2.6.m6.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.6.m6.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.6.m6.1d">⋅</annotation></semantics></math> Multi Agent &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p2.7.m7.1"><semantics id="p2.7.m7.1a"><mo id="p2.7.m7.1.1" xref="p2.7.m7.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.7.m7.1b"><ci id="p2.7.m7.1.1.cmml" xref="p2.7.m7.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.7.m7.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.7.m7.1d">⋅</annotation></semantics></math> Agent Survey &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p2.8.m8.1"><semantics id="p2.8.m8.1a"><mo id="p2.8.m8.1.1" xref="p2.8.m8.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.8.m8.1b"><ci id="p2.8.m8.1.1.cmml" xref="p2.8.m8.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.8.m8.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.8.m8.1d">⋅</annotation></semantics></math> LLM Agent &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p2.9.m9.1"><semantics id="p2.9.m9.1a"><mo id="p2.9.m9.1.1" xref="p2.9.m9.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p2.9.m9.1b"><ci id="p2.9.m9.1.1.cmml" xref="p2.9.m9.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p2.9.m9.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p2.9.m9.1d">⋅</annotation></semantics></math> Autonomous Agent</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">ChatGPT가 출시된 이후, 생성 AI 응용의 많은 첫 번째 물결은 RAG(Retrieval Augmented Generation) 패턴을 사용하는 문서 코퍼스에 대한 채팅의 변형이다. RAG 시스템을 더 견고하게 만드는 활동이 많은 반면, 다양한 그룹은 공통 주제인 에이전트를 중심으로 차세대 AI 애플리케이션이 어떻게 보일지 구축하기 시작하고 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">GPT-4와 같은 최신 기반 모델에 대한 조사를 시작으로 AutoGPT 및 BabyAGI와 같은 오픈 소스 프로젝트를 통해 대중화된 연구 커뮤니티는 자율 에이전트 기반 시스템 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">nakajima_yoheinakajimababyagi_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">birr_autogptp_2024</span>]</cite>를 구축하는 실험을 수행했다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">사용자가 개방형 텍스트 필드에 입력하고 추가 입력 없이 결과를 얻는 대규모 언어 모델의 제로 샷 프롬프트와 달리 에이전트는 보다 복잡한 상호 작용 및 오케스트레이션을 허용한다. 특히, 에이전트 시스템은 계획, 루프, 반사 및 다른 제어 구조의 개념을 가지고 있으며, 이는 모델의 고유한 추론 능력을 크게 활용하여 태스크를 종단 간 달성한다. 도구, 플러그인 및 기능 호출을 사용할 수 있는 기능과 함께 에이전트는 보다 범용적인 작업을 수행할 수 있는 권한을 부여받습니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">커뮤니티 중에는 단일 또는 다중 에이전트 시스템이 복잡한 작업을 해결하는 데 가장 적합한지에 대한 현재 논쟁이 있다. 단일 에이전트 아키텍처는 문제가 잘 정의되고 다른 에이전트 퍼소나 사용자의 피드백이 필요하지 않을 때 탁월하지만, 다중 에이전트 아키텍처는 협업과 여러 개의 별개의 실행 경로가 필요할 때 더 번창하는 경향이 있다.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="337" id="S1.F1.g1" src="https://arxiv.org/html/2404.11584v1/extracted/2404.11584v1/media/agent_comparison.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 1:</span>A visualization of single and multi-agent architecture with their underlying features and abilities</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Taxonomy</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.SS1.p1.1.1">Agents</span>. AI 에이전트는 여러 번의 반복을 통해 목표를 실행하기 위해 계획하고 조치를 취할 수 있는 언어 모델 기반 엔티티이다. AI 에이전트 아키텍처는 단일 에이전트 또는 문제를 해결하기 위해 함께 작동하는 여러 에이전트로 구성된다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p2">
<p class="ltx_p" id="S1.SS1.p2.1">일반적으로 각 에이전트에는 독립적으로 또는 팀의 일부로 작업을 수행하는 데 도움이 되는 다양한 도구에 대한 페르소나와 액세스 권한이 부여됩니다. 일부 에이전트에는 메시지 및 프롬프트 외부에 정보를 저장하고 로드할 수 있는 메모리 구성 요소도 포함되어 있습니다. 본 논문에서는 "뇌, 지각, 행동" <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xi2023rise</span>]</cite>로 구성된 에이전트의 정의를 따른다. 이러한 구성 요소는 에이전트가 주변 환경을 이해하고 추론하고 행동하기 위한 최소 요구 사항을 충족한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p3">
<p class="ltx_p" id="S1.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S1.SS1.p3.1.1">Agent Persona</span>. 에이전트 페르소나는 에이전트에 특정한 다른 지침을 포함하여 에이전트가 수행해야 하는 역할 또는 개성을 설명합니다. 개인에는 에이전트가 액세스할 수 있는 모든 도구에 대한 설명도 포함되어 있습니다. 그들은 에이전트에게 자신의 역할, 도구의 목적 및 효과적으로 활용하는 방법을 인식하게 한다. 연구자들은 “모양의 성격은 소셜 미디어 게시물 작성과 같은 공통 다운스트림(즉, 후속) 작업에서 LLM(Large Language Model) 행동에 검증 가능하게 영향을 미친다” <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">serapiogarcía2023personality</span>]</cite>를 발견했다. 여러 에이전트 페르소나를 사용하여 문제를 해결하는 솔루션은 모델이 단계적으로 계획을 분해하도록 요청되는 CoT(Chain-of-Think) 프롬프트에 비해 상당한 개선을 보여준다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p4">
<p class="ltx_p" id="S1.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S1.SS1.p4.1.1">Tools</span>. AI 에이전트의 맥락에서 도구는 모델이 호출할 수 있는 모든 기능을 나타낸다. 에이전트가 해당 소스에 정보를 끌어당기거나 푸시하여 외부 데이터 소스와 상호 작용할 수 있습니다. 에이전트 페르소나 및 관련 도구의 예로는 전문 계약 작성자가 있습니다. 작가는 자신의 역할과 수행해야 할 작업의 유형을 설명하는 페르소나를 부여받는다. 또한 문서에 메모를 추가하거나 기존 문서를 읽거나 최종 초안이 포함된 이메일을 보내는 것과 관련된 도구가 제공됩니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p5">
<p class="ltx_p" id="S1.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S1.SS1.p5.1.1">Single Agent Architectures</span>. 이러한 아키텍처는 하나의 언어 모델에 의해 구동되며 추론, 계획 및 도구 실행을 모두 자체적으로 수행할 것입니다. 에이전트에는 시스템 프롬프트와 작업을 완료하는 데 필요한 모든 도구가 제공됩니다. 단일 에이전트 패턴에는 다른 AI 에이전트의 피드백 메커니즘이 없지만 인간이 에이전트를 안내하는 피드백을 제공할 수 있는 옵션이 있을 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p6">
<p class="ltx_p" id="S1.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S1.SS1.p6.1.1">Multi-Agent Architectures</span>. 이들 아키텍처는 둘 이상의 에이전트를 포함하며, 여기서 각각의 에이전트는 동일한 언어 모델 또는 상이한 언어 모델의 세트를 이용할 수 있다. 에이전트는 동일한 도구 또는 다른 도구에 액세스할 수 있습니다. 각 에이전트는 일반적으로 고유한 페르소나를 가지고 있습니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p7">
<p class="ltx_p" id="S1.SS1.p7.1">멀티 에이전트 아키텍처는 모든 수준의 복잡성에서 매우 다양한 조직을 가질 수 있습니다. 본 논문에서는 이를 수직과 수평의 두 가지 주요 범주로 나눈다. 이러한 범주는 스펙트럼의 두 끝을 나타내며, 대부분의 기존 아키텍처는 이 두 극단 사이의 어딘가에 있다는 것을 명심하는 것이 중요하다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p8">
<p class="ltx_p" id="S1.SS1.p8.1"><span class="ltx_text ltx_font_bold" id="S1.SS1.p8.1.1">Vertical Architectures</span>. 이 구조에서 한 에이전트가 리더 역할을 하고 다른 에이전트가 직접 그들에게 보고하도록 한다. 아키텍처에 따라 보고 에이전트는 리드 에이전트와 독점적으로 통신할 수 있습니다. 대안적으로, 리더는 모든 에이전트들 사이의 공유된 대화로 정의될 수 있다. 수직 아키텍처의 정의 기능은 납 에이전트와 협업 에이전트 간의 명확한 분업화를 포함한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p9">
<p class="ltx_p" id="S1.SS1.p9.1"><span class="ltx_text ltx_font_bold" id="S1.SS1.p9.1.1">Horizontal Architectures</span>. 이 구조에서 모든 에이전트는 동등하게 취급되며 과제에 대한 한 그룹 토론의 일부이다. 에이전트 간의 통신은 각 에이전트가 다른 에이전트의 모든 메시지를 볼 수 있는 공유 스레드에서 발생합니다. 에이전트는 또한 특정 작업을 완료하거나 도구를 호출하기 위해 자원할 수 있으며, 이는 선두 에이전트에 의해 할당될 필요가 없음을 의미합니다. 수평 아키텍처는 일반적으로 협업, 피드백 및 그룹 토론이 태스크 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen_agentverse_2023</span>]</cite>의 전반적인 성공에 핵심이 되는 태스크에 사용된다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Key Considerations for Effective Agents</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Overview</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">에이전트는 실제 문제를 해결하기 위해 언어 모델 기능을 확장하도록 설계되었습니다. 성공적인 구현에는 에이전트가 새로운 작업에 대해 잘 수행할 수 있는 강력한 문제 해결 기능이 필요합니다. 실제 문제를 효과적으로 해결하기 위해 에이전트는 외부 환경과 상호 작용하는 도구를 호출할 뿐만 아니라 추론하고 계획하는 능력이 필요하다. 이 섹션에서는 추론, 계획 및 도구 호출이 에이전트 성공에 중요한 이유를 탐구합니다.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>The Importance of Reasoning and Planning</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">추론은 인간 인식의 기본 구성 요소이며, 사람들이 우리 주변의 세상을 결정하고, 문제를 해결하고, 이해할 수 있게 한다. AI 에이전트는 복잡한 환경과 효과적으로 상호 작용하고 자율적인 결정을 내리고 광범위한 작업에서 인간을 돕는다면 추론할 수 있는 강력한 능력이 필요하다. "행동"과 "추론" 사이의 이러한 타이트한 시너지는 새로운 태스크들이 빠르게 학습될 수 있게 하고, 이전에 보이지 않았던 상황들 또는 정보 불확실성들 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yao_react_2023</span>]</cite>에서도 강건한 의사 결정 또는 추론을 가능하게 한다. 또한 에이전트는 새로운 피드백이나 학습된 정보를 기반으로 계획을 조정하기 위한 추론이 필요하다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">추론 능력이 부족한 에이전트가 간단한 작업에 대해 작업하는 경우 쿼리를 잘못 해석하거나 문자 그대로의 이해를 기반으로 응답을 생성하거나 다단계 의미를 고려하지 않을 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">강력한 추론 능력을 요구하는 계획은 일반적으로 과제 분해, 다중 계획 선택, 외부 모듈 지원 계획, 반영 및 개선 및 메모리 증강 계획 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2024understanding</span>]</cite>의 다섯 가지 주요 접근법 중 하나에 속한다. 이러한 접근법을 통해 모델은 태스크를 하위 태스크로 세분화하고, 생성된 많은 옵션에서 하나의 플랜을 선택하거나, 기존 외부 플랜을 활용하거나, 새로운 정보를 기반으로 이전 플랜을 수정하거나, 플랜을 개선하기 위해 외부 정보를 활용할 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">대부분의 에이전트 패턴들은 임의의 액션들이 실행되기 전에 계획을 생성하기 위해 이들 기법들 중 하나 이상을 호출하는 전용 계획 단계를 갖는다. 예를 들어, Plan Like a Graph (PLaG)는 계획들을 방향성 그래프로 표현하는 접근법으로서, 다수의 단계들이 병렬 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lin_graph-enhanced_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yao_tree_2023</span>]</cite>로 실행된다. 이는 비동기 실행의 이점을 얻는 많은 독립적인 하위 작업을 포함하는 작업에서 다른 방법에 비해 상당한 성능 증가를 제공할 수 있다.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>The Importance of Effective Tool Calling</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">기본 언어 모델을 프롬프트하는 것보다 에이전트 추상화의 한 가지 중요한 이점은 여러 도구를 호출하여 복잡한 문제를 해결하는 에이전트의 능력이다. 이러한 도구를 사용하면 에이전트가 외부 데이터 원본과 상호 작용하거나 기존 API에서 정보를 보내거나 검색할 수 있습니다. 광범위한 도구 호출이 필요한 문제는 복잡한 추론이 필요한 문제와 병행되는 경우가 많다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">단일 에이전트 및 다중 에이전트 아키텍처는 추론 및 도구 호출 단계를 사용하여 어려운 작업을 해결하는 데 사용할 수 있다. 많은 방법은 문제 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu_llm_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shinn_reflexion_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yao_react_2023</span>]</cite>를 효과적이고 정확하게 완성하기 위해 추론, 기억, 반성의 여러 반복을 사용한다. 그들은 종종 더 큰 문제를 더 작은 하위 문제로 분해한 다음 적절한 도구를 차례로 사용하여 각각을 해결함으로써 이 작업을 수행합니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">에이전트 패턴을 발전시키는 데 초점을 맞춘 다른 작업은 더 큰 문제를 더 작은 하위 문제로 분해하는 것이 복잡한 작업을 해결하는 데 효과적일 수 있지만 단일 에이전트 패턴은 종종 필요한 긴 시퀀스 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shi_learning_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gao_efficient_2024</span>]</cite>를 완료하는 데 어려움을 겪는다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1">다중 에이전트 패턴은 개별 에이전트가 개별 하위 문제에 대해 작업할 수 있기 때문에 병렬 작업과 견고성의 문제를 해결할 수 있다. 많은 다중 에이전트 패턴은 복잡한 문제를 취하여 여러 작은 작업으로 분해하는 것으로 시작한다. 그런 다음 각 에이전트는 자신의 독립적인 도구 세트를 사용하여 각 작업을 독립적으로 해결합니다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Single Agent Architectures</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Overview</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">이 섹션에서는 ReAct, RAISE, 반사, AutoGPT + P 및 LATS와 같은 몇 가지 주목할 만한 단일 에이전트 방법을 강조한다. 이러한 방법들 각각은 목표를 진전시키기 위해 임의의 액션이 취해지기 전에 문제에 대한 추론을 위한 전용 스테이지를 포함한다. 에이전트의 추론 및 도구 호출 기능에 대한 기여도를 기반으로 이러한 방법을 선택했다.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Key Themes</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">우리는 에이전트에 의한 성공적인 목표 실행이 적절한 계획과 자기 수정 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yao_react_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu_llm_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shinn_reflexion_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">birr_autogptp_2024</span>]</cite>에 따라 결정된다는 것을 발견했다. 효과적인 계획을 스스로 평가하고 생성할 수 있는 능력이 없으면 단일 에이전트는 끝없는 실행 루프에 갇혀 주어진 작업을 결코 달성하지 못하거나 사용자의 기대 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yao_react_2023</span>]</cite>를 충족하지 못하는 결과를 반환할 수 있다. 단일 에이전트 아키텍처는 태스크가 간단한 함수 호출을 필요로 하고 다른 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shi_learning_2024</span>]</cite>의 피드백이 필요하지 않을 때 특히 유용하다는 것을 발견했다.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Examples</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.1">ReAct. </span> ReAct(Reason + Act) 방법에서 에이전트는 먼저 주어진 작업에 대한 생각을 작성한다. 그런 다음 해당 사고를 기반으로 작업을 수행하고 출력이 관찰됩니다. 이 사이클은 작업이 완료될 때까지 반복될 수 있다 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yao_react_2023</span>]</cite>. 다양한 언어 및 의사 결정 작업에 적용할 때 ReAct 방법은 동일한 작업에 대한 제로 샷 프롬프트에 비해 향상된 효과를 보여준다. 또한 모델의 전체 사고 과정이 기록되기 때문에 향상된 인간 상호 운용성과 신뢰성을 제공합니다. HotpotQA 데이터 세트에서 평가했을 때 ReAct 방법은 6%의 시간만을 환각시켰지만 CoT(Cain of thought) 방법 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wei_chain--thought_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yao_react_2023</span>]</cite>를 사용한 14%와 비교되었다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">그러나 ReAct 방식은 그 한계가 없는 것은 아니다. 추론, 관찰 및 행동이 얽혀 신뢰성이 향상되지만 모델은 동일한 생각과 행동을 반복적으로 생성하고 새로운 생각을 생성하지 못하여 작업을 끝내고 ReAct 루프를 빠져나갈 수 있다. 과제의 실행 동안 인간 피드백을 통합하면 실제 시나리오에서 효과성과 적용 가능성이 증가할 수 있다.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F2.g1" src="">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 2:</span>ReAct 방법의 일 예를 다른 방법과 비교한 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yao_react_2023</span>]</cite></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">RAISE. </span> RAISE 방법은 ReAct 방법을 기반으로 하며, 인간의 단기 및 장기 메모리 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu_llm_2024</span>]</cite>를 미러링하는 메모리 메커니즘을 추가한다. 이는 단기 저장을 위한 스크래치 패드와 장기 저장을 위한 유사한 이전 예제의 데이터 세트를 사용하여 수행한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1">이러한 컴포넌트를 추가함으로써, RAISE는 더 긴 대화에서 컨텍스트를 유지하는 에이전트의 능력을 향상시킨다. 또한 더 작은 모델을 사용하는 경우에도 모델을 미세 조정하면 작업에 가장 좋은 성능을 얻을 수 있음을 강조합니다. 그들은 또한 RAISE가 효율성과 출력 품질 모두에서 ReAct보다 우수하다는 것을 보여주었다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1">RAISE는 일부 측면에서 기존 방법을 크게 개선하지만 연구진도 몇 가지 문제를 강조했다. 첫째, RAISE는 복잡한 논리를 이해하기 위해 고군분투하여 많은 시나리오에서 유용성을 제한한다. 또한, RAISE 에이전트는 종종 그들의 역할이나 지식과 관련하여 환각을 본다. 예를 들어, 명확하게 정의된 역할이 없는 판매 에이전트는 파이썬에서 코드를 작성하는 기능을 유지할 수 있으며, 이를 통해 판매 작업에 초점을 맞추는 대신 파이썬 코드 작성을 시작할 수 있습니다. 이러한 에이전트는 사용자에게 오판의 소지가 있거나 잘못된 정보를 제공할 수도 있습니다. 이 문제는 모델을 미세 조정함으로써 해결되었지만 연구자들은 여전히 RAISE 구현의 한계로 환각을 강조했다.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F3.g1" src="">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 3:</span>A diagram showing RAISE method <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu_llm_2024</span>]</cite></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p6.1.1">Reflexion. </span> Reflexion은 언어적 피드백 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shinn_reflexion_2023</span>]</cite>를 통한 자기 반성을 사용하는 단일 에이전트 패턴이다. 성공 상태, 현재 궤적 및 영구 기억과 같은 메트릭을 활용하여 이 방법은 LLM 평가기를 사용하여 에이전트에 구체적이고 관련된 피드백을 제공한다. 이것은 연쇄 사상 및 ReAct에 비해 향상된 성공률과 감소된 환각을 초래한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p7">
<p class="ltx_p" id="S3.SS3.p7.1">이러한 발전에도 불구하고 반사 저자는 패턴의 다양한 한계를 식별한다. 주로, 반사는 "최적이 아닌 국소 최소 해"에 취약하다. 또한 데이터베이스가 아닌 장기 기억을 위한 슬라이딩 창을 사용합니다. 이는 언어 모델의 토큰 한도에 의해 장기 기억의 부피가 제한된다는 것을 의미한다. 마지막으로, 연구원들은 반사가 다른 단일 에이전트 패턴을 능가하는 반면, 상당한 양의 다양성, 탐색 및 추론이 필요한 작업에 대한 성능을 향상시킬 수 있는 기회가 여전히 있음을 식별한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p8">
<p class="ltx_p" id="S3.SS3.p8.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p8.1.1">AUTOGPT + P.</span> AutoGPT + P(Planning)는 자연어 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">birr_autogptp_2024</span>]</cite>로 로봇을 명령하는 에이전트에 대한 추론 제한을 해결하는 방법이다. AutoGPT+P는 객체 검출 및 객체 어포던스 매핑(OAM)을 LLM에 의해 구동되는 계획 시스템과 결합한다. 이를 통해 에이전트는 누락된 객체에 대한 환경을 탐색하거나 대안을 제안하거나 사용자에게 목표에 도달하는 데 도움을 요청할 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p9">
<p class="ltx_p" id="S3.SS3.p9.1">AutoGPT+P는 존재하는 객체들을 검출하기 위해 장면의 이미지를 사용함으로써 시작한다. 그런 다음 언어 모델은 이러한 개체를 사용하여 계획 도구, 부분 계획 도구, 대안 도구 제안 및 탐색 도구의 네 가지 옵션에서 사용할 도구를 선택합니다. 이러한 도구를 통해 로봇은 목표를 완수하기 위한 전체 계획을 생성할 뿐만 아니라 환경을 탐색하고 가정을 하고 부분 계획을 생성할 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p10">
<p class="ltx_p" id="S3.SS3.p10.1">그러나 언어 모델은 계획을 완전히 자체적으로 생성하지 않습니다. 대신, 계획 도메인 정의 언어(PDDL)를 사용하여 계획을 실행하는 고전적인 계획자를 제외하고 작업하기 위한 목표와 단계를 생성합니다. 논문은 “LLM은 현재 주로 제한된 추론 능력으로 인해 자연 언어 명령어를 로봇 작업을 실행하기 위한 계획으로 직접 번역하는 능력이 부족하다” <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">birr_autogptp_2024</span>]</cite>를 발견했다. LLM 계획 기능을 고전적 계획기와 결합함으로써, 그들의 접근법은 로봇 계획에 대한 다른 순수 언어 모델 기반 접근법에 비해 상당히 개선된다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p11">
<p class="ltx_p" id="S3.SS3.p11.1">대부분의 첫 번째 접근법과 마찬가지로 AutoGPT+P도 단점이 없는 것은 아니다. 도구 선택의 정확도는 다양하며, 특정 도구가 부적절하게 호출되거나 루프에 갇히게 됩니다. 탐사가 필요한 시나리오에서 도구 선택은 때때로 잘못된 장소에서 객체를 찾는 것과 같은 비논리적인 탐색 결정으로 이어진다. 프레임워크는 또한 에이전트가 설명을 구할 수 없고 사용자가 실행 중에 계획을 수정하거나 종료할 수 없는 인간 상호작용의 측면에서 제한된다.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="161" id="S3.F4.g1" src="https://arxiv.org/html/2404.11584v1/extracted/2404.11584v1/media/autogpt+p.png" width="499">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 4:</span>A diagram of the AutoGPT+P method <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">birr_autogptp_2024</span>]</cite></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.p12">
<p class="ltx_p" id="S3.SS3.p12.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p12.1.1">LATS. </span> 언어 에이전트 트리 검색(LATS)은 트리 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou_language_2023</span>]</cite>를 사용하여 계획, 행동 및 추론을 시너지시키는 단일 에이전트 방법이다. 몬테카를로 트리 탐색(Monte Carlo Tree Search)에서 영감을 받은 이 기법은 노드로서 상태를 나타내고 노드들 사이를 횡단하는 것으로서 액션을 취한다. LM 기반 휴리스틱을 사용하여 가능한 옵션을 검색한 다음 상태 평가기를 사용하여 액션을 선택합니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p13">
<p class="ltx_p" id="S3.SS3.p13.1">LATS는 다른 트리 기반 방법과 비교할 때 성능을 획기적으로 향상시키는 자기 성찰 추론 단계를 구현한다. 어떤 행동을 취하면 환경 피드백과 언어 모델의 피드백을 모두 사용하여 추론에 오류가 있는지 확인하고 대안을 제안한다. 강력한 탐색 알고리즘과 결합된 자기 반영 능력은 LATS가 다양한 작업에서 매우 잘 수행되도록 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p14">
<p class="ltx_p" id="S3.SS3.p14.1">그러나 알고리즘의 복잡성과 관련된 반사 단계로 인해 LATS는 다른 단일 에이전트 방법 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou_language_2023</span>]</cite>보다 더 많은 계산 자원을 사용하고 완료하는 데 더 많은 시간이 걸린다. 이 논문은 또한 비교적 간단한 질의 응답 벤치마크를 사용하며 도구 호출 또는 복잡한 추론을 포함하는 보다 강력한 시나리오에 대해 테스트되지 않았다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Multi Agent Architectures</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Overview</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">이 섹션에서는 Embodied LLM 에이전트 Learn to Cooperate in Organized Teams, DyLAN, AgentVerse 및 MetaGPT와 같은 다중 에이전트 아키텍처를 사용하는 몇 가지 주요 연구 및 샘플 프레임워크를 조사합니다. 이러한 구현들이 에이전트 간 통신 및 협력적 계획 실행을 통해 목표 실행을 용이하게 하는 방법을 강조한다. 이것은 모든 에이전트 프레임워크의 포괄적인 목록이 아니라, 우리의 목표는 다중 에이전트 패턴과 관련된 주요 주제 및 예제에 대한 광범위한 범위를 제공하는 것이다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Key Themes</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">멀티 에이전트 아키텍처는 기술을 기반으로 하는 지능적인 분업과 다양한 에이전트 페르소나의 도움이 되는 피드백 모두를 위한 기회를 만든다. 많은 멀티 에이전트 아키텍처는 계획, 실행 및 평가 단계 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen_agentverse_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2024embodied</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023dynamic</span>]</cite>마다 에이전트의 팀이 동적으로 생성되고 재구성되는 단계에서 작동한다. 이러한 개편은 특정 업무에 전문 에이전트를 채용하고 더 이상 필요하지 않을 때 제거되기 때문에 우수한 결과를 제공한다. 에이전트 역할 및 기술을 당면한 작업에 일치시킴으로써 에이전트 팀은 목표를 달성하는 데 더 큰 정확도를 달성하고 시간을 단축할 수 있습니다. 효과적인 멀티 에이전트 아키텍처의 주요 특징은 에이전트 팀의 명확한 리더십, 동적 팀 구성, 그리고 불필요한 수다에서 중요한 정보가 손실되지 않도록 팀 구성원 간의 효과적인 정보 공유이다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Examples</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.1">Embodied LLM Agents Learn to Cooperate in Organized Teams. Guo et al.의</span> Research는 에이전트 팀 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2024embodied</span>]</cite>의 전체 효과에 대한 납 에이전트의 영향을 보여준다. 이 아키텍처는 리더 에이전트를 통한 수직 구성 요소뿐만 아니라 에이전트가 리더 외에 다른 에이전트와 대화할 수 있는 능력으로부터 수평 구성 요소를 포함한다. 그들의 연구 결과는 리더가 조직된 에이전트 팀이 리더가 없는 팀보다 거의 10% 더 빠르게 작업을 완료한다는 것을 보여준다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">또한, 지정된 리더가 없는 팀에서는 에이전트가 대부분의 시간을 서로 명령(의사소통의 약 50%)하고 나머지 시간을 정보를 공유하거나 지침을 요청하는 데 사용한다는 것을 발견했다. 반대로, 지정된 리더가 있는 팀에서는 리더의 커뮤니케이션의 60%가 지시를 내리는 것과 관련되어 다른 구성원들이 정보를 교환하고 요청하는 데 더 집중하도록 유도했다. 그들의 결과는 리더가 인간일 때 에이전트 팀이 가장 효과적이라는 것을 보여준다.</p>
</div>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="170" id="S4.F5.g1" src="https://arxiv.org/html/2404.11584v1/extracted/2404.11584v1/media/leader_results.png" width="598"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 5:</span>Agent teams with a designated leader achieve superior performance <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2024embodied</span>]</cite></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S4.F5.1">.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">팀 구조를 넘어 계획 생성, 성능 평가, 피드백 제공, 팀 재구성 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2024embodied</span>]</cite>를 위해 "criticize-reflect" 단계를 채택하는 것이 중요하다고 강조한다. 그들의 결과는 회전 리더십을 가진 역동적인 팀 구조를 가진 에이전트가 작업 완료까지의 시간이 가장 낮고 평균 통신 비용이 가장 낮은 최상의 결과를 제공한다는 것을 나타낸다. 궁극적으로 리더십과 역동적인 팀 구조는 팀 전체의 업무 추론, 계획, 수행 능력을 효과적으로 향상시킨다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.1">DyLAN. </span> Dynamic LLM-Agent Network (DyLAN) 프레임워크는 추론 및 코드 생성과 같은 복잡한 작업에 초점을 맞춘 동적 에이전트 구조를 만듭니다 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023dynamic</span>]</cite>. DyLAN은 각 에이전트가 마지막 작업 라운드에서 얼마나 기여했는지 결정하기 위한 특정 단계를 가지며 다음 실행 라운드에서 일등 기여자만 이동시킨다. 이 방법은 에이전트가 서로 정보를 공유할 수 있고 정의된 리더가 없기 때문에 본질적으로 수평적이다. DyLAN은 산술 및 일반적인 추론 능력을 측정하는 다양한 벤치마크에서 향상된 성능을 보여준다. 이는 동적 팀의 영향을 강조하고 에이전트 기여도를 지속적으로 재평가하고 순위를 매김으로써 주어진 작업을 완료하는 데 더 적합한 에이전트 팀을 만들 수 있음을 보여준다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p5.1.1">AgentVerse. AgentVerse와 같은 다중 에이전트 아키텍처는 그룹 계획을 위한 별개의 단계가 AI 에이전트의 추론 및 문제 해결 능력 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen_agentverse_2023</span>]</cite>를 향상시킬 수 있는 방법을 보여줍니다. AgentVerse에는 직무 수행을 위한 4개의 기본 단계, 즉 모집, 협력적 의사 결정, 독립적 행동 수행, 평가가 포함되어 있다. 이는 전체적인 목표가 달성될 때까지 반복될 수 있다. AgentVerse는 각 단계를 엄격하게 정의하여 에이전트 집합을 보다 효과적으로 추론하고 토론하고 실행할 수 있도록 안내합니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p6">
<p class="ltx_p" id="S4.SS3.p6.1">예로서, 모집 단계는 목표를 향한 진행에 기초하여 에이전트가 제거되거나 추가될 수 있게 한다. 이는 주어진 문제 해결 단계에서 올바른 에이전트가 참여하도록 하는 데 도움이 됩니다. 연구진은 일반적으로 수평 팀은 컨설팅과 같은 협력 작업에 가장 적합하고 수직 팀은 도구 호출에 대한 책임을 더 명확하게 분리해야 하는 작업에 더 적합하다는 것을 발견했다.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S4.F6.g1" src="">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 6:</span>A diagram of the AgentVerse method <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen_agentverse_2023</span>]</cite></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.p7">
<p class="ltx_p" id="S4.SS3.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p7.1.1">MetaGPT. </span> 많은 다중 에이전트 아키텍처는 공통 문제에 대해 협력하는 동안 에이전트가 서로 대화할 수 있도록 합니다. 이러한 대화 능력은 불필요하고 팀 목표를 더 이상 달성하지 못하는 에이전트 간의 수다로 이어질 수 있다. MetaGPT는 에이전트가 비정형 채팅 메시지 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hong2023metagpt</span>]</cite>를 공유하는 대신 문서 및 다이어그램과 같은 구조화된 출력을 생성하도록 요구함으로써 에이전트 간의 비생산적인 채팅 문제를 해결한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p8">
<p class="ltx_p" id="S4.SS3.p8.1">또한, MetaGPT는 정보 공유를 위한 "출판-구독" 메커니즘을 구현한다. 이를 통해 모든 에이전트가 한 곳에서 정보를 공유할 수 있지만 개별 목표 및 과제와 관련된 정보만 읽을 수 있다. 이렇게 하면 전체 목표 실행이 간소화되고 에이전트 간의 대화 소음이 줄어듭니다. HumanEval 및 MBPP 벤치마크의 단일 에이전트 아키텍처와 비교할 때 MetaGPT의 다중 에이전트 아키텍처는 훨씬 더 나은 결과를 보여준다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion and Observations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Overview</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">이 섹션에서는 이전에 요약된 에이전트 패턴에 나타난 디자인 선택의 주요 주제와 영향에 대해 논의한다. 이러한 패턴은 AI 에이전트 아키텍처의 연구 및 구현의 증가하는 본문의 핵심 사례 역할을 한다. 단일 및 다중 에이전트 아키텍처 모두 인간 사용자를 대신하여 또는 그와 함께 목표를 실행할 수 있는 능력을 제공함으로써 언어 모델의 능력을 향상시키려고 한다. 관찰된 대부분의 에이전트 구현은 문제를 반복적으로 해결하기 위해 계획을 광범위하게 따르고, 행동하고, 프로세스를 평가한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">단일 및 다중 에이전트 아키텍처 모두 복잡한 목표 실행에서 강력한 성능을 보여준다. 또한 아키텍처 전반에 걸쳐 명확한 피드백, 작업 분해, 반복 정제 및 역할 정의가 에이전트 성능을 향상시킨다는 것을 발견했다.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Key Findings</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">Typical Conditions for Selecting a Single vs Multi-Agent Architecture. </span> 앞서 언급한 에이전트 패턴을 기반으로 단일 에이전트 패턴이 일반적으로 도구 목록이 좁고 프로세스가 잘 정의된 작업에 가장 적합하다는 것을 발견했습니다. 단일 에이전트는 일반적으로 하나의 에이전트 및 도구 세트만 정의하면 되기 때문에 구현하기가 더 쉽습니다. 또한 단일 에이전트 아키텍처는 다른 에이전트의 열악한 피드백이나 다른 팀 구성원의 산만하고 관련 없는 수다와 같은 한계에 직면하지 않는다. 그러나 추론 및 개선 기능이 견고하지 않으면 실행 루프에 갇혀 목표를 향해 나아가지 못할 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">멀티 에이전트 아키텍처는 일반적으로 여러 페르소나로부터의 피드백이 태스크를 달성하는 데 도움이 되는 태스크에 적합하다. 예를 들어, 문서 생성은 하나의 에이전트가 문서의 기입된 섹션 상에서 다른 에이전트에 명확한 피드백을 제공하는 멀티-에이전트 아키텍처로부터 이익을 얻을 수 있다. 다중 에이전트 시스템은 별개의 작업 또는 워크플로우에 걸친 병렬화가 필요한 경우에도 유용합니다. 결정적으로 Wang et. al은 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang_rethinking_2024</span>]</cite>가 제공되지 않는 시나리오에서 다중 에이전트 패턴이 단일 에이전트보다 성능이 우수함을 발견한다. 본질적으로, 다중 에이전트 시스템은 더 복잡하고 종종 강력한 대화 관리 및 명확한 리더십으로부터 이익을 얻는다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">단일 및 다중-에이전트 패턴은 범위 측면에서 발산 능력을 갖지만, 연구는 "다중-에이전트 논의가 에이전트에 제공된 프롬프트가 충분히 견고할 때 추론을 반드시 향상시키는 것은 아니다" <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang_rethinking_2024</span>]</cite>를 발견한다. 이것은 에이전트 아키텍처를 구현하는 사람들이 필요한 추론 능력을 기반으로 하지 않고 사용 사례의 광범위한 컨텍스트에 따라 단일 또는 다중 에이전트 사이에서 결정해야 함을 시사한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p4.1.1">Agents and Asynchronous Task Execution. </span> 단일 에이전트가 여러 비동기 호출을 동시에 시작할 수 있지만 운영 모델은 본질적으로 서로 다른 실행 스레드에 걸친 책임 분할을 지원하지 않습니다. 이는 업무가 비동기적으로 처리되지만, 별개의 의사결정 주체에 의해 자율적으로 관리된다는 의미에서 진정으로 병렬적이지 않다는 것을 의미한다. 대신 단일 에이전트는 작업을 순차적으로 계획하고 실행해야 하며, 평가 및 다음 단계로 넘어가기 전에 비동기 작업의 한 배치가 완료되기를 기다려야 합니다. 반대로 멀티 에이전트 아키텍처에서는 각 에이전트가 독립적으로 동작할 수 있어 보다 역동적인 분업이 가능하다. 이 구조는 상이한 도메인들 또는 목표들에 걸쳐 동시 태스크 실행을 용이하게 할 뿐만 아니라, 개별 에이전트들이 다른 사람들에 의해 처리되는 태스크들의 상태에 방해받지 않고 그들의 다음 단계들을 진행할 수 있게 하여, 태스크 관리에 대한 보다 유연하고 병렬적인 접근법을 구현한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p5">
<p class="ltx_p" id="S5.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p5.1.1">Impact of Feedback and Human Oversight on Agent Systems. </span> 복잡한 문제를 해결할 때 첫 번째 시도에서 정확하고 강력한 솔루션을 제공할 가능성은 극히 낮다. 대신에, 그것을 비판하고 다듬기 전에 잠재적인 해결책을 제시할 수 있다. 다른 사람과 상의하고 다른 관점에서 피드백을 받을 수도 있습니다. 반복 피드백과 정제에 대한 동일한 아이디어는 에이전트가 복잡한 문제를 해결하는 데 필수적이다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p6">
<p class="ltx_p" id="S5.SS2.p6.1">이는 부분적으로 언어 모델이 응답 초기에 답변에 전념하는 경향이 있기 때문에 목표 상태 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang_how_2023</span>]</cite>에서 주의를 분산시키는 '스노우볼 효과'를 유발할 수 있다. 피드백을 구현함으로써 에이전트는 경로를 수정하고 목표에 도달할 가능성이 훨씬 더 높다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p7">
<p class="ltx_p" id="S5.SS2.p7.1">또한, 인간 감독의 포함은 에이전트의 응답을 인간의 기대와 더 밀접하게 정렬하여 에이전트가 과제 해결에 대한 비효율적이거나 무효한 접근법을 조사할 가능성을 완화함으로써 즉각적인 결과를 개선한다. 오늘날과 같이 에이전트 아키텍처에 인간 검증 및 피드백을 포함하면 더 신뢰할 수 있고 신뢰할 수 있는 결과 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2024large</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2024embodied</span>]</cite>가 생성된다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p8">
<p class="ltx_p" id="S5.SS2.p8.1">언어 모델은 또한 "공정하거나 균형 잡힌 시점의 제시를 포기하는 것을 의미하더라도 사용자의 입장을 반영하는 경향이 있는 아첨 행동을 나타낸다" <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">park_ai_2023</span>]</cite>. 특히, AgentVerse 논문은 피드백이 건전하지 않더라도 에이전트가 다른 에이전트의 피드백에 어떻게 민감한지를 설명한다. 이렇게 하면 에이전트 팀이 목표 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen_agentverse_2023</span>]</cite>에서 잘못 된 계획을 생성할 수 있습니다. 강력한 프롬프트는 이를 완화하는 데 도움이 될 수 있지만, 개발 중인 에이전트 애플리케이션은 사용자 또는 에이전트 피드백 시스템을 구현할 때 위험을 인식해야 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p9">
<p class="ltx_p" id="S5.SS2.p9.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p9.1.1">Challenges with Group Conversations and Information Sharing. </span> 다중 에이전트 아키텍처를 사용한 한 가지 과제는 에이전트 간에 메시지를 지능적으로 공유하는 능력에 있다. 멀티 에이전트 패턴은 "어떻게 지내?"와 같은 세세한 것에 사로잡혀 서로 질문하는 경향이 더 큰 반면, 단일 에이전트 패턴은 관리할 팀 역학이 없기 때문에 당면한 작업에 집중하는 경향이 있다. 다중 에이전트 시스템의 외부 대화는 에이전트가 효과적으로 추론하고 올바른 도구를 실행하는 능력을 모두 손상시켜 궁극적으로 에이전트를 작업에서 분산시키고 팀 효율성을 저하시킬 수 있다. 이것은 에이전트가 일반적으로 그룹 채팅을 공유하고 대화에서 모든 에이전트의 메시지에 민감한 수평 아키텍처에서 특히 그렇다. 메시지 구독 또는 필터링은 에이전트가 작업과 관련된 정보만 수신하도록 보장하여 다중 에이전트 성능을 향상시킵니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p10">
<p class="ltx_p" id="S5.SS2.p10.1">수직 아키텍처에서 작업은 팀 내 산만함을 줄이는 데 도움이 되는 에이전트 기술에 의해 명확하게 구분되는 경향이 있습니다. 그러나 선두 에이전트가 중요한 정보를 지원 에이전트에 보내지 못하고 다른 에이전트가 필요한 정보를 알지 못하는 경우 문제가 발생한다. 이러한 실패는 팀의 혼란이나 결과의 환각을 초래할 수 있다. 이 문제를 해결하기 위한 한 가지 접근법은 에이전트가 상황적으로 적절한 상호 작용을 갖도록 시스템 프롬프트에 액세스 권한에 대한 정보를 명시적으로 포함하는 것이다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p11">
<p class="ltx_p" id="S5.SS2.p11.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p11.1.1">Impact of Role Definition and Dynamic Teams. </span> 명확한 역할 정의는 단일 및 다중 에이전트 아키텍처 모두에 중요 합니다. 단일 에이전트 아키텍처에서 역할 정의는 에이전트가 제공된 작업에 집중하고 적절한 도구를 실행하며 다른 기능의 환각을 최소화하도록 합니다. 유사하게, 다중 에이전트 아키텍처의 역할 정의는 각 에이전트가 전체 팀에서 담당하는 것을 알고 설명된 기능이나 범위를 벗어난 작업을 수행하지 않도록 합니다. 개인의 역할 정의를 넘어 명확한 그룹 리더를 확립하는 것도 업무 할당을 간소화하여 다중 에이전트 팀의 전반적인 성과를 향상시킨다. 또한 각 에이전트에 대해 명확한 시스템 프롬프트를 정의하면 에이전트가 비생산적인 커뮤니케이션에 참여하지 않도록 프롬프트함으로써 과도한 채팅을 최소화할 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p12">
<p class="ltx_p" id="S5.SS2.p12.1">요원들이 필요에 따라 시스템에 들어오고 나가는 역동적인 팀도 효과적인 것으로 나타났다. 이렇게 하면 작업의 계획 또는 실행에 참여하는 모든 에이전트가 해당 작업에 적합합니다.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Summary</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">단일 및 다중 에이전트 패턴 모두 추론 및 도구 실행과 관련된 다양한 복잡한 작업에서 강력한 성능을 나타낸다. 단일 에이전트 패턴은 정의된 페르소나 및 도구 세트, 인간 피드백 기회, 목표를 향해 반복적으로 작업할 수 있는 능력이 주어졌을 때 잘 수행된다. 복잡한 목표에 협력해야 하는 에이전트 팀을 구성할 때, 명확한 리더(들), 정의된 계획 단계 및 새로운 정보가 학습됨에 따라 계획을 구체화할 기회, 지능형 메시지 필터링, 에이전트가 현재 하위 작업과 관련된 특정 기술을 소유한 동적 팀 중 적어도 하나를 가진 에이전트를 배치하는 것이 유익하다. 에이전트 아키텍처가 이들 접근법들 중 적어도 하나를 채용하는 경우, 이는 이러한 전술들이 없는 단일 에이전트 아키텍처 또는 멀티-에이전트 아키텍처에 비해 증가된 성능을 초래할 가능성이 있다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations of Current Research and Considerations for Future Research</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Overview</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">이 절에서는 오늘날 에이전트 연구의 몇 가지 한계를 살펴보고 AI 에이전트 시스템을 개선하기 위한 잠재적 영역을 식별한다. 에이전트 아키텍처는 여러 면에서 언어 모델의 능력을 크게 향상시켰지만, 각 에이전트에 전원을 공급하는 언어 모델에서 상속되는 평가, 전체 신뢰성 및 문제에는 몇 가지 주요 문제가 있다.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Challenges with Agent Evaluation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">LLM은 일반적인 이해 및 추론 능력을 측정하기 위해 설계된 표준 벤치마크 세트에서 평가되지만 에이전트 평가를 위한 벤치마크는 크게 다르다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">많은 연구 팀은 에이전트 구현과 함께 고유한 에이전트 벤치마크를 도입하여 동일한 벤치마크에서 여러 에이전트 구현을 비교하는 것이 어렵다. 또한 이러한 새로운 에이전트별 벤치마크에는 결과가 수동으로 채점된 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen_agentverse_2023</span>]</cite>가 포함된 손으로 만든 매우 복잡한 평가 세트가 포함된다. 이것은 방법의 능력에 대한 고품질 평가를 제공할 수 있지만, 방법을 개발하는 것도 결과를 작성하고 채점하는 것이기 때문에 더 큰 데이터 세트의 견고성이 부족하고 평가에 편향을 도입할 위험이 있다. 에이전트는 모델, 환경 또는 문제 상태의 변동성으로 인해 여러 반복에 걸쳐 일관된 답변을 생성하는 문제를 가질 수도 있습니다. 이 추가된 무작위성은 더 작고 복잡한 평가 세트에 훨씬 더 큰 문제를 제기한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Impact of Data Contamination and Static Benchmarks</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">일부 연구자들은 일반적인 LLM 벤치마크에서 에이전트 구현을 평가한다. 신흥 연구는 벤치마크 질문을 수정한 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">golchin_time_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu_dyval_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu_dyval2_2024</span>]</cite>에서 모델의 성능이 크게 악화된다는 관찰에 의해 뒷받침되는 모델의 훈련 데이터에 상당한 데이터 오염이 있음을 나타낸다. 이는 언어 모델과 언어 모델 동력 에이전트 모두에 대한 벤치마크 점수의 진위에 대한 의구심을 불러일으킨다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">또한 연구자들은 “LLM이 빠른 속도로 진행됨에 따라 기존 벤치마크의 복잡성 수준이 일반적으로 정적이고 고정적이기 때문에 기존 데이터 세트가 모델의 계속 진화하는 능력과 일치하지 않는 경우가 많다” <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu_dyval2_2024</span>]</cite>를 발견했다. 이를 해결하기 위해 간단한 암기 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu_dyval_2024</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu_dyval2_2024</span>]</cite>에 강한 동적 벤치마크를 만드는 작업이 이루어졌다. 연구자들은 또한 사용자의 특정 환경 또는 사용 사례 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lei_s3eval_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang_benchmark_2024</span>]</cite>를 기반으로 완전히 합성 벤치마크를 생성하는 아이디어를 탐구했다. 이러한 기술은 오염에 도움이 될 수 있지만 인간의 관여 수준을 낮추면 정확성과 문제 해결 능력과 관련하여 추가 위험이 발생할 수 있다.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Benchmark Scope and Transferability</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">많은 언어 모델 벤치마크는 MMLU 또는 GSM8K <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cobbe_training_2021</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hendrycks_measuring_2021</span>]</cite>와 같은 도구 호출 없이 단일 반복으로 해결되도록 설계된다. 이들은 기본 언어 모델의 능력을 측정하는 데 중요하지만, 여러 단계에 걸쳐 추론하거나 외부 정보에 액세스하는 에이전트 시스템의 능력을 고려하지 않기 때문에 에이전트 능력에 대한 좋은 프록시가 아니다. StrategyQA는 여러 단계에 걸쳐 모델의 추론 능력을 평가하여 이를 개선하지만 응답은 예/아니오 응답 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">geva_did_2021</span>]</cite>로 제한된다. 업계가 에이전트 중심의 사용 사례로 계속 선회함에 따라 에이전트의 성능과 일반화 가능성을 훈련 데이터를 넘어 확장되는 도구와 관련된 작업에 더 잘 평가하기 위한 추가 조치가 필요할 것이다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS4.p2">
<p class="ltx_p" id="S6.SS4.p2.1">AgentBench와 같은 에이전트 특정 벤치마크는 웹 브라우징, 명령줄 인터페이스, 비디오 게임 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu_agentbench_2023</span>]</cite>와 같은 다양한 환경에서 언어 모델 기반 에이전트를 평가한다. 이것은 에이전트가 주어진 작업을 달성하기 위해 추론, 계획 및 호출 도구를 통해 새로운 환경에 얼마나 잘 일반화할 수 있는지에 대한 더 나은 표시를 제공한다. AgentBench 및 SmartPlay와 같은 벤치마크는 구현의 성공률, 인간 응답과의 출력 유사성 및 전체 효율성 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu_agentbench_2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu_smartplay_2024</span>]</cite>를 평가하기 위해 설계된 객관적인 평가 메트릭을 소개한다. 이러한 객관적인 척도는 구현의 전반적인 신뢰성과 정확성을 이해하는 데 중요하지만, 성능에 대한 보다 미묘한 또는 주관적인 척도를 고려하는 것도 중요하다. 도구 사용의 효율성, 신뢰성 및 계획의 견고성과 같은 메트릭은 성공률만큼 중요하지만 측정하기가 훨씬 더 어렵다. 이러한 메트릭 중 다수는 인간 전문가의 평가를 필요로 하며, 이는 LLM-as-Judge 평가에 비해 비용이 많이 들고 시간이 많이 소요될 수 있다.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>Real-world Applicability</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS5.p1">
<p class="ltx_p" id="S6.SS5.p1.1">기존의 많은 벤치마크들은 논리 퍼즐이나 비디오 게임 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu_agentbench_2023</span>]</cite>를 통해 추론하는 에이전트 시스템의 능력에 초점을 맞추고 있다. 이러한 유형의 태스크에 대한 성능을 평가하는 것이 에이전트 시스템의 추론 능력을 감지하는 데 도움이 될 수 있지만, 이러한 벤치마크에 대한 성능이 실제 성능으로 변환되는지 여부는 불분명하다. 특히, 실제 데이터는 시끄러울 수 있고 많은 일반적인 벤치마크가 부족한 훨씬 더 넓은 범위의 주제를 다룰 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS5.p2">
<p class="ltx_p" id="S6.SS5.p2.1">실제 데이터를 사용하는 인기 있는 벤치마크 중 하나는 ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2024inthewildchat</span>]</cite>와 57만 개의 실제 대화의 WildChat 데이터 세트에서 가져온 WildBench이다. 이 때문에 엄청난 범위의 작업과 프롬프트를 포함합니다. 와일드벤치는 광범위한 주제를 다루지만 대부분의 다른 실제 벤치마크는 특정 작업에 중점을 둡니다. 예를 들어, SWE-bench는 Python <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jimenez_swe-bench_2023</span>]</cite>의 소프트웨어 엔지니어링 작업에 대해 GitHub에서 제기된 실제 문제 세트를 사용하는 벤치마크입니다. 이것은 파이썬 코드를 작성하도록 설계된 에이전트를 평가할 때 매우 도움이 될 수 있고 에이전트가 코드 관련 문제에 대해 얼마나 잘 추론할 수 있는지에 대한 감각을 제공할 수 있지만 다른 프로그래밍 언어와 관련된 에이전트 기능을 이해하려고 할 때는 덜 유익하다.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.6 </span>Bias and Fairness in Agent Systems</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS6.p1">
<p class="ltx_p" id="S6.SS6.p1.1">언어 모델은 사회적 또는 공정성 용어 <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gallegos_bias_2024</span>]</cite>뿐만 아니라 평가 측면에서도 편향을 보이는 것으로 알려져 있다. 더욱이, 에이전트는 구체적으로 "덜 견고하고, 더 해로운 행동에 취약하며, LLM보다 스텔지어 콘텐츠를 생성할 수 있어, 중요한 안전 문제를 강조한다" <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tian_evil_2024</span>]</cite>로 나타났다. 다른 연구에서는 "LLM 에이전트가 특정 정치적 관점에서 토론을 지향함에도 불구하고 모델의 고유한 사회적 편향에 순응하는 경향" <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">taubenfeld_systematic_2024</span>]</cite>를 발견했다. 이러한 경향은 에이전트 기반 구현에서 잘못된 추론으로 이어질 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS6.p2">
<p class="ltx_p" id="S6.SS6.p2.1">업무의 복잡성과 에이전트 개입이 증가함에 따라 이러한 시스템 내에서 편향을 식별하고 해결하기 위한 더 많은 연구가 필요하다. 확장 가능하고 새로운 벤치마크는 종종 생성 중 일정 수준의 LLM 관여를 포함하기 때문에 이는 연구자에게 매우 큰 도전을 제기한다. 그러나 LLM 기반 에이전트의 편향을 평가하기 위한 진정으로 강력한 벤치마크에는 인간 평가가 포함되어야 한다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Future Directions</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">이 조사에서 탐색된 AI 에이전트 구현은 언어 모델 기반 추론, 계획 및 도구 호출의 빠른 향상을 보여준다. 단일 및 다중 에이전트 패턴은 모두 고급 문제 해결 기술이 필요한 복잡한 다단계 문제를 해결할 수 있는 능력을 보여준다. 본 논문에서 논의한 주요 통찰은 최상의 에이전트 아키텍처가 사용 사례에 따라 달라진다는 것을 시사한다. 선택된 아키텍처에 관계없이, 최상의 수행 에이전트 시스템들은 다음의 접근법들 중 적어도 하나를 통합하는 경향이 있다 : 잘 정의된 시스템 프롬프트들, 명확한 리더십 및 태스크 분할, 전용 추론/계획-실행-평가 단계들, 동적 팀 구조들, 인간 또는 에이전트 피드백, 및 지능형 메시지 필터링. 이러한 기술을 활용하는 아키텍처는 다양한 벤치마크 및 문제 유형에 걸쳐 더 효과적입니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">AI 기반 에이전트의 현재 상태는 유망하지만 주목할 만한 한계와 향후 개선 분야가 있다. 포괄적인 에이전트 벤치마크, 실제 적용 가능성 및 유해한 언어 모델 편향의 완화에 대한 문제는 신뢰할 수 있는 에이전트를 가능하게 하기 위해 가까운 시일 내에 해결해야 한다. 이 조사는 정적 언어 모델에서 보다 역동적이고 자율적인 에이전트로의 진행을 조사함으로써 현재 AI 에이전트 경관에 대한 전체적인 이해를 제공하고 기존 에이전트 아키텍처로 구축하거나 사용자 지정 에이전트 아키텍처를 개발하는 것에 대한 통찰력을 제공하는 것을 목표로 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.p3">
<span class="ltx_ERROR undefined" id="S7.p3.1">\printbibliography</span>
</div>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header" data-bs-theme="dark"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>