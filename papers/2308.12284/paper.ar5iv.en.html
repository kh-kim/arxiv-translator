<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2308.12284] D4: Improving LLM Pretraining via Document De-Duplication and Diversification</title><meta property="og:description" content="Over recent years, an increasing amount of compute and data has been poured into training large language models (LLMs), usually by doing one-pass learning on as many tokens as possible randomly selected from large-scalâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="D4: Improving LLM Pretraining via Document De-Duplication and Diversification">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="D4: Improving LLM Pretraining via Document De-Duplication and Diversification">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2308.12284">

<!--Generated on Tue Sep  5 20:25:52 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.7.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.1.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_note_type">footnotetext: </span>Equal contribution. Correspondence emails: ktirumala@meta.com, simigd@gmail.com</span></span></span>
<h1 class="ltx_title ltx_title_document">D4: Improving LLM Pretraining via Document De-Duplication and Diversification</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kushal Tirumala* 
<br class="ltx_break">Meta AI Research
<br class="ltx_break">&amp;Daniel Simig*
<br class="ltx_break">Meta AI Research 
<br class="ltx_break">&amp;Armen Aghajanyan 
<br class="ltx_break">Meta AI Research 
<br class="ltx_break">&amp;Ari S. Morcos 
<br class="ltx_break">Meta AI Research 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Over recent years, an increasing amount of compute and data has been poured into training large language models (LLMs), usually by doing one-pass learning on as many tokens as possible randomly selected from large-scale web corpora. While training on ever-larger portions of the internet leads to consistent performance improvements, the size of these improvements diminishes with scale, and there has been little work exploring the effect of data selection on pre-training and downstream performance beyond simple de-duplication methods such as MinHash. Here, we show that careful data selection (on top of de-duplicated data) via pre-trained model embeddings can speed up training (20% efficiency gains) and improves average downstream accuracy on 16 NLP tasks (up to 2%) at the 6.7B model scale. Furthermore, we show that repeating data intelligently consistently <span id="id1.id1.1" class="ltx_text ltx_font_italic">outperforms</span> baseline training (while repeating random data performs worse than baseline training). Our results indicate that clever data selection can significantly improve LLM pre-training, calls into question the common practice of training for a single epoch on as much data as possible, and demonstrates a path to keep improving our models past the limits of randomly sampling web data.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Due to computational limits, initial work on language model pre-training focused on training models on small, high-quality text datasets such as BookCorpus <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> and Wikipedia <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. More recently, however, catalyzed by works like <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, advancements in large language models (LLMs) have been driven by leveraging large collections of unlabeled, uncurated data derived from snapshots of the internet (CommonCrawl <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>), trading off small quantities of heavily-curated data for huge quantities of less-curated data. Because of the dramatic increase in data quantity, these strategies have resulted in higher performance models and have sparked a new paradigm wherein massive, largely unfiltered datasets are utilized for training <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite the essential role that large-scale web data now play in LM pre-training, data curation and selection for large-scale web data have not been thoroughly explored. This is primarily due to the universality of compute and data scaling laws <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> which give practitioners a low-risk way to reliably improve LM performance by merely adding â€œmoreâ€ data, not necessarily the â€œrightâ€ data. Indeed, the data selection method used to model scaling laws (along with the data selection methods used in most LLM pre-training pipelines) involves simply randomly sampling tokens from web data dumps that have been put through a combination of simple heuristic filtering (e.g., to eliminate very short strings) and very near match de-duplication <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">If we continue relying on scaling laws to improve LLMs, we will quickly hit diminishing returns due to the power-law nature of scaling laws. We will therefore need exponentially more data to maintain a consistent marginal improvement, which may prove especially challenging as we are fast approaching the limits of available human-generated text data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. Encouragingly, in the context of vision, <cite class="ltx_cite ltx_citemacro_citet">Sorscher et&nbsp;al. [<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> demonstrated that we could leverage simple data selection strategies to overcome costly power-law scaling. They compare numerous data selection methods and find that clustering data points in a pre-trained embedding space and ranking according to the distance to the cluster centroid ("SSL Prototypes") significantly improves the data efficiency of vision models. Recently, <cite class="ltx_cite ltx_citemacro_citet">Abbas et&nbsp;al. [<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> demonstrated that using a pre-trained embedding space to de-duplicate data ("SemDeDup") improves both efficiency and performance of vision-language models such as CLIP. However, there has been little exploration of these or related approaches in training LLMs at scale. Motivated by this, we argue that by combining these approaches and applying them to LLMs, relatively simple data selection strategies leveraging pre-trained embeddings can significantly improve LLM training. Specifically, our contributions are as follows:</p>
</div>
<div id="S1.p4" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We investigate different data selection strategies for standard LLM pre-training setups where data has already been manually filtered / de-duplicated (e.g., MinHash), and where we do not know the target distribution for which we optimize performance. We argue that the performance of SSL Prototypes is affected by duplicate-driven clusters in the embedding space. In Section&nbsp;<a href="#S3.SS4" title="3.4 Data Selection Strategies (choices for ğ‘†) â€£ 3 Experimental Setup â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a> we propose a new data selection strategy <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">D4</span> that utilizes SemDeDup to avoid getting impacted by such clusters.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">In Section&nbsp;<a href="#S4.SS1" title="4.1 Fixed compute regime: can data selection help on fixed token budgets? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we show that in the <span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">compute-limited regime</span> where we have â€œinfiniteâ€ source data and train models with fixed token budgets, we can achieve better pre-training perplexity and downstream accuracy than random iid data selection and previously established methods. Furthermore, we show that our method D4 can achieve around 20% efficiency gains at the 6.7b model scale, and that the magnitude of efficiency gains increases with model scale.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">In the <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">data-limited regime</span>, where we run out of data and must epoch over data, cleverly choosing what data to repeat can beat training on randomly selected new data, whereas randomly choosing data to repeat underperforms adding new data (Section&nbsp;<a href="#S4.SS2" title="4.2 Fixed data regime: what happens when we run out of data? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>). This calls into question the standard practice of single epoch LLM training, and suggests that epoching over intelligently subselected data might be a better approach.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2308.12284/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="315" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">Learning curves for 6.7B OPT model pretraining on 100B tokens, with data selected with D4 (pink line) and randomly (gray line). D4 significantly outperforms baseline training, getting between 18-20% efficiency gains on validation perplexity and 2% increase in average 0-shot downstream accuracy across 16 NLP tasks. See Section&nbsp;<a href="#A1.SS2" title="A.2 Efficiency gains across model scales and training â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a> for full learning curves.</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Data selection in non-text domains:</span> Numerous works have successfully used data selection techniques in vision models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, though these have largely been at sub-ImageNet scale. Some of these works develop pruning metrics that score individual data points (for example, EL2N from <cite class="ltx_cite ltx_citemacro_citet">Paul et&nbsp;al. [<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>), while some focus on data-efficiency and attempt to find groups of points that allow models to reach baseline performance with less data points, e.g., coresets <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. <cite class="ltx_cite ltx_citemacro_citet">Sorscher et&nbsp;al. [<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> compares many of the existing individual-score methods at ImageNet scale, finding that their SSL prototypes metrics and the (prohibitively expensive) memorization metric from <cite class="ltx_cite ltx_citemacro_citet">Feldman and Zhang [<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> generally outperforms other methods. In the audio domain, <cite class="ltx_cite ltx_citemacro_citet">Dong et&nbsp;al. [<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> computes importance embeddings to find important training samples for audio scene classification. More recently, <cite class="ltx_cite ltx_citemacro_citet">Abbas et&nbsp;al. [<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> demonstrated very encouraging results on vision-language models (CLIP models) using SemDeDup â€” a similar method to SSL prototypes but focused on semantic deduplication. Our work combines these approaches and applies them to large-scale LLMs.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Effect of pre-training data on LM performance:</span> <cite class="ltx_cite ltx_citemacro_citet">Gao et&nbsp;al. [<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> trains variants of GPT-2 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> models from scratch to compare the "Pile" dataset to CommonCrawl-derived corpora. <cite class="ltx_cite ltx_citemacro_citet">Radford et&nbsp;al. [<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> demonstrates the positive impact of the quality filters and data de-duplication methods used to curate MassiveWeb by training 1.4B parameter models from scratch. <cite class="ltx_cite ltx_citemacro_citet">Hernandez et&nbsp;al. [<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> quantifies the effect of various amounts of artificially created data duplication and provides analysis on interpreting the changes in the behaviour of the models trained on duplicated data. Concurrently to our work, <cite class="ltx_cite ltx_citemacro_citet">Xie et&nbsp;al. [<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> propose using importance resampling to align the distribution of web data to high-quality reference corpora such as Wikipedia. Similarly, <cite class="ltx_cite ltx_citemacro_citet">Gururangan et&nbsp;al. [<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> explores data selection strategies for adapting LMs to a task-specific corpus. Another line of recent work explores how data mixture affects pre-training, with <cite class="ltx_cite ltx_citemacro_citet">Xie et&nbsp;al. [<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> demonstrating impressive improvements in downstream accuracy and perplexity across all datasets for 8B parameter models trained on the Pile. Similarly, <cite class="ltx_cite ltx_citemacro_citet">Longpre et&nbsp;al. [<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> explores the role of text quality, toxicity, age, and domain distribution of training data on LLM performance. Outside of data curation, there has been a recent surge of work exploring the impact of repeating data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, generally concluding that repeating tokens is worse than training on new tokens (which we question in Section&nbsp;<a href="#S4.SS2" title="4.2 Fixed data regime: what happens when we run out of data? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Setup</h2>

<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Notation</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.17" class="ltx_p">Given a source dataset, <math id="S3.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="D_{source}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.1.m1.1a"><msub id="S3.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">D</mi><mrow id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.2" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">s</mi><mo id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.3" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">o</mi><mo id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1a" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.4" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.4.cmml">u</mi><mo id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1b" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.5" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.5.cmml">r</mi><mo id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1c" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.6" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.6.cmml">c</mi><mo id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1d" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.7" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2">ğ·</ci><apply id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3"><times id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.2">ğ‘ </ci><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.4.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.4">ğ‘¢</ci><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.5.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.5">ğ‘Ÿ</ci><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.6.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.6">ğ‘</ci><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.7.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.1.m1.1c">D_{source}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math>, of documents (crawled web pages) and model architecture, <math id="S3.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.2.m2.1a"><mi id="S3.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.2.m2.1b"><ci id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.2.m2.1d">italic_M</annotation></semantics></math>, we aim to find a strategy <math id="S3.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.3.m3.1a"><mi id="S3.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.3.m3.1b"><ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.3.m3.1c">S</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.3.m3.1d">italic_S</annotation></semantics></math> for selecting a subset of these documents that maximizes some evaluation metric <math id="S3.SS0.SSS0.Px1.p1.4.m4.3" class="ltx_Math" alttext="E(M(D_{S,R}))" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.4.m4.3a"><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.3.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.3.cmml">E</mi><mo id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.cmml">(</mo><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.3.cmml">M</mi><mo id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.2.cmml">D</mi><mrow id="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.4" xref="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.1.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.1.1.cmml">S</mi><mo id="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.4.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.2.cmml">R</mi></mrow></msub><mo stretchy="false" id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.4.m4.3b"><apply id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3"><times id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.2"></times><ci id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.3">ğ¸</ci><apply id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1"><times id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.2"></times><ci id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.3">ğ‘€</ci><apply id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.3.3.1.1.1.1.1.1.2">ğ·</ci><list id="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.4"><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.1.1">ğ‘†</ci><ci id="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.2.2.2.2">ğ‘…</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.4.m4.3c">E(M(D_{S,R}))</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.4.m4.3d">italic_E ( italic_M ( italic_D start_POSTSUBSCRIPT italic_S , italic_R end_POSTSUBSCRIPT ) )</annotation></semantics></math>. <math id="S3.SS0.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.5.m5.1a"><mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.5.m5.1b"><ci id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.5.m5.1c">R</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.5.m5.1d">italic_R</annotation></semantics></math> indicates the proportion of remaining documents from the source dataset <math id="S3.SS0.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="D_{source}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.6.m6.1a"><msub id="S3.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml">D</mi><mrow id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.2" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.2.cmml">s</mi><mo id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.3" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.3.cmml">o</mi><mo id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1a" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.4" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.4.cmml">u</mi><mo id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1b" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.5" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.5.cmml">r</mi><mo id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1c" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.6" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.6.cmml">c</mi><mo id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1d" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.7" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.6.m6.1b"><apply id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2">ğ·</ci><apply id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3"><times id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.1"></times><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.2">ğ‘ </ci><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.3">ğ‘œ</ci><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.4.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.4">ğ‘¢</ci><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.5.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.5">ğ‘Ÿ</ci><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.6.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.6">ğ‘</ci><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.7.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.6.m6.1c">D_{source}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.6.m6.1d">italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math> after selecting data with strategy <math id="S3.SS0.SSS0.Px1.p1.7.m7.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.7.m7.1a"><mi id="S3.SS0.SSS0.Px1.p1.7.m7.1.1" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.7.m7.1b"><ci id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.7.m7.1c">S</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.7.m7.1d">italic_S</annotation></semantics></math>. For this reason, we refer to <math id="S3.SS0.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.8.m8.1a"><mi id="S3.SS0.SSS0.Px1.p1.8.m8.1.1" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.8.m8.1b"><ci id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.8.m8.1c">R</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.8.m8.1d">italic_R</annotation></semantics></math> throughout this work as the <span id="S3.SS0.SSS0.Px1.p1.17.1" class="ltx_text ltx_font_italic">selection ratio</span>: for example, if <math id="S3.SS0.SSS0.Px1.p1.9.m9.1" class="ltx_Math" alttext="R=0.25" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.9.m9.1a"><mrow id="S3.SS0.SSS0.Px1.p1.9.m9.1.1" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.cmml">R</mi><mo id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.1" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.1.cmml">=</mo><mn id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.9.m9.1b"><apply id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1"><eq id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.1"></eq><ci id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2">ğ‘…</ci><cn type="float" id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.9.m9.1c">R=0.25</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.9.m9.1d">italic_R = 0.25</annotation></semantics></math> and <math id="S3.SS0.SSS0.Px1.p1.10.m10.1" class="ltx_Math" alttext="|D_{source}|=100" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.10.m10.1a"><mrow id="S3.SS0.SSS0.Px1.p1.10.m10.1.1" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.cmml"><mrow id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.2" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.2.1.cmml">|</mo><msub id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.2" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.2.cmml">D</mi><mrow id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.2" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.2.cmml">s</mi><mo id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.3" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.3.cmml">o</mi><mo id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1a" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.4" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.4.cmml">u</mi><mo id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1b" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.5" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.5.cmml">r</mi><mo id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1c" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.6" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.6.cmml">c</mi><mo id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1d" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.7" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.7.cmml">e</mi></mrow></msub><mo stretchy="false" id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.3" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.2.1.cmml">|</mo></mrow><mo id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml">=</mo><mn id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.10.m10.1b"><apply id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1"><eq id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2"></eq><apply id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1"><abs id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.2"></abs><apply id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.2">ğ·</ci><apply id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3"><times id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.1"></times><ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.2">ğ‘ </ci><ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.3">ğ‘œ</ci><ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.4.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.4">ğ‘¢</ci><ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.5.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.5">ğ‘Ÿ</ci><ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.6.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.6">ğ‘</ci><ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.7.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.1.1.3.7">ğ‘’</ci></apply></apply></apply><cn type="integer" id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.10.m10.1c">|D_{source}|=100</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.10.m10.1d">| italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT | = 100</annotation></semantics></math> million, then we <span id="S3.SS0.SSS0.Px1.p1.17.2" class="ltx_text ltx_font_italic">select</span> 25% of documents from a source dataset of size <math id="S3.SS0.SSS0.Px1.p1.11.m11.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.11.m11.1a"><mn id="S3.SS0.SSS0.Px1.p1.11.m11.1.1" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.11.m11.1b"><cn type="integer" id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.11.m11.1c">100</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.11.m11.1d">100</annotation></semantics></math>M documents to arrive at a a training dataset with <math id="S3.SS0.SSS0.Px1.p1.12.m12.1" class="ltx_Math" alttext="25" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.12.m12.1a"><mn id="S3.SS0.SSS0.Px1.p1.12.m12.1.1" xref="S3.SS0.SSS0.Px1.p1.12.m12.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.12.m12.1b"><cn type="integer" id="S3.SS0.SSS0.Px1.p1.12.m12.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.12.m12.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.12.m12.1c">25</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.12.m12.1d">25</annotation></semantics></math>M documents. We operate at the granularity of a single document, independently of how the model trainer would pack these documents into batches later. Throughout the paper, we use random selection as the baseline for <math id="S3.SS0.SSS0.Px1.p1.13.m13.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.13.m13.1a"><mi id="S3.SS0.SSS0.Px1.p1.13.m13.1.1" xref="S3.SS0.SSS0.Px1.p1.13.m13.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.13.m13.1b"><ci id="S3.SS0.SSS0.Px1.p1.13.m13.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.13.m13.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.13.m13.1c">S</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.13.m13.1d">italic_S</annotation></semantics></math>, as it is the most common method for selecting data for language model pre-training. In the rest of this section, we describe our choices of source dataset (<math id="S3.SS0.SSS0.Px1.p1.14.m14.1" class="ltx_Math" alttext="D_{source}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.14.m14.1a"><msub id="S3.SS0.SSS0.Px1.p1.14.m14.1.1" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.2" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.2.cmml">D</mi><mrow id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.cmml"><mi id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.2" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.2.cmml">s</mi><mo id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.3" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.3.cmml">o</mi><mo id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1a" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.4" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.4.cmml">u</mi><mo id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1b" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.5" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.5.cmml">r</mi><mo id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1c" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.6" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.6.cmml">c</mi><mo id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1d" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.7" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.14.m14.1b"><apply id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.2">ğ·</ci><apply id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3"><times id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.1"></times><ci id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.2">ğ‘ </ci><ci id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.3">ğ‘œ</ci><ci id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.4.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.4">ğ‘¢</ci><ci id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.5.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.5">ğ‘Ÿ</ci><ci id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.6.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.6">ğ‘</ci><ci id="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.7.cmml" xref="S3.SS0.SSS0.Px1.p1.14.m14.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.14.m14.1c">D_{source}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.14.m14.1d">italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math>), model (<math id="S3.SS0.SSS0.Px1.p1.15.m15.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.15.m15.1a"><mi id="S3.SS0.SSS0.Px1.p1.15.m15.1.1" xref="S3.SS0.SSS0.Px1.p1.15.m15.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.15.m15.1b"><ci id="S3.SS0.SSS0.Px1.p1.15.m15.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.15.m15.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.15.m15.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.15.m15.1d">italic_M</annotation></semantics></math>), evaluation metric (<math id="S3.SS0.SSS0.Px1.p1.16.m16.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.16.m16.1a"><mi id="S3.SS0.SSS0.Px1.p1.16.m16.1.1" xref="S3.SS0.SSS0.Px1.p1.16.m16.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.16.m16.1b"><ci id="S3.SS0.SSS0.Px1.p1.16.m16.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.16.m16.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.16.m16.1c">E</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.16.m16.1d">italic_E</annotation></semantics></math>), and, most importantly, our suggestions for the selection strategy (<math id="S3.SS0.SSS0.Px1.p1.17.m17.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.17.m17.1a"><mi id="S3.SS0.SSS0.Px1.p1.17.m17.1.1" xref="S3.SS0.SSS0.Px1.p1.17.m17.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.17.m17.1b"><ci id="S3.SS0.SSS0.Px1.p1.17.m17.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.17.m17.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.17.m17.1c">S</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.17.m17.1d">italic_S</annotation></semantics></math>).</p>
</div>
</section>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Training Dataset (choice for <math id="S3.SS1.1.m1.1" class="ltx_Math" alttext="D_{source}" display="inline"><semantics id="S3.SS1.1.m1.1b"><msub id="S3.SS1.1.m1.1.1" xref="S3.SS1.1.m1.1.1.cmml"><mi id="S3.SS1.1.m1.1.1.2" xref="S3.SS1.1.m1.1.1.2.cmml">D</mi><mrow id="S3.SS1.1.m1.1.1.3" xref="S3.SS1.1.m1.1.1.3.cmml"><mi id="S3.SS1.1.m1.1.1.3.2" xref="S3.SS1.1.m1.1.1.3.2.cmml">s</mi><mo id="S3.SS1.1.m1.1.1.3.1" xref="S3.SS1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS1.1.m1.1.1.3.3" xref="S3.SS1.1.m1.1.1.3.3.cmml">o</mi><mo id="S3.SS1.1.m1.1.1.3.1b" xref="S3.SS1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS1.1.m1.1.1.3.4" xref="S3.SS1.1.m1.1.1.3.4.cmml">u</mi><mo id="S3.SS1.1.m1.1.1.3.1c" xref="S3.SS1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS1.1.m1.1.1.3.5" xref="S3.SS1.1.m1.1.1.3.5.cmml">r</mi><mo id="S3.SS1.1.m1.1.1.3.1d" xref="S3.SS1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS1.1.m1.1.1.3.6" xref="S3.SS1.1.m1.1.1.3.6.cmml">c</mi><mo id="S3.SS1.1.m1.1.1.3.1e" xref="S3.SS1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS1.1.m1.1.1.3.7" xref="S3.SS1.1.m1.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.1.m1.1c"><apply id="S3.SS1.1.m1.1.1.cmml" xref="S3.SS1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.1.m1.1.1.1.cmml" xref="S3.SS1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.1.m1.1.1.2.cmml" xref="S3.SS1.1.m1.1.1.2">ğ·</ci><apply id="S3.SS1.1.m1.1.1.3.cmml" xref="S3.SS1.1.m1.1.1.3"><times id="S3.SS1.1.m1.1.1.3.1.cmml" xref="S3.SS1.1.m1.1.1.3.1"></times><ci id="S3.SS1.1.m1.1.1.3.2.cmml" xref="S3.SS1.1.m1.1.1.3.2">ğ‘ </ci><ci id="S3.SS1.1.m1.1.1.3.3.cmml" xref="S3.SS1.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S3.SS1.1.m1.1.1.3.4.cmml" xref="S3.SS1.1.m1.1.1.3.4">ğ‘¢</ci><ci id="S3.SS1.1.m1.1.1.3.5.cmml" xref="S3.SS1.1.m1.1.1.3.5">ğ‘Ÿ</ci><ci id="S3.SS1.1.m1.1.1.3.6.cmml" xref="S3.SS1.1.m1.1.1.3.6">ğ‘</ci><ci id="S3.SS1.1.m1.1.1.3.7.cmml" xref="S3.SS1.1.m1.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.1.m1.1d">D_{source}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.1.m1.1e">italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math>)</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We perform all of our training runs on a version of CommonCrawl pre-processed with a CCNet <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> pipeline identical to the one used by <cite class="ltx_cite ltx_citemacro_citet">Touvron et&nbsp;al. [<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>. We add an additional step of MinHash-based de-duplication (see more details in Section&nbsp;<a href="#A1.SS1" title="A.1 Experimental Setup Details â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a>). Applying this common step before our experiments guarantees that any effects observed in our experiments complement the currently prevalent approach of MinHash-based data de-duplication strategies. Throughout the rest of this work, we refer to this dataset as <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">CC-dedup</span>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model Training (choices for <math id="S3.SS2.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.1.m1.1b"><mi id="S3.SS2.1.m1.1.1" xref="S3.SS2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.1.m1.1c"><ci id="S3.SS2.1.m1.1.1.cmml" xref="S3.SS2.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.1.m1.1d">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.1.m1.1e">italic_M</annotation></semantics></math> and <math id="S3.SS2.2.m2.1" class="ltx_Math" alttext="T_{target}" display="inline"><semantics id="S3.SS2.2.m2.1b"><msub id="S3.SS2.2.m2.1.1" xref="S3.SS2.2.m2.1.1.cmml"><mi id="S3.SS2.2.m2.1.1.2" xref="S3.SS2.2.m2.1.1.2.cmml">T</mi><mrow id="S3.SS2.2.m2.1.1.3" xref="S3.SS2.2.m2.1.1.3.cmml"><mi id="S3.SS2.2.m2.1.1.3.2" xref="S3.SS2.2.m2.1.1.3.2.cmml">t</mi><mo id="S3.SS2.2.m2.1.1.3.1" xref="S3.SS2.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.2.m2.1.1.3.3" xref="S3.SS2.2.m2.1.1.3.3.cmml">a</mi><mo id="S3.SS2.2.m2.1.1.3.1b" xref="S3.SS2.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.2.m2.1.1.3.4" xref="S3.SS2.2.m2.1.1.3.4.cmml">r</mi><mo id="S3.SS2.2.m2.1.1.3.1c" xref="S3.SS2.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.2.m2.1.1.3.5" xref="S3.SS2.2.m2.1.1.3.5.cmml">g</mi><mo id="S3.SS2.2.m2.1.1.3.1d" xref="S3.SS2.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.2.m2.1.1.3.6" xref="S3.SS2.2.m2.1.1.3.6.cmml">e</mi><mo id="S3.SS2.2.m2.1.1.3.1e" xref="S3.SS2.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.2.m2.1.1.3.7" xref="S3.SS2.2.m2.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.2.m2.1c"><apply id="S3.SS2.2.m2.1.1.cmml" xref="S3.SS2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.2.m2.1.1.1.cmml" xref="S3.SS2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.2.m2.1.1.2.cmml" xref="S3.SS2.2.m2.1.1.2">ğ‘‡</ci><apply id="S3.SS2.2.m2.1.1.3.cmml" xref="S3.SS2.2.m2.1.1.3"><times id="S3.SS2.2.m2.1.1.3.1.cmml" xref="S3.SS2.2.m2.1.1.3.1"></times><ci id="S3.SS2.2.m2.1.1.3.2.cmml" xref="S3.SS2.2.m2.1.1.3.2">ğ‘¡</ci><ci id="S3.SS2.2.m2.1.1.3.3.cmml" xref="S3.SS2.2.m2.1.1.3.3">ğ‘</ci><ci id="S3.SS2.2.m2.1.1.3.4.cmml" xref="S3.SS2.2.m2.1.1.3.4">ğ‘Ÿ</ci><ci id="S3.SS2.2.m2.1.1.3.5.cmml" xref="S3.SS2.2.m2.1.1.3.5">ğ‘”</ci><ci id="S3.SS2.2.m2.1.1.3.6.cmml" xref="S3.SS2.2.m2.1.1.3.6">ğ‘’</ci><ci id="S3.SS2.2.m2.1.1.3.7.cmml" xref="S3.SS2.2.m2.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.2.m2.1d">T_{target}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.2.m2.1e">italic_T start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT</annotation></semantics></math>)</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.3" class="ltx_p">To evaluate different configurations of data selection strategies, we train OPT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> models from scratch on the pruned versions of datasets. We use the standard model architectures and settings of <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> and use MetaSeq <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> to train all our models. For 125M models, we train to <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="T_{target}=3B" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><msub id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2.2" xref="S3.SS2.p1.1.m1.1.1.2.2.cmml">T</mi><mrow id="S3.SS2.p1.1.m1.1.1.2.3" xref="S3.SS2.p1.1.m1.1.1.2.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2.3.2" xref="S3.SS2.p1.1.m1.1.1.2.3.2.cmml">t</mi><mo id="S3.SS2.p1.1.m1.1.1.2.3.1" xref="S3.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.1.m1.1.1.2.3.3" xref="S3.SS2.p1.1.m1.1.1.2.3.3.cmml">a</mi><mo id="S3.SS2.p1.1.m1.1.1.2.3.1a" xref="S3.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.1.m1.1.1.2.3.4" xref="S3.SS2.p1.1.m1.1.1.2.3.4.cmml">r</mi><mo id="S3.SS2.p1.1.m1.1.1.2.3.1b" xref="S3.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.1.m1.1.1.2.3.5" xref="S3.SS2.p1.1.m1.1.1.2.3.5.cmml">g</mi><mo id="S3.SS2.p1.1.m1.1.1.2.3.1c" xref="S3.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.1.m1.1.1.2.3.6" xref="S3.SS2.p1.1.m1.1.1.2.3.6.cmml">e</mi><mo id="S3.SS2.p1.1.m1.1.1.2.3.1d" xref="S3.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.1.m1.1.1.2.3.7" xref="S3.SS2.p1.1.m1.1.1.2.3.7.cmml">t</mi></mrow></msub><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml"><mn id="S3.SS2.p1.1.m1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.3.2.cmml">3</mn><mo id="S3.SS2.p1.1.m1.1.1.3.1" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.1.m1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.cmml">B</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><eq id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></eq><apply id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2.2">ğ‘‡</ci><apply id="S3.SS2.p1.1.m1.1.1.2.3.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3"><times id="S3.SS2.p1.1.m1.1.1.2.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3.1"></times><ci id="S3.SS2.p1.1.m1.1.1.2.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3.2">ğ‘¡</ci><ci id="S3.SS2.p1.1.m1.1.1.2.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3.3">ğ‘</ci><ci id="S3.SS2.p1.1.m1.1.1.2.3.4.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3.4">ğ‘Ÿ</ci><ci id="S3.SS2.p1.1.m1.1.1.2.3.5.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3.5">ğ‘”</ci><ci id="S3.SS2.p1.1.m1.1.1.2.3.6.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3.6">ğ‘’</ci><ci id="S3.SS2.p1.1.m1.1.1.2.3.7.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3.7">ğ‘¡</ci></apply></apply><apply id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><times id="S3.SS2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.1"></times><cn type="integer" id="S3.SS2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.2">3</cn><ci id="S3.SS2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3">ğµ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">T_{target}=3B</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_T start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT = 3 italic_B</annotation></semantics></math> tokens. For 1.3B parameter models, we train to target token count of <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="T_{target}=40B" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><msub id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.2" xref="S3.SS2.p1.2.m2.1.1.2.2.cmml">T</mi><mrow id="S3.SS2.p1.2.m2.1.1.2.3" xref="S3.SS2.p1.2.m2.1.1.2.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.3.2" xref="S3.SS2.p1.2.m2.1.1.2.3.2.cmml">t</mi><mo id="S3.SS2.p1.2.m2.1.1.2.3.1" xref="S3.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.2.m2.1.1.2.3.3" xref="S3.SS2.p1.2.m2.1.1.2.3.3.cmml">a</mi><mo id="S3.SS2.p1.2.m2.1.1.2.3.1a" xref="S3.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.2.m2.1.1.2.3.4" xref="S3.SS2.p1.2.m2.1.1.2.3.4.cmml">r</mi><mo id="S3.SS2.p1.2.m2.1.1.2.3.1b" xref="S3.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.2.m2.1.1.2.3.5" xref="S3.SS2.p1.2.m2.1.1.2.3.5.cmml">g</mi><mo id="S3.SS2.p1.2.m2.1.1.2.3.1c" xref="S3.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.2.m2.1.1.2.3.6" xref="S3.SS2.p1.2.m2.1.1.2.3.6.cmml">e</mi><mo id="S3.SS2.p1.2.m2.1.1.2.3.1d" xref="S3.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.2.m2.1.1.2.3.7" xref="S3.SS2.p1.2.m2.1.1.2.3.7.cmml">t</mi></mrow></msub><mo id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">=</mo><mrow id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml"><mn id="S3.SS2.p1.2.m2.1.1.3.2" xref="S3.SS2.p1.2.m2.1.1.3.2.cmml">40</mn><mo id="S3.SS2.p1.2.m2.1.1.3.1" xref="S3.SS2.p1.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.2.m2.1.1.3.3" xref="S3.SS2.p1.2.m2.1.1.3.3.cmml">B</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><eq id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1"></eq><apply id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.2">ğ‘‡</ci><apply id="S3.SS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3"><times id="S3.SS2.p1.2.m2.1.1.2.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.1"></times><ci id="S3.SS2.p1.2.m2.1.1.2.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.2">ğ‘¡</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.3">ğ‘</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.4.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.4">ğ‘Ÿ</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.5.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.5">ğ‘”</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.6.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.6">ğ‘’</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.7.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.7">ğ‘¡</ci></apply></apply><apply id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3"><times id="S3.SS2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.3.1"></times><cn type="integer" id="S3.SS2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.3.2">40</cn><ci id="S3.SS2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3">ğµ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">T_{target}=40B</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_T start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT = 40 italic_B</annotation></semantics></math>. For 6.7B parameter models, we train to <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="T_{target}=100B" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><msub id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2.2" xref="S3.SS2.p1.3.m3.1.1.2.2.cmml">T</mi><mrow id="S3.SS2.p1.3.m3.1.1.2.3" xref="S3.SS2.p1.3.m3.1.1.2.3.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2.3.2" xref="S3.SS2.p1.3.m3.1.1.2.3.2.cmml">t</mi><mo id="S3.SS2.p1.3.m3.1.1.2.3.1" xref="S3.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.3.m3.1.1.2.3.3" xref="S3.SS2.p1.3.m3.1.1.2.3.3.cmml">a</mi><mo id="S3.SS2.p1.3.m3.1.1.2.3.1a" xref="S3.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.3.m3.1.1.2.3.4" xref="S3.SS2.p1.3.m3.1.1.2.3.4.cmml">r</mi><mo id="S3.SS2.p1.3.m3.1.1.2.3.1b" xref="S3.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.3.m3.1.1.2.3.5" xref="S3.SS2.p1.3.m3.1.1.2.3.5.cmml">g</mi><mo id="S3.SS2.p1.3.m3.1.1.2.3.1c" xref="S3.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.3.m3.1.1.2.3.6" xref="S3.SS2.p1.3.m3.1.1.2.3.6.cmml">e</mi><mo id="S3.SS2.p1.3.m3.1.1.2.3.1d" xref="S3.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.3.m3.1.1.2.3.7" xref="S3.SS2.p1.3.m3.1.1.2.3.7.cmml">t</mi></mrow></msub><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">=</mo><mrow id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml"><mn id="S3.SS2.p1.3.m3.1.1.3.2" xref="S3.SS2.p1.3.m3.1.1.3.2.cmml">100</mn><mo id="S3.SS2.p1.3.m3.1.1.3.1" xref="S3.SS2.p1.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS2.p1.3.m3.1.1.3.3" xref="S3.SS2.p1.3.m3.1.1.3.3.cmml">B</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><eq id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1"></eq><apply id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS2.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2.2">ğ‘‡</ci><apply id="S3.SS2.p1.3.m3.1.1.2.3.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3"><times id="S3.SS2.p1.3.m3.1.1.2.3.1.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3.1"></times><ci id="S3.SS2.p1.3.m3.1.1.2.3.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3.2">ğ‘¡</ci><ci id="S3.SS2.p1.3.m3.1.1.2.3.3.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3.3">ğ‘</ci><ci id="S3.SS2.p1.3.m3.1.1.2.3.4.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3.4">ğ‘Ÿ</ci><ci id="S3.SS2.p1.3.m3.1.1.2.3.5.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3.5">ğ‘”</ci><ci id="S3.SS2.p1.3.m3.1.1.2.3.6.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3.6">ğ‘’</ci><ci id="S3.SS2.p1.3.m3.1.1.2.3.7.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3.7">ğ‘¡</ci></apply></apply><apply id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3"><times id="S3.SS2.p1.3.m3.1.1.3.1.cmml" xref="S3.SS2.p1.3.m3.1.1.3.1"></times><cn type="integer" id="S3.SS2.p1.3.m3.1.1.3.2.cmml" xref="S3.SS2.p1.3.m3.1.1.3.2">100</cn><ci id="S3.SS2.p1.3.m3.1.1.3.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3.3">ğµ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">T_{target}=100B</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_T start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT = 100 italic_B</annotation></semantics></math> tokens. We choose these by trimming down the token budgets suggested by <cite class="ltx_cite ltx_citemacro_citet">Hoffmann et&nbsp;al. [<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> to meet our compute limitations. We provide full details of our training setup in Section&nbsp;<a href="#A1.SS1" title="A.1 Experimental Setup Details â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation Metrics (choices for <math id="S3.SS3.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS3.1.m1.1b"><mi id="S3.SS3.1.m1.1.1" xref="S3.SS3.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.1.m1.1c"><ci id="S3.SS3.1.m1.1.1.cmml" xref="S3.SS3.1.m1.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.1.m1.1d">E</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.1.m1.1e">italic_E</annotation></semantics></math>)</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We keep most of our evaluation consistent with the setup from <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">Validation Set Perplexity</span>. Our validation sets mainly come from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, which includes validation sets derived from subsets of the Pile <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> such as CommonCrawl, DM Mathematics, HackerNews, OpenSubtitles, OpenWebText2, Project Gutenberg, USPTO, Wikipedia. We also include a validation set obtained from the PushShift.io Reddit dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> (which we refer to as <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_italic">redditflattened</span>). In addition, we measure perplexity on a validation set obtained from a train-validation split of our source dataset <span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_italic">CC-dedup</span>, and a validation set from C4 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">We notice that the effects of data selection vary significantly on individual validation sets depending on whether the validation set was derived from a web data corpus or not (see more details and analysis in Section <a href="#S4.SS4.SSS1" title="4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4.1</span></a>). Motivated by this, we split validation sets into Web-snapshots (C4, CommonCrawl, and CC-dedup) and Non-web snapshots, and report average perplexity within these sets.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p"><span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_bold">Downstream Task Accuracy.</span> To evaluate downstream performance of our trained models, we report average 0-shot accuracy across the 16 NLP tasks from <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, and use a prompting methodology consistent with <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. These set of 16 NLP tasks include Arc Challenge and ArcEasy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, HellaSwag <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, OpenBookQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, PIQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, StoryCloze <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, Winograd <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, Winogrande <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, as well as tasks from SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. We refer the reader to <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> for more information about this evaluation setup.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.1" class="ltx_p"><span id="S3.SS3.p5.1.1" class="ltx_text ltx_font_bold">Instruction Tuning Perplexity</span>. The evaluation mentioned above metrics presents an inherent trade-off. Though accuracy on downstream tasks is typically viewed as a more concrete representation of a language modelâ€™s real-world value, its variance tends to be higher due to the limited number of examples in these tasks and the step-wise behavior of accuracy as a metric. In contrast, perplexity, as a metric, is smoother while still exhibiting a strong correlation with performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>.
Therefore as a middle ground between the two evaluation metrics, we propose evaluating the perplexity on a sample drawn from the instruction-tuning dataset used for fine-tuning OPT-IML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. This dataset spans over 1500 unique NLP tasks and comprises a wide array of prompt-answer pairs and therefore is representative of the <span id="S3.SS3.p5.1.2" class="ltx_text ltx_font_italic">average</span> NLP task. It has been carefully crafted by merging extensive task collections such as Super-NaturalInstructions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> and PromptSource <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. We refer the reader to Table 2.1 in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> for a comprehensive breakdown. This approach allows us to balance practical performance measures and statistical consistency in evaluation. We note that this metric can simply be considered as perplexity on another validation set, where the validation set is filled with examples used for instruction-tuning (we are <span id="S3.SS3.p5.1.3" class="ltx_text ltx_font_bold">not</span> fine-tuning on this dataset).</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Data Selection Strategies (choices for <math id="S3.SS4.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS4.1.m1.1b"><mi id="S3.SS4.1.m1.1.1" xref="S3.SS4.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.1.m1.1c"><ci id="S3.SS4.1.m1.1.1.cmml" xref="S3.SS4.1.m1.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.1.m1.1d">S</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.1.m1.1e">italic_S</annotation></semantics></math>)</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">In our initial exploration of un-curated web data, we embedded a large sample of web documents, clustered these embeddings, and manually inspected the resulting clusters. We quickly identified several high density clusters with documents that had little to do with the natural distribution of human language and were artifacts of the web crawling: for example, advertisements of Nike shoes that were automatically generated from a single underlying template with minor modifications (see Section&nbsp;<a href="#A1.SS9" title="A.9 Investigating Duplicate-Driven Clusters â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.9</span></a> for details).</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">Motivated by the intuition that these duplicate-driven clusters need tshould be pruned, as well as the recent success of pruning methods in vision and vision-language models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>, we focus our efforts on data selection strategies that manipulate data points based on their position in an embedding space. We embed each document by feeding it into a 125M OPT model and use the last-layer embedding of the last token (we experiment with different embedding spaces in Section&nbsp;<a href="#A1.SS7" title="A.7 Choice of Embedding Space â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.7</span></a>). Following this, we experiment with several approaches:</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p"><span id="S3.SS4.p3.1.1" class="ltx_text ltx_font_bold">SemDeDup</span>: <cite class="ltx_cite ltx_citemacro_citet">Abbas et&nbsp;al. [<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> proposed de-duplicating in both text and image domains by first using K-Means to cluster the embedding space, and removing points in each cluster that are within epsilon-balls of one another. We use this algorithm without any modifications and refer the reader to <cite class="ltx_cite ltx_citemacro_citet">Abbas et&nbsp;al. [<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> for implementation details of this algorithm.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.1" class="ltx_p"><span id="S3.SS4.p4.1.1" class="ltx_text ltx_font_bold">Prototypicality</span>: <cite class="ltx_cite ltx_citemacro_citet">Sorscher et&nbsp;al. [<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> investigated a large variety of data pruning strategies to improve the data efficiency of training image classification models, including a newly introduced "SSL Prototypes" metric that proved to be one of their best methods. This strategy involves first clustering the embedding space using k-means clustering and discarding data points in increasing order of their distance to the nearest cluster centroid, such that the most "prototypical" data points are discarded, enriching the much higher variance outliers. We refer the reader to <cite class="ltx_cite ltx_citemacro_citet">Sorscher et&nbsp;al. [<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> for a more detailed description of this algorithm.</p>
</div>
<div id="S3.SS4.p5" class="ltx_para">
<p id="S3.SS4.p5.1" class="ltx_p"><span id="S3.SS4.p5.1.1" class="ltx_text ltx_font_bold">D4</span>: As mentioned previously, we find many instances of duplicate-driven clusters: clusters of templated text or extremely semantically redundant information that are not removed by MinHash. These regions of embedding space tend to be very dense and cause k-means to waste valuable cluster assignments on duplicated text. This biased clustering could also negatively to impact the effectiveness of SSL Prototypes since many clusters will be entirely driven by duplicates instead of more topical coherence. This insight lead us to our proposed strategy:</p>
</div>
<div id="S3.SS4.p6" class="ltx_para">
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.3" class="ltx_p">Apply <span id="S3.I1.i1.p1.3.1" class="ltx_text ltx_font_italic">SemDeDup</span> with a selection ratio <math id="S3.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="R_{dedup}" display="inline"><semantics id="S3.I1.i1.p1.1.m1.1a"><msub id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml"><mi id="S3.I1.i1.p1.1.m1.1.1.2" xref="S3.I1.i1.p1.1.m1.1.1.2.cmml">R</mi><mrow id="S3.I1.i1.p1.1.m1.1.1.3" xref="S3.I1.i1.p1.1.m1.1.1.3.cmml"><mi id="S3.I1.i1.p1.1.m1.1.1.3.2" xref="S3.I1.i1.p1.1.m1.1.1.3.2.cmml">d</mi><mo id="S3.I1.i1.p1.1.m1.1.1.3.1" xref="S3.I1.i1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.I1.i1.p1.1.m1.1.1.3.3" xref="S3.I1.i1.p1.1.m1.1.1.3.3.cmml">e</mi><mo id="S3.I1.i1.p1.1.m1.1.1.3.1a" xref="S3.I1.i1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.I1.i1.p1.1.m1.1.1.3.4" xref="S3.I1.i1.p1.1.m1.1.1.3.4.cmml">d</mi><mo id="S3.I1.i1.p1.1.m1.1.1.3.1b" xref="S3.I1.i1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.I1.i1.p1.1.m1.1.1.3.5" xref="S3.I1.i1.p1.1.m1.1.1.3.5.cmml">u</mi><mo id="S3.I1.i1.p1.1.m1.1.1.3.1c" xref="S3.I1.i1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.I1.i1.p1.1.m1.1.1.3.6" xref="S3.I1.i1.p1.1.m1.1.1.3.6.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><apply id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.1.m1.1.1.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2">ğ‘…</ci><apply id="S3.I1.i1.p1.1.m1.1.1.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3"><times id="S3.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.1"></times><ci id="S3.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.2">ğ‘‘</ci><ci id="S3.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.3">ğ‘’</ci><ci id="S3.I1.i1.p1.1.m1.1.1.3.4.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.4">ğ‘‘</ci><ci id="S3.I1.i1.p1.1.m1.1.1.3.5.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.5">ğ‘¢</ci><ci id="S3.I1.i1.p1.1.m1.1.1.3.6.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.6">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">R_{dedup}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_d italic_e italic_d italic_u italic_p end_POSTSUBSCRIPT</annotation></semantics></math> on the entire dataset <math id="S3.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.I1.i1.p1.2.m2.1a"><mi id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><ci id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.2.m2.1d">italic_D</annotation></semantics></math>, producing a smaller dataset <math id="S3.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="D^{\prime}" display="inline"><semantics id="S3.I1.i1.p1.3.m3.1a"><msup id="S3.I1.i1.p1.3.m3.1.1" xref="S3.I1.i1.p1.3.m3.1.1.cmml"><mi id="S3.I1.i1.p1.3.m3.1.1.2" xref="S3.I1.i1.p1.3.m3.1.1.2.cmml">D</mi><mo id="S3.I1.i1.p1.3.m3.1.1.3" xref="S3.I1.i1.p1.3.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.3.m3.1b"><apply id="S3.I1.i1.p1.3.m3.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.3.m3.1.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.I1.i1.p1.3.m3.1.1.2.cmml" xref="S3.I1.i1.p1.3.m3.1.1.2">ğ·</ci><ci id="S3.I1.i1.p1.3.m3.1.1.3.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.3.m3.1c">D^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.3.m3.1d">italic_D start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math></p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Cluster points in <math id="S3.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="D^{\prime}" display="inline"><semantics id="S3.I1.i2.p1.1.m1.1a"><msup id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i2.p1.1.m1.1.1.2.cmml">D</mi><mo id="S3.I1.i2.p1.1.m1.1.1.3" xref="S3.I1.i2.p1.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2">ğ·</ci><ci id="S3.I1.i2.p1.1.m1.1.1.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">D^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">italic_D start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math> with K-Means</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.2" class="ltx_p">Apply <span id="S3.I1.i3.p1.2.1" class="ltx_text ltx_font_italic">SSL Prototypes</span> on <math id="S3.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="D^{\prime}" display="inline"><semantics id="S3.I1.i3.p1.1.m1.1a"><msup id="S3.I1.i3.p1.1.m1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1.2" xref="S3.I1.i3.p1.1.m1.1.1.2.cmml">D</mi><mo id="S3.I1.i3.p1.1.m1.1.1.3" xref="S3.I1.i3.p1.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b"><apply id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.I1.i3.p1.1.m1.1.1.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.2">ğ·</ci><ci id="S3.I1.i3.p1.1.m1.1.1.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">D^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.1d">italic_D start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math>, with a selection ratio <math id="S3.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="R_{proto}" display="inline"><semantics id="S3.I1.i3.p1.2.m2.1a"><msub id="S3.I1.i3.p1.2.m2.1.1" xref="S3.I1.i3.p1.2.m2.1.1.cmml"><mi id="S3.I1.i3.p1.2.m2.1.1.2" xref="S3.I1.i3.p1.2.m2.1.1.2.cmml">R</mi><mrow id="S3.I1.i3.p1.2.m2.1.1.3" xref="S3.I1.i3.p1.2.m2.1.1.3.cmml"><mi id="S3.I1.i3.p1.2.m2.1.1.3.2" xref="S3.I1.i3.p1.2.m2.1.1.3.2.cmml">p</mi><mo id="S3.I1.i3.p1.2.m2.1.1.3.1" xref="S3.I1.i3.p1.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.I1.i3.p1.2.m2.1.1.3.3" xref="S3.I1.i3.p1.2.m2.1.1.3.3.cmml">r</mi><mo id="S3.I1.i3.p1.2.m2.1.1.3.1a" xref="S3.I1.i3.p1.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.I1.i3.p1.2.m2.1.1.3.4" xref="S3.I1.i3.p1.2.m2.1.1.3.4.cmml">o</mi><mo id="S3.I1.i3.p1.2.m2.1.1.3.1b" xref="S3.I1.i3.p1.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.I1.i3.p1.2.m2.1.1.3.5" xref="S3.I1.i3.p1.2.m2.1.1.3.5.cmml">t</mi><mo id="S3.I1.i3.p1.2.m2.1.1.3.1c" xref="S3.I1.i3.p1.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.I1.i3.p1.2.m2.1.1.3.6" xref="S3.I1.i3.p1.2.m2.1.1.3.6.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.2.m2.1b"><apply id="S3.I1.i3.p1.2.m2.1.1.cmml" xref="S3.I1.i3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I1.i3.p1.2.m2.1.1.1.cmml" xref="S3.I1.i3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I1.i3.p1.2.m2.1.1.2.cmml" xref="S3.I1.i3.p1.2.m2.1.1.2">ğ‘…</ci><apply id="S3.I1.i3.p1.2.m2.1.1.3.cmml" xref="S3.I1.i3.p1.2.m2.1.1.3"><times id="S3.I1.i3.p1.2.m2.1.1.3.1.cmml" xref="S3.I1.i3.p1.2.m2.1.1.3.1"></times><ci id="S3.I1.i3.p1.2.m2.1.1.3.2.cmml" xref="S3.I1.i3.p1.2.m2.1.1.3.2">ğ‘</ci><ci id="S3.I1.i3.p1.2.m2.1.1.3.3.cmml" xref="S3.I1.i3.p1.2.m2.1.1.3.3">ğ‘Ÿ</ci><ci id="S3.I1.i3.p1.2.m2.1.1.3.4.cmml" xref="S3.I1.i3.p1.2.m2.1.1.3.4">ğ‘œ</ci><ci id="S3.I1.i3.p1.2.m2.1.1.3.5.cmml" xref="S3.I1.i3.p1.2.m2.1.1.3.5">ğ‘¡</ci><ci id="S3.I1.i3.p1.2.m2.1.1.3.6.cmml" xref="S3.I1.i3.p1.2.m2.1.1.3.6">ğ‘œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.2.m2.1c">R_{proto}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_p italic_r italic_o italic_t italic_o end_POSTSUBSCRIPT</annotation></semantics></math></p>
</div>
</li>
</ol>
</div>
<div id="S3.SS4.p7" class="ltx_para">
<p id="S3.SS4.p7.3" class="ltx_p">The above-described strategy has an overall selection ratio of <math id="S3.SS4.p7.1.m1.1" class="ltx_Math" alttext="R=R_{dedup}*R_{proto}" display="inline"><semantics id="S3.SS4.p7.1.m1.1a"><mrow id="S3.SS4.p7.1.m1.1.1" xref="S3.SS4.p7.1.m1.1.1.cmml"><mi id="S3.SS4.p7.1.m1.1.1.2" xref="S3.SS4.p7.1.m1.1.1.2.cmml">R</mi><mo id="S3.SS4.p7.1.m1.1.1.1" xref="S3.SS4.p7.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS4.p7.1.m1.1.1.3" xref="S3.SS4.p7.1.m1.1.1.3.cmml"><msub id="S3.SS4.p7.1.m1.1.1.3.2" xref="S3.SS4.p7.1.m1.1.1.3.2.cmml"><mi id="S3.SS4.p7.1.m1.1.1.3.2.2" xref="S3.SS4.p7.1.m1.1.1.3.2.2.cmml">R</mi><mrow id="S3.SS4.p7.1.m1.1.1.3.2.3" xref="S3.SS4.p7.1.m1.1.1.3.2.3.cmml"><mi id="S3.SS4.p7.1.m1.1.1.3.2.3.2" xref="S3.SS4.p7.1.m1.1.1.3.2.3.2.cmml">d</mi><mo id="S3.SS4.p7.1.m1.1.1.3.2.3.1" xref="S3.SS4.p7.1.m1.1.1.3.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.1.m1.1.1.3.2.3.3" xref="S3.SS4.p7.1.m1.1.1.3.2.3.3.cmml">e</mi><mo id="S3.SS4.p7.1.m1.1.1.3.2.3.1a" xref="S3.SS4.p7.1.m1.1.1.3.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.1.m1.1.1.3.2.3.4" xref="S3.SS4.p7.1.m1.1.1.3.2.3.4.cmml">d</mi><mo id="S3.SS4.p7.1.m1.1.1.3.2.3.1b" xref="S3.SS4.p7.1.m1.1.1.3.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.1.m1.1.1.3.2.3.5" xref="S3.SS4.p7.1.m1.1.1.3.2.3.5.cmml">u</mi><mo id="S3.SS4.p7.1.m1.1.1.3.2.3.1c" xref="S3.SS4.p7.1.m1.1.1.3.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.1.m1.1.1.3.2.3.6" xref="S3.SS4.p7.1.m1.1.1.3.2.3.6.cmml">p</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p7.1.m1.1.1.3.1" xref="S3.SS4.p7.1.m1.1.1.3.1.cmml">*</mo><msub id="S3.SS4.p7.1.m1.1.1.3.3" xref="S3.SS4.p7.1.m1.1.1.3.3.cmml"><mi id="S3.SS4.p7.1.m1.1.1.3.3.2" xref="S3.SS4.p7.1.m1.1.1.3.3.2.cmml">R</mi><mrow id="S3.SS4.p7.1.m1.1.1.3.3.3" xref="S3.SS4.p7.1.m1.1.1.3.3.3.cmml"><mi id="S3.SS4.p7.1.m1.1.1.3.3.3.2" xref="S3.SS4.p7.1.m1.1.1.3.3.3.2.cmml">p</mi><mo id="S3.SS4.p7.1.m1.1.1.3.3.3.1" xref="S3.SS4.p7.1.m1.1.1.3.3.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.1.m1.1.1.3.3.3.3" xref="S3.SS4.p7.1.m1.1.1.3.3.3.3.cmml">r</mi><mo id="S3.SS4.p7.1.m1.1.1.3.3.3.1a" xref="S3.SS4.p7.1.m1.1.1.3.3.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.1.m1.1.1.3.3.3.4" xref="S3.SS4.p7.1.m1.1.1.3.3.3.4.cmml">o</mi><mo id="S3.SS4.p7.1.m1.1.1.3.3.3.1b" xref="S3.SS4.p7.1.m1.1.1.3.3.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.1.m1.1.1.3.3.3.5" xref="S3.SS4.p7.1.m1.1.1.3.3.3.5.cmml">t</mi><mo id="S3.SS4.p7.1.m1.1.1.3.3.3.1c" xref="S3.SS4.p7.1.m1.1.1.3.3.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.1.m1.1.1.3.3.3.6" xref="S3.SS4.p7.1.m1.1.1.3.3.3.6.cmml">o</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.1.m1.1b"><apply id="S3.SS4.p7.1.m1.1.1.cmml" xref="S3.SS4.p7.1.m1.1.1"><eq id="S3.SS4.p7.1.m1.1.1.1.cmml" xref="S3.SS4.p7.1.m1.1.1.1"></eq><ci id="S3.SS4.p7.1.m1.1.1.2.cmml" xref="S3.SS4.p7.1.m1.1.1.2">ğ‘…</ci><apply id="S3.SS4.p7.1.m1.1.1.3.cmml" xref="S3.SS4.p7.1.m1.1.1.3"><times id="S3.SS4.p7.1.m1.1.1.3.1.cmml" xref="S3.SS4.p7.1.m1.1.1.3.1"></times><apply id="S3.SS4.p7.1.m1.1.1.3.2.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS4.p7.1.m1.1.1.3.2.1.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2">subscript</csymbol><ci id="S3.SS4.p7.1.m1.1.1.3.2.2.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2.2">ğ‘…</ci><apply id="S3.SS4.p7.1.m1.1.1.3.2.3.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2.3"><times id="S3.SS4.p7.1.m1.1.1.3.2.3.1.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2.3.1"></times><ci id="S3.SS4.p7.1.m1.1.1.3.2.3.2.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2.3.2">ğ‘‘</ci><ci id="S3.SS4.p7.1.m1.1.1.3.2.3.3.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2.3.3">ğ‘’</ci><ci id="S3.SS4.p7.1.m1.1.1.3.2.3.4.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2.3.4">ğ‘‘</ci><ci id="S3.SS4.p7.1.m1.1.1.3.2.3.5.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2.3.5">ğ‘¢</ci><ci id="S3.SS4.p7.1.m1.1.1.3.2.3.6.cmml" xref="S3.SS4.p7.1.m1.1.1.3.2.3.6">ğ‘</ci></apply></apply><apply id="S3.SS4.p7.1.m1.1.1.3.3.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS4.p7.1.m1.1.1.3.3.1.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3">subscript</csymbol><ci id="S3.SS4.p7.1.m1.1.1.3.3.2.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3.2">ğ‘…</ci><apply id="S3.SS4.p7.1.m1.1.1.3.3.3.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3.3"><times id="S3.SS4.p7.1.m1.1.1.3.3.3.1.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3.3.1"></times><ci id="S3.SS4.p7.1.m1.1.1.3.3.3.2.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3.3.2">ğ‘</ci><ci id="S3.SS4.p7.1.m1.1.1.3.3.3.3.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3.3.3">ğ‘Ÿ</ci><ci id="S3.SS4.p7.1.m1.1.1.3.3.3.4.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3.3.4">ğ‘œ</ci><ci id="S3.SS4.p7.1.m1.1.1.3.3.3.5.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3.3.5">ğ‘¡</ci><ci id="S3.SS4.p7.1.m1.1.1.3.3.3.6.cmml" xref="S3.SS4.p7.1.m1.1.1.3.3.3.6">ğ‘œ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.1.m1.1c">R=R_{dedup}*R_{proto}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p7.1.m1.1d">italic_R = italic_R start_POSTSUBSCRIPT italic_d italic_e italic_d italic_u italic_p end_POSTSUBSCRIPT * italic_R start_POSTSUBSCRIPT italic_p italic_r italic_o italic_t italic_o end_POSTSUBSCRIPT</annotation></semantics></math> and intends to diversify the distribution of our data locally and globally. For brevity we refer to this method as <span id="S3.SS4.p7.3.1" class="ltx_text ltx_font_bold">D4</span>, a shorthand for <span id="S3.SS4.p7.3.2" class="ltx_text ltx_font_italic">Document De-Duplication and Diversification</span>. Throughout this work, we choose <math id="S3.SS4.p7.2.m2.1" class="ltx_Math" alttext="R_{dedup}=0.75" display="inline"><semantics id="S3.SS4.p7.2.m2.1a"><mrow id="S3.SS4.p7.2.m2.1.1" xref="S3.SS4.p7.2.m2.1.1.cmml"><msub id="S3.SS4.p7.2.m2.1.1.2" xref="S3.SS4.p7.2.m2.1.1.2.cmml"><mi id="S3.SS4.p7.2.m2.1.1.2.2" xref="S3.SS4.p7.2.m2.1.1.2.2.cmml">R</mi><mrow id="S3.SS4.p7.2.m2.1.1.2.3" xref="S3.SS4.p7.2.m2.1.1.2.3.cmml"><mi id="S3.SS4.p7.2.m2.1.1.2.3.2" xref="S3.SS4.p7.2.m2.1.1.2.3.2.cmml">d</mi><mo id="S3.SS4.p7.2.m2.1.1.2.3.1" xref="S3.SS4.p7.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.2.m2.1.1.2.3.3" xref="S3.SS4.p7.2.m2.1.1.2.3.3.cmml">e</mi><mo id="S3.SS4.p7.2.m2.1.1.2.3.1a" xref="S3.SS4.p7.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.2.m2.1.1.2.3.4" xref="S3.SS4.p7.2.m2.1.1.2.3.4.cmml">d</mi><mo id="S3.SS4.p7.2.m2.1.1.2.3.1b" xref="S3.SS4.p7.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.2.m2.1.1.2.3.5" xref="S3.SS4.p7.2.m2.1.1.2.3.5.cmml">u</mi><mo id="S3.SS4.p7.2.m2.1.1.2.3.1c" xref="S3.SS4.p7.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.2.m2.1.1.2.3.6" xref="S3.SS4.p7.2.m2.1.1.2.3.6.cmml">p</mi></mrow></msub><mo id="S3.SS4.p7.2.m2.1.1.1" xref="S3.SS4.p7.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS4.p7.2.m2.1.1.3" xref="S3.SS4.p7.2.m2.1.1.3.cmml">0.75</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.2.m2.1b"><apply id="S3.SS4.p7.2.m2.1.1.cmml" xref="S3.SS4.p7.2.m2.1.1"><eq id="S3.SS4.p7.2.m2.1.1.1.cmml" xref="S3.SS4.p7.2.m2.1.1.1"></eq><apply id="S3.SS4.p7.2.m2.1.1.2.cmml" xref="S3.SS4.p7.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p7.2.m2.1.1.2.1.cmml" xref="S3.SS4.p7.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS4.p7.2.m2.1.1.2.2.cmml" xref="S3.SS4.p7.2.m2.1.1.2.2">ğ‘…</ci><apply id="S3.SS4.p7.2.m2.1.1.2.3.cmml" xref="S3.SS4.p7.2.m2.1.1.2.3"><times id="S3.SS4.p7.2.m2.1.1.2.3.1.cmml" xref="S3.SS4.p7.2.m2.1.1.2.3.1"></times><ci id="S3.SS4.p7.2.m2.1.1.2.3.2.cmml" xref="S3.SS4.p7.2.m2.1.1.2.3.2">ğ‘‘</ci><ci id="S3.SS4.p7.2.m2.1.1.2.3.3.cmml" xref="S3.SS4.p7.2.m2.1.1.2.3.3">ğ‘’</ci><ci id="S3.SS4.p7.2.m2.1.1.2.3.4.cmml" xref="S3.SS4.p7.2.m2.1.1.2.3.4">ğ‘‘</ci><ci id="S3.SS4.p7.2.m2.1.1.2.3.5.cmml" xref="S3.SS4.p7.2.m2.1.1.2.3.5">ğ‘¢</ci><ci id="S3.SS4.p7.2.m2.1.1.2.3.6.cmml" xref="S3.SS4.p7.2.m2.1.1.2.3.6">ğ‘</ci></apply></apply><cn type="float" id="S3.SS4.p7.2.m2.1.1.3.cmml" xref="S3.SS4.p7.2.m2.1.1.3">0.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.2.m2.1c">R_{dedup}=0.75</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p7.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_d italic_e italic_d italic_u italic_p end_POSTSUBSCRIPT = 0.75</annotation></semantics></math> and vary <math id="S3.SS4.p7.3.m3.1" class="ltx_Math" alttext="R_{proto}" display="inline"><semantics id="S3.SS4.p7.3.m3.1a"><msub id="S3.SS4.p7.3.m3.1.1" xref="S3.SS4.p7.3.m3.1.1.cmml"><mi id="S3.SS4.p7.3.m3.1.1.2" xref="S3.SS4.p7.3.m3.1.1.2.cmml">R</mi><mrow id="S3.SS4.p7.3.m3.1.1.3" xref="S3.SS4.p7.3.m3.1.1.3.cmml"><mi id="S3.SS4.p7.3.m3.1.1.3.2" xref="S3.SS4.p7.3.m3.1.1.3.2.cmml">p</mi><mo id="S3.SS4.p7.3.m3.1.1.3.1" xref="S3.SS4.p7.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.3.m3.1.1.3.3" xref="S3.SS4.p7.3.m3.1.1.3.3.cmml">r</mi><mo id="S3.SS4.p7.3.m3.1.1.3.1a" xref="S3.SS4.p7.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.3.m3.1.1.3.4" xref="S3.SS4.p7.3.m3.1.1.3.4.cmml">o</mi><mo id="S3.SS4.p7.3.m3.1.1.3.1b" xref="S3.SS4.p7.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.3.m3.1.1.3.5" xref="S3.SS4.p7.3.m3.1.1.3.5.cmml">t</mi><mo id="S3.SS4.p7.3.m3.1.1.3.1c" xref="S3.SS4.p7.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S3.SS4.p7.3.m3.1.1.3.6" xref="S3.SS4.p7.3.m3.1.1.3.6.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p7.3.m3.1b"><apply id="S3.SS4.p7.3.m3.1.1.cmml" xref="S3.SS4.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p7.3.m3.1.1.1.cmml" xref="S3.SS4.p7.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p7.3.m3.1.1.2.cmml" xref="S3.SS4.p7.3.m3.1.1.2">ğ‘…</ci><apply id="S3.SS4.p7.3.m3.1.1.3.cmml" xref="S3.SS4.p7.3.m3.1.1.3"><times id="S3.SS4.p7.3.m3.1.1.3.1.cmml" xref="S3.SS4.p7.3.m3.1.1.3.1"></times><ci id="S3.SS4.p7.3.m3.1.1.3.2.cmml" xref="S3.SS4.p7.3.m3.1.1.3.2">ğ‘</ci><ci id="S3.SS4.p7.3.m3.1.1.3.3.cmml" xref="S3.SS4.p7.3.m3.1.1.3.3">ğ‘Ÿ</ci><ci id="S3.SS4.p7.3.m3.1.1.3.4.cmml" xref="S3.SS4.p7.3.m3.1.1.3.4">ğ‘œ</ci><ci id="S3.SS4.p7.3.m3.1.1.3.5.cmml" xref="S3.SS4.p7.3.m3.1.1.3.5">ğ‘¡</ci><ci id="S3.SS4.p7.3.m3.1.1.3.6.cmml" xref="S3.SS4.p7.3.m3.1.1.3.6">ğ‘œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p7.3.m3.1c">R_{proto}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p7.3.m3.1d">italic_R start_POSTSUBSCRIPT italic_p italic_r italic_o italic_t italic_o end_POSTSUBSCRIPT</annotation></semantics></math> (we discuss this choice in Section&nbsp;<a href="#A1.SS1" title="A.1 Experimental Setup Details â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a>). In Section&nbsp;<a href="#S4" title="4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we compare the performance of D4 to baseline training and other methods, and in Section&nbsp;<a href="#S4.SS4" title="4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a> we analyze D4 and show that reclustering after semantic de-duplication indeed reduces the impact of duplicate-driven clusters (see Figure&nbsp;<a href="#S4.F7" title="Figure 7 â€£ 4.4.2 Importance of re-clustering between SemDeDup and SSL Prototypes â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<figure id="S4.F2" class="ltx_figure"><img src="/html/2308.12284/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="597" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.7.3.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.4.2" class="ltx_text" style="font-size:90%;">Comparison of data selection methods on validation perplexity. Each point denotes a 1.3B OPT model trained on 40B tokens. The x-axis denotes the selection ratio <math id="S4.F2.3.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.F2.3.1.m1.1b"><mi id="S4.F2.3.1.m1.1.1" xref="S4.F2.3.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.F2.3.1.m1.1c"><ci id="S4.F2.3.1.m1.1.1.cmml" xref="S4.F2.3.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.3.1.m1.1d">R</annotation><annotation encoding="application/x-llamapun" id="S4.F2.3.1.m1.1e">italic_R</annotation></semantics></math>. The y-axis for the top 2 and bottom left graph depicts perplexity; the bottom right graph is average downstream on 16 NLP tasks from <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. The grey line denotes the value for baseline training. Shaded error is standard error across 3 seeds. <span id="S4.F2.4.2.1" class="ltx_text ltx_font_bold">Each point on this graph is trained on the same token budget</span>: when we decrease <math id="S4.F2.4.2.m2.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.F2.4.2.m2.1b"><mi id="S4.F2.4.2.m2.1.1" xref="S4.F2.4.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.F2.4.2.m2.1c"><ci id="S4.F2.4.2.m2.1.1.cmml" xref="S4.F2.4.2.m2.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.4.2.m2.1d">R</annotation><annotation encoding="application/x-llamapun" id="S4.F2.4.2.m2.1e">italic_R</annotation></semantics></math>, we jointly increase the size of the source dataset (e.g. choosing 1/4 of documents from a 4xâ€™ed sized source dataset).</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Fixed compute regime: can data selection help on fixed token budgets?</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.7" class="ltx_p">In this section, we consider the fixed compute setting, where we curate and train on a fixed token budget by jointly increasing the size of the source dataset <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="D_{source}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><msub id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">D</mi><mrow id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.2" xref="S4.SS1.p1.1.m1.1.1.3.2.cmml">s</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.1.m1.1.1.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.cmml">o</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1a" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.1.m1.1.1.3.4" xref="S4.SS1.p1.1.m1.1.1.3.4.cmml">u</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1b" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.1.m1.1.1.3.5" xref="S4.SS1.p1.1.m1.1.1.3.5.cmml">r</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1c" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.1.m1.1.1.3.6" xref="S4.SS1.p1.1.m1.1.1.3.6.cmml">c</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1d" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.1.m1.1.1.3.7" xref="S4.SS1.p1.1.m1.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">ğ·</ci><apply id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3"><times id="S4.SS1.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3.1"></times><ci id="S4.SS1.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.2">ğ‘ </ci><ci id="S4.SS1.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.SS1.p1.1.m1.1.1.3.4.cmml" xref="S4.SS1.p1.1.m1.1.1.3.4">ğ‘¢</ci><ci id="S4.SS1.p1.1.m1.1.1.3.5.cmml" xref="S4.SS1.p1.1.m1.1.1.3.5">ğ‘Ÿ</ci><ci id="S4.SS1.p1.1.m1.1.1.3.6.cmml" xref="S4.SS1.p1.1.m1.1.1.3.6">ğ‘</ci><ci id="S4.SS1.p1.1.m1.1.1.3.7.cmml" xref="S4.SS1.p1.1.m1.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">D_{source}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math> and decreasing <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">R</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_R</annotation></semantics></math> (the fraction of the <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="D_{source}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><msub id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">D</mi><mrow id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml"><mi id="S4.SS1.p1.3.m3.1.1.3.2" xref="S4.SS1.p1.3.m3.1.1.3.2.cmml">s</mi><mo id="S4.SS1.p1.3.m3.1.1.3.1" xref="S4.SS1.p1.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.3.m3.1.1.3.3" xref="S4.SS1.p1.3.m3.1.1.3.3.cmml">o</mi><mo id="S4.SS1.p1.3.m3.1.1.3.1a" xref="S4.SS1.p1.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.3.m3.1.1.3.4" xref="S4.SS1.p1.3.m3.1.1.3.4.cmml">u</mi><mo id="S4.SS1.p1.3.m3.1.1.3.1b" xref="S4.SS1.p1.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.3.m3.1.1.3.5" xref="S4.SS1.p1.3.m3.1.1.3.5.cmml">r</mi><mo id="S4.SS1.p1.3.m3.1.1.3.1c" xref="S4.SS1.p1.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.3.m3.1.1.3.6" xref="S4.SS1.p1.3.m3.1.1.3.6.cmml">c</mi><mo id="S4.SS1.p1.3.m3.1.1.3.1d" xref="S4.SS1.p1.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.3.m3.1.1.3.7" xref="S4.SS1.p1.3.m3.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">ğ·</ci><apply id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3"><times id="S4.SS1.p1.3.m3.1.1.3.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3.1"></times><ci id="S4.SS1.p1.3.m3.1.1.3.2.cmml" xref="S4.SS1.p1.3.m3.1.1.3.2">ğ‘ </ci><ci id="S4.SS1.p1.3.m3.1.1.3.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3">ğ‘œ</ci><ci id="S4.SS1.p1.3.m3.1.1.3.4.cmml" xref="S4.SS1.p1.3.m3.1.1.3.4">ğ‘¢</ci><ci id="S4.SS1.p1.3.m3.1.1.3.5.cmml" xref="S4.SS1.p1.3.m3.1.1.3.5">ğ‘Ÿ</ci><ci id="S4.SS1.p1.3.m3.1.1.3.6.cmml" xref="S4.SS1.p1.3.m3.1.1.3.6">ğ‘</ci><ci id="S4.SS1.p1.3.m3.1.1.3.7.cmml" xref="S4.SS1.p1.3.m3.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">D_{source}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math> which is selected), such that the target token budget remains constant. This setting is analogous to the most common paradigm for LLM training. As <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="D_{source}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><msub id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">D</mi><mrow id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml"><mi id="S4.SS1.p1.4.m4.1.1.3.2" xref="S4.SS1.p1.4.m4.1.1.3.2.cmml">s</mi><mo id="S4.SS1.p1.4.m4.1.1.3.1" xref="S4.SS1.p1.4.m4.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.4.m4.1.1.3.3" xref="S4.SS1.p1.4.m4.1.1.3.3.cmml">o</mi><mo id="S4.SS1.p1.4.m4.1.1.3.1a" xref="S4.SS1.p1.4.m4.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.4.m4.1.1.3.4" xref="S4.SS1.p1.4.m4.1.1.3.4.cmml">u</mi><mo id="S4.SS1.p1.4.m4.1.1.3.1b" xref="S4.SS1.p1.4.m4.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.4.m4.1.1.3.5" xref="S4.SS1.p1.4.m4.1.1.3.5.cmml">r</mi><mo id="S4.SS1.p1.4.m4.1.1.3.1c" xref="S4.SS1.p1.4.m4.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.4.m4.1.1.3.6" xref="S4.SS1.p1.4.m4.1.1.3.6.cmml">c</mi><mo id="S4.SS1.p1.4.m4.1.1.3.1d" xref="S4.SS1.p1.4.m4.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.4.m4.1.1.3.7" xref="S4.SS1.p1.4.m4.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">ğ·</ci><apply id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3"><times id="S4.SS1.p1.4.m4.1.1.3.1.cmml" xref="S4.SS1.p1.4.m4.1.1.3.1"></times><ci id="S4.SS1.p1.4.m4.1.1.3.2.cmml" xref="S4.SS1.p1.4.m4.1.1.3.2">ğ‘ </ci><ci id="S4.SS1.p1.4.m4.1.1.3.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3.3">ğ‘œ</ci><ci id="S4.SS1.p1.4.m4.1.1.3.4.cmml" xref="S4.SS1.p1.4.m4.1.1.3.4">ğ‘¢</ci><ci id="S4.SS1.p1.4.m4.1.1.3.5.cmml" xref="S4.SS1.p1.4.m4.1.1.3.5">ğ‘Ÿ</ci><ci id="S4.SS1.p1.4.m4.1.1.3.6.cmml" xref="S4.SS1.p1.4.m4.1.1.3.6">ğ‘</ci><ci id="S4.SS1.p1.4.m4.1.1.3.7.cmml" xref="S4.SS1.p1.4.m4.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">D_{source}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math> grows and <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mi id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">R</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">italic_R</annotation></semantics></math> decreases, we select from larger and larger initial datasets, resulting in a larger set of high-quality data points to select from and increasing the overall quality of the selected set. For clarity, we plot performance as a function of the ratio of the <math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="D_{source}" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><msub id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml"><mi id="S4.SS1.p1.6.m6.1.1.2" xref="S4.SS1.p1.6.m6.1.1.2.cmml">D</mi><mrow id="S4.SS1.p1.6.m6.1.1.3" xref="S4.SS1.p1.6.m6.1.1.3.cmml"><mi id="S4.SS1.p1.6.m6.1.1.3.2" xref="S4.SS1.p1.6.m6.1.1.3.2.cmml">s</mi><mo id="S4.SS1.p1.6.m6.1.1.3.1" xref="S4.SS1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.6.m6.1.1.3.3" xref="S4.SS1.p1.6.m6.1.1.3.3.cmml">o</mi><mo id="S4.SS1.p1.6.m6.1.1.3.1a" xref="S4.SS1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.6.m6.1.1.3.4" xref="S4.SS1.p1.6.m6.1.1.3.4.cmml">u</mi><mo id="S4.SS1.p1.6.m6.1.1.3.1b" xref="S4.SS1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.6.m6.1.1.3.5" xref="S4.SS1.p1.6.m6.1.1.3.5.cmml">r</mi><mo id="S4.SS1.p1.6.m6.1.1.3.1c" xref="S4.SS1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.6.m6.1.1.3.6" xref="S4.SS1.p1.6.m6.1.1.3.6.cmml">c</mi><mo id="S4.SS1.p1.6.m6.1.1.3.1d" xref="S4.SS1.p1.6.m6.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.6.m6.1.1.3.7" xref="S4.SS1.p1.6.m6.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><apply id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p1.6.m6.1.1.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2">ğ·</ci><apply id="S4.SS1.p1.6.m6.1.1.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3"><times id="S4.SS1.p1.6.m6.1.1.3.1.cmml" xref="S4.SS1.p1.6.m6.1.1.3.1"></times><ci id="S4.SS1.p1.6.m6.1.1.3.2.cmml" xref="S4.SS1.p1.6.m6.1.1.3.2">ğ‘ </ci><ci id="S4.SS1.p1.6.m6.1.1.3.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3">ğ‘œ</ci><ci id="S4.SS1.p1.6.m6.1.1.3.4.cmml" xref="S4.SS1.p1.6.m6.1.1.3.4">ğ‘¢</ci><ci id="S4.SS1.p1.6.m6.1.1.3.5.cmml" xref="S4.SS1.p1.6.m6.1.1.3.5">ğ‘Ÿ</ci><ci id="S4.SS1.p1.6.m6.1.1.3.6.cmml" xref="S4.SS1.p1.6.m6.1.1.3.6">ğ‘</ci><ci id="S4.SS1.p1.6.m6.1.1.3.7.cmml" xref="S4.SS1.p1.6.m6.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">D_{source}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.1d">italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math> to <math id="S4.SS1.p1.7.m7.1" class="ltx_Math" alttext="D_{target}" display="inline"><semantics id="S4.SS1.p1.7.m7.1a"><msub id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml"><mi id="S4.SS1.p1.7.m7.1.1.2" xref="S4.SS1.p1.7.m7.1.1.2.cmml">D</mi><mrow id="S4.SS1.p1.7.m7.1.1.3" xref="S4.SS1.p1.7.m7.1.1.3.cmml"><mi id="S4.SS1.p1.7.m7.1.1.3.2" xref="S4.SS1.p1.7.m7.1.1.3.2.cmml">t</mi><mo id="S4.SS1.p1.7.m7.1.1.3.1" xref="S4.SS1.p1.7.m7.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.7.m7.1.1.3.3" xref="S4.SS1.p1.7.m7.1.1.3.3.cmml">a</mi><mo id="S4.SS1.p1.7.m7.1.1.3.1a" xref="S4.SS1.p1.7.m7.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.7.m7.1.1.3.4" xref="S4.SS1.p1.7.m7.1.1.3.4.cmml">r</mi><mo id="S4.SS1.p1.7.m7.1.1.3.1b" xref="S4.SS1.p1.7.m7.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.7.m7.1.1.3.5" xref="S4.SS1.p1.7.m7.1.1.3.5.cmml">g</mi><mo id="S4.SS1.p1.7.m7.1.1.3.1c" xref="S4.SS1.p1.7.m7.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.7.m7.1.1.3.6" xref="S4.SS1.p1.7.m7.1.1.3.6.cmml">e</mi><mo id="S4.SS1.p1.7.m7.1.1.3.1d" xref="S4.SS1.p1.7.m7.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.SS1.p1.7.m7.1.1.3.7" xref="S4.SS1.p1.7.m7.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><apply id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS1.p1.7.m7.1.1.2.cmml" xref="S4.SS1.p1.7.m7.1.1.2">ğ·</ci><apply id="S4.SS1.p1.7.m7.1.1.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3"><times id="S4.SS1.p1.7.m7.1.1.3.1.cmml" xref="S4.SS1.p1.7.m7.1.1.3.1"></times><ci id="S4.SS1.p1.7.m7.1.1.3.2.cmml" xref="S4.SS1.p1.7.m7.1.1.3.2">ğ‘¡</ci><ci id="S4.SS1.p1.7.m7.1.1.3.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3.3">ğ‘</ci><ci id="S4.SS1.p1.7.m7.1.1.3.4.cmml" xref="S4.SS1.p1.7.m7.1.1.3.4">ğ‘Ÿ</ci><ci id="S4.SS1.p1.7.m7.1.1.3.5.cmml" xref="S4.SS1.p1.7.m7.1.1.3.5">ğ‘”</ci><ci id="S4.SS1.p1.7.m7.1.1.3.6.cmml" xref="S4.SS1.p1.7.m7.1.1.3.6">ğ‘’</ci><ci id="S4.SS1.p1.7.m7.1.1.3.7.cmml" xref="S4.SS1.p1.7.m7.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">D_{target}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.7.m7.1d">italic_D start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. For each setting, we evaluate the performance of a baseline, SemDeDup alone, SSL Prototypes alone, and our proposed method D4.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.2" class="ltx_p"><span id="S4.SS1.p2.2.1" class="ltx_text ltx_font_bold">Validation Perplexity.</span> In Figure&nbsp;<a href="#S4.F2" title="Figure 2 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we show that a relatively small amount of data selection using any of the three methods (small <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">R</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">italic_R</annotation></semantics></math>) brings consistent improvements on all validation sets. However, as we increase <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mi id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">R</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">italic_R</annotation></semantics></math>, we observe <span id="S4.SS1.p2.2.2" class="ltx_text ltx_font_italic">opposing effects</span> on web snapshot and non-web-snapshots validation sets.
We analyze this discrepancy in-depth in Section&nbsp;<a href="#S4.SS4" title="4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>. However, on the Instruct OPT validation set, which corresponds much more closely to the the high-quality generations we want our LLMs to achieve, we found that all three methods led to consistent and clear perplexity improvements. Notably, we found that while all three methods provided benefits, D4 outperformed using both SemDeDup and SSL Prototypes independently, with the most notable gains exhibited when the source dataset is around 4x the target dataset size. Given that D4 consistently improves with source dataset size, we estimate this gap to grow with source dataset size.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Downstream Task Accuracy.</span> In Figure&nbsp;<a href="#S4.F2" title="Figure 2 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we also report 0-shot downstream accuracy averaged across a suite of NLP tasks. While the high variance of downstream accuracy makes it challenging to identify clear trends in the performance of various models, we again observe that 0-shot downstream accuracy generally increases with source dataset size.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.2" class="ltx_p">Our findings also hold at larger model scales. We pick our best-performing configuration from 1.3B OPT experiments (e.g., <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="R=0.25" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mrow id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml"><mi id="S4.SS1.p4.1.m1.1.1.2" xref="S4.SS1.p4.1.m1.1.1.2.cmml">R</mi><mo id="S4.SS1.p4.1.m1.1.1.1" xref="S4.SS1.p4.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS1.p4.1.m1.1.1.3" xref="S4.SS1.p4.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><apply id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1"><eq id="S4.SS1.p4.1.m1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1.1"></eq><ci id="S4.SS1.p4.1.m1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.1.1.2">ğ‘…</ci><cn type="float" id="S4.SS1.p4.1.m1.1.1.3.cmml" xref="S4.SS1.p4.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">R=0.25</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">italic_R = 0.25</annotation></semantics></math>) and train 6.7B OPT models on 100B tokens. Figure&nbsp;<a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the positive effects of applying D4 with <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="R=0.25" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mrow id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml"><mi id="S4.SS1.p4.2.m2.1.1.2" xref="S4.SS1.p4.2.m2.1.1.2.cmml">R</mi><mo id="S4.SS1.p4.2.m2.1.1.1" xref="S4.SS1.p4.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.p4.2.m2.1.1.3" xref="S4.SS1.p4.2.m2.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><apply id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1"><eq id="S4.SS1.p4.2.m2.1.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1.1"></eq><ci id="S4.SS1.p4.2.m2.1.1.2.cmml" xref="S4.SS1.p4.2.m2.1.1.2">ğ‘…</ci><cn type="float" id="S4.SS1.p4.2.m2.1.1.3.cmml" xref="S4.SS1.p4.2.m2.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">R=0.25</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.2.m2.1d">italic_R = 0.25</annotation></semantics></math> for a 6.7B model. The model trained on the pruned data reaches the same perplexity as the baseline model using 20% fewer update steps on average and achieves a 2% improvement in accuracy on our suite of downstream tasks at the end of the training - about as much difference as was reported by <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> between the OPT and GPT-3 family of models on the same set of tasks (See Figure 3 of <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>).</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Fixed data regime: what happens when we run out of data?</h3>

<figure id="S4.F3" class="ltx_figure"><img src="/html/2308.12284/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="326" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.6.3.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.4.2" class="ltx_text" style="font-size:90%;">Comparing new tokens vs. repeated tokens for random data selection and D4 for fixed selection ratio <math id="S4.F3.3.1.m1.1" class="ltx_Math" alttext="R=0.25" display="inline"><semantics id="S4.F3.3.1.m1.1b"><mrow id="S4.F3.3.1.m1.1.1" xref="S4.F3.3.1.m1.1.1.cmml"><mi id="S4.F3.3.1.m1.1.1.2" xref="S4.F3.3.1.m1.1.1.2.cmml">R</mi><mo id="S4.F3.3.1.m1.1.1.1" xref="S4.F3.3.1.m1.1.1.1.cmml">=</mo><mn id="S4.F3.3.1.m1.1.1.3" xref="S4.F3.3.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.3.1.m1.1c"><apply id="S4.F3.3.1.m1.1.1.cmml" xref="S4.F3.3.1.m1.1.1"><eq id="S4.F3.3.1.m1.1.1.1.cmml" xref="S4.F3.3.1.m1.1.1.1"></eq><ci id="S4.F3.3.1.m1.1.1.2.cmml" xref="S4.F3.3.1.m1.1.1.2">ğ‘…</ci><cn type="float" id="S4.F3.3.1.m1.1.1.3.cmml" xref="S4.F3.3.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.3.1.m1.1d">R=0.25</annotation><annotation encoding="application/x-llamapun" id="S4.F3.3.1.m1.1e">italic_R = 0.25</annotation></semantics></math> for 1.3B OPT pre-training. Each method chooses 25% of documents from the source dataset <math id="S4.F3.4.2.m2.1" class="ltx_Math" alttext="D_{source}" display="inline"><semantics id="S4.F3.4.2.m2.1b"><msub id="S4.F3.4.2.m2.1.1" xref="S4.F3.4.2.m2.1.1.cmml"><mi id="S4.F3.4.2.m2.1.1.2" xref="S4.F3.4.2.m2.1.1.2.cmml">D</mi><mrow id="S4.F3.4.2.m2.1.1.3" xref="S4.F3.4.2.m2.1.1.3.cmml"><mi id="S4.F3.4.2.m2.1.1.3.2" xref="S4.F3.4.2.m2.1.1.3.2.cmml">s</mi><mo id="S4.F3.4.2.m2.1.1.3.1" xref="S4.F3.4.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.F3.4.2.m2.1.1.3.3" xref="S4.F3.4.2.m2.1.1.3.3.cmml">o</mi><mo id="S4.F3.4.2.m2.1.1.3.1b" xref="S4.F3.4.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.F3.4.2.m2.1.1.3.4" xref="S4.F3.4.2.m2.1.1.3.4.cmml">u</mi><mo id="S4.F3.4.2.m2.1.1.3.1c" xref="S4.F3.4.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.F3.4.2.m2.1.1.3.5" xref="S4.F3.4.2.m2.1.1.3.5.cmml">r</mi><mo id="S4.F3.4.2.m2.1.1.3.1d" xref="S4.F3.4.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.F3.4.2.m2.1.1.3.6" xref="S4.F3.4.2.m2.1.1.3.6.cmml">c</mi><mo id="S4.F3.4.2.m2.1.1.3.1e" xref="S4.F3.4.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.F3.4.2.m2.1.1.3.7" xref="S4.F3.4.2.m2.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.F3.4.2.m2.1c"><apply id="S4.F3.4.2.m2.1.1.cmml" xref="S4.F3.4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.F3.4.2.m2.1.1.1.cmml" xref="S4.F3.4.2.m2.1.1">subscript</csymbol><ci id="S4.F3.4.2.m2.1.1.2.cmml" xref="S4.F3.4.2.m2.1.1.2">ğ·</ci><apply id="S4.F3.4.2.m2.1.1.3.cmml" xref="S4.F3.4.2.m2.1.1.3"><times id="S4.F3.4.2.m2.1.1.3.1.cmml" xref="S4.F3.4.2.m2.1.1.3.1"></times><ci id="S4.F3.4.2.m2.1.1.3.2.cmml" xref="S4.F3.4.2.m2.1.1.3.2">ğ‘ </ci><ci id="S4.F3.4.2.m2.1.1.3.3.cmml" xref="S4.F3.4.2.m2.1.1.3.3">ğ‘œ</ci><ci id="S4.F3.4.2.m2.1.1.3.4.cmml" xref="S4.F3.4.2.m2.1.1.3.4">ğ‘¢</ci><ci id="S4.F3.4.2.m2.1.1.3.5.cmml" xref="S4.F3.4.2.m2.1.1.3.5">ğ‘Ÿ</ci><ci id="S4.F3.4.2.m2.1.1.3.6.cmml" xref="S4.F3.4.2.m2.1.1.3.6">ğ‘</ci><ci id="S4.F3.4.2.m2.1.1.3.7.cmml" xref="S4.F3.4.2.m2.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.4.2.m2.1d">D_{source}</annotation><annotation encoding="application/x-llamapun" id="S4.F3.4.2.m2.1e">italic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math>, and epochs over that subset until the target token budget of 40B is reached. We observe that repeating tokens via D4 outperforms baseline training (random, new tokens).</span></figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The results in Section &nbsp;<a href="#S4.SS1" title="4.1 Fixed compute regime: can data selection help on fixed token budgets? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>
indicate that, given a fixed amount of compute for training, selecting data from larger and larger source datasets is a promising method to improve language model performance. However, there is a practical limit to how much data can be curated from the web and, therefore, a natural limit to the size of the source dataset. What happens when we run out of data? <cite class="ltx_cite ltx_citemacro_citet">Hernandez et&nbsp;al. [<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> found and analyzed disproportionately adverse effects of repeated data points in the training data. Similarly, concurrently to our work <cite class="ltx_cite ltx_citemacro_citet">Muennighoff et&nbsp;al. [<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> shows that test loss deteriorates when epoching over a random subset of C4 more than four times. In this section, we investigate how the use of D4 affects model performance in this limited data, multi-epoch setting.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.15" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S4.T1.3.3" class="ltx_tr">
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_left"><math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><mi mathsize="90%" id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.m1.1d">italic_S</annotation></semantics></math></td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_left"><math id="S4.T1.2.2.2.m1.1" class="ltx_Math" alttext="T_{total}" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><msub id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml"><mi mathsize="90%" id="S4.T1.2.2.2.m1.1.1.2" xref="S4.T1.2.2.2.m1.1.1.2.cmml">T</mi><mrow id="S4.T1.2.2.2.m1.1.1.3" xref="S4.T1.2.2.2.m1.1.1.3.cmml"><mi mathsize="90%" id="S4.T1.2.2.2.m1.1.1.3.2" xref="S4.T1.2.2.2.m1.1.1.3.2.cmml">t</mi><mo id="S4.T1.2.2.2.m1.1.1.3.1" xref="S4.T1.2.2.2.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.2.2.2.m1.1.1.3.3" xref="S4.T1.2.2.2.m1.1.1.3.3.cmml">o</mi><mo id="S4.T1.2.2.2.m1.1.1.3.1a" xref="S4.T1.2.2.2.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.2.2.2.m1.1.1.3.4" xref="S4.T1.2.2.2.m1.1.1.3.4.cmml">t</mi><mo id="S4.T1.2.2.2.m1.1.1.3.1b" xref="S4.T1.2.2.2.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.2.2.2.m1.1.1.3.5" xref="S4.T1.2.2.2.m1.1.1.3.5.cmml">a</mi><mo id="S4.T1.2.2.2.m1.1.1.3.1c" xref="S4.T1.2.2.2.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.2.2.2.m1.1.1.3.6" xref="S4.T1.2.2.2.m1.1.1.3.6.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><apply id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.2.2.2.m1.1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">subscript</csymbol><ci id="S4.T1.2.2.2.m1.1.1.2.cmml" xref="S4.T1.2.2.2.m1.1.1.2">ğ‘‡</ci><apply id="S4.T1.2.2.2.m1.1.1.3.cmml" xref="S4.T1.2.2.2.m1.1.1.3"><times id="S4.T1.2.2.2.m1.1.1.3.1.cmml" xref="S4.T1.2.2.2.m1.1.1.3.1"></times><ci id="S4.T1.2.2.2.m1.1.1.3.2.cmml" xref="S4.T1.2.2.2.m1.1.1.3.2">ğ‘¡</ci><ci id="S4.T1.2.2.2.m1.1.1.3.3.cmml" xref="S4.T1.2.2.2.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.T1.2.2.2.m1.1.1.3.4.cmml" xref="S4.T1.2.2.2.m1.1.1.3.4">ğ‘¡</ci><ci id="S4.T1.2.2.2.m1.1.1.3.5.cmml" xref="S4.T1.2.2.2.m1.1.1.3.5">ğ‘</ci><ci id="S4.T1.2.2.2.m1.1.1.3.6.cmml" xref="S4.T1.2.2.2.m1.1.1.3.6">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">T_{total}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.m1.1d">italic_T start_POSTSUBSCRIPT italic_t italic_o italic_t italic_a italic_l end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td id="S4.T1.3.3.3" class="ltx_td ltx_align_left"><math id="S4.T1.3.3.3.m1.1" class="ltx_Math" alttext="T_{selected}" display="inline"><semantics id="S4.T1.3.3.3.m1.1a"><msub id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml"><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.2" xref="S4.T1.3.3.3.m1.1.1.2.cmml">T</mi><mrow id="S4.T1.3.3.3.m1.1.1.3" xref="S4.T1.3.3.3.m1.1.1.3.cmml"><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3.2" xref="S4.T1.3.3.3.m1.1.1.3.2.cmml">s</mi><mo id="S4.T1.3.3.3.m1.1.1.3.1" xref="S4.T1.3.3.3.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3.3" xref="S4.T1.3.3.3.m1.1.1.3.3.cmml">e</mi><mo id="S4.T1.3.3.3.m1.1.1.3.1a" xref="S4.T1.3.3.3.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3.4" xref="S4.T1.3.3.3.m1.1.1.3.4.cmml">l</mi><mo id="S4.T1.3.3.3.m1.1.1.3.1b" xref="S4.T1.3.3.3.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3.5" xref="S4.T1.3.3.3.m1.1.1.3.5.cmml">e</mi><mo id="S4.T1.3.3.3.m1.1.1.3.1c" xref="S4.T1.3.3.3.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3.6" xref="S4.T1.3.3.3.m1.1.1.3.6.cmml">c</mi><mo id="S4.T1.3.3.3.m1.1.1.3.1d" xref="S4.T1.3.3.3.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3.7" xref="S4.T1.3.3.3.m1.1.1.3.7.cmml">t</mi><mo id="S4.T1.3.3.3.m1.1.1.3.1e" xref="S4.T1.3.3.3.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3.8" xref="S4.T1.3.3.3.m1.1.1.3.8.cmml">e</mi><mo id="S4.T1.3.3.3.m1.1.1.3.1f" xref="S4.T1.3.3.3.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3.9" xref="S4.T1.3.3.3.m1.1.1.3.9.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><apply id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.3.3.3.m1.1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T1.3.3.3.m1.1.1.2.cmml" xref="S4.T1.3.3.3.m1.1.1.2">ğ‘‡</ci><apply id="S4.T1.3.3.3.m1.1.1.3.cmml" xref="S4.T1.3.3.3.m1.1.1.3"><times id="S4.T1.3.3.3.m1.1.1.3.1.cmml" xref="S4.T1.3.3.3.m1.1.1.3.1"></times><ci id="S4.T1.3.3.3.m1.1.1.3.2.cmml" xref="S4.T1.3.3.3.m1.1.1.3.2">ğ‘ </ci><ci id="S4.T1.3.3.3.m1.1.1.3.3.cmml" xref="S4.T1.3.3.3.m1.1.1.3.3">ğ‘’</ci><ci id="S4.T1.3.3.3.m1.1.1.3.4.cmml" xref="S4.T1.3.3.3.m1.1.1.3.4">ğ‘™</ci><ci id="S4.T1.3.3.3.m1.1.1.3.5.cmml" xref="S4.T1.3.3.3.m1.1.1.3.5">ğ‘’</ci><ci id="S4.T1.3.3.3.m1.1.1.3.6.cmml" xref="S4.T1.3.3.3.m1.1.1.3.6">ğ‘</ci><ci id="S4.T1.3.3.3.m1.1.1.3.7.cmml" xref="S4.T1.3.3.3.m1.1.1.3.7">ğ‘¡</ci><ci id="S4.T1.3.3.3.m1.1.1.3.8.cmml" xref="S4.T1.3.3.3.m1.1.1.3.8">ğ‘’</ci><ci id="S4.T1.3.3.3.m1.1.1.3.9.cmml" xref="S4.T1.3.3.3.m1.1.1.3.9">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">T_{selected}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.m1.1d">italic_T start_POSTSUBSCRIPT italic_s italic_e italic_l italic_e italic_c italic_t italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td id="S4.T1.3.3.4" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.3.3.4.1" class="ltx_text" style="font-size:90%;">Epochs</span></td>
<td id="S4.T1.3.3.5" class="ltx_td ltx_align_left"><span id="S4.T1.3.3.5.1" class="ltx_text" style="font-size:90%;">Non-Web Snapshot PPL</span></td>
<td id="S4.T1.3.3.6" class="ltx_td ltx_align_left"><span id="S4.T1.3.3.6.1" class="ltx_text" style="font-size:90%;">Instruction + Answers PPL</span></td>
</tr>
<tr id="S4.T1.6.6" class="ltx_tr">
<td id="S4.T1.6.6.4" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T1.6.6.4.1" class="ltx_text" style="font-size:90%;">Random</span></td>
<td id="S4.T1.6.6.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.6.6.5.1" class="ltx_text" style="font-size:90%;">40B</span></td>
<td id="S4.T1.6.6.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.6.6.6.1" class="ltx_text" style="font-size:90%;">40B</span></td>
<td id="S4.T1.4.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S4.T1.4.4.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.T1.4.4.1.m1.1a"><mn mathsize="90%" id="S4.T1.4.4.1.m1.1.1" xref="S4.T1.4.4.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.1.m1.1b"><cn type="integer" id="S4.T1.4.4.1.m1.1.1.cmml" xref="S4.T1.4.4.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.1.m1.1d">1</annotation></semantics></math></td>
<td id="S4.T1.5.5.2" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.5.5.2.m1.1" class="ltx_Math" alttext="16.27\pm 0.012" display="inline"><semantics id="S4.T1.5.5.2.m1.1a"><mrow id="S4.T1.5.5.2.m1.1.1" xref="S4.T1.5.5.2.m1.1.1.cmml"><mn mathsize="90%" id="S4.T1.5.5.2.m1.1.1.2" xref="S4.T1.5.5.2.m1.1.1.2.cmml">16.27</mn><mo mathsize="90%" id="S4.T1.5.5.2.m1.1.1.1" xref="S4.T1.5.5.2.m1.1.1.1.cmml">Â±</mo><mn mathsize="90%" id="S4.T1.5.5.2.m1.1.1.3" xref="S4.T1.5.5.2.m1.1.1.3.cmml">0.012</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.2.m1.1b"><apply id="S4.T1.5.5.2.m1.1.1.cmml" xref="S4.T1.5.5.2.m1.1.1"><csymbol cd="latexml" id="S4.T1.5.5.2.m1.1.1.1.cmml" xref="S4.T1.5.5.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T1.5.5.2.m1.1.1.2.cmml" xref="S4.T1.5.5.2.m1.1.1.2">16.27</cn><cn type="float" id="S4.T1.5.5.2.m1.1.1.3.cmml" xref="S4.T1.5.5.2.m1.1.1.3">0.012</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.2.m1.1c">16.27\pm 0.012</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.5.2.m1.1d">16.27 Â± 0.012</annotation></semantics></math></td>
<td id="S4.T1.6.6.3" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.6.6.3.m1.1" class="ltx_Math" alttext="14.19\pm 0.003" display="inline"><semantics id="S4.T1.6.6.3.m1.1a"><mrow id="S4.T1.6.6.3.m1.1.1" xref="S4.T1.6.6.3.m1.1.1.cmml"><mn mathsize="90%" id="S4.T1.6.6.3.m1.1.1.2" xref="S4.T1.6.6.3.m1.1.1.2.cmml">14.19</mn><mo mathsize="90%" id="S4.T1.6.6.3.m1.1.1.1" xref="S4.T1.6.6.3.m1.1.1.1.cmml">Â±</mo><mn mathsize="90%" id="S4.T1.6.6.3.m1.1.1.3" xref="S4.T1.6.6.3.m1.1.1.3.cmml">0.003</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.3.m1.1b"><apply id="S4.T1.6.6.3.m1.1.1.cmml" xref="S4.T1.6.6.3.m1.1.1"><csymbol cd="latexml" id="S4.T1.6.6.3.m1.1.1.1.cmml" xref="S4.T1.6.6.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T1.6.6.3.m1.1.1.2.cmml" xref="S4.T1.6.6.3.m1.1.1.2">14.19</cn><cn type="float" id="S4.T1.6.6.3.m1.1.1.3.cmml" xref="S4.T1.6.6.3.m1.1.1.3">0.003</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.3.m1.1c">14.19\pm 0.003</annotation><annotation encoding="application/x-llamapun" id="S4.T1.6.6.3.m1.1d">14.19 Â± 0.003</annotation></semantics></math></td>
</tr>
<tr id="S4.T1.11.11" class="ltx_tr">
<td id="S4.T1.11.11.6" class="ltx_td ltx_align_left"><span id="S4.T1.11.11.6.1" class="ltx_text" style="font-size:90%;">40B</span></td>
<td id="S4.T1.11.11.7" class="ltx_td ltx_align_left"><span id="S4.T1.11.11.7.1" class="ltx_text" style="font-size:90%;">20B</span></td>
<td id="S4.T1.7.7.1" class="ltx_td ltx_align_left ltx_border_r"><math id="S4.T1.7.7.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.T1.7.7.1.m1.1a"><mn mathsize="90%" id="S4.T1.7.7.1.m1.1.1" xref="S4.T1.7.7.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.1.m1.1b"><cn type="integer" id="S4.T1.7.7.1.m1.1.1.cmml" xref="S4.T1.7.7.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.7.1.m1.1d">2</annotation></semantics></math></td>
<td id="S4.T1.9.9.3" class="ltx_td ltx_align_left">
<math id="S4.T1.8.8.2.m1.1" class="ltx_Math" alttext="16.39\pm 0.011" display="inline"><semantics id="S4.T1.8.8.2.m1.1a"><mrow id="S4.T1.8.8.2.m1.1.1" xref="S4.T1.8.8.2.m1.1.1.cmml"><mn mathsize="90%" id="S4.T1.8.8.2.m1.1.1.2" xref="S4.T1.8.8.2.m1.1.1.2.cmml">16.39</mn><mo mathsize="90%" id="S4.T1.8.8.2.m1.1.1.1" xref="S4.T1.8.8.2.m1.1.1.1.cmml">Â±</mo><mn mathsize="90%" id="S4.T1.8.8.2.m1.1.1.3" xref="S4.T1.8.8.2.m1.1.1.3.cmml">0.011</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.2.m1.1b"><apply id="S4.T1.8.8.2.m1.1.1.cmml" xref="S4.T1.8.8.2.m1.1.1"><csymbol cd="latexml" id="S4.T1.8.8.2.m1.1.1.1.cmml" xref="S4.T1.8.8.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T1.8.8.2.m1.1.1.2.cmml" xref="S4.T1.8.8.2.m1.1.1.2">16.39</cn><cn type="float" id="S4.T1.8.8.2.m1.1.1.3.cmml" xref="S4.T1.8.8.2.m1.1.1.3">0.011</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.2.m1.1c">16.39\pm 0.011</annotation><annotation encoding="application/x-llamapun" id="S4.T1.8.8.2.m1.1d">16.39 Â± 0.011</annotation></semantics></math><span id="S4.T1.9.9.3.2" class="ltx_text" style="font-size:90%;"> </span><span id="S4.T1.9.9.3.1" class="ltx_text" style="font-size:90%;color:#A8213D;">(+<math id="S4.T1.9.9.3.1.m1.1" class="ltx_Math" alttext="0.12" display="inline"><semantics id="S4.T1.9.9.3.1.m1.1a"><mn mathcolor="#A8213D" id="S4.T1.9.9.3.1.m1.1.1" xref="S4.T1.9.9.3.1.m1.1.1.cmml">0.12</mn><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.3.1.m1.1b"><cn type="float" id="S4.T1.9.9.3.1.m1.1.1.cmml" xref="S4.T1.9.9.3.1.m1.1.1">0.12</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.3.1.m1.1c">0.12</annotation><annotation encoding="application/x-llamapun" id="S4.T1.9.9.3.1.m1.1d">0.12</annotation></semantics></math>)</span>
</td>
<td id="S4.T1.11.11.5" class="ltx_td ltx_align_left">
<math id="S4.T1.10.10.4.m1.1" class="ltx_Math" alttext="14.37\pm 0.015" display="inline"><semantics id="S4.T1.10.10.4.m1.1a"><mrow id="S4.T1.10.10.4.m1.1.1" xref="S4.T1.10.10.4.m1.1.1.cmml"><mn mathsize="90%" id="S4.T1.10.10.4.m1.1.1.2" xref="S4.T1.10.10.4.m1.1.1.2.cmml">14.37</mn><mo mathsize="90%" id="S4.T1.10.10.4.m1.1.1.1" xref="S4.T1.10.10.4.m1.1.1.1.cmml">Â±</mo><mn mathsize="90%" id="S4.T1.10.10.4.m1.1.1.3" xref="S4.T1.10.10.4.m1.1.1.3.cmml">0.015</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.4.m1.1b"><apply id="S4.T1.10.10.4.m1.1.1.cmml" xref="S4.T1.10.10.4.m1.1.1"><csymbol cd="latexml" id="S4.T1.10.10.4.m1.1.1.1.cmml" xref="S4.T1.10.10.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T1.10.10.4.m1.1.1.2.cmml" xref="S4.T1.10.10.4.m1.1.1.2">14.37</cn><cn type="float" id="S4.T1.10.10.4.m1.1.1.3.cmml" xref="S4.T1.10.10.4.m1.1.1.3">0.015</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.4.m1.1c">14.37\pm 0.015</annotation><annotation encoding="application/x-llamapun" id="S4.T1.10.10.4.m1.1d">14.37 Â± 0.015</annotation></semantics></math><span id="S4.T1.11.11.5.2" class="ltx_text" style="font-size:90%;"> </span><span id="S4.T1.11.11.5.1" class="ltx_text" style="font-size:90%;color:#A8213D;">(+<math id="S4.T1.11.11.5.1.m1.1" class="ltx_Math" alttext="0.18" display="inline"><semantics id="S4.T1.11.11.5.1.m1.1a"><mn mathcolor="#A8213D" id="S4.T1.11.11.5.1.m1.1.1" xref="S4.T1.11.11.5.1.m1.1.1.cmml">0.18</mn><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.5.1.m1.1b"><cn type="float" id="S4.T1.11.11.5.1.m1.1.1.cmml" xref="S4.T1.11.11.5.1.m1.1.1">0.18</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.5.1.m1.1c">0.18</annotation><annotation encoding="application/x-llamapun" id="S4.T1.11.11.5.1.m1.1d">0.18</annotation></semantics></math>)</span>
</td>
</tr>
<tr id="S4.T1.15.15" class="ltx_tr">
<td id="S4.T1.15.15.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.15.15.5.1" class="ltx_text" style="font-size:90%;">D4</span></td>
<td id="S4.T1.15.15.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.15.15.6.1" class="ltx_text" style="font-size:90%;">40B</span></td>
<td id="S4.T1.15.15.7" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.15.15.7.1" class="ltx_text" style="font-size:90%;">20B</span></td>
<td id="S4.T1.15.15.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.15.15.8.1" class="ltx_text" style="font-size:90%;">2</span></td>
<td id="S4.T1.13.13.2" class="ltx_td ltx_align_left ltx_border_t">
<math id="S4.T1.12.12.1.m1.1" class="ltx_Math" alttext="\textbf{16.10}\pm 0.024" display="inline"><semantics id="S4.T1.12.12.1.m1.1a"><mrow id="S4.T1.12.12.1.m1.1.1" xref="S4.T1.12.12.1.m1.1.1.cmml"><mtext mathsize="90%" mathvariant="bold" id="S4.T1.12.12.1.m1.1.1.2" xref="S4.T1.12.12.1.m1.1.1.2a.cmml">16.10</mtext><mo mathsize="90%" id="S4.T1.12.12.1.m1.1.1.1" xref="S4.T1.12.12.1.m1.1.1.1.cmml">Â±</mo><mn mathsize="90%" id="S4.T1.12.12.1.m1.1.1.3" xref="S4.T1.12.12.1.m1.1.1.3.cmml">0.024</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.12.12.1.m1.1b"><apply id="S4.T1.12.12.1.m1.1.1.cmml" xref="S4.T1.12.12.1.m1.1.1"><csymbol cd="latexml" id="S4.T1.12.12.1.m1.1.1.1.cmml" xref="S4.T1.12.12.1.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T1.12.12.1.m1.1.1.2a.cmml" xref="S4.T1.12.12.1.m1.1.1.2"><mtext mathsize="90%" mathvariant="bold" id="S4.T1.12.12.1.m1.1.1.2.cmml" xref="S4.T1.12.12.1.m1.1.1.2">16.10</mtext></ci><cn type="float" id="S4.T1.12.12.1.m1.1.1.3.cmml" xref="S4.T1.12.12.1.m1.1.1.3">0.024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.12.1.m1.1c">\textbf{16.10}\pm 0.024</annotation><annotation encoding="application/x-llamapun" id="S4.T1.12.12.1.m1.1d">16.10 Â± 0.024</annotation></semantics></math><span id="S4.T1.13.13.2.2" class="ltx_text" style="font-size:90%;"> </span><span id="S4.T1.13.13.2.1" class="ltx_text" style="font-size:90%;color:#0D800F;">(-<math id="S4.T1.13.13.2.1.m1.1" class="ltx_Math" alttext="0.17" display="inline"><semantics id="S4.T1.13.13.2.1.m1.1a"><mn mathcolor="#0D800F" id="S4.T1.13.13.2.1.m1.1.1" xref="S4.T1.13.13.2.1.m1.1.1.cmml">0.17</mn><annotation-xml encoding="MathML-Content" id="S4.T1.13.13.2.1.m1.1b"><cn type="float" id="S4.T1.13.13.2.1.m1.1.1.cmml" xref="S4.T1.13.13.2.1.m1.1.1">0.17</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.13.2.1.m1.1c">0.17</annotation><annotation encoding="application/x-llamapun" id="S4.T1.13.13.2.1.m1.1d">0.17</annotation></semantics></math>)</span>
</td>
<td id="S4.T1.15.15.4" class="ltx_td ltx_align_left ltx_border_t">
<math id="S4.T1.14.14.3.m1.1" class="ltx_Math" alttext="\textbf{13.85}\pm 0.016" display="inline"><semantics id="S4.T1.14.14.3.m1.1a"><mrow id="S4.T1.14.14.3.m1.1.1" xref="S4.T1.14.14.3.m1.1.1.cmml"><mtext mathsize="90%" mathvariant="bold" id="S4.T1.14.14.3.m1.1.1.2" xref="S4.T1.14.14.3.m1.1.1.2a.cmml">13.85</mtext><mo mathsize="90%" id="S4.T1.14.14.3.m1.1.1.1" xref="S4.T1.14.14.3.m1.1.1.1.cmml">Â±</mo><mn mathsize="90%" id="S4.T1.14.14.3.m1.1.1.3" xref="S4.T1.14.14.3.m1.1.1.3.cmml">0.016</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.14.14.3.m1.1b"><apply id="S4.T1.14.14.3.m1.1.1.cmml" xref="S4.T1.14.14.3.m1.1.1"><csymbol cd="latexml" id="S4.T1.14.14.3.m1.1.1.1.cmml" xref="S4.T1.14.14.3.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T1.14.14.3.m1.1.1.2a.cmml" xref="S4.T1.14.14.3.m1.1.1.2"><mtext mathsize="90%" mathvariant="bold" id="S4.T1.14.14.3.m1.1.1.2.cmml" xref="S4.T1.14.14.3.m1.1.1.2">13.85</mtext></ci><cn type="float" id="S4.T1.14.14.3.m1.1.1.3.cmml" xref="S4.T1.14.14.3.m1.1.1.3">0.016</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.14.3.m1.1c">\textbf{13.85}\pm 0.016</annotation><annotation encoding="application/x-llamapun" id="S4.T1.14.14.3.m1.1d">13.85 Â± 0.016</annotation></semantics></math><span id="S4.T1.15.15.4.2" class="ltx_text" style="font-size:90%;"> </span><span id="S4.T1.15.15.4.1" class="ltx_text" style="font-size:90%;color:#0D800F;">(<math id="S4.T1.15.15.4.1.m1.1" class="ltx_Math" alttext="-0.34" display="inline"><semantics id="S4.T1.15.15.4.1.m1.1a"><mrow id="S4.T1.15.15.4.1.m1.1.1" xref="S4.T1.15.15.4.1.m1.1.1.cmml"><mo mathcolor="#0D800F" id="S4.T1.15.15.4.1.m1.1.1a" xref="S4.T1.15.15.4.1.m1.1.1.cmml">âˆ’</mo><mn mathcolor="#0D800F" id="S4.T1.15.15.4.1.m1.1.1.2" xref="S4.T1.15.15.4.1.m1.1.1.2.cmml">0.34</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.15.15.4.1.m1.1b"><apply id="S4.T1.15.15.4.1.m1.1.1.cmml" xref="S4.T1.15.15.4.1.m1.1.1"><minus id="S4.T1.15.15.4.1.m1.1.1.1.cmml" xref="S4.T1.15.15.4.1.m1.1.1"></minus><cn type="float" id="S4.T1.15.15.4.1.m1.1.1.2.cmml" xref="S4.T1.15.15.4.1.m1.1.1.2">0.34</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.15.4.1.m1.1c">-0.34</annotation><annotation encoding="application/x-llamapun" id="S4.T1.15.15.4.1.m1.1d">- 0.34</annotation></semantics></math>)</span>
</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>For fixed data selection method and source dataset size, we compare the effects of choosing new tokens or repeating token. All models are 1.3B OPT models trained on 40B tokens. <math id="S4.T1.17.m1.1" class="ltx_Math" alttext="T_{selected}" display="inline"><semantics id="S4.T1.17.m1.1b"><msub id="S4.T1.17.m1.1.1" xref="S4.T1.17.m1.1.1.cmml"><mi id="S4.T1.17.m1.1.1.2" xref="S4.T1.17.m1.1.1.2.cmml">T</mi><mrow id="S4.T1.17.m1.1.1.3" xref="S4.T1.17.m1.1.1.3.cmml"><mi id="S4.T1.17.m1.1.1.3.2" xref="S4.T1.17.m1.1.1.3.2.cmml">s</mi><mo id="S4.T1.17.m1.1.1.3.1" xref="S4.T1.17.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.T1.17.m1.1.1.3.3" xref="S4.T1.17.m1.1.1.3.3.cmml">e</mi><mo id="S4.T1.17.m1.1.1.3.1b" xref="S4.T1.17.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.T1.17.m1.1.1.3.4" xref="S4.T1.17.m1.1.1.3.4.cmml">l</mi><mo id="S4.T1.17.m1.1.1.3.1c" xref="S4.T1.17.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.T1.17.m1.1.1.3.5" xref="S4.T1.17.m1.1.1.3.5.cmml">e</mi><mo id="S4.T1.17.m1.1.1.3.1d" xref="S4.T1.17.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.T1.17.m1.1.1.3.6" xref="S4.T1.17.m1.1.1.3.6.cmml">c</mi><mo id="S4.T1.17.m1.1.1.3.1e" xref="S4.T1.17.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.T1.17.m1.1.1.3.7" xref="S4.T1.17.m1.1.1.3.7.cmml">t</mi><mo id="S4.T1.17.m1.1.1.3.1f" xref="S4.T1.17.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.T1.17.m1.1.1.3.8" xref="S4.T1.17.m1.1.1.3.8.cmml">e</mi><mo id="S4.T1.17.m1.1.1.3.1g" xref="S4.T1.17.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="S4.T1.17.m1.1.1.3.9" xref="S4.T1.17.m1.1.1.3.9.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T1.17.m1.1c"><apply id="S4.T1.17.m1.1.1.cmml" xref="S4.T1.17.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.17.m1.1.1.1.cmml" xref="S4.T1.17.m1.1.1">subscript</csymbol><ci id="S4.T1.17.m1.1.1.2.cmml" xref="S4.T1.17.m1.1.1.2">ğ‘‡</ci><apply id="S4.T1.17.m1.1.1.3.cmml" xref="S4.T1.17.m1.1.1.3"><times id="S4.T1.17.m1.1.1.3.1.cmml" xref="S4.T1.17.m1.1.1.3.1"></times><ci id="S4.T1.17.m1.1.1.3.2.cmml" xref="S4.T1.17.m1.1.1.3.2">ğ‘ </ci><ci id="S4.T1.17.m1.1.1.3.3.cmml" xref="S4.T1.17.m1.1.1.3.3">ğ‘’</ci><ci id="S4.T1.17.m1.1.1.3.4.cmml" xref="S4.T1.17.m1.1.1.3.4">ğ‘™</ci><ci id="S4.T1.17.m1.1.1.3.5.cmml" xref="S4.T1.17.m1.1.1.3.5">ğ‘’</ci><ci id="S4.T1.17.m1.1.1.3.6.cmml" xref="S4.T1.17.m1.1.1.3.6">ğ‘</ci><ci id="S4.T1.17.m1.1.1.3.7.cmml" xref="S4.T1.17.m1.1.1.3.7">ğ‘¡</ci><ci id="S4.T1.17.m1.1.1.3.8.cmml" xref="S4.T1.17.m1.1.1.3.8">ğ‘’</ci><ci id="S4.T1.17.m1.1.1.3.9.cmml" xref="S4.T1.17.m1.1.1.3.9">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.17.m1.1d">T_{selected}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.17.m1.1e">italic_T start_POSTSUBSCRIPT italic_s italic_e italic_l italic_e italic_c italic_t italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math> denotes the number of tokens selected from the source dataset. The top row denotes baseline training. Mean and standard error across 3 seeds are shown. <span id="S4.T1.23.1" class="ltx_text ltx_font_bold">Surprisingly, cleverly choosing tokens to repeat via D4 outperforms randomly selecting new tokens.</span></figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">To test this, we assume a fixed token budget and a fixed data size which matches the token budget. We evaluate training on all the data as well as for two epochs on subsets of the data selected either randomly or using D4. We trained 1.3B parameter OPT models on these configurations and report average perplexity in Table <a href="#S4.T1" title="Table 1 â€£ 4.2 Fixed data regime: what happens when we run out of data? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Unsurprisingly, epoching over a randomly selected subset of the data instead of using all the available data once leads to a slight degradation in model perplexity. In contrast, repeating data selected by D4 leads to an improvement in perplexity and downstream accuracy over randomly sampling new tokens. In other words, it is beneficial to select data via D4 and epoch 2 times, instead of doing one-pass learning on all available data. As seen in Figure&nbsp;<a href="#S4.F3" title="Figure 3 â€£ 4.2 Fixed data regime: what happens when we run out of data? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, this finding generally holds across training as well. We refer to Section&nbsp;<a href="#A1.SS6" title="A.6 Further investigation of repeating tokens â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.6</span></a> for results across model scale and data selection ratio.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">To the best of our knowledge, this is the first result to demonstrate the benefits of repeating data for LLM pre-training, over randomly sampling new tokens via a principled data selection technique. We argue that the optimal way of using large-scale web data to pre-train LLMs could be: strategically choose a significantly smaller but better-distributed subset of the data and epoch over it multiple times.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Cost of data selection</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In Section <a href="#S4.SS1" title="4.1 Fixed compute regime: can data selection help on fixed token budgets? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we find that by training a 6.7B parameter model on data selected by D4, we reach the final perplexity of a baseline model using 20% fewer model updates. In our particular setup, this translates to <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_bold">saving approximately 4300 GPU hours</span> - we will refer to this as the <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">naive</span> efficiency gain as it does not account for the the cost of computing the selection metric.</p>
</div>
<figure id="S4.F4" class="ltx_figure ltx_align_floatright">
<br class="ltx_break"><img src="/html/2308.12284/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="290" height="254" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.6.2.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Naive<span id="S4.F4.2.1.2" class="ltx_text ltx_font_upright"> and </span>overall<span id="S4.F4.2.1.1" class="ltx_text ltx_font_upright"> efficiency gain of data selection via D4 relative to the total cost of training as a function of model size on Instruct + Answers perplexity at <math id="S4.F4.2.1.1.m1.1" class="ltx_Math" alttext="R=0.25" display="inline"><semantics id="S4.F4.2.1.1.m1.1b"><mrow id="S4.F4.2.1.1.m1.1.1" xref="S4.F4.2.1.1.m1.1.1.cmml"><mi id="S4.F4.2.1.1.m1.1.1.2" xref="S4.F4.2.1.1.m1.1.1.2.cmml">R</mi><mo mathvariant="normal" id="S4.F4.2.1.1.m1.1.1.1" xref="S4.F4.2.1.1.m1.1.1.1.cmml">=</mo><mn mathvariant="normal" id="S4.F4.2.1.1.m1.1.1.3" xref="S4.F4.2.1.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.2.1.1.m1.1c"><apply id="S4.F4.2.1.1.m1.1.1.cmml" xref="S4.F4.2.1.1.m1.1.1"><eq id="S4.F4.2.1.1.m1.1.1.1.cmml" xref="S4.F4.2.1.1.m1.1.1.1"></eq><ci id="S4.F4.2.1.1.m1.1.1.2.cmml" xref="S4.F4.2.1.1.m1.1.1.2">ğ‘…</ci><cn type="float" id="S4.F4.2.1.1.m1.1.1.3.cmml" xref="S4.F4.2.1.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.2.1.1.m1.1d">R=0.25</annotation><annotation encoding="application/x-llamapun" id="S4.F4.2.1.1.m1.1e">italic_R = 0.25</annotation></semantics></math>.</span></span></figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">To demonstrate our methodâ€™s practicality, we must ensure the cost of selecting data is significantly less than this. As described in Section&nbsp;<a href="#S3.SS4" title="3.4 Data Selection Strategies (choices for ğ‘†) â€£ 3 Experimental Setup â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>, selecting data via D4 involves: first, embedding documents via a 125M OPT model; second, computing K-Means indices + distance to indices. The first step is completed on a single machine with 96 CPU cores in approximately one day.&nbsp;Given the two orders of magnitude difference between the prices of CPU and GPU cores <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Source: <a target="_blank" href="https://aws.amazon.com/ec2/pricing/on-demand/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aws.amazon.com/ec2/pricing/on-demand/</a></span></span></span>, we consider this cost negligible. For the second step, embedding 400B tokens with a 125M parameter model takes approximately 888 GPU hours, using the same A100 GPUs. Subtracting this from the <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">naive</span> efficiency gain of 4300 GPU hours, we arrive at an <span id="S4.SS3.p2.1.2" class="ltx_text ltx_font_italic">overall</span> efficiency gain of 3412 GPU hours. This is how much compute D4 saved us in practice when training our single 6.7B parameter model. In Figure&nbsp;<a href="#S4.F4" title="Figure 4 â€£ 4.3 Cost of data selection â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we redo this calculation for different model sizes and we see that <span id="S4.SS3.p2.1.3" class="ltx_text ltx_font_italic">overall</span> efficiency gain increases with model size. Based on this, we can conservatively estimate that D4 would have overall efficiency gains of 20% for LLama-65B <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> and 22% for OPT-175B <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Analysis of D4</h3>

<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Why does data selection hurt performance on web snapshots?</h4>

<figure id="S4.F5" class="ltx_figure"><img src="/html/2308.12284/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="831" height="422" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.4.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Left<span id="S4.F5.5.2.1" class="ltx_text ltx_font_medium">: Train-test similarity across validation sets. X-axis denotes the name of the validation set (refer to Section&nbsp;<a href="#S3.SS4" title="3.4 Data Selection Strategies (choices for ğ‘†) â€£ 3 Experimental Setup â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a> for more information about each validation set), and y-axis denotes the cosine distance to the nearest neighbor in the training set for the 1.3B OPT 40B baseline (the green triangle denotes mean, and the yellow bar denotes median). We observe that web-snapshots validation sets are closest to points in the training set. </span>Right<span id="S4.F5.5.2.2" class="ltx_text ltx_font_medium">: Analysis of the C4 validation set. (Top): Histogram of cosine distance to nearest neighbor in train. For each bin, we show the mean original perplexity (middle) and mean difference in perplexity after data selection (bottom). "Easy" (low original ppl) points close to the training set are generally the points most affected by data selection.</span></span></figcaption>
</figure>
<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p">While we observe consistent <span id="S4.SS4.SSS1.p1.1.1" class="ltx_text ltx_font_italic">average</span> perplexity improvements, Section&nbsp;<a href="#A1.SS3" title="A.3 Individual Breakdowns of Downstream Accuracy and PPL â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a> demonstrates that this perplexity improvement varies greatly across validation sets. More importantly, data selection always impairs performance on web snapshot validation sets such as CC-dedup, CommonCrawl, and C4. To investigate why this occurs, we embed each validation set into the same embedding space as the training set and search for the nearest neighbors to validation points in the training set for our 1.3B baseline model. In the left plot of Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we show that validation sets drawn from the same distribution as web-snapshots are closer to training set compared to other validation sets, while the right plot of Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows that data selection disproportionately affects these web-snapshot validation sets: on the top-right plot, we see that web validation sets reside in regions of the embedding space which are sparsified as a result of data selection (e.g. regions of space close to cluster centroids in the training set), and in the bottom-right plot we see that these points are also the most affected by data selection, since their perplexity after data selection significantly increases. Moreover, the middle-right plot shows that these validation points have the lowest perplexity before pruning indicating that these points are "easy" points, perhaps due to their proximity to the training set.</p>
</div>
<div id="S4.SS4.SSS1.p2" class="ltx_para">
<p id="S4.SS4.SSS1.p2.1" class="ltx_p">Given that some of our validation sets are extremely close to the training set, we question whether they are still strong indicators of generalization. In fact, in Figure&nbsp;<a href="#S4.F6" title="Figure 6 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we find evidence of a slight inverse relationship between perplexity on web snapshots and more robust indicators of LM ability, such as perplexity on instruction-tuned datasets and downstream accuracy. In contrast, we observe that perplexity on Instruct+Answers is positively correlated with downstream accuracy, suggesting that validation perplexity on instruction tuned data is a better measure of model quality. For this reason, we group most of our results in Section&nbsp;<a href="#S4" title="4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> into Web Snapshots and Non-web Snapshots (which consists of Web-Derived + Web-Independent from Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, see Section&nbsp;<a href="#A1.SS1.SSS4" title="A.1.4 Which validation sets go into the averages? â€£ A.1 Experimental Setup Details â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1.4</span></a> for a full-list of validation set names).</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_3"><img src="/html/2308.12284/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_flex_size_3 ltx_img_landscape" width="273" height="196" alt="Refer to caption"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_3"><img src="/html/2308.12284/assets/x7.png" id="S4.F6.g2" class="ltx_graphics ltx_centering ltx_flex_size_3 ltx_img_landscape" width="266" height="204" alt="Refer to caption"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_3"><img src="/html/2308.12284/assets/x8.png" id="S4.F6.g3" class="ltx_graphics ltx_centering ltx_flex_size_3 ltx_img_landscape" width="274" height="206" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">Correlation between (left): negative Instruct+Answers perplexity and negative web snapshot perplexity, (middle): Downstream accuracy and negative web snapshot perplexity, (right): Downstream accuracy and negative Instruct+Answers perplexity. Each point is one training configuration (1.3B OPT model, 40B tokens), with the only change being the data selection method and pretraining seed. Web snapshot perplexity is slightly negatively correlated with stronger indicators of LM ability.</span></figcaption>
</figure>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>Importance of re-clustering between SemDeDup and SSL Prototypes</h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.1" class="ltx_p">As mentioned in Section&nbsp;<a href="#S3.SS4" title="3.4 Data Selection Strategies (choices for ğ‘†) â€£ 3 Experimental Setup â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>, we hypothesize that sparsifying dense regions of space containing excessive semantic duplicates improves the clustering quality and is, therefore, critical to the performance of D4. To isolate the effect of re-clustering on D4, we run experiments with a version of D4 where we remove the re-clustering step (e.g. we keep the original clustering). As shown in Figure&nbsp;<a href="#S4.F7" title="Figure 7 â€£ 4.4.2 Importance of re-clustering between SemDeDup and SSL Prototypes â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, omitting the re-clustering step significantly worsens performance, and we observe in the rightmost plot of Figure&nbsp;<a href="#S4.F7" title="Figure 7 â€£ 4.4.2 Importance of re-clustering between SemDeDup and SSL Prototypes â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> that SemDeDup indeed removes extremely dense clusters surrounding centroids (e.g. duplicate-driven clusters). We analyze this in more depth in Section&nbsp;<a href="#A1.SS9" title="A.9 Investigating Duplicate-Driven Clusters â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.9</span></a>.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2308.12284/assets/x9.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="221" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Investigating the necessity of the re-clustering step in D4. We see that re-clustering improves perplexity across Web snapshots (left), Non-web snapshots (middle-left), and Instruct + Answers (middle-right). Right: Empirical CDF of mean distance to centroid, with and without re-clustering. Re-clustering removes duplicate driven clusters (clusters with low mean distance to centroid).</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Summary and Limitations</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We introduced D4, a method for data curation on LLMs that improves training efficiency by &nbsp;20% across multiple model scales, with larger gains at increased model scale. We also demonstrated that, in contrast to common practice, repeating data via epoching can be beneficial for LLM training, but only if the data subset is intelligently selected.
While we have shown encouraging efficiency gains and performance improvements via D4, our work has several limitations and many future directions.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Mixing different training distributions:</span> While we chose one data distribution to both select data and train on, modern LLM setups usually mix different data sources. Our method is likely complimentary to such pipelines: practitioners may use D4 to diversify and de-duplicate individual data sources and then mix data sources to provide additional diversity in their training dataset. We leave exploring the efficacy of D4 on a mix of training distributions as future work, but expect that this will yield further gains by reducing redundancy across datasets as well as within datasets.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Model scale:</span> Due to compute limitations, the largest models we evaluated were 6.7B parameters trained on 100B tokens. While, to our knowledge, this is the largest to date application of embedding based data curation approaches, further investigation at model scales exceeding 100B would be very interesting, particularly in light of our observation that the efficiency gain grows with model scale.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The authors would like to thank many people who helped bring this work to fruition: Srini Iyer, Yuchen Zhang, Todor Mihaylov, Jacob Xu Moya Chen, Mansheej Paul, Mitchell Wortsman, Amro Abbas, Aaditya Singh, Myra Cheng, and Matthew Leavitt. The authors would also like to thank Surya Ganguli, Mona Diab, and Xian Li for initial brainstorming and are grateful for help with compute infrastructure given by Henry Estela and Victoria Lin. Lastly, the authors would like to thank anonymous reviewers for improving the quality and writing of this paper.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abbas et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Amro Abbas, Kushal Tirumala, Daniel Simig, Surya Ganguli, and Ari&nbsp;S. Morcos.

</span>
<span class="ltx_bibblock">Semdedup: Data-efficient learning at web-scale through semantic
deduplication.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2303.09540, 2023.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Artetxe et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Mikel Artetxe, Shruti Bhosale, Naman Goyal, Todor Mihaylov, Myle Ott, Sam
Shleifer, Xi&nbsp;Victoria Lin, Jingfei Du, Srinivasan Iyer, Ramakanth Pasunuru,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Efficient large scale language modeling with mixtures of experts.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.10684</em>, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bach et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Stephen&nbsp;H. Bach, Victor Sanh, Zheng&nbsp;Xin Yong, Albert Webson, Colin Raffel,
Nihal&nbsp;V. Nayak, Abheesht Sharma, Taewoon Kim, M&nbsp;Saiful Bari, Thibault
FÃ©vry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik
Ben-David, Canwen Xu, Gunjan Chhablani, Han Wang, Jason&nbsp;Alan Fries, Maged&nbsp;S.
Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang,
Mike Tian-Jian Jiang, and Alexander&nbsp;M. Rush.

</span>
<span class="ltx_bibblock">Promptsource: An integrated development environment and repository
for natural language prompts.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2202.01279, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baumgartner et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan Squire, and Jeremy
Blackburn.

</span>
<span class="ltx_bibblock">The pushshift reddit dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the international AAAI conference on web and
social media</em>, volume&nbsp;14, pages 830â€“839, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biderman et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Stella Biderman, Hailey Schoelkopf, Quentin Anthony, Herbie Bradley, Kyle
Oâ€™Brien, Eric Hallahan, Mohammad&nbsp;Aflah Khan, Shivanshu Purohit, USVSN&nbsp;Sai
Prashanth, Edward Raff, et&nbsp;al.

</span>
<span class="ltx_bibblock">Pythia: A suite for analyzing large language models across training
and scaling.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.01373</em>, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Birodkar et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Vighnesh Birodkar, Hossein Mobahi, and Samy Bengio.

</span>
<span class="ltx_bibblock">Semantic redundancies in image-classification datasets: The 10% you
donâ€™t need.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1901.11409</em>, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bisk et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et&nbsp;al.

</span>
<span class="ltx_bibblock">Piqa: Reasoning about physical commonsense in natural language.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial
intelligence</em>, volume&nbsp;34, pages 7432â€“7439, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Broder [1997]</span>
<span class="ltx_bibblock">
Andrei&nbsp;Z Broder.

</span>
<span class="ltx_bibblock">On the resemblance and containment of documents.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings. Compression and Complexity of SEQUENCES 1997
(Cat. No. 97TB100171)</em>, pages 21â€“29. IEEE, 1997.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cazenavette et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
George Cazenavette, Tongzhou Wang, Antonio Torralba, Alexei&nbsp;A Efros, and
Jun-Yan Zhu.

</span>
<span class="ltx_bibblock">Dataset distillation by matching training trajectories.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pages 4750â€“4759, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chitta et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Kashyap Chitta, JosÃ©&nbsp;M Ãlvarez, Elmar Haussmann, and ClÃ©ment
Farabet.

</span>
<span class="ltx_bibblock">Training data subset search with ensemble active learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Intelligent Transportation Systems</em>,
23(9):14741â€“14752, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
Adam Roberts, Paul Barham, Hyung&nbsp;Won Chung, Charles Sutton, Sebastian
Gehrmann, et&nbsp;al.

</span>
<span class="ltx_bibblock">Palm: Scaling language modeling with pathways.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.02311</em>, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa
Schoenick, and Oyvind Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the ai2 reasoning
challenge.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1803.05457</em>, 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Tim Dettmers, Mike Lewis, Younes Belkada, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Llm. int8 (): 8-bit matrix multiplication for transformers at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2208.07339</em>, 2022.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Bo&nbsp;Dong, Cristian Lumezanu, Yuncong Chen, Dongjin Song, Takehiko Mizoguchi,
Haifeng Chen, and Latifur Khan.

</span>
<span class="ltx_bibblock">At the speed of sound: Efficient audio scene classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 International Conference on
Multimedia Retrieval</em>, ICMR â€™20, page 301â€“305, New York, NY, USA, 2020.
Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450370875.

</span>
<span class="ltx_bibblock">doi: <a href="10.1145/3372278.3390730" title="" class="ltx_ref ltx_Url">10.1145/3372278.3390730</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/3372278.3390730" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3372278.3390730</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feldman and Zhang [2020]</span>
<span class="ltx_bibblock">
Vitaly Feldman and Chiyuan Zhang.

</span>
<span class="ltx_bibblock">What neural networks memorize and why: Discovering the long tail via
influence estimation.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:2881â€“2891, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Leo Gao, Stella&nbsp;Rose Biderman, Sid Black, Laurence Golding, Travis Hoppe,
Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn
Presser, and Connor Leahy.

</span>
<span class="ltx_bibblock">The pile: An 800gb dataset of diverse text for language modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2101.00027, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Suchin Gururangan, Ana MarasoviÄ‡, Swabha Swayamdipta, Kyle Lo, Iz&nbsp;Beltagy,
Doug Downey, and Noah&nbsp;A Smith.

</span>
<span class="ltx_bibblock">Donâ€™t stop pretraining: Adapt language models to domains and tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.10964</em>, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks and Gimpel [2016]</span>
<span class="ltx_bibblock">
Dan Hendrycks and Kevin Gimpel.

</span>
<span class="ltx_bibblock">Gaussian error linear units (gelus).

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.08415</em>, 2016.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hernandez et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Danny Hernandez, Tom&nbsp;B. Brown, Tom Conerly, Nova DasSarma, Dawn Drain, Sheer
El-Showk, Nelson Elhage, Zac Hatfield-Dodds, T.&nbsp;J. Henighan, Tristan Hume,
Scott Johnston, Benjamin Mann, Christopher Olah, Catherine Olsson, Dario
Amodei, Nicholas Joseph, Jared Kaplan, and Sam McCandlish.

</span>
<span class="ltx_bibblock">Scaling laws and interpretability of learning from repeated data.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2205.10487, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffmann et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor
Cai, Eliza Rutherford, Diego de&nbsp;Las&nbsp;Casas, Lisa&nbsp;Anne Hendricks, Johannes
Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van&nbsp;den
Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich
Elsen, Jack&nbsp;W. Rae, Oriol Vinyals, and L.&nbsp;Sifre.

</span>
<span class="ltx_bibblock">Training compute-optimal large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2203.15556, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyer et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Srinivas Iyer, Xiaojuan Lin, Ramakanth Pasunuru, Todor Mihaylov, Daniel Simig,
Ping Yu, Kurt Shuster, Tianlu Wang, Qing Liu, Punit&nbsp;Singh Koura, Xian Li,
Brian Oâ€™Horo, Gabriel Pereyra, Jeff Wang, Christopher Dewan, Asli
Celikyilmaz, Luke Zettlemoyer, and Veselin Stoyanov.

</span>
<span class="ltx_bibblock">Opt-iml: Scaling language model instruction meta learning through the
lens of generalization.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2212.12017, 2022.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr
Bojanowski, Armand Joulin, and Edouard Grave.

</span>
<span class="ltx_bibblock">Unsupervised dense information retrieval with contrastive learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.09118</em>, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Angela&nbsp;H Jiang, Daniel L-K Wong, Giulio Zhou, David&nbsp;G Andersen, Jeffrey Dean,
Gregory&nbsp;R Ganger, Gauri Joshi, Michael Kaminksy, Michael Kozuch, Zachary&nbsp;C
Lipton, et&nbsp;al.

</span>
<span class="ltx_bibblock">Accelerating deep learning by focusing on the biggest losers.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.00762</em>, 2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Jeff Johnson, Matthijs Douze, and HervÃ© JÃ©gou.

</span>
<span class="ltx_bibblock">Billion-scale similarity search with GPUs.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>, 7(3):535â€“547, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaplan et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jared Kaplan, Sam McCandlish, T.&nbsp;J. Henighan, Tom&nbsp;B. Brown, Benjamin Chess,
Rewon Child, Scott Gray, Alec Radford, Jeff Wu, and Dario Amodei.

</span>
<span class="ltx_bibblock">Scaling laws for neural language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2001.08361, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba [2014]</span>
<span class="ltx_bibblock">
Diederik&nbsp;P Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6980</em>, 2014.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck,
Chris Callison-Burch, and Nicholas Carlini.

</span>
<span class="ltx_bibblock">Deduplicating training data makes language models better.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics</em>, 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levesque et&nbsp;al. [2012]</span>
<span class="ltx_bibblock">
Hector Levesque, Ernest Davis, and Leora Morgenstern.

</span>
<span class="ltx_bibblock">The winograd schema challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Thirteenth international conference on the principles of
knowledge representation and reasoning</em>, 2012.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Zichang Liu, Jue Wang, Tri Dao, Tianyi Zhou, Binhang Yuan, Zhao Song, Anshumali
Shrivastava, Ce&nbsp;Zhang, Yuandong Tian, Christopher Re, et&nbsp;al.

</span>
<span class="ltx_bibblock">Deja vu: Contextual sparsity for efficient llms at inference time,
2023.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
S.&nbsp;Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret
Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David&nbsp;M. Mimno, and Daphne
Ippolito.

</span>
<span class="ltx_bibblock">A pretrainerâ€™s guide to training data: Measuring the effects of data
age, domain coverage, quality, &amp; toxicity.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.13169, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meding et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Kristof Meding, Luca M&nbsp;Schulze Buschoff, Robert Geirhos, and Felix&nbsp;A Wichmann.

</span>
<span class="ltx_bibblock">Trivial or impossibleâ€“dichotomous data difficulty masks model
differences (on imagenet and beyond).

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.05922</em>, 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merity et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher.

</span>
<span class="ltx_bibblock">Pointer sentinel mixture models.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1609.07843</em>, 2016.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mihaylov et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">Can a suit of armor conduct electricity? a new dataset for open book
question answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1809.02789</em>, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mindermann et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
SÃ¶ren Mindermann, Jan&nbsp;M Brauner, Muhammed&nbsp;T Razzak, Mrinank Sharma, Andreas
Kirsch, Winnie Xu, Benedikt HÃ¶ltgen, Aidan&nbsp;N Gomez, Adrien Morisot,
Sebastian Farquhar, et&nbsp;al.

</span>
<span class="ltx_bibblock">Prioritized training on points that are learnable, worth learning,
and not yet learnt.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
15630â€“15649. PMLR, 2022.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mirzasoleiman et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Baharan Mirzasoleiman, Jeff Bilmes, and Jure Leskovec.

</span>
<span class="ltx_bibblock">Coresets for data-efficient training of machine learning models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
6950â€“6960. PMLR, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mostafazadeh et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra,
Lucy Vanderwende, Pushmeet Kohli, and James Allen.

</span>
<span class="ltx_bibblock">A corpus and evaluation framework for deeper understanding of
commonsense stories.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1604.01696</em>, 2016.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muennighoff et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Niklas Muennighoff, Alexander&nbsp;M. Rush, Boaz Barak, Teven&nbsp;Le Scao, Aleksandra
Piktus, Nouamane Tazi, Sampo Pyysalo, Thomas Wolf, and Colin Raffel.

</span>
<span class="ltx_bibblock">Scaling data-constrained language models.

</span>
<span class="ltx_bibblock">2023.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paul et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Mansheej Paul, Surya Ganguli, and Gintare&nbsp;Karolina Dziugaite.

</span>
<span class="ltx_bibblock">Deep learning on a data diet: Finding important examples early in
training.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
34:20596â€“20607, 2021.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru,
Alessandro Cappelli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay.

</span>
<span class="ltx_bibblock">The refinedweb dataset for falcon llm: Outperforming curated corpora
with web data, and web data only.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock">2019.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">The Journal of Machine Learning Research</em>, 21(1):5485â€“5551, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sakaguchi et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Keisuke Sakaguchi, Ronan&nbsp;Le Bras, Chandra Bhagavatula, and Yejin Choi.

</span>
<span class="ltx_bibblock">Winogrande: An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 64(9):99â€“106,
2021.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schaeffer et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo.

</span>
<span class="ltx_bibblock">Are emergent abilities of large language models a mirage?

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.15004</em>, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sener and Savarese [2017]</span>
<span class="ltx_bibblock">
Ozan Sener and Silvio Savarese.

</span>
<span class="ltx_bibblock">Active learning for convolutional neural networks: A core-set
approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1708.00489</em>, 2017.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shoeybi et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Mohammad Shoeybi, M&nbsp;Patwary, R&nbsp;Puri, P&nbsp;LeGresley, J&nbsp;Casper, B&nbsp;Megatron-LM
Catanzaro, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training multi-billion parameter language models using model
parallelism.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint cs.CL/1909.08053</em>, 2019.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Shaden Smith, Mostofa Patwary, Brandon Norick, Patrick LeGresley, Samyam
Rajbhandari, Jared Casper, Zhun Liu, Shrimai Prabhumoye, George Zerveas,
Vijay Korthikanti, et&nbsp;al.

</span>
<span class="ltx_bibblock">Using deepspeed and megatron to train megatron-turing nlg 530b, a
large-scale generative language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.11990</em>, 2022.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sorscher et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Ben Sorscher, Robert Geirhos, Shashank Shekhar, Surya Ganguli, and Ari&nbsp;S.
Morcos.

</span>
<span class="ltx_bibblock">Beyond neural scaling laws: beating power law scaling via data
pruning.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2206.14486, 2022.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tirumala et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Kushal Tirumala, Aram Markosyan, Luke Zettlemoyer, and Armen Aghajanyan.

</span>
<span class="ltx_bibblock">Memorization without overfitting: Analyzing the training dynamics of
large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
35:38274â€“38290, 2022.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Toneva et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Mariya Toneva, Alessandro Sordoni, Remi Tachet&nbsp;des Combes, Adam Trischler,
Yoshua Bengio, and Geoffrey&nbsp;J Gordon.

</span>
<span class="ltx_bibblock">An empirical study of example forgetting during deep neural network
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.05159</em>, 2018.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric
Hambro, Faisal Azhar, Aurâ€™elien Rodriguez, Armand Joulin, Edouard Grave, and
Guillaume Lample.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2302.13971, 2023.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Villalobos et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Pablo Villalobos, Jaime Sevilla, Lennart Heim, Tamay Besiroglu, Marius
Hobbhahn, and Anson Ho.

</span>
<span class="ltx_bibblock">Will we run out of data? an analysis of the limits of scaling
datasets in machine learning, 2022.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael,
Felix Hill, Omer Levy, and Samuel Bowman.

</span>
<span class="ltx_bibblock">Superglue: A stickier benchmark for general-purpose language
understanding systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza
Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut&nbsp;Selvan Dhanasekaran, Atharva
Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi&nbsp;Gary Lai,
Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi,
Maitreya Patel, Kuntal&nbsp;Kumar Pal, M.&nbsp;Moradshahi, Mihir Parmar, Mirali
Purohit, Neeraj Varshney, Phani&nbsp;Rohitha Kaza, Pulkit Verma, Ravsehaj&nbsp;Singh
Puri, Rushang Karia, Shailaja&nbsp;Keyur Sampat, Savan Doshi, Siddharth&nbsp;Deepak
Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral,
Yejin Choi, Noah&nbsp;A. Smith, Hanna Hajishirzi, and Daniel Khashabi.

</span>
<span class="ltx_bibblock">Super-naturalinstructions: Generalization via declarative
instructions on 1600+ nlp tasks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing</em>, 2022.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wenzek et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary,
Francisco Guzmâ€™an, Armand Joulin, and Edouard Grave.

</span>
<span class="ltx_bibblock">Ccnet: Extracting high quality monolingual datasets from web crawl
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/1911.00359, 2019.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et&nbsp;al. [2023a]</span>
<span class="ltx_bibblock">
Sang&nbsp;Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy
Liang, Quoc&nbsp;V. Le, Tengyu Ma, and Adams&nbsp;Wei Yu.

</span>
<span class="ltx_bibblock">Doremi: Optimizing data mixtures speeds up language model
pretraining.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2305.10429, 2023a.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et&nbsp;al. [2023b]</span>
<span class="ltx_bibblock">
Sang&nbsp;Michael Xie, Shibani Santurkar, Tengyu Ma, and Percy Liang.

</span>
<span class="ltx_bibblock">Data selection for language models via importance resampling.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2302.03169, 2023b.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et&nbsp;al. [2023]</span>
<span class="ltx_bibblock">
Fuzhao Xue, Yao Fu, Wangchunshu Zhou, Zangwei Zheng, and Yang You.

</span>
<span class="ltx_bibblock">To repeat or not to repeat: Insights from scaling llm under
token-crisis.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.13230</em>, 2023.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.

</span>
<span class="ltx_bibblock">Hellaswag: Can a machine really finish your sentence?

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.07830</em>, 2019.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. [2022]</span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
Chen, Christopher Dewan, Mona Diab, Xian Li, Xi&nbsp;Victoria Lin, Todor Mihaylov,
Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit&nbsp;Singh Koura, Anjali
Sridhar, Tianlu Wang, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Opt: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2205.01068, 2022.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Bo&nbsp;Zhao, Konda&nbsp;Reddy Mopuri, and Hakan Bilen.

</span>
<span class="ltx_bibblock">Dataset condensation with gradient matching.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.05929</em>, 2020.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. [2015]</span>
<span class="ltx_bibblock">
Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun,
Antonio Torralba, and Sanja Fidler.

</span>
<span class="ltx_bibblock">Aligning books and movies: Towards story-like visual explanations by
watching movies and reading books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pages 19â€“27, 2015.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Experimental Setup Details</h3>

<section id="A1.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.1 </span>Hyperparameters for model training</h4>

<div id="A1.SS1.SSS1.p1" class="ltx_para">
<p id="A1.SS1.SSS1.p1.6" class="ltx_p">As mentioned in Section&nbsp;<a href="#S3.SS4" title="3.4 Data Selection Strategies (choices for ğ‘†) â€£ 3 Experimental Setup â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>, we use the same hyperparameters and configurations as the original OPT model architecture from <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. We describe these hyperparameters briefly in Table&nbsp;<a href="#A1.T1" title="Table A1 â€£ A.1.1 Hyperparameters for model training â€£ A.1 Experimental Setup Details â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A1</span></a>.
We chose these configurations because they are openly available and have been used as the standard in many previous works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. All models use GELU activation <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, Adam optimizer <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> with <math id="A1.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\beta_{1}=0.9" display="inline"><semantics id="A1.SS1.SSS1.p1.1.m1.1a"><mrow id="A1.SS1.SSS1.p1.1.m1.1.1" xref="A1.SS1.SSS1.p1.1.m1.1.1.cmml"><msub id="A1.SS1.SSS1.p1.1.m1.1.1.2" xref="A1.SS1.SSS1.p1.1.m1.1.1.2.cmml"><mi id="A1.SS1.SSS1.p1.1.m1.1.1.2.2" xref="A1.SS1.SSS1.p1.1.m1.1.1.2.2.cmml">Î²</mi><mn id="A1.SS1.SSS1.p1.1.m1.1.1.2.3" xref="A1.SS1.SSS1.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.SS1.SSS1.p1.1.m1.1.1.1" xref="A1.SS1.SSS1.p1.1.m1.1.1.1.cmml">=</mo><mn id="A1.SS1.SSS1.p1.1.m1.1.1.3" xref="A1.SS1.SSS1.p1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS1.p1.1.m1.1b"><apply id="A1.SS1.SSS1.p1.1.m1.1.1.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1"><eq id="A1.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1.1"></eq><apply id="A1.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.SSS1.p1.1.m1.1.1.2.1.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1.2">subscript</csymbol><ci id="A1.SS1.SSS1.p1.1.m1.1.1.2.2.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1.2.2">ğ›½</ci><cn type="integer" id="A1.SS1.SSS1.p1.1.m1.1.1.2.3.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1.2.3">1</cn></apply><cn type="float" id="A1.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS1.p1.1.m1.1c">\beta_{1}=0.9</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS1.p1.1.m1.1d">italic_Î² start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9</annotation></semantics></math>, <math id="A1.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\beta_{2}=0.95" display="inline"><semantics id="A1.SS1.SSS1.p1.2.m2.1a"><mrow id="A1.SS1.SSS1.p1.2.m2.1.1" xref="A1.SS1.SSS1.p1.2.m2.1.1.cmml"><msub id="A1.SS1.SSS1.p1.2.m2.1.1.2" xref="A1.SS1.SSS1.p1.2.m2.1.1.2.cmml"><mi id="A1.SS1.SSS1.p1.2.m2.1.1.2.2" xref="A1.SS1.SSS1.p1.2.m2.1.1.2.2.cmml">Î²</mi><mn id="A1.SS1.SSS1.p1.2.m2.1.1.2.3" xref="A1.SS1.SSS1.p1.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="A1.SS1.SSS1.p1.2.m2.1.1.1" xref="A1.SS1.SSS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="A1.SS1.SSS1.p1.2.m2.1.1.3" xref="A1.SS1.SSS1.p1.2.m2.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS1.p1.2.m2.1b"><apply id="A1.SS1.SSS1.p1.2.m2.1.1.cmml" xref="A1.SS1.SSS1.p1.2.m2.1.1"><eq id="A1.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="A1.SS1.SSS1.p1.2.m2.1.1.1"></eq><apply id="A1.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="A1.SS1.SSS1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.SSS1.p1.2.m2.1.1.2.1.cmml" xref="A1.SS1.SSS1.p1.2.m2.1.1.2">subscript</csymbol><ci id="A1.SS1.SSS1.p1.2.m2.1.1.2.2.cmml" xref="A1.SS1.SSS1.p1.2.m2.1.1.2.2">ğ›½</ci><cn type="integer" id="A1.SS1.SSS1.p1.2.m2.1.1.2.3.cmml" xref="A1.SS1.SSS1.p1.2.m2.1.1.2.3">2</cn></apply><cn type="float" id="A1.SS1.SSS1.p1.2.m2.1.1.3.cmml" xref="A1.SS1.SSS1.p1.2.m2.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS1.p1.2.m2.1c">\beta_{2}=0.95</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS1.p1.2.m2.1d">italic_Î² start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.95</annotation></semantics></math>, <math id="A1.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="\epsilon=10^{-8}" display="inline"><semantics id="A1.SS1.SSS1.p1.3.m3.1a"><mrow id="A1.SS1.SSS1.p1.3.m3.1.1" xref="A1.SS1.SSS1.p1.3.m3.1.1.cmml"><mi id="A1.SS1.SSS1.p1.3.m3.1.1.2" xref="A1.SS1.SSS1.p1.3.m3.1.1.2.cmml">Ïµ</mi><mo id="A1.SS1.SSS1.p1.3.m3.1.1.1" xref="A1.SS1.SSS1.p1.3.m3.1.1.1.cmml">=</mo><msup id="A1.SS1.SSS1.p1.3.m3.1.1.3" xref="A1.SS1.SSS1.p1.3.m3.1.1.3.cmml"><mn id="A1.SS1.SSS1.p1.3.m3.1.1.3.2" xref="A1.SS1.SSS1.p1.3.m3.1.1.3.2.cmml">10</mn><mrow id="A1.SS1.SSS1.p1.3.m3.1.1.3.3" xref="A1.SS1.SSS1.p1.3.m3.1.1.3.3.cmml"><mo id="A1.SS1.SSS1.p1.3.m3.1.1.3.3a" xref="A1.SS1.SSS1.p1.3.m3.1.1.3.3.cmml">âˆ’</mo><mn id="A1.SS1.SSS1.p1.3.m3.1.1.3.3.2" xref="A1.SS1.SSS1.p1.3.m3.1.1.3.3.2.cmml">8</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS1.p1.3.m3.1b"><apply id="A1.SS1.SSS1.p1.3.m3.1.1.cmml" xref="A1.SS1.SSS1.p1.3.m3.1.1"><eq id="A1.SS1.SSS1.p1.3.m3.1.1.1.cmml" xref="A1.SS1.SSS1.p1.3.m3.1.1.1"></eq><ci id="A1.SS1.SSS1.p1.3.m3.1.1.2.cmml" xref="A1.SS1.SSS1.p1.3.m3.1.1.2">italic-Ïµ</ci><apply id="A1.SS1.SSS1.p1.3.m3.1.1.3.cmml" xref="A1.SS1.SSS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS1.p1.3.m3.1.1.3.1.cmml" xref="A1.SS1.SSS1.p1.3.m3.1.1.3">superscript</csymbol><cn type="integer" id="A1.SS1.SSS1.p1.3.m3.1.1.3.2.cmml" xref="A1.SS1.SSS1.p1.3.m3.1.1.3.2">10</cn><apply id="A1.SS1.SSS1.p1.3.m3.1.1.3.3.cmml" xref="A1.SS1.SSS1.p1.3.m3.1.1.3.3"><minus id="A1.SS1.SSS1.p1.3.m3.1.1.3.3.1.cmml" xref="A1.SS1.SSS1.p1.3.m3.1.1.3.3"></minus><cn type="integer" id="A1.SS1.SSS1.p1.3.m3.1.1.3.3.2.cmml" xref="A1.SS1.SSS1.p1.3.m3.1.1.3.3.2">8</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS1.p1.3.m3.1c">\epsilon=10^{-8}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS1.p1.3.m3.1d">italic_Ïµ = 10 start_POSTSUPERSCRIPT - 8 end_POSTSUPERSCRIPT</annotation></semantics></math>, weight decay set
to <math id="A1.SS1.SSS1.p1.4.m4.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A1.SS1.SSS1.p1.4.m4.1a"><mn id="A1.SS1.SSS1.p1.4.m4.1.1" xref="A1.SS1.SSS1.p1.4.m4.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS1.p1.4.m4.1b"><cn type="float" id="A1.SS1.SSS1.p1.4.m4.1.1.cmml" xref="A1.SS1.SSS1.p1.4.m4.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS1.p1.4.m4.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS1.p1.4.m4.1d">0.1</annotation></semantics></math>, and we clip gradient norms at 1.0. We use a polynomial learning rate schedule, where learning rate warms up from 0.0 to peak learning rate over the first 375 million tokens, and is then annealed to (<math id="A1.SS1.SSS1.p1.5.m5.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A1.SS1.SSS1.p1.5.m5.1a"><mn id="A1.SS1.SSS1.p1.5.m5.1.1" xref="A1.SS1.SSS1.p1.5.m5.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS1.p1.5.m5.1b"><cn type="float" id="A1.SS1.SSS1.p1.5.m5.1.1.cmml" xref="A1.SS1.SSS1.p1.5.m5.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS1.p1.5.m5.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS1.p1.5.m5.1d">0.1</annotation></semantics></math> * Peak LR) over the remaining <math id="A1.SS1.SSS1.p1.6.m6.1" class="ltx_Math" alttext="(T_{target}-375)" display="inline"><semantics id="A1.SS1.SSS1.p1.6.m6.1a"><mrow id="A1.SS1.SSS1.p1.6.m6.1.1.1" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.cmml"><mo stretchy="false" id="A1.SS1.SSS1.p1.6.m6.1.1.1.2" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.cmml">(</mo><mrow id="A1.SS1.SSS1.p1.6.m6.1.1.1.1" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.cmml"><msub id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.cmml"><mi id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.2" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.2.cmml">T</mi><mrow id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.cmml"><mi id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.2" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.2.cmml">t</mi><mo id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.3" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.3.cmml">a</mi><mo id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1a" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.4" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.4.cmml">r</mi><mo id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1b" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.5" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.5.cmml">g</mi><mo id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1c" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.6" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.6.cmml">e</mi><mo id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1d" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.7" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.7.cmml">t</mi></mrow></msub><mo id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.1" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.1.cmml">âˆ’</mo><mn id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.3" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.3.cmml">375</mn></mrow><mo stretchy="false" id="A1.SS1.SSS1.p1.6.m6.1.1.1.3" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS1.p1.6.m6.1b"><apply id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1"><minus id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.1.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.1"></minus><apply id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.1.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2">subscript</csymbol><ci id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.2.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.2">ğ‘‡</ci><apply id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3"><times id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.1"></times><ci id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.2.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.2">ğ‘¡</ci><ci id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.3.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.3">ğ‘</ci><ci id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.4.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.4">ğ‘Ÿ</ci><ci id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.5.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.5">ğ‘”</ci><ci id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.6.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.6">ğ‘’</ci><ci id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.7.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.2.3.7">ğ‘¡</ci></apply></apply><cn type="integer" id="A1.SS1.SSS1.p1.6.m6.1.1.1.1.3.cmml" xref="A1.SS1.SSS1.p1.6.m6.1.1.1.1.3">375</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS1.p1.6.m6.1c">(T_{target}-375)</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS1.p1.6.m6.1d">( italic_T start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT - 375 )</annotation></semantics></math> M tokens. We train all our models in fully sharded data parallel mode <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> using Megatron-LM Tensor Parallelism <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> with fp16 precision. For reproducibility (and perhaps the only difference from the original configuration in <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>) is that we do not use dropout.</p>
</div>
<figure id="A1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table A1</span>: </span><span id="A1.T1.3.2" class="ltx_text" style="font-size:90%;">Model architecture details. Most of the parameter configurations are the same as in Table 1 of <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. Batch size denotes the total tokens that the model sees during one gradient descent update.</span></figcaption>
<table id="A1.T1.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T1.4.1" class="ltx_tr">
<td id="A1.T1.4.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T1.4.1.1.1" class="ltx_text ltx_font_bold">Scale</span></td>
<td id="A1.T1.4.1.2" class="ltx_td ltx_align_center ltx_border_tt">Num Layers</td>
<td id="A1.T1.4.1.3" class="ltx_td ltx_align_center ltx_border_tt">Num Heads</td>
<td id="A1.T1.4.1.4" class="ltx_td ltx_align_center ltx_border_tt">Embedding Dim</td>
<td id="A1.T1.4.1.5" class="ltx_td ltx_align_center ltx_border_tt">Peak Learning Rate (LR)</td>
<td id="A1.T1.4.1.6" class="ltx_td ltx_align_center ltx_border_tt">Batch Size</td>
</tr>
<tr id="A1.T1.4.2" class="ltx_tr">
<td id="A1.T1.4.2.1" class="ltx_td ltx_align_center ltx_border_t">8M</td>
<td id="A1.T1.4.2.2" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="A1.T1.4.2.3" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="A1.T1.4.2.4" class="ltx_td ltx_align_center ltx_border_t">128</td>
<td id="A1.T1.4.2.5" class="ltx_td ltx_align_center ltx_border_t">1.0e-3</td>
<td id="A1.T1.4.2.6" class="ltx_td ltx_align_center ltx_border_t">0.5M</td>
</tr>
<tr id="A1.T1.4.3" class="ltx_tr">
<td id="A1.T1.4.3.1" class="ltx_td ltx_align_center">125M</td>
<td id="A1.T1.4.3.2" class="ltx_td ltx_align_center">12</td>
<td id="A1.T1.4.3.3" class="ltx_td ltx_align_center">12</td>
<td id="A1.T1.4.3.4" class="ltx_td ltx_align_center">768</td>
<td id="A1.T1.4.3.5" class="ltx_td ltx_align_center">6.0e-4</td>
<td id="A1.T1.4.3.6" class="ltx_td ltx_align_center">0.5M</td>
</tr>
<tr id="A1.T1.4.4" class="ltx_tr">
<td id="A1.T1.4.4.1" class="ltx_td ltx_align_center">1.3B</td>
<td id="A1.T1.4.4.2" class="ltx_td ltx_align_center">24</td>
<td id="A1.T1.4.4.3" class="ltx_td ltx_align_center">32</td>
<td id="A1.T1.4.4.4" class="ltx_td ltx_align_center">2048</td>
<td id="A1.T1.4.4.5" class="ltx_td ltx_align_center">2.0e-4</td>
<td id="A1.T1.4.4.6" class="ltx_td ltx_align_center">1M</td>
</tr>
<tr id="A1.T1.4.5" class="ltx_tr">
<td id="A1.T1.4.5.1" class="ltx_td ltx_align_center">6.7B</td>
<td id="A1.T1.4.5.2" class="ltx_td ltx_align_center">32</td>
<td id="A1.T1.4.5.3" class="ltx_td ltx_align_center">32</td>
<td id="A1.T1.4.5.4" class="ltx_td ltx_align_center">4096</td>
<td id="A1.T1.4.5.5" class="ltx_td ltx_align_center">1.2e-4</td>
<td id="A1.T1.4.5.6" class="ltx_td ltx_align_center">2M</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="A1.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.2 </span>Dataset Curation Details</h4>

<div id="A1.SS1.SSS2.p1" class="ltx_para">
<p id="A1.SS1.SSS2.p1.1" class="ltx_p">In this subsection, we describe how we curate <span id="A1.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_italic">CC-dedup</span>, the starting source dataset used throughout the paper. We start with 5 CommonCrawl dumps <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://commoncrawl.org/the-data/get-started/</span></span></span> which range from 2017 to 2020. We then use CC-net <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, to de-duplicate data at the paragraph level, remove non-English web pages, and filter out low-quality pages. The pipeline we use is identical to the pipeline used in <cite class="ltx_cite ltx_citemacro_citet">Touvron et&nbsp;al. [<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> (see the section after the subtitle "English CommonCrawl [67%]", within Section 2).</p>
</div>
<div id="A1.SS1.SSS2.p2" class="ltx_para">
<p id="A1.SS1.SSS2.p2.3" class="ltx_p">On top of this, we add an additional step of MinHash <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> de-duplication at the document-level. The parameters for MinHash are 20 hashes per signature, 20 buckets, and 1 row per bucket. These parameters are the default parameters in the spark implementation of MinHashLSH, and we did not do a hyperparameter sweep on these parameters due to compute limitations. Previous work has attempted running MinHash with much more aggressive parameters: <cite class="ltx_cite ltx_citemacro_citet">Lee et&nbsp;al. [<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Penedo et&nbsp;al. [<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> use <math id="A1.SS1.SSS2.p2.1.m1.1" class="ltx_Math" alttext="20" display="inline"><semantics id="A1.SS1.SSS2.p2.1.m1.1a"><mn id="A1.SS1.SSS2.p2.1.m1.1.1" xref="A1.SS1.SSS2.p2.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS2.p2.1.m1.1b"><cn type="integer" id="A1.SS1.SSS2.p2.1.m1.1.1.cmml" xref="A1.SS1.SSS2.p2.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS2.p2.1.m1.1c">20</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS2.p2.1.m1.1d">20</annotation></semantics></math> buckets, <math id="A1.SS1.SSS2.p2.2.m2.1" class="ltx_Math" alttext="450" display="inline"><semantics id="A1.SS1.SSS2.p2.2.m2.1a"><mn id="A1.SS1.SSS2.p2.2.m2.1.1" xref="A1.SS1.SSS2.p2.2.m2.1.1.cmml">450</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS2.p2.2.m2.1b"><cn type="integer" id="A1.SS1.SSS2.p2.2.m2.1.1.cmml" xref="A1.SS1.SSS2.p2.2.m2.1.1">450</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS2.p2.2.m2.1c">450</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS2.p2.2.m2.1d">450</annotation></semantics></math> hashes per bucket, and <math id="A1.SS1.SSS2.p2.3.m3.1" class="ltx_Math" alttext="9000" display="inline"><semantics id="A1.SS1.SSS2.p2.3.m3.1a"><mn id="A1.SS1.SSS2.p2.3.m3.1.1" xref="A1.SS1.SSS2.p2.3.m3.1.1.cmml">9000</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS2.p2.3.m3.1b"><cn type="integer" id="A1.SS1.SSS2.p2.3.m3.1.1.cmml" xref="A1.SS1.SSS2.p2.3.m3.1.1">9000</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS2.p2.3.m3.1c">9000</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS2.p2.3.m3.1d">9000</annotation></semantics></math> signatures per hash. We conjecture that more aggressive MinHash would remove more templates, resulting in a higher-quality starting dataset, potentially making the SemDeDup step of D4 less necessary. <cite class="ltx_cite ltx_citemacro_citet">Abbas et&nbsp;al. [<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> did find that the performance of MinHash from <cite class="ltx_cite ltx_citemacro_citet">Lee et&nbsp;al. [<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and SemDeDup are comparable at a fixed data selection ratio of 3.9% on C4, indicating that SemDeDup filters out similar data to aggressive MinHash does. We leave sweeping over these hyperparameters as future work.</p>
</div>
<div id="A1.SS1.SSS2.p3" class="ltx_para">
<p id="A1.SS1.SSS2.p3.1" class="ltx_p">We note that since our dataset is curated from CommonCrawl dumps, there is risk that our training set contains offensive or PII content. We note, however, that this risk is no more than that of standard language modeling curation such as <cite class="ltx_cite ltx_citemacro_citet">Touvron et&nbsp;al. [<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, since we use the same pipeline to filter CommonCrawl dumps.</p>
</div>
</section>
<section id="A1.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.3 </span>Parameters for Data Selection</h4>

<div id="A1.SS1.SSS3.p1" class="ltx_para">
<p id="A1.SS1.SSS3.p1.1" class="ltx_p">All methods introduced in Section&nbsp;<a href="#S3.SS4" title="3.4 Data Selection Strategies (choices for ğ‘†) â€£ 3 Experimental Setup â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a> involve clustering embeddings using K-Means. Our starting training dataset CC-dedup contains roughly 600 million documents in total. Running K-Means clustering on all 600 million 768-sized vectors would take a considerable amount of compute. Instead, we follow previous work <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> and randomly sample roughly 100M documents with which to calculate centroids. We normalize the embeddings for these 100M documents to have L2-norm of 1.0, and then use faiss <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> with the following parameters:</p>
</div>
<div id="A1.SS1.SSS3.p2" class="ltx_para">
<pre id="A1.SS1.SSS3.p2.1" class="ltx_verbatim ltx_font_typewriter">    faiss.Kmeans(
        768 # 125M OPT model embedding size,
        11000 # 11K clusters,
        niter=20 # 20 iterations,
        verbose=True,
        seed=0,
        gpu=False,
        spherical=True,
        min_points_per_centroid=1,
        max_points_per_centroid=100000000
    )
</pre>
</div>
<div id="A1.SS1.SSS3.p3" class="ltx_para">
<p id="A1.SS1.SSS3.p3.1" class="ltx_p">We choose <math id="A1.SS1.SSS3.p3.1.m1.1" class="ltx_Math" alttext="11000" display="inline"><semantics id="A1.SS1.SSS3.p3.1.m1.1a"><mn id="A1.SS1.SSS3.p3.1.m1.1.1" xref="A1.SS1.SSS3.p3.1.m1.1.1.cmml">11000</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p3.1.m1.1b"><cn type="integer" id="A1.SS1.SSS3.p3.1.m1.1.1.cmml" xref="A1.SS1.SSS3.p3.1.m1.1.1">11000</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p3.1.m1.1c">11000</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p3.1.m1.1d">11000</annotation></semantics></math> clusters following previous work <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and we note that this choice sticks to the heuristic that the number of clusters should roughly be the square root of the number of total points being clustered. We also note that in initial experiments for data selection at the 125M OPT model scale, we did not find a significant effect of number of clusters on the performance of our data selection methods (see Figure&nbsp;<a href="#A1.F1" title="Figure A1 â€£ A.1.3 Parameters for Data Selection â€£ A.1 Experimental Setup Details â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A1</span></a>) this finding agrees with <cite class="ltx_cite ltx_citemacro_citet">Abbas et&nbsp;al. [<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> who notice significant overlap between datasets selected by SemDeDup with different number of clusters (see Figure A2 in <cite class="ltx_cite ltx_citemacro_citet">Abbas et&nbsp;al. [<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>).</p>
</div>
<figure id="A1.F1" class="ltx_figure"><img src="/html/2308.12284/assets/x10.png" id="A1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="365" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F1.4.1.1" class="ltx_text" style="font-size:90%;">Figure A1</span>: </span><span id="A1.F1.5.2" class="ltx_text" style="font-size:90%;">Effect of number of clusters in K-Means on data selection performance. All models are 125M OPT models, where the training set (and starting source dataset) is C4 and we select data with SSL prototypes. The y-axis is the change in perplexity compared to baseline training, meaning that baseline training is at 0.0, and going <span id="A1.F1.5.2.1" class="ltx_text ltx_font_italic">down</span> on the graphs indicates <span id="A1.F1.5.2.2" class="ltx_text ltx_font_italic">better</span> performance. The x-axis is the source dataset size. We show results for average perplexity on Non-web snapshot validation sets (left) and Instruct + Answers (right). We notice that there is not a significant difference when changing number of clusters (e.g. if we drew error bars around each line, they would all be overlapping), but 11K clusters is generally among the top-3 best performing methods.</span></figcaption>
</figure>
<div id="A1.SS1.SSS3.p4" class="ltx_para">
<p id="A1.SS1.SSS3.p4.3" class="ltx_p">We deliberately set min points per centroids low and max points per centroid high so that faiss does not attempt to manually balance the clusters while doing K-Means. <cite class="ltx_cite ltx_citemacro_citet">Sorscher et&nbsp;al. [<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> found that explicitly class-balancing is important: they introduce the "class balance score" (see Section H of <cite class="ltx_cite ltx_citemacro_citet">Sorscher et&nbsp;al. [<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>) which is the expectation of the quantity <math id="A1.SS1.SSS3.p4.1.m1.1" class="ltx_Math" alttext="\frac{\text{size of majority class}}{\text{size of minority class}}" display="inline"><semantics id="A1.SS1.SSS3.p4.1.m1.1a"><mfrac id="A1.SS1.SSS3.p4.1.m1.1.1" xref="A1.SS1.SSS3.p4.1.m1.1.1.cmml"><mtext id="A1.SS1.SSS3.p4.1.m1.1.1.2" xref="A1.SS1.SSS3.p4.1.m1.1.1.2a.cmml">size of majority class</mtext><mtext id="A1.SS1.SSS3.p4.1.m1.1.1.3" xref="A1.SS1.SSS3.p4.1.m1.1.1.3a.cmml">size of minority class</mtext></mfrac><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p4.1.m1.1b"><apply id="A1.SS1.SSS3.p4.1.m1.1.1.cmml" xref="A1.SS1.SSS3.p4.1.m1.1.1"><divide id="A1.SS1.SSS3.p4.1.m1.1.1.1.cmml" xref="A1.SS1.SSS3.p4.1.m1.1.1"></divide><ci id="A1.SS1.SSS3.p4.1.m1.1.1.2a.cmml" xref="A1.SS1.SSS3.p4.1.m1.1.1.2"><mtext mathsize="70%" id="A1.SS1.SSS3.p4.1.m1.1.1.2.cmml" xref="A1.SS1.SSS3.p4.1.m1.1.1.2">size of majority class</mtext></ci><ci id="A1.SS1.SSS3.p4.1.m1.1.1.3a.cmml" xref="A1.SS1.SSS3.p4.1.m1.1.1.3"><mtext mathsize="70%" id="A1.SS1.SSS3.p4.1.m1.1.1.3.cmml" xref="A1.SS1.SSS3.p4.1.m1.1.1.3">size of minority class</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p4.1.m1.1c">\frac{\text{size of majority class}}{\text{size of minority class}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p4.1.m1.1d">divide start_ARG size of majority class end_ARG start_ARG size of minority class end_ARG</annotation></semantics></math> over all pairs of classes. They then set a hard limit for the class balance score of 0.5, meaning that "every class has at least 50% of the images that it would have when pruning all classes equally" <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. We consider the unsupervised-learning analog of the class-balance score, which we refer to as the "cluster balance" score. The cluster balance score is the expectation of the quantity <math id="A1.SS1.SSS3.p4.2.m2.1" class="ltx_Math" alttext="\frac{\text{size of bigger cluster}}{\text{size of smaller cluster}}" display="inline"><semantics id="A1.SS1.SSS3.p4.2.m2.1a"><mfrac id="A1.SS1.SSS3.p4.2.m2.1.1" xref="A1.SS1.SSS3.p4.2.m2.1.1.cmml"><mtext id="A1.SS1.SSS3.p4.2.m2.1.1.2" xref="A1.SS1.SSS3.p4.2.m2.1.1.2a.cmml">size of bigger cluster</mtext><mtext id="A1.SS1.SSS3.p4.2.m2.1.1.3" xref="A1.SS1.SSS3.p4.2.m2.1.1.3a.cmml">size of smaller cluster</mtext></mfrac><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p4.2.m2.1b"><apply id="A1.SS1.SSS3.p4.2.m2.1.1.cmml" xref="A1.SS1.SSS3.p4.2.m2.1.1"><divide id="A1.SS1.SSS3.p4.2.m2.1.1.1.cmml" xref="A1.SS1.SSS3.p4.2.m2.1.1"></divide><ci id="A1.SS1.SSS3.p4.2.m2.1.1.2a.cmml" xref="A1.SS1.SSS3.p4.2.m2.1.1.2"><mtext mathsize="70%" id="A1.SS1.SSS3.p4.2.m2.1.1.2.cmml" xref="A1.SS1.SSS3.p4.2.m2.1.1.2">size of bigger cluster</mtext></ci><ci id="A1.SS1.SSS3.p4.2.m2.1.1.3a.cmml" xref="A1.SS1.SSS3.p4.2.m2.1.1.3"><mtext mathsize="70%" id="A1.SS1.SSS3.p4.2.m2.1.1.3.cmml" xref="A1.SS1.SSS3.p4.2.m2.1.1.3">size of smaller cluster</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p4.2.m2.1c">\frac{\text{size of bigger cluster}}{\text{size of smaller cluster}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p4.2.m2.1d">divide start_ARG size of bigger cluster end_ARG start_ARG size of smaller cluster end_ARG</annotation></semantics></math> over all pairs of clusters. Across all of our data selection methods (and choices for R) we find that this value is generally equal to or bigger than <math id="A1.SS1.SSS3.p4.3.m3.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A1.SS1.SSS3.p4.3.m3.1a"><mn id="A1.SS1.SSS3.p4.3.m3.1.1" xref="A1.SS1.SSS3.p4.3.m3.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p4.3.m3.1b"><cn type="float" id="A1.SS1.SSS3.p4.3.m3.1.1.cmml" xref="A1.SS1.SSS3.p4.3.m3.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p4.3.m3.1c">0.5</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p4.3.m3.1d">0.5</annotation></semantics></math> without any explicit intervention. For this reason, we do not explicitly cluster balance, although we note that changing how many points are sampled from each cluster (based on properties of the cluster) is very interesting future work.</p>
</div>
<div id="A1.SS1.SSS3.p5" class="ltx_para">
<p id="A1.SS1.SSS3.p5.7" class="ltx_p">D4 parameters: The choice of parameters <math id="A1.SS1.SSS3.p5.1.m1.1" class="ltx_Math" alttext="R_{proto}" display="inline"><semantics id="A1.SS1.SSS3.p5.1.m1.1a"><msub id="A1.SS1.SSS3.p5.1.m1.1.1" xref="A1.SS1.SSS3.p5.1.m1.1.1.cmml"><mi id="A1.SS1.SSS3.p5.1.m1.1.1.2" xref="A1.SS1.SSS3.p5.1.m1.1.1.2.cmml">R</mi><mrow id="A1.SS1.SSS3.p5.1.m1.1.1.3" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.cmml"><mi id="A1.SS1.SSS3.p5.1.m1.1.1.3.2" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.2.cmml">p</mi><mo id="A1.SS1.SSS3.p5.1.m1.1.1.3.1" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.1.m1.1.1.3.3" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.3.cmml">r</mi><mo id="A1.SS1.SSS3.p5.1.m1.1.1.3.1a" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.1.m1.1.1.3.4" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.4.cmml">o</mi><mo id="A1.SS1.SSS3.p5.1.m1.1.1.3.1b" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.1.m1.1.1.3.5" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.5.cmml">t</mi><mo id="A1.SS1.SSS3.p5.1.m1.1.1.3.1c" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.1.m1.1.1.3.6" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.6.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p5.1.m1.1b"><apply id="A1.SS1.SSS3.p5.1.m1.1.1.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS3.p5.1.m1.1.1.1.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1">subscript</csymbol><ci id="A1.SS1.SSS3.p5.1.m1.1.1.2.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1.2">ğ‘…</ci><apply id="A1.SS1.SSS3.p5.1.m1.1.1.3.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1.3"><times id="A1.SS1.SSS3.p5.1.m1.1.1.3.1.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.1"></times><ci id="A1.SS1.SSS3.p5.1.m1.1.1.3.2.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.2">ğ‘</ci><ci id="A1.SS1.SSS3.p5.1.m1.1.1.3.3.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.3">ğ‘Ÿ</ci><ci id="A1.SS1.SSS3.p5.1.m1.1.1.3.4.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.4">ğ‘œ</ci><ci id="A1.SS1.SSS3.p5.1.m1.1.1.3.5.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.5">ğ‘¡</ci><ci id="A1.SS1.SSS3.p5.1.m1.1.1.3.6.cmml" xref="A1.SS1.SSS3.p5.1.m1.1.1.3.6">ğ‘œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p5.1.m1.1c">R_{proto}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p5.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_p italic_r italic_o italic_t italic_o end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="A1.SS1.SSS3.p5.2.m2.1" class="ltx_Math" alttext="R_{dedup}" display="inline"><semantics id="A1.SS1.SSS3.p5.2.m2.1a"><msub id="A1.SS1.SSS3.p5.2.m2.1.1" xref="A1.SS1.SSS3.p5.2.m2.1.1.cmml"><mi id="A1.SS1.SSS3.p5.2.m2.1.1.2" xref="A1.SS1.SSS3.p5.2.m2.1.1.2.cmml">R</mi><mrow id="A1.SS1.SSS3.p5.2.m2.1.1.3" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.cmml"><mi id="A1.SS1.SSS3.p5.2.m2.1.1.3.2" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.2.cmml">d</mi><mo id="A1.SS1.SSS3.p5.2.m2.1.1.3.1" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.2.m2.1.1.3.3" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.3.cmml">e</mi><mo id="A1.SS1.SSS3.p5.2.m2.1.1.3.1a" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.2.m2.1.1.3.4" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.4.cmml">d</mi><mo id="A1.SS1.SSS3.p5.2.m2.1.1.3.1b" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.2.m2.1.1.3.5" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.5.cmml">u</mi><mo id="A1.SS1.SSS3.p5.2.m2.1.1.3.1c" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.2.m2.1.1.3.6" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.6.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p5.2.m2.1b"><apply id="A1.SS1.SSS3.p5.2.m2.1.1.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS3.p5.2.m2.1.1.1.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1">subscript</csymbol><ci id="A1.SS1.SSS3.p5.2.m2.1.1.2.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1.2">ğ‘…</ci><apply id="A1.SS1.SSS3.p5.2.m2.1.1.3.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1.3"><times id="A1.SS1.SSS3.p5.2.m2.1.1.3.1.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.1"></times><ci id="A1.SS1.SSS3.p5.2.m2.1.1.3.2.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.2">ğ‘‘</ci><ci id="A1.SS1.SSS3.p5.2.m2.1.1.3.3.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.3">ğ‘’</ci><ci id="A1.SS1.SSS3.p5.2.m2.1.1.3.4.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.4">ğ‘‘</ci><ci id="A1.SS1.SSS3.p5.2.m2.1.1.3.5.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.5">ğ‘¢</ci><ci id="A1.SS1.SSS3.p5.2.m2.1.1.3.6.cmml" xref="A1.SS1.SSS3.p5.2.m2.1.1.3.6">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p5.2.m2.1c">R_{dedup}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p5.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_d italic_e italic_d italic_u italic_p end_POSTSUBSCRIPT</annotation></semantics></math> while using D4 will have impact on the performance of D4. Given limited compute, we are not able to sweep over these hyperparameters. Instead, we strategically choose these parameters: we first look at the highest value of <math id="A1.SS1.SSS3.p5.3.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="A1.SS1.SSS3.p5.3.m3.1a"><mi id="A1.SS1.SSS3.p5.3.m3.1.1" xref="A1.SS1.SSS3.p5.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p5.3.m3.1b"><ci id="A1.SS1.SSS3.p5.3.m3.1.1.cmml" xref="A1.SS1.SSS3.p5.3.m3.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p5.3.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p5.3.m3.1d">italic_R</annotation></semantics></math> in SemDeDup that results in perplexity improvement across validation sets. We choose the "highest value" because the purpose of SemDeDup is to remove duplicate-driven clusters and low <math id="A1.SS1.SSS3.p5.4.m4.1" class="ltx_Math" alttext="R" display="inline"><semantics id="A1.SS1.SSS3.p5.4.m4.1a"><mi id="A1.SS1.SSS3.p5.4.m4.1.1" xref="A1.SS1.SSS3.p5.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p5.4.m4.1b"><ci id="A1.SS1.SSS3.p5.4.m4.1.1.cmml" xref="A1.SS1.SSS3.p5.4.m4.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p5.4.m4.1c">R</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p5.4.m4.1d">italic_R</annotation></semantics></math> with SemDeDup generally removes more than just templates/semantic duplicates. As seen in Section&nbsp;<a href="#A1.SS3" title="A.3 Individual Breakdowns of Downstream Accuracy and PPL â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a>, this generally occured with <math id="A1.SS1.SSS3.p5.5.m5.1" class="ltx_Math" alttext="R_{dedup}=0.75" display="inline"><semantics id="A1.SS1.SSS3.p5.5.m5.1a"><mrow id="A1.SS1.SSS3.p5.5.m5.1.1" xref="A1.SS1.SSS3.p5.5.m5.1.1.cmml"><msub id="A1.SS1.SSS3.p5.5.m5.1.1.2" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.cmml"><mi id="A1.SS1.SSS3.p5.5.m5.1.1.2.2" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.2.cmml">R</mi><mrow id="A1.SS1.SSS3.p5.5.m5.1.1.2.3" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.cmml"><mi id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.2" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.2.cmml">d</mi><mo id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.3" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.3.cmml">e</mi><mo id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1a" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.4" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.4.cmml">d</mi><mo id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1b" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.5" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.5.cmml">u</mi><mo id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1c" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.6" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.6.cmml">p</mi></mrow></msub><mo id="A1.SS1.SSS3.p5.5.m5.1.1.1" xref="A1.SS1.SSS3.p5.5.m5.1.1.1.cmml">=</mo><mn id="A1.SS1.SSS3.p5.5.m5.1.1.3" xref="A1.SS1.SSS3.p5.5.m5.1.1.3.cmml">0.75</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p5.5.m5.1b"><apply id="A1.SS1.SSS3.p5.5.m5.1.1.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1"><eq id="A1.SS1.SSS3.p5.5.m5.1.1.1.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.1"></eq><apply id="A1.SS1.SSS3.p5.5.m5.1.1.2.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.SSS3.p5.5.m5.1.1.2.1.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2">subscript</csymbol><ci id="A1.SS1.SSS3.p5.5.m5.1.1.2.2.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.2">ğ‘…</ci><apply id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3"><times id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.1"></times><ci id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.2.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.2">ğ‘‘</ci><ci id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.3.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.3">ğ‘’</ci><ci id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.4.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.4">ğ‘‘</ci><ci id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.5.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.5">ğ‘¢</ci><ci id="A1.SS1.SSS3.p5.5.m5.1.1.2.3.6.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.2.3.6">ğ‘</ci></apply></apply><cn type="float" id="A1.SS1.SSS3.p5.5.m5.1.1.3.cmml" xref="A1.SS1.SSS3.p5.5.m5.1.1.3">0.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p5.5.m5.1c">R_{dedup}=0.75</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p5.5.m5.1d">italic_R start_POSTSUBSCRIPT italic_d italic_e italic_d italic_u italic_p end_POSTSUBSCRIPT = 0.75</annotation></semantics></math>. Thus, we chose <math id="A1.SS1.SSS3.p5.6.m6.1" class="ltx_Math" alttext="R_{dedup}=0.75" display="inline"><semantics id="A1.SS1.SSS3.p5.6.m6.1a"><mrow id="A1.SS1.SSS3.p5.6.m6.1.1" xref="A1.SS1.SSS3.p5.6.m6.1.1.cmml"><msub id="A1.SS1.SSS3.p5.6.m6.1.1.2" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.cmml"><mi id="A1.SS1.SSS3.p5.6.m6.1.1.2.2" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.2.cmml">R</mi><mrow id="A1.SS1.SSS3.p5.6.m6.1.1.2.3" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.cmml"><mi id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.2" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.2.cmml">d</mi><mo id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.3" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.3.cmml">e</mi><mo id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1a" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.4" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.4.cmml">d</mi><mo id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1b" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.5" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.5.cmml">u</mi><mo id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1c" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.6" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.6.cmml">p</mi></mrow></msub><mo id="A1.SS1.SSS3.p5.6.m6.1.1.1" xref="A1.SS1.SSS3.p5.6.m6.1.1.1.cmml">=</mo><mn id="A1.SS1.SSS3.p5.6.m6.1.1.3" xref="A1.SS1.SSS3.p5.6.m6.1.1.3.cmml">0.75</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p5.6.m6.1b"><apply id="A1.SS1.SSS3.p5.6.m6.1.1.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1"><eq id="A1.SS1.SSS3.p5.6.m6.1.1.1.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.1"></eq><apply id="A1.SS1.SSS3.p5.6.m6.1.1.2.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.SSS3.p5.6.m6.1.1.2.1.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2">subscript</csymbol><ci id="A1.SS1.SSS3.p5.6.m6.1.1.2.2.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.2">ğ‘…</ci><apply id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3"><times id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.1"></times><ci id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.2.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.2">ğ‘‘</ci><ci id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.3.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.3">ğ‘’</ci><ci id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.4.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.4">ğ‘‘</ci><ci id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.5.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.5">ğ‘¢</ci><ci id="A1.SS1.SSS3.p5.6.m6.1.1.2.3.6.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.2.3.6">ğ‘</ci></apply></apply><cn type="float" id="A1.SS1.SSS3.p5.6.m6.1.1.3.cmml" xref="A1.SS1.SSS3.p5.6.m6.1.1.3">0.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p5.6.m6.1c">R_{dedup}=0.75</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p5.6.m6.1d">italic_R start_POSTSUBSCRIPT italic_d italic_e italic_d italic_u italic_p end_POSTSUBSCRIPT = 0.75</annotation></semantics></math> and varied <math id="A1.SS1.SSS3.p5.7.m7.1" class="ltx_Math" alttext="R_{proto}" display="inline"><semantics id="A1.SS1.SSS3.p5.7.m7.1a"><msub id="A1.SS1.SSS3.p5.7.m7.1.1" xref="A1.SS1.SSS3.p5.7.m7.1.1.cmml"><mi id="A1.SS1.SSS3.p5.7.m7.1.1.2" xref="A1.SS1.SSS3.p5.7.m7.1.1.2.cmml">R</mi><mrow id="A1.SS1.SSS3.p5.7.m7.1.1.3" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.cmml"><mi id="A1.SS1.SSS3.p5.7.m7.1.1.3.2" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.2.cmml">p</mi><mo id="A1.SS1.SSS3.p5.7.m7.1.1.3.1" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.7.m7.1.1.3.3" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.3.cmml">r</mi><mo id="A1.SS1.SSS3.p5.7.m7.1.1.3.1a" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.7.m7.1.1.3.4" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.4.cmml">o</mi><mo id="A1.SS1.SSS3.p5.7.m7.1.1.3.1b" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.7.m7.1.1.3.5" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.5.cmml">t</mi><mo id="A1.SS1.SSS3.p5.7.m7.1.1.3.1c" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS1.SSS3.p5.7.m7.1.1.3.6" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.6.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p5.7.m7.1b"><apply id="A1.SS1.SSS3.p5.7.m7.1.1.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS3.p5.7.m7.1.1.1.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1">subscript</csymbol><ci id="A1.SS1.SSS3.p5.7.m7.1.1.2.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1.2">ğ‘…</ci><apply id="A1.SS1.SSS3.p5.7.m7.1.1.3.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1.3"><times id="A1.SS1.SSS3.p5.7.m7.1.1.3.1.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.1"></times><ci id="A1.SS1.SSS3.p5.7.m7.1.1.3.2.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.2">ğ‘</ci><ci id="A1.SS1.SSS3.p5.7.m7.1.1.3.3.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.3">ğ‘Ÿ</ci><ci id="A1.SS1.SSS3.p5.7.m7.1.1.3.4.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.4">ğ‘œ</ci><ci id="A1.SS1.SSS3.p5.7.m7.1.1.3.5.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.5">ğ‘¡</ci><ci id="A1.SS1.SSS3.p5.7.m7.1.1.3.6.cmml" xref="A1.SS1.SSS3.p5.7.m7.1.1.3.6">ğ‘œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p5.7.m7.1c">R_{proto}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS3.p5.7.m7.1d">italic_R start_POSTSUBSCRIPT italic_p italic_r italic_o italic_t italic_o end_POSTSUBSCRIPT</annotation></semantics></math> to obtain different data selection ratios for D4.</p>
</div>
</section>
<section id="A1.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.4 </span>Which validation sets go into the averages?</h4>

<div id="A1.SS1.SSS4.p1" class="ltx_para">
<p id="A1.SS1.SSS4.p1.1" class="ltx_p">For clarity, we explicitly state the validation sets which we consider "Web Snapshots", "Non Web Snapshots", and "Instruct + Answers" when reporting averages:</p>
</div>
<div id="A1.SS1.SSS4.p2" class="ltx_para">
<p id="A1.SS1.SSS4.p2.1" class="ltx_p"><span id="A1.SS1.SSS4.p2.1.1" class="ltx_text ltx_font_bold">Web Snapshots</span>: perplexity on validation set of C4, CC-dedup, CommonCrawl (from the Pile)</p>
</div>
<div id="A1.SS1.SSS4.p3" class="ltx_para">
<p id="A1.SS1.SSS4.p3.1" class="ltx_p"><span id="A1.SS1.SSS4.p3.1.1" class="ltx_text ltx_font_bold">Non-web Snapshots</span>: perplexity other validation sets from the Pile, comprising of OpenWebText2, HackerNews, Wikipedia (en), BookCorpusFair, DM Mathematics, Gutenberg PG-19, OpenSubtitles, and USPTO. Also included in this average is "redditflattened" (validation set from Pusshift.io Reddit <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>), "stories", "prompts_with_answers" (which is described below) and "prompts" (which is the same as "prompts_with_answers" but where each sample is just the instruction-tuning prompt without the answer).</p>
</div>
<div id="A1.SS1.SSS4.p4" class="ltx_para">
<p id="A1.SS1.SSS4.p4.1" class="ltx_p"><span id="A1.SS1.SSS4.p4.1.1" class="ltx_text ltx_font_bold">Instruct + Answers</span>: perplexity on instruction-tuning data from OPT-IML <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, where each sample contains both the instruction-tuning prompt and the answer (in Figure&nbsp;<a href="#A1.F4" title="Figure A4 â€£ A.3 Individual Breakdowns of Downstream Accuracy and PPL â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A4</span></a> this is referred to as "prompts_with_answers."</p>
</div>
<div id="A1.SS1.SSS4.p5" class="ltx_para">
<p id="A1.SS1.SSS4.p5.1" class="ltx_p">While the validation sets in web-snapshots and non-web snapshots are clear (they are either standard open-sourced datasets, or derived from commonly used data), we expect that the "Instruct + Answers" data might be new to some readers. We provide a few examples of what this validation set looks like in Table&nbsp;<a href="#A1.T2" title="Table A2 â€£ A.1.4 Which validation sets go into the averages? â€£ A.1 Experimental Setup Details â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A2</span></a>.</p>
</div>
<figure id="A1.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table A2</span>: </span><span id="A1.T2.3.2" class="ltx_text" style="font-size:90%;">Examples from "Instruct + Answers" validation set</span></figcaption>
<table id="A1.T2.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T2.4.1" class="ltx_tr">
<td id="A1.T2.4.1.1" class="ltx_td ltx_align_justify ltx_border_tt" style="width:398.3pt;"><span id="A1.T2.4.1.1.1" class="ltx_text ltx_font_bold ltx_align_top">Raw Text</span></td>
</tr>
<tr id="A1.T2.4.2" class="ltx_tr">
<td id="A1.T2.4.2.1" class="ltx_td ltx_align_justify ltx_border_t" style="width:398.3pt;">
<p id="A1.T2.4.2.1.1" class="ltx_p ltx_align_top">Instructions: In this task, you are given two phrases: Head and Tail, separated with &lt;sep&gt;. The Head and the Tail events are short phrases possibly involving participants. The names of specific people have been replaced by generic words (e.g., PersonX, PersonY, PersonZ). PersonX is always the subject of the event. You have to determine whether the Head is located or can be found at/in/on the Tail or not. Classify your answers into "Yes" and "No". The phrase may also contain "___", a placeholder that can be an object, a person, and/or an action.Input: Head: PersonX acknowledges gratefully the ___&lt;sep&gt;Tail: to use it Output: No</p>
</td>
</tr>
<tr id="A1.T2.4.3" class="ltx_tr">
<td id="A1.T2.4.3.1" class="ltx_td ltx_align_justify ltx_border_t" style="width:398.3pt;">
<p id="A1.T2.4.3.1.1" class="ltx_p ltx_align_top">Read the given sentence and if it is a general advice then indicate via "yes". Otherwise indicate via "no". advice is basically offering suggestions about the best course of action to someone. advice can come in a variety of forms, for example Direct advice and Indirect advice. (1) Direct advice: Using words (e.g., suggest, advice, recommend), verbs (e.g., can, could, should, may), or using questions (e.g., why donâ€™t youâ€™s, how about, have you thought about). (2) Indirect advice: contains hints from personal experiences with the intention for someone to do the same thing or statements that imply an action should (or should not) be taken. Input: Let it go. Output: yes"</p>
</td>
</tr>
<tr id="A1.T2.4.4" class="ltx_tr">
<td id="A1.T2.4.4.1" class="ltx_td ltx_align_justify ltx_border_t" style="width:398.3pt;">
<p id="A1.T2.4.4.1.1" class="ltx_p ltx_align_top">Instructions: You are given a sentence in English. Your job is to translate the English sentence into Italian. No! Demand to understand. Ask. Answer: No! Esigete di comprendere. Chiedete.</p>
</td>
</tr>
<tr id="A1.T2.4.5" class="ltx_tr">
<td id="A1.T2.4.5.1" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" style="width:398.3pt;">
<p id="A1.T2.4.5.1.1" class="ltx_p ltx_align_top">Task: In this task you will be given a list of integers. You should round each integer to the nearest tens place. That means you should round the number to the nearest multiple of 10.Input: [528, -636, -686, 368, -433, 992, 886] Answer: [530, -640, -690, 370, -430, 990, 890]</p>
</td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Efficiency gains across model scales and training</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.3" class="ltx_p">In this section, we investigate the relationship between model scale, and performance gain obtained by selecting data via D4. Specifically, we train three groups of models: 125M OPT models trained on <math id="A1.SS2.p1.1.m1.1" class="ltx_Math" alttext="T_{target}=3" display="inline"><semantics id="A1.SS2.p1.1.m1.1a"><mrow id="A1.SS2.p1.1.m1.1.1" xref="A1.SS2.p1.1.m1.1.1.cmml"><msub id="A1.SS2.p1.1.m1.1.1.2" xref="A1.SS2.p1.1.m1.1.1.2.cmml"><mi id="A1.SS2.p1.1.m1.1.1.2.2" xref="A1.SS2.p1.1.m1.1.1.2.2.cmml">T</mi><mrow id="A1.SS2.p1.1.m1.1.1.2.3" xref="A1.SS2.p1.1.m1.1.1.2.3.cmml"><mi id="A1.SS2.p1.1.m1.1.1.2.3.2" xref="A1.SS2.p1.1.m1.1.1.2.3.2.cmml">t</mi><mo id="A1.SS2.p1.1.m1.1.1.2.3.1" xref="A1.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.1.m1.1.1.2.3.3" xref="A1.SS2.p1.1.m1.1.1.2.3.3.cmml">a</mi><mo id="A1.SS2.p1.1.m1.1.1.2.3.1a" xref="A1.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.1.m1.1.1.2.3.4" xref="A1.SS2.p1.1.m1.1.1.2.3.4.cmml">r</mi><mo id="A1.SS2.p1.1.m1.1.1.2.3.1b" xref="A1.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.1.m1.1.1.2.3.5" xref="A1.SS2.p1.1.m1.1.1.2.3.5.cmml">g</mi><mo id="A1.SS2.p1.1.m1.1.1.2.3.1c" xref="A1.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.1.m1.1.1.2.3.6" xref="A1.SS2.p1.1.m1.1.1.2.3.6.cmml">e</mi><mo id="A1.SS2.p1.1.m1.1.1.2.3.1d" xref="A1.SS2.p1.1.m1.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.1.m1.1.1.2.3.7" xref="A1.SS2.p1.1.m1.1.1.2.3.7.cmml">t</mi></mrow></msub><mo id="A1.SS2.p1.1.m1.1.1.1" xref="A1.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="A1.SS2.p1.1.m1.1.1.3" xref="A1.SS2.p1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.m1.1b"><apply id="A1.SS2.p1.1.m1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1"><eq id="A1.SS2.p1.1.m1.1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1.1"></eq><apply id="A1.SS2.p1.1.m1.1.1.2.cmml" xref="A1.SS2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="A1.SS2.p1.1.m1.1.1.2.1.cmml" xref="A1.SS2.p1.1.m1.1.1.2">subscript</csymbol><ci id="A1.SS2.p1.1.m1.1.1.2.2.cmml" xref="A1.SS2.p1.1.m1.1.1.2.2">ğ‘‡</ci><apply id="A1.SS2.p1.1.m1.1.1.2.3.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3"><times id="A1.SS2.p1.1.m1.1.1.2.3.1.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.1"></times><ci id="A1.SS2.p1.1.m1.1.1.2.3.2.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.2">ğ‘¡</ci><ci id="A1.SS2.p1.1.m1.1.1.2.3.3.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.3">ğ‘</ci><ci id="A1.SS2.p1.1.m1.1.1.2.3.4.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.4">ğ‘Ÿ</ci><ci id="A1.SS2.p1.1.m1.1.1.2.3.5.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.5">ğ‘”</ci><ci id="A1.SS2.p1.1.m1.1.1.2.3.6.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.6">ğ‘’</ci><ci id="A1.SS2.p1.1.m1.1.1.2.3.7.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.7">ğ‘¡</ci></apply></apply><cn type="integer" id="A1.SS2.p1.1.m1.1.1.3.cmml" xref="A1.SS2.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.m1.1c">T_{target}=3</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.1.m1.1d">italic_T start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT = 3</annotation></semantics></math>B tokens, 1.3B OPT models trained on <math id="A1.SS2.p1.2.m2.1" class="ltx_Math" alttext="T_{target}=40" display="inline"><semantics id="A1.SS2.p1.2.m2.1a"><mrow id="A1.SS2.p1.2.m2.1.1" xref="A1.SS2.p1.2.m2.1.1.cmml"><msub id="A1.SS2.p1.2.m2.1.1.2" xref="A1.SS2.p1.2.m2.1.1.2.cmml"><mi id="A1.SS2.p1.2.m2.1.1.2.2" xref="A1.SS2.p1.2.m2.1.1.2.2.cmml">T</mi><mrow id="A1.SS2.p1.2.m2.1.1.2.3" xref="A1.SS2.p1.2.m2.1.1.2.3.cmml"><mi id="A1.SS2.p1.2.m2.1.1.2.3.2" xref="A1.SS2.p1.2.m2.1.1.2.3.2.cmml">t</mi><mo id="A1.SS2.p1.2.m2.1.1.2.3.1" xref="A1.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.2.m2.1.1.2.3.3" xref="A1.SS2.p1.2.m2.1.1.2.3.3.cmml">a</mi><mo id="A1.SS2.p1.2.m2.1.1.2.3.1a" xref="A1.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.2.m2.1.1.2.3.4" xref="A1.SS2.p1.2.m2.1.1.2.3.4.cmml">r</mi><mo id="A1.SS2.p1.2.m2.1.1.2.3.1b" xref="A1.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.2.m2.1.1.2.3.5" xref="A1.SS2.p1.2.m2.1.1.2.3.5.cmml">g</mi><mo id="A1.SS2.p1.2.m2.1.1.2.3.1c" xref="A1.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.2.m2.1.1.2.3.6" xref="A1.SS2.p1.2.m2.1.1.2.3.6.cmml">e</mi><mo id="A1.SS2.p1.2.m2.1.1.2.3.1d" xref="A1.SS2.p1.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.2.m2.1.1.2.3.7" xref="A1.SS2.p1.2.m2.1.1.2.3.7.cmml">t</mi></mrow></msub><mo id="A1.SS2.p1.2.m2.1.1.1" xref="A1.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="A1.SS2.p1.2.m2.1.1.3" xref="A1.SS2.p1.2.m2.1.1.3.cmml">40</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.2.m2.1b"><apply id="A1.SS2.p1.2.m2.1.1.cmml" xref="A1.SS2.p1.2.m2.1.1"><eq id="A1.SS2.p1.2.m2.1.1.1.cmml" xref="A1.SS2.p1.2.m2.1.1.1"></eq><apply id="A1.SS2.p1.2.m2.1.1.2.cmml" xref="A1.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="A1.SS2.p1.2.m2.1.1.2.1.cmml" xref="A1.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="A1.SS2.p1.2.m2.1.1.2.2.cmml" xref="A1.SS2.p1.2.m2.1.1.2.2">ğ‘‡</ci><apply id="A1.SS2.p1.2.m2.1.1.2.3.cmml" xref="A1.SS2.p1.2.m2.1.1.2.3"><times id="A1.SS2.p1.2.m2.1.1.2.3.1.cmml" xref="A1.SS2.p1.2.m2.1.1.2.3.1"></times><ci id="A1.SS2.p1.2.m2.1.1.2.3.2.cmml" xref="A1.SS2.p1.2.m2.1.1.2.3.2">ğ‘¡</ci><ci id="A1.SS2.p1.2.m2.1.1.2.3.3.cmml" xref="A1.SS2.p1.2.m2.1.1.2.3.3">ğ‘</ci><ci id="A1.SS2.p1.2.m2.1.1.2.3.4.cmml" xref="A1.SS2.p1.2.m2.1.1.2.3.4">ğ‘Ÿ</ci><ci id="A1.SS2.p1.2.m2.1.1.2.3.5.cmml" xref="A1.SS2.p1.2.m2.1.1.2.3.5">ğ‘”</ci><ci id="A1.SS2.p1.2.m2.1.1.2.3.6.cmml" xref="A1.SS2.p1.2.m2.1.1.2.3.6">ğ‘’</ci><ci id="A1.SS2.p1.2.m2.1.1.2.3.7.cmml" xref="A1.SS2.p1.2.m2.1.1.2.3.7">ğ‘¡</ci></apply></apply><cn type="integer" id="A1.SS2.p1.2.m2.1.1.3.cmml" xref="A1.SS2.p1.2.m2.1.1.3">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.2.m2.1c">T_{target}=40</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.2.m2.1d">italic_T start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT = 40</annotation></semantics></math>B tokens, and 6.7B OPT models trained on <math id="A1.SS2.p1.3.m3.1" class="ltx_Math" alttext="T_{target}=100" display="inline"><semantics id="A1.SS2.p1.3.m3.1a"><mrow id="A1.SS2.p1.3.m3.1.1" xref="A1.SS2.p1.3.m3.1.1.cmml"><msub id="A1.SS2.p1.3.m3.1.1.2" xref="A1.SS2.p1.3.m3.1.1.2.cmml"><mi id="A1.SS2.p1.3.m3.1.1.2.2" xref="A1.SS2.p1.3.m3.1.1.2.2.cmml">T</mi><mrow id="A1.SS2.p1.3.m3.1.1.2.3" xref="A1.SS2.p1.3.m3.1.1.2.3.cmml"><mi id="A1.SS2.p1.3.m3.1.1.2.3.2" xref="A1.SS2.p1.3.m3.1.1.2.3.2.cmml">t</mi><mo id="A1.SS2.p1.3.m3.1.1.2.3.1" xref="A1.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.3.m3.1.1.2.3.3" xref="A1.SS2.p1.3.m3.1.1.2.3.3.cmml">a</mi><mo id="A1.SS2.p1.3.m3.1.1.2.3.1a" xref="A1.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.3.m3.1.1.2.3.4" xref="A1.SS2.p1.3.m3.1.1.2.3.4.cmml">r</mi><mo id="A1.SS2.p1.3.m3.1.1.2.3.1b" xref="A1.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.3.m3.1.1.2.3.5" xref="A1.SS2.p1.3.m3.1.1.2.3.5.cmml">g</mi><mo id="A1.SS2.p1.3.m3.1.1.2.3.1c" xref="A1.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.3.m3.1.1.2.3.6" xref="A1.SS2.p1.3.m3.1.1.2.3.6.cmml">e</mi><mo id="A1.SS2.p1.3.m3.1.1.2.3.1d" xref="A1.SS2.p1.3.m3.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.SS2.p1.3.m3.1.1.2.3.7" xref="A1.SS2.p1.3.m3.1.1.2.3.7.cmml">t</mi></mrow></msub><mo id="A1.SS2.p1.3.m3.1.1.1" xref="A1.SS2.p1.3.m3.1.1.1.cmml">=</mo><mn id="A1.SS2.p1.3.m3.1.1.3" xref="A1.SS2.p1.3.m3.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.3.m3.1b"><apply id="A1.SS2.p1.3.m3.1.1.cmml" xref="A1.SS2.p1.3.m3.1.1"><eq id="A1.SS2.p1.3.m3.1.1.1.cmml" xref="A1.SS2.p1.3.m3.1.1.1"></eq><apply id="A1.SS2.p1.3.m3.1.1.2.cmml" xref="A1.SS2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="A1.SS2.p1.3.m3.1.1.2.1.cmml" xref="A1.SS2.p1.3.m3.1.1.2">subscript</csymbol><ci id="A1.SS2.p1.3.m3.1.1.2.2.cmml" xref="A1.SS2.p1.3.m3.1.1.2.2">ğ‘‡</ci><apply id="A1.SS2.p1.3.m3.1.1.2.3.cmml" xref="A1.SS2.p1.3.m3.1.1.2.3"><times id="A1.SS2.p1.3.m3.1.1.2.3.1.cmml" xref="A1.SS2.p1.3.m3.1.1.2.3.1"></times><ci id="A1.SS2.p1.3.m3.1.1.2.3.2.cmml" xref="A1.SS2.p1.3.m3.1.1.2.3.2">ğ‘¡</ci><ci id="A1.SS2.p1.3.m3.1.1.2.3.3.cmml" xref="A1.SS2.p1.3.m3.1.1.2.3.3">ğ‘</ci><ci id="A1.SS2.p1.3.m3.1.1.2.3.4.cmml" xref="A1.SS2.p1.3.m3.1.1.2.3.4">ğ‘Ÿ</ci><ci id="A1.SS2.p1.3.m3.1.1.2.3.5.cmml" xref="A1.SS2.p1.3.m3.1.1.2.3.5">ğ‘”</ci><ci id="A1.SS2.p1.3.m3.1.1.2.3.6.cmml" xref="A1.SS2.p1.3.m3.1.1.2.3.6">ğ‘’</ci><ci id="A1.SS2.p1.3.m3.1.1.2.3.7.cmml" xref="A1.SS2.p1.3.m3.1.1.2.3.7">ğ‘¡</ci></apply></apply><cn type="integer" id="A1.SS2.p1.3.m3.1.1.3.cmml" xref="A1.SS2.p1.3.m3.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.3.m3.1c">T_{target}=100</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.3.m3.1d">italic_T start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT = 100</annotation></semantics></math>B tokens. We notice in Figure&nbsp;<a href="#A1.F2" title="Figure A2 â€£ A.2 Efficiency gains across model scales and training â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A2</span></a> that D4 results in efficiency gains across the board in terms of perplexity. Surprisingly, these efficiency gains seem to increase with scale, indicating that at bigger model scales, D4 might lead to even more efficiency gains. We also see efficiency gains in 0-shot downstream accuracy for 1.3B and 6.7B model scales on the order of 30% for both 1.3B and 6.7B models, but we note that evaluation downstream performance on intermediate checkpoints is not completely fair due to unfinished learning rate schedule. Nonetheless, we see that downstream accuracy efficiency gains are not decreasing with scale.</p>
</div>
<figure id="A1.F2" class="ltx_figure"><img src="/html/2308.12284/assets/x11.png" id="A1.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="830" height="856" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure A2</span>: </span><span id="A1.F2.3.2" class="ltx_text" style="font-size:90%;">Training trajectory of OPT models trained on raw data (gray line) and data selected via D4 (pink line). Across model scales (1st row: 8M OPT models trained on 2B tokens, 2nd row: 125M OPT models trained on 3B tokens, 3rd row: 1.3B OPT models trained on 40B tokens, 4th row: 6.7B OPT models trained on 100B tokens), we see significant efficiency gains in both perplexity (left two columns) and 0-shot downstream accuracy on 16 NLP tasks (right column). Importantly, we see that increasing model scale does not decrease efficiency gains. All plots show mean and standard error across three seeds, except for the last row. We do not evaluate downstream accuracy for models smaller than 1.3B because they are likely too close to random performance to indicate whether a particular data selection method is better.
</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Individual Breakdowns of Downstream Accuracy and PPL</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.1" class="ltx_p">In Section&nbsp;<a href="#S4" title="4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we see that D4, SSL prototypes, and SemDeDup achieves significant gains on perplexity (averaged across different validation sets) and downstream accuracy (averaged across different NLP tasks) compared to baseline training. Further, we generally see that D4 outperforms SSL prototypes and SemDeDup. In this section, we provide a more fine-grained analysis of these claims across individual tasks.</p>
</div>
<div id="A1.SS3.p2" class="ltx_para">
<p id="A1.SS3.p2.1" class="ltx_p">For perplexity, we notice in Figure&nbsp;<a href="#A1.F4" title="Figure A4 â€£ A.3 Individual Breakdowns of Downstream Accuracy and PPL â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A4</span></a> that the claims in Section&nbsp;<a href="#S4" title="4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> generally hold across validation sets: for web snapshots validation sets such C4, CC-dedup, and CommonCrawl, we see performance worsens with data selection compared to baseline training, and that D4 generally has the slowest rate of performance degradation. We note that, across all non web-snapshot validation sets, there is no clear winner among data selection methods. We emphasize however that <span id="A1.SS3.p2.1.1" class="ltx_text ltx_font_italic">we observe consistent improvement over baseline training on most validation sets</span> we use â€” for example in Figure&nbsp;<a href="#A1.F4" title="Figure A4 â€£ A.3 Individual Breakdowns of Downstream Accuracy and PPL â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A4</span></a> we observe that, when selecting tokens from a 1.25x source dataset, all data selection methods improve over baseline across all validation sets except C4 and CC-dedup (however, as we explain in Section&nbsp;<a href="#S4.SS4" title="4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>, this decrease in performance on C4 and CC-dedup is expected).</p>
</div>
<div id="A1.SS3.p3" class="ltx_para">
<p id="A1.SS3.p3.1" class="ltx_p">For downstream accuracy, we chose to match the exact downstream evaluation done in <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> since we use OPT architecture and hyperparameters. Similar to <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. [<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, we notice considerable variability across the 16 NLP tasks in Figure&nbsp;<a href="#A1.F3" title="Figure A3 â€£ A.3 Individual Breakdowns of Downstream Accuracy and PPL â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A3</span></a>, motivating us to look at the mean downstream accuracy across tasks.</p>
</div>
<figure id="A1.F3" class="ltx_figure"><img src="/html/2308.12284/assets/x12.png" id="A1.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="830" height="870" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure A3</span>: </span><span id="A1.F3.3.2" class="ltx_text" style="font-size:90%;">Per-task breakdown of 0-shot downstream accuracy comparison across data selection methods, for 1.3B, 40B OPT model. For a description of the 16 NLP tasks shown above, see Section&nbsp;<a href="#S3.SS4" title="3.4 Data Selection Strategies (choices for ğ‘†) â€£ 3 Experimental Setup â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>. We note that there is considerable variability across individual downstream tasks.</span></figcaption>
</figure>
<figure id="A1.F4" class="ltx_figure"><img src="/html/2308.12284/assets/x13.png" id="A1.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="830" height="832" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure A4</span>: </span><span id="A1.F4.3.2" class="ltx_text" style="font-size:90%;">Perplexity as a function of source dataset size for 1.3B OPT model 40B token training runs, across data selection runs. Each plot above represents perplexity on an individual validation set (see Section&nbsp;<a href="#S3.SS4" title="3.4 Data Selection Strategies (choices for ğ‘†) â€£ 3 Experimental Setup â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a> for more information). Mean and standard error across 3 seeds is shown (standard error is denoted by shaded regions).</span></figcaption>
</figure>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>SSL prototypes and SemDeDup overlap</h3>

<figure id="A1.F5" class="ltx_figure">
<br class="ltx_break"><img src="/html/2308.12284/assets/x14.png" id="A1.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="269" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F5.6.3.1" class="ltx_text" style="font-size:90%;">Figure A5</span>: </span><span id="A1.F5.4.2" class="ltx_text" style="font-size:90%;">Similarity between data selection methods. Each square represents the percentage of training data that is intersecting, when selecting data via two different strategies. The <math id="A1.F5.3.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="A1.F5.3.1.m1.1b"><mi id="A1.F5.3.1.m1.1.1" xref="A1.F5.3.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="A1.F5.3.1.m1.1c"><ci id="A1.F5.3.1.m1.1.1.cmml" xref="A1.F5.3.1.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.3.1.m1.1d">x</annotation><annotation encoding="application/x-llamapun" id="A1.F5.3.1.m1.1e">italic_x</annotation></semantics></math> and <math id="A1.F5.4.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="A1.F5.4.2.m2.1b"><mi id="A1.F5.4.2.m2.1.1" xref="A1.F5.4.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="A1.F5.4.2.m2.1c"><ci id="A1.F5.4.2.m2.1.1.cmml" xref="A1.F5.4.2.m2.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F5.4.2.m2.1d">y</annotation><annotation encoding="application/x-llamapun" id="A1.F5.4.2.m2.1e">italic_y</annotation></semantics></math> axis enumerate different data selection strategies.</span></figcaption>
</figure>
<div id="A1.SS4.p1" class="ltx_para">
<p id="A1.SS4.p1.1" class="ltx_p">Figure&nbsp;<a href="#A1.F5" title="Figure A5 â€£ A.4 SSL prototypes and SemDeDup overlap â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A5</span></a> shows the overlap between datasets selected by SemDeDup and SSL Prototypes. While the two methods do not arrive at the same set of data points, there is a significant overlap between the datasets curated by the two methods. We hypothesize that this is because both SSL prototypes and SemDeDup prune away dense regions of space surrounding cluster centroids: by definition, SemDeDup sparsifies dense regions of space within a cluster; similarly, by definition, SSL prototypes will prune away datapoints close to the cluster centroids. Since K-means clustering places centroids in dense regions of space (see Figure&nbsp;<a href="#A1.F6" title="Figure A6 â€£ A.4 SSL prototypes and SemDeDup overlap â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A6</span></a> where we observe that the distribution of cosine distances to cluster centroid is skewed right), we know that the regions of space surroundings centroids will be dense, and expect SSL prototypes and SemDedup to have significant overlap. Qualitatively, we inspect a few examples of points close to cluster centroids in Figure&nbsp;<a href="#A1.T3" title="Table A3 â€£ A.9 Investigating Duplicate-Driven Clusters â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A3</span></a>, Figure&nbsp;<a href="#A1.T4" title="Table A4 â€£ A.9 Investigating Duplicate-Driven Clusters â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A4</span></a>, Figure&nbsp;<a href="#A1.T5" title="Table A5 â€£ A.9 Investigating Duplicate-Driven Clusters â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A5</span></a>, and see that examples close to cluster centroids can be semantically redundant (e.g. templates). Therefore, it makes sense that any reasonable data selection strategy would prioritize sparsifying these dense regions of space surrounding cluster centroids. As mentioned in Section&nbsp;<a href="#S3.SS4" title="3.4 Data Selection Strategies (choices for ğ‘†) â€£ 3 Experimental Setup â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>, sparsifying these dense regions of space containing excessive semantic duplicates is the original motiviation behind D4. As shown in Figure&nbsp;<a href="#S4.F7" title="Figure 7 â€£ 4.4.2 Importance of re-clustering between SemDeDup and SSL Prototypes â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, omitting the re-clustering step significantly worsens performance, and we observe in the rightmost plot of Figure&nbsp;<a href="#S4.F7" title="Figure 7 â€£ 4.4.2 Importance of re-clustering between SemDeDup and SSL Prototypes â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> that SemDeDup indeed removes duplicate-driven clusters.</p>
</div>
<figure id="A1.F6" class="ltx_figure"><img src="/html/2308.12284/assets/v7_aug16_images/distribution_of_cosine_distance_hist.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="221" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure A6</span>: </span><span id="A1.F6.3.2" class="ltx_text" style="font-size:90%;">Distribution of cosine distance to cluster centroids for &nbsp;50M randomly selected documents from the training set of CC-dedup. We notice that the distribution is skewed right, implying that datapoints are generally close to centroids.</span></figcaption>
</figure>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Investigating Train-Validation overlap</h3>

<div id="A1.SS5.p1" class="ltx_para">
<p id="A1.SS5.p1.1" class="ltx_p">As briefly described in Section&nbsp;<a href="#S4.SS4" title="4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>, we observe that many of our validation sets are close (in cosine distance) to our training sets, and the impact of data selection is varies across individual validation sets. Individual validation sets live in different regions of the embedding space, and as such they are affected differently by data selection. For example, one could imagine that web-snapshot validation sets such as C4 is close to CC-dedup in the embedding space, while esoteric validation sets (such as Gutenberg PG 19 or DM Mathematics) might be far. To quantify this, we first find the nearest neighbors in the training set to each validation point in all of our validation sets. We then qualitatively check (see Table&nbsp;<a href="#A1.T8" title="Table A8 â€£ A.9 Investigating Duplicate-Driven Clusters â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A8</span></a> and Table&nbsp;<a href="#A1.T9" title="Table A9 â€£ A.9 Investigating Duplicate-Driven Clusters â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A9</span></a> for examples) that nearest-neighbors in the training set truly convey information about validation points. we observe significant overlap between training points and validation points. We then quanitatively analyze how close each validation set is to the training set: in Figure&nbsp;<a href="#A1.F12" title="Figure A12 â€£ A.5 Investigating Train-Validation overlap â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A12</span></a>, we show the breakdown of this distribution for each validation set. We see a general trend, that web-snapshots validation sets are closest to the training set as they are skewed to the right, while more esoteric validation sets (Gutenberg, or Wikipedia (en)) are more centered or even slightly left-skewed.</p>
</div>
<div id="A1.SS5.p2" class="ltx_para">
<p id="A1.SS5.p2.1" class="ltx_p">Motivated by this, we compare validation sets side-by-side (in terms of distance to training set) in Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, and we see a similar trend. To further understand why different validation sets are affected differently by data selection, we loop through each data point in the validation set and record:</p>
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.1" class="ltx_p">distance to the training set e.g. how close is the validation point to the training set</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p">perplexity difference before and after data selection with D4 e.g. how much was this validation point affected by data selection</p>
</div>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i3.p1" class="ltx_para">
<p id="A1.I1.i3.p1.1" class="ltx_p">original perplexity e.g. how easy was this data point originally</p>
</div>
</li>
</ul>
</div>
<div id="A1.SS5.p3" class="ltx_para">
<p id="A1.SS5.p3.1" class="ltx_p">In Figure&nbsp;<a href="#A1.F11" title="Figure A11 â€£ A.5 Investigating Train-Validation overlap â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A11</span></a>, we observe an interesting trend: for web-snapshot validation sets such as C4, the validation points closest to the training set are both (1) the easiest (lowest perplexity) points before data selection and (2) the points most affected by data selection. This seems to indicate that these validation points are "easy" due to their proximity to training points, and when these training points are removed from the training set due to data selection, the close-by validation points become difficult for the model. We do not see this trend on non-web snapshot validation sets such as DM Mathematics and Open Subtitles; in fact, we see an opposite trend where points furthest from the training set are generally most affected by data selection.</p>
</div>
<div id="A1.SS5.p4" class="ltx_para">
<p id="A1.SS5.p4.1" class="ltx_p">As a sanity check, we change the sizes of validation sets used to plot Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> in Section&nbsp;<a href="#S4.SS4" title="4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>. We see in Figure&nbsp;<a href="#A1.F8" title="Figure A8 â€£ A.5 Investigating Train-Validation overlap â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A8</span></a> that controlling for validation set size, we get the same jump going from web-derived to web-independent validation sets. In running this experiment, we are forced to randomly sample if the particular validation set is too big; to ensure that such random sampling does not change the distance to nearest neighbor in the training dataset too much, we vary the amount we sample for three differently sized datasets in Figure&nbsp;<a href="#A1.F7" title="Figure A7 â€£ A.5 Investigating Train-Validation overlap â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A7</span></a>. We observe that changing the amount we randomly sample from a validation set does not significantly change the mean distance to nearest neighbor in train.</p>
</div>
<div id="A1.SS5.p5" class="ltx_para">
<p id="A1.SS5.p5.1" class="ltx_p">We also investigate whether the differences between validation sets in Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> is due to training set size. We would expect that smaller training sets are "further" from validation sets, since (). Indeed we see this in Figure&nbsp;<a href="#A1.F9" title="Figure A9 â€£ A.5 Investigating Train-Validation overlap â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A9</span></a>. However, we observe that the relative ordering of validation sets (with respect to average distance to the training set) remains the same for any fixed training dataset size. Moreover, we see in Figure&nbsp;<a href="#A1.F10" title="Figure A10 â€£ A.5 Investigating Train-Validation overlap â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A10</span></a> that the relative ranking of all validation sets as well as the jump from web-derived to web-independent validation sets from the original Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> holds, even as we reduce training dataset size.</p>
</div>
<figure id="A1.F7" class="ltx_figure">
<br class="ltx_break"><img src="/html/2308.12284/assets/x15.png" id="A1.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="831" height="366" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure A7</span>: </span><span id="A1.F7.3.2" class="ltx_text" style="font-size:90%;">Studying the effect of validation set size on cosine distance to nearest-neighbor in training set. On the x-axis, we vary the size of the validation set (by randomly sampling the original larger validation set), and the y-axis represents distance to nearest neighbor in the training set (averaged across the validation set). We observe that regardless of what fraction of the original validation set is sampled, the mean distance to the nearest neighbor in train does not change, indicating that Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> is not due to different validation set sizes.</span></figcaption>
</figure>
<figure id="A1.F8" class="ltx_figure">
<br class="ltx_break"><img src="/html/2308.12284/assets/x16.png" id="A1.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="385" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure A8</span>: </span><span id="A1.F8.3.2" class="ltx_text" style="font-size:90%;">Investigating whether Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> changes if we control for validation set size. In the Figure above, each validation set contains 50 data points, which is the size of the smallest validation set we use (BookCorpusFair). If a validation set is bigger than 50 data points, we randomly sample the validation set to obtain 50 data points.</span></figcaption>
</figure>
<figure id="A1.F9" class="ltx_figure">
<br class="ltx_break"><img src="/html/2308.12284/assets/x17.png" id="A1.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="370" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure A9</span>: </span><span id="A1.F9.3.2" class="ltx_text" style="font-size:90%;">Studying the effect of training set set size on cosine distance to nearest-neighbor in training set. On the x-axis, we vary the size of the training set (by randomly sampling the original training set), and the y-axis represents distance to nearest neighbor in the training set (averaged across the validation set). We observe that cosine distance to the training set increases with smaller training sets, but the relative ordering of validation sets (with respect to mean distance to training set) remains the same.</span></figcaption>
</figure>
<figure id="A1.F10" class="ltx_figure">
<br class="ltx_break"><img src="/html/2308.12284/assets/x18.png" id="A1.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="264" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure A10</span>: </span><span id="A1.F10.3.2" class="ltx_text" style="font-size:90%;">Investigating whether Figure&nbsp;<a href="#S4.F5" title="Figure 5 â€£ 4.4.1 Why does data selection hurt performance on web snapshots? â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> changes if we change training set size set size. In the figure above, each plot randomly samples a fraction of the training set (the fraction is denoted by the title of the plot). We see that the relative ranking of the validation sets generally remains the same, and there is consistently a jump between web-derived and web-independent validation sets.</span></figcaption>
</figure>
<figure id="A1.F11" class="ltx_figure">
<br class="ltx_break"><img src="/html/2308.12284/assets/x19.png" id="A1.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="412" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure A11</span>: </span><span id="A1.F11.3.2" class="ltx_text" style="font-size:90%;">(Top): Histogram of cosine distance to nearest neighbor in train. Within each bin, we show the mean original perplexity (middle) and mean difference in perplexity after data selection (bottom), for DM_Mathematics (left), OpenSubtitles(middle), and C4 (right). We note that points in the C4 validation set closest to the training set are both "easy" (perhaps because of proximity to training points) and are affected the most by data selection. We do not see this trend for non-web snapshot validation sets such as DM_Mathematics and OpenSubtitles.</span></figcaption>
</figure>
<figure id="A1.F12" class="ltx_figure"><img src="/html/2308.12284/assets/x20.png" id="A1.F12.g1" class="ltx_graphics ltx_centering ltx_img_square" width="830" height="811" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure A12</span>: </span><span id="A1.F12.3.2" class="ltx_text" style="font-size:90%;">Distribution of cosine distance to nearest neighbor in the training set, for each individual validation set.</span></figcaption>
</figure>
</section>
<section id="A1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Further investigation of repeating tokens</h3>

<div id="A1.SS6.p1" class="ltx_para">
<p id="A1.SS6.p1.1" class="ltx_p">In this section, we investigate whether the findings from Section&nbsp;<a href="#S4.SS2" title="4.2 Fixed data regime: what happens when we run out of data? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> hold across model scale, data selection ratio (e.g. number of epochs), and data selection method.</p>
</div>
<div id="A1.SS6.p2" class="ltx_para">
<p id="A1.SS6.p2.1" class="ltx_p"><span id="A1.SS6.p2.1.1" class="ltx_text ltx_font_bold">Across data selection methods</span>: We first take the same configuration as Section&nbsp;<a href="#S4.SS2" title="4.2 Fixed data regime: what happens when we run out of data? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, where we have a starting source dataset of 40B tokens, use each of our data selection methods with <math id="A1.SS6.p2.1.m1.1" class="ltx_Math" alttext="R=0.25" display="inline"><semantics id="A1.SS6.p2.1.m1.1a"><mrow id="A1.SS6.p2.1.m1.1.1" xref="A1.SS6.p2.1.m1.1.1.cmml"><mi id="A1.SS6.p2.1.m1.1.1.2" xref="A1.SS6.p2.1.m1.1.1.2.cmml">R</mi><mo id="A1.SS6.p2.1.m1.1.1.1" xref="A1.SS6.p2.1.m1.1.1.1.cmml">=</mo><mn id="A1.SS6.p2.1.m1.1.1.3" xref="A1.SS6.p2.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p2.1.m1.1b"><apply id="A1.SS6.p2.1.m1.1.1.cmml" xref="A1.SS6.p2.1.m1.1.1"><eq id="A1.SS6.p2.1.m1.1.1.1.cmml" xref="A1.SS6.p2.1.m1.1.1.1"></eq><ci id="A1.SS6.p2.1.m1.1.1.2.cmml" xref="A1.SS6.p2.1.m1.1.1.2">ğ‘…</ci><cn type="float" id="A1.SS6.p2.1.m1.1.1.3.cmml" xref="A1.SS6.p2.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p2.1.m1.1c">R=0.25</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p2.1.m1.1d">italic_R = 0.25</annotation></semantics></math> to select a subset of documents, and repeat over these documents until we reach the target token budget of 40B tokens. Note that this is at the 1.3B model scale. In Figure&nbsp;<a href="#A1.F13" title="Figure A13 â€£ A.6 Further investigation of repeating tokens â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A13</span></a> we see that repeating data selected by both SemDeDup and SSL prototypes also outperforms randomly selecting new data. However, we quickly notice that for <span id="A1.SS6.p2.1.2" class="ltx_text ltx_font_italic">fixed</span> data selection strategy (e.g. <span id="A1.SS6.p2.1.3" class="ltx_text ltx_font_italic">fixed</span> column in Figure&nbsp;<a href="#A1.F13" title="Figure A13 â€£ A.6 Further investigation of repeating tokens â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A13</span></a>), repeating tokens either outperforms or matched selecting new tokens. In other words: cleverly repeating tokens can outperform randomly selecting new tokens, but if we fix the data selection strategy (random, SemDeDup, SSL prototypes, or D4) then it is usually preferable to select new tokens. We also note in Figure&nbsp;<a href="#A1.F16" title="Figure A16 â€£ A.6 Further investigation of repeating tokens â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A16</span></a> that D4 outperforms other methods, although by a smaller margin than in the fixed-compute regime.</p>
</div>
<figure id="A1.F13" class="ltx_figure"><img src="/html/2308.12284/assets/x21.png" id="A1.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="460" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F13.3.1.1" class="ltx_text" style="font-size:90%;">Figure A13</span>: </span><span id="A1.F13.4.2" class="ltx_text" style="font-size:90%;">Effect of repeating tokens across data selection methods over training. X-axis denotes the number of updates, and the y-axis denotes average perplexity across non-web-snapshot validation sets (top row) and Instruct OPT (bottom row). Each column in the plot above denotes a different data selection method. Within each column: (1) the gray line denotes baseline training, (2) the colored-dashed line denotes repeating tokens via the specified data selection method, and (3) the colored-solid line denotes selecting new tokens via the specified data selection method. Repeating data is generally worse than selecting new data for a <span id="A1.F13.4.2.1" class="ltx_text ltx_font_italic">fixed data selection method</span> (e.g., fixed column).</span></figcaption>
</figure>
<div id="A1.SS6.p3" class="ltx_para">
<p id="A1.SS6.p3.3" class="ltx_p"><span id="A1.SS6.p3.3.1" class="ltx_text ltx_font_bold">Across model scale and data selection ratio</span>: We fix our data selection strategy as D4 as done in Section&nbsp;<a href="#S4.SS2" title="4.2 Fixed data regime: what happens when we run out of data? â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, but attempt repeating tokens across 3 model scales (125M, 1.3B, and 6.7B), and across data selection ratios (<math id="A1.SS6.p3.1.m1.1" class="ltx_Math" alttext="R=0.5" display="inline"><semantics id="A1.SS6.p3.1.m1.1a"><mrow id="A1.SS6.p3.1.m1.1.1" xref="A1.SS6.p3.1.m1.1.1.cmml"><mi id="A1.SS6.p3.1.m1.1.1.2" xref="A1.SS6.p3.1.m1.1.1.2.cmml">R</mi><mo id="A1.SS6.p3.1.m1.1.1.1" xref="A1.SS6.p3.1.m1.1.1.1.cmml">=</mo><mn id="A1.SS6.p3.1.m1.1.1.3" xref="A1.SS6.p3.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p3.1.m1.1b"><apply id="A1.SS6.p3.1.m1.1.1.cmml" xref="A1.SS6.p3.1.m1.1.1"><eq id="A1.SS6.p3.1.m1.1.1.1.cmml" xref="A1.SS6.p3.1.m1.1.1.1"></eq><ci id="A1.SS6.p3.1.m1.1.1.2.cmml" xref="A1.SS6.p3.1.m1.1.1.2">ğ‘…</ci><cn type="float" id="A1.SS6.p3.1.m1.1.1.3.cmml" xref="A1.SS6.p3.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p3.1.m1.1c">R=0.5</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p3.1.m1.1d">italic_R = 0.5</annotation></semantics></math> and <math id="A1.SS6.p3.2.m2.1" class="ltx_Math" alttext="R=0.25" display="inline"><semantics id="A1.SS6.p3.2.m2.1a"><mrow id="A1.SS6.p3.2.m2.1.1" xref="A1.SS6.p3.2.m2.1.1.cmml"><mi id="A1.SS6.p3.2.m2.1.1.2" xref="A1.SS6.p3.2.m2.1.1.2.cmml">R</mi><mo id="A1.SS6.p3.2.m2.1.1.1" xref="A1.SS6.p3.2.m2.1.1.1.cmml">=</mo><mn id="A1.SS6.p3.2.m2.1.1.3" xref="A1.SS6.p3.2.m2.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p3.2.m2.1b"><apply id="A1.SS6.p3.2.m2.1.1.cmml" xref="A1.SS6.p3.2.m2.1.1"><eq id="A1.SS6.p3.2.m2.1.1.1.cmml" xref="A1.SS6.p3.2.m2.1.1.1"></eq><ci id="A1.SS6.p3.2.m2.1.1.2.cmml" xref="A1.SS6.p3.2.m2.1.1.2">ğ‘…</ci><cn type="float" id="A1.SS6.p3.2.m2.1.1.3.cmml" xref="A1.SS6.p3.2.m2.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p3.2.m2.1c">R=0.25</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p3.2.m2.1d">italic_R = 0.25</annotation></semantics></math>). We see in Figure&nbsp;<a href="#A1.F15" title="Figure A15 â€£ A.6 Further investigation of repeating tokens â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A15</span></a> that repeating data with D4 outperforms randomly selecting new tokens across all model scales and choice of <math id="A1.SS6.p3.3.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="A1.SS6.p3.3.m3.1a"><mi id="A1.SS6.p3.3.m3.1.1" xref="A1.SS6.p3.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="A1.SS6.p3.3.m3.1b"><ci id="A1.SS6.p3.3.m3.1.1.cmml" xref="A1.SS6.p3.3.m3.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p3.3.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p3.3.m3.1d">italic_R</annotation></semantics></math>.</p>
</div>
<div id="A1.SS6.p4" class="ltx_para">
<p id="A1.SS6.p4.3" class="ltx_p">We note that for fixed <math id="A1.SS6.p4.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="A1.SS6.p4.1.m1.1a"><mi id="A1.SS6.p4.1.m1.1.1" xref="A1.SS6.p4.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="A1.SS6.p4.1.m1.1b"><ci id="A1.SS6.p4.1.m1.1.1.cmml" xref="A1.SS6.p4.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p4.1.m1.1c">R</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p4.1.m1.1d">italic_R</annotation></semantics></math>, different data selection methods will choose subsets of the source dataset that contain different amounts of tokens. This means that different data selection methods will epoch a different number of times. For example, for a 1.3B OPT model 40B token budget training run, if randomly repeating data with <math id="A1.SS6.p4.2.m2.1" class="ltx_Math" alttext="R=0.25" display="inline"><semantics id="A1.SS6.p4.2.m2.1a"><mrow id="A1.SS6.p4.2.m2.1.1" xref="A1.SS6.p4.2.m2.1.1.cmml"><mi id="A1.SS6.p4.2.m2.1.1.2" xref="A1.SS6.p4.2.m2.1.1.2.cmml">R</mi><mo id="A1.SS6.p4.2.m2.1.1.1" xref="A1.SS6.p4.2.m2.1.1.1.cmml">=</mo><mn id="A1.SS6.p4.2.m2.1.1.3" xref="A1.SS6.p4.2.m2.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p4.2.m2.1b"><apply id="A1.SS6.p4.2.m2.1.1.cmml" xref="A1.SS6.p4.2.m2.1.1"><eq id="A1.SS6.p4.2.m2.1.1.1.cmml" xref="A1.SS6.p4.2.m2.1.1.1"></eq><ci id="A1.SS6.p4.2.m2.1.1.2.cmml" xref="A1.SS6.p4.2.m2.1.1.2">ğ‘…</ci><cn type="float" id="A1.SS6.p4.2.m2.1.1.3.cmml" xref="A1.SS6.p4.2.m2.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p4.2.m2.1c">R=0.25</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p4.2.m2.1d">italic_R = 0.25</annotation></semantics></math> chooses a subset with 10B tokens and D4 with <math id="A1.SS6.p4.3.m3.1" class="ltx_Math" alttext="R=0.25" display="inline"><semantics id="A1.SS6.p4.3.m3.1a"><mrow id="A1.SS6.p4.3.m3.1.1" xref="A1.SS6.p4.3.m3.1.1.cmml"><mi id="A1.SS6.p4.3.m3.1.1.2" xref="A1.SS6.p4.3.m3.1.1.2.cmml">R</mi><mo id="A1.SS6.p4.3.m3.1.1.1" xref="A1.SS6.p4.3.m3.1.1.1.cmml">=</mo><mn id="A1.SS6.p4.3.m3.1.1.3" xref="A1.SS6.p4.3.m3.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p4.3.m3.1b"><apply id="A1.SS6.p4.3.m3.1.1.cmml" xref="A1.SS6.p4.3.m3.1.1"><eq id="A1.SS6.p4.3.m3.1.1.1.cmml" xref="A1.SS6.p4.3.m3.1.1.1"></eq><ci id="A1.SS6.p4.3.m3.1.1.2.cmml" xref="A1.SS6.p4.3.m3.1.1.2">ğ‘…</ci><cn type="float" id="A1.SS6.p4.3.m3.1.1.3.cmml" xref="A1.SS6.p4.3.m3.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p4.3.m3.1c">R=0.25</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p4.3.m3.1d">italic_R = 0.25</annotation></semantics></math> chooses a subset with 15B tokens, then the random run will epoch 4 times while the D4 run will epoch 2.67 times. To show this more clearly, we plot 1.3B and 6.7B repeated data runs with the x-axis changed to number of epochs in Figure&nbsp;<a href="#A1.F14" title="Figure A14 â€£ A.6 Further investigation of repeating tokens â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A14</span></a>. We see that up to roughly 2 epochs of data chosen with D4 significantly outperforms randomly selected new data; however, close to 5 epochs leads to worse performance.</p>
</div>
<figure id="A1.F14" class="ltx_figure"><img src="/html/2308.12284/assets/x22.png" id="A1.F14.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="249" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F14.2.1.1" class="ltx_text" style="font-size:90%;">Figure A14</span>: </span><span id="A1.F14.3.2" class="ltx_text" style="font-size:90%;">Comparison of repeating tokens with D4 (pink line), randomly selecting new tokens (horizontal dashed gray line), and randomly repeating data (gray line). We see with different epoch numbers. The y-axis denotes perplexity, and x-axis denotes number of epochs.</span></figcaption>
</figure>
<figure id="A1.F15" class="ltx_figure"><img src="/html/2308.12284/assets/x23.png" id="A1.F15.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="552" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F15.2.1.1" class="ltx_text" style="font-size:90%;">Figure A15</span>: </span><span id="A1.F15.3.2" class="ltx_text" style="font-size:90%;">Comparison of repeating tokens with D4 (pink line), randomly selecting new tokens (horizontal dashed gray line), and randomly repeating data (gray line). We see across model scales (top: 125M trained on 3B tokens; middle: 1.3B trained on 40B tokens; bottom: 6.7B trained on 100B tokens) and data selection ratios, repeating data selected by D4 outperforms randomly selecting new data.</span></figcaption>
</figure>
<figure id="A1.F16" class="ltx_figure"><img src="/html/2308.12284/assets/x24.png" id="A1.F16.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="276" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F16.6.3.1" class="ltx_text" style="font-size:90%;">Figure A16</span>: </span><span id="A1.F16.4.2" class="ltx_text" style="font-size:90%;">Comparison data selection methods when repeating data at the 125M, 3B token budget scale. The x-axis is data selection ratio <math id="A1.F16.3.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="A1.F16.3.1.m1.1b"><mi id="A1.F16.3.1.m1.1.1" xref="A1.F16.3.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="A1.F16.3.1.m1.1c"><ci id="A1.F16.3.1.m1.1.1.cmml" xref="A1.F16.3.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F16.3.1.m1.1d">R</annotation><annotation encoding="application/x-llamapun" id="A1.F16.3.1.m1.1e">italic_R</annotation></semantics></math>, and the y-axis is average perplexity on validation sets. We observe that selecting data to repeat via D4 outperforms other data selection methods, especially at low selection ratios <math id="A1.F16.4.2.m2.1" class="ltx_Math" alttext="R" display="inline"><semantics id="A1.F16.4.2.m2.1b"><mi id="A1.F16.4.2.m2.1.1" xref="A1.F16.4.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="A1.F16.4.2.m2.1c"><ci id="A1.F16.4.2.m2.1.1.cmml" xref="A1.F16.4.2.m2.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F16.4.2.m2.1d">R</annotation><annotation encoding="application/x-llamapun" id="A1.F16.4.2.m2.1e">italic_R</annotation></semantics></math> (note that low selection ratios in the fixed-data regime correspond to more epochs).</span></figcaption>
</figure>
</section>
<section id="A1.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.7 </span>Choice of Embedding Space</h3>

<div id="A1.SS7.p1" class="ltx_para">
<p id="A1.SS7.p1.1" class="ltx_p">All data selection methods we employ rely heavily on the quality of the underlying embedding space. We qualitatively analyzed the embedding produced by the last-token last-layer OPT 125M model and observed a bias towards end-of-document format. For example, if documents all end with an email or a standard phrase ("Buy our product today!"), then these documents would be clustered together. This likely helps detect templates (since templates tend to end their text in very similar ways), but has clear pitfalls â€” for example, if we took thousands of wikipedia articles about unrelated topics and appended the same email at the end of each article, they might be clustered together.</p>
</div>
<div id="A1.SS7.p2" class="ltx_para">
<p id="A1.SS7.p2.1" class="ltx_p">Motivated by this, we briefly experiment with different embedding spaces and discuss our results in this section.</p>
</div>
<section id="A1.SS7.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.7.1 </span>SentenceTransformer models</h4>

<div id="A1.SS7.SSS1.p1" class="ltx_para">
<p id="A1.SS7.SSS1.p1.1" class="ltx_p">BERT embeddings have generally been used to accomplish various NLP tasks, because BERT (unlike GPT/OPT) is able to attend to every token in the input when producing an embedding (BERT is a encoder-decoder model, while OPT/GPT are decoder only). While there are numerous BERT-style models available, we hoped to achieve an embedding space that focused on semantic similarity. Thus, we opted to use the widely popular SentenceTransformer models <span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://www.sbert.net/docs/pretrained_models.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sbert.net/docs/pretrained_models.html</a></span></span></span>, which are BERT-style models finetund specifically &gt;1B text similarity pairs. We choose the top model on the SentenceTransformer leaderboard (all-mpnet-base-v2) and the smallest well-performing model (all-Mini-LM-v6). Note that these models have max context length of 256 and 384 (respectively), and we stuck with the SentenceTransformer default of truncating inputs to fit the max sequence length (i.e. these embeddings only consider the beginning of documents).</p>
</div>
<div id="A1.SS7.SSS1.p2" class="ltx_para">
<p id="A1.SS7.SSS1.p2.1" class="ltx_p">We observe, in Figure&nbsp;<a href="#A1.F17" title="Figure A17 â€£ A.7.1 SentenceTransformer models â€£ A.7 Choice of Embedding Space â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A17</span></a> that at small model scales, sentence transformer embedding spaces outperforms the OPT embedding space. Given these initial results, we took our most overall-all efficient embedding space at the 1.3b model scale ("all-mini-lm-v6") and ran a 6.7b training run with it. Surprisingly, we observed that at larger model scale, the OPT embedding space outperforms the "all-mini-LM-v6" embedding space. Given that the difference between "all-mini-LM-v6" and "all-mp-net-base-v2" is generally small (see Figure&nbsp;<a href="#A1.F17" title="Figure A17 â€£ A.7.1 SentenceTransformer models â€£ A.7 Choice of Embedding Space â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A17</span></a>), we also expect the OPT embedding space to beat "all-mpnet-base-v2" at the 6.7b, although we were not able to complete this run due to compute restrictions. We see the same trend when we consider overall and naive efficiency of using D4 with different embedding spaces in Figure&nbsp;<a href="#A1.F18" title="Figure A18 â€£ A.7.1 SentenceTransformer models â€£ A.7 Choice of Embedding Space â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A18</span></a>.</p>
</div>
<div id="A1.SS7.SSS1.p3" class="ltx_para">
<p id="A1.SS7.SSS1.p3.1" class="ltx_p">In an effort to understand why SentenceTransformer embedding spaces perform worse at larger model scales, we qualitatively analyze the clusterings with each SentenceTransformer embedding space. We find that using D4 with "all-mp-net-base-v2" and "all-mini-lm-v6" disproportionately prunes long documents. We hypothesize that this is because sentence transformer models are trained and finetuned on actual sentence pairs, which very rarely saturate the max context length of the model. This might result in all "long" documents (or at least any input that is max-context-length size) seem out-of-distribution to the model. We guess that this results in long documents being clustered together, and therefore disproportionately affected during pruning. This might be especially relevant in domains like Wikipedia articles, where headers and introductions look semantically similar, but the actual content (past the first max-context-length tokens) is very different.</p>
</div>
<div id="A1.SS7.SSS1.p4" class="ltx_para">
<p id="A1.SS7.SSS1.p4.1" class="ltx_p">In an effort to circumvent this problem, we tried two approaches at a small model scale:</p>
</div>
<div id="A1.SS7.SSS1.p5" class="ltx_para">
<ul id="A1.I2" class="ltx_itemize">
<li id="A1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I2.i1.p1" class="ltx_para">
<p id="A1.I2.i1.p1.1" class="ltx_p">M1: Chunking long documents into max-context-length chunks, and averaging all-mini-LM-v6 embeddings across chunks to produce a final document embedding.</p>
</div>
</li>
<li id="A1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I2.i2.p1" class="ltx_para">
<p id="A1.I2.i2.p1.1" class="ltx_p">M2: Using Contriever <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> embeddings, where we chose the Contriever model because it is trained to determine if two sentences are from the same document, and therefore should be agnostic to position within a document.</p>
</div>
</li>
</ul>
</div>
<div id="A1.SS7.SSS1.p6" class="ltx_para">
<p id="A1.SS7.SSS1.p6.1" class="ltx_p">Both in terms of perplexity improvement at the end of training (see Figure&nbsp;<a href="#A1.F19" title="Figure A19 â€£ A.7.1 SentenceTransformer models â€£ A.7 Choice of Embedding Space â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A19</span></a>) and efficiency (see Figure&nbsp;<a href="#A1.F18" title="Figure A18 â€£ A.7.1 SentenceTransformer models â€£ A.7 Choice of Embedding Space â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A18</span></a>) we do not observe a significant difference between the OPT embedding space and embedding spaces M1 and M2 at the small model scale (125 million parameters). We note that M1 and M2 are significantly worse than the all-mp-net-base-v2 and all-mini-LM-v6 at small scales <span id="A1.SS7.SSS1.p6.1.1" class="ltx_text ltx_font_bold">and</span> suffer from the same problem of pruning away long documents (compared to the OPT embedding space), so we expect these models to under-perform the OPT embedding space at the 6.7b scale.</p>
</div>
<figure id="A1.F17" class="ltx_figure"><img src="/html/2308.12284/assets/x25.png" id="A1.F17.g1" class="ltx_graphics ltx_centering ltx_img_square" width="830" height="974" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F17.4.2.1" class="ltx_text" style="font-size:90%;">Figure A17</span>: </span><span id="A1.F17.2.1" class="ltx_text" style="font-size:90%;">Perplexity (y-axis) versus selection ratio <math id="A1.F17.2.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="A1.F17.2.1.m1.1b"><mi id="A1.F17.2.1.m1.1.1" xref="A1.F17.2.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="A1.F17.2.1.m1.1c"><ci id="A1.F17.2.1.m1.1.1.cmml" xref="A1.F17.2.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F17.2.1.m1.1d">R</annotation><annotation encoding="application/x-llamapun" id="A1.F17.2.1.m1.1e">italic_R</annotation></semantics></math> (x-axis) for different embedding spaces, when selecting data via D4. Across different 8m (top), 125m (middle) and 1.3b (bottom) model scales, we see that the SentenceTransformer embedding spaces outperform the OPT embedding space, but at the 6.7b model scale, we see that the OPT embedding space begins outperforming the all Mini LM v6 embedding space. We were unable to run an "all-mp-net-base-v2" 6.7b experiment due to compute restrictions, but we note that the difference between "all-mini-lm-v6" and "all-mp-net-base-v2" across model scales and selection ratios is generally small, so we expect the OPT embedding space to outperform the "all-mp-net-base-v2" at the 6.7b scale.</span></figcaption>
</figure>
<figure id="A1.F18" class="ltx_figure"><img src="/html/2308.12284/assets/x26.png" id="A1.F18.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="314" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F18.2.1.1" class="ltx_text" style="font-size:90%;">Figure A18</span>: </span><span id="A1.F18.3.2" class="ltx_text" style="font-size:90%;">Comparison of naive efficiency for different embedding spaces, when using D4 as the data selection strategy. Similar to Figure&nbsp;<a href="#A1.F17" title="Figure A17 â€£ A.7.1 SentenceTransformer models â€£ A.7 Choice of Embedding Space â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A17</span></a>, we see that all-mini-LM-v6 outperforms the OPT embedding space at small scale, but not at large (6.7b) model scale.</span></figcaption>
</figure>
<figure id="A1.F19" class="ltx_figure"><img src="/html/2308.12284/assets/x27.png" id="A1.F19.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="459" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F19.2.1.1" class="ltx_text" style="font-size:90%;">Figure A19</span>: </span><span id="A1.F19.3.2" class="ltx_text" style="font-size:90%;">Comparison of embedding spaces M1 (averaging embedding of all-mini-LM-v6 across all chunks in a document, where a chunk is defined as 256 tokens) and M2 (embeddings from the Contriever model), with the OPT model embedding space, when using D4 as a the selection strategy. We note that neither embedding space signifigantly outperforms the OPT model embedding space at the 125M scale.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A1.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.8 </span>Replicating Fixed Compute Results on C4</h3>

<div id="A1.SS8.p1" class="ltx_para">
<p id="A1.SS8.p1.1" class="ltx_p">In this section, we briefly show our results for comparing data selecting methods at the 125M scale, where the pre-training dataset is the C4 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> dataset instead of CC-dedup. We see in Figure&nbsp;<a href="#A1.F20" title="Figure A20 â€£ A.8 Replicating Fixed Compute Results on C4 â€£ Appendix A Appendix â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A20</span></a> that D4 generally outperforms other methods. These initial experiments motivates us to try comparing data selection methods on more heavily filtered web-data (i.e. CC-dedup).</p>
</div>
<figure id="A1.F20" class="ltx_figure"><img src="/html/2308.12284/assets/x28.png" id="A1.F20.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="261" alt="Refer to caption">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F20.9.4.1" class="ltx_text" style="font-size:90%;">Figure A20</span>: </span><span id="A1.F20.6.3" class="ltx_text" style="font-size:90%;">Comparison of data selection strategies with the OPT model embedding space, when using D4 as a the selection strategy, when using C4 as the starting training dataset. The x-axis is selectoin ratio <math id="A1.F20.4.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="A1.F20.4.1.m1.1b"><mi id="A1.F20.4.1.m1.1.1" xref="A1.F20.4.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="A1.F20.4.1.m1.1c"><ci id="A1.F20.4.1.m1.1.1.cmml" xref="A1.F20.4.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.F20.4.1.m1.1d">R</annotation><annotation encoding="application/x-llamapun" id="A1.F20.4.1.m1.1e">italic_R</annotation></semantics></math>, and the y-axis is perplexity difference compared to baseline (the horizontal gray dotted line at 0.0 represents our baseline i.e. when no data selection is done), so <span id="A1.F20.6.3.1" class="ltx_text ltx_font_bold">lower is better</span>. Notice that D4 and SemDeDup match at 90%, because we use <math id="A1.F20.5.2.m2.1" class="ltx_Math" alttext="R_{dedup}=0.9" display="inline"><semantics id="A1.F20.5.2.m2.1b"><mrow id="A1.F20.5.2.m2.1.1" xref="A1.F20.5.2.m2.1.1.cmml"><msub id="A1.F20.5.2.m2.1.1.2" xref="A1.F20.5.2.m2.1.1.2.cmml"><mi id="A1.F20.5.2.m2.1.1.2.2" xref="A1.F20.5.2.m2.1.1.2.2.cmml">R</mi><mrow id="A1.F20.5.2.m2.1.1.2.3" xref="A1.F20.5.2.m2.1.1.2.3.cmml"><mi id="A1.F20.5.2.m2.1.1.2.3.2" xref="A1.F20.5.2.m2.1.1.2.3.2.cmml">d</mi><mo id="A1.F20.5.2.m2.1.1.2.3.1" xref="A1.F20.5.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.F20.5.2.m2.1.1.2.3.3" xref="A1.F20.5.2.m2.1.1.2.3.3.cmml">e</mi><mo id="A1.F20.5.2.m2.1.1.2.3.1b" xref="A1.F20.5.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.F20.5.2.m2.1.1.2.3.4" xref="A1.F20.5.2.m2.1.1.2.3.4.cmml">d</mi><mo id="A1.F20.5.2.m2.1.1.2.3.1c" xref="A1.F20.5.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.F20.5.2.m2.1.1.2.3.5" xref="A1.F20.5.2.m2.1.1.2.3.5.cmml">u</mi><mo id="A1.F20.5.2.m2.1.1.2.3.1d" xref="A1.F20.5.2.m2.1.1.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.F20.5.2.m2.1.1.2.3.6" xref="A1.F20.5.2.m2.1.1.2.3.6.cmml">p</mi></mrow></msub><mo id="A1.F20.5.2.m2.1.1.1" xref="A1.F20.5.2.m2.1.1.1.cmml">=</mo><mn id="A1.F20.5.2.m2.1.1.3" xref="A1.F20.5.2.m2.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.F20.5.2.m2.1c"><apply id="A1.F20.5.2.m2.1.1.cmml" xref="A1.F20.5.2.m2.1.1"><eq id="A1.F20.5.2.m2.1.1.1.cmml" xref="A1.F20.5.2.m2.1.1.1"></eq><apply id="A1.F20.5.2.m2.1.1.2.cmml" xref="A1.F20.5.2.m2.1.1.2"><csymbol cd="ambiguous" id="A1.F20.5.2.m2.1.1.2.1.cmml" xref="A1.F20.5.2.m2.1.1.2">subscript</csymbol><ci id="A1.F20.5.2.m2.1.1.2.2.cmml" xref="A1.F20.5.2.m2.1.1.2.2">ğ‘…</ci><apply id="A1.F20.5.2.m2.1.1.2.3.cmml" xref="A1.F20.5.2.m2.1.1.2.3"><times id="A1.F20.5.2.m2.1.1.2.3.1.cmml" xref="A1.F20.5.2.m2.1.1.2.3.1"></times><ci id="A1.F20.5.2.m2.1.1.2.3.2.cmml" xref="A1.F20.5.2.m2.1.1.2.3.2">ğ‘‘</ci><ci id="A1.F20.5.2.m2.1.1.2.3.3.cmml" xref="A1.F20.5.2.m2.1.1.2.3.3">ğ‘’</ci><ci id="A1.F20.5.2.m2.1.1.2.3.4.cmml" xref="A1.F20.5.2.m2.1.1.2.3.4">ğ‘‘</ci><ci id="A1.F20.5.2.m2.1.1.2.3.5.cmml" xref="A1.F20.5.2.m2.1.1.2.3.5">ğ‘¢</ci><ci id="A1.F20.5.2.m2.1.1.2.3.6.cmml" xref="A1.F20.5.2.m2.1.1.2.3.6">ğ‘</ci></apply></apply><cn type="float" id="A1.F20.5.2.m2.1.1.3.cmml" xref="A1.F20.5.2.m2.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F20.5.2.m2.1d">R_{dedup}=0.9</annotation><annotation encoding="application/x-llamapun" id="A1.F20.5.2.m2.1e">italic_R start_POSTSUBSCRIPT italic_d italic_e italic_d italic_u italic_p end_POSTSUBSCRIPT = 0.9</annotation></semantics></math> and varied <math id="A1.F20.6.3.m3.1" class="ltx_Math" alttext="R_{proto}" display="inline"><semantics id="A1.F20.6.3.m3.1b"><msub id="A1.F20.6.3.m3.1.1" xref="A1.F20.6.3.m3.1.1.cmml"><mi id="A1.F20.6.3.m3.1.1.2" xref="A1.F20.6.3.m3.1.1.2.cmml">R</mi><mrow id="A1.F20.6.3.m3.1.1.3" xref="A1.F20.6.3.m3.1.1.3.cmml"><mi id="A1.F20.6.3.m3.1.1.3.2" xref="A1.F20.6.3.m3.1.1.3.2.cmml">p</mi><mo id="A1.F20.6.3.m3.1.1.3.1" xref="A1.F20.6.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.F20.6.3.m3.1.1.3.3" xref="A1.F20.6.3.m3.1.1.3.3.cmml">r</mi><mo id="A1.F20.6.3.m3.1.1.3.1b" xref="A1.F20.6.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.F20.6.3.m3.1.1.3.4" xref="A1.F20.6.3.m3.1.1.3.4.cmml">o</mi><mo id="A1.F20.6.3.m3.1.1.3.1c" xref="A1.F20.6.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.F20.6.3.m3.1.1.3.5" xref="A1.F20.6.3.m3.1.1.3.5.cmml">t</mi><mo id="A1.F20.6.3.m3.1.1.3.1d" xref="A1.F20.6.3.m3.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.F20.6.3.m3.1.1.3.6" xref="A1.F20.6.3.m3.1.1.3.6.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.F20.6.3.m3.1c"><apply id="A1.F20.6.3.m3.1.1.cmml" xref="A1.F20.6.3.m3.1.1"><csymbol cd="ambiguous" id="A1.F20.6.3.m3.1.1.1.cmml" xref="A1.F20.6.3.m3.1.1">subscript</csymbol><ci id="A1.F20.6.3.m3.1.1.2.cmml" xref="A1.F20.6.3.m3.1.1.2">ğ‘…</ci><apply id="A1.F20.6.3.m3.1.1.3.cmml" xref="A1.F20.6.3.m3.1.1.3"><times id="A1.F20.6.3.m3.1.1.3.1.cmml" xref="A1.F20.6.3.m3.1.1.3.1"></times><ci id="A1.F20.6.3.m3.1.1.3.2.cmml" xref="A1.F20.6.3.m3.1.1.3.2">ğ‘</ci><ci id="A1.F20.6.3.m3.1.1.3.3.cmml" xref="A1.F20.6.3.m3.1.1.3.3">ğ‘Ÿ</ci><ci id="A1.F20.6.3.m3.1.1.3.4.cmml" xref="A1.F20.6.3.m3.1.1.3.4">ğ‘œ</ci><ci id="A1.F20.6.3.m3.1.1.3.5.cmml" xref="A1.F20.6.3.m3.1.1.3.5">ğ‘¡</ci><ci id="A1.F20.6.3.m3.1.1.3.6.cmml" xref="A1.F20.6.3.m3.1.1.3.6">ğ‘œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F20.6.3.m3.1d">R_{proto}</annotation><annotation encoding="application/x-llamapun" id="A1.F20.6.3.m3.1e">italic_R start_POSTSUBSCRIPT italic_p italic_r italic_o italic_t italic_o end_POSTSUBSCRIPT</annotation></semantics></math> for this experiment.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.9 </span>Investigating Duplicate-Driven Clusters</h3>

<div id="A1.SS9.p1" class="ltx_para">
<p id="A1.SS9.p1.1" class="ltx_p">In this subsection, we present a few examples of duplicate-driven clusters, which are clusters that are very dense and near centroids. We find that these clusters tend to be filled with semantic duplicates and/or duplicated text. We generally can find such extreme duplicate-driven clusters by looking at clusters whose standard deviation of cosine distance to cluster centroid is less than 0.03. This is essentially looking at clusters in the lower tail of the empirical CDF in Figure&nbsp;<a href="#S4.F7" title="Figure 7 â€£ 4.4.2 Importance of re-clustering between SemDeDup and SSL Prototypes â€£ 4.4 Analysis of D4 â€£ 4 Results â€£ D4: Improving LLM Pretraining via Document De-Duplication and Diversification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (brown line). We present a few examples of such clusters below:</p>
</div>
<figure id="A1.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table A3</span>: </span><span id="A1.T3.3.2" class="ltx_text" style="font-size:90%;">Nearest Neighbors to Cluster Centroid 682</span></figcaption>
<table id="A1.T3.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T3.4.1" class="ltx_tr">
<td id="A1.T3.4.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A1.T3.4.1.1.1" class="ltx_text ltx_font_bold">Cosine Distance to Centroid</span></td>
<td id="A1.T3.4.1.2" class="ltx_td ltx_align_justify ltx_border_tt" style="width:284.5pt;"><span id="A1.T3.4.1.2.1" class="ltx_text ltx_font_bold ltx_align_top">Raw Text</span></td>
</tr>
<tr id="A1.T3.4.2" class="ltx_tr">
<td id="A1.T3.4.2.1" class="ltx_td ltx_align_left ltx_border_t">0.03581655</td>
<td id="A1.T3.4.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T3.4.2.2.1" class="ltx_p ltx_align_top">The USGS (U.S. Geological Survey) publishes a set of the most commonly used topographic maps of the U.S. called US â€¦â€¦â€¦ may have differences in elevation and topography, the historic weather at the two separate locations may be different as well.</p>
</td>
</tr>
<tr id="A1.T3.4.3" class="ltx_tr">
<td id="A1.T3.4.3.1" class="ltx_td ltx_align_left ltx_border_t">0.03584063</td>
<td id="A1.T3.4.3.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T3.4.3.2.1" class="ltx_p ltx_align_top">The USGS (U.S. Geological Survey) publishes a set of the most commonly used topographic maps of the U.S. called US â€¦â€¦â€¦ may have differences in elevation and topography, the historic weather at the two separate locations may be different as well.</p>
</td>
</tr>
<tr id="A1.T3.4.4" class="ltx_tr">
<td id="A1.T3.4.4.1" class="ltx_td ltx_align_left ltx_border_t">0.036803484</td>
<td id="A1.T3.4.4.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T3.4.4.2.1" class="ltx_p ltx_align_top">The USGS (U.S. Geological Survey) publishes a set of the most commonly used topographic maps of the U.S. called US â€¦â€¦â€¦ may have differences in elevation and topography, the historic weather at the two separate locations may be different as well.</p>
</td>
</tr>
<tr id="A1.T3.4.5" class="ltx_tr">
<td id="A1.T3.4.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_t">0.037270606</td>
<td id="A1.T3.4.5.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_b ltx_border_t" style="width:284.5pt;">
<p id="A1.T3.4.5.2.1" class="ltx_p ltx_align_top">Search Near Clinton County, OH: Trails National and State Parks City Parks Lakes Lookouts Marinas Historical Sites
The USGS (U.S. Geological â€¦â€¦â€¦ may have differences in elevation and topography, the historic weather at the two separate locations may be different as well.</p>
</td>
</tr>
</tbody></table>
</figure>
<figure id="A1.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T4.2.1.1" class="ltx_text" style="font-size:90%;">Table A4</span>: </span><span id="A1.T4.3.2" class="ltx_text" style="font-size:90%;">Nearest Neighbors to Cluster Centroid 975</span></figcaption>
<table id="A1.T4.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T4.4.1" class="ltx_tr">
<td id="A1.T4.4.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A1.T4.4.1.1.1" class="ltx_text ltx_font_bold">Cosine Distance to Centroid</span></td>
<td id="A1.T4.4.1.2" class="ltx_td ltx_align_justify ltx_border_tt" style="width:284.5pt;"><span id="A1.T4.4.1.2.1" class="ltx_text ltx_font_bold ltx_align_top">Raw Text</span></td>
</tr>
<tr id="A1.T4.4.2" class="ltx_tr">
<td id="A1.T4.4.2.1" class="ltx_td ltx_align_left ltx_border_t">0.011662006</td>
<td id="A1.T4.4.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T4.4.2.2.1" class="ltx_p ltx_align_top">The American Way, Inc.
The American Way, Inc. is a suspended Californian business entity incorporated 19th August 1949. is listed as â€¦â€¦â€¦ for bulk data downloadsI want to request the removal of a page on your websiteI want to contact California Explore</p>
</td>
</tr>
<tr id="A1.T4.4.3" class="ltx_tr">
<td id="A1.T4.4.3.1" class="ltx_td ltx_align_left ltx_border_t">0.012483656</td>
<td id="A1.T4.4.3.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T4.4.3.2.1" class="ltx_p ltx_align_top">John St-Amour, Inc.
John St-Amour, Inc. is a suspended Californian business entity incorporated 5th October 1962. is listed as the agent â€¦â€¦â€¦ for bulk data downloadsI want to request the removal of a page on your websiteI want to contact California Explore</p>
</td>
</tr>
<tr id="A1.T4.4.4" class="ltx_tr">
<td id="A1.T4.4.4.1" class="ltx_td ltx_align_left ltx_border_t">0.012564898</td>
<td id="A1.T4.4.4.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T4.4.4.2.1" class="ltx_p ltx_align_top">Joseph E. Barbour, Inc.
Joseph E. Barbour, Inc. is a suspended Californian business entity incorporated 27th January 1959. is listed as â€¦â€¦â€¦ for bulk data downloadsI want to request the removal of a page on your websiteI want to contact California Explore</p>
</td>
</tr>
<tr id="A1.T4.4.5" class="ltx_tr">
<td id="A1.T4.4.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_t">0.012756169</td>
<td id="A1.T4.4.5.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_b ltx_border_t" style="width:284.5pt;">
<p id="A1.T4.4.5.2.1" class="ltx_p ltx_align_top">The Jolly Boys, Inc.
The Jolly Boys, Inc. is a suspended Californian business entity incorporated 4th March 1955. is listed as â€¦â€¦â€¦ for bulk data downloadsI want to request the removal of a page on your websiteI want to contact California Explore</p>
</td>
</tr>
</tbody></table>
</figure>
<figure id="A1.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T5.2.1.1" class="ltx_text" style="font-size:90%;">Table A5</span>: </span><span id="A1.T5.3.2" class="ltx_text" style="font-size:90%;">Nearest Neighbors to Cluster Centroid 10715</span></figcaption>
<table id="A1.T5.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T5.4.1" class="ltx_tr">
<td id="A1.T5.4.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A1.T5.4.1.1.1" class="ltx_text ltx_font_bold">Cosine Distance to Centroid</span></td>
<td id="A1.T5.4.1.2" class="ltx_td ltx_align_justify ltx_border_tt" style="width:284.5pt;"><span id="A1.T5.4.1.2.1" class="ltx_text ltx_font_bold ltx_align_top">Raw Text</span></td>
</tr>
<tr id="A1.T5.4.2" class="ltx_tr">
<td id="A1.T5.4.2.1" class="ltx_td ltx_align_left ltx_border_t">0.035506427</td>
<td id="A1.T5.4.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T5.4.2.2.1" class="ltx_p ltx_align_top">Search hundreds of travel sites at once for hotel deals at Hotel Olympic
Kornarou Square 44, Heraklion, Greece
34 m Bembo Fountain
262 â€¦â€¦â€¦ hundreds of travel sites to help you find and book the hotel deal at Hotel Olympic that suits you best.</p>
</td>
</tr>
<tr id="A1.T5.4.3" class="ltx_tr">
<td id="A1.T5.4.3.1" class="ltx_td ltx_align_left ltx_border_t">0.036230028</td>
<td id="A1.T5.4.3.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T5.4.3.2.1" class="ltx_p ltx_align_top">Search hundreds of travel sites at once for hotel deals at Hotel Estrella del Norte
Juan Hormaechea, s/n, 39195 Isla, Cantabria, â€¦â€¦â€¦ travel sites to help you find and book the hotel deal at Hotel Estrella del Norte that suits you best.</p>
</td>
</tr>
<tr id="A1.T5.4.4" class="ltx_tr">
<td id="A1.T5.4.4.1" class="ltx_td ltx_align_left ltx_border_t">0.036280274</td>
<td id="A1.T5.4.4.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T5.4.4.2.1" class="ltx_p ltx_align_top">Search hundreds of travel sites at once for hotel deals at H10 Costa Adeje Palace
Provided by H10 Costa Adeje Palace
Provided â€¦â€¦â€¦ travel sites to help you find and book the hotel deal at H10 Costa Adeje Palace that suits you best.</p>
</td>
</tr>
<tr id="A1.T5.4.5" class="ltx_tr">
<td id="A1.T5.4.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_t">0.036827266</td>
<td id="A1.T5.4.5.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_b ltx_border_t" style="width:284.5pt;">
<p id="A1.T5.4.5.2.1" class="ltx_p ltx_align_top">Search hundreds of travel sites at once for hotel deals at Hotel Miguel Angel by BlueBay
Calle Miguel Angel 29-31, 28010 â€¦â€¦â€¦ sites to help you find and book the hotel deal at Hotel Miguel Angel by BlueBay that suits you best.</p>
</td>
</tr>
</tbody></table>
</figure>
<figure id="A1.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T6.2.1.1" class="ltx_text" style="font-size:90%;">Table A6</span>: </span><span id="A1.T6.3.2" class="ltx_text" style="font-size:90%;">Random Examples from Cluster 695</span></figcaption>
<table id="A1.T6.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T6.4.1" class="ltx_tr">
<td id="A1.T6.4.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A1.T6.4.1.1.1" class="ltx_text ltx_font_bold">Cosine Distance to Cluster Centroid</span></td>
<td id="A1.T6.4.1.2" class="ltx_td ltx_align_justify ltx_border_tt" style="width:256.1pt;"><span id="A1.T6.4.1.2.1" class="ltx_text ltx_font_bold ltx_align_top">Raw Text</span></td>
</tr>
<tr id="A1.T6.4.2" class="ltx_tr">
<td id="A1.T6.4.2.1" class="ltx_td ltx_align_left ltx_border_t">0.044178426</td>
<td id="A1.T6.4.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T6.4.2.2.1" class="ltx_p ltx_align_top">Eastern Florida State College nutritional sciences
Learn about Eastern Florida State College nutritional sciences, and registering for electives. Which college degrees â€¦â€¦â€¦ System (IPEDS). If any stats on Hagerstown Community College career planning are incorrect, please contact us with the right data.</p>
</td>
</tr>
<tr id="A1.T6.4.3" class="ltx_tr">
<td id="A1.T6.4.3.1" class="ltx_td ltx_align_left ltx_border_t">0.056984067</td>
<td id="A1.T6.4.3.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T6.4.3.2.1" class="ltx_p ltx_align_top">Albany State University introduction to business
Find info concerning Albany State University introduction to business, and registering for elective discussion sections â€¦â€¦â€¦ If any stats on Warren County Community College plant science major are incorrect, please contact us with the right data.</p>
</td>
</tr>
<tr id="A1.T6.4.4" class="ltx_tr">
<td id="A1.T6.4.4.1" class="ltx_td ltx_align_left ltx_border_t">0.0534693</td>
<td id="A1.T6.4.4.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T6.4.4.2.1" class="ltx_p ltx_align_top">Baldwin Wallace University cost per unit
Learn about Baldwin Wallace University cost per unit, submitting required application forms, and follow-up scheduling. â€¦â€¦â€¦ (IPEDS). If any stats on San Jose State nursing degree programs are incorrect, please contact us with the right data.</p>
</td>
</tr>
<tr id="A1.T6.4.5" class="ltx_tr">
<td id="A1.T6.4.5.1" class="ltx_td ltx_align_left ltx_border_t">0.06892538</td>
<td id="A1.T6.4.5.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T6.4.5.2.1" class="ltx_p ltx_align_top">Niagara University managerial accounting
Information about Niagara University managerial accounting, and registering for elective lectures. Which college degrees give you the â€¦â€¦â€¦ System (IPEDS). If any stats on Midwestern University pharmacy tech program are incorrect, please contact us with the right data.</p>
</td>
</tr>
<tr id="A1.T6.4.6" class="ltx_tr">
<td id="A1.T6.4.6.1" class="ltx_td ltx_align_left ltx_border_t">0.07246786</td>
<td id="A1.T6.4.6.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T6.4.6.2.1" class="ltx_p ltx_align_top">Fanshawe College app download
Learn about Fanshawe College app download, and registering for elective discussion sections and seminars. Which college degrees â€¦â€¦â€¦ Data System (IPEDS). If any stats on Stratford University cell biology are incorrect, please contact us with the right data.</p>
</td>
</tr>
<tr id="A1.T6.4.7" class="ltx_tr">
<td id="A1.T6.4.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_t">0.07147932</td>
<td id="A1.T6.4.7.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_b ltx_border_t" style="width:256.1pt;">
<p id="A1.T6.4.7.2.1" class="ltx_p ltx_align_top">Standish Maine Licensed Vocational Nurse LVN Jobs
Find out about Standish, ME licensed vocational nurse LVN jobs options. Itâ€™s a smart â€¦â€¦â€¦ (IPEDS). If any stats on William Jewell College medical insurance coding are incorrect, please contact us with the right data.</p>
</td>
</tr>
</tbody></table>
</figure>
<figure id="A1.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T7.2.1.1" class="ltx_text" style="font-size:90%;">Table A7</span>: </span><span id="A1.T7.3.2" class="ltx_text" style="font-size:90%;">Random Examples from Cluster 8342</span></figcaption>
<table id="A1.T7.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T7.4.1" class="ltx_tr">
<td id="A1.T7.4.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A1.T7.4.1.1.1" class="ltx_text ltx_font_bold">Cosine Distance to Cluster Centroid</span></td>
<td id="A1.T7.4.1.2" class="ltx_td ltx_align_justify ltx_border_tt" style="width:256.1pt;"><span id="A1.T7.4.1.2.1" class="ltx_text ltx_font_bold ltx_align_top">Raw Text</span></td>
</tr>
<tr id="A1.T7.4.2" class="ltx_tr">
<td id="A1.T7.4.2.1" class="ltx_td ltx_align_left ltx_border_t">0.027729392</td>
<td id="A1.T7.4.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T7.4.2.2.1" class="ltx_p ltx_align_top">Seenti - Bundi
Seenti Population - Bundi, Rajasthan
Seenti is a medium size village located in Bundi Tehsil of Bundi district, Rajasthan â€¦â€¦â€¦ 6 months. Of 186 workers engaged in Main Work, 63 were cultivators (owner or co-owner) while 0 were Agricultural labourer.</p>
</td>
</tr>
<tr id="A1.T7.4.3" class="ltx_tr">
<td id="A1.T7.4.3.1" class="ltx_td ltx_align_left ltx_border_t">0.036407113</td>
<td id="A1.T7.4.3.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T7.4.3.2.1" class="ltx_p ltx_align_top">Kodunaickenpatty pudur - Salem
Kodunaickenpatty pudur Population - Salem, Tamil Nadu
Kodunaickenpatty pudur is a large village located in Omalur Taluka of â€¦â€¦â€¦ 6 months. Of 3523 workers engaged in Main Work, 1500 were cultivators (owner or co-owner) while 1533 were Agricultural labourer.</p>
</td>
</tr>
<tr id="A1.T7.4.4" class="ltx_tr">
<td id="A1.T7.4.4.1" class="ltx_td ltx_align_left ltx_border_t">0.017463684</td>
<td id="A1.T7.4.4.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T7.4.4.2.1" class="ltx_p ltx_align_top">Chhotepur - Gurdaspur
Chhotepur Population - Gurdaspur, Punjab
Chhotepur is a medium size village located in Gurdaspur Tehsil of Gurdaspur district, Punjab â€¦â€¦â€¦ 6 months. Of 677 workers engaged in Main Work, 123 were cultivators (owner or co-owner) while 142 were Agricultural labourer.</p>
</td>
</tr>
<tr id="A1.T7.4.5" class="ltx_tr">
<td id="A1.T7.4.5.1" class="ltx_td ltx_align_left ltx_border_t">0.02616191</td>
<td id="A1.T7.4.5.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T7.4.5.2.1" class="ltx_p ltx_align_top">Maksudanpur - Azamgarh
Maksudanpur Population - Azamgarh, Uttar Pradesh
Maksudanpur is a small village located in Sagri Tehsil of Azamgarh district, Uttar â€¦â€¦â€¦ 6 months. Of 22 workers engaged in Main Work, 14 were cultivators (owner or co-owner) while 0 were Agricultural labourer.</p>
</td>
</tr>
<tr id="A1.T7.4.6" class="ltx_tr">
<td id="A1.T7.4.6.1" class="ltx_td ltx_align_left ltx_border_t">0.028420448</td>
<td id="A1.T7.4.6.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:256.1pt;">
<p id="A1.T7.4.6.2.1" class="ltx_p ltx_align_top">Karambavane - Ratnagiri
Karambavane Population - Ratnagiri, Maharashtra
Karambavane is a medium size village located in Chiplun Taluka of Ratnagiri district, Maharashtra â€¦â€¦â€¦ 6 months. Of 444 workers engaged in Main Work, 116 were cultivators (owner or co-owner) while 214 were Agricultural labourer.</p>
</td>
</tr>
<tr id="A1.T7.4.7" class="ltx_tr">
<td id="A1.T7.4.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_t">0.037917078</td>
<td id="A1.T7.4.7.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_b ltx_border_t" style="width:256.1pt;">
<p id="A1.T7.4.7.2.1" class="ltx_p ltx_align_top">Barda - Purba Medinipur
Barda Population - Purba Medinipur, West Bengal
Barda is a large village located in Egra - I Block â€¦â€¦â€¦ 6 months. Of 1182 workers engaged in Main Work, 278 were cultivators (owner or co-owner) while 252 were Agricultural labourer.</p>
</td>
</tr>
</tbody></table>
</figure>
<figure id="A1.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T8.2.1.1" class="ltx_text" style="font-size:90%;">Table A8</span>: </span><span id="A1.T8.3.2" class="ltx_text" style="font-size:90%;">Nearest Neighbors to random validation point in C4</span></figcaption>
<table id="A1.T8.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T8.4.1" class="ltx_tr">
<td id="A1.T8.4.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A1.T8.4.1.1.1" class="ltx_text ltx_font_bold">Cosine Distance</span></td>
<td id="A1.T8.4.1.2" class="ltx_td ltx_align_justify ltx_border_tt" style="width:284.5pt;"><span id="A1.T8.4.1.2.1" class="ltx_text ltx_font_bold ltx_align_top">Raw Text</span></td>
</tr>
<tr id="A1.T8.4.2" class="ltx_tr">
<td id="A1.T8.4.2.1" class="ltx_td ltx_align_left ltx_border_t">0.0(original validation text)</td>
<td id="A1.T8.4.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T8.4.2.2.1" class="ltx_p ltx_align_top">Offers two child care opportunities to Charles County citizensâ€” the Port Tobacco Onsite Child Care Program and the Before and After School Child Care Program (BASCC).
Supports parents through home visits to first time parents and by helping them search for child care, find resources for a child with social, emotional . . . . . . . . Special needs kids. Free to look, a fee to contact the providers.
Hotline is staffed by highly-trained and friendly Child Care Consumer Education Specialists who offer both parents and providers invaluable information about child care, and referrals to local Child Care Resource and Referral agencies where they can receive individualized assistance.</p>
</td>
</tr>
<tr id="A1.T8.4.3" class="ltx_tr">
<td id="A1.T8.4.3.1" class="ltx_td ltx_align_left ltx_border_t">0.12867724895477295</td>
<td id="A1.T8.4.3.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T8.4.3.2.1" class="ltx_p ltx_align_top">Child Care Options is a program of Options Community Services , a non-profit registered charity dedicated to making a difference in the South Fraser Region. Options is committed to empowering individuals, supporting families and promoting community health. Funding for Child Care Options is provided through British Columbiaâ€™s Ministry of Children . . . . . . . . Rock.
Child Care Options links families and child care providers in the communities of Delta, Surrey and White Rock by offering free consultation, support and child care referral services and subsidy support to parents seeking child care. Child care providers are supported through information, outreach, resource library, networking, and learning opportunities.</p>
</td>
</tr>
<tr id="A1.T8.4.4" class="ltx_tr">
<td id="A1.T8.4.4.1" class="ltx_td ltx_align_left ltx_border_t">0.15080827474594116</td>
<td id="A1.T8.4.4.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T8.4.4.2.1" class="ltx_p ltx_align_top">Below are links to child development resources, both from within the department and from external sources.
Child Development Division Publications
Publications that can help you will help you follow your childâ€™s development (from birth to age five) so you can identify and address any issues early on.
Resources to help you understand childrenâ€™s . . . . . . . . families to local resources and services. Specialists are available from 9 AM to 6 PM Monday â€“ Friday. Services are confidential. Caregivers can also visit http://www.helpmegrowvt.org/families.html to learn more about child development, discover developmental tips, and watch videos demonstrating childrenâ€™s developmental milestones (click a button to choose your childâ€™s age).</p>
</td>
</tr>
<tr id="A1.T8.4.5" class="ltx_tr">
<td id="A1.T8.4.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_t">0.15738284587860107</td>
<td id="A1.T8.4.5.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_b ltx_border_t" style="width:284.5pt;">
<p id="A1.T8.4.5.2.1" class="ltx_p ltx_align_top">National Domestic Violence Hotlines
Programs that provide immediate assistance for women and men who have experienced domestic abuse which may include steps to ensure the personâ€™s safety; short-term emotional support; assistance with shelter; legal information and advocacy; referrals for medical treatment; ongoing counseling and/or group support; and other related services. Hotline . . . . . . . . RP-1500.1400-200)
www.thehotline.org/
Toll Free Phone: 800-799-SAFE
URL: https://www.thehotline.org/
Eligibility: Anyone affected by relationship abuse.
Services Provided: Available 24/7/365 via phone, TTY, and chat. Provides lifesaving tools and immediate support to enable victims to find safety and live lives free of abuse. Highly trained, experienced advocates offer support, crisis intervention, education, safety planning, and referral services.</p>
</td>
</tr>
</tbody></table>
</figure>
<figure id="A1.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T9.2.1.1" class="ltx_text" style="font-size:90%;">Table A9</span>: </span><span id="A1.T9.3.2" class="ltx_text" style="font-size:90%;">Nearest Neighbors to random validation point in USPTO</span></figcaption>
<table id="A1.T9.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T9.4.1" class="ltx_tr">
<td id="A1.T9.4.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A1.T9.4.1.1.1" class="ltx_text ltx_font_bold">Cosine Distance</span></td>
<td id="A1.T9.4.1.2" class="ltx_td ltx_align_justify ltx_border_tt" style="width:284.5pt;"><span id="A1.T9.4.1.2.1" class="ltx_text ltx_font_bold ltx_align_top">Raw Text</span></td>
</tr>
<tr id="A1.T9.4.2" class="ltx_tr">
<td id="A1.T9.4.2.1" class="ltx_td ltx_align_left ltx_border_t">0.0(original validation text)</td>
<td id="A1.T9.4.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T9.4.2.2.1" class="ltx_p ltx_align_top">SONET (Synchronous Optical NETwork) is a North American transmission standard for optical communication systems. SDH (Synchronous Digital Hierarchy), a European transmission standard, is a minor variant of SONET.
SONET defines a hierarchy of electrical signals referred to as Synchronous Transport Signals (STS). The STS hierarchy is built upon a basic signal . . . . . . . . the corresponding row and column numbers may include up to 18 comparison operations, which are onerous to implement, for example, in terms of the required logic circuitry. This problem is exacerbated at the upper levels of the STS hierarchy, where processing of multiple pointer values per data frame is performed.</p>
</td>
</tr>
<tr id="A1.T9.4.3" class="ltx_tr">
<td id="A1.T9.4.3.1" class="ltx_td ltx_align_left ltx_border_t">0.1998944878578186</td>
<td id="A1.T9.4.3.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T9.4.3.2.1" class="ltx_p ltx_align_top">US20080109728A1 - Methods and Systems for Effecting Video Transitions Represented By Bitmaps - Google Patents
Methods and Systems for Effecting Video Transitions Represented By Bitmaps Download PDF
David Maymudes
Multi-media project editing methods and systems are described. In one embodiment, a project editing system comprises a multi-media editing application that is configured to . . . . . . . . synchronization models for multimedia data
US20120206653A1 (en) 2012-08-16 Efficient Media Processing
US6658477B1 (en) 2003-12-02 Improving the control of streaming data through multiple processing modules
US6212574B1 (en) 2001-04-03 User mode proxy of kernel mode operations in a computer operating system
US7752548B2 (en) 2010-07-06 Features such as titles, transitions, and/or effects which vary according to positions</p>
</td>
</tr>
<tr id="A1.T9.4.4" class="ltx_tr">
<td id="A1.T9.4.4.1" class="ltx_td ltx_align_left ltx_border_t">0.21122217178344727</td>
<td id="A1.T9.4.4.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:284.5pt;">
<p id="A1.T9.4.4.2.1" class="ltx_p ltx_align_top">Both the Ethernet II and IEEE 802.3 standards define the minimum frame size as 64 bytes and the maximum as 1518 bytes. This includes all bytes from the Destination MAC Address field through the Frame Check Sequence (FCS) field. The Preamble and Start Frame Delimiter fields are not included when . . . . . . . . frame. Dropped frames are likely to be the result of collisions or other unwanted signals and are therefore considered invalid.
At the data link layer the frame structure is nearly identical. At the physical layer different versions of Ethernet vary in their method for detecting and placing data on the media.</p>
</td>
</tr>
<tr id="A1.T9.4.5" class="ltx_tr">
<td id="A1.T9.4.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_t">0.2133803367614746</td>
<td id="A1.T9.4.5.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_b ltx_border_t" style="width:284.5pt;">
<p id="A1.T9.4.5.2.1" class="ltx_p ltx_align_top">A byte is a group of bits, usually eight. As memory capacities increase, the capacity of chip cards is often quoted in bytes rather than in bits as in the past.</p>
</td>
</tr>
</tbody></table>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2308.12283" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2308.12284" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2308.12284">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2308.12284" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2308.12285" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Sep  5 20:25:52 2023 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>