[MISSING_PAGE_EMPTY:1]

튜닝 프로세스가 특정 기간 내에 워크로드 추적을 사용하여 복사된 인스턴스에서 실행되기 때문에 시스템은 _오프라인 튜닝_ 시스템에 속합니다. 한편으로는 워크로드 패턴이 너무 멀리 이동하지 않는다고 가정하면 워크로드의 일부만 고려합니다. 튜닝 프로세스는 일반적으로 최적에 가까운 구성을 찾는 데 몇 시간 또는 며칠이 걸립니다. 따라서 오프라인 메서드는 실제 응용 프로그램의 동적 워크로드에 적응할 수 없습니다. 한편, 이러한 시스템들은 복사된 인스턴스에 의존하며, 인프라는 워크로드를 리플레이할 것을 요구한다[69]. 데이터 프라이버시를 고려 하려면 복사 된 인스턴스를 사용자 환경 (예: Virtual Private Cloud)에서 시작 해야 합니다. 최종 사용자가 구성을 조정 하려는 경우 복사 된 인스턴스를 구입 하 고 스냅숏을 기반으로 워크로드 및 데이터를 준비 해야 합니다. 이 복제 프로세스는 시간이 많이 걸리기 때문에 튜닝 작업이 비용이 많이 들고 지연됩니다. 클라우드에서 중요한 요소인 최종 사용자에게는 총소유비용(TCO)이 증가한다.

상기 갭들을 채우기 위해, 워크로드 변화들에 직접적이고 편리하게 적응하기 위해 온라인 데이터베이스와 조율하는 구성 튜닝 시스템을 설계하는 것이 바람직하다. 온라인 데이터베이스의 구성 노브를 조정하면 인스턴스를 복사할 필요가 없으므로 TCO 문제가 직접 해결됩니다. 그러나 온라인 튜닝 시스템은 다음과 같은 문제를 해결해야 합니다. 첫째, 고가용성은 온라인 데이터베이스에 필수적이며 튜닝 중에 잘못된 구성을 샘플링할 수 없으므로 성능 저하가 발생합니다. 그러나, 불량 구성들을 샘플링하기 위한 기존의 접근법들은 불가피하다. 도 1의 (c)는 MySQL 인스턴스에서 TPCC 워크로드를 튜닝하는 기존의 자동 구성 튜닝 시스템들의 프로세스를 나타낸다. 오터튠(OtterTune)은 베이지안 최적화(Bayesian Optimization)를 사용하여 탐색과 활용의 균형을 맞추어 유망한 구성을 제안하며, CDBTune은 강화학습을 적용하여 시행착오를 통해 튜닝 정책을 학습한다. 그들은 거의 최적에 가까운 구성을 찾을 수 있었다. 그러나 권장 구성의 50%-70%가 기본값보다 더 나쁩니다. 튜닝은 심지어 기계의 물리적 용량보다 더 큰 총 메모리(예를 들어, 버퍼 풀, 삽입 버퍼, 정렬 버퍼 등)를 구성함으로써 두 개의 시스템 걸림을 야기한다. 이러한 유해한 권장 사항은 온라인 데이터베이스에 막대한 위험을 노출시킵니다. 둘째, 클라우드의 동적 환경을 고려해야 하며, 오프라인 튜닝 방식을 직접적으로 활용할 수 없다. 도 1(d)는 도 1(c)에서의 튜닝 프로세스들로부터 얻어진 최상의 구성들을 동적 워크로드(원래의 TPC-C 워크로드로부터 점진적으로 트랜잭션 가중치를 변경함)에 적용하는 성능을 도시한다. 우리는 적용된 구성이 초기에 더 나은 성능을 갖는다는 것을 관찰한다. 그러나 오프라인 튜닝 시스템에서 권장하는 구성이 이후 동적 워크로드와 일치하지 않습니다. 75분 후에 기본값보다 더 나빠집니다. 이러한 관점에서 온라인 데이터베이스 튜닝은 다음과 같은 desiderata를 충족해야 합니다.

**동적**: 튜너는 동적 환경 (예: 워크로드 및 기본 데이터)에 적응적으로 응답할 수 있습니다.

**안전**: 튜너는 튜닝 프로세스 중에 데이터베이스 성능을 다운그레이드하지 않는 구성을 권장해야 합니다.

본 논문에서는 지속적으로 변화하는 클라우드 환경에서 안전하고 적응적으로 데이터베이스를 튜닝하는 온라인 튜닝 시스템인 OnlineTune을 제안한다. **동적성** 의 경우 온라인 튜닝 문제를 상황별 도적 문제로 공식화 합니다. OnlineTune은 컨텍스트를 기능 하 고 컨텍스트 구성 공동 공간에서 데이터베이스 성능을 최적화 합니다. 우리는 누적된 관측치로 OnlineTune을 확장하기 위한 클러스터링 및 모델 섹션 전략을 제안한다. 온라인 튜닝은 관측치를 군집화하고 여러 모델에 적합하며 주어진 컨텍스트에 대한 평가 모델을 선택합니다. **안전** 에 대해 OnlineTune은 구성 공간을 안전하게 탐색합니다. 블랙박스 지식(즉, 모델의 사후 추정)과 화이트박스 지식(즉, 도메인 경험으로부터의 휴리스틱 기반 규칙)을 모두 활용하여 구성의 안전성을 평가한다. 연속 및 고차원 공간에서 안전 제약을 만족시키는 것은 자명하지 않기 때문에 [34] 고차원 최적화 문제를 효율적으로 해결할 수 있는 일련의 부분 공간 문제로 변환한다. 각 모델은 지금까지 발견된 최상의 구성을 중심으로 한 구성 부분 공간을 유지한다. OnlineTune은 안전한 것으로 알려진 구성과 유사한 구성에서 시작하여 추가 탐색을 용이하게 하기 위해 하위 공간을 확장 합니다. 구체적으로, 다음과 같은 기여를 한다:

* 동적 워크로드를 사용 하 여 실제 DBMS 시나리오의 문제를 해결 하기 위해 온라인 튜닝 문제를 정의 하 고 안전 제약 조건이 있는 컨텍스트 밴딧 문제로 해결 합니다. 우리가 아는 한, OnlineTune은 안전을 고려한 최초의 DBMS용 온라인 구성 튜닝 시스템이다.
* 워크로드 및 기본 데이터의 기능을 추출하는 컨텍스트 포화 모델을 제안합니다. 이를 이용하여 OnlineTune은 컨텍스트 베이지안 최적화 기법을 채택하여 지속적으로 변화하는 환경에 적응적으로 데이터베이스를 최적화한다.
* 클라우드에서 광범위한 데이터로 OnlineTune의 확장성을 향상시키기 위해 계산 복잡성을 크게 줄이는 클러스터링 및 모델 선택 전략을 제안합니다.

도 1. 운동 예들: 도 (a) 및 (b)는 클라우드에서의 동적 환경을 도시한다. 그림 (c)와 (d)는 기존 자동 튜너의 성능을 보여준다. (c)에서 튜너는 수많은 안전하지 않은 시행으로 정적 워크로드를 조정합니다. (d)에서는 (c)에서 찾은 최상의 구성을 동적 워크로드에 적용하고 개선되는 것을 관찰합니다.

* 안전 문제를 해결 하기 위해 블랙 박스와 화이트 박스 지식을 결합하여 구성의 안전성을 평가하고 하위 공간 적응을 통해 안전한 탐색 전략을 제안 하 여 유해한 구성을 적용 하는 위험을 크게 줄입니다.
* 제안된 방법을 구현하고 벤치마크 및 실제 애플리케이션의 동적 워크로드에 대해 평가합니다. 온라인 튜닝은 최신 기술과 비교하여 누적 개선에서 14.4%-165.3%의 개선을 달성하고 91.0%-99.5%의 안전하지 않은 권장 사항을 감소시킨다.

논문의 나머지 부분은 다음과 같이 정리되어 있다. 2절에서 관련 작업을 검토하고 3절에서 온라인 튜닝 문제를 공식적으로 정의한다. 4절에서는 OnlineTune에 대한 시스템 개요를 제시하고, 5절에서는 상황별 성능 모델링을 위한 기술에 대해 설명하고, 6절에서는 안전한 구성 권장 사항을 설명한다. 7절에서는 실험 평가를 제시한다. 마지막으로, 우리는 섹션 8에서 결론을 맺는다.

## 2. 관련 작업

**구성 튜닝.** DBMS의 구성 튜닝에 대한 연구가 활발히 진행되었으며 다음과 같이 요약할 수 있습니다.

* **규칙 기반.** 규칙 기반 메서드는 휴리스틱 규칙을 사용 하 여 구성을 권장 합니다. 데이터베이스 벤더들은 잘못된 구성으로 인한 데이터베이스의 병목 현상을 식별하거나(Krishnan et al., 2017) DBA 애플리케이션에 대한 질문을 통해 DBA에게 노브 추천을 제공하기 위한 튜닝 툴을 개발한다(Wainwright et al., 2018). Wei 등은 데이터베이스 튜닝을 위한 퍼지 규칙을 생성하는 것을 제안한다(Wang et al., 2019). BestConfig(Wang et al., 2019)는 여러 휴리스틱을 기반으로 구성을 검색한다. 규칙 기반 방법은 휴리스틱의 가정에 크게 의존하며 이전의 튜닝 노력에서 얻은 지식을 활용하지 못한다.
* **학습 기반.** iTuned(Wang et al., 2019), Ottertune(Brandt et al., 2019) 및 ResTune(Wang et al., 2019)은 베이지안 최적화(BO) 기반 방법을 사용하여 튜닝을 블랙박스 최적화 문제로 모델링합니다. 강화 학습(RL: Reinforcement Learning)은 내부 메트릭들과 구성들 사이의 신경망을 학습함으로써 DBMS를 튜닝하기 위해 (Wang et al., 2019; Wang et al., 2019)에서 채택된다. 데이터 분석 시스템 분야에서 ReIM(Wang et al., 2019)은 메모리 할당의 튜닝 문제를 연구하고 경험적으로 구동되는 알고리즘을 개발한다. 그리고 Tuneful(Wang et al., 2019; Wang et al., 2019)는 증분 민감도 분석 및 BO를 엎드린 구성 공간에 결합한다. RL 방법은 신경망을 미세 조정하여 워크로드에 적응할 수 있지만 추가 시간과 평가 샘플이 필요하다. 위의 모든 방법은 오프라인 튜닝 정책을 학습하기 위해 기계 학습 모델을 학습하고 동적 환경에 신속하게 대응할 수 없다. 또한 데이터베이스와 상호 작용할 때 안전 제약을 고려하지 않아 생산에 배포되는 것을 제한한다.

**쿼리 포화** 쿼리 포화화는 일반 SQL을 벡터화된 표현으로 변환하는 것을 목표로 합니다. 이를 SQL 텍스트 파싱과 논리적 계획 파싱으로 요약한다. SQL 텍스트 구문 분석은 쿼리 텍스트를 직접 처리합니다. TF-IDF는 그 개별 단어 토큰들의 가중 빈도들의 집합으로서 질의를 표현하는 데 사용된다(Wang et al., 2019; Wang et al., 2019). 그러나, 그것의 무제한 어휘는 워크로드 전반에 걸친 일반화를 어렵게 한다. 따라서 ResTune은 자신의 계산을 예약된 SQL 키워드로 제한한다(Wang et al., 2019). 더 큰 어휘를 지원하기 위해, (Wang et al., 2019; Wang et al., 2019)는 NLP에서 자주 사용되는 표현 학습에 의존한다. 표현 학습은 비정형 데이터의 미묘한 관계를 포착하는 조밀한 벡터를 생성한다. 이들은 분포 임베딩을 학습하기 위해 LSTM 또는 CNN과 같은 딥 모델을 사용한다. 논리 계획 파싱은 쿼리 계획을 파싱하여 연산자, 검색된 테이블 및 술어의 비용 또는 범주를 포함한 주요 피쳐를 집계합니다. 이는 질의-성능 예측 또는 카디널리티 추정 분야에서 많은 최신 작업들에 의해 채택되었다(Chen et al., 2018; Chen et al., 2018; Chen et al., 2018; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019). QTune은 데이터베이스의 내부 메트릭을 예측하기 위해 쿼리 유형, 관련 테이블, 쿼리 연산자 및 해당 비용을 인코딩한다(Wang et al., 2019).

**베이지안 최적화.** 본 알고리즘은 베이지안 최적화(BO)의 일반적인 우산에 속합니다. 구성 공간 상에서 블랙박스 기능을 학습 및 최적화한다(Wang et al., 2019). BO는 반복적으로 작동한다 : (1) 구성들과 그들의 성능들 사이의 관계를 기술하는 대리 모델을 업데이트하는 것, (2) 획득 함수 값을 계산함으로써 평가할 다음 구성을 선택하는 것. 획득함수는 불확실한 영역의 탐색을 거래하고 유망한 영역을 활용하여 다음 평가를 위한 후보 포인트의 효용을 측정한다.

BO는 하이퍼-파라미터 튜닝(Chen et al., 2018; Chen et al., 2018; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019), 실험 설계(Krishnan et al., 2017) 및 제어기 튜닝(Chen et al., 2018; Chen et al., 2018; Wang et al., 2019; Wang et al., 2019)을 포함하는 많은 시나리오에서 광범위하게 사용되었다. Contextual BO는 GP 커널에 여분의 컨텍스트 변수를 추가하여 환경 조건을 고려하고, \(CGP-UCB\)을 사용하여 유망한 액션을 선택한다(Wang et al., 2019). DBA Bandit(DBA Bandit, 2019)는 색인된 열의 컨텍스트에 기초하여 유한하고 이산적인 구성 공간으로부터 인덱스 세트를 선택하고 데이터베이스 최적화기로부터 통계치를 도출한다. 안전보장으로 \(n\) 라운드를 수행한 후 \(\tilde{O}(\sqrt{n})\) regret bound를 달성하며, 이는 충분히 많은 단계 후에 단계당 평균 누적 regret가 0에 가까워짐을 의미한다. 그러나 모든 단계의 안전을 보장하는 것은 여전히 도전적이지만 임무가 중요한 응용 프로그램에는 필수적입니다. 최근에, 제약 조건이 알려지지 않은 블랙-박스 함수를 최적화하기 위해 Constrained BO가 제안된다(Wang et al., 2019; Wang et al., 2019; Wang et al., 2019). 그러나 제약조건은 안전성이 중요한 것으로 간주되지 않으며 알고리즘이 안전하지 않은 매개변수를 평가할 수 있도록 허용된다. 안전 최적화의 주요 인스턴스는 SAFEOPT 알고리즘(Wang et al., 2019)이다. 그러나, 그것의 공식은 구성 공간의 이산화에 의존하며, 이는 고차원 적용을 방해한다. 한편, 높은 치수로 BO를 스케일업하는 것은 또 다른 활성 영역이다. 최근 연구에서는 지역 모델링(Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019)과 공간 분할(Wang et al., 2019; Wang et al., 2019)을 제안하여 고차원 문제에서 강력한 경험적 결과를 달성한다. 이러한 발전에 따라 OnlineTune은 효율적으로 이산화할 수 있는 구성 _하위 공간_ 을 세분화 합니다.

## 3. 문제 진술

연속 구성 공간 \(\Theta=\Theta_{1}\times\Theta_{2}\times...\ times\Theta_{m}\)와 문맥공간 \(C\)을 포함한다. 컨텍스트 \(c\in C\)는 제어할 수 없는 환경 조건(예: 동적 워크로드)입니다. 데이터베이스 성능 메트릭을 \(f\)으로 표시하며, 이는 _처리량_, _99%th 백분위수 대기 시간_ 등과 같이 최적화해야 하는 선택 된 메트릭이 될 수 있습니다. 구성 \(\theta\) 및 컨텍스트 \(c\)가 주어지면 평가 후에만 해당 성능 \(f(\theta,c)\)을 관찰할 수 있습니다.

논의한 바와 같이 온라인 튜너는 **동적성** 및 **안전성** 두 가지 요구 사항을 충족해야 합니다. **동적성** 요구 사항은 튜너가 구성을 권장할 때 환경 조건(맥락)을 변경하는 것을 고려해야 함을 의미합니다. 이를 문맥적 대역 문제(Wang et al., 2019)로 정형화하는데, 이때 각 반복에서 튜너는 문맥(c_{t}\)을 입력받아 구성(\theta_{t}\)을 출력하여 페이오프(즉, 데이터베이스 성능 \(f\))를 최대화한다. **안전** 요구 사항은 각 튜닝 반복 \(t\)에 대해 \(f_{t}\geq\tau\)가 유지되도록 추가로 보장해야 함을 나타냅니다. 여기서 \(f_{t}=f(\theta_{t},c_{t})\) 및 \(\tau\in\mathbb{R}\)은 특정 안전 임계값입니다. 위의 조건을 충족 하는 구성을 _안전_ 이라고 정의 합니다. 안전 임계값은 튜닝 접근법을 채택할 때 최종 사용자가 견딜 수 있는 위험 정도를 나타낸다. 데이터베이스가 미션-임계 시스템인 만큼, 서비스 레벨 계약은 벤더 디폴트 구성 하에서 클라우드 제공자들에 의해 보장되어야 한다(Zhu et al., 2017; Zhang et al., 2018). 직관적으로, 안전 임계치는 디폴트 구성 하에서 데이터베이스 성능으로 설정된다(디폴트 성능으로 표시됨). 워크로드가 변경 되 면 기본 성능이 변동 하는 경우 지정 된 워크로드에 대 한 기본 성능을 얻을 수 있다고 가정 합니다. 실제로, 디폴트 성능은 이력 지식 베이스가 이용 가능할 때(예를 들어, in(Zhu et al., 2017; Zhang et al., 2018; Zhang et al., 2018)) 쉽게 획득되거나 예측될 수 있다. 예를 들어, 사용자는 컨텍스트를 입력하고 기본 성능을 출력하는 회귀 모델을 트레이닝할 수 있다. 이전 지식이 없어도 기본 성능을 관찰하는 데 시간이 걸릴 수 있습니다. 초기에는 \(f\)에 대한 가정 없이 안전한 구성을 검색하는 것은 무의미한 작업이다. 따라서, 또한 최적화 이전에, 적어도 하나의 안전한 구성을 포함하는 초기 안전 세트가 주어진다고 가정한다. 목표가 최대화 문제라고 가정하면, \(c_{t}\in\mathcal{C}\)에 대해 풀어야 할 온라인 동조 문제는 다음과 같다.

\[\begin{split}\operatorname*{arg\,max}_{\theta_{t}\in\theta}f( \theta_{t},c_{t}),\\ \text{subject to }f(\theta_{t},c_{t})\geq\tau.\end{split} \tag{1}\]

## 4. Onlinetune 개요

**워크플로.** 온라인 조정을 수행 하려면 OnlineTune 먼저 기본 구성 및 성능을 쿼리 하 여 초기 안전 집합을 빌드합니다. 안전 임계값은 섹션 3에서 논의된 바와 같이 기본 성능으로 설정된다. 그런 다음, OnlineTune 기능은 반복적으로 수행된다. 이 모델은 문맥을 포화시키고, 반복 초기에 유망한 구성\(\theta_{t}\)을 추천하며, 반복 동안 성능을 평가하여 모델을 갱신함으로써 동적 환경에 적응한다. 구간 크기(즉, 하나의 반복에 대한 시간)는 동적성에 대한 OnlineTune의 적응의 세분성을 제어한다. 튜닝 시간이 주어지면 OnlineTune은 더 많은 관찰을 수집하고 작은 간격 크기로 더 세밀한 제안을 수행할 수 있습니다. 우리는 기본적으로 3분 간격을 사용하고 실험에서 민감도 분석을 수행한다. 하나의 반복 내에서 OnlineTune의 워크플로는 그림 2의 1-2에서 제시한 바와 같이 반복 주기를 형성한다. 워크플로는 맥락적 성능 모델링과 안전한 구성 추천의 두 단계로 구성된다.

상황적 성능 모델링은 동적 환경에서 주어진 구성의 성능을 예측하는 대리 모델을 얻는 것을 목표로 한다. 대리는 과거 관측치(또는 과거 관측치가 존재하지 않는 경우 초기 안전 세트)에 맞춰진 문맥적 가우시안 프로세스(GP) 모델이다. 1 OnlineTune은 먼저 컨텍스트 포화화를 통해 동적 인자(예를 들어, 워크로드 및 그 기본 데이터)를 캡처하여 컨텍스트를 획득한다(자세한 내용은 섹션 5.1 참조). 그런 다음 유사한 컨텍스트를 가진 클러스터에서 관찰에 적합 한 컨텍스트 GP 모델을 선택 합니다. 클러스터들은 오프라인 방식으로 주기적으로 재클러스터된다(섹션 5.3). 3 맥락형 GP의 구성은 섹션 5.2에 소개되어 있다.

안전한 구성 추천은 구성 공간으로부터 안전하고 유망한 구성을 선택하는 것을 목표로 한다. BO의 공격적인 탐색, 특히 경계의 과도한 탐색을 피하기 위해 OnlineTune은 전체 구성 공간에 대한 최적화를 _하위 공간_ 최적화 시퀀스로 줄입니다. 이 단계의 모든 작업은 안전 최적화 문제를 이산화 하 고 효율적으로 해결할 수 있는 _하위 공간_ 에서 제한 됩니다. 본질적으로, _서브스페이스_는 지금까지 추정된 최상의 구성을 중심으로 하여 점진적으로 최적을 향해 이동한다. 이 단계는 선택된 대리 모델과 그에 대응하는 부분 공간을 입력한다. 3 새로 적합 된 모델의 경우 OnlineTune은 가장 잘 추정된 구성을 중심으로 하는 하위 공간을 초기화 합니다. 그렇지 않으면, OnlineTune은 튜닝 이력에 따라 부분 공간을 적응시키는데, 예를 들어 연속적인 성공을 할 때 부분 공간을 확장한다(섹션 6.1). 4 적응된 부분 공간은 후보 세트를 구축하기 위해 이산화된다. OnlineTune은 모델의 하한 추정치를 기반으로 후보의 안전성을 평가 하 여 안전 집합을 형성 합니다. 또한 화이트 박스가 안전하지 않은 구성을 해제합니다. 휴리스틱 화이트 박스가 안전 세트로부터 최적의 구성들을 배제하는 경우에, OnlineTune은 부적절한 규칙들을 완화한다(섹션 6.2.2). 그런 다음 5 OnlineTune은 획득 함수를 최대화 하거나 하위 공간의 안전 경계를 탐색 하 여 안전 집합에서 구성을 선택 합니다. 6 마지막으로 OnlineTune은 온라인 데이터베이스에 구성을 적용하고 그 성능을 평가한다.

**아키텍처.** OnlineTune의 주요 부분은 백 엔드 튜닝 클러스터(OnlineTune 서버)에 배포되는 반면 컨텍스트 포화 모듈은 데이터용 데이터베이스 인스턴스에 배포됩니다.

도 2. OnlineTune Workflow.

사생활 문제 OnlineTune 서버는 처음에 비워둘 수 있는 이전 튜닝 반복의 과거 관찰을 저장하는 데이터 리포지토리를 유지 관리합니다. OnlineTune 서버는 튜닝 작업의 상태를 모니터링하고 데이터를 전송하는 컨트롤러를 통해 데이터베이스 인스턴스와 상호 작용합니다.

## 5. Contextual Performance Modeling

온라인 튜닝은 온라인 DBMS를 튜닝할 때 동적 환경에 대응합니다. GP 커널은 컨텍스트 변수를 추가하여 \(\langle\)context, configuration\(\rangle\) 및 데이터베이스 성능 사이의 관계를 학습한다. 우리는 먼저 컨텍스트를 완성하고 컨텍스트 GP 모델을 구성하는 방법에 대해 논의한다. 그런 다음, 모델의 확장성을 향상시키기 위한 클러스터링 및 모델 선택 전략을 제시한다.

### Context Featurization

컨텍스트 포화(context featurization)는 제어 불가능한 동적 요소를 포착하는 것을 목표로 하며, 이는 구성과 데이터베이스 성능 사이의 관계에 영향을 미친다. 데이터베이스를 튜닝할 때, 업스트림 애플리케이션들 및 DML 문들(예를 들어, 삽입, 삭제 및 업데이트)로 인해 워크로드 및 기초 데이터가 끊임없이 그리고 지속적으로 변화한다. 온라인 튜닝은 역동성에 적응하기 위해 두 가지 요소를 충족시킨다.

#### 5.1.1. 워크로드 포화

이제 변화하는 워크로드를 충족시키는 방법을 설명합니다. 워크로드에는 두 가지 동적 측면이 있습니다 (Kang et al., 2017): (1) _쿼리 도착 속도_: 초당 도착하는 쿼리 수가 변동할 수 있습니다. (2) _쿼리 구성_: 쿼리의 종류가 변할 수 있고, 쿼리 구성의 비율이 달라질 수 있다.

_Query arrival rate_는 하나의 차원으로 인코딩될 수 있다. _쿼리 구성_의 경우 일반 쿼리를 벡터화된 표현으로 변환해야 합니다. 우리는 질의의 정보 인코딩을 추출하고 워크로드 전반에 걸쳐 일반화하기 위해 표현 학습 기법(Beng et al., 2017)을 채택한다. SQL 쿼리 분석에 성공적으로 사용된 LSTM을 선택한다(Srivastava et al., 2017; Wang et al., 2018; Wang et al., 2018). 라벨링 데이터의 수집 부담을 덜어주기 위해 표준 LSTM 인코더-디코더 네트워크(Wang et al., 2018)를 사용한다. 인코더 네트워크 상의 최종 은닉 상태는 질의에 대한 조밀한 인코딩을 제공한다. 마지막으로 워크로드의 _쿼리 구성_ 기능을 획득 하 여 쿼리 인코딩을 평균 합니다.

#### 5.1.2. 데이터 포화 기반

데이터베이스 데이터의 분포를 학습하는 것은 자명하지 않은 작업이다(Wang et al., 2018; Wang et al., 2018; Wang et al., 2018). 워크로드 질의에 영향을 미치는 데이터 변화만이 튜닝 정책과 관련이 있다는 관찰에 기초하여, 우리는 DBMS 최적화기에서 다음을 사용한다: (1) 질의에 의해 검사될 행의 추정, (2) 질의에서 테이블 조건에 의해 필터링된 행의 백분율, (3) 인덱스의 사용 여부. 첫 번째 두 가지 특징은 쿼리의 기수 추정으로 데이터 크기와 분포의 효과적인 변화를 포착한다. 마지막 기능은 인덱스 빌드/드롭 작업을 나타냅니다. 질의의 세 가지 특징을 평균하여 워크로드의 기본 데이터 특징을 얻는다.

마지막으로, 최종 컨텍스트 특징을 얻기 위해 워크로드 특징과 기본 데이터 특징을 연결한다. 쿼리 계획은 쿼리 실행에 대한 추가 정보(예: 연산자 및 비용)를 제공할 수 있지만 컨텍스트로 인코딩하지는 않습니다. 추가 정보는 OnlineTune의 이전 구성에 영향을 받아 향후 튜닝을 위한 컨텍스트로 적합하지 않기 때문이다. 또한, 현대의 DBMS는 수백 개의 플랜 오퍼레이터(Wang et al., 2018)를 가지며, 플랜 오퍼레이터를 인코딩하면 희소하고 고차원 변수를 GP 커널에 증강할 때 "차원성 문제"를 야기할 수 있다. 하드웨어 구성, 데이터 파티션 변경, 사용자 호출 구성 등과 같은 다른 동적 요인이 데이터베이스 성능에 영향을 미칠 수 있습니다. 그들의 변화는 보통 간헐적으로 일어난다. 온라인 튜닝은 변경사항이 발생하거나 이러한 요소를 인코딩할 때 튜닝 작업을 다시 초기화할 수 있습니다. 예를 들어, OnlineTune은 하드웨어 업데이트를 지원하기 위해 하드웨어 구성(예: 메모리 크기, #CPU)을 인코딩할 수 있다. 데이터베이스 이상(예: 디스크 공간 부족 및 사이버 범죄 공격)은 온라인 튜닝의 범위를 벗어납니다.

### 컨텍스트를 사용한 성능 모델링

성능 모델은 컨텍스트 및 잠재적 구성이 주어진 성능 메트릭을 추정합니다. 동적 환경을 지원하기 위해 GP를 확장한 컨텍스트 GP를 성능 모델로 채택한다. GP는 베이지안 최적화(Wang et al., 2018)에서 표현성과 잘 보정된 불확실성 추정으로 인해 객관적인 모델링을 위한 인기 있는 대리 모델이다. GP는 제한된 샘플로 목적 함수를 모델링하기 위해 예측에 대한 신뢰 한계를 제공한다. 그러한 시나리오에서, 다른 데이터 집약적 기법들, 예를 들어, 딥 러닝(Wang et al., 2018; Wang et al., 2018)은 낮은 데이터 효율성 및 해석 가능성(Wang et al., 2018)과 투쟁할 수 있다. 본 절에서는 성능 모델 학습에 초점을 두고 6절에서 안전한 튜닝의 단계를 남긴다.

우리는 서로 다르지만 상관 관계가 있는 컨텍스트에 대한 성능 모델을 학습하는 것을 목표로 한다. 학습 단계에서는 입력(\theta\), 문맥 특징(c\) 및 관측(H_{t}=\{c_{i},\theta_{i},y_{t}\}_{i=1}^{t}\)이 주어졌을 때 대상 함수의 확률 분포 \(p|\theta,c,H_{t}\right)\(f=f\left(\theta,c\right)\)를 구성한다. \(f\) 위의 사후 분포는 평균 \(\mu_{t}\left(\theta,c\right)\) 및 분산 \(\sigma_{t}^{2}\left(\theta,c\right)\):

\[\begin{split}\mu_{t}(\theta,c)&=k^{T}\left(K+ \sigma^{2}I\right)^{-1}y_{1:t},\\ \sigma_{t}^{2}(\theta)&=k\big{(}\left(\theta,c \right),\left(\theta,c\right)\big{)}-k^{T}\Big{(}K+ \sigma^{2}I\Big{)}^{-1}k, \end{split} \tag{2}\]

그림 3. 컨텍스트에 대한 일반화: OnlineTune은 컨텍스트 \(c=0\)(왼쪽) 아래에 세 개의 관측치(파란색 점)를 가지며 평균(파란색 선) 및 신뢰 한계(연한 파란색 영역)가 있는 사후 분포를 적합시킵니다. 온라인 튜닝은 서로 다른 컨텍스트 간의 상관관계를 이용하여 목적 함수의 지식을 서로 다른 컨텍스트 \(c=0.1\)(중간)으로 전달할 수 있지만 먼 컨텍스트(오른쪽)로 지식은 거의 전달할 수 없다. 빨간색 라벨은 안전 임계값으로 0을 사용하여 추정된 안전 세트를 보여준다.

여기서, \(k=[k((\theta_{1},c_{1}),(\theta,c)),...,k((\theta_{t},c_{t}),(\theta,c))]^{T}\)이고, K는 \((i,j)\)번째 엔트리가 \(K_{i,j}=k((\theta_{i},c_{i}),(\theta_{j},c_{j}))인 공분산 행렬이다. 커널 \(k((\theta,c),(\theta^{{}^{\prime}},c^{{}^{\prime}}))\)은 구성점과 문맥 사이의 거리를 모델링해야 한다. 구체적으로, 첨가 커널 \(k_{\theta}(\theta,\theta^{{}^{\prime}})+k_{C}(c,c^{{}^{\prime}})\)을 구성한다. 컨텍스트에 대한 의존성을 모델링하기 위해 선형 커널 \(k_{C}(c,c^{{}^{\prime}})\)과 구성에 대한 비선형 성능을 모델링하기 위해 마틴 커널 \(k_{\theta}(\theta,\theta^{{}^{\prime}})\)을 사용한다. 직관적으로, 그러한 설계는 맥락에 따라 전체적인 경향 및 이러한 경향으로부터의 구성-특정 편차를 모델링할 수 있었다(Mikolov et al., 2017).

복합 커널은 구성들 및 컨텍스트들이 유사할 때 함수 값들이 상관된다는 것을 암시한다(Kang et al., 2017). 우리는 상관된 컨텍스트에 걸쳐 동일한 구성이 유사한 성능 예측을 가질 것으로 예상한다. 컨텍스트 간의 상관 관계는 튜닝을 상당히 빠르게 할 수 있다. 그림 3은 1차원 컨텍스트 특징과 1차원 구성을 가진 간단한 시나리오를 보여준다. 알고리즘은 첫 번째 컨텍스트(z = 0, 왼쪽 그림)에서 구성 공간만 탐색했지만 함수 간의 상관 관계는 관측되지 않은 컨텍스트(z = 0.1, 중심 그림)로 정보를 일반화한다. 지식 전달은 데이터 효율성을 향상시키고 필요한 평가 횟수를 줄인다.

### 클러스터 및 모델 선택

상황별 GP는 동적 환경에서 데이터베이스 성능을 모델링할 수 있다. 그러나 \(n^{3})\)의 복잡도는 \(n\)의 관측값을 가지고 있다. 입방 계산 복잡도는 클라우드에서 관측치가 증가함에 따라 적용 가능성을 제한한다. 이러한 문제를 해결하기 위해, 본 논문에서는 컨텍스트 특징의 유사도에 기반한 클러스터링 및 모델 선택 전략을 제안한다. 관측치는 군집링되며 각 군집의 관측치 수는 상수 \(P\)으로 제한될 수 있습니다. OnlineTune은 클러스터를 기반으로 여러 컨텍스트 GP에 적합하고 모델 선택을 위한 결정 경계를 학습합니다. 따라서 복잡도는 \(O(P^{3})\)로 제한되며, 이는 관측치가 증가함에 따라 OnlineTune이 확장될 수 있도록 한다.

알고리즘 1은 절차를 제시한다. 먼저 컨텍스트 특징 \(\{c_{i}\}_{1}^{t}\)을 기반으로 DBSCAN 클러스터링 알고리즘(Kang et al., 2017)을 수행하여 각 \(c_{i}\)에 대한 클러스터 레이블 \(l_{i}\)을 구한다(Line 2). 각 클러스터에 대해 OnlineTune은 관측치(라인 3)를 사용하여 상황별 GP 모델을 적합시킵니다. 보이지 않는 컨텍스트에 대한 모델을 선택하기 위해, OnlineTune은 SVM을 사용하여 비선형 결정 경계를 학습한다(도 4의 (b)에 도시된 바와 같이, 라인 4). 우리는 SVM의 단순성, 훈련의 용이성, 및 실제에서 잘 일반화시키기 위한 더 적은 샘플들의 필요성을 위해 SVM을 선택한다(Zhu 등, 2017). 확장성을 개선하는 것 외에도, 이러한 클러스터링은 GP 모델에 대한 트레이닝 세트로부터 먼 컨텍스트를 갖는 관찰을 배제하여, "부정적인 전달"을 방지한다(Zhu 등, 2017).

증강된 관측치는 맥락과 학습된 경계에 따라 군집으로 분류된다. 그러나, 컨텍스트 특징들의 분포는 더 많은 관찰들이 수집될 때 이동할 수 있고, 이전의 클러스터링 및 경계는 주기적으로 재학습될 필요가 있다. OnlineTune은 기존의 클러스터링과 모의된 새로운 클러스터링을 유지하여 재학습 여부를 결정한다(Line 1). 두 종류의 클러스터링 간의 차이는 컨텍스트 이동을 나타낸다. 우리는 상호 정보 기반 점수(MI)를 사용하여 차이를 정량화한다. 0에 가까운 MI는 두 개의 매우 다른 군집링을 나타내는 반면 1에 가까운 MI는 그 반대를 나타낸다. MI 점수가 임계값보다 작으면(실험에서 0.5로 설정) 재클러스터링이 트리거되고 수정된 클러스터를 기반으로 경계 및 모델이 업데이트된다(라인 2-4).

## 6. 안전한 구성 권장 사항

온라인 튜닝은 튜닝 프로세스 전반에 걸쳐 안전성을 보장하면서 데이터베이스 성능을 최적화하는 것을 목표로 합니다. 온라인튠은 전역 구성 공간에서 성능 함수를 최적화하는 대신 부분 공간에서 최적화를 제한하고 점진적으로 최적으로 확장한다. 부분 공간 제한은 안전을 일반화하고 BO의 과잉 탐색 특성을 완화하기 위한 미세한 이산화를 가능하게 한다. 이 섹션에서는 OnlineTune이 하위 공간을 적응 하 고 하위 공간 내에서 안전 집합을 형성 하 고 안전하고 유망한 구성을 선택 하는 방법을 소개 합니다.

### Subspace Adaptation

글로벌 최적으로 확장하기 위해 구성 부분 공간을 반복적으로 조정하고 알고리즘 2와 같이 하이퍼큐브 영역과 라인 영역 사이를 번갈아 가며 조정한다.

하이퍼큐브 영역 \(\{\theta\left\|\left\|\theta-\theta_{best}\right\|_{2}\leq R_{n}\}\cap\theta\)은 영역 중심 \(\theta_{best}\)과 반경 \(R_{m}\)으로 정의된다. 영역 중심 \(\theta_{best}\)은 지금까지 관찰된 최상의 구성으로 설정된다. 반경 \(R_{n}\)은 최적화 공간을 제어한다. 만약 \(R_{n}\)이 하이퍼큐브 영역이 전체 구성 공간을 포함하기에 충분히 크다면, 이것은 표준 글로벌 BO를 실행하는 것과 동등할 것이고, 반면에 작은 \(R_{n}\)은 탐사를 느리게 할 수 있다. 초기화 시, \(R_{n}\)은 기본 값(예를 들어, 각 차원의 5% 범위)으로 설정된다. 연속적인 "실패" 후에 \(R_{n}\)을 축소하고 연속적인 "성공" 후에 확장하는 것이 전형적인 행동이다(Zhu et al., 2017). 우리는 "성공"은 이전 구성보다 더 나은 구성을 권장하는 것으로 정의하고 "실패"는 그렇지 않은 권장 사항으로 정의한다. \(R_{n}\) 조정에 대한 자세한 내용은 4-7행에 나와 있다.

선 영역은 1차원 아핀 부분공간 \(\{\theta_{best}+ad:a\in\mathbb{R}\}\cap\theta\)으로 오프셋 \(\theta_{best}\)과 방향 \(d\in\mathbb{R}^{m}\)으로 정의된다. 라인 영역들을 갖는 최적화가 전역적으로 수렴할 수 있음이 증명된다(Zhu 등, 2017). 선 영역의 방향이 최적화의 궤적을 결정합니다. 방향 생성을 위해 랜덤 방향(탐색 증가)과 중요 방향(중요 구성 노브와 정렬, 활용 증가)의 두 가지 전략을 구현합니다. 부록에는 세부 정보가 포함되어 있습니다.

도 4. 클러스터링 및 모델 선택: 각 점은 샘플을 나타내고 학습된 경계는 컨텍스트 공간을 분할한다.

서브공간은 초기 안전 세트(라인 1-2) 근처에서 최적화를 제한하기 위해 먼저 하이퍼큐브 영역으로서 초기화된다. 하이퍼큐브 영역은 내부에서는 최적화를 조밀하게 장려하지만, 국부 최적에 갇히게 되는 오버-exploitation으로 이어질 수 있다(Kumar et al., 2017). 온라인 튜닝은 공격과 안전한 탐색 간의 절충을 제어하기 위해 라인 영역으로 전환합니다(라인 3-13). 교대는 전환 규칙 (줄 8 및 12)에 의해 트리거됩니다. \(\Theta_{m}\)에서 평가 되지 않은 안전한 구성이 빠져나가지 않거나 더 나은 구성을 권장 하기 위해 특정 수의 연속 오류가 발생 하는 경우 OnlineTune은 다른 유형의 하위 공간으로 전환 합니다. (\theta_{best}\)의 갱신은 부분 공간을 최적 방향으로 이동시킨다.

### Safety Assessment

OnlineTune은 후보 집합을 구축하기 위해 적응된 부분 공간을 이산화한다. 그런 다음 컨텍스트 GP(블랙박스 지식)와 기존 도메인 지식(화이트박스 지식)의 신뢰 범위를 기반으로 각 후보의 안전성을 평가한다.

#### 6.2.1. Black-Box Knowledge

주어진 컨텍스트 \(c\), OnlineTune은 선택한 컨텍스트 GP 모델 \(m^{\text{tr}}\)의 신뢰 경계를 사용하여 \(\theta\):의 안전성에 액세스합니다.

\[\begin{split}& l_{n}(\theta,c)=\mu_{n}(\theta,c)-\beta\sigma_{n}( \theta,c),\\ & u_{n}(\theta,c)=\mu_{n}(\theta,c)+\beta\sigma_{n}(\theta,c), \end{split} \tag{3}\]

여기서 \(l_{n}\)과 \(u_{n}\)은 하한 및 상한 예측이며, 식 2의 \(\mu_{n}\)과 \(\sigma_{n}\)이다. 매개변수 \(\beta\)는 신뢰범위의 기밀성을 제어하며, Srinivas et al.(Srinivas et al., 2019)의 연구에 따라 그 값을 설정한다. 참함수 값 \(f\)은 높은 확률로 신뢰구간 \([l_{n}(\theta,c),u_{n}(\theta,c)]\)에 속하게 된다. 우리는 \(l_{n}(\theta,c)>\tau\)으로 안전한 구성을 결정할 수 있다; 즉, 최악의 경우 성능이 여전히 안전 임계값 \(\tau\) 이상인 구성을 결정할 수 있다. 우리는 이전에 평가된 구성을 포함하는 지역 부분 공간에서 성능 모델링을 제한하며, 지역 모델링은 전역 모델링보다 더 신뢰할 수 있다. 이것은 또한 확률적 최적화(Srinivas et al., 2019)로부터 신뢰 영역 방법의 이면에 있는 근거이다.

#### 6.2.2. White-Box Knowledge

구성 및 데이터베이스 성능 간의 관계는 복잡합니다. 도메인 지식은 잘못된 구성을 무시하기 위해 존재합니다. 예를 들어, 전체 버퍼 크기는 배포된 컴퓨터의 물리적 메모리 용량을 초과할 수 없습니다. 경험 DBA는 도메인 지식에 기초하여 데이터베이스를 튜닝하고, 일부 데이터베이스 튜닝 툴은 또한 휴리스틱을 사용하여 튜닝 제안을 제공한다(Bradner et al., 2017; Krizhevsky et al., 2017; Krizhevsky et al., 2017; Krizhevsky et al., 2017). 이러한 화이트박스 튜닝은 직관적인 제안을 제공하며 ML 기반 튜닝을 위한 따뜻한 시작 및 공간 가지치기 구성요소 역할을 할 수 있다. 최종 안전 세트를 형성할 때, OnlineTune은 화이트 박스의 결과를 도출하고 안전하지 않거나 그렇지 않은 구성을 화이트 박스의 제안에서 벗어났다. 우리는 MysqlTuner(Bradner et al., 2017)를 이용하여 OnlineTune의 white-box assistant를 구현한다. MysqlTuner는 DBMS 메트릭을 검사하고 정적 휴리스틱을 사용하여 구성에 대한 설정 범위를 제안합니다. 범위들은 규칙들에 기초하여 생성된다(예를 들어, 하루에 인덱스가 없는 #조인이 250보다 큰 경우 키 버퍼 크기를 총 MyISAM 인덱스 크기보다 크게 설정하거나 조인 버퍼 크기를 증가시킨다). 온라인 튜닝은 화이트 박스의 제안들을 만족시키지 못하는 구성들을 그것의 안전 세트로부터 제거한다. 화이트 박스가 범위 대신 특정 구성을 제안 하는 경우 OnlineTune은 제안 된 구성에서 멀리 떨어진 구성을 필터링 합니다. 다른 화이트-박스 튜닝 툴들 또는 수작업된 규칙들이 온라인 튜닝의 튜닝 노브들에 대한 제안들을 제공하는 경우 온라인 튜닝과 공존할 수 있다. 이들의 제안은 직접 신청하는 대신 온라인튠의 화이트박스 어시스턴트로 활용할 수 있다.

그러나 화이트 박스는 피드백에 따라 진화하지 않아 로컬 최적에 트랩이 발생한다. 이 규칙은 \(S_{n}\)에서 최적의 구성을 제외하고 부적절할 수도 있다. 이것은 블랙박스 알고리즘이 이 구성(즉, 결정 충돌)을 권장하는 동안 화이트박스 규칙이 구성을 거부할 때만 발생합니다. 이를 방지하기 위해 OnlineTune은 부적절한 규칙을 완화하기 위해 완화 전략을 사용한다. OnlineTune은 각 규칙에 대해 충돌 카운터 및 충돌 안전 카운터를 유지 관리 합니다. 결정 충돌이 여러 번 발생 하 여 임계값에 도달 하면 OnlineTune은 규칙을 무시하고 논란의 여지가 있는 구성을 권장 합니다. 상이한 규칙들 사이의 상호 의존성을 제어하기 위한 권고에서 오직 하나의 규칙만이 무시될 수 있다는 것에 유의한다. 평가 후 구성이 안전하면 충돌 안전 카운터가 하나 증가합니다. 규칙의 충돌-안전 카운터가 임계값에 도달하면, 규칙은 완화될 것이다(예를 들어, 규칙에 의해 주어진 구성 범위가 확대된다). 각 화이트박스 규칙에 대한 임계값은 신뢰도에 따라 다르게 설정될 수 있다. 더 큰 임계값은 화이트 박스 규칙에 대한 더 많은 신뢰로 이어진다.

### Candidate Selection

안전 세트가 생성된 후, OnlineTune은 안전 세트 내의 후보들로부터 구성을 선택한다. 모든 블랙박스 최적화와 마찬가지로 선택은 (1) 개발, 현재 안전 세트 내에서 고성능 영역을 지역화하려는 시도, (2) 탐색, 새로운 지식 획득 및 안전 세트의 현재 추정치를 확장하려는 시도라는 두 가지 목표 사이의 균형을 유지해야 한다. 안전 세트에 제약된 상한 신뢰 경계(UCB)(Srinivas et al., 2019)를 샘플링 기준으로 채택하며, 수학식 4와 같다:

\[\theta_{max}=\operatorname*{arg\,max}_{\theta\in S_{n}}\mu_{n}(\theta,c)+\beta \sigma_{n}(\theta,c). \tag{4}\]

UCB는 신뢰 구간의 상한이 최대인 위치에서 구성을 선택한다. UCB에 의해 주어진 구성에서 시스템 성능을 반복적으로 평가하면 기본 함수의 평균 추정치가 향상되고 후보 구성에서 불확실성이 최대치로 감소한다. 글로벌 최대치는 결국 증명가능하게 발견된다(Shi et al., 2019).

온라인튠은 안전한 부분 공간을 명시적으로 확장하기 위해 안전 집합 확장을 위한 유망한 후보이기 때문에 불확실성이 가장 높은 안전 집합 경계에서 안전 구성을 선택한다. 두 가지 샘플링 기준을 통합하기 위해 \(1-\epsilon\)의 확률을 갖는 최대 UCB 구성과 \(\epsilon\)의 가능성을 갖는 경계점을 선택하는 엡실론 탐욕 정책(Shi et al., 2019)을 채택한다.

## 7. Evaluation

** 개요**: 먼저 OnlineTune과 섹션 7.1의 동적 환경에 대 한 최신 데이터베이스 구성 조정 방법을 비교 합니다. 비교는 (1) 워크로드의 쿼리 구성이 지속적으로 변경 되는 동적 쿼리 구성_, (2) OLTP 및 OLAP 워크로드의 실행을 번갈아 가며 일일 트랜잭션 분석 주기를 시뮬레이션 하는 (3) 실제 워크로드_의 세 가지 설정에서 수행 됩니다. 섹션 7.1.4에서는 비교된 방법의 오버헤드를 분석한다. 7.2절에서는 사례 연구를 제시한다. 섹션 7.3에서는 컨텍스트 공간 설계와 안전한 탐색 전략을 포함하여 OnlineTune의 설계의 효과를 평가하기 위한 절제 연구를 수행한다. 또한 다양한 초기 안전 세트 및 간격 크기에 대한 OnlineTune의 견고성을 검증한다. 또한 섹션 7.4의 검색 효율성을 분석하기 위해 _정적 워크로드_ 설정에서 기준선을 평가합니다.

**기준**: 기준선은 아래에 설명되어 있습니다.

* _DBA 기본값_ 은 숙련된 DBAs에서 제공 하는 구성입니다.
* OnlineTune은 안전하고 상황별 튜너입니다. GPy 라이브러리를 이용하여 OnlineTune의 예측 모델을 구현한다(Bondel et al., 2019).
* _BDG_는 베이지안 최적화 접근법으로서, 데이터베이스 구성 튜닝에 널리 사용된다(Bondel et al., 2019; Bondel et al., 2019; Shi et al., 2019). 우리는 OLTP(Shi et al., 2019)와 유사한 설계를 사용한다 : 가우시안 프로세스를 대리 모델로, EI를 획득 함수로 사용한다. 또한 GPy 라이브러리를 통해 BO를 구현했다.
*_DDPG_는 데이터베이스 구성을 튜닝하는데 사용되는 강화 학습 에이전트이다(Shi 등, 2019). 에이전트는 DBMS의 내부 메트릭을 입력하고 적절한 구성을 출력합니다. DDPG 알고리즘은 CDBTune(Shi et al., 2019)로부터 차용된 그의 신경망 아키텍처와 함께 PyTorch 라이브러리(Bondel et al., 2019)를 사용하여 구현된다.
* _Qtune_ 은 세 가지 튜닝 세분성을 지원 하는 쿼리 인식 튜너입니다 (Shi et al., 2019). 우리는 워크로드 수준의 조정을 채택합니다. 미리 훈련 된 모델을 통해 내부 메트릭을 예측 하는 워크로드 기능을 포함 하는 반면 CDBTune은 측정 된 내부 메트릭을 사용 합니다.
* _ResTune_ 은 SLA 제약 조건을 사용 하 여 리소스 사용률을 최소화 하기 위해 제약 된 베이지안 최적화를 채택 합니다 (Shi et al., 2019). 앙상블 프레임워크(즉, RGPE)를 사용하여 원본 워크로드의 관찰에서 과거 지식을 전달합니다. OnlineTune과 동일한 안전 제약 조건으로 데이터베이스 성능을 최대화하기 위해 ResTune을 수정합니다. 온라인 튜닝에서 RGPE를 채택하기 위해 25개의 관측치마다 하나의 소스 워크로드로 클러스터링한다.
* _MysqlTuner_ 는 DBMS 메트릭을 검사 하 고 정적 휴리스틱을 사용 하 여 구성을 제안 하는 MySQL 튜닝 도구입니다 (Bondel et al., 2019). 온라인 튜닝 결과물은 화이트박스 어시스턴트이기도 합니다.

**워크로드**: 잘 알려진 벤치마크 및 실제 워크로드와 다른 특성을 가진 세 가지 워크로드를 사용합니다. 세 가지 워크로드는 TPC-C, OLTP-Bench(Bondel et al., 2019)의 Twitter 및 JOB(Shi et al., 2019)이다. TPC-C는 복잡한 관계를 갖는 쓰기-무거운 트랜잭션을 특징으로 하는 전통적인 OLTP 벤치마크이다. 트위터는 웹 기반 응용 프로그램에서 추출되며, 다대다 관계가 심하게 왜곡되고 불균일한 액세스가 특징이다. JOB 는 현실적이고 복잡한 조인을 특징으로 하는 113개의 멀티-조인 쿼리를 갖는 분석적 워크로드이다(Shi et al., 2019). 우리는 트위터에 대해 약 29GB 데이터, TPC-C에 대해 18GB, JOB에 대해 9GB를 로딩하고 OLTP 워크로드에 대해 무제한 도착 레이트를 사용하여 튜닝으로부터의 이점을 완전히 평가했다(본델 등, 2019; Shi 등, 2019; Shi 등, 2019; Shi 등, 2019; Shi 등, 2019). 실제 워크로드는 데이터베이스 모니터링 서비스에서 발생합니다. 실험에서는 2021년 9월 2일 10:00부터 16:00까지의 작업부하를 사용한다. 이 기간 동안 분당 읽기 쓰기 비율은 3:1 -74:1까지 다양하다.

**설정**: RDS MySQL의 버전 5.7을 사용합니다. 온라인 데이터베이스에는 재시작이 허용되지 않으므로 데이터베이스를 재시작하지 않고 40개의 동적 구성 노브를 조정합니다. 40개의 구성 노브는 DBA의 중요도에 따라 선택됩니다. 실험은 8 vCPU 및 16GB RAM이 있는 클라우드 인스턴스에서 실행됩니다. 간격 크기는 3분으로 설정됩니다. 우리는 DBA 기본 구성을 초기 안전 집합으로 사용하고 그 성능을 안전 임계값으로 사용하며, 이는 공정성을 위해 다른 기준선의 훈련 집합에도 추가된다.

**메트릭**: 튜닝 중 안전 및 누적 성능의 두 가지 관점에서 기준선을 평가합니다. 안전을 위해 튜닝 기간 내에 안전하지 않은 구성 권장 사항 수(#Unsafe)와 시스템 오류 수(#Failure)를 계산합니다. 누적 성능을 위해 OLTP 워크로드에 대한 튜닝 동안 데이터베이스에 의해 처리된 트랜잭션 수(#txn)와 OLAP 워크로드에 대한 실행 시간의 합으로 측정한다.

### 동적 워크로드 평가

구축된 동적 워크로드와 동적 질의 도착률을 갖는 실제 워크로드 워크로드를 사용하여 기준선 튜닝 온라인 데이터베이스를 평가한다. 두 가지 질문에 답할 것입니다. (1) _동적 워크 로드에 적응적으로 구성을 권장할 수 있습니까?_ (2) _안전 요구 사항을 확실하게 존중할 수 있는가?_

#### 7.1.1. 동적 쿼리 구성을 사용하는 워크로드 평가

동적 특성을 시뮬레이션하기 위해 동적 질의 구성으로 워크로드를 구성한다. TPC-C와 트위터의 경우 OLTP-Bench(Bondel et al., 2019)를 통해 트랜잭션 가중치를 달리한다. 가중치는 반복의 사인 함수를 평균 및 10% 표준 편차로 사용하여 정규 분포에서 샘플링된다. JOB에 대해 반복당 10개의 쿼리를 실행 하 고 그 중 5개를 다시 샘플링 합니다. 실행 시간이 간격 크기를 초과하면 쿼리를 제거합니다. TPC-C는 쓰기가 많은 워크로드이기 때문에, 그것의 기본 데이터도 변화하고 있다(예를 들어, 튜닝 동안 그것의 데이터 크기가 18 GB에서 48 GB로 변화함).

**OnlineTune은 워크로드별 구성을 찾습니다.* * 그림 5에 표시된 것처럼 OnlineTune은 MySQL 기본값보다 누적 성능이 54.3% -93.8%, DBA 기본값보다 16.2% -21.9% 향상됩니다. DBA 기본값은 워크로드 전반에 걸쳐 비교적 강력한 성능을 가질 것으로 예상됩니다. OnlineTune은 동적 환경에서 적응성을 보여 주는 더 나은 구성을 적용 합니다. 또한, 온라인 튜닝은 기존 오프라인 방식보다 누적 성능에서 14.4%-165.3%의 성능 향상을 달성하였다. 이유는 이중적이다. 첫째, 오프라인 메서드는 동적 환경을 처리하는 데 어려움을 겪습니다. BO는 GP 모델에 적합하도록 관측치 \(\{\theta_{i},y_{i}\}_{1}^{t}\)을 사용하여 동적 환경 요인을 무시한다. 워크로드가 분산되면 BO는 적합한 구성을 학습하지 못합니다. ResTune은 기본 모델에 다른 가중치를 할당하는 앙상블 GP를 채택하지만 기본 모델은 여전히 동적 요인을 무시한다. DDPG와 QTune은 환경이 변할 때 모델을 미세 조정하지만 신경망을 미세 조정하려면 많은 훈련 샘플이 필요하므로 온라인 튜닝에는 비효율적이다. 둘째, 오프라인 메서드는 구성 공간을 과도하게 탐색합니다. 불안전한 구성을 평가하는 것은 오프라인 방법에 대한 학습의 일부입니다. ResTune은 제약 조건을 만족하는 구성을 찾는 것을 목표로 하지만 여전히 안전하지 않은 영역을 평가하고 학습해야 한다. White-box 방식(MysqTuner)과 비교하여 OnlineTune은 10.1%-19.7%의 향상을 달성한다. MysqTuner는 과도한 탐색 문제가 없지만 지역 최적에서 발견적 규칙과 덫에 의존한다.

**OnlineTune은 온라인 데이터베이스를 튜닝할 때 안전 요구 사항을 안정적으로 존중합니다.* * 워크로드가 변경되면 안전 구성이 이동할 수 있으므로 온라인 데이터베이스를 튜닝할 때 안전 구성을 권장하는 것은 중요하지 않습니다. <그림 5>와 같이 OnlineTune 적용 시 시스템 장애는 발생하지 않는 반면, 오프라인 튜닝 방식은 여러 시스템 장애를 발생시킨다. 오프라인 방법은 400개의 튜닝 구간 내에서 22.2% -97.8%의 안전하지 않은 구성 권장 사항을 가지고 있다. 이에 비해 OnlineTune은 91.0%-99.5%의 안전하지 않은 권장 사항을 줄인다. 이것은 섹션 7.3.2의 절제 연구로 자세히 분석하는 OnlineTune의 안전한 탐색 전략에 기여했다.

#### 7.1.2. 트랜잭션 분석 주기에 대한 평가

우리는 동적 TPC-C와 JOB 워크로드를 번갈아 가면서 일별 트랜잭션 분석 워크로드 사이클을 시뮬레이션한다. 최적화 목표로 99%의 대기 시간을 사용합니다. TPC-C(OLTP, write-heavy)와 JOB(OLAP, complex join)의 작업부하 특성은 크게 다르다. 안전 제약을 존중하는 것은 그러한 시나리오에서 다소 까다롭다. 도 6의 (a)는 OnlineTune과 DBA default의 성능을 나타낸다. 워크로드는 TPC-C를 시작하고, 100회 반복마다 반복적으로 JOB와 교번한다. 온라인 튜닝은 줌인 그림과 같이 DBA 기본값보다 구성을 점진적으로 더 잘 찾습니다. JOB로 전환할 때 OnlineTune은 구성 공간을 탐색하는 데 몇 번의 반복이 필요합니다. 한편, 안전 임계값보다 약간 큰 대기 시간을 갖는 몇 가지 안전하지 않은 구성이 발생한다. 그런 다음, OnlineTune은 적응적으로 적합한 구성(예를 들어, JOB 워크로드에 대한 더 큰 정렬 버퍼 크기)을 찾는다. TPC-C에서 JOB로 다시 전환할 때, OnlineTune은 JOB에 대한 이전 관찰에 적합한 대리 모델을 선택하고 보다 신속하게 적합한 구성을 추천한다. OnlineTune은 안전 요건을 존중하면서 DBA 디폴트보다 성능을 달성하는 반면, 다른 접근법은 도 7(a)에 도시된 바와 같이 실패한다.

#### 7.1.3. Real-World Workload 평가

실제 워크로드 응용 프로그램의 워크로드를 평가합니다. 그림 6(b)는 OnlineTune의 튜닝 과정을 보여주고 그림 7(b)는 모든 베이스라인의 성능을 제시하고 있다. 온라인 튜닝은 DBA 기본값 대비 누적 개선률이 39.4%, 오프라인 방식 대비 누적 개선률이 25.5% \(\sim\)64.2% 향상되는 것을 확인하였다. OnlineTune은 초기에 몇 가지 안전하지 않은 구성을 적용하지만, 그들의 성능은 그림 6(b)와 같이 기본 성능의 10% 편차 이내이다.

#### 7.1.4. 알고리즘 오버헤드

도 8은 JOB 워크로드를 튜닝할 때의 연산 시간을 나타낸다. BO, DDPG 및 ResTune의 경우 계산 시간은 (1) 통계 수집, (2) 모델 피팅 및 (3) 모델 프로브로 구성된다. 온라인 튜닝 및 QTune의 경우 시간에는 포화도 포함됩니다. 온라인 튜닝의 계산 시간은 초기에 BO보다 약간 더 크다. 그러나 GP가 샘플 수에 대한 3차 복잡도를 겪기 때문에 BO의 오버헤드는 튜닝 반복보다 기하급수적으로 증가한다. 그 대신, OnlineTune의 계산 시간은 클러스터링 전략으로 인해 3.79초 이내이다.

또한, 온라인 튜닝 오버헤드의 영향을 분석한다. OnlineTune의 포화 모듈은 데이터베이스 인스턴스에 배포되고 다른 부분은 오버헤드가 데이터베이스 인스턴스에 영향을 주지 않는 백 엔드 튜닝 서버에 배포됩니다. 따라서 우리는 포화 현상의 영향에 초점을 맞춥니다. 이 모듈은 평균적으로 반복당 약 57.7ms가 걸린다. 그 영향을 측정하기 위해 구성을 변경하지 않고 유지하며 자원 사용량과 데이터베이스 성능을 비교하였으며, 평균 CPU 사용량은 77.28%, 비사용량은 77.27%로 나타났다. 포화 시간이 튜닝 간격(180초)의 약간의 비율만을 차지하기 때문에 증가는 무시할 수 있다. 데이터베이스 성능에 미치는 영향

도 5. 동적 워크로드를 튜닝할 때의 누적 성능(TPC-C 및 트위터의 경우, 높을수록 양호함; JOB의 경우, 낮을수록 양호함) 및 안전 통계.

한계 자원 소비로 인해 간과될 수도 있다. 평가를 위해 영향을 관찰하기 위해 구성을 변경하지 않습니다. 실제로, 위에서 평가된 바와 같이, OnlineTune을 실행할 때 데이터베이스 성능이 향상될 것이다.

### Case Study

온라인 튜닝의 튜닝 성능을 추가로 조사하기 위해 5개의 노브를 튜닝하는 사례 연구를 수행한다. 우리는 그림 9와 같이 읽기/쓰기 트랜잭션 구성이 다른 YCSB를 사용하여 워크로드 트레이스를 구성한다. 공동 컨텍스트 구성 공간은 논문의 다른 실험보다 작다. 따라서 광범위한 평가를 사용하여 공간을 탐색하고 각 워크로드 구성에 대한 최상의 구성(최상으로 표시됨) 및 안전하지 않은 영역을 얻을 수 있습니다. 그림 10과 같이 우리는 손잡이 사이에 상호 작용이 있음을 관찰한다. 그리고, 워크로드 구성들 사이에 규칙적인 패턴들이 존재하는데, 예를 들어, 버퍼 풀 크기(k1)가 크고 힙 테이블 크기(k2)가 작을 때, 처리량은 상대적으로 낮다. 그러나 노브의 전체 효과는 워크로드(예: 개별 최적 위치) 간에 상당히 다릅니다. 따라서 온라인 튜닝 시 워크로드 동적성을 고려해야 합니다.

그림 11은 섹션 7.1의 평가와 일치하는 튜닝 결과를 제시한다. 반복 도표에서 볼 수 있듯이 OnlineTune과 Best 사이의 거리는 OnlineTune이 최적 근처에서 구성을 안전하게 찾을 때 점차 감소한다. 오프라인 기준선의 반복 성능은 시행착오에 의해 큰 변동을 갖는다. 그림 12에서는 top-2 중요 노브의 구성 값에 초점을 맞춘다. 안전하지 않은 영역은 모든 안전 구성에서 노브의 값을 제외하여 근사화된다. 구성이 안전하지 않은 영역에서 노브 값으로 할당되는 경우, 구성은 안전하지 않지만 그 반대는 아니라는 점에 유의한다. 이것은 손잡이 상호 작용으로 인해 안전하지 않을 수 있습니다. 최적의 구성(최상)은 워크로드 간에 휴대할 수 없습니다. OnlineTune은 동적 워크 로드에 적응적인 구성을 적용 하 여 최적으로 안전하게 진행 합니다. 다른 기준선은 처음 50번의 반복에서 공격적으로 공간을 탐험하고 항상 안전하지 않은 지역을 탐험할 기회를 갖는다.

<그림 13>은 OnlineTune의 모듈들의 작업 과정을 시각화한 것이다. 왼쪽 그림에서 우리는 두 개의 관찰을 한다. 첫째, OnlineTune은 관측된 컨텍스트에 대한 해당 모델을 선택할 수 있다. 둘째, 서브공간은 처음에 디폴트 구성을 중심으로 하여 최적을 향해 이동한다. 각 모델에서 유지 관리되는 구성 부분 공간은 기본값에서 점차 멀리 이동하여 구성 공간을 안전하게 탐색합니다. 오른쪽 그림에서 우리는 안전 세트의 크기가 증강된 관찰로 업데이트된다는 것을 관찰한다. 온라인튠이 안전하지 않은 구성을 평가하면 안전성 추정이 즉시 강화되고 온라인튠은 평가된 최상의 구성 근처에 보수적인 구성을 권장하여 연속 회귀를 피할 수 있다.

### OnlineTune 분석

동적인 환경에서 안전하게 구성을 탐색하기 위해 상황 모델링과 안전한 탐색 전략으로 온라인 튜닝을 신중하게 설계합니다. 절제 연구를 통해 해당 디자인을 평가하고 OnlineTune의 견고성을 검증한다.

도 8. 상이한 접근법들의 계산 시간.

도 6. OLTP-OLAP 서클 및 실제 워크로드에 대한 반복 성능.

도 7. OLTP-OLAP 서클 및 실제 워크로드에 대한 누적 성능 및 안전 통계.

#### 7.3.1. Ablation Study for Contextual Modeling

온라인 튜닝에서 컨텍스트 모델링(워크로드의 포화 및 데이터 변경, 클러스터링 및 모델 선택)의 특정 구성 요소를 제거하여 전체 시스템에 대한 기여도를 파악한다. (1) OnlineTune, (2) OnlineTune-w/o-workload, context에서 workload feature 제거, (3) OnlineTune-w/o-data, context에서 optimizer statistics(데이터 feature 기반) 제거, (4) OnlineTune-w/o-clustering, clustering 및 model selection 제거

도 11. YCSB 워크로드에 대한 결과: 좌측 그림은 누적 결과를 나타내고 우측은 반복 성능을 나타낸다. 프레젠테이션의 명확성을 위해, 우리는 상위 3개의 베이스라인(OnlineTune, ResTune 및 BO)의 반복적 성능만을 보여준다.

도 12. YCSB 워크로드 상에서 OnlineTune, ResTune 및 BO에 의해 적용된 구성: 상위 2개의 중요한 노브를 제시한다.

도 13. OnlineTune의 시각화. 왼쪽 그림에서 다른 색상은 반복에 걸쳐 선택된 다른 모델을 나타낸다. 선은 권장 구성과 기본값 사이의 거리를 나타내고 대시는 부분 공간 중심과 기본값 사이의 거리를 나타낸다. 오른쪽 그림은 제한된 부분 공간에서 OnlineTune이 추정한 안전 집합의 크기를 보여준다. 참고로, 반복에 대한 성능 개선도 도식화한다.

도 9. YCSB 워크로드의 패턴. 도 10. 구성들의 함수로서의 처리량: k1은 sort_buffer_pool_size를 나타내고 k2는 max_heap_table_size를 나타낸다.

설계한다. 실험은 섹션 7.1.1과 동일한 설정으로 동적 TPC-C와 JOB에서 수행된다. 그림 14는 이러한 기준선의 DBA 기본값과 안전 통계량에 대한 누적 성능 향상을 보여준다. 다음 평가에서는 누적 성과 대신 온라인 튜닝의 이점을 보다 명확하게 보여주는 누적 개선을 사용한다. 데이터 변화가 발생하지 않는 읽기 전용 워크로드 JOB에서 OnlineTune-w/o-데이터는 정보 손실 없이 컨텍스트 특징의 차원이 감소하기 때문에 OnlineTune을 약간 초과하며, 이는 컨텍스트에 대한 모델링이 더 쉬워진다는 것을 의미한다. 그러나 TPC-C 워크로드와 같이 데이터 변경이 발생할 경우, 온라인 튜닝은 컨텍스트 기능이 동적 환경의 포괄적인 추상화를 제공하기 때문에 다른 기준선보다 성능이 우수하다. 클러스터링 및 모델 선택 전략은 "부정적인 전송"을 방지할 수 있기 때문에 모든 경우에 OnlineTune이 OnlineTune-w/o-클러스터링보다 우수하다.

#### 7.3.2. Ablation Study for Safe Exploration

온라인 데이터베이스를 안전하게 최적화하기 위해 OnlineTune은 컨텍스트 GP(블랙박스 지식)와 도메인 지식(화이트박스 지식)을 활용하여 최적화 하위 공간을 점진적으로 확장한다. 그 기능을 분석하기 위해 (1) OnlineTune, (2) OnlineTune-w/o-white, White-box 안전성 평가 제거 (3) OnlineTune-w/o-black, black-box 안전성 평가 제거, (4) OnlineTune-w/o-subspace, 전체 구성 공간에서 최적화, (5) OnlineTune-w/o-safe, 모든 안전 전략, 즉 바닐라 컨텍스트 BO를 제거한다. 그림 15와 같이 OnlineTune은 성능과 안전도 모두에서 다른 기준선을 능가한다. 다음과 같은 관찰을 수행합니다. (1) 블랙박스 지식은 안전하지 않은 권장 사항을 크게 줄입니다. 제한된 도메인 규칙은 안전하지 않은 사례의 작은 부분 집합만 포함하고 구성, 환경 및 데이터베이스 성능 사이의 복잡하고 고차원 관계를 포착하지 못한다. 따라서 OnlineTune-w/o-black의 안전하지 않은 추천은 OnlineTune-w/o-white보다 훨씬 많다. (2) 화이트박스 지식은 안전하지 않은 구성을 필터링하는 데 도움이 된다. 온라인 튜닝-w/o-화이트에서 안전하지 않은 추천은 주로 고유한 순서(예: thread_concurrency)가 없는 노브에 의해 발생한다는 것을 발견했다. Thread_concurrency는 InnoDB 내에서 허용되는 최대 스레드 수를 정의합니다. 그러나 0의 값(기본값)은 무한 동시성(제한 없음)으로 해석됩니다. GP 모델은 공간의 자연스러운 순서 특성과 매끄러움에 따라 달라진다. OnlineTune-w/o-white가 안전 공간을 확장할 때 컴퓨팅 리소스의 부족으로 인해 케이싱 성능 다운그레이드처럼 0에 가까운 값을 시도할 가능성이 높습니다. OnlineTune에는 가상 CPU 수의 절반 미만의 스레드 동시성 값을 필터링하는 도메인 규칙이 있어 안전하지 않은 경우를 방지합니다. (3) 전체 구성 공간 대신에 유망한 부분 공간에 대해 최적화하는 것은 안전성을 향상시키고 양호한 구성을 국지화할 수 있다. OnlineTune-w/o-subspace는 OnlineTune보다 안전하지 않은 구성을 권장합니다. 논의된 바와 같이, 전체 공간에서 구성의 안전성을 일반화하기 어렵고, GP의 예측은 작은 신뢰 지역에서 더 신뢰할 수 있다. 또한 전역 최적화 접근법(OnlineTune-w/o-subspace, OnlineTune-w/o-safe)은 구성 공간의 경계를 과도하게 탐색한다. (4) 어떠한 안전 설계도 없이, OnlineTune-w/o-safe는 최악의 성능을 갖는다.

#### 7.3.3. 가변 간격 크기 조정

다양한 간격 크기: 5초, 1분, 3분, 6분 및 12에서 OnlineTune을 실행합니다.

도 16. 서로 다른 간격 크기로 트위터를 튜닝함.

도 14. 문맥 공간 설계에 관한 절제 연구.

도 17. MySQL Default로부터 시작.

도 15. 안전한 탐사에 대한 절제 연구.

분, 도 16에 도시된 바와 같이. 일정 범위 내에서, 더 작은 간격은 더 빠른 적응으로 이어진다. 그 이유는 두 가지입니다. 먼저 OnlineTune은 동적 워크 로드에 적합한 세분화된 구성을 권장할 수 있습니다. 둘째, 온라인 튜닝은 주어진 시간에 더 많은 관찰을 수집하여 더 나은 튜닝 정책으로 이어질 수 있다. 그러나 간격 크기는 데이터베이스 성능을 평가하는 시간도 결정합니다. 성능 변동에 의한 불안정성을 회피하기에는 너무 작을 수 없다(Beng et al., 2019). 도시된 바와 같이, 5초 간격으로 튜닝하는 것은 더 안전하지 않은 추천을 갖는 1분 간격보다 더 나쁘다. 그리고 고정된 구성에서 5초 간격에 대해 상당한 성능 분산을 관찰했다.

#### 7.3.4. 초기 안전 설정 및 안전 임계값 변경

위의 평가에서는 DBA 기본값을 초기 안전 집합으로 사용하고 그 성능을 안전 임계값으로 사용한다. 그러나 다음과 같은 질문이 있습니다. _OnlineTune이 시작점이 낮은 적절한 구성을 권장할 수 있습니까?_ 따라서 MySQL 기본 구성을 초기 안전 집합으로 사용 하 고 성능을 안전 임계값으로 사용 합니다. 그림 17과 같이 MySQL 기본값은 DBA 기본값보다 성능이 좋지 않습니다. 한 가지 주요 차이점은 MySQL 기본값은 버퍼 풀 크기를 128MB로 설정하고 DBA 기본값은 버퍼 풀 크기를 13GB로 설정한다는 것입니다. MySQL 기본값에서 시작할 때 OnlineTune은 MySQL 기본값보다 안전한 구성을 더 잘 적용 합니다. 그리고 약 150회 반복 후 DBA 디폴트를 시작점으로 하는 튜닝과 비슷한 성능을 달성합니다.

### 정적 워크로드 평가

기존 접근 방식은 정적 워크로드에서 최적의 구성을 검색하는 데 효과적입니다. 이 평가는 안전성 제약조건을 가지고 온라인 튜닝의 검색 효율성을 평가하는 것을 목표로 한다. <그림 18>은 <표 1>과 같은 통계량으로 성과를 제시하고 있다.

**OnlineTune은 최신 오프라인 튜닝 방법에 필적하는 검색 효율로 안전하지 않은 권장 사항을 크게 줄입니다.* * 오프라인 메서드는 안전 고려 사항 없이 최적을 검색하도록 설계되었습니다. 효율성 측면에서 OnlineTune은 BO, ResTune과 비슷하며 모든 경우에 DDPG, QTune보다 우수하다. 온라인 튜닝은 안전하지 않은 구성을 적용할 가능성이 매우 낮지만 오프라인 방법은 안전 제약을 상당히 위반한다. 온라인 튜닝의 안전 고려는 탐사를 느리게 만들 수 있지만, 탐색 공간을 적응적으로 제한하면 좋은 솔루션을 국소화할 수 있으며, 이는 특히 JOB의 경우 수렴성을 향상시킨다.

## 8. Conclusion

동적인 환경을 인식하고 데이터베이스를 안전하게 최적화하는 온라인 튜닝 시스템인 OnlineTune을 소개합니다. 온라인 튜닝은 동적 환경 요소를 컨텍스트 특성으로 최적화하고 컨텍스트-구성 결합 공간을 최적화하기 위해 컨텍스트 베이지안 최적화를 활용한다. 온라인 튜닝의 안전성을 크게 높이는 안전한 탐색 전략을 제안합니다. 향후 확장으로 OnlineTune과 오프라인 튜닝을 결합하여 조사할 계획이다. 오프라인 프로세스는 대상 DBMS의 복제본에서 더 많은 구성을 탐색하여 과거 워크로드를 다시 재생하여 온라인 튜닝을 위한 관찰을 수집할 수 있습니다. 따라서 온라인 튜닝은 온라인 단계에서 유망한 구성 공간을 활용하여 동적 환경에 보다 빠르게 대응할 수 있다. 또한 온라인 튜닝은 적합한 구성을 적용한 후 온라인 구성을 일시 중지할 수 있습니다. 이것은 정지 및 트리거링 메커니즘에 의해 달성될 수 있다. 우리는 온라인 튜닝의 워크플로우를 각 반복(후보 포인트에 대한 컨텍스트 포화 및 획득 값 계산 포함)에서 유지할 수 있지만 더 유망한 후보가 나타날 때까지 데이터베이스 구성을 변경하지 않을 수 있다. 예를 들어, 적용된 구성에 대해 기대 개선(Expected Improvement; EI) 값을 계산함으로써 더 많은 유망한 후보들이 존재하는지 여부를 측정할 수 있다. 구성하는 것은 임계치보다 큰 EI 값들을 갖는 후보들이 존재할 때 트리거되며, 이는 컨텍스트 변경들이 재-구성할 필요로 이어진다는 것을 나타낸다.

#### Acknowledgments

이 작업은 중국 국립자연과학재단(NSFC)(No. 61832001)의 지원을 받는다. , 알리바바 혁신연구 프로그램과 국가핵심연구를 통한 알리바바 그룹, 베이징 인공지능아카데미 등이다. 빈 쿠이가 해당 작가입니다.

\begin{table}
\begin{tabular}{c|c c|c c|c c|c c|c c} \hline \hline  & \multicolumn{2}{c}{**OnlineTune**} & \multicolumn{2}{c}{**BO**} & \multicolumn{2}{c}{**DDPG**} & \multicolumn{2}{c}{**ResTune**} & \multicolumn{2}{c}{**QTune**} & \multicolumn{2}{c}{**MySQLTune**} \\
**Workload** & Max Improv. & Search Step & Max Improv. & Search Step & Max Improv. & Search Step & Max Improv. & Search Step & Max Improv. & Search Step \\ \hline TPC-C & 17.0\% & 176 & **19.99\%** & **74** & 16.64\% & 76 & 12.0\% & \multirow{2}{*}{\(\backslash\)} & 12.02\% & \multirow{2}{*}{\(\backslash\)} & 13.44\% & \\ Twitter & **48.18\%** & 129 & 43.43\% & 158 & 35.79\% & \(\backslash\) & 46.95\% & **10** & 8.06\% & \multirow{2}{*}{\(\backslash\)} & 13.07\% & \\ JOB & 11.67\% & **141** & 7.77\% & \(\backslash\) & 7.60\% & \(\backslash\) & **11.84\%** & 155 & 11.24\% & 168 & 7.23\% & \\ \hline \hline \end{tabular}
\end{table}
표 1. 정적 워크로드에 대한 통계: 각 워크로드에 대해 굵은 면은 최상의 값을 나타낸다. 검색 단계는 추정된 최적값의 10% 이내의 구성을 찾는 데 필요한 반복을 의미하고, \(\backslash\)은 그러한 구성을 찾을 수 없음을 나타낸다.

도 18. 정적 워크로드들에 대한 반복 성능: 최소 처리량(0) 및 최대 대기 시간(200)은 시스템 실패를 나타낸다.

## References

* (1)
* (2015) 2015. GPy Library. [https://sheffieldml.github.io/GPy] (https://sheffieldml.github.io/GPy).
* (2017) 2017. PyTorch Library. [https://pytorch.org] (https://pytorch.org).
* (2019) 2019. MYSQL Tuning Primer Script. [https://github.com/major/MySQL_Tunter-perl] (https://github.com/major/MySQL_Tunter-perl).
* (2011) Mert Akdere, Ugur Cetintemel, Matteo Rionlado, Eli Upfal, and Stanley B. Zdonik. 2011. 예측 데이터베이스 시스템의 사례: 기회와 도전. _CIDR_에서. www.cidrhorg, 167-174.
* (2012) Mater Akdere, Ugur Cetintemel, Matteo Rionlado, Eli Upfal, and Stanley B. Zdonik. 2012. Learning-based Query Performance Modeling and Prediction. _ICDE_에서. IEEE Computer Society, 390-401.
* (2017) Dana Yan Aken, Andrew Pavlo, Geoffrey J. Gordon, and Bohan Zhang. 2017. 대규모 기계학습을 통한 데이터베이스 자동 관리 시스템 튜닝. _SIGMOD Conference_에서. ACM, 1009-1024.
* (2018) Dana Yan Aken, Dongsheng Yang, Sebastien Brillard, Ari Fiorino, Bohan Zhang, Christian Billan, and Andrew Pavlo. 2021. Real-World Database Management Systems 상에서 Machine Learning 기반 자동 구성 튜닝 서비스에 대한 조회. Proc. VLDB Endow. 14, 7(2021), 1241-1253.
* (2013) Yoshua Bengio, Aaron C. Courville, and Pascal Vincent. 2013. Representation Learning: A Review and New Perspectives. _ EEE Trans. Pattern Anal. 마케터 Intell._ 35, 8(2013), 1798-1828.
* (2011) James Bergstra, Remi Bardenet, Yoshua Bengio, and Balasz Kegl. 2011. Algorithms for Hyper-Parameter Optimization. _NIPS_에서입니다. 2546-2554.
* (2016) Felix Berikenkamp, Andreas Krause, and Angela P. Schoellig. 2016. Bayesian Optimization with Safety Constraints: Safe and Automatic Parameter Tuning in Robotics. _ CoRR_ abs/1602.04450 (2016).
* (2014) Roberto Calandras, Andre Seyfarth, Jan Peters, and Marc Peter Deisenroth. 2014. experimental comparison of Bayesian optimization for bipedal locomotion. _ICRA_에서. IEEE, 1951-1958.
* (2005) Karl Dias, Mark Ramacher, Uri Shaft, Venkateshwaran Venkataramani, and Graham Wood. 2005. Automatic Performance Diagnosis and Tuning in Oracle. _CIDR_에서. workcidrhorg, 84-94.
* (2013) Jiejelle Eddine Difallah, Andrew Pavlo, Carlo Curino, and Philippe Cuche-Mauroux. 2013. CLTP-Bench: Benchmarking Relational Database for Extensible Testbed. _ Proc. VLDB Endow. 4_, 7(2013), 277-288).
* (2012) Liang Du, Ruobin Gao, Ponmuthuri Nagataman Suganthan, and David Z. W. Wang. 2022. 베이지안 최적화 기반 시계열 예측을 위한 동적 앙상블. _Ist._ 551(2022), 155-175.
*(2009) Songyuan Duan, Yannakshin Thummala, Shirvnath Babu. 2009. Tuning database Configuration Parameters with iTuned. _ Proc. VLDB Endow. 2_, 1(2009), 1246-1257).
* (2019) David Eriksson, Michael Pearace, Jacob R. 가드너, 라이언 터너, 마티아스 폴로첵 2019. Scalable Global Optimization via Local Bayesian Optimization. _NeurIPS_에서입니다. 5497-5508.
* (2019) Martin Ester, Hans-Peter Kriegel, Jorg Sander, and Xiaowei Xu. 1996. A Density-Based Algorithm for Discovering Clusters with Large Spatial Databases with Noise. _KDD_에서. AAAI Press, 226-231.
* (2020) Araf Fekry, Lucian Carata, Thomas F. J.-M. 파스키어, 앤드류 라이스 앤디 하퍼 2020년. 튜닝할 것인가 아니면 튜닝하지 않을 것인가? Data Analytics용 최적 구성기의 _S_ectural. _KDD_에서. ACM, 2494-2504.
* (2020) Araf Fekry, Lucian Carata, Thomas F. J.-M. 파스키어, 앤드류 라이스 앤디 하퍼 2020. Tuneful: Big Data Analytics를 위한 온라인 의미 인식 구성 조정입니다. _ CoRR_ abs/2001.08002 (2020).
* (2020) Marcelo Fiducaro, Sebastien Curi, Benedik Schumacher, Markus Guerer, Andreas Krause. 2019. Safe Contextual Bayesian Optimization for Sustainable Room Temperature PID Control Tuning. _IJCAI_에서. ivsci.org, 5850-5856.
* (2015) Lorenz Fischer, Shen Gao, and Abraham Bernstein. 2015. Machines Tuning Machines: Distributed Stream Processors with Bayesian Optimization. _CLUSTER_에서입니다. IEEE Computer Society, 22-31.
* (2015) Adam Foster, Martin Jankowik, Eli Engham, Paul Horsfall, Yee Whye Teh, Tom Rainforth, and Noah D. Goodman. 2019. Variational Bayesian Optimal Experimental Design. _NeurIPS_에서입니다. 14036-14047.
* (2009) Archana Ganapathi, Harun A. Kuno, Umeshwar Dayal, Janet L. 위너, 아르만도 폭스, 마이클 조던, 데이비드 A. 패터슨 2009. Predicted Multiple Metrics for Query: Better Decision Enable by Machine Learning. _ICDE_에서. IEEE Computer Society, 592-603.
* (2014) Jacob R. Gardner, Matt J. Kunner, Zhixiang Eddie Xu, Kilian Q. 와인버거, 존 P 커닝햄 2014. Bayesian Optimization with Inequality Constraints. _ICML(JMLR Workshop and Conference Proceedings, Vol. 32)_에서. JMLR, org, 937-945.
* (2014) Michael A. Gelhart, Japper Smock, and Ryan P. Adams. 2014. Bayesian Optimization with Unknown Constraints. _IAI_에서. AUAI Press, 250-259
* (2020) Benjamin Hilprecht, Andreas Schmati, Moritz Kulessa, Alejandro Molina, Kristina Kerting, and Carsten Binnig. 2020. DeepDB: 쿼리가 아닌 데이터에서 학습합니다. _ Proc. VLDB Endow._ 13, 7(2020), 992-1005.
* (2014) Frank Hutter, Jeffger H. Hoos, and Kevin Leyton-Brown. 2014. Efficient Approach for Assessing Hyperparameter Importance. _ICML(JMLR Workshop and Conference Proceedings, Vol. 32)_에서. JMLR org, 754-762.
* (2019) Frank Hutter, Lars Kotthoff, and Joquin Vanschoren (Eds.). 2019. _Automatic Machine Learning: Methods, Systems, Challenges_. 스프링거
* (2018) Shraink Jain and Bill Howe. 2018. Query2Vec: NLP Meets Databases for Generalized Workload Analytics. _ CoRR_ abs/1801.05613 (2018).
* (2019) Shraink Jain, Jiaqi Yan, Thierry Crunas, and Bill Howe. 2019. Database-Agnostic Workload Management. _CIDR_에서. www.cidrhorg.
* (2013) Marjan Backait, Nasser Ghasen-Aghagan-Abdang, and Chang Wook Ahn. 2013. Holographic memory-based Bayesian optimization algorithm (HM-BOA) in dynamic environments. _ Sci. China Inf. Sci._ 56, 9(2013), 1-17.
* (2020) Konstantinos Kannelis, Ramatthan Alagapour, and Shivaram Venkataraman. 2020년, 튜닝할 노브가 너무 많아? 중요 노브를 미리 선택하여 데이터베이스 조정 속도 향상 _InfStorage_에서입니다. USENIX 협회요
* (2020) Andreas Kipt, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter A. Boncz, and Alfos Kemper. 2020. Leonard Cardinales: Estimating Correlated Jons with Deep Learning. _CIDR_에서. www.cidrhorg.
*(2021) Johannes Kirschener, Mojin Mutny, Neocle Hiller, Rasmus Ischebeck, Andreas Krause. 2019. Adaptive and Safe Bayesian Optimization in High Dimensions via One-Dimensional Subspaces. _ICML(Proceedings of Machine Learning Research, Vol. 97)_에서. PMLR, 3429-343.
* (2011) Andreas Krause and Cheng Soon Ong. 2011. Contextual Gaussian Process Bandit Optimization. _NIPS_에서입니다. 2447-2455.
*(2020) Adri Krishnan, Mahasukeu Das, Mangesh Bendre, Hao Yang, and Hari Sundaram. 2020. Transfer Learning via Contextual Invariants for One-to-Many Cross-Domain Recommendation. _SIGIR_에서. ACM, 1081-1090.
* (2020) Mayuresh Kunjiar and Shirvnath Babu. 2020년 블랙? 화이트? 오토튠을 개발하는 방법? 메모리 기반 분석을 위한 AutoTune 개발 방법. _SIGMOD Conference_에서. ACM, 1667-1683.
* (2021) Hari Lan, Zhifeng Bao, and Yu Yuwei Peng. 2021. DBMS Query Optimizer 고도화에 대한 설문조사: Cardinality Estimation, Cost Model, Plan Enumeration. _ Data Sci. Eng._ 6, 1(2021), 86-101.
* (2015) Viktor Leis, Andrey Guhchiken, Matzas Mirchev, Peter A. Boncz, Alfons Kemper, and Thomas Neumann. 2015. Query Optimizers는 얼마나 좋은가요? Proc. VLDB Endow._ 9, 3(2015), 204-215).
* (2017) Benjamin Leichnan, Brian Karrer, Guilherme Ottoni, Eytan Balsky. 2017. Constrained Bayesian Optimization with Noisy Experiment. _ CoRR_ abs/1706.07094 (2017).
*(2019) Guoliang Li, Shuanhe Zhou, Shifu Li, and Bo Gao. 2019. QTune: 심층 강화 학습을 이용한 질의 인식 데이터베이스 튜닝 시스템. _ Proc. VLDB Endow._ 12, 12(2019), 2118-2130).
* (2021) Edo Liberty, Zohar S. 카민, 빙샹, 로렌스 루셀, 바리스 코스쿤, 라마스 날라파티, 훌리오 델가도, 아미르 사도피, 유리 아스타슈호크, 파틸다스, 칸 발로구, 사완타 차크라바티, 마디아 자하, 필립 고티에, 다비드 아르핀, 팀 야누스쇼프스키, 발렌틴 플렁커, 유양 왕, 얀 가스타우스, 로렌조 스텔라, 시라마 순다르 랑고람, 다비드 살리나스, 세바스티안 셸터, 알렉스 스몰라 등이다. 2020. Amazon SageMaker에서의 탄성 기계 학습 알고리즘. _SIGMOD Conference_에서. ACM, 731-737.
* (2018) Lin Ma, Daana Van Aken, Ahmed Hefny, Gustavo Mezerhane, Andrew Pavlo, and Geoffrey J. Gordon. 2018. Query-based Workload Forecasting for Self-Driving Database Management Systems. _SIGMOD Conference_에서. ACM, 631-645.
*(2019) Lin Ma, William Zhang, Jie Jiao, Wuwen Wang, Matthew Burtovich, Wan Shen Lim, Prashanth Menon, and Andrew Pavlo. 2021. MB2: Self-Driving Database Management Systems를 위한 분해된 행위 모델링. _SIGMOD Conference_에서. ACM, 1248-1261.
* (2019) Victor Hirota Makiyama, M. 조던 라디젝과 라파엘 D.C. 산토스 2019. SQL 쿼리에 적용된 텍스트 마이닝: SDSS/Server 사례 연구 _SMBig(CEURUR Workshop, Vol. 1478)_에서. CEUR-UR-WS,org, 66-72
* (2017) Alonso Marco, Felix Berikenkamp, Philipp Heming, Angela P. Schoellig, Andreas Krause, Stefan Schaal, and Sebastian Trimpe. 2017. Virtual vs real: Trading of simulation and physical experiments in reinforcement learning with Bayesian optimization. _ICRA_에서. IEEE, 1557-1563.
* (2019) Ryan C. Marcus, Parimara Nregi, Hongyi Mao, Chi Zhang, Mohammad Alizadeh, Tim Kraska, Olga Pap* Snoek 등 (2012) Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. 2012. Practical Bayesian Optimization of Machine Learning Algorithms. _NIPS_에서입니다. 2960-2968.
* Srinivas et al. (2010) Niranjan Srinivas, Andreas Krause, Sham M. Kakade, Matthias W. 시거 2010. Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design. _ICML_에서. Omnipress, 1015-1022.
* Sui 등(2015) Yanan Sui, Alkis Gotovos, Joel W. 버딕과 안드레아스 크라우세 2015. Safe Exploration for Optimization with Gaussian Processes. _ICML_(_JMLR Workshop and Conference Proceedings_, Vol. 37).MLR_.org, 997-1005.
* Sullivan 등(2004) David G. Sullivan, Margo I. Seltzer, and Avi Pfeffer. 2004. using probabilistic reasoning to automate software tuning. _SIGMETRICS_에서. ACM, 404-405.
* Sun and Li (2019) Ji Sun and Guoliang Li. 2019. End-to-End 학습 기반 비용 추정기. _ Proc. VLDB Endow._ 13, 3(2019), 307-319).
* Sutskever et al. (2014) Ilya Sutskever, Oriol Vinyals, and Quoc V. 레 2014. Sequence to Sequence Learning with Neural Networks. _NIPS_에서입니다. 3104-3112.
* Taff 등(2018) Rebecca Taff, Nosayba El-Sayed, Marco Serafini, Yu Lu, Ashraf Aboulnaga, Michael Stonebrenker, Ricardo Mayerhofer, and Francisco Jose Andrade. 2018. P-Store-Predictive Provisioning을 갖는 탄력적 데이터베이스 시스템. _SIGMOD Conference_에서. ACM, 2015-219
* Tan 등(2021) Jian Tan, Niv Nayman, Mengchang Wang, and Rong Jin. 2021. CoBBO: Coordinate Backoff Bayesian Optimization with Two-Stage Kernels. _ CoRR_ abs/2101.05147 (2021).
* Tan 등(2019) Jian Tan, Tiseying Zhang, Feifei Li, Lie Chen, Qixing Zheng, Ping Zhang, Honglin Qiu, Yue Shi, Wei Cao, and Rui Zhang. 2019. The: Individual Buffer Tuning for large-scale Cloud Databases. _ Proc. VLDB Endow._ 12, 10(2019), 1221-1234.
* Wang 등(2020) Linnan Wang, Rodrigo Fonseca, and Yuandong Tian. 2020. Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search. _NeurIPS_에서입니다.
* Wang 등(2018) Zi Wang, Clement Gehring, Pushner Kohli, and Stefanie Jegelka. 2018. Batched Large-scale Bayesian Optimization in High-dimensional Space. _AISTATS(Proceedings of Machine Learning Research, Vol. 84)_에서. PMLR, 745-754.
* Wang 등(2014) Zijyu Wang, Babak Shakhidi, Lin, Jin, and Nando de Freitas. 2014. Bayesian Multi-Scale Optimatic Optimization. _AISTATS(_QMLR Workshop and Conference Proceedings_, Vol. 33). JMLR.org, 1005-1014.
* Wei 등(2014) Zhibe Wei, Zuohua Ding, and Jipeling Hu. 2014. Self-tuning performance of database systems based on fuzzy rules. _FSDI_에서입니다. IEEE, 194-198.
* Weikum et al. (2002) Gerhard Weikum, Axel Monkerey, Christof Hasse, and Peter Zabback. 2002. Self-tuning Database Technology and Information Services: Wishful Thinking to Viable Engineering. _VLDB_에서. 모건 카우프만, 20-31
* Wistuba et al.(2015) Martin Wistuba, Nicolas Schilling, and Lars Schmidt-Thieme. 2015. Sequential Model-Free Hyperparameter Tuning. _ICDM_에서. IEEE Computer Society, 1033-1038.
* Yan 등(2018) Jiaqi Yan, Qiuye Jin, Shrainik Jain, Stratis D. Viglas, and Allison W. 리 2018. Snowtrial: Cloud Database에서 프로덕션 쿼리로 테스트. _DITest@SIGMOD_에서. ACM, 41-46
* Yang et al.(2020) Zongheng Yang, Amog Kammetty, Sifei Luan, Eric Liang, Yan Duan, Peter Chen, and Ion Stoica. 2020. Next-Accurad: 모든 테이블에 대한 하나의 Cardinality Estimator. _ Proc. VLDB Endow._ 14, 1(2020), 61-73).
* Yang et al. (2019) Zongheng Yang, Eric Liang, Aong Kammetty, Chenggang Wu, Yan Duan, Peter Chen, Pieter Abbeel, Joseph M. 헬러스타인, 산제이 크리쉬난, 이온 스토이카 2019. Deep Unsupervised Cardinality Estimation. _ Proc. VLDB Endow._ 13, (2019), 279-292.
* Yuan ([n.d.]) Yu-Xiang Yuan. [n.d.]. A Review of Trust Region Algorithms for Optimization. _ 제이 Zhang 등(2019) J. Zhang, Yu Liu, Ke Zhou, Guoliang Li, Zhili Xiao, Bin Cheng, Jiashu Xing, Yanjong Wang, Tianheng Cheng, Li Liu, Minwei Ran, and Zekang Li. 2019. Deep Reinforcement Learning을 이용한 End-to-End 자동 클라우드 데이터베이스 튜닝 시스템. _SIGMOD Conference_에서. ACM, 415-432.
* Zhang 등(2021) Xinyi Zhang, Hong Wu, Zhuo Chang, Shuowei Jin, Jian Tan, Feifei Li, Tieying Zhang, and Bin Cui. 2021. ResTune: Resource Oriented Tuning Boosted by Meta-Learning for Cloud Databases. _SIGMOD Conference_에서. ACM, 2021-2114.
* Zhu 등(2017) Yuqing Zhu, Jianxun Liu, Mengying Guo, Yungang Bao, Wenlong Ma, Zhuoyue Liu, Kunpeng Song, and Yingchun Yang. 2017. BestConfig: 자동 구성 튜닝을 통해 시스템의 성능 잠재력을 탭핑. _SoCC_ 에서입니다. ACM, 338-350
* Zolakraf 등(2020) Zainab Zolakraf, Mostafa Milani, and Rachel Pottinger. 2020. SQL 쿼리 구성 및 분석을 촉진합니다. _SIGMOD Conference_에서. ACM, 209-224

## Appendix A Outline

이 첨부 자료는 다음과 같이 구성되어 있습니다.

**A.1** OnlineTune 아키텍처에 대한 자세한 내용은 다음과 같습니다.

**A.2** 상위 수준 알고리즘입니다.

**A.3** 부분 공간 적응에 대 한 세부 정보입니다.

## A1. OnlineTune 아키텍처에 대한 자세한 내용

**시스템 아키텍처.** 그림 A1은 OnlineTune의 아키텍처를 보여 줍니다. 왼쪽 부분은 끊임없이 변화하는 워크로드를 실행하는 클라우드 환경의 온라인 데이터베이스 시스템을 보여줍니다. 오른쪽 부분은 백 엔드 튜닝 클러스터에 배포된 OnlineTune 서버를 나타냅니다. 온라인 튜닝은 초기 비어있을 수 있는 이전 튜닝 반복의 과거 관측치 \(\{<e_{i}\,\theta_{i},y_{i}>\}_{1}^{t}\)을 저장하는 데이터 저장소를 유지한다. 제어기는 튜닝 작업의 상태를 모니터링하고 데이터베이스측과 OnlineTune 서버측 사이에서 데이터를 전송한다. OnlineTune의 주요 부분은 리소스 소비가 온라인 데이터베이스에 영향을 주지 않는 서버 쪽에서 실행됩니다. 컨텍스트 포화 모듈은 데이터 프라이버시 문제를 위해 데이터베이스 인스턴스에 배치된다.

**토론.** OnlineTune은 반응형 접근 방식입니다. 반복 시작 시 온라인 워크로드를 충족시키고 반복의 나중에 구성을 적용합니다. 실제 워크로드의 변화는 점진적이기 때문에, 적은 지연도 수용할 수 있다. 상황에 대한 예측 모듈이 도움이 될 수 있습니다. 그러나 여전히 과거 데이터를 기반으로 점진적이고 예측 가능한 변화를 가정하고 있으며, 부정확한 예측 모듈은 튜너의 성능에 큰 영향을 미칠 수 있다.

## 부록 B. 최상위 알고리즘

알고리즘 3은 최상위 알고리즘을 제시한다. OnlineTune은 먼저 기본 구성과 성능을 쿼리하여 초기 안전 집합을 형성하고 데이터 리포지토리(Line1-3)를 초기화합니다. 안전 임계값은 기본 성능으로 설정됩니다. 반복 시작 시 OnlineTune은 들어오는 워크로드 쿼리 및 해당 최적화기의 추정치를 수집 하 여 컨텍스트 벡터 \(c_{i}\)를 계산 합니다 (라인 5, 섹션 5.1). OnlineTune은 컨텍스트 벡터를 입력하고 클러스터 레이블 \(n\)을 출력하는 SVM 모델에 의해 선택된 예측 모델 \(m_{i-1}^{n}\)을 로딩한다(Line 6, Section 5.3). 그런 다음, 구성 서브스페이스가 초기화되거나 적응된다(라인 7, 섹션 6.1). OnlineTune은 구성 부분 공간을 이산화하고 흑백 사전 지식을 기반으로 평가되지 않은 구성의 안전성을 평가하여 안전한 후보 세트(안전 세트)를 형성한다(라인 8, 섹션 6.2). 다음으로, OnlineTune은 안전 세트 내의 구성 \(\theta_{i}\)을 trade-off exploitation(즉, 기존 지식을 기반으로 결정) 및 탐색(즉, 새로운 지식을 획득하거나 안전 세트를 확장)할 것을 권고한다(9행 6.3절). 구성 \(\theta_{i}\)을 온라인 데이터베이스에 적용하고 튜닝 구간 동안의 데이터베이스 성능 \(y_{i}\)을 수집한다. 마지막으로 OnlineTune은 예측모델과 데이터 저장소를 \(\{\theta_{i},c_{i},y_{i}\}\) (라인 12~11)로 갱신한다. OnlineTune은 다시 클러스터할지 여부를 결정합니다 (13번 라인, 자세한 내용은 알고리즘 1 참조). 재클러스터가 필요한 경우 OnlineTune은 \(\{c_{i}\}_{i}^{t}\)을 기반으로 관측치를 군집화하고 각 군집에 대한 예측 모델을 적합시키고 섹션 5.3에 설명된 대로 SVM 모델을 재학습한다.

```
출력: 변화하는 환경에 적응적으로 구성 추천
1Fauturize the environment factor, get context \(c_{0}\)
2Query default configuration \(\theta_{0}\) and get its performance \(y_{0}\)
3 \(<c_{0},\theta_{0},y_{0}>\)으로 데이터 리포지토리 \(H_{0}\)을 초기화합니다.
4for\(i\gets 1\) to \(K\)do
5Fauturize and get context \(c_{i}\)
6 모델 \(m_{i-1}^{n}\), 여기서 \(n=SVM(c_{i})\)을 선택합니다.
7\(\Theta_{i}^{n}=\text{Subspace\_Adaptation}(\Theta_{i-1}^{n},H_{i-1})\).
8 안전한 후보 \(S_{i}^{n}\in\Theta_{i}^{n}\)을 생성합니다.
9 \(S_{i}^{n}\) 내에서 구성 \(\theta_{i}\)을 선택합니다.
10\(\theta_{i}\)을 적용하여 성능을 평가한다 \(y_{i}\).
11\(H_{i}=\text{Append}(H_{i-1},<\theta_{i},c_{i},y_{i}>)\).
12Fit 예측 모델 \(m_{i}^{n}\) on \(H_{i}\)
13Offline_Clustering(\(H_{i}\)).
```

**알고리즘 3** OnlineTune 최상위 알고리즘

## 부록 C. A3. Subspace Adaptation에 대한 세부 정보

### 하위 공간 제한에 대 한 더 합리적입니다.

구성공간 \(\theta\)과 문맥적 GP 모델이 주어졌을 때, 우리는 \(\theta\)을 이산화하여 후보 집합을 구하고, GP 모델의 추정을 기반으로 각 후보의 안전성을 평가할 수 있다. 그러나 공간 전체에 대한 직접적인 조작은 차원의 저주에 시달린다. 먼저, GP를 활용하여 안전성을 일반화하기 위해서는 후보자들이 서로 가까워질 필요가 있다. 두 개 이상의 노브를 튜닝할 때, 전체 구성 공간에 대해 미세한 이산화를 수행하는 것이 계산적으로 저렴하다(Srivastava et al., 2017). 또한, 데이터베이스 성능 함수는 종종 복잡하여, GP 모델의 추정이 고차원 구성(10개 이상의 파라미터)에 문제가 된다(Srivastava et al., 2017). 이러한 문제를 해결하기 위해 우리는 확률적 최적화(stochastic optimization, 72)에서 신뢰 영역 메소드의 클래스에서 영감을 얻는다. 이러한 방법들은 가장 좋은 관측치를 중심으로 하는 구 또는 폴리토프인 트러스트 영역 내부에 선형 및 이차 예측 모델을 사용한다. 직관적으로 선형 및 이차 모델은 전 세계적으로 모델링하기에 부적절할 가능성이 높지만 충분히 작은 신뢰 영역에서 정확할 수 있다[16]. 그러나 선형 모델은 잡음이 많은 관측을 처리하는데 어려움을 겪으며 정확한 모델링 동작을 제공하기 위해 작은 신뢰 영역이 필요하다. 예측 모델은 문맥적 GP를 사용하여 함수 \(f(\theta,c)\)를 기술하고 트러스트 영역에서 OnlineTune의 최적화 공간(즉, 구성 부분 공간)을 제한한다. 최적화는 신뢰 영역 내에서 효율적으로 해결될 수 있고, GP 모델의 추정은 신뢰 영역에서 신뢰될 수 있다[16].

### 라인 영역의 방향 Oracles

온라인 튜닝은 임의의 방향과 중요한 방향을 포함하여 방향을 생성하는 두 가지 전략을 구현한다.

**무작위 방향.** 전략은 방향을 균일하게 선택 하 여 탐색을 증가 시키는 것입니다 (무작위 방향).

**중요 방향.** OnlineTune은 기존 구성 튜닝 접근법에서 사용하는 튜닝 전에 중요 노브 사전 선택 절차에서 영감을 받아 중요 구성 노브(중요 방향)와 정렬된 방향을 선택합니다. [6, 18, 32]. 여러 중요한 노브에서 최적화 공간을 제한하는 것은 튜닝 반복을 크게 감소시키고 유사한 개선을 달성할 수 있다는 것이 경험적으로 보여진다[32]. 노브의 중요성은 특징 중요성을 평가하기 위한 라인 타임 접근법인 Fanova [27]에 의해 정량화된다. 그러나 중요 한 노브를 감지 하려면 지정 된 워크 로드에 대 한 수천 개의 평가 샘플이 필요 합니다. 그리고 구성 공간을 잘못 고정하는 것(예를 들어, 중요한 노브를 필터링하는 것)은 최적화를 심각하게 방해할 것이다. 온라인 튜닝의 부분공간 적응은 반복을 통해 부분공간을 조정함으로써 이 문제를 해결한다.

이전 하이퍼큐브 영역에서의 성능 향상이 임계치(탐색)보다 낮으면 랜덤 방향이 선택된다. 그렇지 않으면 상위 5개의 중요한 노브(탐색)에서 샘플링하여 중요한 방향을 선택합니다. 노브의 중요성은 관측치가 증가함에 따라 업데이트됩니다.
