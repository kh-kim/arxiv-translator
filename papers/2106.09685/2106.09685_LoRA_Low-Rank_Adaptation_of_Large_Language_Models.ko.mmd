# LoRA: Low-Rank Adaptation of Large Language Models

 Edward Hu\({}^{*}\)  Yelong Shen\({}^{*}\)  Phillip Wallis  Zeyuan Allen-Zhu

원지리산왕루왕위주천

Microsoft Corporation

{edwardhu, yeshe, phwallis, zeyuana}

yuanzhil, swang, luw, wzchen}@microsoft.com

yuanzhil@andrew.cmu.edu

(Version 2)

동일한 기여.V1과 비교하여 이 초안에는 더 나은 기준선, GLUE에 대한 실험 및 어댑터 대기 시간에 대한 더 많은 것이 포함된다.

###### Abstract

자연어 처리의 중요한 패러다임은 일반 도메인 데이터에 대한 대규모 사전 훈련과 특정 작업 또는 도메인에 대한 적응으로 구성된다. 우리가 더 큰 모델들을 미리 훈련시킬 때, 모든 모델 파라미터들을 재훈련하는 완전 미세 조정이 덜 실현가능해진다. GPT-3 175B를 예로 사용 합니다. 각각 175B 매개 변수를 사용 하 여 미세 조정 된 모델의 독립 인스턴스를 배포 하는 것은 엄청나게 비쌉니다. 미리 훈련 된 모델 가중치를 동결 하 고 훈련 가능한 순위 분해 행렬을 Transformer 아키텍처의 각 계층에 주입 하 여 다운스트림 작업에 대 한 훈련 가능한 매개 변수의 수를 크게 줄이는 **Lo**w-**R** 순위 **A** 적응 또는 LoRA를 제안 합니다. 아담과 미세 조정된 GPT-3 175B에 비해 LoRA는 훈련 가능한 파라미터 수를 10,000배, GPU 메모리 요구량을 3배 줄일 수 있다. LoRA는 RoBERTa, DeBERTa, GPT-2 및 GPT-3에서 훈련 가능한 매개변수가 적고 훈련 처리량이 높으며 어댑터와 달리 _추가 추론 대기 시간이 없음_에도 불구하고 모델 품질에서 온-파 또는 미세 조정보다 더 나은 성능을 수행한다. 또한 LoRA의 효능을 밝히는 언어 모델 적응의 순위 결핍에 대한 경험적 조사를 제공한다. LoRA와 PyTorch 모델의 통합을 용이하게 하는 패키지를 릴리스하고 [https://github.com/microsoft/LoRA](https://github.com/microsoft/LoRA)에서 RoBERTa, DeBERTa 및 GPT-2에 대한 구현 및 모델 체크포인트를 제공합니다.

## 1 Introduction

자연어 처리의 많은 응용 프로그램은 _하나의_ 대규모 사전 훈련 된 언어 모델을 _다중_ 다운스트림 응용 프로그램에 적용 하는 데 의존 합니다. 이러한 적응은 일반적으로 미리 훈련된 모델의 모든 매개 변수를 업데이트하는 _fine-tuning_을 통해 수행됩니다. 미세 조정의 주요 단점은 새로운 모델이 원래 모델만큼 많은 매개변수를 포함한다는 것이다. 수개월마다 더 큰 모델이 훈련됨에 따라, 이는 GPT-2(래드포드 등, b) 또는 RoBERTa 대형(Liu 등, 2019)에 대한 단순한 "불편함"에서 1,750억 훈련 가능한 파라미터를 갖는 GPT-3(브라운 등, 2020)에 대한 중요한 배치 챌린지로 변경된다.1

각주 1: GPT-3 175B는 적은 샷 학습으로 자명하지 않은 성능을 달성하는 반면, 미세 조정은 부록 A에서 볼 수 있듯이 성능을 크게 향상시킨다.

많은 사람들이 일부 매개변수만 적용하거나 새로운 작업에 대한 외부 모듈을 학습하여 이를 완화하려고 했다. 이렇게 하면 각 작업에 대해 미리 훈련 된 모델 외에도 적은 수의 작업별 매개 변수만 저장 하 고 로드 하면 되므로 배포 시 운영 효율성이 크게 향상 됩니다. 그러나, 기존의 기술들은

도 1: 우리의 재파라메트리화. 우리는 \(A\)와 \(B\)만 훈련한다.

종종 모델 깊이를 확장하거나 모델의 사용 가능한 시퀀스 길이를 줄임으로써 추론 레이턴시(Houlsby 등, 2019; Rebuffi 등, 2017)를 도입한다(Li and Liang, 2021; Lester 등, 2021; Hambardzumyan 등, 2020; Liu 등, 2021)(섹션 3). 더 중요한 것은 이러한 방법이 종종 미세 조정 기준선과 일치하지 않아 효율성과 모델 품질 간의 균형을 이루지 못한다는 것이다.

우리는 Li et al. (2018); Aghajanyan et al. (2020)에서 영감을 얻었으며, 이는 학습된 과대매개 모형이 실제로 낮은 내재적 차원에 존재한다는 것을 보여준다. 모델 적응 중 가중치의 변경도 "내재 순위"가 낮아서 제안된 **Low-Rank A** 적응(LoRA) 접근 방식으로 이어졌다고 가정합니다. LoRA는 그림 1과 같이 미리 훈련된 가중치를 동결 상태로 유지하면서 적응 동안 조밀한 레이어의 변화에 대한 순위 분해 행렬을 대신 최적화하여 신경망에서 일부 조밀한 레이어를 간접적으로 훈련시킬 수 있다. GPT-3 175B를 예로 들어, 전체 순위(즉, \(d\))가 12,288만큼 높을 때에도 그림 1의 매우 낮은 순위(즉, \(r\)가 하나 또는 두 개일 수 있음)가 충분하다는 것을 보여 LoRA를 저장 및 컴퓨팅 효율 모두 만든다.

LoRA는 몇 가지 주요 이점을 가지고 있다.

* 미리 훈련 된 모델을 공유 하 고 사용 하 여 여러 작업에 대 한 많은 작은 LoRA 모듈을 빌드할 수 있습니다. 그림 1의 행렬 \(A\)과 \(B\)을 대체하여 공유 모델을 동결하고 작업을 효율적으로 전환할 수 있어 스토리지 요구량과 작업 전환 오버헤드를 크게 줄일 수 있다.
* LoRA는 대부분의 매개 변수에 대해 기울기를 계산 하거나 최적화기 상태를 유지할 필요가 없기 때문에 적응 최적화기를 사용할 때 훈련을 더 효율적으로 만들고 하드웨어 진입 장벽을 최대 3배 낮춥니다. 대신 주입된 훨씬 더 작은 저순위 행렬만 최적화한다.
* 간단한 선형 설계를 통해 배포 시 훈련 가능한 행렬을 동결된 가중치와 병합할 수 있습니다. 구성을 통해 완전히 미세 조정된 모델과 비교하여 추론 대기 시간을 도입하지 않습니다.
* LoRA는 많은 이전 방법들과 직교하며, 프리픽스-튜닝과 같은 많은 방법들과 조합될 수 있다. 우리는 부록 E에 예를 제공한다.

용어와 컨벤션은 트랜스포머 아키텍처를 자주 참조하고 기존 용어를 차원에 사용한다. 우리는 변환기의 입출력 크기 \(d_{model}\)라고 부른다. 자기 주의 모듈에서 질의/키/값/출력 투영 행렬을 참조하기 위해 \(W_{q}\), \(W_{k}\), \(W_{v}\), \(W_{o}\)을 사용한다. \ (W\) 또는 \(W_{0}\)은 적응 동안 미리 훈련된 가중치 행렬과 \(\Delta W\)의 누적 기울기 업데이트를 의미한다. 우리는 LoRA 모듈의 순위를 나타내기 위해 \(r\)을 사용한다. 모델 최적화를 위해 Vaswani et al., 2017; Brown et al., 2020)에서 제시한 규칙을 따르고 Adam (Loshchilov and Hutter, 2019; Kingma and Ba, 2017)을 사용하며 Transformer MLP feedforward 차원 \(d_{ffn}=4\times d_{model}\)을 사용한다.

## 2 Problem Statement

우리의 제안은 훈련 목표에 불가지론적이지만 동기 부여 사용 사례로 언어 모델링에 중점을 둔다. 아래는 언어 모델링 문제, 특히 태스크별 프롬프트가 주어졌을 때 조건부 확률의 최대화에 대한 간략한 설명이다.

미리 훈련된 자기회귀 언어 모델 \(P_{\Phi}(y|x)\)을 \(\Phi\)으로 매개변수화했다고 가정하자. 예를 들어, \(P_{\Phi}(y|x)\)는 Transformer 아키텍처(Vaswani et al., 2017)를 기반으로 하는 GPT(Radford et al., b; Brown et al., 2020)와 같은 일반적인 멀티 태스크 학습자가 될 수 있다. 이 사전 훈련 된 모델을 요약, 기계 읽기 이해 (MRC) 및 자연 언어와 같은 다운스트림 조건부 텍스트 생성 작업에 적용 하는 것이 좋습니다 (NL2SQL). 각 다운스트림 태스크는 문맥-타겟 쌍의 훈련 데이터셋으로 표현된다. \(\mathcal{Z}=\{(x_{i},y_{i})\}_{i=1,..,N}\) 여기서 \(x_{i}\)과 \(y_{i}\)은 모두 토큰의 시퀀스이다. 예를 들어, NL2SQL에서 \(x_{i}\)은 자연어 질의이고 \(y_{i}\)의 해당 SQL 명령이며, 요약을 위해 \(x_{i}\)은 문서의 내용이고 \(y_{i}\)의 요약이다.

완전 미세 조정 동안 모델은 사전 훈련된 가중치 \(\Phi_{0}\)로 초기화되고 조건 언어 모델링 목적을 최대화하기 위해 기울기를 반복적으로 따라 \(\Phi_{0}+\Delta\Phi\)으로 업데이트된다:

\[\max_{\Phi}\sum_{(x,y)\in\mathcal{Z}}\sum_{t=1}^{|y|}\text{log}\left(P_{\Phi}(y_ {t}|x,y_{<t})\right) \tag{1}\]

전체 미세 조정의 주요 단점 중 하나는 _각_ 다운스트림 작업의 경우 차원 \(|\Delta\Phi|\)이 \(|\Phi_{0}|\)과 동일한 매개 변수 \(\Delta\Phi\)의 _different_ 집합을 학습한다는 것입니다. 따라서 사전 훈련된 모델이 큰 경우(예: \(|\Phi_{0}|\approx 175\) Billion) 미세 조정된 모델의 많은 독립적인 인스턴스를 저장하고 배포하는 것은 가능하더라도 어려울 수 있다.

본 논문에서는 태스크별 파라미터 증분 \(\Delta\Phi=\Delta\Phi(\Theta)\)을 더 작은 크기의 파라미터 집합 \(\Theta\)과 \(|\Theta|\ll|\Phi_{0}|\)으로 부호화하는 보다 효율적인 방법을 제안한다. 따라서 \(\Delta\Phi\)를 찾는 작업은 \(\Theta\):

\[\max_{\theta}\sum_{(x,y)\in\mathcal{Z}}\sum_{t=1}^{|y|}\text{log}\left(p_{ \Phi_{0}+\Delta\Phi(\theta)}(y_{t}|x,y_{<t})\right) \tag{2}\]

다음 절에서는 계산과 메모리 효율이 모두 좋은 \(\Delta\Phi\)을 인코딩하기 위해 낮은 순위의 표현을 사용하는 것을 제안한다. 미리 훈련된 모델이 GPT-3 175B일 때 훈련 가능한 매개변수 \(|\theta|\)의 수는 \(|\Phi_{0}|\)의 \(0.01\%\)만큼 작을 수 있다.

## 3 기존 솔루션은 충분 하지 않나요?

우리가 해결하기 위해 시작한 문제는 결코 새로운 것이 아니다. 전이학습이 시작된 이후, 모델 적응을 보다 매개변수와 계산 효율적으로 만들기 위해 수십 개의 작업이 시도되었다. 잘 알려진 일부 작업에 대한 조사는 섹션 6을 참조하십시오. 언어 모델링을 예로서 사용하면, 효율적인 적응과 관련하여 두 가지 두드러진 전략이 있다 : 어댑터 층 추가(Houlsby et al., 2019; Rebuffi et al., 2017; Pfeiffer et al., 2021; Ruckle et al., 2020) 또는 입력 층 활성화의 일부 형태 최적화(Li and Liang, 2021; Lester et al., 2021; Hambardzumyan et al., 2020; Liu et al., 2021). 그러나 두 전략 모두 특히 대규모 및 지연에 민감한 생산 시나리오에서 한계가 있다.

어댑터 레이어 추론 대기 시간을 도입 어댑터에는 여러 가지 변형이 있습니다. 본 논문에서는 Transformer 블록당 2개의 어댑터 레이어를 갖는 Houlsby et al.(2019)과 블록당 단 1개의 어댑터 레이어를 갖는 Lin et al.(2020)의 최근 디자인인 LayerNorm(Ba et al., 2016)에 초점을 맞추었다. 계층들을 프루닝하거나 멀티-태스크 설정들을 이용함으로써 전체 대기 시간을 감소시킬 수 있지만(Ruckle 등, 2020; Pfeiffer 등, 2021), 어댑터 계층들에서 여분의 컴퓨팅을 우회하는 직접적인 방법은 없다. 이는 어댑터 레이어가 작은 병목 차원을 가짐으로써 적은 매개변수(때로는 원래 모델의 \(<\)1%)를 가지도록 설계되어 추가할 수 있는 FLOP를 제한하기 때문에 문제가 되지 않는 것으로 판단된다. 그러나, 큰 신경망은 레이턴시를 낮게 유지하기 위해 하드웨어 병렬성에 의존하며, 어댑터 계층은 순차적으로 처리되어야 한다. 이것은 배치 크기가 일반적으로 하나만큼 작은 온라인 추론 설정에서 차이를 만든다. 단일 GPU 상의 GPT-2(Radford et al., b) 매체에서 추론을 실행하는 것과 같은 모델 병렬성이 없는 일반적인 시나리오에서, 우리는 매우 작은 병목 차원에서도, 어댑터를 사용할 때 레이턴시가 눈에 띄게 증가하는 것을 볼 수 있다(표 1).

이 문제는 Shoeybi et al. (2020); Lepikhin et al. (2020)에서 수행한 것처럼 모델을 분할해야 할 때 더 악화되는데, 왜냐하면 어댑터 파라미터를 여러 번 중복 저장하지 않는 한 추가 깊이는 AllReduce 및 Broadcast와 같은 동기 GPU 연산을 더 필요로 하기 때문이다.

프롬프트를 직접 최적화하는 것은 프리픽스 튜닝(Li 및 Liang, 2021)에 의해 예시된 바와 같이 HardThe other 방향과는 다른 도전에 직면한다. 우리는 프리픽스 튜닝이 최적화되기 어렵고 훈련 가능한 매개변수에서 그 성능이 단조롭지 않게 변한다는 것을 관찰하여 원래 논문에서 유사한 관찰을 확인했다. 보다 근본적으로, 적응을 위해 시퀀스 길이의 일부를 예약하는 것은 다운스트림 작업을 처리하는 데 사용할 수 있는 시퀀스 길이를 필연적으로 감소시키며, 이는 프롬프트 튜닝이 다른 방법에 비해 덜 수행적이라고 의심한다. 우리는 과제 수행에 대한 연구를 섹션 5로 연기한다.

## 4 Our Method

LoRA의 간단한 설계와 그 실용적 이점을 설명한다. 여기에 설명된 원칙은 딥 러닝 모델의 모든 조밀한 계층에 적용되지만, 동기 부여 사용 사례로 실험에서 트랜스포머 언어 모델의 특정 가중치에만 초점을 맞춘다.

### Low-Rank-Parametrized Update Matrix

신경망은 행렬 곱셈을 수행하는 많은 조밀한 계층을 포함한다. 이들 계층에서의 가중치 행렬은 전형적으로 풀-랭크를 갖는다. 특정 태스크에 적응하는 경우, Aghajanyan 등(2020)은 사전 훈련된 언어 모델들이 낮은 "instrisic dimension"을 가지며, 더 작은 서브공간으로의 랜덤 프로젝션에도 불구하고 여전히 효율적으로 학습할 수 있음을 보여준다. 이에 영감을 받아 가중치에 대한 업데이트도 적응 동안 낮은 "내재 순위"를 갖는다고 가정한다. 미리 훈련된 가중치 행렬 \(W_{0}\in\mathbb{R}^{d\times k}\)의 경우 낮은 순위 분해 \(W_{0}+\Delta W=W_{0}+BA\), 여기서 \(B\in\mathbb{R}^{d\times r}\), \(A\in\mathbb{R}^{r\times k}\), 그리고 순위 \(r\ll\min(d,k)\)으로 표현하여 갱신을 제한한다. 훈련 중에 \(W_{0}\)은 동결되어 기울기 업데이트를 받지 않는 반면 \(A\) 및 \(B\)에는 훈련 가능한 매개변수가 포함되어 있다. \(W_{0}\)과 \(\Delta W=BA\)은 모두 동일한 입력으로 곱해지고, 각각의 출력 벡터는 좌표로 합산된다. \(h=W_{0}x\)의 경우 수정된 순방향 패스 수율은 다음과 같다.

\[h=W_{0}x+\Delta Wx=W_{0}x+BAx \tag{3}\]

우리는 그림 1에서 우리의 재파라메트리화를 설명한다. 우리는 \(A\)에 대해 무작위 가우시안 초기화를 사용하고 \(B\)에 대해 0을 사용하므로 \(\Delta W=BA\)은 훈련 초기에 0이다. 그런 다음 \(\Delta Wx\)을 \(\frac{\alpha}{r}\)으로 축척하고, 여기서 \(\alpha\)는 \(r\)에서 상수이다. 아담으로 최적화할 때 튜닝 \(\alpha\)은 초기화를 적절하게 스케일링하면 학습률을 튜닝하는 것과 거의 같다. 결과적으로 우리는 단순히 \(\alpha\)를 첫 번째 \(r\)으로 설정하고 튜닝을 시도하지 않는다. 이 크기 조정은 \(r\)(Yang and Hu, 2021)을 변경할 때 하이퍼 매개 변수를 다시 조정할 필요성을 줄이는 데 도움이 됩니다.

완전 미세 조정의 일반화. 보다 일반적인 형태의 미세 조정은 미리 훈련된 파라미터들의 서브세트의 훈련을 허용한다. LoRA는 한 단계 더 나아가 적응 동안 전체 순위를 가지기 위해 가중치 행렬에 대한 누적 구배 업데이트를 요구하지 않는다. 이는 LoRA를 모든 가중치 행렬에 적용하고 모든 바이어스 2를 훈련할 때 LoRA 순위 \(r\)를 미리 훈련된 가중치 행렬의 순위로 설정하여 전체 미세 조정의 표현력을 대략적으로 회복한다는 것을 의미한다. 즉, 훈련 가능한 매개변수 3의 수를 증가시키면 훈련 LoRA는 대략 원래 모델을 훈련하는 것으로 수렴하는 반면 어댑터 기반 방법은 MLP로, 접두사 기반 방법은 긴 입력 시퀀스를 취할 수 없는 모델로 수렴한다.

각주 2: 가중치와 비교하여 무시할 수 있는 수의 파라미터를 나타낸다.

각주 3: 어려운 일에 적응할 때 불가피하다.

추가 추론 지연은 없다. 프로덕션에 배포될 때, 우리는 \(W=W_{0}+BA\)을 명시적으로 계산 및 저장하고 평소와 같이 추론을 수행할 수 있다. \(W_{0}\)과 \(BA\)은 모두 \(\mathbb{R}^{d\times k}\)에 있다. 다른 다운스트림 태스크로 전환해야 할 때, \(BA\)를 뺀 다음 다른 \(B^{\prime}A^{\prime}\)을 추가함으로써 \(W_{0}\)을 복구할 수 있으며, 이는 메모리 오버헤드가 거의 없는 빠른 연산이다. 비판적으로

\begin{table}
\begin{tabular}{c|c c c} \hline \hline Batch Size & 32 & 16 & 1 \\ Sequence Length & 512 & 256 & 128 \\ \(|\Theta|\) & 0.5M & 11M & 11M \\ \hline Fine-Tune/LoRA & 1449.4\(\pm\)0.8 & 338.0\(\pm\)0.6 & 19.8\(\pm\)2.7 \\ \hline Adapter\({}^{\text{L}}\) & 1482.0\(\pm\)1.0 (+2.2\%) & 354.8\(\pm\)0.5 (+5.0\%) & 23.9\(\pm\)2.1 (+20.7\%) \\ Adapter\({}^{\text{H}}\) & 1492.2\(\pm\)1.0 (+3.0\%) & 366.3\(\pm\)0.5 (+8.4\%) & 25.8\(\pm\)2.2 (+30.3\%) \\ \hline \hline \end{tabular}
\end{table}
표 1: 밀리초 단위로 측정된 GPT-2 매질에서의 단일 순방향 통과의 지연 지연, 평균 100회 이상의 시험. NVIDIA Quadro RTX8000을 사용합니다. "\(|\theta|\)"는 어댑터 계층에서 훈련 가능한 매개 변수의 수를 나타냅니다. Adapter\({}^{\text{L}}\)과 Adapter\({}^{\text{H}}\)은 어댑터 튜닝의 두 가지 변형으로 섹션 5.1에서 설명한다. 어댑터 계층에 의해 도입된 추론 지연은 온라인, 짧은 시퀀스 길이 시나리오에서 중요할 수 있다. 부록 B의 전체 연구를 참조하십시오.

구축에 의해 미세 조정된 모델에 비해 추론 중에 추가 지연 시간을 도입하지 않는다는 것을 보증한다.

### LoRA를 Transformer에 적용

원칙적으로, 우리는 훈련 가능한 파라미터의 수를 줄이기 위해 신경망의 가중치 행렬의 임의의 부분집합에 LoRA를 적용할 수 있다. 트랜스포머 구조에서는 자기 주의 모듈(\(W_{q},W_{k},W_{v},W_{o}\))에 4개의 가중치 행렬이 있고 MLP 모듈에는 2개의 가중치 행렬이 있다. 출력 차원은 일반적으로 어텐션 헤드로 슬라이스되지만 \(W_{q}\)(또는 \(W_{k},W_{v}\))을 차원 \(d_{model}\times d_{model}\)의 단일 행렬로 취급한다. 우리는 단순성과 매개변수 효율성을 위해 다운스트림 작업에 대한 **주의 가중치만 적응** 으로 연구를 제한하고 MLP 모듈(따라서 다운스트림 작업에서 훈련되지 않음)을 동결한다. 섹션 7.1의 트랜스포머에서 다양한 유형의 주의 가중치 매트릭스를 적응하는 데 미치는 영향을 추가로 연구한다. MLP 계층, LayerNorm 계층 및 편향에 대한 경험적 조사를 향후 작업에 맡긴다.

실용적인 이점 및 한계.가장 중요한 이점은 메모리 및 스토리지 사용량의 감소에서 비롯됩니다. 아담으로 훈련된 대형 변압기의 경우, 동결된 파라미터에 대한 최적화 상태를 저장할 필요가 없기 때문에 VRAM 사용량을 최대 \(r\ll d_{model}\)까지 줄인다. GPT-3 175B에서는 훈련 중 VRAM 소비를 1.2TB에서 350GB로 줄인다. \(r=4\)과 질의 및 값 프로젝션 행렬만을 적용하여 검사점 크기를 약 10,000\(\times\)(350GB에서 35MB)4로 줄였다. 이를 통해 GPU를 훨씬 적게 사용하여 학습하고 I/O 병목 현상을 피할 수 있다. 또 다른 이점은 모든 매개 변수와 달리 LoRA 가중치만 교체 하 여 훨씬 더 저렴한 비용으로 배포 하는 동안 작업 간에 전환할 수 있다는 것입니다. 이를 통해 미리 훈련된 가중치를 VRAM에 저장하는 기계에서 즉석에서 교체할 수 있는 많은 맞춤형 모델을 만들 수 있습니다. 또한 대부분의 매개변수에 대한 기울기를 계산할 필요가 없기 때문에 전체 미세 조정 5에 비해 GPT-3 175B에서 훈련하는 동안 25% 속도 향상을 관찰했다.

각주 4: 배포 중에 여전히 350GB 모델이 필요합니다. 그러나 100개의 적응된 모델을 저장하려면 100 * 350GB \(\approx\) 35TB와 반대로 350GB + 35MB * 100 \(\approx\) 354GB만 필요합니다.

각주 5: GPT-3 175B의 경우, 완전 미세 조정을 위한 트레이닝 처리량은 V100 GPU당 32.5 토큰/s이고, 모델 병렬화를 위한 동일한 수의 가중치 샤드들과 함께, 처리량은 LoRA의 경우 V100 GPU당 43.1 토큰/s이다.

LoRA 역시 그 한계가 있다. 예를 들어 추가 추론 대기 시간을 제거하기 위해 \(A\) 및 \(B\)을 \(W\)으로 흡수하기로 선택한 경우 단일 순방향 통과에서 \(A\) 및 \(B\)이 다른 작업에 입력을 일괄 처리하는 것은 간단하지 않습니다. 가중치를 병합하지 않고 대기 시간이 중요하지 않은 시나리오에 대해 일괄 처리에서 샘플에 사용할 LoRA 모듈을 동적으로 선택할 수 있습니다.

## 5 경험적 실험

LoRA on RoBERTa (Liu et al., 2019), DeBERTa (He et al., 2021), GPT-2 (Radford et al., b)의 다운스트림 태스크 성능을 GPT-3 175B (Brown et al., 2020)까지 스케일링하기 전에 평가한다. 우리의 실험은 자연어 이해(NLU)에서 생성(NLG)에 이르기까지 광범위한 작업을 다룬다. 구체적으로, RoBERTa 및 DeBERTa에 대한 GLUE(Wang et al., 2019) 벤치마크 상에서 평가한다. 직접 비교를 위해 GPT-2의 Li 및 Liang (2021) 설정을 따르고 GPT-3에 대 한 대규모 실험을 위해 WikiSQL (Zhong et al., 2017) (NL to SQL 쿼리) 및 SAMSum (Gliwa et al., 2019) (대화 요약)을 추가 합니다. 사용 하는 데이터 세트에 대 한 자세한 내용은 부록 C를 참조 하세요. 우리는 모든 실험에 NVIDIA 테슬라 V100을 사용한다.

### Baselines

다른 기준선과 광범위하게 비교하기 위해 이전 작업에서 사용된 설정을 복제하고 가능한 한 보고된 수를 재사용한다. 그러나 이것은 일부 기준선이 특정 실험에서만 나타날 수 있음을 의미한다.

**Fine-Tuning(FT)** 은 적응을 위한 일반적인 접근 방식입니다. 미세 조정 동안, 모델은 미리 훈련된 가중치들 및 바이어스들로 초기화되고, 모든 모델 파라미터들은 구배 업데이트들을 겪는다. 간단한 변형은 다른 것들을 동결시키면서 일부 층들만을 업데이트하는 것이다. 우리는 GPT-2에 대한 이전 작업(Li 및 Liang, 2021)에서 보고된 이러한 기준선 중 하나를 포함하며, 이는 마지막 두 층(**FT\({}^{\textbf{Top2}}\)**)에만 적용한다.

**바이어스 전용 또는 BitFit** 은 다른 모든 항목을 동결하는 동안 바이어스 벡터만 학습하는 기준선입니다. 동시에, 이 베이스라인은 BitFit(Zaken et al., 2021)에 의해서도 연구되었다.

**Prefix-embedding 튜닝(PreEmbed)** 입력 토큰 중 특수 토큰을 삽입합니다. 이러한 특수 토큰은 훈련 가능한 단어 임베딩을 가지며 일반적으로 모델의 어휘에 없다. 이러한 토큰을 어디에 배치할 것인가는 성과에 영향을 미칠 수 있다. 우리는 이러한 토큰을 프롬프트에 미리 보내는 "접두사"와 프롬프트에 추가하는 "접두사"에 초점을 맞추는데, 둘 다 Li와 Liang(2021)에서 논의된다. 우리는 \(l_{p}\) (resp. \ (l_{i}\))는 접두사 수(resp. infix)를 나타낸다. tokens. 훈련 가능한 파라미터의 수는 \(|\Theta|=d_{model}\times(l_{p}+l_{i})\)이다.

**접두사 계층 튜닝(PreLayer)** 은 접두사 임베딩 튜닝의 확장입니다. 일부 특수 토큰에 대한 단어 임베딩(또는 등가적으로 임베딩 계층 이후의 활성화)만 학습하는 대신, 우리는 모든 트랜스포머 계층 이후의 활성화를 학습한다. 이전 계층에서 계산된 활성화는 단순히 훈련 가능한 계층으로 대체된다. 학습 가능한 파라미터의 수는 \(|\Theta|=L\times d_{model}\times(l_{p}+l_{i})\), 여기서 \(L\)은 변압기 층의 수이다.

Houlsby 등(2019)에서 제안한 **어댑터 튜닝** 은 자체 주의 모듈(및 MLP 모듈)과 후속 잔차 연결 사이에 어댑터 계층을 삽입합니다. 비선형성을 사이에 둔 어댑터 층에는 바이어스를 갖는 두 개의 완전히 연결된 층이 있다. 이를 원설계 \(\textbf{Adapter}^{\textbf{H}}\)이라 한다. 최근 Lin et al.(2020)은 MLP 모듈 이후와 LayerNorm 이후에만 어댑터 레이어를 적용하여 보다 효율적인 설계를 제안하였다. 이를 \(\textbf{Adapter}^{\textbf{L}}\)이라 한다. 이것은 우리가 \(\textbf{Adapter}^{\textbf{P}}\)이라고 부르는 Pfeiffer et al.(2021)에서 제안한 다른 설계와 매우 유사하다. 또한, 더 큰 효율을 위해 일부 어댑터 레이어를 드롭하는 또 다른 베이스라인 콜 AdapterDrop(Ruckle et al., 2020)을 포함한다(\(\textbf{Adapter}^{\textbf{P}}\)) 우리는 우리가 비교하는 기준선의 수를 최대화하기 위해 가능한 한 이전 작업의 수를 인용하며, 첫 번째 열에 별표(*)가 있는 행에 있다. 모든 경우에, 우리는 \(|\Theta|=\hat{L}_{Adpt}\times(2\times d_{model}\times r+r+d_{model})+2\times \hat{L}_{LN}\times d_{model}\)을 갖는다. 여기서 \(\hat{L}_{Adpt}\)은 어댑터 층의 수이고 \(\hat{L}_{LN}\)은 훈련 가능한 LayerNorm의 수이다(예: Adapter\({}^{\textbf{L}}\)).

**LoRA** 는 기존 가중치 행렬에 병렬로 훈련 가능한 순위 분해 행렬 쌍을 추가합니다. 섹션 4.2에서 언급한 바와 같이 단순화를 위해 대부분의 실험에서 \(W_{q}\) 및 \(W_{v}\)에만 LoRA를 적용한다. 훈련 가능한 매개 변수의 수는 순위 \(r\)와 원래 가중치의 모양에 의해 결정된다. \(|\Theta|=2\times\hat{L}_{LoRA}\times d_{model}\times r\), 여기서 \(\hat{L}_{LoRA}\)은 우리가 LoRA를 적용하는 가중치 행렬의 수이다.

\begin{table}
\begin{tabular}{l|r|r r r r r r r r} \hline \hline Model \& Method & \# Trainable & & & & & & & & \\  & Parameters & MNLI & SST-2 & MRPC & CoLA & QNLI & QQP & RTE & STS-B & Avg. \\ \hline RoB\({}_{\text{Base}}\) (FT)* & 125.0M & **87.6** & 94.8 & 90.2 & **63.6** & 92.8 & **91.9** & 78.7 & 91.2 & 86.4 \\ RoB\({}_{\text{Base}}\) (BitFit)* & 0.1M & 84.7 & 93.7 & **92.7** & 62.0 & 91.8 & 84.0 & 81.5 & 90.8 & 85.2 \\ RoB\({}_{\text{Base}}\) (Adpt\({}^{\text{D}}\))* & 0.3M & 87.1\({}_{\pm 0.9}\) & 94.2\({}_{\pm 1.1}\) & 88.5\({}_{\pm 1.1}\) & 60.8\({}_{\pm 9}\) & 93.1\({}_{\pm 1.1}\) & 90.2\({}_{\pm 0.9}\) & 71.5\({}_{\pm 2.7}\) & 89.7\({}_{\pm 3}\) & 84.4 \\ RoB\({}_{\text{Base}}\) (Adpt\({}^{\text{D}}\))* & 0.9M & 87.3\({}_{\pm 1.1}\) & 94.7\({}_{\pm 3}\) & 88.4\({}_{\pm 1.2}\) & 62.6\({}_{\pm 9}\) & 93.0\({}_{\pm 2}\) & 90.6\({}_{\pm 0.6}\) & 75.9\({}_{\pm 2.2}\) & 90.3\({}_{\pm 1.1}\) & 85.4 \\ RoB\({}_{\text{Base}}\) (LoRA) & 0.3M & 87.5\({}_{\pm 3}\) & **95.1\({}_{\pm 2}\)** & 89.7\({}_{\pm 7}\) & 63.4\({}_{\pm 12}\) & **93.3\({}_{\pm 3}\)** & 90.8\({}_{\pm 1}\) & **86.6\({}_{\pm 7}\)** & **91.5\({}_{\pm 2}\)** & **87.2** \\ \hline RoB\({}_{\text{large}}\) (FT)* & 355.0M & 90.2 & **96.4** & **90.9** & 68.0 & 94.7 & **92.2** & 86.6 & 92.4 & 88.9 \\ RoB\({}_{\text{large}}\) (LoRA) & 0.8M & **90.6\({}_{\pm 2}\)** & 96.2\({}_{\pm 5}\) & **90.9\({}_{\pm 1.2}\)** & **68.2\({}_{\pm 1.9}\)** & **94.9\({}_{\pm 3}\)** & 91.6\({}_{\pm 1}\) & **87.4\({}_{\pm 2.5}\)** & **92.6\({}_{\pm 2}\)** & **89.0** \\ \hline RoB\({}_{\text{large}}\) (Adpt\({}^{\text{D}}\))\(\dagger\) & 3.0M & 90.2\({}_{\pm 3}\) & 96.1\({}_{\pm 3}\) & 90.2\({}_{\pm 7}\) & **68.3\({}_{\pm 10}\)** & **94.8\({}_{\pm 2}\)** & **91.9\({}_{\pm 1}\)** & 83.8\({}_{\pm 2}\) & 92.1\({}_{\pm 7}\) & 88.4 \\ RoB\({}_{\text{large}}\) (Adpt\({}^{\text{D}}\))\(\dagger\) & 0.8M & **90.5\({}_{\pm 3}\)** & **96.6\({}_{\pm 2}\)** & 89.7\({}_{\pm 12}\) & 67.8\({}_{\pm 2}\) & **94.8\({}_{\pm 3}\)** & 93.1\({}_{\pm 2}\) & 80.1\({}_{\pm 2}\) & 91.9\({}_{\pm 4}\) & 87.9 \\ RoB\({}_{\text{large}}\) (Adpt\({}^{\text{D}}\))\(\dagger\) & 6.0M & 89.9\({}_{\pm 5}\) & 89.5\({}_{\pm 3}\) & 88.7\({}_{\pm 2}\) & 66.5\({}_{\pm 4}\) & 94.7\({}_{\pm 2}\) & 92.1\({}_{\pm 3}\) & 83.4\({}_{\pm 4}\) & 91.1\({}_{\pm 1}\) & 91.0\({}_{\pm 1}\) & 87.8 \\ RoB\({}_{\text{large}}\) (Adpt\({}^{\text{D}}\))\(\dagger\) & 0.8M & 90.3\({}_{\pm 3}\) & 96.3\({}_{\pm 3}\) & 87.7\({}_{\pm 1}\) & 66.3\({}_{\pm 2}\) & 94.7\({}_{\pm 2}\) & 91.5\({}_{\pm 3}\) & 72.9\({}_{\pm 2}\) & 91.5\({}_{\pm 5}\) & 86.4 \\ RoB\({}_{\text{large}}\)

### RoBERTa base/large

RoBERTa Liu 등(2019)은 BERT Devlin 등(2019)에서 원래 제안된 사전 트레이닝 레시피를 최적화하고, 더 많은 트레이닝 가능한 파라미터를 도입하지 않고 후자의 태스크 성능을 향상시켰다. RoBERTa는 최근 몇 년 동안 GLUE 벤치마크 Wang 등(2019)과 같은 NLP 리더보드에서 훨씬 더 큰 모델에 추월되었지만, 실무자들 사이에서 그 크기에 대해 경쟁적이고 인기 있는 사전 훈련 모델이다. HuggingFace Transformers 라이브러리 Wolf 등(2020)에서 미리 훈련된 RoBERTa base(125M)와 RoBERTa large(355M)를 사용하여 GLUE 벤치마크에서 태스크에 대한 다양한 효율적인 적응 접근법의 성능을 평가한다. 또한 Houlsby 등 (2019) 및 Pfeiffer 등 (2021)을 설정에 따라 복제합니다. 공정하게 비교하기 위해 어댑터와 비교할 때 LoRA를 평가하는 방법에 두 가지 중요한 변화를 준다. 첫째, 모든 작업에 동일한 배치 크기를 사용하고 어댑터 기준선과 일치하도록 128의 시퀀스 길이를 사용합니다. 둘째, 모델을 미세 조정 기준선과 같이 MNLI에 이미 적응된 모델이 아닌 MRPC, RTE 및 STS-B에 대해 사전 훈련된 모델로 초기화한다. Houlsby 등 (2019)에서 이 더 제한된 설정을 따르는 실행은 \(\dagger\)로 레이블이 지정됩니다. 결과는 표 2(상위 3개 섹션)에 제시되어 있다. 사용된 하이퍼파라미터에 대한 자세한 내용은 섹션 D.1을 참조하십시오.

### DeBERTa XXL

DeBERTa He 등(2021)은 훨씬 더 큰 규모로 훈련되고 GLUE Wang 등(2019) 및 SuperGLUE Wang 등(2020)과 같은 벤치마크에서 매우 경쟁적으로 수행되는 BERT의 보다 최근의 변형이다. 우리는 LoRA가 GLUE에서 완전히 미세 조정된 DeBERTa XXL(1.5B)의 성능과 여전히 일치할 수 있는지 평가한다. 그 결과는 표 2(하단 섹션)에 제시되어 있다. 사용된 하이퍼파라미터에 대한 자세한 내용은 섹션 D.2를 참조하십시오.

### GPT-2 medium/large

LoRA가 NLU에서 완전 미세 조정에 대한 경쟁력 있는 대안이 될 수 있음을 보여주었으므로, GPT-2 중형 및 대형 래드포드 등(b)과 같은 NLG 모델에서 LoRA가 여전히 우세하다면 답변하기를 바란다. 우리는 직접 비교를 위해 Li & Liang(2021)과 가능한 한 가까운 설정을 유지합니다. 공간 제약으로 인해 이 섹션에서는 E2E NLG 챌린지(표 3)에 대한 결과만 제시한다. WebNLG Gardent 등(2017) 및 DART Nan 등(2020)에 대한 결과는 섹션 F.1을 참조한다. 우리는 섹션 D.3에 사용된 하이퍼파라미터 목록을 포함한다.

\begin{table}
\begin{tabular}{l|r|r r r r r} \hline \hline Model \& Method & \# Trainable & \multicolumn{5}{c}{E2E NLG Challenge} \\  & Parameters & BLEU & NIST & MET & ROUGE-L & CIDEr \\ \hline GPT-2 M (FT)* & 354.92M & 68.2 & 8.62 & 46.2 & 71.0 & 2.47 \\ GPT-2 M (Adapter\({}^{\text{L}}\))* & 0.37M & 66.3 & 8.41 & 45.0 & 69.8 & 2.40 \\ GPT-2 M (Adapter\({}^{\text{L}}\))* & 11.09M & 68.9 & 8.71 & 46.1 & 71.3 & 2.47 \\ GPT-2 M (Adapter\({}^{\text{H}}\)) & 11.09M & 67.3\({}_{\pm 6}\) & 8.50\({}_{\pm 07}\) & 46.0\({}_{\pm 2}\) & 70.7\({}_{\pm 2}\) & 2.44\({}_{\pm 01}\) \\ GPT-2 M (FT\({}^{\text{Top2}}\))* & 25.19M & 68.1 & 8.59 & 46.0 & 70.8 & 2.41 \\ GPT-2 M (PreLayer)* & 0.35M & 69.7 & 8.81 & 46.1 & 71.4 & 2.49 \\ GPT-2 M (LoRA) & 0.35M & **70.4\({}_{\pm 1}\)** & **8.85\({}_{\pm 02}\)** & **46.8\({}_{\pm 2}\)** & **71.8\({}_{\pm 1}\)** & **2.53\({}_{\pm 02}\)** \\ \hline GPT-2 L (FT)* & 774.03M & 68.5 & 8.78 & 46.0 & 69.9 & 2.45 \\ GPT-2 L (Adapter\({}^{\text{L}}\)) & 0.88M & 69.1\({}_{\pm 1.1}\) & 8.68\({}_{\pm 03}\) & 46.3\({}_{\pm 0}\) & 71.4\({}_{\pm 2}\) & **2.49\({}_{\pm 0}\)** \\ GPT-2 L (Adapter\({}^{\text{L}}\)) & 23.00M & 68.9\({}_{\pm 3}\) & 8.70\({}_{\pm 04}\) & 46.1\({}_{\pm 1}\) & 71.3\({}_{\pm 2}\) & 2.45\({}_{\pm 02}\) \\ GPT-2 L (PreLayer)* & 0.77M & 70.3 & 8.85 & 46.2 & 71.7 & 2.47 \\ GPT-2 L (LoRA) & 0.77M & **70.4\({}_{\pm 1}\)** & **8.89\({}_{\pm 02}\)** & **46.8\({}_{\pm 2}\)** & **72.0\({}_{\pm 2}\)** & 2.47\({}_{\pm 02}\) \\ \hline \hline \end{tabular}
\end{table}
표 3: E2E NLG 챌린지에서 적응 방법이 다른 GPT-2 배지(M) 및 대형(L)이다. 모든 메트릭에 대해, 높은 것이 더 좋다. LoRA는 비교 가능하거나 훈련 가능한 파라미터가 적은 여러 기준선보다 성능이 우수하다. 우리가 실행한 실험에 대한 신뢰 구간이 표시된다. *는 이전 작업에 게시된 숫자를 나타낸다.

### Scaling up to GPT-3 175B

LoRA에 대한 최종 스트레스 테스트로서, 우리는 1,750억 개의 매개변수로 최대 GPT-3을 확장한다. 높은 훈련 비용으로 인해 모든 항목에 대해 하나를 제공하는 대신 무작위 시드보다 주어진 작업에 대한 평균 표준 편차만 보고한다. 사용된 하이퍼파라미터에 대한 자세한 내용은 섹션 D.4를 참조하십시오.

표 4에서 볼 수 있듯이 LoRA는 세 데이터 세트 모두에서 미세 조정 기준선과 일치하거나 초과한다. 도 2에 도시된 바와 같이, 모든 방법이 더 많은 트레이닝 가능한 파라미터를 갖는 것으로부터 단조롭게 이득을 얻는 것은 아니라는 점에 유의한다. 우리는 프리픽스-임베딩 튜닝을 위해 256개 이상의 특수 토큰을 사용하거나 프리픽스-레이어 튜닝을 위해 32개 이상의 특수 토큰을 사용할 때 상당한 성능 저하를 관찰한다. 이는 Li와 Liang(2021)에서 유사한 관측치를 확증한다. 이 현상에 대한 철저한 조사는 이 작업의 범위를 벗어났지만, 더 많은 특수 토큰을 갖는 것은 입력 분포가 사전 훈련 데이터 분포에서 더 멀리 이동하게 한다고 의심한다. 이와 별도로 F.3절의 저데이터 체제에서 다양한 적응 접근법의 성능을 조사한다.

## 6 관련 작업

Transformer Language Models.Transformer(Vaswani et al., 2017)는 self-attention을 무겁게 사용하는 sequence-to-sequence 아키텍처이다. Radford et al.(a)는 Transformer 디코더의 스택을 이용하여 자기회귀 언어 모델링에 적용하였다. 그 이후로 트랜스포머 기반 언어 모델이 NLP를 지배하여 많은 작업에서 최첨단을 달성했다. BERT(Devlin et al., 2019)와 GPT-2(Radford et al., b)로 등장한 새로운 패러다임 - 둘 다 대형 트랜스포머 lan

\begin{table}
\begin{tabular}{l|r|r r r} \hline \hline \multirow{2}{*}{Model\&Method} & \# Trainable & WikiSQL & MNLI-m & SAMSum \\ \cline{2-5}  & \multicolumn{1}{c|}{Parameters} & Acc. (\%) & Acc. (\%) & R1/R2/RL \\ \hline GPT-3 (FT) & 175,255.8M & **73.8** & 89.5 & 52.0/28.0/44.5 \\ GPT-3 (BitFit) & 14.2M & 71.3 & 91.0 & 51.3/27.4/43.5 \\ GPT-3 (PreEmbed) & 3.2M & 63.1 & 88.6 & 48.3/24.2/40.5 \\ GPT-3 (PreLayer) & 20.2M & 70.1 & 89.5 & 50.8/27.3/43.5 \\ GPT-3 (Adapter\({}^{\text{H}}\)) & 7.1M & 71.9 & 89.8 & 53.0/28.9/44.8 \\ GPT-3 (Adapter\({}^{\text{H}}\)) & 40.1M & 73.2 & **91.5** & 53.2/29.0/45.1 \\ \hline GPT-3 (LoRA) & 4.7M & 73.4 & **91.7** & **53.8/29.8/45.9** \\ GPT-3 (LoRA) & 37.7M & **74.0** & **91.6** & 53.4/29.2/45.1 \\ \hline \hline \end{tabular}
\end{table}
표 4: GPT-3 175B에 대한 상이한 적응 방법의 성능. 우리는 위키SQL의 논리적 형식 검증 정확도, MultiNLI 일치의 검증 정확도, SAMSum의 Rouge-1/2/L을 보고한다. LoRA는 전체 미세 조정을 포함하여 이전 접근법보다 더 나은 성능을 보인다. WikiSQL의 결과는 3가지 메트릭에 대해 \(\pm 0.5\%\), MNLI-m \(\pm 0.1\%\), SAMSum \(\pm 0.2\)/\(\pm 0.2\)/\(\pm 0.1\)의 변동을 보인다.

도 2: GPT-3 175B 검증 정확도 대. WikiSQL 및 MNLI 일치에서 여러 적응 방법의 훈련 가능한 매개 변수 수. LoRA는 더 나은 확장성과 작업 성능을 보여줍니다. 플롯된 데이터 점에 대한 자세한 내용은 F.2절을 참조하십시오.

많은 양의 텍스트에 대해 훈련된 길잡이 모델 - 일반 도메인 데이터에 대한 사전 훈련 후 태스크 특정 데이터에 대한 미세 조정은 태스크 특정 데이터에 대한 훈련에 비해 상당한 성능 이득을 제공한다. 더 큰 변압기를 훈련하는 것은 일반적으로 더 나은 성능을 가져오며 여전히 활발한 연구 방향으로 남아 있다. GPT-3(Brown et al., 2020)은 175B 파라미터로 현재까지 훈련된 가장 큰 단일 트랜스포머 언어 모델이다.

프롬프트 엔지니어링 및 Fine-Tuning. GPT-3 175B는 단지 몇 개의 추가 트레이닝 예들만으로 그의 거동을 적응시킬 수 있지만, 결과는 입력 프롬프트에 크게 의존한다(Brown 등, 2020). 이는 프롬프트 엔지니어링 또는 프롬프트 해킹으로 알려진 원하는 작업에 대한 모델의 성능을 최대화하기 위해 프롬프트를 구성하고 포맷하는 경험적 기술을 필요로 한다. Fine-tuning은 일반 도메인들에 대해 사전 트레이닝된 모델을 특정 태스크 Devlin 등(2019); Radford 등(a)으로 재 트레이닝한다. 그것의 변형들은 단지 파라미터들 Devlin 등(2019); Collobert and Weston(2008)의 서브세트만을 학습하는 것을 포함하지만, 실무자들은 종종 다운스트림 성능을 최대화하기 위해 이들 모두를 재트레이닝한다. 그러나 GPT-3 175B의 거대함은 그것이 생성하는 큰 체크포인트 및 사전 훈련과 동일한 메모리 풋프린트를 갖기 때문에 높은 하드웨어 진입 장벽으로 인해 통상적인 방식으로 미세 조정을 수행하는 것을 어렵게 한다.

파라미터-효율적인 적응.많은 사람들이 신경망에서 기존 레이어 사이에 _어댑터_ 레이어를 삽입하는 것을 제안했다(Houlsby et al., 2019; Rebuffi et al., 2017; Lin et al., 2020). 이 방법은 유사한 병목 구조를 사용하여 가중치 업데이트에 낮은 순위 제약을 부과한다. 주요 기능적인 차이는 우리의 학습된 가중치가 추론 동안 주요 가중치와 병합될 수 있고, 따라서 어댑터 레이어의 경우가 아닌 어떠한 지연도 도입하지 않는다는 것이다(섹션 3). 어댑터의 임시 확장은 컴팩터(Mahabadi et al., 2021)이며, 이는 본질적으로 소정의 가중치 공유 방식을 갖는 크로네커 제품을 사용하여 어댑터 층들을 파라미터화한다. 마찬가지로 LoRA를 다른 텐서 제품 기반 방법과 결합하면 잠재적으로 매개변수 효율성을 향상시킬 수 있으며, 이는 향후 작업으로 남겨둔다. 보다 최근에, 많은 제안들은 프롬프트 엔지니어링의 지속적이고 미분가능한 일반화와 유사한, 미세 조정 대신에 입력 워드 임베딩을 최적화하는 것을 제안했다(Li and Liang, 2021; Lester et al., 2021; Hambardzumyan et al., 2020; Liu et al., 2021). 우리는 실험 섹션에 Li 및 Liang(2021)과의 비교를 포함한다. 그러나 이 작업 라인은 프롬프트에서 더 많은 특수 토큰을 사용 하 여 확장할 수 있으며, 위치 임베딩이 학습 될 때 작업 토큰에 대 한 사용 가능한 시퀀스 길이를 차지 합니다.

딥러닝에서 낮은 순위의 구조.낮은 순위의 구조는 기계 학습에서 매우 일반적이다. 많은 기계 학습 문제들은 특정한 본질적인 하위-순위 구조를 갖는다(Li et al., 2016; Cai et al., 2010; Li et al., 2018; Grasedyck et al., 2013). 더욱이, 많은 딥 러닝 태스크들, 특히 심하게 오버-파라메트리된 신경망을 갖는 태스크들에 대해, 학습된 신경망은 트레이닝 후에 낮은-순위 속성들을 즐길 것이라는 것이 알려져 있다(Oymak 등, 2019). 일부 선행 작업들은 심지어 원래의 신경망을 트레이닝할 때 낮은-순위 제약을 명시적으로 부과한다(Sainath et al., 2013; Povey et al., 2018; Zhang et al., 2014; Jaderberg et al., 2014; Zhao et al., 2016; Khodak et al., 2021; Denil et al., 2014); 그러나, 우리가 아는 한, 이들 작업들 중 어느 것도 다운스트림 작업들에 대한 적응_을 위해 동결된 모델에 대한 낮은-순위 업데이트를 고려하지 않는다. 이론 문헌에서, 신경망은 기초 개념 클래스가 특정 하위-순위 구조를 가질 때 대응하는 (유한-폭) 신경 접선 커널들(Allen-Zhu 등, 2019; Li 및 Liang, 2018)을 포함하는 다른 고전적 학습 방법들보다 우수한 것으로 알려져 있다(Ghorbani 등, 2020; Allen-Zhu 및 Li, 2019; Allen-Zhu 및 Li, 2020). Allen-Zhu and Li (2020)의 또 다른 이론적 결과는 낮은 순위의 적응이 적대적 훈련에 유용할 수 있음을 시사한다. 요약하면, 우리는 제안된 낮은 순위 적응 업데이트가 문헌에 의해 잘 동기화되어 있다고 믿는다.

## 7 Low-Rank 업데이트 이해

LoRA의 경험적 이점을 감안할 때 다운스트림 작업에서 학습된 낮은 순위 적응의 속성을 추가로 설명하기를 바란다. 낮은 순위의 구조는 여러 실험을 병렬로 실행할 수 있는 하드웨어 진입 장벽을 낮출 뿐만 아니라 업데이트 가중치가 미리 훈련된 가중치와 어떻게 상관되는지에 대한 더 나은 해석 가능성을 제공한다는 점에 유의해야 한다. 본 연구에서는 GPT-3 175B에 대한 연구를 수행하였는데, GPT-3 175B에서 학습 가능한 파라미터(최대 10,000\(\times\))의 최대 감소를 달성하였다.

다음 질문에 답하기 위해 일련의 경험적 연구를 수행합니다. 1) 매개 변수 예산 제약 조건이 주어지면 _미리 훈련된 변압기에서 가중치 행렬의 일부 집합_ 다운스트림 성능을 최대화하기 위해 적응해야 하나요? 2) "최적" 적응 행렬 \(\Delta W\)_really rank-deficient_인가? 그렇다면, 실무에서 사용하기 좋은 등급은 무엇입니까? 3) \(\Delta W\)와 \(W\)의 연결은 무엇인가요? \(\Delta W\)은 \(W\)과 상관관계가 높은가? \(\Delta W\)이 \(W\)에 비해 얼마나 큰가?

우리는 질문 (2)와 (3)에 대한 우리의 답변이 NLP의 중요한 주제인 다운스트림 작업에 사전 훈련된 언어 모델을 사용하는 기본 원칙을 조명한다고 믿는다.

### LoRA를 적용해야 하는 Transformer의 가중치 행렬은 무엇입니까?

제한된 매개변수 예산을 감안할 때, 다운스트림 작업에서 최상의 성능을 얻기 위해 LoRA와 어떤 유형의 가중치를 적용해야 하는가? 섹션 4.2에서 언급한 바와 같이, 우리는 자기 주의 모듈의 가중치 행렬만을 고려한다. GPT-3 175B에서 18M(FP16에 저장된 경우 대략 35MB)의 매개변수 예산을 설정했으며, 이는 96개 계층 모두에 대해 주의 가중치에 따라 하나씩 적응하는 경우 \(r=8\) 또는 두 가지 유형을 적응하는 경우 \(r=4\)에 해당한다. 결과는 표 5에 제시되어 있다.

모든 파라미터를 \(\Delta W_{q}\) 또는 \(\Delta W_{k}\)에 넣으면 성능이 현저히 저하되지만 \(W_{q}\)과 \(W_{v}\)을 모두 적용하면 가장 좋은 결과를 얻을 수 있다. 이는 4개의 순위조차도 \(\Delta W\)에서 충분한 정보를 포착하여 순위가 더 큰 단일 유형의 가중치를 적용하는 것보다 더 많은 가중치 매트릭스를 적용하는 것이 바람직함을 시사한다.

### LoRA의 최적 순위 \(r\)는 무엇인가요?

우리는 순위 \(r\)이 모델 성능에 미치는 영향에 주의를 돌린다. 비교를 위해 \(\{W_{q},W_{v}\}\), \(\{W_{q},W_{k},W_{v},W_{c}\}\), 그리고 단지 \(W_{q}\)을 적용한다.

표 6은 놀랍게도 LoRA가 단지 \(W_{q}\)보다 \(\{W_{q},W_{v}\}\)에 대해 이미 매우 작은 \(r\)으로 경쟁적으로 수행한다는 것을 보여준다. 이것은 갱신 행렬 \(\Delta W\)이 매우 작은 "내재적 순위"를 가질 수 있음을 시사한다. 6 이 발견을 추가로 뒷받침하기 위해 \(r\)의 다른 선택과 다른 무작위 시드들에 의해 학습된 부분 공간들의 중첩을 확인한다. 우리는 \(r\)을 증가시키는 것이 더 의미 있는 부분 공간을 커버하지 않는다고 주장하며, 이는 낮은 순위의 적응 행렬이 충분함을 시사한다.

\begin{table}
\begin{tabular}{c|c|c c c c c} \hline \hline  & Weight Type & \(r=1\) & \(r=2\) & \(r=4\) & \(r=8\) & \(r=64\) \\ \hline WikiSQL(\(\pm 0.5\)\%) & \(W_{q}\) & 68.8 & 69.6 & 70.5 & 70.4 & 70.0 \\  & \(W_{q},W_{v}\) & 73.4 & 73.3 & 73.7 & 73.8 & 73.5 \\  & \(W_{q},W_{k},W_{v},W_{o}\) & 74.1 & 73.7 & 74.0 & 74.0 & 73.9 \\ \hline \multirow{2}{*}{MultiNLI (\(\pm 0.1\)\%)} & \(W_{q}\) & 90.7 & 90.9 & 91.1 & 90.7 & 90.7 \\  & \(W_{q},W_{v}\) & 91.3 & 91.4 & 91.3 & 91.6 & 91.4 \\  & \(W_{q},W_{k},W_{v},W_{o}\) & 91.2 & 91.7 & 91.7 & 91.5 & 91.4 \\ \hline \hline \end{tabular}
\end{table}
표 6: 상이한 랭크 \(r\)를 갖는 WikiSQL 및 MultiNLI에서의 검증 정확도. 놀랍게도, \(W_{q}\)과 \(W_{v}\)을 학습하는 동안 \(W_{q}\)에만 더 큰 \(r\)이 필요하다. 우리는 섹션 H.2에서 GPT-2에 대해 유사한 실험을 수행한다.

\begin{table}
\begin{tabular}{l|c c c c c c c} \hline \hline  & \multicolumn{6}{c}{\# of Trainable Parameters = 18M} \\ \hline Weight Type & \(W_{q}\) & \(W_{k}\) & \(W_{v}\) & \(W_{o}\) & \(W_{q},W_{k}\) & \(W_{q},W_{v}\) & \(W_{q},W_{k},W_{v},W_{o}\) \\ Rank \(r\) & 8 & 8 & 8 & 8 & 4 & 4 & 2 \\ \hline WikiSQL (\(\pm 0.5\)\%) & 70.4 & 70.0 & 73.0 & 73.2 & 71.4 & **73.7** & **73.7** \\ MultiNLI (\(\pm 0.1\)\%) & 91.0 & 90.8 & 91.0 & 91.3 & 91.3 & 91.3 & **91.7** \\ \hline \hline \end{tabular}
\end{table}
표 5: 동일한 수의 훈련 가능한 매개변수가 주어졌을 때 GPT-3의 다른 유형의 주의력 가중치에 LoRA를 적용한 후 WikiSQL 및 MultiNLI에 대한 검증 정확도. \(W_{q}\)과 \(W_{v}\)을 모두 적용하였을 때 전체적으로 가장 좋은 성능을 보였다. 우리는 첫 번째 열에 보고하는 주어진 데이터 세트에 대해 무작위 씨드에 걸친 표준 편차가 일관성이 있음을 발견한다.

서로 다른 \(r\).주어진 \(A_{r=8}\)과 \(A_{r=64}\) 사이의 부분공간 유사성은 \(r=8}\)과 \(64\)을 갖는 학습된 적응행렬로서 _동일한 사전 훈련된 모델_을 이용하여 특이값 분해를 수행하고 우-단수 단위행렬 \(U_{A_{r=8}}\)과 \(U_{A_{r=64}}\)을 구한다. 7 : \(U_{A_{r=8}\)(\(1\leq i\leq 8\))의 상위 \(i\) 특이벡터에 의해 스패닝된 부분공간은 \(U_{A_{r=64}\)(\(1\leq j\leq 64\))의 상위 \(j\) 특이벡터에 의해 스패닝된 부분공간에 얼마나 포함되어 있는가? 우리는 그래스만 거리를 기반으로 정규화된 부분 공간 유사성으로 이 양을 측정한다(보다 공식적인 논의는 부록 G 참조).

각주 7: 유사한 분석이 \(B\) 및 좌-특이 단일 행렬로 수행될 수 있다는 점에 유의하라. 우리는 실험을 위해 \(A\)을 고수한다.

\[\phi(A_{r=8},A_{r=64},i,j)=\frac{||U_{A_{r=8}}^{i\top}U_{A_{r=64}}^{j}||_{F}^{2}}{\min(i,j)}\in[0,1] \tag{4}\]

여기서 \(U_{A_{r=8}}^{i}\)는 상단-\(i\) 특이 벡터에 해당하는 \(U_{A_{r=8}}\)의 열을 나타낸다.

\(\phi(\cdot)\)는 \([0,1]\)의 범위를 가지며, 여기서 \(1\)은 부분 공간의 완전한 중첩과 \(0\) 완전한 분리를 나타낸다. 우리가 \(i\)와 \(j\)을 변화시킴에 따라 \(\phi\)가 어떻게 변하는지는 그림 3을 참조하라. 공간 제약으로 인해 48번째 층(96개 중)만 살펴보지만 H.1절과 같이 다른 층에서도 결론이 성립한다.

우리는 그림 3에서 _중요한 관찰_을 만든다.

상단 특이 벡터에 해당하는 방향들은 \(A_{r=8}\)과 \(A_{r=64}\) 사이에서 크게 겹치는 반면, 다른 방향들은 겹치지 않는다. 구체적으로는, \(\Delta W_{v}\)(resp. \ \(A_{r=8}\) 및 \(\Delta W_{v}\)의 (\Delta W_{q}\)) (resp. \ \(A_{r=64}\)의 (\Delta W_{q}\))은 정규화된 유사성 \(>0.5\)을 갖는 차원 1의 부분 공간을 공유하여 \(r=1\)이 GPT-3의 다운스트림 태스크에서 상당히 잘 수행하는 이유에 대한 설명을 제공한다.

동일한 사전 훈련 모델을 사용하여 \(A_{r=8}\)과 \(A_{r=64}\)을 모두 학습하기 때문에 그림 3은 \(A_{r=8}\)과 \(A_{r=64}\)의 상단 특이 벡터 방향이 가장 유용하고 다른 방향은 훈련 중에 누적된 대부분의 무작위 잡음을 잠재적으로 포함하고 있음을 나타낸다. 따라서 적응 행렬은 실제로 매우 낮은 순위를 가질 수 있다.

서로 다른 랜덤 시드 사이의 부분 공간 유사성.그림 4에 표시된 \(r=64\)으로 무작위로 시드된 두 런 사이의 정규화된 부분 공간 유사성을 도표화하여 이를 추가로 확인한다. \(\Delta W_{q}\)은 \(\Delta W_{v}\)보다 높은 "내재 순위"를 갖는 것으로 보이며, 이는 표 6의 경험적 관찰과 일치한다.

### Adaptation Matrix \(\Delta W\)와 \(W\)을 비교하는 방법은 무엇입니까?

또한 \(\Delta W\)과 \(W\)의 관계를 조사하였다. 특히 \(\Delta W\)은 \(W\)과 상관관계가 높은가? (또는 수학적으로, \(\Delta W\)은 대부분 \(W\)α의 상단 단수 방향에 포함되어 있는가) 또한,

그림 3: \(\Delta W_{q}\)과 \(\Delta W_{v}\)에 대한 \(A_{r=8}\)과 \(A_{r=64}\)의 열 벡터 사이의 부분 공간 유사성. 세 번째와 네 번째 그림은 첫 번째 두 그림에서 왼쪽 아래 삼각형을 확대한다. \(r=8\)의 상단 방향은 \(r=64\)에 포함되며 그 반대의 경우도 마찬가지이다.

"크다"는 \(\Delta W\)가 \(W\)에서 대응하는 방향과 얼마나 비교되는가? 이는 사전 훈련된 언어 모델을 적용하기 위한 기본 메커니즘을 밝힐 수 있다.

이러한 질문에 답하기 위해, 우리는 \(W\)을 \(U^{\top}WV^{\top}\을 계산하여 \(\Delta W\)의 \(r\)차원 부분공간에 투영하고, \(U/V\)은 \(\Delta W\)의 좌/우 특이벡터 행렬이다. 그리고 \(\|U^{\top}WV^{\top}\|_{F}\)과 \(\|W\|_{F}\) 사이의 Frobenius norm을 비교한다. 또한 비교를 위해 \(\|U^{\top}WV^{\top}\|_{F}\)을 \(W\) 또는 랜덤 행렬의 상단 \(r\) 특이 벡터로 대체하여 계산한다.

먼저, \(\Delta W\)은 랜덤 행렬에 비해 \(W\)과 더 강한 상관 관계를 가지며, 이는 \(\Delta W\)이 이미 \(W\)에 있는 일부 피쳐를 증폭한다는 것을 나타낸다. 둘째, \(W\)의 상단 특이 방향을 반복하는 대신 \(\Delta W\)는 \(W\)_에서 강조되지 않는 방향만을 증폭한다. 셋째, 증폭율은 \(r=4\)에 대해 \(21.5\approx 6.91/0.32\)로 다소 크다. \(r=64\)의 증폭률이 더 작은 이유는 H.4 절을 참조하십시오. 우리는 또한 섹션 H.3에서 \(W_{q}\)에서 더 많은 상단 특이 방향을 포함함에 따라 상관 관계가 어떻게 변하는지에 대한 시각화를 제공한다. 이는 하위 순위 적응 행렬이 잠재적으로 _일반 사전 훈련 모델에서 학습되었지만 강조되지 않은 특정 다운스트림 작업에 대한 중요한 기능을 증폭함_을 시사한다.

## 8 결론 및 향후 작업

막대한 언어 모델을 미세 조정하는 것은 필요한 하드웨어와 서로 다른 작업에 대한 독립적인 인스턴스를 호스팅하기 위한 스토리지/스위칭 비용 측면에서 엄청나게 비싸다. 우리는 높은 모델 품질을 유지하면서 추론 지연 시간을 도입하거나 입력 시퀀스 길이를 줄이지 않는 효율적인 적응 전략인 LoRA를 제안한다. 중요한 것은 대부분의 모델 매개 변수를 공유 하 여 서비스로 배포 될 때 빠른 작업 전환을 허용 합니다. 트랜스포머 언어 모델에 초점을 맞추었지만 제안된 원리는 일반적으로 밀도가 높은 계층을 가진 모든 신경망에 적용할 수 있다.

미래의 일을 위한 많은 방향들이 있다. 1) LoRA는 다른 효율적인 적응 방법들과 결합될 수 있으며, 잠재적으로 직교 개선을 제공한다. 2) 미세 조정 또는 LoRA 뒤에 있는 메커니즘은 명확하지 않다 - 사전 훈련 동안 학습된 특징들이 다운스트림 작업들에서 잘하도록 어떻게 변환되는가? 우리는 LoRA가 완전한 벌금보다 이것에 답하는 것이 더 다루기 쉽다고 믿습니다.

그림 4: **왼쪽과 중간:** 48번째 레이어의 \(\Delta W_{q}\)과 \(\Delta W_{v}\) 모두에 대해 두 개의 무작위 시드로부터 \(A_{r=64}\)의 열 벡터 사이의 정규화된 부분 공간 유사성. **오른쪽:** 두 개의 무작위 가우시안 행렬의 열 벡터 간에 동일한 열 맵입니다. 다른 층은 섹션 H.1을 참조한다.

\begin{table}
\begin{tabular}{l|c c c|c c c} \hline \hline  & \multicolumn{4}{c|}{\(r=4\)} & \multicolumn{4}{c}{\(r=64\)} \\  & \(\Delta W_{q}\) & \(W_{q}\) & Random & \(\Delta W_{q}\) & \(W_{q}\) & Random \\ \hline \(||U^{\top}W_{q}V^{\top}||_{F}=\) & 0.32 & 21.67 & 0.02 & 1.90 & 37.71 & 0.33 \\ \hline \(||W_{q}||_{F}=61.95\) & \multicolumn{4}{c|}{\(||\Delta W_{q}||_{F}=6.91\)} & \multicolumn{4}{c}{\(||\Delta W_{q}||_{F}=3.57\)} \\ \hline \hline \end{tabular}
\end{table}
표 7: \(U^{\top}W_{q}V^{\top}\)의 Frobenius norm으로서, \(U\) 및 \(V\)은 (1) \(\Delta W_{q}\), (2) \(W_{q}\) 또는 (3) 랜덤 매트릭스의 좌/우측 상단 \(r\) 특이 벡터 방향이다. 가중치 행렬들은 GPT-3의 48번째 층으로부터 취해진다.

tuning. 3) LoRA를 적용할 가중치 행렬을 선택하기 위해 대부분 휴리스틱에 의존한다. 그것을 할 수 있는 더 원칙적인 방법이 있나요? 넷째, \(\Delta W\)의 순위 결핍은 \(W\)도 순위 결핍이 될 수 있음을 시사하며, 이는 향후 작품에 대한 영감의 원천이 될 수 있다.

## References

* Aghajanyan 등(2020) Armen Aghajanyan, Luke Zettlemoyer, and Sonal Gupta. 내재적 차원은 언어 모델 미세 조정의 효과를 설명 합니다. _ arXiv:2012.13255 [cs]_, 2020년 12월 URL [http://arxiv.org/abs/2012.13255](http://arxiv.org/abs/2012.13255).
* Allen-Zhu and Li (2019) Zeyuan Allen-Zhu and Yuanzhi Li. 커널을 넘어 효율적으로 학습할 수 있는 ResNet은 무엇인가? _NeurIPS_, 2019. [http://arxiv.org/abs/1905.10337](http://arxiv.org/abs/1905.10337)에서 사용할 수 있는 전체 버전입니다.
* Allen-Zhu and Li(2020a) Zeyuan Allen-Zhu and Yuanzhi Li. 역방향 특징 보정: 딥 러닝이 딥 러닝을 수행하는 방법_ arXiv preprint arXiv:2001.04413_, 2020a.
* Allen-Zhu and Li(2020b) Zeyuan Allen-Zhu and Yuanzhi Li. 특징 정제: 적대적 트레이닝이 강건한 딥 러닝을 수행하는 방법_ arXiv preprint arXiv:2005.10190_, 2020b.
* Allen-Zhu 등(2019) Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song. 과모수화를 통한 딥러닝 융합 이론 _ICML_ 2019. [http://arxiv.org/abs/1811.03962](http://arxiv.org/abs/1811.03962)에서 사용할 수 있는 전체 버전입니다.
* Ba 등(2016) Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. Layer Normalization, 2016.
* Brown 등(2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. 지글러, 제프리 우, 클레멘스 윈터, 크리스토퍼 헤세, 마크 첸, 에릭 시글러, 마테우스 리트윈, 스콧 그레이, 벤자민 체스, 잭 클라크, 크리스토퍼 베르너, 샘 맥캔들리시, 알렉 래드포드, 일야 서츠케버, 다리오 아모데이. 언어 모델은 Few-Shot 학습자이다. _ arXiv:2005.14165 [cs]_, July 2020. URL [http://arxiv.org/abs/2005.14165](http://arxiv.org/abs/2005.14165).
* Cai 등(2010) Jian-Feng Cai, Emmanuel J Candes, and Zuowei Shen. 행렬 완성을 위한 특이값 임계화 알고리즘. _ SIAM Journal on optimization_, 20(4):1956-1982, 2010).
* Cer 등(2017) Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia. Semeval-2017 과제 1: 의미 텍스트 유사성 다국어 및 교차 언어 집중 평가_ Proceedings of 11th International Workshop on SemEval-2017)_, 2017. doi: 10.18653/v1/s17-2001. URL [http://dx.doi.org/10.18653/v1/S17-2001](http://dx.doi.org/10.18653/v1/S17-2001).
* Collobert and Weston (2008) Ronan Collobert and Jason Weston. 자연어 처리를 위한 통합 아키텍처: 멀티태스크 학습이 포함된 심층 신경망입니다. _Proceedings of the 25th international conference on Machine Learning_, ICML '08, pp. 160-167, New York, NY, USA, July 2008. Association for Computing Machinery. ISBN 978-1-60558-205-4. doi: 10.1145/1390156.1390177. URL [https://doi.org/10.1145/1390156.1390177](https://doi.org/10.1145/1390156.1390177)
* Denil 등(2014) Misha Denil, Babak Shakibi, Laurent Dinh, Marc'Aurelio Ranzato, and Nando de Freitas. 2014년 딥 러닝에서 매개 변수를 예측합니다.
* Devlin 등(2019a) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: 언어 이해를 위한 심층 양방향 변압기 사전 훈련, 2019a.
* Devlin 등(2019b) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: 언어 이해를 위한 딥 양방향 트랜스포머의 사전 트레이닝. _ arXiv:1810.04805 [cs]_, May 2019b. URL [http://arxiv.org/abs/1810.04805](http://arxiv.org/abs/1810.04805). arXiv: 1810.04805.
* Dolan and Brockett (2005) William B. Dolan and Chris Brockett. 센센셜 패러프레이즈 코퍼스를 자동으로 구성합니다. _IWP2005(Third International Workshop on Paraphrasing)_, 2005. URL [https://aclanthology.org/I05-5002](https://aclanthology.org/I05-5002).
* Gardent 등(2017) Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini. 웹nlg 도전: rdf 데이터에서 텍스트를 생성합니다. _Proceedings of the 10th International Conference on Natural Language Generation_, pp. 124-133, 2017.
* Ganin 등(2017)* Ghorbani 등(2020) Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, and Andrea Montanari. 신경망이 커널 메서드를 능가하는 시기는 언제입니까? _ arXiv preprint arXiv:2006.13409_, 2020.
* Gliwa et al. (2019) Bogdan Gliwa, Iwona Mochol, Maciej Biesek, and Aleksander Wawer. Samsum corpus: 추상적 요약을 위한 인간 주석 대화 데이터 세트입니다. _ CoRR_, abs/1911.12237, 2019. URL [http://arxiv.org/abs/1911.12237](http://arxiv.org/abs/1911.12237).
* Grasedyck 등(2013) Lars Grasedyck, Daniel Kressner, and Christine Tobler. 저순위 텐서 근사 기법에 대한 문헌 연구 GAMM-Mitteilungen_, 36(1):53-78, 2013).
* Ham and Lee (2008) Jihun Ham and Daniel D. Lee. Grassmann 판별 분석: 부분 공간 기반 학습에 대한 통합적인 관점. _ICML_에서 pp. 376-383, 2008. URL [https://doi.org/10.1145/1390156.1390204](https://doi.org/10.1145/1390156.1390204)
* Hambardzumyan 등(2020) Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May. WARP: 워드 레벨 적대적 재프로그래밍. _ arXiv:2101.00121 [cs]_, 2020년 12월. URL [http://arxiv.org/abs/2101.00121](http://arxiv.org/abs/2101.00121). arXiv: 2101.00121.
*He et al.(2021) Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 데버타: 2021년, 디컴코딩 강화 버트.
* Houlsby 등(2019) Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-Efficient Transfer Learning for NLP. _ arXiv:1902.00751 [cs, stat]_, June 2019. URL [http://arxiv.org/abs/1902.00751](http://arxiv.org/abs/1902.00751).
* Jaderberg 등(2014) Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. 낮은 순위 확장을 사용 하 여 컨볼루션 신경망을 가속화 합니다. _ arXiv preprint arXiv:1405.3866_, 2014.
* Khodak 등(2021) Mikhail Khodak, Neil Tenenholtz, Lester Mackey, and Nicolo Fusi. 인수분해 신경망의 초기화 및 정규화, 2021년입니다.
* Kingma and Ba (2017) Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.
* Lepikhin 등(2020) Dmitry Lepikhin, Hyouk중 Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. Gshard: Scaling giant models with conditional computation and automatic sharding, 2020.
* Lester 등(2021) Brian Lester, Rami Al-Rfou, Noah Constant. 파라미터-효율적인 프롬프트 튜닝을 위한 스케일의 파워. _ arXiv:2104.08691 [cs]_, 2021년 4월. URL [http://arxiv.org/abs/2104.08691](http://arxiv.org/abs/2104.08691). 2104.08691
* Li 등(2018a) Chunyuan Li, Heerad Farkhoor, Rosanne Liu, and Jason Yosinski. 객관적 경관의 내재적 차원 측정. _ arXiv:1804.08838 [cs, stat]_, April 2018a. URL [http://arxiv.org/abs/1804.08838](http://arxiv.org/abs/1804.08838). arXiv: 1804.08838.
* Li and Liang (2021) Xiang Lisa Li and Percy Liang. Prefix-Tuning: 생성을 위한 연속 프롬프트 최적화 _ arXiv:2101.00190 [cs]_, 2021년 1월. URL [http://arxiv.org/abs/2101.00190](http://arxiv.org/abs/2101.00190)
* Li and Liang (2018) Yuanzhi Li and Yingyu Liang. 구조화 데이터에 대한 확률적 기울기 하강을 통해 오버파라미터화된 신경망을 학습한다. _Advances in Neural Information Processing Systems_, 2018.
* Li 등(2016) Yuanzhi Li, Yingyu Liang, and Andrej Risteski. 교번 최소화를 통한 가중 저순위 근사치의 복구 보장 _International Conference on Machine Learning_, pp. 2358-2367. PMLR, 2016.
* Li 등(2018b) Yuanzhi Li, Tengyu Ma, and Hongyang Zhang. 과파라미터화된 행렬 감지 및 2차 활성화를 갖는 신경망에서의 알고리즘 정규화. _Conference On Learning Theory_, pp. 2-47. PMLR, 2018b.
* Lin 등(2020) Zhaojiang Lin, Andrea Madotto, and Pascale Fung. 파라미터 효율적인 전이 학습을 통한 다용도 생성 언어 모델 탐색 _Findings of the Association for Computational Linguistics: EMNLP 2020_, pp.441-459, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.41. URL [https://aclanthology.org/2020.findings-emnlp.41](https://aclanthology.org/2020.findings-emnlp.41).

샤오 류, 옌안 정, 정샤오 두, 밍 딩, 위제치안, 지린양, 지탕 등이 있다. GPT 이해도. _ arXiv:2103.10385 [cs]_, 2021년 3월. URL [http://arxiv.org/abs/2103.10385](http://arxiv.org/abs/2103.10385) 2103.10385
* Liu 등(2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 로베르타: 견고하게 최적화된 버트 사전 훈련 접근법, 2019년입니다.
* Loshchilov and Hutter (2017) Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. _ arXiv preprint arXiv:1711.05101_, 2017.
* Loshchilov and Hutter (2019) Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization, 2019.
* Mahabadi 등(2021) Rabeeh Karimi Mahabadi, James Henderson, and Sebastian Ruder. Compacter: Efficient low-rank hypercomplex adapter layers, 2021.
* Nan et al. (2020) Linyong Nan, Dragomir Radev, Rui Zhang, Arrit Rau, Abhinand Sivaprasad, Chiachun Hsieh, Xiangru Tang, Aadit Vyas, Neha Verma, Pranav Krishna, et al. Dart: Open-domain structured data record to text generation. _ arXiv preprint arXiv: 2007.02871_, 2020.
* Novikova et al. (2017) Jekaterina Novikova, Ondrej Dusek, and Verena Rieser. e2e 데이터 세트: 엔드 투 엔드 생성을 위한 새로운 도전 과제입니다. _ arXiv preprint arXiv:1706.09254_, 2017.
* Oymak 등(2019) Samet Oymak, Zalan Fabian, Mingchen Li, and Mahdi Soltanolkotabi. 자코비안의 낮은 순위 구조를 활용 하 여 신경망에 대 한 일반화를 보장 합니다. _ arXiv preprint arXiv:1906.05392_, 2019.
* Pfeiffer 등(2021) Jonas Pfeiffer, Aishwarya Kamath, Andreas Ruckle, Kyungghyun Cho, and Iryna Gurevych. Adapterfusion: 2021년 전이학습용 비파괴 과제 구성.
* Povey 등(2018) Daniel Povey, Gaofeng Cheng, Yiming Wang, Ke Li, Hainan Xu, Mahsa Yarmohammadi, and Sanjeev Khudanpur. 심층 신경망에 대한 반직교 저순위 행렬 인수분해 _Interspeech_, pp. 3743-3747, 2018.
* Radford 등(2017) Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 생성 사전 교육을 통한 언어 이해 향상 12번, A
* Radford 등(2018) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 언어 모델은 감독되지 않은 멀티태스킹 학습자입니다. pp. 24, b.
* Rajpurkar 등(2018) Pranav Rajpurkar, Robin Jia, and Percy Liang. 네가 모르는 것을 알아라: 팀에 대한 대답할 수 없는 질문들. CoRR_, abs/1806.03822, 2018. URL [http://arxiv.org/abs/1806.03822](http://arxiv.org/abs/1806.03822).
* Rebuffi 등(2017) Sylvestre-Alvise Rebuffi, Hakan Bilen, and Andrea Vedaldi. 잔여 어댑터를 사용 하 여 여러 시각적 도메인을 학습 합니다. _ arXiv:1705.08045 [cs, stat]_, 2017년 11월 URL [http://arxiv.org/abs/1705.08045](http://arxiv.org/abs/1705.08045). 1705.08045
* Ruckle 등(2020) Andreas Ruckle, Gregor Geigle, Max Glockner, Tilman Beck, Jonas Pfeiffer, Nils Reimers, and Iryna Gurevych. 어댑터 드롭: 2020년 변압기의 어댑터 효율에 대해 설명합니다.
* Sainath 등(2013) Tara N Sainath, Brian Kingsbury, Vikas Sindhwani, Ebru Arisoy, and Bhuvana Ramabhadran. 고차원 출력 타겟을 갖는 심층 신경망 학습을 위한 저순위 행렬 인수분해 _2013 IEEE International conference on acoustics, speech and signal processing_, pp. 6655-6659. IEEE, 2013.
* Shoeybi 등(2020) Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. Megatron-lm: 모델 병렬성을 사용하여 수십억 개의 파라미터 언어 모델을 훈련, 2020.
* Socher 등(2013) Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 감성 트리뱅크에 대한 의미 구성성에 대한 재귀적 심층 모델입니다. _Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing_, pp. 1631-1642, Seattle, Washington, USA, October 2013. Association for Computational Linguistics. URL [https://aclanthology.org/D13-1170](https://aclanthology.org/D13-1170).
* Sainath 등(2018)* Vaswani 등(2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 관심만 있으면 됩니다. _Proceedings of the 31st International Conference on Neural Information Processing Systems_, pp. 6000-6010, 2017.
* Wang 등(2019) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. 보우먼 글루: 2019년 자연어 이해를 위한 멀티태스크 벤치마크 및 분석 플랫폼입니다.
* Wang 등(2020) Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. 보우먼 슈퍼글루: 2020년 범용 언어 이해 시스템을 위한 보다 엄격한 벤치마크입니다.
* Warstadt et al. (2018) Alex Warstadt, Amanpreet Singh, and Samuel R Bowman. 신경망 허용 여부 판단 _ arXiv preprint arXiv:1805.12471_, 2018.
* Williams 등(2018) Adina Williams, Nikita Nangia, and Samuel Bowman. 추론을 통한 문장 이해를 위한 광범위한 도전 말뭉치입니다. _Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1(Long Papers)_, pp. 1112-1122, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1101. URL [https://www.aclweb.org/anthology/N18-1101](https://www.aclweb.org/anthology/N18-1101).
* Wolf 등(2020) 토마스 울프, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. 러쉬 트랜스포머: 최첨단 자연어 처리입니다. _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations_, pp. 38-45, Online, October 2020. Association for Computational Linguistics. URL [https://www.aclweb.org/anthology/2020.emnlp-demos.6](https://www.aclweb.org/anthology/2020.emnlp-demos.6).
* Yang and Hu (2021) Greg Yang and Edward J. Hu. 무한 폭 신경망에서의 특징 학습 _ arXiv:2011.14522 [cond-mat]_, 2021년 5월. URL [http://arxiv.org/abs/2011.14522](http://arxiv.org/abs/2011.14522). 2011.14522
* Zaken 등(2021) Elad Ben Zaken, Shauli Ravfogel, and Yoav Goldberg. 비트핏: 2021년 트랜스포머 기반 마스킹 언어 모델에 대한 간단한 매개변수 효율적인 미세 조정입니다.
* Zhang et al.(2014) Yu Zhang, Ekapol Chuangsuwanich, and James Glass. 저순위 행렬 인수분해를 이용한 심층 신경망 병목 특징 추출 _2014 IEEE International conference on acoustics, speech and signal processing (ICASSP)_, pp. 185-189. IEEE, 2014.
* Zhao et al.(2016) Yong Zhao, Jinyu Li, and Yifan Gong. 심층 신경망에 대한 낮은 순위와 대각선 적응입니다. _2016 IEEE International Conference on Acoustics, Speech and Signal Processing(ICASSP)_, pp. 5005-5009. IEEE, 2016.
* Zhong et al.(2017) Victor Zhong, Caiming Xiong, and Richard Socher. Seq2sql: 강화 학습을 사용하여 자연어에서 구조화된 쿼리를 생성합니다. _ CoRR_, abs/1709.00103, 2017. URL [http://arxiv.org/abs/1709.00103](http://arxiv.org/abs/1709.00103).

## 부록 큰 언어 모델에는 여전히 매개 변수 업데이트가 필요합니다.

소수의 샷 학습 또는 신속한 공학은 소수의 훈련 샘플만 있을 때 매우 유리하다. 그러나 실제로 우리는 종종 성능에 민감한 응용 프로그램에 대해 수천 개 이상의 훈련 예를 큐레이션할 수 있다. 표 8과 같이 미세조정은 크고 작은 데이터셋에 대한 적은 샷 학습에 비해 모델 성능을 획기적으로 향상시킨다. 우리는 GPT-3 논문으로부터 RTE에 대한 GPT-3 few-shot 결과를 취한다(Brown et al., 2020). MNLI 일치의 경우 클래스당 2개의 시연과 총 6개의 맥락 내 예제를 사용한다.

## Adapter Layers에 의해 도입된 부록 B 추론 대기 시간

어댑터 계층은 _sequential_ 방식으로 사전 훈련된 모델에 추가된 외부 모듈인 반면, 우리의 제안인 LoRA는 병렬 방식으로 추가된 외부 모듈로 볼 수 있다. 결과적으로 어댑터 레이어는 기본 모델에 추가하여 계산되어야 하므로 필연적으로 추가 대기 시간이 도입된다. Ruckle 등(2020)에서 지적된 바와 같이, 어댑터 계층들에 의해 도입된 레이턴시는 모델 배치 크기 및/또는 시퀀스 길이가 하드웨어 병렬성을 충분히 활용하기에 충분히 클 때 완화될 수 있다. GPT-2 매체에 대한 유사한 잠복기 연구로 그들의 관찰을 확인하고 배치 크기가 작고 추가된 잠복기가 중요할 수 있는 시나리오, 특히 온라인 추론이 있음을 지적한다.

우리는 100회 이상의 시행을 평균하여 NVIDIA 쿼드로 RTX8000의 단일 전진 패스의 대기 시간을 측정한다. 입력 배치 크기, 시퀀스 길이 및 어댑터 병목 차원 \(r\)을 변경한다. 우리는 AdapterH라고 부르는 Houlsby 등(2019)의 오리지널 어댑터 디자인과 AdapterI라고 부르는 Lin 등(2020)의 최근, 보다 효율적인 변형의 두 가지 어댑터 디자인을 테스트한다. 설계에 대한 자세한 내용은 섹션 5.1을 참조하십시오. 그림 5의 어댑터 없음 기준선과 비교하여 백분율에서 느려짐을 표시한다.

각주 8: [https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs](https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs)

## Appendix C Dataset Details

**GLUE 벤치마크** 는 광범위한 자연어 이해 작업 모음입니다. MNLI(inference, Williams et al. (2018)), SST-2(sentiment analysis, Socher et al. (2013)), MRPC(paraphrase detection, Dolan and Brockett (2005)), CoLA(linguistic acceptability, Warstadt et al. (2018)), QNLI(inference, Rajpurkar et al. (2018)), QQP(question-answering), RTE(inference),

\begin{table}
\begin{tabular}{l|c c} \hline \hline Method & MNLI-m (Val. Acc./\%) & RTE (Val. Acc./\%) \\ \hline GPT-3 Few-Shot & 40.6 & 69.0 \\ GPT-3 Fine-Tuned & 89.5 & 85.4 \\ \hline \hline \end{tabular}
\end{table}
표 8: Fine-tuning은 GPT-3 상에서 few-shot learning을 상당히 능가한다(Brown et al., 2020).

도 5: 무-어댑터(\(r=0\)) 기준선에 비해 추론 지연의 속도 감소율. 맨 위 행은 어댑터H 및 맨 아래 행 어댑터I의 결과를 보여줍니다. 더 큰 배치 크기와 시퀀스 길이는 대기 시간을 완화하는 데 도움이 되지만 느린 속도는 온라인, 짧은 시퀀스 길이 시나리오에서 30% 이상 높을 수 있습니다. 더 나은 가시성을 위해 컬러맵을 조정합니다.

및 STS-B (textual similarity, Cer et al.(2017)). 광범위한 적용 범위는 GLUE가 RoBERTa 및 DeBERTa와 같은 NLU 모델을 평가하기 위한 표준 메트릭을 벤치마킹하도록 만든다. 개별 데이터 세트는 서로 다른 허용 라이선스에서 릴리스됩니다.

**WikiSQL** 은 Zhong et al. (2017)에 소개되어 있으며 \(56,355\)/\(8,421\) 훈련/검증 예제를 포함합니다. 작업은 자연어 질문 및 테이블 스키마에서 SQL 쿼리를 생성 하는 것입니다. 우리는 문맥을 \(x=\{\text{table schema},\text{query}\}\)으로, 대상을 \(y=\{\text{SQL}\}\)으로 인코딩한다. 데이터 세트는 BSD 3-Clause 라이선스 아래에 릴리스됩니다.

**SAMSum** 은 Gliwa et al. (2019)에 소개되어 있으며 \(14,732\)/\(819\) 훈련/테스트 예제를 포함합니다. 그것은 두 사람 사이의 단계적 채팅 대화와 언어학자들이 작성한 추상적 요약으로 구성된다. 본 논문에서는 문맥을 "\(\backslash\)n"으로 인코딩한 후 "\(\backslash\)n\(\backslash\)n"으로 인코딩하고, 대상을 \(y=\{\text{summary}\}\)으로 인코딩한다. 데이터 세트는 비상업적 라이선스: 크리에이티브 커먼즈 BY-NC-ND 4.0으로 릴리스됩니다.

**E2E NLG Challenge** 는 End-to-End, 데이터 기반 자연어 생성 시스템을 훈련하기 위한 데이터 집합으로 Novikova et al.(2017)에 처음 소개되었으며 일반적으로 데이터 대 텍스트 평가에 사용됩니다. E2E 데이터 세트는 레스토랑 도메인의 \(42,000\) 훈련, \(4,600\) 유효성 검사 및 \(4,600\) 테스트 예제로 구성된다. 입력으로 사용되는 각 원본 테이블에는 여러 참조가 있을 수 있습니다. 각각의 샘플 입력 \((x,y)\)은 대응하는 자연 언어 참조 텍스트와 함께 슬롯-값 쌍들의 시퀀스로 구성된다. 데이터 세트는 Creative Commons BY-NC-SA 4.0에서 릴리스됩니다.

**DART** 는 Nan et al. (2020)에 설명 된 오픈 도메인 데이터 대 텍스트 데이터 집합입니다. DART 입력들은 ENTITY-RelATION-ENTITY 트리플들의 시퀀스들로서 구조화된다. 총 \(82K\)의 예제에서 DART는 E2E에 비해 훨씬 더 크고 복잡한 데이터 대 텍스트 작업이다. 데이터 세트는 MIT 라이선스로 릴리스됩니다.

**WebNLG** 는 데이터 대 텍스트 평가를 위해 일반적으로 사용되는 또 다른 데이터 세트입니다 (Gardent et al., 2017). 전체 웹NLG의 \(22K\) 예제는 14개의 별개의 범주로 구성되며, 그 중 9개는 훈련 중에 볼 수 있다. 14개의 총 카테고리 중 5개는 훈련 중에 보이지 않지만 테스트 세트에 표시되기 때문에, 평가는 전형적으로 "보이지 않는" 카테고리(S), "보이지 않는" 카테고리(U) 및 "모든" 카테고리(A)에 의해 깨진다. 각각의 입력 예는 SUBJECT -- PROPERT -- OBJECT 트리플의 시퀀스로 표현된다. 데이터 세트는 Creative Commons BY-NC-SA 4.0에서 릴리스됩니다.

## 실험에 사용된 부록 D Hyperparameters

### RoBERTa

우리는 선형 학습률 감쇠 스케줄로 AdamW를 사용하여 훈련한다. LoRA의 학습 속도, 학습 에포크 수 및 배치 크기를 스윕합니다. Liu 등(2019)에 이어, 우리는 일반적인 초기화 대신에 MRPC, RTE 및 STS-B에 적응할 때 LoRA 모듈을 우리의 최상의 MNLI 체크포인트로 초기화한다; 사전 훈련된 모델은 모든 작업에 대해 동결 상태를 유지한다. 우리는 5개의 무작위 종자 이상의 중앙값을 보고하며, 각 실행에 대한 결과는 최상의 시대에서 가져왔다. Houlsby 등(2019)과 Pfeiffer 등(2021)의 설정과 공정한 비교를 위해 모델 시퀀스 길이를 128로 제한하고 모든 작업에 고정 배치 크기를 사용했다. 중요하게도, 우리는 이미 MNLI에 적응된 모델 대신 MRPC, RTE 및 STS-B에 적응할 때 미리 훈련된 RoBERTa 대형 모델로 시작한다. 이 제한 된 설정을 사용 하는 실행은 \(\dagger\)로 표시 됩니다. 표 9의 실행에 사용된 하이퍼 매개 변수를 참조하세요.

### DeBERTa

우리는 다시 선형 학습률 감쇠 스케줄과 함께 AdamW를 사용하여 훈련한다. He 등(2021)에 따라 학습률, 탈락 확률, 준비 단계 및 배치 크기를 조정한다. 우리는 비교를 공정하게 유지하기 위해 (He et al., 2021)에 의해 사용된 동일한 모델 시퀀스 길이를 사용한다. He 등(2021)에 이어, 일반적인 초기화 대신에, MRPC, RTE 및 STS-B에 적응할 때 LoRA 모듈을 우리의 최상의 MNLI 체크포인트로 초기화한다; 사전 트레이닝된 모델은 모든 작업에 대해 동결 상태를 유지한다. 우리는 5개의 무작위 종자 이상의 중앙값을 보고하며, 각 실행에 대한 결과는 최상의 시대에서 가져왔다. 표 10의 실행에 사용된 하이퍼 매개 변수를 참조하세요.

### Gpt-2

우리는 5 에폭에 대한 선형 학습 속도 스케줄로 AdamW(Loshchilov and Hutter, 2017)를 사용하여 모든 GPT-2 모델을 훈련시킨다. Li와 Liang(2021)에 기술된 배치 크기, 학습률, 빔 탐색 빔 크기를 사용한다. 따라서 LoRA에 대한 위의 하이퍼파라미터도 조정한다. 우리는 3개 이상의 무작위 종자를 보고하며, 각 실행에 대한 결과는 최상의 시대에서 가져왔다. GPT-2에서 LoRA에 사용되는 하이퍼 파라미터는 표 11에 나열되어 있다. 다른 베이스라인에 사용되는 파라미터는 Li 및 Liang(2021)을 참조한다.

### Gpt-3

모든 GPT-3 실험에 대해, 배치 크기가 128 샘플이고 중량 감소 계수가 0.1인 2개의 에폭에 대해 AdamW(Loshchilov and Hutter, 2017)를 사용하여 훈련한다. 384의 시퀀스 길이를 사용한다.

\begin{table}
\begin{tabular}{l l|c c c c c c c c} \hline \hline Method & Dataset & MNLI & SST-2 & MRPC & CoLA & QNLI & QQP & RTE & STS-B \\ \hline \multirow{8}{*}{RoBERTa base LoRA} & Optimizer & \multicolumn{8}{c}{AdamW} \\  & Warmup Ratio & \multicolumn{8}{c}{0.06} \\  & LR Schedule & \multicolumn{8}{c}{Linear} \\ \hline \multirow{4}{*}{RoBERTa base LoRA} & Batch Size & 16 & 16 & 16 & 32 & 32 & 16 & 32 & 16 \\  & \# Epochs & 30 & 60 & 30 & 80 & 25 & 25 & 80 & 40 \\  & Learning Rate & 5E-04 & 5E-04 & 4E-04 & 4E-04 & 4E-04 & 5E-04 & 5E-04 & 4E-04 \\  & LoRA Config. & \multicolumn{8}{c}{\(r_{q}=r_{v}=8\)} \\  & LoRA \(\alpha\) & \multicolumn{8}{c}{8} \\  & Max Seq. Len. & \multicolumn{8}{c}{512} \\ \hline \multirow{4}{*}{RoBERTa large LoRA} & Batch Size & 4 & 4 & 4 & 4 & 4 & 8 & 8 \\  & \# Epochs & 10 & 10 & 20 & 20 & 10 & 20 & 30 \\  & Learning Rate & 3E-04 & 4E-04 & 3E-04 & 2E-04 & 3E-04 & 4E-04 & 2E-04 \\  & LoRA Config. & \multicolumn{8}{c}{\(r_{q}=r_{v}=8\)} \\  & LoRA \(\alpha\) & \multicolumn{8}{c}{16} \\  & Max Seq. Len. & 128 & 128 & 512 & 128 & 512 & 512 & 512 & 512 \\ \hline \multirow{4}{*}{RoBERTa large LoRA\(\dagger\)} & Batch Size & \multicolumn{8}{c}{4} \\  & \# Epochs & 10 & 10 & 20 & 20 & 10 & 20 & 20 & 10 \\  & Learning Rate & 3E-04 & 4E-04 & 3E-04 & 2E-04 & 2E-04 & 3E-04 & 4E-04 & 2E-04 \\  & LoRA Config. & \multicolumn{8}{c}{\(r_{q}=r_{v}=8\)} \\  & Max Seq. Len. & \multicolumn{8}{c}{128} \\ \hline \multirow{4}{*}{RoBERTa large LoRA\(\dagger\)} & Batch Size & \multicolumn{8}{c}{32} \\  & \# Epochs & 10 & 20 & 20 & 20 & 10 & 20 & 20 & 20 \\  & Learning Rate & 3E-05 & 3E-05 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 \\  & Bottleneck \(r\) & \multicolumn{8}{c}{64} \\  & Max Seq. Len. & \multicolumn{8}{c}{128} \\ \hline \multirow{4}{*}{RoBERTa large LoRA\(\dagger\)} & Batch Size & \multicolumn{8}{c}{32} \\  & \# Epochs & 5 & 20 & 20 & 10 & 20 & 20 & 20 \\  & Learning Rate & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 \\  & Bottleneck \(r\) & \multicolumn{8}{c}{64} \\  & Max Seq. Len. & \multicolumn{8}{c}{128} \\ \hline \multirow{4}{*}{RoBERTa large Adpr\({}^{\dagger}\) (0.8M)\(\dagger\)} & Batch Size & \multicolumn{8}{c}{32} \\  & \# Epochs & 10 & 5 & 10 & 10 & 5 & 20 & 20 & 10 \\  & Learning Rate & 3E-05 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 \\  & Bottleneck \(r\) & \multicolumn{8}{c}{64} \\  & Max Seq. Len. & \multicolumn{8}{c}{128} \\ \hline \multirow{4}{*}{RoBERTa large Adpr\({}^{\dagger}\) (6M)\(\dagger\)} & Batch Size & \multicolumn{8}{c}{32} \\  & \# Epochs & 5 & 20 & 20 & 10 & 20 & 20 & 20 \\  & Learning Rate & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 \\  & Bottleneck \(r\) & \multicolumn{8}{c}{16} \\  & Max Seq. Len. & \multicolumn{8}{c}{128} \\ \hline \multirow{4}{*}{RoBERTa large Adpr\({}^{\ddagger}\) (0.8M)\(\dagger\)} & Batch Size & \multicolumn{8}{c}{32} \\  & \# Epochs & 10 & 5 & 10 & 10 & 5 & 20 & 20 & 10 \\  & Learning Rate & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 \\  & Bottleneck \(r\) & \multicolumn{8}{c}{64} \\  & Max Seq. Len. & \multicolumn{8}{c}{128} \\ \hline \multirow{4}{*}{RoBERTa large Adpr\({}^{\ddagger}\) (0.8M)\(\dagger\)} & Batch Size & \multicolumn{8}{c}{32} \\  & \# Epochs & 10 & 5 & 10 & 10 & 5 & 20 & 20 & 10 \\  & Learning Rate & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 & 3E-04 \\  & Bottleneck \(r\) & \multicolumn{8}{c}{128} \\ \hline \hline \end{tabular}
\end{table}
표 9: GLUE 벤치마크에서 RoBERTa에 대해 사용한 하이퍼파라미터.

WikiSQL (Zhong et al., 2017), 768 for MNLI (Williams et al., 2018), 2048 for SAMSum (Gliwa et al., 2019). 모든 메서드-데이터 세트 조합에 대한 학습률을 조정합니다. 사용된 하이퍼파라미터에 대한 자세한 내용은 섹션 D.4를 참조하십시오. 접두사-임베딩 튜닝을 위한 최적의 \(l_{p}\)과 \(l_{i}\)은 각각 256과 8이며, 훈련 가능한 파라미터는 총 \(3.2M\)이다. 접두사 계층 튜닝은 \(l_{p}=8\)과 \(l_{i}=8\)을 사용하였으며, \(20.2M\) 훈련 가능한 파라미터를 사용하여 최적의 성능을 얻었다. LoRA에 대한 두 가지 매개변수 예산은 4.7M (\(r_{q}=r_{v}=1\) 또는 \(r_{v}=2\))과 37.7M (\(r_{q}=r_{v}=8\) 또는 \(r_{q}=r_{k}=r_{v}=r_{o}=2\))이다. 각 실행에서 최상의 유효성 검사 성능을 보고합니다. GPT-3 실험에 사용된 훈련 하이퍼파라미터는 표 12에 나열되어 있다.

## Appendix E Combination LoRA with Prefix Tuning

LoRA는 기존의 프리픽스 기반 접근법들과 자연스럽게 결합될 수 있다. 이 섹션에서는 LoRA와 WikiSQL 및 MNLI에서 접두사 튜닝의 두 가지 조합을 평가한다.

**LoRA + PrefixEmbed (LoRA + PE)** 는 LoRA와 prefix-embedding 튜닝을 결합 하 여 임베딩이 훈련 가능한 매개 변수로 처리 되는 \(l_{p}+l_{i}\) 특수 토큰을 삽입 합니다. 접두사-임베딩 튜닝에 대한 자세한 내용은 섹션 5.1을 참조하십시오.

**LoRA + PrefixLayer (LoRA + PL)** 는 LoRA와 prefix-layer 튜닝을 결합 합니다. 우리는 또한 \(l_{p}+l_{i}\)개의 특별한 토큰들을 삽입한다; 그러나, 이러한 토큰들의 숨겨진 표현들이 나타를 진화하게 하는 대신에.

\begin{table}
\begin{tabular}{l l|c c c c c c c} \hline \hline Method & Dataset & MNLI & SST-2 & MRPC & CoLA & QNLI & QQP & RTE & STS-B \\ \hline \multirow{8}{*}{DeBERTa XXL LoRA} & Optimizer & \multicolumn{8}{c}{AdamW} \\  & Warmup Ratio & \multicolumn{8}{c}{0.1} \\  & LR Schedule & \multicolumn{8}{c}{Linear} \\ \hline \multirow{4}{*}{DeBERTa XXL} & Batch Size & 8 & 8 & 32 & 4 & 6 & 8 & 4 & 4 \\  & \# Epochs & 5 & 16 & 30 & 10 & 8 & 11 & 11 & 10 \\  & Learning Rate & 1E-04 & 6E-05 & 2E-04 & 1E-04 & 1E-04 & 1E-04 & 2E-04 & 2E-04 \\  & Weight Decay & 0 & 0.01 & 0.01 & 0 & 0.01 & 0.01 & 0.1 \\  & CLS Dropout & 0.15 & 0 & 0 & 0.1 & 0.1 & 0.2 & 0.2 & 0.2 \\  & LoRA Config. & \multicolumn{8}{c}{\(r_{q}=r_{v}=8\)} \\  & LoRA \(\alpha\) & \multicolumn{8}{c}{8} \\  & Max Seq. Len. & 256 & 128 & 128 & 64 & 512 & 320 & 320 & 128 \\ \hline \hline \end{tabular}
\end{table}
표 10: GLUE 벤치마크에 포함된 태스크에 대한 DeBERTa XXL에 대한 하이퍼파라미터.

\begin{table}
\begin{tabular}{l|c c c} \hline \hline Dataset & E2E & WebNLG & DART \\ \hline \multicolumn{4}{l}{Training} \\ \hline Optimizer & \multicolumn{4}{c}{AdamW} \\ Weight Decay & 0.01 & 0.01 & 0.0 \\ Dropout Prob & 0.1 & 0.1 & 0.0 \\ Batch Size & \multicolumn{4}{c}{8} \\ \# Epoch & \multicolumn{4}{c}{5} \\ Warmup Steps & \multicolumn{4}{c}{500} \\ Learning Rate Schedule & \multicolumn{4}{c}{Linear} \\ Label Smooth & 0.1 & 0.1 & 0.0 \\ Learning Rate & \multicolumn{4}{c}{0.0002} \\ Adaptation & \multicolumn{4}{c}{\(r_{q}=r_{v}=4\)} \\ LoRA \(\alpha\) & \multicolumn{4}{c}{32} \\ \hline \multicolumn{4}{c}{Inference} \\ \hline Beam Size & \multicolumn{4}{c}{10} \\ Length Penalty & 0.9 & 0.8 & 0.8 \\ no repeat ngram size & \multicolumn{4}{c}{4} \\ \hline \hline \end{tabular}
\end{table}
표 11: E2E, WebNLG 및 DART 상의 GPT-2 LoRA에 대한 하이퍼파라미터.

모든 변압기 블록을 입력 불가지론 벡터로 교체합니다. 따라서, 임베딩 및 후속 트랜스포머 블록 활성화는 모두 트레이닝 가능한 파라미터로서 취급된다. 접두사 계층 튜닝에 대한 자세한 내용은 섹션 5.1을 참조하십시오.

표 15에서 우리는 위키SQL과 MultiNLI에 대한 LoRA+PE와 LoRA+PL의 평가 결과를 보여준다. 우선, LoRA+PE는 위키SQL에서 LoRA와 프리픽스-임베딩 튜닝을 모두 유의하게 능가하며, 이는 LoRA가 프리픽스-임베딩 튜닝과 다소 직교함을 나타낸다. MultiNLI에서 LoRA+PE의 조합은 LoRA보다 더 잘 수행되지 않는데, 아마도 LoRA 자체가 이미 인간 기준선에 필적하는 성능을 달성했기 때문일 수 있다. 둘째, LoRA+PL이 더 많은 훈련 가능한 매개변수를 사용하여도 LoRA보다 약간 더 나쁜 성능을 보인다는 것을 알 수 있다. 우리는 프리픽스 계층 튜닝이 학습률의 선택에 매우 민감하여 LoRA+PL에서 LoRA 가중치의 최적화가 더 어려워진다는 사실에 기인한다.

## 부록 F 추가 경험 실험

### GPT-2 추가 실험

또한, Li&Liang(2021)의 설정에 따라 DART(Nan et al., 2020) 및 WebNLG(Gardent et al., 2017)에 대한 실험을 반복한다. 결과는 표 13에 나와 있다. 섹션 5에 보고된 E2E NLG 챌린지에 대한 우리의 결과와 유사하게 LoRA는 동일한 수의 훈련 가능한 매개변수가 주어지면 접두사 기반 접근법보다 더 잘 또는 적어도 온-파르를 수행한다.

\begin{table}
\begin{tabular}{l c|c c c} \hline \hline Method & \# Trainable & \multicolumn{3}{c}{DART} \\  & Parameters & BLEU\(\uparrow\) & MET\(\uparrow\) & TER\(\downarrow\) \\ \hline \multicolumn{5}{c}{GPT-2 Medium} \\ Fine-Tune & 354M & 46.2 & **0.39** & **0.46** \\ Adapter\({}^{\text{L}}\) & 0.37M & 42.4 & 0.36 & 0.48 \\ Adapter\({}^{\text{L}}\) & 11M & 45.2 & 0.38 & **0.46** \\ FT\({}^{\text{Top2}}\) & 24M & 41.0 & 0.34 & 0.56 \\ PrefLayer & 0.35M & 46.4 & 0.38 & **0.46** \\ LoRA & 0.35M & **47.1\(\pm\)**2.2 & **0.39** & **0.46** \\ \hline \multicolumn{5}{c}{GPT-2 Large} \\ Fine-Tune & 774M & 47.0 & **0.39** & 0.46 \\ Adapter\({}^{\text{L}}\) & 0.88M & 45.7\(\pm\).1 & 0.38 & 0.46 \\ Adapter\({}^{\text{L}}\) & 23M & 47.1\(\pm\).1 & **0.39** & **0.45** \\ PrefLayer & 0.77M & 46.7 & 0.38 & **0.45** \\ LoRA & 0.77M & **47.5\(\pm\)**1.0 & **0.39** & **0.45** \\ \hline \hline \end{tabular}
\end{table}
표 13: DART 상에서 상이한 적응 방법을 갖는 GPT-2. MET 및 TER의 분산은 모든 적응 접근법에서 \(0.01\) 미만이다.

\begin{table}
\begin{tabular}{l|c c c c c c} \hline \hline Hyperparameters & Fine-Tune & PreEmbed & PreLayer & BitFit & Adapter\({}^{\text{H}}\) & LoRA \\ \hline Optimizer & \multicolumn{5}{c}{AdamW} \\ Batch Size & \multicolumn{5}{c}{128} \\ \# Epoch & \multicolumn{5}{c}{2} \\ Warmup Tokens & \multicolumn{5}{c}{250,000} \\ LR Schedule & \multicolumn{5}{c}{Linear} \\ \hline Learning Rate & 5.00E-06 & 5.00E-04 & 1.00E-04 & 1.6E-03 & 1.00E-04 & 2.00E-04 \\ \hline \hline \end{tabular}
\end{table}
표 12: 상이한 GPT-3 적응 방법에 사용되는 트레이닝 하이퍼파라미터. 학습률을 튜닝한 후 모든 데이터 세트에 대해 동일한 하이퍼파라미터를 사용한다.

### GPT-3 추가 실험

표 15에 다른 적응 방법을 사용하여 GPT-3에 대한 추가 실행을 제시한다. 성능 및 훈련 가능한 매개변수 수 간의 균형을 식별하는 데 중점을 둔다.

### Low-Data Regime

저데이터 체제에서 다양한 적응 접근법의 성능을 평가한다. 낮은 데이터 MNLI-\(n\) 태스크를 형성하기 위해 MNLI의 전체 트레이닝 세트에서 무작위로 100, 1k 및 10k 트레이닝 예제를 샘플링한다. 표 16에서 우리는 MNLI-\(n\)에 대한 다양한 적응 접근법의 성능을 보여준다. 놀랍게도, PrefixEmbed와 PrefixLayer는 MNLI-100 데이터셋에서 매우 저조한 성능을 보이며, PrefixEmbed는 랜덤 확률(37.6% vs. 33.3%)보다 약간만 더 나은 성능을 보인다. PrefixLayer는 PrefixEmbed보다 성능이 우수하지만, MNLI-100에서는 Fine-Tune이나 LoRA보다 성능이 현저히 떨어진다. Prefix 기반 접근법과 LoRA/Fine-tuning의 차이는 훈련 예제의 수가 증가함에 따라 작아지며, 이는 GPT-3에서 prefix 기반 접근법이 저 데이터 작업에 적합하지 않음을 시사한다. LoRA는 MNLI-100과 MNLI-Full 모두에서 Fine-tuning보다 성능이 우수하며, 랜덤 시드로 인한 (\(\pm 0.3\)) 분산을 고려할 때 MNLI-1k와 MNLI-10K에서 유사한 결과를 얻을 수 있다.

MNLI-n에 대한 다양한 적응 접근법의 훈련 하이퍼파라미터는 표 17에 보고되어 있다. 우리는 MNLI-100 집합의 PrefixLayer에 대해 더 작은 학습률을 사용하는데, 이는 더 큰 학습률과 함께 훈련 손실이 감소하지 않기 때문이다.

## 부록 G Subspaces 간의 유사성 측정

본 논문에서는 \(A\)와 \(B\)의 왼쪽 특이행렬의 열을 취하여 얻어진 두 열 직교행렬 \(U_{A}^{i}\in\mathbb{R}^{d\times i}\)과 \(U_{B}\in\mathbb{R}^{d\times j}\) 사이의 부분공간 유사성을 측정하기 위해 \(\phi(A,B,i,j)=\psi(U_{A}^{i},U_{B}^{j})=\frac{\|U_{A}^{j}U_{B}\|_{2}^{2}}{\min \{i,j\}\)을 이용한다. 우리는 이러한 유사성이 단순히 Ham & Lee (2008)의 부분 공간 사이의 거리를 측정하는 표준 투영 계량의 반대라고 지적한다.

\begin{table}
\begin{tabular}{l|c c c|c c c|c c c} \hline \hline Method & \multicolumn{8}{c}{WebNLG} \\  & \multicolumn{3}{c}{BLEU\(\uparrow\)} & \multicolumn{3}{c}{MET\(\uparrow\)} & \multicolumn{3}{c}{TER\(\downarrow\)} \\  & U & S & A & U & S & A & U & S & A \\ \hline \multicolumn{10}{c|}{GPT-2 Medium} \\ Fine-Tune (354M) & 27.7 & **64.2** & 46.5 &.30 & **.45** &.38 &.76 & **.33** &.53 \\ Adapter\({}^{\text{L}}\) (0.37M) & 45.1 & 54.5 & 50.2 &.36 &.39 &.38 &.46 &.40 &.43 \\ Adapter\({}^{\text{L}}\) (11M) & **48.3** & 60.4 & 54.9 & **.38** &.43 & **.41** & **.45** &.35 & **.39** \\ FT\({}^{\text{Top2}}\) (24M) & 18.9 & 53.6 & 36.0 &.23 &.38 &.31 &.99 &.49 &.72 \\ Prefix (0.35M) & 45.6 & 62.9 & 55.1 & **.38** &.44 & **.41** &.49 &.35 &.40 \\ LoRA (0.35M) & 46.7\({}_{\pm 4}\) & 62.1\({}_{\pm 2}\) & **55.3\({}_{\pm 2}\)** & **.38** &.44 & **.41** &.46 & **.33** & **.39** \\ \hline \multicolumn{10}{c|}{GPT-2 Large} \\ Fine-Tune (774M) & 43.1 & 65.3 & 55.5 &.38 & **.46** &.42 &.53 &.33 &.42 \\ Adapter\({}^{\text{L}}\) (0.88M) & **49.8\({}_{\pm 0}\)** & 61.1\({}_{\pm 0}\) & 56.0\({}_{\pm 0}\) &.38 &.43 &.41 & **.44** &.35 &.39 \\ Adapter\({}^{\text{L}}\) (23M) & 49.2\({}_{\pm 1}\) & 64.7\({}_{\pm 2}\) & **57.7\({}_{\pm 1}\)** & **.39** & **.46** & **.43** &.46 &.33 &.39 \\ Prefix (0.77M) & 47.7 & 63.4 & 56.3 & **.39** &.45 &.42 &.48 &.34 &.40 \\ LoRA (0.77M) & 48.4\({}_{\pm 3}\) & 64.0\({}_{\pm 3}\) & 57.0\({}_{\pm 1}\) & **.39** &.45 &.42 &.45 & **.32** & **.38** \\ \hline \hline \end{tabular}
\end{table}
표 14: WebNLG 상에서 상이한 적응 방법을 갖는 GPT-2. MET 및 TER의 분산은 우리가 실행한 모든 실험에서 \(0.01\) 미만이다. “U”는 보이지 않는 카테고리를 나타내고, “S”는 보이는 카테고리를 나타내며, “A”는 WebNLG의 테스트 세트 내의 모든 카테고리를 나타낸다.

구체적으로는 \(U_{A}^{i\top}U_{B}^{j}\)의 특이값을 \(\sigma_{1},\sigma_{2},\cdots,\sigma_{p}\)으로 하고, 여기서 \(p=\min\{i,j\}\)으로 한다. 우리는 Projection Metric Ham & Lee(2008)가 다음과 같이 정의된다는 것을 알고 있다:

\[d(U_{A}^{i},U_{B}^{j})=\sqrt{p-\sum_{i=1}^{p}\sigma_{i}^{2}}\in[0,\sqrt{p}]\]

\begin{table}
\begin{tabular}{l|c c c c} \hline \hline Method & MNFLI(m)-100 & MNLI(m)-1k & MNLI(m)-10k & MNLI(m)-392K \\ \hline GPT-3 (Fine-Tune) & 60.2 & **85.8** & 88.9 & 89.5 \\ GPT-3 (PrefixEmbed) & 37.6 & 75.2 & 79.5 & 88.6 \\ GPT-3 (PrefixLayer) & 48.3 & 82.5 & 85.9 & 89.6 \\ GPT-3 (LoRA) & **63.8** & 85.6 & **89.2** & **91.7** \\ \hline \hline \end{tabular}
\end{table}
표 16: GPT-3 175B를 사용하는 MNLI의 서브세트에 대한 상이한 방법의 검증 정확도. MNLI-\(n\)는 \(n\) 훈련 예제를 사용 하 여 하위 집합을 설명 합니다. 전체 유효성 검사 세트로 평가합니다. LoRA는 미세 조정을 포함한 다른 방법에 비해 유리한 샘플 효율성을 보인다.

\begin{table}
\begin{tabular}{l|c|c|c|c} \hline \hline Method & Hyperparameters & \# Trainable Parameters & WikiSQL & MNLI-m \\ \hline Fine-Tune & - & 175B & 73.8 & 89.5 \\ \hline \multirow{4}{*}{PrefixEmbed} & \(l_{p}=32,l_{i}=8\) & 0.4 M & 55.9 & 84.9 \\  & \(l_{p}=64,l_{i}=8\) & 0.9 M & 58.7 & 88.1 \\  & \(l_{p}=128,l_{i}=8\) & 1.7 M & 60.6 & 88.0 \\  & \(l_{p}=256,l_{i}=8\) & 3.2 M & 63.1 & 88.6 \\  & \(l_{p}=512,l_{i}=8\) & 6.4 M & 55.9 & 85.8 \\ \hline \multirow{4}{*}{PrefixLayer} & \(l_{p}=2,l_{i}=2\) & 5.1 M & 68.5 & 89.2 \\  & \(l_{p}=8,l_{i}=0\) & 10.1 M & 69.8 & 88.2 \\  & \(l_{p}=8,l_{i}=8\) & 20.2 M & 70.1 & 89.5 \\  & \(l_{p}=32,l_{i}=4\) & 44.1 M & 66.4 & 89.6 \\  & \(l_{p}=64,l_{i}=0\) & 76.1 M & 64.9 & 87.9 \\ \hline \multirow{4}{*}{AdapterH} & \(r=1\) & 7.1 M & 71.9 & 89.8 \\  & \(r=4\) & 21.2 M & 73.2 & 91.0 \\  & \(r=8\) & 40.1 M & 73.2 & 91.5 \\  & \(r=16\) & 77.9 M & 73.2 & 91.5 \\  & \(r=64\) & 304.4 M & 72.6 & 91.5 \\ \hline \multirow{4}{*}{LoRA} & \(r_{v}=2\) & 4.7 M & 73.4 & **91.7** \\  & \(r_{q}=r_{v}=1\) & 4.7 M & 73.4 & 91.3 \\  & \(r_{q}=r_{v}=2\) & 9.4 M & 73.3 & 91.4 \\  & \(r_{q}=r_{k}=r_{v}=r_{o}=1\) & 9.4 M & 74.1 & 91.2 \\  & \(r_{q}=r_{v}=4\) & 18.8 M & 73.7 & 91.3 \\  & \(r_{q}=r_{v}=8\) & 37.7 M & 73.8 & **91.6** \\  & \(r_{q}=r_{k}=r_{v}=r_{o}=4\) & 37.7 M & 74.0 & **91.7** \\  & \(r_{q}=r_{v}=64\) & 301.9 M & 73.6 & 91.4 \\  & \(r_{q}=r_{k}=r_{v}=r_{o}=64\) & 603.8 M & 73.9 & 91.4 \\ \hline \multirow{4}{*}{LoRA+PE} & \(r_{q}=r_{v}=8,l_{p}=8,l_{i}=4\) & 37.8 M & 75.0 & 91.4 \\  & \(r_{q}=r_{v}=32,l_{p}=8,l_{i}=4\) & 151.1 M & **75.9** & 91.1 \\  & \(r_{q}=r_{v}=64,l_{p}=8,l_{i}=4\) & 302.1 M & **76.2** & 91.3 \\ \hline LoRA+PL & \(r_{q}=r_{v}=8,l_{p}=8,l_{i}=4\) & 52.8 M & 72.9 & 90.2 \\ \hline \hline \end{tabular}
\end{table}
표 15: WikiSQL 및 MNLI에 대한 상이한 적응 접근법의 하이퍼파라미터 분석. Prefix-embedding tuning (PrefixEmbed)과 prefix-layer tuning (PrefixLayer)은 훈련 가능한 파라미터의 수가 증가함에 따라 성능이 저하되는 반면 LoRA의 성능은 안정화된다. 성능은 검증 정확도로 측정됩니다.

[MISSING_PAGE_FAIL:24]

### Amplification Factor

특징 증폭률(feature amplification factor)은 자연히 _ratio_\(\frac{\|\Delta W\|_{F}}{\|U^{\top}W^{\top}\|_{F}}\)으로 간주할 수 있으며, 여기서 \(U\)과 \(V\)은 \(\Delta W\)의 SVD 분해의 좌우 단일 행렬이다. (Recall \(UU^{\top}WV^{\top}V\)는 \(\Delta W\)에 의해 스팬된 부분공간에 \(W\)의 "투영"을 제공한다.)

직관적으로, \(\Delta W\)이 대부분 작업별 방향을 포함할 때, 이 양은 이들 중 \(\Delta W\)에 의해 증폭되는 양을 측정한다. 섹션 7.3에서 볼 수 있듯이 \(r=4\)의 경우 이 증폭 계수는 20만큼 크다. 즉, 각 레이어에는 (일반적으로 말해서) 4개의 특징 방향이 있는데, 이는 다운스트림 특정 작업에 대해 보고된 정확도를 달성하기 위해 매우 큰 요인 20으로 증폭되어야 한다. 그리고, 각각의 상이한 다운스트림 태스크에 대해 매우 상이한 피처 방향들의 세트가 증폭될 것으로 예상해야 한다.

그러나 \(r=64\)의 경우 이 증폭률은 약 2에 불과하며, 이는 \(r=64\)이 있는 \(\Delta W\)에서 학습한 _대부분의_ 방향이 _많이 증폭되지 않음_을 의미한다. 이것은 놀라운 일이 아니어야 하며 실제로 "작업별 방향"(모델 적응을 위해)을 나타내기 위해 고유 순위 _필요_가 낮다는 증거를 제공한다. 대조적으로, 순위-4 버전의 \(\Delta W\)(\(r=4\)에 해당)의 방향은 훨씬 더 큰 요인 20에 의해 증폭된다.

그림 6: 96층 변압기에서 1, 32, 64, 96층의 \(\Delta W_{q}\)과 \(\Delta W_{v}\)에 대한 \(A_{r=8}\)과 \(A_{r=64}\)의 열 벡터 사이의 정규화된 부분 공간 유사성.

\begin{table}
\begin{tabular}{c|c c c c c c} \hline Rank \(r\) & val\_loss & BLEU & NIST & METEOR & ROUGEL & CIDEr \\ \hline
1 & 1.23 & 68.72 & 8.7215 & 0.4565 & 0.7052 & 2.4329 \\
2 & 1.21 & 69.17 & 8.7413 & 0.4590 & 0.7052 & 2.4639 \\
4 & 1.18 & **70.38** & **8.8439** & **0.4689** & 0.7186 & **2.5349** \\
8 & 1.17 & 69.57 & 8.7457 & 0.4636 & **0.7196** & 2.5196 \\
16 & **1.16** & 69.61 & 8.7483 & 0.4629 & 0.7177 & 2.4985 \\
32 & **1.16** & 69.33 & 8.7736 & 0.4642 & 0.7105 & 2.5255 \\
64 & **1.16** & 69.24 & 8.7174 & 0.4651 & 0.7180 & 2.5070 \\
128 & **1.16** & 68.73 & 8.6718 & 0.4628 & 0.7127 & 2.5030 \\
256 & **1.16** & 68.92 & 8.6982 & 0.4629 & 0.7128 & 2.5012 \\
512 & **1.16** & 68.78 & 8.6857 & 0.4637 & 0.7128 & 2.5025 \\
1024 & 1.17 & 69.37 & 8.7495 & 0.4659 & 0.7149 & 2.5090 \\ \hline \end{tabular}
\end{table}
표 18: GPT-2 배지를 사용하여 상이한 순위 \(r\)를 갖는 LoRA에 의해 달성된 E2E NLG 챌린지에 대한 검증 손실 및 테스트 세트 메트릭. GPT-3이 많은 작업에 \(r=1\)이 충분한 것과 달리, 여기서 성능 피크는 검증 손실에 대해 \(r=16\)이고 BLEU에 대해 \(r=4\)이며, 이는 GPT-2 Medium이 GPT-3 175B와 유사한 적응 고유 순위를 갖는다는 것을 시사한다. 우리의 하이퍼파라미터 중 일부는 다른 기준선의 매개변수 수와 일치하는 \(r=4\)에 조정되므로 \(r\)의 다른 선택에는 최적이 아닐 수 있습니다.

그림 8: \(r\)과 무작위 기준선을 변화시키면서 \(W_{q}\)의 특이 방향과 \(\Delta W_{q}\)의 특이 방향 사이의 정규화된 부분 공간 유사성. \ (\Delta W_{q}\)는 \(W\)에서 강조되지 않지만 중요한 방향을 증폭한다. \ (\Delta W\)이 큰 \(r\)은 \(W\)에서 이미 강조된 방향을 더 많이 선택하는 경향이 있다.

그림 7: 96층 변압기에서 1, 32, 64, 96층의 \(\Delta W_{q}\)과 \(\Delta W_{v}\)에 대해 무작위로 시드된 두 번의 실행에서 \(A_{r=64}\)의 열 벡터 사이의 정규화된 부분 공간 유사성.
