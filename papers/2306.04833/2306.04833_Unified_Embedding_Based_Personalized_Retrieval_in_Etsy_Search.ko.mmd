[MISSING_PAGE_FAIL:1]

텍스트 기능을 기반으로 하는 것은 어려울 수 있습니다. 따라서 본 논문에서는 그래프, 변환기, 용어 기반 임베딩이 통합된 통합 임베딩 모델을 학습하여 이러한 모든 접근법의 장점을 최대한 활용하고 어휘 격차의 이중 문제를 해결하고 규모에서 개인화된 제품을 검색할 수 있는 방법을 제안한다.

전자 상거래 검색 시스템에서 텍스트 유사성을 넘어서는 또 다른 고려 사항은 질의(예를 들어, 평균 제품 리뷰)[16]와 무관한 고유한 제품 품질이다. 그러나 임베딩 기반 검색의 이전 작업은 제품 품질에 대한 명시적 모델링을 피하고 이러한 책임은 전적으로 후기 단계에 맡긴다. 종종, 특정 사용자로부터의 추가 컨텍스트에도 후속 레이어에 의해 효율적으로 재순위화될 수 있는 것보다 카탈로그에 더 의미적으로 관련된 제품이 있을 수 있다. 따라서, 최적의 검색 후보 세트를 생성하기 위해, 관련성이 희생되지 않는 한 품질을 고려하는 것이 유익하다. 이를 위해 내부 제품 점수와 결합할 때 품질과 관련성의 균형을 맞추기 위해 조정된 벡터로 기존 임베딩을 확장하는 _ANN 기반 제품 부스팅_을 제안한다. 본 논문에서는 블랙박스 최적화 기법을 이용하여 전역적으로 최적의 품질 가중치를 도출하여 현실적인 서비스 제약조건을 가지고 원하는 타겟 메트릭을 직접 최대화하는 방법을 제안한다.

본 논문에서는 개인화 상품 검색을 위한 통합 임베딩 기반 개인화 상품 검색(UPPER: Unified Embedding Based Personalized Product Retrieval) 시스템의 학습 및 구현에 대해 기술한다. 우리는 오프라인 평가와 라이브 A/B 테스트를 통해 헤드 쿼리와 테일 쿼리 모두에 대한 이러한 시스템의 효과를 보여준다. 우리의 기여는 다음과 같이 요약할 수 있다.

i) 다양한 검색 질의를 처리하기 위해 통합 임베딩 기반 제품 인코더와 전자 상거래 웹사이트에 배포된 공동 사용자 질의 인코더를 가진 새로운 2타워 모델을 제시한다.

ii) 학습 중 하드 네거티브 마이닝, 제품 텍스트 특징 표현에 사용되는 언어 모델에 대한 사전 학습 전략 및 손실 함수 및 이러한 모델을 학습하기 위한 학습 데이터 생성 접근법과 같은 다른 설계 선택을 포함하는 새로운 학습 전략을 공유한다.

iii) 절제 연구를 사용하여, 다양한 사용자, 제품 및 질의 특징을 인코딩하기 위한 다양한 특징 인코더 및 엔지니어링 트릭을 사용하는 데 있어서 우리의 학습을 공유한다.

iv) 리스팅 품질 점수에 기초하여 후보들의 재순위화를 위한 _ANN-Based Product Boosting_의 새로운 접근법.

## 2. 관련 작업

최근 들어, 심층 학습 기술은 정보 검색(IR: Information Retrieval) 시스템, 특히 신경 증강 어휘 검색에 널리 적용되고 있다. 이러한 기법들은 표현 모델들(예를 들어, DSSM[13] 및 CLSM[26]) 및 질의-문서 상호작용 모델들(예를 들어, MatchPyramid[23] 및 Match-SRNN[27])로 분류될 수 있다.

대부분의 전자 상거래 검색 시스템은 임베딩 기반 검색(EBR)을 위해 ANN을 갖는 투타워 아키텍처를 채용한다([22], [11], [20], [29], [18]. Nigam, Song et al(22)은 단어 임베딩과 범주형 제품 특징 임베딩의 얕은 텍스트 백을 활용했다. 최근의 연구는 EBR 모델들의 표현 능력을 개선하고자 했다([2][4]). 개인화된 모델은 사용자 동작 및 프로파일 특징을 통합하여 특정 사용자에 대한 후보를 더 잘 맞춤화한다[32][18]. 그래프 기반 임베딩에 의해 강화된 모델[9][28]은 별개의 엔티티들 사이의 알려진 관계를 활용함으로써 순수 내용 기반 모델들을 개선한다[19][34]. 따라서, 우리는 통합 표현의 일부로 이분 그래프 부호화를 사용한다.

사전 훈련된 트랜스포머 기반 언어 모델[17][35][14]은 문맥화된 용어 표현[10] 및 더 깊은 의미론적 이해를 가능하게 함으로써 얕은 비순서형 용어 임베딩 시 개선된다(그러나, 증가된 모델링 용량은 대기 시간[5]의 비용을 초래하고, 강화된 언어 이해는 짧고 문맥이 부족한 전자 상거래 질의에 덜 이점을 제공할 수 있다.

_Hard Negative Sampling_은 Hard Negative를 통합하여 dense 검색 모델의 학습 향상에 초점을 맞춘 활발한 연구의 영역이다. [30] 밀집 검색 모델의 학습을 최적화하기 위해 하드 네거티브 샘플을 사용하는 접근법을 제안했다. 유사하게, [33]은 밀집 텍스트 검색을 위한 근사 최근접 이웃 네거티브 대조적 학습을 제안하였다. 이러한 방법들은 검색 성능을 크게 향상시켰다. 페이스북은 EBR 모델[11]에서 하드 네거티브 마이닝을 위한 트릭과 랜덤 네거티브와 결합하는 이점을 소개했다.

요약하면, 딥러닝 기술은 IR 시스템의 정확성과 효율성을 향상시키는 데 큰 잠재력을 보여주었다. 위에서 언급한 작업은 의미 관계 모델링, 개인화 및 검색 모델의 훈련 개선을 포함하여 IR의 다양한 문제를 해결하는 데 다양한 딥 러닝 기술의 효과를 보여준다.

## 3. Architecture

본 논문에서 제안하는 통합 임베딩 기반 개인화 상품 검색(UPPER) 시스템은 Etsy의 다양한 다중 채널 검색 시스템의 필수적인 부분으로서, 사용자 선호도를 고려하면서 의미적으로 관련된 상품을 선택할 수 있도록 설계되었다. 그림 2와 3은 본 시스템의 워크플로우에 대한 개요를 제공한다. Etsy에서 사용자 검색 질의가 수신되면, 본 시스템은 질의, 사용자 프로파일, 히스토리 특징을 검색하고, 이를 신경망 검색 엔진에 전달하여 질의 추론 및 ANN 룩업을 수행한다. 본 시스템은 크게 세 가지 구성 요소로 구성된다. 섹션 4에 설명된 **UPPER** 모델은 공동으로 훈련된 쿼리 사용자 및 제품 타워를 강조 표시합니다. ii) 섹션 5에 소개 된 **ANN 제품 부스팅** 은 ANN에서 블랙 박스 최적화 기술을 사용 하 여 고품질 제품을 선택 하는 것을 목표로 합니다. iii) **온라인 서빈

도 2. UPPER의 베이스 아키텍처

섹션 6은 산업 규모에서 모델 배치를 다루기 위한 우리의 접근법을 설명한다.

## 4. 통합 임베딩 모델

제안된 2-타워 UPPER 모델은 제품 인코더 \(\mathcal{P}\)와 공동 질의 사용자 인코더 \(\mathcal{Q}\)로 구성된다. 주어진 쿼리 \(q\), 사용자 \(u\)에 대해 다음과 같이 주어진 제품 \(p\)에 대한 개인화된 의미 점수 \(y\)를 계산합니다.

\[y=cos(\mathcal{P}(p),\mathcal{Q}(q,u)) \tag{1}\]

여기서 \(\mathcal{P}(p)\)와 \(\mathcal{Q}(q,u)\)은 모두 d차원 벡터이다. 유사함수로 코사인을 사용하는 방법은 두 개의 타워를 독립적으로 유지하고 ANN을 통해 오프라인 인덱싱과 효율적인 서빙을 할 수 있기 때문에 효율성을 기반으로 한다. \(\mathcal{P}\) 및 \(\mathcal{Q}\)의 표현은 관련 기능을 나타내는 데 사용되는 구성 인코더를 풀링한 결과입니다. 우리의 목표는 검색 성능을 효과적으로 측정하기 때문에 문헌에서 널리 사용되는 메트릭인 Recall@K를 최대화하는 것이다. 이 절에서는 제안된 UPPER 모델의 아키텍처 세부 사항과 피처 엔지니어링의 주요 설계 선택을 제시한다. 먼저 제품 인코더의 디자인에 대해 설명한 후 두 타워 간의 공유 인코더에 대해 설명합니다. 이어서, 공동 질의-사용자 인코더에 대한 포괄적인 개요를 제공한다.

또한, \(\mathcal{P}\)과 \(\mathcal{Q}\)의 성공적인 오프라인 교육에 중요한 접근 방법을 탐구한다. 여기에는 새로운 손실 함수, 언어 모델에 사용되는 사전 훈련 전략, 레이블이 지정된 데이터를 생성하기 위해 검색 로그에서 양성을 마이닝하는 기술 및 동적 하드 네거티브를 마이닝하는 방법이 포함된다.

### Product Encoder

그림 2(오른쪽)에서는 제품의 다양한 보완적인 측면을 포착하기 위해 통합 임베딩 모델로 설계된 제품 인코더 \(\mathcal{P}\)를 제시한다. 이 인코더에서 얻은 제품 표현은 연접을 통해 풀링되고 최종 제품 표현을 얻기 위해 피드포워드 네트워크 및 배치 정규화의 연속 계층을 사용하여 추가로 투영된다. 이 섹션에서는 중요한 제품 기능을 인코딩하는 데 전념하는 인코더와 사용된 관련 기능 엔지니어링 기술에 대해 설명한다.

#### 4.1.1. 트랜스포머 기반 표현

트랜스포머의 컨텍스트 표현은 제목 및 태그와 같은 텍스트 특징으로부터 중요한 토큰에 대한 제품 표현을 편향시키는 데 도움이 될 수 있다. 그러나 본 연구 결과는 널리 사용되는 두 개의 텍스트 인코더인 distilBERT(Zhu et al., 2017)와 T5(Zhu et al., 2017)의 인코더 부분을 미세 조정하는 것이 오프라인 개선을 나타내지 않았음을 나타낸다. 이는 대기 시간 고려 사항으로 인해 쿼리 타워에 동일한 변압기가 없는 비대칭 아키텍처에 기인할 수 있습니다. 그 후, docT5query(Chen et al., 2018)의 영향을 받은 사전 훈련 접근법을 사용했다. 이 전략에서 우리는 제품 텍스트를 기반으로 가장 역사적으로 구매한 쿼리를 생성하기 위해 T5 소형 모델을 훈련하고 인코더를 활용했다. 우리의 가설은 이 접근법이 제품 제목/태그와 같은 중요한 측면에 대한 모델의 이해도를 향상시킬 것이라는 것이다.

#### 4.1.2. 이분 그래프 인코더

이분 그래프 기반 임베딩(Han et al., 2017)을 사용하여 과거 검색을 기반으로 관련 있는 쿼리 용어와 제품 콘텐츠 간의 의미적 격차를 효과적으로 해결한다. 제품-질의 그래프를 구성하기 위해 쿼리와 제품 간의 긍정적인 상호 작용을 포함하는 1년 동안의 검색 로그를 활용한다. 학습하는 동안 그래프에서 주어진 제품에 대한 쿼리를 샘플링하고 쿼리 타워와 공유되는 매개 변수를 사용하여 인코딩합니다. 단일 홉 그래프 임베딩을 얻기 위해 질의 임베딩에 대한 평균 풀링을 사용한다. 일반화를 보장하기 위해 샘플링된 이웃 집합에서 대상 쿼리를 제외한다. 또한 공유 매개변수가 과적합으로 이어진다는 것을 발견했으며, 이는 여러 개입으로 해결했으며 그래프 인코더로 인해 공유 매개변수 업데이트가 단순히 동결되는 것이 최상의 성능으로 이어진다는 것을 발견했다.

### Shared Encoders

#### 4.2.1. 토큰 및 ID Embeddings

쿼리와 제품에는 각각 토큰 필드 \(F_{q}\) 및 \(F_{p}\) 집합이 포함됩니다. 각 토큰 필드 \(f\)는 원시 입력에서 파생된 정렬되지 않은 토큰 백으로 구성됩니다. (Zhu 등, 2017)에서와 같이 텍스트 필드에서 유니그램, 바이그램 및 문자 트리그램을 추출한다. 또한 각 계층(예: #category_furniture, #category_furniture.bedroom 등)에서 제품 카테고리를 추출한다. 색상 또는 재료와 같은 제품 속성의 경우 각 키/값 쌍(예: #attr_color_red)에 대한 토큰을 추출하고 판매자가 임의 값을 입력할 수 있는 속성에 대한 텍스트 n-gram을 추출합니다.

이 제품과 쿼리 인코더는 모두 토큰 임베딩의 간단한 평균을 통해 \(N_{t}(F)\) 총 토큰을 포함하는 필드 집합을 인코딩하기 위해 평균 임베딩 계층을 사용합니다.

\[\text{avg}(F)=\frac{1}{N_{t}(F)}\sum_{f\in F}\sum_{t\in f}E[t] \tag{2}\]

초기에는 토큰_rep\((p)=\text{avg}(F_{p})\)로 표현되는 질의 사용자 타워와 제품의 토큰 입력 계층에 대한 평균 임베딩 방법을 사용하였다. 그러나 특정 새로운 필드, 특히 제품 설명에서 추출된 키워드와 같은 노이즈 필드를 통합하면 모델 성능이 저하될 수 있음을 관찰했다. 이를 해결하기 위해 필드를 \(F^{1}_{p},F^{2}_{p},...\)로 표시된 별개의 그룹으로 분할했다. (예를 들어, 설명 토큰을 배타적으로 포함하는 하나의 그룹). 그런 다음 각 그룹의 평균 임베딩을 연결하여 업데이트된 토큰 표현 토큰_rep\((p)=\text{concat}([\text{avg}(F^{1}_{p});\text{avg}(F^{2}_{p}),...])\을 생성했다.

#### 4.2.2. Location Encoder

(Zhu 등, 2017)에서와 같이, 우리는 질의 및 리스팅 타워에서 각각 사용자 위치 및 리스팅 위치 특징 모두를 통합한다. 언어, 국가 및 우편 번호를 내장하고 위도/경도 및 우편 번호를 모두 사용하여 여러 수준의 세분성에서 위치를 추가로 설명한다. 고객 위도/경도 좌표에 대한 K-means 클러스터링을 수행하고, k(50,100,500) 값이 다른 사용자 및 리스팅에 대한 위치 버킷 ID를 추출한다. 또한 접두사가 인접한 지리적 영역에 해당하므로 우편 번호의 접두사를 추출하여 대략적인 지리적 영역을 캡처한다(예: "54321"은 "5", "54" 등). 우리는 우편번호와 위치 버킷이 모델 성능 측면에서 비중복적이라는 것을 발견했는데, 이는 아마도 근접성에 대한 다소 다른 개념을 포착하기 때문일 수 있다(예를 들어, k-평균 클러스터는 인구 밀도에 대한 의존성으로 인해 지리적 범위의 큰 변동성을 가질 수 있는 반면 우편번호는 크기가 더 균일한 경향이 있다). 모든 위치 특징을 함께 사용하여 국내 사용자의 구매 회수율에서 8%의 상대적 이득을 관찰했다.

### Joint Query-User Encoder

그림 2에서 왼쪽에 있는 조인트 타워의 아키텍처를 설명 합니다. 쿼리 텍스트를 표시 하기 위해 섹션 4.2.1에 설명 된 대로 경량 토큰 인코더를 사용 합니다. 토큰 수준에서 이러한 매개 변수는 제품 제목/태그 및 그래프 인코더 간에 공유 됩니다. 또한, 사용자 위치를 나타내기 위해 앞서 설명한 위치 인코더를 사용한다. 또한, (Wang et al., 2017) 및 (Kang et al., 2017)과 유사한 다양한 이벤트 유형으로부터의 사용자 참여 이력을 통합한다. 특히 사용자의 최근 검색, 최근 상점 클릭, 최근 클릭된 항목의 용어 및 역대 구매 항목의 태그를 활용한다. 쿼리 사용자 타워에서 대기 시간을 최소화 하기 위해 4.2.1에 설명 된 대로 경량 토큰 임베딩 및 주의 메커니즘을 사용 하 여 최종 공동 쿼리에 통합 합니다. (Bang 등, 2017)에서 지적된 바와 같이, 모든 이력 사용자 액션이 현재 검색 세션과 동등하게 관련되지는 않으므로, 현재 쿼리와 관련하여 이벤트들을 가중시키고 개인화에서 사용자 이벤트들의 총 기여도를 제어하는데 유익할 수 있다. (Bang 등, 2018)과 유사하게, 우리의 쿼리-사용자 타워는 이벤트 레벨에서 적용된 경량 변압기를 사용하여 쿼리 및 사용자 액션으로부터 이력 임베딩을 생성한다. 특히, \([q,u_{s}^{1},...,u_{s}^{n},u_{t}^{c}]\)는 검색 질의이고, \(u_{s}\)은 사용자의 최근 검색 질의의 시퀀스이며, \(u^{c}\)은 사용자의 최근 클릭된 상점이다. \(u_{s}\)의 각 벡터는 질의 토큰 임베딩의 단순 평균이며, 각 벡터 \(u_{c}\)는 상점 ID 임베딩이다. 1층 트랜스포머는 지연시간에 거의 기여하지 않으며 오프라인 재현율을 2% 향상시킨다는 것을 알 수 있다.

### Negative Mining

우리의 네거티브 마이닝 전략은 네거티브 제품의 세 가지 차이 소스를 사용한다.

* _하드 배치 내 음성_: 배치 내 음성은 지정된 쿼리에 대해 음성으로 샘플링되는 배치의 다른 쿼리의 양성 제품입니다. 제품 및 쿼리 표현은 2개 타워 모델에서 독립적이므로 교차 인코더에서와 같이 다시 계산할 필요가 없습니다. 또한 주어진 쿼리에 대해 가장 유사한 배치 내 제품을 샘플링하여 모델이 _가장 단단한_ 예제에 집중할 수 있도록 탐색했으며 균일한 샘플링보다 더 잘 작동한다는 것을 발견했다.
* _균일 네거티브_: 또한, 우리는 또한 제품의 전체 코퍼스로부터 네거티브로서 균일하게 제품을 샘플링한다. 균일한 네거티브는 하드 네거티브에 상보적인 값을 제공하는데, 이는 하드 네거티브가 _하위 랭킹_ 성능을 돕는 반면 하드 네거티브는 상위 랭킹 성능을 돕기 때문이다(Wang et al., 2017). 또한 음성이 샘플링된 말뭉치의 크기가 성능에 영향을 미치고 배치 내 음성은 양의 생성물만 있기 때문에 음성의 다양성이 제한적이며 모델이 과잉 적합할 수 있음을 관찰했다.
* _대규모 배치로부터의 동적 하드 네거티브_: 트레이닝 동안 모델 파라미터에 관한 동적 네거티브, 즉 네거티브는 정적 네거티브에 비해 조밀한 검색 성능(Wang et al., 2017)을 향상시키는 것으로 나타났다. 동적 음수 샘플링에 대한 메모리 효율적인 접근법은 두 단계로 구성된다. 첫째, 제품 코퍼스에서 대량의 음성 샘플을 무작위로 샘플링하고 현재 모델 매개변수를 사용하여 가장 유사한 상위 K개의 제품을 선택하지만 모델 매개변수는 아직 업데이트하지 않는다. 초기 선택 후 _동적 하드 네거티브_ 는 모델 매개 변수를 업데이트 하는 데 사용 되는 부정적인 예제의 다른 원본과 결합 됩니다. 부정적인 예로 인한 손실은 각 마이닝 전략에서 개인의 가중 합이며 훈련 중에 가중치를 선형적으로 업데이트한다. 우리는 균일한 음성과 균일한 음성의 선형 감쇠 손실 중량만을 사용하여 워밍업 훈련을 하고 수렴과 성능에 이상적이라는 것을 발견했기 때문에 단단한 음성의 무게를 증가시킨다.

### Loss Function

문턱치 기반 가지치기는 검색 계층에서 널리 사용되는 접근법으로 관련 없는 후보들을 제거하기 위해 사용된다. 쌍별 손실 함수는 널리 사용되지만 임계값 기반 가지치기에는 적합하지 않다(Zhou et al., 2017). 우리의 접근법은 힌지 손실 프레임워크를 통합하여 모델 훈련 단계 자체 동안 임계값을 설정한다. 훈련 데이터는 서로 다른 종류의 상호작용 유형으로 구성되고 각 상호작용 유형은 서로 다른 관련성을 나타내기 때문에 각 부분이 서로 다른 임계값과 연관되는 다중 부분 힌지 손실을 사용한다. 출력 점수를 \(y\)로, 참 레이블을 \(\hat{y}\)로 지정하면 손실 함수는 다음과 같이 나타낼 수 있습니다.

\[L(y,\hat{y})=\left(\sum_{i\in I}\mathbb{I}[\hat{y}==i]\cdot(-\min(0,y-\epsilon _{i}))\right)+\mathbb{I}-\cdot max(0,y-\epsilon)\]

여기서 \(I\)은 모든 양의 상호작용으로 설정되고 \(\epsilon_{i}\)은 이에 대응하는 임계값이며 \(\mathbb{I}-\), \(\epsilon\)은 각각 음의 샘플에 대한 지표 변수 및 임계값이다.

## 5. Ann 기반 Product Boosting

쿼리에 대한 제품들의 후보 세트를 형성할 때, 쿼리와 의미적으로 관련되고 고객들에게 어필하는 후보들을 모두 검색하는 것이 유익하다. Etsy 내에서, 역색인 후보 검색 시스템은 질의 독립적인 "품질 점수" \(Q(p)\)와 제품을 연관시키고, 곱셈 부스팅을 사용하여 품질 점수와 질의 목록 관련성 점수의 곱으로 후보 점수를 계산한다 \(R(q,p)\), 또는 \(S(q,p)=R(q,p)Q(p)\). 이 품질 점수는 쿼리 나열 관련성과 독립적으로 참여를 증가시키는 것으로 알려진 높은 제품 등급, 제품 신선도 및 상점 전환율과 같은 속성을 설명할 수 있습니다.

본 논문에서는 신경망 기반 의미 검색에서 부가적인 부스팅(additive boosting)을 구현하기 위해 추가적인 수치 특징을 가진 모델 유래 제품 벡터를 풍부하게 하고 질의 벡터에 대응하는 특징 가중치를 추가한다. 원래의 곱 임베딩 \(p\)과 질의 임베딩 \(q\)을 고려하여 수화된 벡터 \(p^{\prime}=\text{concat}([p;f(p)])\)와 \(q^{\prime}=\text{concat}([q;w])\)를 생성한다. 여기서, \(f(p)\)은 수치적 특징의 특징 벡터이고, \(w\)은 동일한 차원의 상수 벡터이다. 그런 다음 후보 점수를 \(S(q^{\prime},p^{\prime})=\text{dot}(p^{\prime},q^{\prime})=\text{dot}(p,q)+ \text{dot}(f(p),w)\)로 모델링한다. 서빙을 위해 원본 제품 임베딩이 아닌 단순히 수화된 제품 벡터를 인덱싱하고, 수화된 쿼리 벡터로 인덱스를 쿼리한다.

원론적으로, 우리는 엔드 투 엔드 모델 훈련의 일부로 쿼리 측 특징 가중치를 직접 학습할 수 있다. 그러나 쿼리나 제목 텍스트와 같은 텍스트 기능에 비해 상점 인기와 같은 정적 품질 기능은 부정적인 샘플링 접근법에 민감하며 신중한 조정 없이 프록시 메트릭에 쉽게 과도하게 적합할 수 있으며 직접 리콜을 최적화하지 않는다. 그 대신에, 우리는 임의의 타겟 메트릭들을 직접적으로 최대화하는 쿼리 측 특징 가중치들을 식별하기 위해 블랙박스 최적화를 사용한다. 특히, Skopt(Bang et al., 2017)를 사용하여 베이지안 최적화를 수행하여 모델 학습 후 구매한 아이템에 대한 구매 회수를 최적화하는 쿼리 가중치를 학습한다.

[MISSING_PAGE_FAIL:5]

### Evaluation Methodology

* _오프라인 메트릭_ 검색 성능을 효과적으로 측정하기 때문에 문헌에서 널리 사용되는 메트릭인 Recall@K를 사용합니다. 본질적으로 질의 \(q\), 대상 관련 제품 집합 \(\mathcal{T}\) 및 상위 K 제품 집합 \(\mathcal{R}\): \[Recall@K=\frac{\sum_{t\in\mathcal{T}}\mathbb{I}(t\in\mathcal{R})}{|\mathcal{T}|}\].

또한 오프라인 Recall@K 메트릭은 사이트 전체 및 검색 전환율의 온라인 개선과 양의 상관관계가 있음을 관찰했다. 오프라인 평가를 위해 \(K\in\{100,1000\}\)을 사용한다.
* _훈련 및 평가 데이터_ 모든 플랫폼에서 지난 달의 데이터를 사용하여 검색 로그에서 카트드 및 구매와 같은 긍정적인 상호 작용을 마이닝하여 훈련 데이터를 만듭니다. 우리는 모델을 훈련시키기 위해 텐서플로우2.6을 사용했다. 우리는 MirroredStrategy를 사용하여 4개의 A100 GPU에서 모델을 훈련하고 모델이 수렴하는 데 약 72시간이 걸린다. 평가 중에 우리의 목표는 최신 일 훈련 데이터 이후의 일에서 구매를 회수할 수 있는 모델의 능력을 평가하는 것이다. 결과적으로, 학습 데이터 다음 날 발생하는 사용자 구매를 통합하는 샘플링된 검색 로그를 사용하여 평가 데이터 세트를 구성한다. 전반적으로, 우리는 구매가 있는 11k개의 고유한 쿼리로 구성된 각 날짜 데이터로 다음 5일 동안의 평가 데이터를 평균 보고한다.
* _Offline Baseline 모델_ _Base_ 라고 하는 기준 임베딩 기반 검색 모델은 얕고 대칭인 2타워 모델입니다. 이 모델은 원시 쿼리 텍스트와 제품의 제목 및 태그의 용어 임베딩을 통합한다. 섹션 4에 설명된 대로 다중 부분 힌지 손실을 사용하고 (Kumar et al., 2019)에서와 같이 전체 목록 카탈로그와 배치 내 양성에서 무작위로 음성을 선택한다. 또한, 본 논문에서 제안한 모델을 고튜닝된 사내 고전 역색인 및 랜덤워크 기반 검색기와 비교하여 질의 세그먼트에 대한 효율성을 입증한다.

### 오프라인 실험 결과

표 1에서 UPPER을 여러 강력한 기준선과 개별 구성 요소의 효능을 보여주는 자체 모델의 다양한 변형과 비교한다. 본 논문에서 제안하는 UPPER은 질의 세그먼트들 간의 집합에서 랜덤워크 기반 검색기와 역색인 검색기를 능가하는 반면, 머리 질의에서는 더 나쁘지만 꼬리 부분에서는 가장 좋은 비개인화 모델이 더 우수함을 알 수 있다. 쿼리 타워에 개인화를 추가 하면 헤드 쿼리의 성능이 다른 메서드와 크게 경쟁할 수 있습니다. **UPPER rand** 는 학습에서 무작위 및 일괄 처리 음수만 사용 하는 모델을 참조 합니다. 우리는 구매 리콜@100이 하드 네거티브 없이 7% 하락하는 것을 볼 수 있다. 또한, 표 2에서 우리는 세 가지 부정적인 마이닝 전략을 사용하는 것의 영향을 보여주는 삭제를 보여주고 세 가지 단단한 부정적인 마이닝 전략과 동적 손실 가중을 결합한다는 것을 보여준다. **업퍼 부스트** 는 제안된 ANN 기반 제품 부스트를 통합 하는 모델 변형을 참조 합니다. 표 1에서 부스팅은 리콜@100의 전반적인 이득으로 이어지며 가정된 바와 같이 잠재적으로 관련된 목록이 더 많은 꼬리보다 머리 쿼리에서 훨씬 더 중요한 개선으로 이어진다는 것을 알 수 있다.

표 1의 **큰 보컬** 변형 모델은 보컬 크기 및 더 많은 숨겨진 계층 측면에서 **베이스** 보다 개선 된 것입니다. 그래프 임베딩과 다른 변환기 및 용어 기반 표현을 추가할 때 성능의 현저한 향상을 특히 강조 하는 **큰 어휘** 에 추가 될 때 각 개별 인코더의 중요성을 보여 주는 표 3의 절제 연구를 공유 합니다.

#### 7.2.1. 위치 임베딩의 영향

우리의 위치 인식 모델은 사용자로부터 매우 멀리 떨어져 있는 후보들을 더 적게 생성하는 경향이 있다. 위치 지원 모델의 후보자에 대한 사용자까지의 98번째 백분위수 거리는 기준선의 4200마일에 비해 2600마일임을 관찰했다. 국내 사용자의 경우 위치 기반 모델이 훨씬 적은 국제 목록을 검색했음을 관찰했다. 그러나 국제 상장에 국한된 국내 구매 리콜은 거의 영향을 받지 않았으며, 이는 우리 모델이 어떤 국제 상장이 적절하고 매력적일 가능성이 있는지 정확하게 구별할 수 있음을 시사한다.

#### 7.2.2. 정성적 분석

그림 1에서 우리는 위치 특징과 최근 검색을 기반으로 개인화 정도가 미치는 영향을 관찰한다. 쿼리 "브리지 사진"의 경우 사용자/위치 기능에 따라 점차 증가합니다. NYC/SF에서 위치 특징을 갖는 사용자의 경우, 이력이 없는 사용자에 비해 더 국부화된 결과를 보게 된다. 또한, 1c에서, 사용자가 세션에서 "NYC"를 최근에 검색했을 때 결과가 NYC(즉, 마리오 쿠오모 브리지)로 훨씬 더 편향된다는 것을 알 수 있다.

### Online Evaluation

우리는 온라인에 시스템을 배포하고 라이브 에시 트래픽에 대한 A/B 테스트를 수행하여 시스템의 효과를 평가했다. 우리의 평가는 사이트 전체 전환율(CVR)과 유기 검색 구매율(OSPR)의 상대적 변화라는 두 가지 중요한 메트릭에 초점을 맞췄다. 이러한 메트릭은 Etsy에 대한 고객의 전반적인 검색 경험에 대한 귀중한 통찰력을 제공합니다. 종합적으로, 우리의 UPPER 시스템은 CVR을 2.63%, OSPR을 5.58% 향상시켰다. 특히, 개인화된 UPPER 변형은 예상대로 로그인 및 습관적인 구매자 세그먼트에 더 큰 영향을 미쳤다.

## 8. Conclusion

결론적으로, 본 논문에서는 통합 임베딩 기반 개인화 상품 검색 시스템인 UPPER을 소개하고, 학습 및 배포에 대한 포괄적인 세부 정보를 제공한다. 헤드 쿼리와 테일 쿼리 모두에서 오프라인 평가와 라이브 A/B 테스트를 통해 시스템의 효과를 성공적으로 입증했습니다.

## References

* (1)
* (2) 2023. Scikit-Optimize: Sequential model-based optimization in Python. [https://scikit-optimize.github.io] (https://scikit-optimize.github.io) Accessed: 2023-05-23.
*(3) Qingyao Ai, Daniel N Hill, SVN Vishwanathan, W Bruce Croft. 2019. 개인 맞춤형 제품 검색을 위한 제로 어텐션 모델입니다. 「제28회 ACM 국제 정보 및 지식 관리에 관한 회의의 진행례」에 기재되어 있다. 379-388.
*(4) F. Andreik, A.-M Kermarrec, and Nicolas Le Scournene. 2016. _캐시 지역성이 충분하지 않습니다. 제품 양자화가 빠른 고성능 최근접 이웃 검색_입니다. 288-299
*(5) Keping Bil, Qingyao Ai, W Bruce Croft. 2020. 개인 맞춤형 상품 검색을 위한 트랜스포머 기반 임베딩 모델. 「제3회 국제 ACM SIGIR 회의의 정보 검색에서의 연구 개발에 관한 회보」에 있다. 1521-1524.
*(6) Wei-Cheng Chang, Daniel Jiang, Hsiang-Fu Yu, Choon Hui Teo, Jong Zhang, Kai Zhong, Kedarnath Kolluri, Qie Hu, Nikhil Shandiya, Vyacheslav leyergalov, et al. 2021. Extreme multi-label learning for semantic matching in product search. _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_. 2643-2651.
*(7) David R. 셰리톤 2019. doc2query에서 docTTTTquery로.
*(8) Luyu Gao, Zhuyuan Dai, Tongfei Chen, Zhen Fan, Benjamin Van Durme, Janie Callan. 2021. Complement lexical retrieval model with semantic residualembeddings. In Advances in Information Retrieval, pp.1460-1460. Cited by:SS2.
* D. Golovin, B. Solnik, S. Moitra, G. Kochanski, J. Karoro, and D. Sculley (2017)Google vizer: a service for black-box optimization. In Proceedings of the 23rd ACM SIGKDD International conference on Knowledge discovery and data mining, pp. 1487-1495. Cited by: SS2.
* W. L. Hamilton, R. Ying, and J. Leskovec (2017)Inductive representation learning on large graph. 제31차 국제 신경 정보 처리 시스템 회의에서 SS2가 인용한다.
*S. 호프스타터 Zhihagher, and A. Hanbury (2020) 해석 가능 및 시간-예산-제약 상황화 for re-ranking. arXiv preprint arXiv:2002.01842. Cited by: SS2.
* J. Huang, A. Sharma, S. 선락 Xia, D. Zhang, P. Pronin, J. Padmanabhan, G. Ottaviano, and L. Yang(2020)Embedding-based retrieval in facebook search. In Proceedings of the 22th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2553-2561. Cited by: SS2.
* J. Huang, A. Sharma, S. 선락 Xia, D. Zhang, P. Pronin, J. Padmanabhan, G. Ottaviano, and L. Yang(2020)Embedding-based retrieval in facebook search. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2553-2561. Cited by: SS2.
* P. Huang, X. 허정가오 Deng, A. Acero, L. Heck(2013)Learning deep structured semantic models for web search using clickthrough data. In Proceedings of the 22nd ACM International Conference on Information & Knowledge Management, pp. 3233-3238. Cited by: SS2.
*Z. 장엘자라우디 Hartmann, D. Karakos, L. Zhao (2020) Cross-lingual information retrieval with BERT. In Proceedings of the workshop on Cross-Language Search and Summarization of Text and Speech (CLSSTS2020), pp. 149-157. Cited by: SS2.
* J. Johnson, M. Douze, and H. Jegou (2017)Billion-scale similarity search with GPUs. IEEE Transactions on Big Data 7, pp. 535-547. Cited by: SS2.
* S. K. Kamaker Santu, P. Sondhi, and C. Zhai(2017)On learning to rank for e-commerce search. In Proceedings of the 40th international ACM SIGIR conference on research and development in information retrieval, pp. 475-484. Cited by: SS2.
* J. Devlin M. C. Kenton and L. K. Toutanova (2019)Bert: Pre-training of deep 양방향 Transformers for language understanding. In Proceedings of a near-ILT, Vol.1, pp.2. Cited by:SS2.
*S. 이영 진경린 양석호 정석 Wu, Q. Ma(2021)Embedding-based product retrieval in lnaoo search. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pp. 3467-3471. Cited by: SS2.
*H. Lu, Y. 후태 조태 우영 Song, and B. Yin(2021)Graph-based multilingual product retrieval in e-commerce search. NAACL, pp. 1177-1180. Cited by: SS2.
* A. Magnani, F. Liu, S. 차이다론 Yadav, P. Reddy Suram, A. Buttyunthussery, S. 진민 시애철 Lee, and C. Liao (2022)Semantic retrieval at wlamart. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pp. 3495-3503. Cited by: SS2.
* Y. A. Malkov and D. A. Yashunin (2020)Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graph. IEEE Trans. Pattern Anal. 마케터 Intell.42(4), pp.824-836. External Links: Document, ISSN 1039-7498, Link Cited by: SS2.
* P. Nagan, Y. 장성훈 야오영 모한 락쉬만 Allen Ding, A. Shingavi, C. Hui Teo, H. Gu, and B. Yin(2019)Semantic product search. In Proceedings of the 28th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 191-197. Cited by: SS2.
* L. 방영 란재국 완, X. Cheng(2016)Text matching as image recognition. Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pp. 2793-2799. Cited by: SS2.
* C. Raffel, N. 셰이저 A 로버츠 K 이상 나랑모 마테나 주원 Li, and P. J. Liu (2020)Exploring the limit of transfer learning with Unified text-to-text transformer. J. Mach. 배워 Res.21(Article), pp.6792-6802. Cited by: SS2.
* V. 산락 Debut, J. Chaumond, T. Wolf (2019)DistilBERT: 증류된 버전의 BERT: 더 작고, 빠르고, 저렴하고, 더 가볍다. ArXiv abs/1910.011018. 인용: SS2.
*Y. 신석 허정가오 Deng, and G. Mesnil (2014)A latent semantic model with convolutional-pooling structure for information retrieval. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, pp. 101-110. Cited by: SS2.
*S. 완영 란재수 Pang, X. Cheng (2016)Match-sktnn: 공간 rnn으로 재귀적 매칭 구조를 모델링한다. Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, pp. 2922-2928. Cited by: SS2.
*X. 왕석 그민 Wang, F. Feng, T. Chua(2019)Neural Graph Collaborative Filtering. In Proceedings of the 24th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 165-174. Cited by: SS2.
*Y. 시태 나X 샤오성 만찬다 라오진 Xu, G. Shu, E. Vaiteg, J. Tennett, and H. Wang(2022)Embedding-imagen discovery search model at infaxax. arXiv. External Links: 2209.05555 Cited by: SS2.
* J. Zhan, J. Mao, Y. 유종국 Zhang, S. Ma(2021) 하드 네거티브를 이용한 밀집 검색 모델 학습 최적화. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 1503-1512. Cited by: SS2.
*H. 장, S. 왕광 장진 탕영 장영 샤오원 Yan, W. Yang(2020)Towards personalized and semantic retrieval: End-to-end solution for e-commerce search via embedding learning. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 2047-2046. Cited by: SS2.
* W. Zhang and K. Stratos (2021) 잡음 대비 추정에서 하드 네거티브를 이해한다. SS2에 의해 인용된 계산 언어학 협회의 북미 장에서.
*Y. 장대왕 Zhang(2019)Neural lr은 제품 검색을 위한 랭킹 모델인 그래프 임베딩을 만난다. The World Wide Web Conference, pp. 2390-2400. Cited by: SS2.
* L. 장락 웨인석 Ya, Z. Jun (2021)은 사후 훈련과 함께 견고하게 최적화된 BERT 사전 훈련 접근법이다. The Proceedings of the 20th Chinese National Conference on Computational Linguistics, pp. 1218-1227. Cited by: SS2.
